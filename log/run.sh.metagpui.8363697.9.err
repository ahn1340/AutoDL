/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 22:02:28.406532: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 22:02:28.410796: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299865000 Hz
2020-03-09 22:02:28.411073: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fec69a2d40 executing computations on platform Host. Devices:
2020-03-09 22:02:28.411110: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 22:02:28.411846: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

22:02:28 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f5c54782630; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:33743>
22:02:28 WORKER: No dispatcher found. Waiting for one to initiate contact.
22:02:28 WORKER: start listening for jobs
22:02:28 wait_for_workers trying to get the condition
22:02:28 DISPATCHER: started the 'discover_worker' thread
22:02:28 DISPATCHER: started the 'job_runner' thread
22:02:28 DISPATCHER: Pyro daemon running on localhost:45867
22:02:28 HBMASTER: only 0 worker(s) available, waiting for at least 1.
22:02:28 DISPATCHER: Starting worker discovery
22:02:28 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
22:02:28 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1575140037953214272
22:02:28 HBMASTER: number of workers changed to 1
22:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:28 adjust_queue_size: lock accquired
22:02:28 HBMASTER: adjusted queue size to (0, 1)
22:02:28 DISPATCHER: Finished worker discovery
22:02:28 DISPATCHER: A new worker triggered discover_worker
22:02:28 DISPATCHER: Trying to submit another job.
22:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:28 Enough workers to start this run!
22:02:28 DISPATCHER: Starting worker discovery
22:02:28 HBMASTER: starting run at 1583787748.506606
22:02:28 start sampling a new configuration.
22:02:28 done sampling a new configuration.
22:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:28 HBMASTER: schedule new run for iteration 0
22:02:28 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
22:02:28 HBMASTER: submitting job (0, 0, 0) to dispatcher
22:02:28 DISPATCHER: trying to submit job (0, 0, 0)
22:02:28 DISPATCHER: Finished worker discovery
22:02:28 DISPATCHER: trying to notify the job_runner thread.
22:02:28 HBMASTER: job (0, 0, 0) submitted to dispatcher
22:02:28 DISPATCHER: Trying to submit another job.
22:02:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:02:28 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:02:28 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:02:28 WORKER: start processing job (0, 0, 0)
22:02:28 WORKER: args: ()
22:02:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 201, 'last_n_outputs': 33, 'leak_rate': 0.8927054914364885, 'lr': 0.01085277587972539, 'optimizer': 'SGD', 'sparsity': 0.8749993070684813, 'steps_to_train': 26, 'weight_decay': 0.050977431878344415}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:03:23 WORKER: done with job (0, 0, 0), trying to register it.
22:03:23 WORKER: registered result for job (0, 0, 0) with dispatcher
22:03:23 DISPATCHER: job (0, 0, 0) finished
22:03:23 DISPATCHER: register_result: lock acquired
22:03:23 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:03:23 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 201, 'last_n_outputs': 33, 'leak_rate': 0.8927054914364885, 'lr': 0.01085277587972539, 'optimizer': 'SGD', 'sparsity': 0.8749993070684813, 'steps_to_train': 26, 'weight_decay': 0.050977431878344415}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43418058513347324, 'info': {'data02': 0.43418058513347324, 'config': "{'batch_size': 128, 'hidden_dim': 201, 'last_n_outputs': 33, 'leak_rate': 0.8927054914364885, 'lr': 0.01085277587972539, 'optimizer': 'SGD', 'sparsity': 0.8749993070684813, 'steps_to_train': 26, 'weight_decay': 0.050977431878344415}"}}
exception: None

22:03:23 job_callback for (0, 0, 0) started
22:03:23 DISPATCHER: Trying to submit another job.
22:03:23 job_callback for (0, 0, 0) got condition
22:03:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:03:23 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:03:23 HBMASTER: Trying to run another job!
22:03:23 job_callback for (0, 0, 0) finished
22:03:23 start sampling a new configuration.
22:03:23 done sampling a new configuration.
22:03:23 HBMASTER: schedule new run for iteration 0
22:03:23 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
22:03:23 HBMASTER: submitting job (0, 0, 1) to dispatcher
22:03:23 DISPATCHER: trying to submit job (0, 0, 1)
22:03:23 DISPATCHER: trying to notify the job_runner thread.
22:03:23 HBMASTER: job (0, 0, 1) submitted to dispatcher
22:03:23 DISPATCHER: Trying to submit another job.
22:03:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:03:23 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:03:23 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:03:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:03:23 WORKER: start processing job (0, 0, 1)
22:03:23 WORKER: args: ()
22:03:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 474, 'last_n_outputs': 11, 'leak_rate': 0.8708196454088692, 'lr': 0.006386462679891074, 'optimizer': 'Adam', 'sparsity': 0.9796455745305964, 'steps_to_train': 48, 'weight_decay': 0.1155925272735597}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:03:28 DISPATCHER: Starting worker discovery
22:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:28 DISPATCHER: Finished worker discovery
22:04:13 WORKER: done with job (0, 0, 1), trying to register it.
22:04:13 WORKER: registered result for job (0, 0, 1) with dispatcher
22:04:13 DISPATCHER: job (0, 0, 1) finished
22:04:13 DISPATCHER: register_result: lock acquired
22:04:13 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:04:13 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 474, 'last_n_outputs': 11, 'leak_rate': 0.8708196454088692, 'lr': 0.006386462679891074, 'optimizer': 'Adam', 'sparsity': 0.9796455745305964, 'steps_to_train': 48, 'weight_decay': 0.1155925272735597}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24167340363319134, 'info': {'data02': 0.24167340363319134, 'config': "{'batch_size': 16, 'hidden_dim': 474, 'last_n_outputs': 11, 'leak_rate': 0.8708196454088692, 'lr': 0.006386462679891074, 'optimizer': 'Adam', 'sparsity': 0.9796455745305964, 'steps_to_train': 48, 'weight_decay': 0.1155925272735597}"}}
exception: None

22:04:13 job_callback for (0, 0, 1) started
22:04:13 job_callback for (0, 0, 1) got condition
22:04:13 DISPATCHER: Trying to submit another job.
22:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:13 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:04:13 HBMASTER: Trying to run another job!
22:04:13 job_callback for (0, 0, 1) finished
22:04:13 start sampling a new configuration.
22:04:13 done sampling a new configuration.
22:04:13 HBMASTER: schedule new run for iteration 0
22:04:13 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
22:04:13 HBMASTER: submitting job (0, 0, 2) to dispatcher
22:04:13 DISPATCHER: trying to submit job (0, 0, 2)
22:04:13 DISPATCHER: trying to notify the job_runner thread.
22:04:13 HBMASTER: job (0, 0, 2) submitted to dispatcher
22:04:13 DISPATCHER: Trying to submit another job.
22:04:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:13 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:04:13 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:04:13 WORKER: start processing job (0, 0, 2)
22:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:13 WORKER: args: ()
22:04:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 914, 'last_n_outputs': 22, 'leak_rate': 0.8732216171569299, 'lr': 0.015688074884239952, 'optimizer': 'Adam', 'sparsity': 0.7541250594713456, 'steps_to_train': 11, 'weight_decay': 0.04475155375738159}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:04:28 DISPATCHER: Starting worker discovery
22:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:28 DISPATCHER: Finished worker discovery
22:05:03 WORKER: done with job (0, 0, 2), trying to register it.
22:05:03 WORKER: registered result for job (0, 0, 2) with dispatcher
22:05:03 DISPATCHER: job (0, 0, 2) finished
22:05:03 DISPATCHER: register_result: lock acquired
22:05:03 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:05:03 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 914, 'last_n_outputs': 22, 'leak_rate': 0.8732216171569299, 'lr': 0.015688074884239952, 'optimizer': 'Adam', 'sparsity': 0.7541250594713456, 'steps_to_train': 11, 'weight_decay': 0.04475155375738159}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1548869512127855, 'info': {'data02': 0.1548869512127855, 'config': "{'batch_size': 32, 'hidden_dim': 914, 'last_n_outputs': 22, 'leak_rate': 0.8732216171569299, 'lr': 0.015688074884239952, 'optimizer': 'Adam', 'sparsity': 0.7541250594713456, 'steps_to_train': 11, 'weight_decay': 0.04475155375738159}"}}
exception: None

22:05:03 job_callback for (0, 0, 2) started
22:05:03 DISPATCHER: Trying to submit another job.
22:05:03 job_callback for (0, 0, 2) got condition
22:05:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:05:03 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:05:03 HBMASTER: Trying to run another job!
22:05:03 job_callback for (0, 0, 2) finished
22:05:03 start sampling a new configuration.
22:05:03 done sampling a new configuration.
22:05:03 HBMASTER: schedule new run for iteration 0
22:05:03 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
22:05:03 HBMASTER: submitting job (0, 0, 3) to dispatcher
22:05:03 DISPATCHER: trying to submit job (0, 0, 3)
22:05:03 DISPATCHER: trying to notify the job_runner thread.
22:05:03 HBMASTER: job (0, 0, 3) submitted to dispatcher
22:05:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:05:03 DISPATCHER: Trying to submit another job.
22:05:03 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:05:03 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:05:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:05:03 WORKER: start processing job (0, 0, 3)
22:05:03 WORKER: args: ()
22:05:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 497, 'last_n_outputs': 49, 'leak_rate': 0.9809186031085639, 'lr': 0.010663793778463947, 'optimizer': 'SGD', 'sparsity': 0.899935488274374, 'steps_to_train': 35, 'weight_decay': 0.023558931681380315}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:05:28 DISPATCHER: Starting worker discovery
22:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:28 DISPATCHER: Finished worker discovery
22:05:52 WORKER: done with job (0, 0, 3), trying to register it.
22:05:52 WORKER: registered result for job (0, 0, 3) with dispatcher
22:05:52 DISPATCHER: job (0, 0, 3) finished
22:05:52 DISPATCHER: register_result: lock acquired
22:05:52 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:05:52 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 497, 'last_n_outputs': 49, 'leak_rate': 0.9809186031085639, 'lr': 0.010663793778463947, 'optimizer': 'SGD', 'sparsity': 0.899935488274374, 'steps_to_train': 35, 'weight_decay': 0.023558931681380315}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6035612030757374, 'info': {'data02': 0.6035612030757374, 'config': "{'batch_size': 64, 'hidden_dim': 497, 'last_n_outputs': 49, 'leak_rate': 0.9809186031085639, 'lr': 0.010663793778463947, 'optimizer': 'SGD', 'sparsity': 0.899935488274374, 'steps_to_train': 35, 'weight_decay': 0.023558931681380315}"}}
exception: None

22:05:52 job_callback for (0, 0, 3) started
22:05:52 job_callback for (0, 0, 3) got condition
22:05:52 DISPATCHER: Trying to submit another job.
22:05:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:05:52 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:05:52 HBMASTER: Trying to run another job!
22:05:52 job_callback for (0, 0, 3) finished
22:05:52 start sampling a new configuration.
22:05:52 done sampling a new configuration.
22:05:52 HBMASTER: schedule new run for iteration 0
22:05:52 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
22:05:52 HBMASTER: submitting job (0, 0, 4) to dispatcher
22:05:52 DISPATCHER: trying to submit job (0, 0, 4)
22:05:52 DISPATCHER: trying to notify the job_runner thread.
22:05:52 HBMASTER: job (0, 0, 4) submitted to dispatcher
22:05:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:05:52 DISPATCHER: Trying to submit another job.
22:05:52 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:05:52 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:05:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:05:52 WORKER: start processing job (0, 0, 4)
22:05:52 WORKER: args: ()
22:05:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 981, 'last_n_outputs': 16, 'leak_rate': 0.8173629927014847, 'lr': 0.0010024217990973556, 'optimizer': 'SGD', 'sparsity': 0.9807008057468792, 'steps_to_train': 70, 'weight_decay': 0.012404568698584757}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:06:28 DISPATCHER: Starting worker discovery
22:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:28 DISPATCHER: Finished worker discovery
22:06:44 WORKER: done with job (0, 0, 4), trying to register it.
22:06:44 WORKER: registered result for job (0, 0, 4) with dispatcher
22:06:44 DISPATCHER: job (0, 0, 4) finished
22:06:44 DISPATCHER: register_result: lock acquired
22:06:44 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:06:44 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 981, 'last_n_outputs': 16, 'leak_rate': 0.8173629927014847, 'lr': 0.0010024217990973556, 'optimizer': 'SGD', 'sparsity': 0.9807008057468792, 'steps_to_train': 70, 'weight_decay': 0.012404568698584757}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4895497247022785, 'info': {'data02': 0.4895497247022785, 'config': "{'batch_size': 32, 'hidden_dim': 981, 'last_n_outputs': 16, 'leak_rate': 0.8173629927014847, 'lr': 0.0010024217990973556, 'optimizer': 'SGD', 'sparsity': 0.9807008057468792, 'steps_to_train': 70, 'weight_decay': 0.012404568698584757}"}}
exception: None

22:06:44 job_callback for (0, 0, 4) started
22:06:44 DISPATCHER: Trying to submit another job.
22:06:44 job_callback for (0, 0, 4) got condition
22:06:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:06:44 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:06:44 HBMASTER: Trying to run another job!
22:06:44 job_callback for (0, 0, 4) finished
22:06:44 start sampling a new configuration.
22:06:44 done sampling a new configuration.
22:06:44 HBMASTER: schedule new run for iteration 0
22:06:44 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
22:06:44 HBMASTER: submitting job (0, 0, 5) to dispatcher
22:06:44 DISPATCHER: trying to submit job (0, 0, 5)
22:06:44 DISPATCHER: trying to notify the job_runner thread.
22:06:44 HBMASTER: job (0, 0, 5) submitted to dispatcher
22:06:44 DISPATCHER: Trying to submit another job.
22:06:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:06:44 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:06:44 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:06:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:06:44 WORKER: start processing job (0, 0, 5)
22:06:44 WORKER: args: ()
22:06:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:07:28 DISPATCHER: Starting worker discovery
22:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:28 DISPATCHER: Finished worker discovery
22:07:35 WORKER: done with job (0, 0, 5), trying to register it.
22:07:35 WORKER: registered result for job (0, 0, 5) with dispatcher
22:07:35 DISPATCHER: job (0, 0, 5) finished
22:07:35 DISPATCHER: register_result: lock acquired
22:07:35 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:07:35 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5790344927936667, 'info': {'data02': 0.5790344927936667, 'config': "{'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}"}}
exception: None

22:07:35 job_callback for (0, 0, 5) started
22:07:35 job_callback for (0, 0, 5) got condition
22:07:35 DISPATCHER: Trying to submit another job.
22:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:07:35 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:07:35 HBMASTER: Trying to run another job!
22:07:35 job_callback for (0, 0, 5) finished
22:07:35 start sampling a new configuration.
22:07:35 done sampling a new configuration.
22:07:35 HBMASTER: schedule new run for iteration 0
22:07:35 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
22:07:35 HBMASTER: submitting job (0, 0, 6) to dispatcher
22:07:35 DISPATCHER: trying to submit job (0, 0, 6)
22:07:35 DISPATCHER: trying to notify the job_runner thread.
22:07:35 HBMASTER: job (0, 0, 6) submitted to dispatcher
22:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:07:35 DISPATCHER: Trying to submit another job.
22:07:35 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:07:35 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:07:35 WORKER: start processing job (0, 0, 6)
22:07:35 WORKER: args: ()
22:07:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 14, 'leak_rate': 0.8125805776517413, 'lr': 0.002870740647424209, 'optimizer': 'Adam', 'sparsity': 0.9362347013976964, 'steps_to_train': 32, 'weight_decay': 0.019767323488678355}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:08:24 WORKER: done with job (0, 0, 6), trying to register it.
22:08:24 WORKER: registered result for job (0, 0, 6) with dispatcher
22:08:24 DISPATCHER: job (0, 0, 6) finished
22:08:24 DISPATCHER: register_result: lock acquired
22:08:24 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:08:24 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 14, 'leak_rate': 0.8125805776517413, 'lr': 0.002870740647424209, 'optimizer': 'Adam', 'sparsity': 0.9362347013976964, 'steps_to_train': 32, 'weight_decay': 0.019767323488678355}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5421917622513167, 'info': {'data02': 0.5421917622513167, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 14, 'leak_rate': 0.8125805776517413, 'lr': 0.002870740647424209, 'optimizer': 'Adam', 'sparsity': 0.9362347013976964, 'steps_to_train': 32, 'weight_decay': 0.019767323488678355}"}}
exception: None

22:08:24 job_callback for (0, 0, 6) started
22:08:24 DISPATCHER: Trying to submit another job.
22:08:24 job_callback for (0, 0, 6) got condition
22:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:08:24 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:08:24 HBMASTER: Trying to run another job!
22:08:24 job_callback for (0, 0, 6) finished
22:08:24 start sampling a new configuration.
22:08:24 done sampling a new configuration.
22:08:24 HBMASTER: schedule new run for iteration 0
22:08:24 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
22:08:24 HBMASTER: submitting job (0, 0, 7) to dispatcher
22:08:24 DISPATCHER: trying to submit job (0, 0, 7)
22:08:24 DISPATCHER: trying to notify the job_runner thread.
22:08:24 HBMASTER: job (0, 0, 7) submitted to dispatcher
22:08:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:08:24 DISPATCHER: Trying to submit another job.
22:08:24 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:08:24 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:08:24 WORKER: start processing job (0, 0, 7)
22:08:24 WORKER: args: ()
22:08:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 243, 'last_n_outputs': 31, 'leak_rate': 0.8826710020048195, 'lr': 0.002864170978971059, 'optimizer': 'Adam', 'sparsity': 0.889456461111989, 'steps_to_train': 27, 'weight_decay': 0.026370969181508348}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:08:28 DISPATCHER: Starting worker discovery
22:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:28 DISPATCHER: Finished worker discovery
22:09:13 WORKER: done with job (0, 0, 7), trying to register it.
22:09:13 WORKER: registered result for job (0, 0, 7) with dispatcher
22:09:13 DISPATCHER: job (0, 0, 7) finished
22:09:13 DISPATCHER: register_result: lock acquired
22:09:13 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:09:13 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 243, 'last_n_outputs': 31, 'leak_rate': 0.8826710020048195, 'lr': 0.002864170978971059, 'optimizer': 'Adam', 'sparsity': 0.889456461111989, 'steps_to_train': 27, 'weight_decay': 0.026370969181508348}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4293590796730957, 'info': {'data02': 0.4293590796730957, 'config': "{'batch_size': 32, 'hidden_dim': 243, 'last_n_outputs': 31, 'leak_rate': 0.8826710020048195, 'lr': 0.002864170978971059, 'optimizer': 'Adam', 'sparsity': 0.889456461111989, 'steps_to_train': 27, 'weight_decay': 0.026370969181508348}"}}
exception: None

22:09:13 job_callback for (0, 0, 7) started
22:09:13 job_callback for (0, 0, 7) got condition
22:09:13 DISPATCHER: Trying to submit another job.
22:09:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:09:13 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:09:13 HBMASTER: Trying to run another job!
22:09:13 job_callback for (0, 0, 7) finished
22:09:13 start sampling a new configuration.
22:09:13 done sampling a new configuration.
22:09:13 HBMASTER: schedule new run for iteration 0
22:09:13 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
22:09:13 HBMASTER: submitting job (0, 0, 8) to dispatcher
22:09:13 DISPATCHER: trying to submit job (0, 0, 8)
22:09:13 DISPATCHER: trying to notify the job_runner thread.
22:09:13 HBMASTER: job (0, 0, 8) submitted to dispatcher
22:09:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:09:13 DISPATCHER: Trying to submit another job.
22:09:13 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:09:13 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:09:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:09:13 WORKER: start processing job (0, 0, 8)
22:09:13 WORKER: args: ()
22:09:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 808, 'last_n_outputs': 27, 'leak_rate': 0.9335443319539694, 'lr': 0.0791188999238312, 'optimizer': 'Adam', 'sparsity': 0.8224818612358139, 'steps_to_train': 24, 'weight_decay': 0.06876614184776991}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:09:28 DISPATCHER: Starting worker discovery
22:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:28 DISPATCHER: Finished worker discovery
22:10:03 WORKER: done with job (0, 0, 8), trying to register it.
22:10:03 WORKER: registered result for job (0, 0, 8) with dispatcher
22:10:03 DISPATCHER: job (0, 0, 8) finished
22:10:03 DISPATCHER: register_result: lock acquired
22:10:03 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:10:03 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 808, 'last_n_outputs': 27, 'leak_rate': 0.9335443319539694, 'lr': 0.0791188999238312, 'optimizer': 'Adam', 'sparsity': 0.8224818612358139, 'steps_to_train': 24, 'weight_decay': 0.06876614184776991}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1029125722936987, 'info': {'data02': 0.1029125722936987, 'config': "{'batch_size': 64, 'hidden_dim': 808, 'last_n_outputs': 27, 'leak_rate': 0.9335443319539694, 'lr': 0.0791188999238312, 'optimizer': 'Adam', 'sparsity': 0.8224818612358139, 'steps_to_train': 24, 'weight_decay': 0.06876614184776991}"}}
exception: None

22:10:03 job_callback for (0, 0, 8) started
22:10:03 DISPATCHER: Trying to submit another job.
22:10:03 job_callback for (0, 0, 8) got condition
22:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:10:03 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:10:03 HBMASTER: Trying to run another job!
22:10:03 job_callback for (0, 0, 8) finished
22:10:03 start sampling a new configuration.
22:10:03 done sampling a new configuration.
22:10:03 HBMASTER: schedule new run for iteration 0
22:10:03 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
22:10:03 HBMASTER: submitting job (0, 0, 9) to dispatcher
22:10:03 DISPATCHER: trying to submit job (0, 0, 9)
22:10:03 DISPATCHER: trying to notify the job_runner thread.
22:10:03 HBMASTER: job (0, 0, 9) submitted to dispatcher
22:10:03 DISPATCHER: Trying to submit another job.
22:10:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:10:03 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:10:03 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:10:03 WORKER: start processing job (0, 0, 9)
22:10:03 WORKER: args: ()
22:10:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 580, 'last_n_outputs': 18, 'leak_rate': 0.8985400313959835, 'lr': 0.003772354011225016, 'optimizer': 'Adam', 'sparsity': 0.9367637430669644, 'steps_to_train': 22, 'weight_decay': 0.025701938488570057}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:10:28 DISPATCHER: Starting worker discovery
22:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:28 DISPATCHER: Finished worker discovery
22:10:54 WORKER: done with job (0, 0, 9), trying to register it.
22:10:54 WORKER: registered result for job (0, 0, 9) with dispatcher
22:10:54 DISPATCHER: job (0, 0, 9) finished
22:10:54 DISPATCHER: register_result: lock acquired
22:10:54 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:10:54 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 580, 'last_n_outputs': 18, 'leak_rate': 0.8985400313959835, 'lr': 0.003772354011225016, 'optimizer': 'Adam', 'sparsity': 0.9367637430669644, 'steps_to_train': 22, 'weight_decay': 0.025701938488570057}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4355067641520746, 'info': {'data02': 0.4355067641520746, 'config': "{'batch_size': 64, 'hidden_dim': 580, 'last_n_outputs': 18, 'leak_rate': 0.8985400313959835, 'lr': 0.003772354011225016, 'optimizer': 'Adam', 'sparsity': 0.9367637430669644, 'steps_to_train': 22, 'weight_decay': 0.025701938488570057}"}}
exception: None

22:10:54 job_callback for (0, 0, 9) started
22:10:54 DISPATCHER: Trying to submit another job.
22:10:54 job_callback for (0, 0, 9) got condition
22:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:10:54 HBMASTER: Trying to run another job!
22:10:54 job_callback for (0, 0, 9) finished
22:10:54 start sampling a new configuration.
22:10:54 done sampling a new configuration.
22:10:54 HBMASTER: schedule new run for iteration 0
22:10:54 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
22:10:54 HBMASTER: submitting job (0, 0, 10) to dispatcher
22:10:54 DISPATCHER: trying to submit job (0, 0, 10)
22:10:54 DISPATCHER: trying to notify the job_runner thread.
22:10:54 HBMASTER: job (0, 0, 10) submitted to dispatcher
22:10:54 DISPATCHER: Trying to submit another job.
22:10:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:10:54 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:10:54 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:10:54 WORKER: start processing job (0, 0, 10)
22:10:54 WORKER: args: ()
22:10:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 222, 'last_n_outputs': 37, 'leak_rate': 0.9783702669297386, 'lr': 0.0055365905220786755, 'optimizer': 'SGD', 'sparsity': 0.7834681035977051, 'steps_to_train': 25, 'weight_decay': 0.018607379746279712}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:11:28 DISPATCHER: Starting worker discovery
22:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:28 DISPATCHER: Finished worker discovery
22:11:44 WORKER: done with job (0, 0, 10), trying to register it.
22:11:44 WORKER: registered result for job (0, 0, 10) with dispatcher
22:11:44 DISPATCHER: job (0, 0, 10) finished
22:11:44 DISPATCHER: register_result: lock acquired
22:11:44 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:11:44 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 222, 'last_n_outputs': 37, 'leak_rate': 0.9783702669297386, 'lr': 0.0055365905220786755, 'optimizer': 'SGD', 'sparsity': 0.7834681035977051, 'steps_to_train': 25, 'weight_decay': 0.018607379746279712}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5149145972403129, 'info': {'data02': 0.5149145972403129, 'config': "{'batch_size': 64, 'hidden_dim': 222, 'last_n_outputs': 37, 'leak_rate': 0.9783702669297386, 'lr': 0.0055365905220786755, 'optimizer': 'SGD', 'sparsity': 0.7834681035977051, 'steps_to_train': 25, 'weight_decay': 0.018607379746279712}"}}
exception: None

22:11:44 job_callback for (0, 0, 10) started
22:11:44 DISPATCHER: Trying to submit another job.
22:11:44 job_callback for (0, 0, 10) got condition
22:11:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:44 HBMASTER: Trying to run another job!
22:11:44 job_callback for (0, 0, 10) finished
22:11:44 start sampling a new configuration.
22:11:44 done sampling a new configuration.
22:11:44 HBMASTER: schedule new run for iteration 0
22:11:44 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
22:11:44 HBMASTER: submitting job (0, 0, 11) to dispatcher
22:11:44 DISPATCHER: trying to submit job (0, 0, 11)
22:11:44 DISPATCHER: trying to notify the job_runner thread.
22:11:44 HBMASTER: job (0, 0, 11) submitted to dispatcher
22:11:44 DISPATCHER: Trying to submit another job.
22:11:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:44 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:11:44 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:11:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:44 WORKER: start processing job (0, 0, 11)
22:11:44 WORKER: args: ()
22:11:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 589, 'last_n_outputs': 37, 'leak_rate': 0.9013888142126162, 'lr': 0.05683653847411912, 'optimizer': 'SGD', 'sparsity': 0.9150950093236727, 'steps_to_train': 97, 'weight_decay': 0.031520188178275364}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:12:28 DISPATCHER: Starting worker discovery
22:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:28 DISPATCHER: Finished worker discovery
22:12:34 WORKER: done with job (0, 0, 11), trying to register it.
22:12:34 WORKER: registered result for job (0, 0, 11) with dispatcher
22:12:34 DISPATCHER: job (0, 0, 11) finished
22:12:34 DISPATCHER: register_result: lock acquired
22:12:34 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:12:34 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 589, 'last_n_outputs': 37, 'leak_rate': 0.9013888142126162, 'lr': 0.05683653847411912, 'optimizer': 'SGD', 'sparsity': 0.9150950093236727, 'steps_to_train': 97, 'weight_decay': 0.031520188178275364}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45877363444644204, 'info': {'data02': 0.45877363444644204, 'config': "{'batch_size': 64, 'hidden_dim': 589, 'last_n_outputs': 37, 'leak_rate': 0.9013888142126162, 'lr': 0.05683653847411912, 'optimizer': 'SGD', 'sparsity': 0.9150950093236727, 'steps_to_train': 97, 'weight_decay': 0.031520188178275364}"}}
exception: None

22:12:34 job_callback for (0, 0, 11) started
22:12:34 job_callback for (0, 0, 11) got condition
22:12:34 DISPATCHER: Trying to submit another job.
22:12:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:12:34 HBMASTER: Trying to run another job!
22:12:34 job_callback for (0, 0, 11) finished
22:12:34 start sampling a new configuration.
22:12:34 done sampling a new configuration.
22:12:34 HBMASTER: schedule new run for iteration 0
22:12:34 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
22:12:34 HBMASTER: submitting job (0, 0, 12) to dispatcher
22:12:34 DISPATCHER: trying to submit job (0, 0, 12)
22:12:34 DISPATCHER: trying to notify the job_runner thread.
22:12:34 HBMASTER: job (0, 0, 12) submitted to dispatcher
22:12:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:12:34 DISPATCHER: Trying to submit another job.
22:12:34 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:12:34 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:12:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:12:34 WORKER: start processing job (0, 0, 12)
22:12:34 WORKER: args: ()
22:12:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 603, 'last_n_outputs': 47, 'leak_rate': 0.7540795790878727, 'lr': 0.0022601223260617265, 'optimizer': 'Adam', 'sparsity': 0.813872034537129, 'steps_to_train': 33, 'weight_decay': 0.016375522972586324}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:13:23 WORKER: done with job (0, 0, 12), trying to register it.
22:13:23 WORKER: registered result for job (0, 0, 12) with dispatcher
22:13:23 DISPATCHER: job (0, 0, 12) finished
22:13:23 DISPATCHER: register_result: lock acquired
22:13:23 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:13:23 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 603, 'last_n_outputs': 47, 'leak_rate': 0.7540795790878727, 'lr': 0.0022601223260617265, 'optimizer': 'Adam', 'sparsity': 0.813872034537129, 'steps_to_train': 33, 'weight_decay': 0.016375522972586324}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49751553348735195, 'info': {'data02': 0.49751553348735195, 'config': "{'batch_size': 32, 'hidden_dim': 603, 'last_n_outputs': 47, 'leak_rate': 0.7540795790878727, 'lr': 0.0022601223260617265, 'optimizer': 'Adam', 'sparsity': 0.813872034537129, 'steps_to_train': 33, 'weight_decay': 0.016375522972586324}"}}
exception: None

22:13:23 job_callback for (0, 0, 12) started
22:13:23 DISPATCHER: Trying to submit another job.
22:13:23 job_callback for (0, 0, 12) got condition
22:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:13:23 HBMASTER: Trying to run another job!
22:13:23 job_callback for (0, 0, 12) finished
22:13:23 start sampling a new configuration.
22:13:23 done sampling a new configuration.
22:13:23 HBMASTER: schedule new run for iteration 0
22:13:23 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
22:13:23 HBMASTER: submitting job (0, 0, 13) to dispatcher
22:13:23 DISPATCHER: trying to submit job (0, 0, 13)
22:13:23 DISPATCHER: trying to notify the job_runner thread.
22:13:23 HBMASTER: job (0, 0, 13) submitted to dispatcher
22:13:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:13:23 DISPATCHER: Trying to submit another job.
22:13:23 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:13:23 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:13:23 WORKER: start processing job (0, 0, 13)
22:13:23 WORKER: args: ()
22:13:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 912, 'last_n_outputs': 13, 'leak_rate': 0.7581671897305919, 'lr': 0.004274895852029732, 'optimizer': 'SGD', 'sparsity': 0.8125008682960542, 'steps_to_train': 88, 'weight_decay': 0.013150052041845195}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:13:28 DISPATCHER: Starting worker discovery
22:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:28 DISPATCHER: Finished worker discovery
22:14:14 WORKER: done with job (0, 0, 13), trying to register it.
22:14:14 WORKER: registered result for job (0, 0, 13) with dispatcher
22:14:14 DISPATCHER: job (0, 0, 13) finished
22:14:14 DISPATCHER: register_result: lock acquired
22:14:14 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:14:14 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 912, 'last_n_outputs': 13, 'leak_rate': 0.7581671897305919, 'lr': 0.004274895852029732, 'optimizer': 'SGD', 'sparsity': 0.8125008682960542, 'steps_to_train': 88, 'weight_decay': 0.013150052041845195}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5746418888312697, 'info': {'data02': 0.5746418888312697, 'config': "{'batch_size': 16, 'hidden_dim': 912, 'last_n_outputs': 13, 'leak_rate': 0.7581671897305919, 'lr': 0.004274895852029732, 'optimizer': 'SGD', 'sparsity': 0.8125008682960542, 'steps_to_train': 88, 'weight_decay': 0.013150052041845195}"}}
exception: None

22:14:14 job_callback for (0, 0, 13) started
22:14:14 DISPATCHER: Trying to submit another job.
22:14:14 job_callback for (0, 0, 13) got condition
22:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:14:14 HBMASTER: Trying to run another job!
22:14:14 job_callback for (0, 0, 13) finished
22:14:14 start sampling a new configuration.
22:14:14 done sampling a new configuration.
22:14:14 HBMASTER: schedule new run for iteration 0
22:14:14 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
22:14:14 HBMASTER: submitting job (0, 0, 14) to dispatcher
22:14:14 DISPATCHER: trying to submit job (0, 0, 14)
22:14:14 DISPATCHER: trying to notify the job_runner thread.
22:14:14 HBMASTER: job (0, 0, 14) submitted to dispatcher
22:14:14 DISPATCHER: Trying to submit another job.
22:14:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:14:14 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:14:14 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:14:14 WORKER: start processing job (0, 0, 14)
22:14:14 WORKER: args: ()
22:14:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 274, 'last_n_outputs': 38, 'leak_rate': 0.9325680427075124, 'lr': 0.006346367003517431, 'optimizer': 'Adam', 'sparsity': 0.8255652487121022, 'steps_to_train': 72, 'weight_decay': 0.016076917376883805}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:14:28 DISPATCHER: Starting worker discovery
22:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:28 DISPATCHER: Finished worker discovery
22:15:05 WORKER: done with job (0, 0, 14), trying to register it.
22:15:05 WORKER: registered result for job (0, 0, 14) with dispatcher
22:15:05 DISPATCHER: job (0, 0, 14) finished
22:15:05 DISPATCHER: register_result: lock acquired
22:15:05 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:15:05 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 274, 'last_n_outputs': 38, 'leak_rate': 0.9325680427075124, 'lr': 0.006346367003517431, 'optimizer': 'Adam', 'sparsity': 0.8255652487121022, 'steps_to_train': 72, 'weight_decay': 0.016076917376883805}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28849645416032266, 'info': {'data02': 0.28849645416032266, 'config': "{'batch_size': 16, 'hidden_dim': 274, 'last_n_outputs': 38, 'leak_rate': 0.9325680427075124, 'lr': 0.006346367003517431, 'optimizer': 'Adam', 'sparsity': 0.8255652487121022, 'steps_to_train': 72, 'weight_decay': 0.016076917376883805}"}}
exception: None

22:15:05 job_callback for (0, 0, 14) started
22:15:05 DISPATCHER: Trying to submit another job.
22:15:05 job_callback for (0, 0, 14) got condition
22:15:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:15:05 HBMASTER: Trying to run another job!
22:15:05 job_callback for (0, 0, 14) finished
22:15:05 start sampling a new configuration.
22:15:05 done sampling a new configuration.
22:15:05 HBMASTER: schedule new run for iteration 0
22:15:05 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
22:15:05 HBMASTER: submitting job (0, 0, 15) to dispatcher
22:15:05 DISPATCHER: trying to submit job (0, 0, 15)
22:15:05 DISPATCHER: trying to notify the job_runner thread.
22:15:05 HBMASTER: job (0, 0, 15) submitted to dispatcher
22:15:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:15:05 DISPATCHER: Trying to submit another job.
22:15:05 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:15:05 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:15:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:15:05 WORKER: start processing job (0, 0, 15)
22:15:05 WORKER: args: ()
22:15:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 229, 'last_n_outputs': 16, 'leak_rate': 0.9098913716606579, 'lr': 0.011650984239854929, 'optimizer': 'SGD', 'sparsity': 0.8643836735619242, 'steps_to_train': 47, 'weight_decay': 0.014993951893354406}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:15:28 DISPATCHER: Starting worker discovery
22:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:28 DISPATCHER: Finished worker discovery
22:15:55 WORKER: done with job (0, 0, 15), trying to register it.
22:15:55 WORKER: registered result for job (0, 0, 15) with dispatcher
22:15:55 DISPATCHER: job (0, 0, 15) finished
22:15:55 DISPATCHER: register_result: lock acquired
22:15:55 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:15:55 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 229, 'last_n_outputs': 16, 'leak_rate': 0.9098913716606579, 'lr': 0.011650984239854929, 'optimizer': 'SGD', 'sparsity': 0.8643836735619242, 'steps_to_train': 47, 'weight_decay': 0.014993951893354406}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43816579430387015, 'info': {'data02': 0.43816579430387015, 'config': "{'batch_size': 16, 'hidden_dim': 229, 'last_n_outputs': 16, 'leak_rate': 0.9098913716606579, 'lr': 0.011650984239854929, 'optimizer': 'SGD', 'sparsity': 0.8643836735619242, 'steps_to_train': 47, 'weight_decay': 0.014993951893354406}"}}
exception: None

22:15:55 job_callback for (0, 0, 15) started
22:15:55 job_callback for (0, 0, 15) got condition
22:15:55 DISPATCHER: Trying to submit another job.
22:15:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:15:55 HBMASTER: Trying to run another job!
22:15:55 job_callback for (0, 0, 15) finished
22:15:55 start sampling a new configuration.
22:15:55 done sampling a new configuration.
22:15:55 HBMASTER: schedule new run for iteration 0
22:15:55 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
22:15:55 HBMASTER: submitting job (0, 0, 16) to dispatcher
22:15:55 DISPATCHER: trying to submit job (0, 0, 16)
22:15:55 DISPATCHER: trying to notify the job_runner thread.
22:15:55 HBMASTER: job (0, 0, 16) submitted to dispatcher
22:15:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:15:55 DISPATCHER: Trying to submit another job.
22:15:55 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:15:55 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:15:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:15:55 WORKER: start processing job (0, 0, 16)
22:15:55 WORKER: args: ()
22:15:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 483, 'last_n_outputs': 17, 'leak_rate': 0.9073418214681068, 'lr': 0.0022213238180909816, 'optimizer': 'Adam', 'sparsity': 0.8522520125088636, 'steps_to_train': 21, 'weight_decay': 0.023785062087939287}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:16:28 DISPATCHER: Starting worker discovery
22:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:28 DISPATCHER: Finished worker discovery
22:16:44 WORKER: done with job (0, 0, 16), trying to register it.
22:16:44 WORKER: registered result for job (0, 0, 16) with dispatcher
22:16:44 DISPATCHER: job (0, 0, 16) finished
22:16:44 DISPATCHER: register_result: lock acquired
22:16:44 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:16:44 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 483, 'last_n_outputs': 17, 'leak_rate': 0.9073418214681068, 'lr': 0.0022213238180909816, 'optimizer': 'Adam', 'sparsity': 0.8522520125088636, 'steps_to_train': 21, 'weight_decay': 0.023785062087939287}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4678324744682239, 'info': {'data02': 0.4678324744682239, 'config': "{'batch_size': 64, 'hidden_dim': 483, 'last_n_outputs': 17, 'leak_rate': 0.9073418214681068, 'lr': 0.0022213238180909816, 'optimizer': 'Adam', 'sparsity': 0.8522520125088636, 'steps_to_train': 21, 'weight_decay': 0.023785062087939287}"}}
exception: None

22:16:44 job_callback for (0, 0, 16) started
22:16:44 DISPATCHER: Trying to submit another job.
22:16:44 job_callback for (0, 0, 16) got condition
22:16:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:44 HBMASTER: Trying to run another job!
22:16:44 job_callback for (0, 0, 16) finished
22:16:44 start sampling a new configuration.
22:16:44 done sampling a new configuration.
22:16:44 HBMASTER: schedule new run for iteration 0
22:16:44 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
22:16:44 HBMASTER: submitting job (0, 0, 17) to dispatcher
22:16:44 DISPATCHER: trying to submit job (0, 0, 17)
22:16:44 DISPATCHER: trying to notify the job_runner thread.
22:16:44 HBMASTER: job (0, 0, 17) submitted to dispatcher
22:16:44 DISPATCHER: Trying to submit another job.
22:16:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:44 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:16:44 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:16:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:44 WORKER: start processing job (0, 0, 17)
22:16:44 WORKER: args: ()
22:16:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 331, 'last_n_outputs': 22, 'leak_rate': 0.8544441930703404, 'lr': 0.01833354373244328, 'optimizer': 'Adam', 'sparsity': 0.9652435714207109, 'steps_to_train': 68, 'weight_decay': 0.02005268155714933}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:17:28 DISPATCHER: Starting worker discovery
22:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:28 DISPATCHER: Finished worker discovery
22:17:35 WORKER: done with job (0, 0, 17), trying to register it.
22:17:35 WORKER: registered result for job (0, 0, 17) with dispatcher
22:17:35 DISPATCHER: job (0, 0, 17) finished
22:17:35 DISPATCHER: register_result: lock acquired
22:17:35 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:17:35 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 331, 'last_n_outputs': 22, 'leak_rate': 0.8544441930703404, 'lr': 0.01833354373244328, 'optimizer': 'Adam', 'sparsity': 0.9652435714207109, 'steps_to_train': 68, 'weight_decay': 0.02005268155714933}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25807572153446573, 'info': {'data02': 0.25807572153446573, 'config': "{'batch_size': 128, 'hidden_dim': 331, 'last_n_outputs': 22, 'leak_rate': 0.8544441930703404, 'lr': 0.01833354373244328, 'optimizer': 'Adam', 'sparsity': 0.9652435714207109, 'steps_to_train': 68, 'weight_decay': 0.02005268155714933}"}}
exception: None

22:17:35 job_callback for (0, 0, 17) started
22:17:35 job_callback for (0, 0, 17) got condition
22:17:35 DISPATCHER: Trying to submit another job.
22:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:17:35 HBMASTER: Trying to run another job!
22:17:35 job_callback for (0, 0, 17) finished
22:17:35 start sampling a new configuration.
22:17:35 done sampling a new configuration.
22:17:35 HBMASTER: schedule new run for iteration 0
22:17:35 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
22:17:35 HBMASTER: submitting job (0, 0, 18) to dispatcher
22:17:35 DISPATCHER: trying to submit job (0, 0, 18)
22:17:35 DISPATCHER: trying to notify the job_runner thread.
22:17:35 HBMASTER: job (0, 0, 18) submitted to dispatcher
22:17:35 DISPATCHER: Trying to submit another job.
22:17:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:17:35 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:17:35 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:17:35 WORKER: start processing job (0, 0, 18)
22:17:35 WORKER: args: ()
22:17:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 760, 'last_n_outputs': 26, 'leak_rate': 0.9223721385615882, 'lr': 0.03396340551827462, 'optimizer': 'SGD', 'sparsity': 0.8560925215557496, 'steps_to_train': 22, 'weight_decay': 0.05137829279008158}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:18:25 WORKER: done with job (0, 0, 18), trying to register it.
22:18:25 WORKER: registered result for job (0, 0, 18) with dispatcher
22:18:25 DISPATCHER: job (0, 0, 18) finished
22:18:25 DISPATCHER: register_result: lock acquired
22:18:25 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:18:25 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 760, 'last_n_outputs': 26, 'leak_rate': 0.9223721385615882, 'lr': 0.03396340551827462, 'optimizer': 'SGD', 'sparsity': 0.8560925215557496, 'steps_to_train': 22, 'weight_decay': 0.05137829279008158}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5056323074975727, 'info': {'data02': 0.5056323074975727, 'config': "{'batch_size': 64, 'hidden_dim': 760, 'last_n_outputs': 26, 'leak_rate': 0.9223721385615882, 'lr': 0.03396340551827462, 'optimizer': 'SGD', 'sparsity': 0.8560925215557496, 'steps_to_train': 22, 'weight_decay': 0.05137829279008158}"}}
exception: None

22:18:25 job_callback for (0, 0, 18) started
22:18:25 DISPATCHER: Trying to submit another job.
22:18:25 job_callback for (0, 0, 18) got condition
22:18:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:25 HBMASTER: Trying to run another job!
22:18:25 job_callback for (0, 0, 18) finished
22:18:25 start sampling a new configuration.
22:18:25 done sampling a new configuration.
22:18:25 HBMASTER: schedule new run for iteration 0
22:18:25 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
22:18:25 HBMASTER: submitting job (0, 0, 19) to dispatcher
22:18:25 DISPATCHER: trying to submit job (0, 0, 19)
22:18:25 DISPATCHER: trying to notify the job_runner thread.
22:18:25 HBMASTER: job (0, 0, 19) submitted to dispatcher
22:18:25 DISPATCHER: Trying to submit another job.
22:18:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:25 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:18:25 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:18:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:25 WORKER: start processing job (0, 0, 19)
22:18:25 WORKER: args: ()
22:18:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 895, 'last_n_outputs': 14, 'leak_rate': 0.879856560299842, 'lr': 0.03152537022371939, 'optimizer': 'Adam', 'sparsity': 0.8484380824737773, 'steps_to_train': 25, 'weight_decay': 0.1942851699731279}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:18:28 DISPATCHER: Starting worker discovery
22:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:28 DISPATCHER: Finished worker discovery
22:19:16 WORKER: done with job (0, 0, 19), trying to register it.
22:19:16 WORKER: registered result for job (0, 0, 19) with dispatcher
22:19:16 DISPATCHER: job (0, 0, 19) finished
22:19:16 DISPATCHER: register_result: lock acquired
22:19:16 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:19:16 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 895, 'last_n_outputs': 14, 'leak_rate': 0.879856560299842, 'lr': 0.03152537022371939, 'optimizer': 'Adam', 'sparsity': 0.8484380824737773, 'steps_to_train': 25, 'weight_decay': 0.1942851699731279}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00875425974860575, 'info': {'data02': 0.00875425974860575, 'config': "{'batch_size': 32, 'hidden_dim': 895, 'last_n_outputs': 14, 'leak_rate': 0.879856560299842, 'lr': 0.03152537022371939, 'optimizer': 'Adam', 'sparsity': 0.8484380824737773, 'steps_to_train': 25, 'weight_decay': 0.1942851699731279}"}}
exception: None

22:19:16 job_callback for (0, 0, 19) started
22:19:16 job_callback for (0, 0, 19) got condition
22:19:16 DISPATCHER: Trying to submit another job.
22:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:19:16 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.603561





22:19:16 HBMASTER: Trying to run another job!
22:19:16 job_callback for (0, 0, 19) finished
22:19:16 start sampling a new configuration.
22:19:16 best_vector: [2, 0.7576993403256724, 0.2929263669732124, 0.029943862801768528, 0.05511917679571472, 0, 0.6167647655626385, 0.5852977195387619, 0.09783631331583115], 5.094185682950845e-07, 0.17553263153598492, 8.941958184613004e-08
22:19:16 done sampling a new configuration.
22:19:16 HBMASTER: schedule new run for iteration 0
22:19:16 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
22:19:16 HBMASTER: submitting job (0, 0, 20) to dispatcher
22:19:16 DISPATCHER: trying to submit job (0, 0, 20)
22:19:16 DISPATCHER: trying to notify the job_runner thread.
22:19:16 HBMASTER: job (0, 0, 20) submitted to dispatcher
22:19:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:19:16 DISPATCHER: Trying to submit another job.
22:19:16 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:19:16 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:19:16 WORKER: start processing job (0, 0, 20)
22:19:16 WORKER: args: ()
22:19:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 806, 'last_n_outputs': 22, 'leak_rate': 0.7574859657004421, 'lr': 0.0012889567750104935, 'optimizer': 'Adam', 'sparsity': 0.8980235437350332, 'steps_to_train': 63, 'weight_decay': 0.013405653142791898}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:19:28 DISPATCHER: Starting worker discovery
22:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:28 DISPATCHER: Finished worker discovery
22:20:07 WORKER: done with job (0, 0, 20), trying to register it.
22:20:07 WORKER: registered result for job (0, 0, 20) with dispatcher
22:20:07 DISPATCHER: job (0, 0, 20) finished
22:20:07 DISPATCHER: register_result: lock acquired
22:20:07 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:20:07 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 806, 'last_n_outputs': 22, 'leak_rate': 0.7574859657004421, 'lr': 0.0012889567750104935, 'optimizer': 'Adam', 'sparsity': 0.8980235437350332, 'steps_to_train': 63, 'weight_decay': 0.013405653142791898}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49865287167866856, 'info': {'data02': 0.49865287167866856, 'config': "{'batch_size': 64, 'hidden_dim': 806, 'last_n_outputs': 22, 'leak_rate': 0.7574859657004421, 'lr': 0.0012889567750104935, 'optimizer': 'Adam', 'sparsity': 0.8980235437350332, 'steps_to_train': 63, 'weight_decay': 0.013405653142791898}"}}
exception: None

22:20:07 job_callback for (0, 0, 20) started
22:20:07 DISPATCHER: Trying to submit another job.
22:20:07 job_callback for (0, 0, 20) got condition
22:20:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:20:07 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.603561





22:20:07 HBMASTER: Trying to run another job!
22:20:07 job_callback for (0, 0, 20) finished
22:20:07 start sampling a new configuration.
22:20:07 done sampling a new configuration.
22:20:07 HBMASTER: schedule new run for iteration 0
22:20:07 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
22:20:07 HBMASTER: submitting job (0, 0, 21) to dispatcher
22:20:07 DISPATCHER: trying to submit job (0, 0, 21)
22:20:07 DISPATCHER: trying to notify the job_runner thread.
22:20:07 HBMASTER: job (0, 0, 21) submitted to dispatcher
22:20:07 DISPATCHER: Trying to submit another job.
22:20:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:20:07 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:07 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:20:07 WORKER: start processing job (0, 0, 21)
22:20:07 WORKER: args: ()
22:20:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 398, 'last_n_outputs': 14, 'leak_rate': 0.7812431001918582, 'lr': 0.046219947288745296, 'optimizer': 'SGD', 'sparsity': 0.9164213170662701, 'steps_to_train': 62, 'weight_decay': 0.059024716685429676}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:20:28 DISPATCHER: Starting worker discovery
22:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:28 DISPATCHER: Finished worker discovery
22:20:56 WORKER: done with job (0, 0, 21), trying to register it.
22:20:56 WORKER: registered result for job (0, 0, 21) with dispatcher
22:20:56 DISPATCHER: job (0, 0, 21) finished
22:20:56 DISPATCHER: register_result: lock acquired
22:20:56 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:20:56 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 398, 'last_n_outputs': 14, 'leak_rate': 0.7812431001918582, 'lr': 0.046219947288745296, 'optimizer': 'SGD', 'sparsity': 0.9164213170662701, 'steps_to_train': 62, 'weight_decay': 0.059024716685429676}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2779935192221893, 'info': {'data02': 0.2779935192221893, 'config': "{'batch_size': 32, 'hidden_dim': 398, 'last_n_outputs': 14, 'leak_rate': 0.7812431001918582, 'lr': 0.046219947288745296, 'optimizer': 'SGD', 'sparsity': 0.9164213170662701, 'steps_to_train': 62, 'weight_decay': 0.059024716685429676}"}}
exception: None

22:20:56 job_callback for (0, 0, 21) started
22:20:56 job_callback for (0, 0, 21) got condition
22:20:56 DISPATCHER: Trying to submit another job.
22:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:20:56 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.603561





22:20:56 HBMASTER: Trying to run another job!
22:20:56 job_callback for (0, 0, 21) finished
22:20:56 start sampling a new configuration.
22:20:56 done sampling a new configuration.
22:20:56 HBMASTER: schedule new run for iteration 0
22:20:56 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
22:20:56 HBMASTER: submitting job (0, 0, 22) to dispatcher
22:20:56 DISPATCHER: trying to submit job (0, 0, 22)
22:20:56 DISPATCHER: trying to notify the job_runner thread.
22:20:56 HBMASTER: job (0, 0, 22) submitted to dispatcher
22:20:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:20:56 DISPATCHER: Trying to submit another job.
22:20:56 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:56 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:20:56 WORKER: start processing job (0, 0, 22)
22:20:56 WORKER: args: ()
22:20:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 849, 'last_n_outputs': 35, 'leak_rate': 0.9868240290560188, 'lr': 0.016090847537322397, 'optimizer': 'SGD', 'sparsity': 0.801176789913705, 'steps_to_train': 19, 'weight_decay': 0.07404687814857107}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:21:28 DISPATCHER: Starting worker discovery
22:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:28 DISPATCHER: Finished worker discovery
22:21:46 WORKER: done with job (0, 0, 22), trying to register it.
22:21:46 WORKER: registered result for job (0, 0, 22) with dispatcher
22:21:46 DISPATCHER: job (0, 0, 22) finished
22:21:46 DISPATCHER: register_result: lock acquired
22:21:46 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:21:46 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 849, 'last_n_outputs': 35, 'leak_rate': 0.9868240290560188, 'lr': 0.016090847537322397, 'optimizer': 'SGD', 'sparsity': 0.801176789913705, 'steps_to_train': 19, 'weight_decay': 0.07404687814857107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5964415346455177, 'info': {'data02': 0.5964415346455177, 'config': "{'batch_size': 16, 'hidden_dim': 849, 'last_n_outputs': 35, 'leak_rate': 0.9868240290560188, 'lr': 0.016090847537322397, 'optimizer': 'SGD', 'sparsity': 0.801176789913705, 'steps_to_train': 19, 'weight_decay': 0.07404687814857107}"}}
exception: None

22:21:46 job_callback for (0, 0, 22) started
22:21:46 DISPATCHER: Trying to submit another job.
22:21:46 job_callback for (0, 0, 22) got condition
22:21:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:21:46 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.603561





22:21:46 HBMASTER: Trying to run another job!
22:21:46 job_callback for (0, 0, 22) finished
22:21:46 start sampling a new configuration.
22:21:46 done sampling a new configuration.
22:21:46 HBMASTER: schedule new run for iteration 0
22:21:46 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
22:21:46 HBMASTER: submitting job (0, 0, 23) to dispatcher
22:21:46 DISPATCHER: trying to submit job (0, 0, 23)
22:21:46 DISPATCHER: trying to notify the job_runner thread.
22:21:46 HBMASTER: job (0, 0, 23) submitted to dispatcher
22:21:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:21:46 DISPATCHER: Trying to submit another job.
22:21:46 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:21:46 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:21:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:21:46 WORKER: start processing job (0, 0, 23)
22:21:46 WORKER: args: ()
22:21:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 938, 'last_n_outputs': 20, 'leak_rate': 0.9973112093575468, 'lr': 0.06979633700586511, 'optimizer': 'Adam', 'sparsity': 0.7983669716902524, 'steps_to_train': 38, 'weight_decay': 0.03885187762165058}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:22:28 DISPATCHER: Starting worker discovery
22:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:28 DISPATCHER: Finished worker discovery
22:22:36 WORKER: done with job (0, 0, 23), trying to register it.
22:22:36 WORKER: registered result for job (0, 0, 23) with dispatcher
22:22:36 DISPATCHER: job (0, 0, 23) finished
22:22:36 DISPATCHER: register_result: lock acquired
22:22:36 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:22:36 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 938, 'last_n_outputs': 20, 'leak_rate': 0.9973112093575468, 'lr': 0.06979633700586511, 'optimizer': 'Adam', 'sparsity': 0.7983669716902524, 'steps_to_train': 38, 'weight_decay': 0.03885187762165058}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21508331621613622, 'info': {'data02': 0.21508331621613622, 'config': "{'batch_size': 16, 'hidden_dim': 938, 'last_n_outputs': 20, 'leak_rate': 0.9973112093575468, 'lr': 0.06979633700586511, 'optimizer': 'Adam', 'sparsity': 0.7983669716902524, 'steps_to_train': 38, 'weight_decay': 0.03885187762165058}"}}
exception: None

22:22:36 job_callback for (0, 0, 23) started
22:22:36 DISPATCHER: Trying to submit another job.
22:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:22:36 job_callback for (0, 0, 23) got condition
22:22:36 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.603561





22:22:36 HBMASTER: Trying to run another job!
22:22:36 job_callback for (0, 0, 23) finished
22:22:36 start sampling a new configuration.
22:22:36 best_vector: [0, 0.7377839157233139, 0.8717694910377151, 0.9793925651536363, 0.5573795598118017, 1, 0.9089129633726711, 0.04186604282472606, 0.09426897365968948], 0.0005829091199340207, 0.03510942435270384, 2.0465603650824668e-05
22:22:36 done sampling a new configuration.
22:22:36 HBMASTER: schedule new run for iteration 0
22:22:36 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
22:22:36 HBMASTER: submitting job (0, 0, 24) to dispatcher
22:22:36 DISPATCHER: trying to submit job (0, 0, 24)
22:22:36 DISPATCHER: trying to notify the job_runner thread.
22:22:36 HBMASTER: job (0, 0, 24) submitted to dispatcher
22:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:22:36 DISPATCHER: Trying to submit another job.
22:22:36 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:22:36 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:22:36 WORKER: start processing job (0, 0, 24)
22:22:36 WORKER: args: ()
22:22:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:23:26 WORKER: done with job (0, 0, 24), trying to register it.
22:23:26 WORKER: registered result for job (0, 0, 24) with dispatcher
22:23:26 DISPATCHER: job (0, 0, 24) finished
22:23:26 DISPATCHER: register_result: lock acquired
22:23:26 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:23:26 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6203150963713122, 'info': {'data02': 0.6203150963713122, 'config': "{'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}"}}
exception: None

22:23:26 job_callback for (0, 0, 24) started
22:23:26 job_callback for (0, 0, 24) got condition
22:23:26 DISPATCHER: Trying to submit another job.
22:23:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:26 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.620315





22:23:26 HBMASTER: Trying to run another job!
22:23:26 job_callback for (0, 0, 24) finished
22:23:26 start sampling a new configuration.
22:23:26 best_vector: [0, 0.72431325738621, 0.8355674192127239, 0.12823538142804536, 0.37814237342222584, 0, 0.44067380654664257, 0.4710011430872437, 0.13566460995778384], 0.0012464557190945836, 0.1835940298920191, 0.00022884182855052913
22:23:26 done sampling a new configuration.
22:23:26 HBMASTER: schedule new run for iteration 0
22:23:26 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
22:23:26 HBMASTER: submitting job (0, 0, 25) to dispatcher
22:23:26 DISPATCHER: trying to submit job (0, 0, 25)
22:23:26 DISPATCHER: trying to notify the job_runner thread.
22:23:26 HBMASTER: job (0, 0, 25) submitted to dispatcher
22:23:26 DISPATCHER: Trying to submit another job.
22:23:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:26 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:23:26 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:23:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:26 WORKER: start processing job (0, 0, 25)
22:23:26 WORKER: args: ()
22:23:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 780, 'last_n_outputs': 44, 'leak_rate': 0.7820588453570113, 'lr': 0.00570538225253362, 'optimizer': 'Adam', 'sparsity': 0.8557617135711942, 'steps_to_train': 52, 'weight_decay': 0.015014252902043035}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:23:28 DISPATCHER: Starting worker discovery
22:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:28 DISPATCHER: Finished worker discovery
22:24:15 WORKER: done with job (0, 0, 25), trying to register it.
22:24:15 WORKER: registered result for job (0, 0, 25) with dispatcher
22:24:15 DISPATCHER: job (0, 0, 25) finished
22:24:15 DISPATCHER: register_result: lock acquired
22:24:15 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:24:15 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 780, 'last_n_outputs': 44, 'leak_rate': 0.7820588453570113, 'lr': 0.00570538225253362, 'optimizer': 'Adam', 'sparsity': 0.8557617135711942, 'steps_to_train': 52, 'weight_decay': 0.015014252902043035}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4801147520095072, 'info': {'data02': 0.4801147520095072, 'config': "{'batch_size': 16, 'hidden_dim': 780, 'last_n_outputs': 44, 'leak_rate': 0.7820588453570113, 'lr': 0.00570538225253362, 'optimizer': 'Adam', 'sparsity': 0.8557617135711942, 'steps_to_train': 52, 'weight_decay': 0.015014252902043035}"}}
exception: None

22:24:15 job_callback for (0, 0, 25) started
22:24:15 DISPATCHER: Trying to submit another job.
22:24:15 job_callback for (0, 0, 25) got condition
22:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:15 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.620315





22:24:15 HBMASTER: Trying to run another job!
22:24:15 job_callback for (0, 0, 25) finished
22:24:15 start sampling a new configuration.
22:24:15 done sampling a new configuration.
22:24:15 HBMASTER: schedule new run for iteration 0
22:24:15 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
22:24:15 HBMASTER: submitting job (0, 0, 26) to dispatcher
22:24:15 DISPATCHER: trying to submit job (0, 0, 26)
22:24:15 DISPATCHER: trying to notify the job_runner thread.
22:24:15 HBMASTER: job (0, 0, 26) submitted to dispatcher
22:24:15 DISPATCHER: Trying to submit another job.
22:24:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:24:15 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:24:15 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:24:15 WORKER: start processing job (0, 0, 26)
22:24:15 WORKER: args: ()
22:24:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:24:28 DISPATCHER: Starting worker discovery
22:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:28 DISPATCHER: Finished worker discovery
22:25:08 WORKER: done with job (0, 0, 26), trying to register it.
22:25:08 WORKER: registered result for job (0, 0, 26) with dispatcher
22:25:08 DISPATCHER: job (0, 0, 26) finished
22:25:08 DISPATCHER: register_result: lock acquired
22:25:08 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:25:08 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5850464059239958, 'info': {'data02': 0.5850464059239958, 'config': "{'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}"}}
exception: None

22:25:08 job_callback for (0, 0, 26) started
22:25:08 job_callback for (0, 0, 26) got condition
22:25:08 DISPATCHER: Trying to submit another job.
22:25:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:25:08 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.620315





22:25:08 HBMASTER: Trying to run another job!
22:25:08 job_callback for (0, 0, 26) finished
22:25:08 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 13) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
22:25:08 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
22:25:08 HBMASTER: schedule new run for iteration 0
22:25:08 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
22:25:08 HBMASTER: submitting job (0, 0, 3) to dispatcher
22:25:08 DISPATCHER: trying to submit job (0, 0, 3)
22:25:08 DISPATCHER: trying to notify the job_runner thread.
22:25:08 HBMASTER: job (0, 0, 3) submitted to dispatcher
22:25:08 DISPATCHER: Trying to submit another job.
22:25:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:08 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:25:08 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:25:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:08 WORKER: start processing job (0, 0, 3)
22:25:08 WORKER: args: ()
22:25:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 497, 'last_n_outputs': 49, 'leak_rate': 0.9809186031085639, 'lr': 0.010663793778463947, 'optimizer': 'SGD', 'sparsity': 0.899935488274374, 'steps_to_train': 35, 'weight_decay': 0.023558931681380315}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:25:28 DISPATCHER: Starting worker discovery
22:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:28 DISPATCHER: Finished worker discovery
22:26:28 DISPATCHER: Starting worker discovery
22:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:28 DISPATCHER: Finished worker discovery
22:27:26 WORKER: done with job (0, 0, 3), trying to register it.
22:27:26 WORKER: registered result for job (0, 0, 3) with dispatcher
22:27:26 DISPATCHER: job (0, 0, 3) finished
22:27:26 DISPATCHER: register_result: lock acquired
22:27:26 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:27:26 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 497, 'last_n_outputs': 49, 'leak_rate': 0.9809186031085639, 'lr': 0.010663793778463947, 'optimizer': 'SGD', 'sparsity': 0.899935488274374, 'steps_to_train': 35, 'weight_decay': 0.023558931681380315}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5773800890297305, 'info': {'data02': 0.5773800890297305, 'config': "{'batch_size': 64, 'hidden_dim': 497, 'last_n_outputs': 49, 'leak_rate': 0.9809186031085639, 'lr': 0.010663793778463947, 'optimizer': 'SGD', 'sparsity': 0.899935488274374, 'steps_to_train': 35, 'weight_decay': 0.023558931681380315}"}}
exception: None

22:27:26 job_callback for (0, 0, 3) started
22:27:26 job_callback for (0, 0, 3) got condition
22:27:26 DISPATCHER: Trying to submit another job.
22:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:27:26 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:27:26 HBMASTER: Trying to run another job!
22:27:26 job_callback for (0, 0, 3) finished
22:27:26 HBMASTER: schedule new run for iteration 0
22:27:26 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
22:27:26 HBMASTER: submitting job (0, 0, 5) to dispatcher
22:27:26 DISPATCHER: trying to submit job (0, 0, 5)
22:27:26 DISPATCHER: trying to notify the job_runner thread.
22:27:26 HBMASTER: job (0, 0, 5) submitted to dispatcher
22:27:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:27:26 DISPATCHER: Trying to submit another job.
22:27:26 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:27:26 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:27:26 WORKER: start processing job (0, 0, 5)
22:27:26 WORKER: args: ()
22:27:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:27:28 DISPATCHER: Starting worker discovery
22:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:28 DISPATCHER: Finished worker discovery
22:28:28 DISPATCHER: Starting worker discovery
22:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:28 DISPATCHER: Finished worker discovery
22:29:28 DISPATCHER: Starting worker discovery
22:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:28 DISPATCHER: Finished worker discovery
22:29:46 WORKER: done with job (0, 0, 5), trying to register it.
22:29:46 WORKER: registered result for job (0, 0, 5) with dispatcher
22:29:46 DISPATCHER: job (0, 0, 5) finished
22:29:46 DISPATCHER: register_result: lock acquired
22:29:46 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:29:46 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5785708733785222, 'info': {'data02': 0.5785708733785222, 'config': "{'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}"}}
exception: None

22:29:46 job_callback for (0, 0, 5) started
22:29:46 DISPATCHER: Trying to submit another job.
22:29:46 job_callback for (0, 0, 5) got condition
22:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:29:46 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:29:46 HBMASTER: Trying to run another job!
22:29:46 job_callback for (0, 0, 5) finished
22:29:46 HBMASTER: schedule new run for iteration 0
22:29:46 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
22:29:46 HBMASTER: submitting job (0, 0, 6) to dispatcher
22:29:46 DISPATCHER: trying to submit job (0, 0, 6)
22:29:46 DISPATCHER: trying to notify the job_runner thread.
22:29:46 HBMASTER: job (0, 0, 6) submitted to dispatcher
22:29:46 DISPATCHER: Trying to submit another job.
22:29:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:29:46 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:29:46 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:29:46 WORKER: start processing job (0, 0, 6)
22:29:46 WORKER: args: ()
22:29:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 14, 'leak_rate': 0.8125805776517413, 'lr': 0.002870740647424209, 'optimizer': 'Adam', 'sparsity': 0.9362347013976964, 'steps_to_train': 32, 'weight_decay': 0.019767323488678355}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:30:28 DISPATCHER: Starting worker discovery
22:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:28 DISPATCHER: Finished worker discovery
22:31:28 DISPATCHER: Starting worker discovery
22:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:28 DISPATCHER: Finished worker discovery
22:32:04 WORKER: done with job (0, 0, 6), trying to register it.
22:32:04 WORKER: registered result for job (0, 0, 6) with dispatcher
22:32:04 DISPATCHER: job (0, 0, 6) finished
22:32:04 DISPATCHER: register_result: lock acquired
22:32:04 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:32:04 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 14, 'leak_rate': 0.8125805776517413, 'lr': 0.002870740647424209, 'optimizer': 'Adam', 'sparsity': 0.9362347013976964, 'steps_to_train': 32, 'weight_decay': 0.019767323488678355}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4887804959757583, 'info': {'data02': 0.4887804959757583, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 14, 'leak_rate': 0.8125805776517413, 'lr': 0.002870740647424209, 'optimizer': 'Adam', 'sparsity': 0.9362347013976964, 'steps_to_train': 32, 'weight_decay': 0.019767323488678355}"}}
exception: None

22:32:04 job_callback for (0, 0, 6) started
22:32:04 DISPATCHER: Trying to submit another job.
22:32:04 job_callback for (0, 0, 6) got condition
22:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:32:04 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:32:04 HBMASTER: Trying to run another job!
22:32:04 job_callback for (0, 0, 6) finished
22:32:04 HBMASTER: schedule new run for iteration 0
22:32:04 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
22:32:04 HBMASTER: submitting job (0, 0, 10) to dispatcher
22:32:04 DISPATCHER: trying to submit job (0, 0, 10)
22:32:04 DISPATCHER: trying to notify the job_runner thread.
22:32:04 HBMASTER: job (0, 0, 10) submitted to dispatcher
22:32:04 DISPATCHER: Trying to submit another job.
22:32:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:32:04 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:32:04 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:32:04 WORKER: start processing job (0, 0, 10)
22:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:32:04 WORKER: args: ()
22:32:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 222, 'last_n_outputs': 37, 'leak_rate': 0.9783702669297386, 'lr': 0.0055365905220786755, 'optimizer': 'SGD', 'sparsity': 0.7834681035977051, 'steps_to_train': 25, 'weight_decay': 0.018607379746279712}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:32:28 DISPATCHER: Starting worker discovery
22:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:28 DISPATCHER: Finished worker discovery
22:33:28 DISPATCHER: Starting worker discovery
22:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:28 DISPATCHER: Finished worker discovery
22:34:22 WORKER: done with job (0, 0, 10), trying to register it.
22:34:22 WORKER: registered result for job (0, 0, 10) with dispatcher
22:34:22 DISPATCHER: job (0, 0, 10) finished
22:34:22 DISPATCHER: register_result: lock acquired
22:34:22 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:34:22 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 222, 'last_n_outputs': 37, 'leak_rate': 0.9783702669297386, 'lr': 0.0055365905220786755, 'optimizer': 'SGD', 'sparsity': 0.7834681035977051, 'steps_to_train': 25, 'weight_decay': 0.018607379746279712}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5547698366040988, 'info': {'data02': 0.5547698366040988, 'config': "{'batch_size': 64, 'hidden_dim': 222, 'last_n_outputs': 37, 'leak_rate': 0.9783702669297386, 'lr': 0.0055365905220786755, 'optimizer': 'SGD', 'sparsity': 0.7834681035977051, 'steps_to_train': 25, 'weight_decay': 0.018607379746279712}"}}
exception: None

22:34:22 job_callback for (0, 0, 10) started
22:34:22 job_callback for (0, 0, 10) got condition
22:34:22 DISPATCHER: Trying to submit another job.
22:34:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:34:22 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:34:22 HBMASTER: Trying to run another job!
22:34:22 job_callback for (0, 0, 10) finished
22:34:22 HBMASTER: schedule new run for iteration 0
22:34:22 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
22:34:22 HBMASTER: submitting job (0, 0, 13) to dispatcher
22:34:22 DISPATCHER: trying to submit job (0, 0, 13)
22:34:22 DISPATCHER: trying to notify the job_runner thread.
22:34:22 HBMASTER: job (0, 0, 13) submitted to dispatcher
22:34:22 DISPATCHER: Trying to submit another job.
22:34:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:34:22 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:34:22 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:34:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:34:22 WORKER: start processing job (0, 0, 13)
22:34:22 WORKER: args: ()
22:34:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 912, 'last_n_outputs': 13, 'leak_rate': 0.7581671897305919, 'lr': 0.004274895852029732, 'optimizer': 'SGD', 'sparsity': 0.8125008682960542, 'steps_to_train': 88, 'weight_decay': 0.013150052041845195}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:34:28 DISPATCHER: Starting worker discovery
22:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:28 DISPATCHER: Finished worker discovery
22:35:28 DISPATCHER: Starting worker discovery
22:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:28 DISPATCHER: Finished worker discovery
22:36:28 DISPATCHER: Starting worker discovery
22:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:28 DISPATCHER: Finished worker discovery
22:36:43 WORKER: done with job (0, 0, 13), trying to register it.
22:36:43 WORKER: registered result for job (0, 0, 13) with dispatcher
22:36:43 DISPATCHER: job (0, 0, 13) finished
22:36:43 DISPATCHER: register_result: lock acquired
22:36:43 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:36:43 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 912, 'last_n_outputs': 13, 'leak_rate': 0.7581671897305919, 'lr': 0.004274895852029732, 'optimizer': 'SGD', 'sparsity': 0.8125008682960542, 'steps_to_train': 88, 'weight_decay': 0.013150052041845195}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5785362776182837, 'info': {'data02': 0.5785362776182837, 'config': "{'batch_size': 16, 'hidden_dim': 912, 'last_n_outputs': 13, 'leak_rate': 0.7581671897305919, 'lr': 0.004274895852029732, 'optimizer': 'SGD', 'sparsity': 0.8125008682960542, 'steps_to_train': 88, 'weight_decay': 0.013150052041845195}"}}
exception: None

22:36:43 job_callback for (0, 0, 13) started
22:36:43 job_callback for (0, 0, 13) got condition
22:36:43 DISPATCHER: Trying to submit another job.
22:36:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:36:43 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:36:43 HBMASTER: Trying to run another job!
22:36:43 job_callback for (0, 0, 13) finished
22:36:43 HBMASTER: schedule new run for iteration 0
22:36:43 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
22:36:43 HBMASTER: submitting job (0, 0, 18) to dispatcher
22:36:43 DISPATCHER: trying to submit job (0, 0, 18)
22:36:43 DISPATCHER: trying to notify the job_runner thread.
22:36:43 HBMASTER: job (0, 0, 18) submitted to dispatcher
22:36:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:36:43 DISPATCHER: Trying to submit another job.
22:36:43 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:36:43 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:36:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:36:43 WORKER: start processing job (0, 0, 18)
22:36:43 WORKER: args: ()
22:36:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 760, 'last_n_outputs': 26, 'leak_rate': 0.9223721385615882, 'lr': 0.03396340551827462, 'optimizer': 'SGD', 'sparsity': 0.8560925215557496, 'steps_to_train': 22, 'weight_decay': 0.05137829279008158}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:37:28 DISPATCHER: Starting worker discovery
22:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:28 DISPATCHER: Finished worker discovery
22:38:28 DISPATCHER: Starting worker discovery
22:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:28 DISPATCHER: Finished worker discovery
22:39:02 WORKER: done with job (0, 0, 18), trying to register it.
22:39:02 WORKER: registered result for job (0, 0, 18) with dispatcher
22:39:02 DISPATCHER: job (0, 0, 18) finished
22:39:02 DISPATCHER: register_result: lock acquired
22:39:02 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:39:02 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 760, 'last_n_outputs': 26, 'leak_rate': 0.9223721385615882, 'lr': 0.03396340551827462, 'optimizer': 'SGD', 'sparsity': 0.8560925215557496, 'steps_to_train': 22, 'weight_decay': 0.05137829279008158}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.44935163745448314, 'info': {'data02': 0.44935163745448314, 'config': "{'batch_size': 64, 'hidden_dim': 760, 'last_n_outputs': 26, 'leak_rate': 0.9223721385615882, 'lr': 0.03396340551827462, 'optimizer': 'SGD', 'sparsity': 0.8560925215557496, 'steps_to_train': 22, 'weight_decay': 0.05137829279008158}"}}
exception: None

22:39:02 job_callback for (0, 0, 18) started
22:39:02 DISPATCHER: Trying to submit another job.
22:39:02 job_callback for (0, 0, 18) got condition
22:39:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:02 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:39:02 HBMASTER: Trying to run another job!
22:39:02 job_callback for (0, 0, 18) finished
22:39:02 HBMASTER: schedule new run for iteration 0
22:39:02 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
22:39:02 HBMASTER: submitting job (0, 0, 22) to dispatcher
22:39:02 DISPATCHER: trying to submit job (0, 0, 22)
22:39:02 DISPATCHER: trying to notify the job_runner thread.
22:39:02 HBMASTER: job (0, 0, 22) submitted to dispatcher
22:39:02 DISPATCHER: Trying to submit another job.
22:39:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:02 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:39:02 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:39:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:02 WORKER: start processing job (0, 0, 22)
22:39:02 WORKER: args: ()
22:39:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 849, 'last_n_outputs': 35, 'leak_rate': 0.9868240290560188, 'lr': 0.016090847537322397, 'optimizer': 'SGD', 'sparsity': 0.801176789913705, 'steps_to_train': 19, 'weight_decay': 0.07404687814857107}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:39:28 DISPATCHER: Starting worker discovery
22:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:28 DISPATCHER: Finished worker discovery
22:40:28 DISPATCHER: Starting worker discovery
22:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:28 DISPATCHER: Finished worker discovery
22:41:20 WORKER: done with job (0, 0, 22), trying to register it.
22:41:20 WORKER: registered result for job (0, 0, 22) with dispatcher
22:41:20 DISPATCHER: job (0, 0, 22) finished
22:41:20 DISPATCHER: register_result: lock acquired
22:41:20 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:41:20 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 849, 'last_n_outputs': 35, 'leak_rate': 0.9868240290560188, 'lr': 0.016090847537322397, 'optimizer': 'SGD', 'sparsity': 0.801176789913705, 'steps_to_train': 19, 'weight_decay': 0.07404687814857107}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.48991445814875234, 'info': {'data02': 0.48991445814875234, 'config': "{'batch_size': 16, 'hidden_dim': 849, 'last_n_outputs': 35, 'leak_rate': 0.9868240290560188, 'lr': 0.016090847537322397, 'optimizer': 'SGD', 'sparsity': 0.801176789913705, 'steps_to_train': 19, 'weight_decay': 0.07404687814857107}"}}
exception: None

22:41:20 job_callback for (0, 0, 22) started
22:41:20 DISPATCHER: Trying to submit another job.
22:41:20 job_callback for (0, 0, 22) got condition
22:41:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:41:20 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:41:20 HBMASTER: Trying to run another job!
22:41:20 job_callback for (0, 0, 22) finished
22:41:20 HBMASTER: schedule new run for iteration 0
22:41:20 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
22:41:20 HBMASTER: submitting job (0, 0, 24) to dispatcher
22:41:20 DISPATCHER: trying to submit job (0, 0, 24)
22:41:20 DISPATCHER: trying to notify the job_runner thread.
22:41:20 HBMASTER: job (0, 0, 24) submitted to dispatcher
22:41:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:41:20 DISPATCHER: Trying to submit another job.
22:41:20 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:41:20 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:41:20 WORKER: start processing job (0, 0, 24)
22:41:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:41:20 WORKER: args: ()
22:41:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:41:28 DISPATCHER: Starting worker discovery
22:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:28 DISPATCHER: Finished worker discovery
22:42:28 DISPATCHER: Starting worker discovery
22:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:28 DISPATCHER: Finished worker discovery
22:43:28 DISPATCHER: Starting worker discovery
22:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:28 DISPATCHER: Finished worker discovery
22:43:39 WORKER: done with job (0, 0, 24), trying to register it.
22:43:39 WORKER: registered result for job (0, 0, 24) with dispatcher
22:43:39 DISPATCHER: job (0, 0, 24) finished
22:43:39 DISPATCHER: register_result: lock acquired
22:43:39 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:43:39 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6258538035249218, 'info': {'data02': 0.6258538035249218, 'config': "{'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}"}}
exception: None

22:43:39 job_callback for (0, 0, 24) started
22:43:39 job_callback for (0, 0, 24) got condition
22:43:39 DISPATCHER: Trying to submit another job.
22:43:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:43:39 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:43:39 HBMASTER: Trying to run another job!
22:43:39 job_callback for (0, 0, 24) finished
22:43:39 HBMASTER: schedule new run for iteration 0
22:43:39 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
22:43:39 HBMASTER: submitting job (0, 0, 26) to dispatcher
22:43:39 DISPATCHER: trying to submit job (0, 0, 26)
22:43:39 DISPATCHER: trying to notify the job_runner thread.
22:43:39 HBMASTER: job (0, 0, 26) submitted to dispatcher
22:43:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:43:39 DISPATCHER: Trying to submit another job.
22:43:39 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:43:39 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:43:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:43:39 WORKER: start processing job (0, 0, 26)
22:43:39 WORKER: args: ()
22:43:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:44:28 DISPATCHER: Starting worker discovery
22:44:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:28 DISPATCHER: Finished worker discovery
22:45:28 DISPATCHER: Starting worker discovery
22:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:28 DISPATCHER: Finished worker discovery
22:45:59 WORKER: done with job (0, 0, 26), trying to register it.
22:45:59 WORKER: registered result for job (0, 0, 26) with dispatcher
22:45:59 DISPATCHER: job (0, 0, 26) finished
22:45:59 DISPATCHER: register_result: lock acquired
22:45:59 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:45:59 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5885280623003682, 'info': {'data02': 0.5885280623003682, 'config': "{'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}"}}
exception: None

22:45:59 job_callback for (0, 0, 26) started
22:45:59 DISPATCHER: Trying to submit another job.
22:45:59 job_callback for (0, 0, 26) got condition
22:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:59 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:45:59 HBMASTER: Trying to run another job!
22:45:59 job_callback for (0, 0, 26) finished
22:45:59 ITERATION: Advancing config (0, 0, 5) to next budget 400.000000
22:45:59 ITERATION: Advancing config (0, 0, 24) to next budget 400.000000
22:45:59 ITERATION: Advancing config (0, 0, 26) to next budget 400.000000
22:45:59 HBMASTER: schedule new run for iteration 0
22:45:59 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
22:45:59 HBMASTER: submitting job (0, 0, 5) to dispatcher
22:45:59 DISPATCHER: trying to submit job (0, 0, 5)
22:45:59 DISPATCHER: trying to notify the job_runner thread.
22:45:59 HBMASTER: job (0, 0, 5) submitted to dispatcher
22:45:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:59 DISPATCHER: Trying to submit another job.
22:45:59 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:45:59 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:59 WORKER: start processing job (0, 0, 5)
22:45:59 WORKER: args: ()
22:45:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}, 'budget': 400.0, 'working_directory': '.'}
22:46:28 DISPATCHER: Starting worker discovery
22:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:28 DISPATCHER: Finished worker discovery
22:47:28 DISPATCHER: Starting worker discovery
22:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:28 DISPATCHER: Finished worker discovery
22:48:28 DISPATCHER: Starting worker discovery
22:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:28 DISPATCHER: Finished worker discovery
22:49:28 DISPATCHER: Starting worker discovery
22:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:28 DISPATCHER: Finished worker discovery
22:50:28 DISPATCHER: Starting worker discovery
22:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:28 DISPATCHER: Finished worker discovery
22:51:28 DISPATCHER: Starting worker discovery
22:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:28 DISPATCHER: Finished worker discovery
22:52:28 DISPATCHER: Starting worker discovery
22:52:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:28 DISPATCHER: Finished worker discovery
22:52:46 WORKER: done with job (0, 0, 5), trying to register it.
22:52:46 WORKER: registered result for job (0, 0, 5) with dispatcher
22:52:46 DISPATCHER: job (0, 0, 5) finished
22:52:46 DISPATCHER: register_result: lock acquired
22:52:46 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:52:46 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5942259120131184, 'info': {'data02': 0.5942259120131184, 'config': "{'batch_size': 64, 'hidden_dim': 547, 'last_n_outputs': 30, 'leak_rate': 0.976128476507298, 'lr': 0.00819494635346201, 'optimizer': 'SGD', 'sparsity': 0.9530590088175768, 'steps_to_train': 85, 'weight_decay': 0.02263903909414495}"}}
exception: None

22:52:46 job_callback for (0, 0, 5) started
22:52:46 DISPATCHER: Trying to submit another job.
22:52:46 job_callback for (0, 0, 5) got condition
22:52:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:52:46 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:52:46 HBMASTER: Trying to run another job!
22:52:46 job_callback for (0, 0, 5) finished
22:52:46 HBMASTER: schedule new run for iteration 0
22:52:46 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
22:52:46 HBMASTER: submitting job (0, 0, 24) to dispatcher
22:52:46 DISPATCHER: trying to submit job (0, 0, 24)
22:52:46 DISPATCHER: trying to notify the job_runner thread.
22:52:46 HBMASTER: job (0, 0, 24) submitted to dispatcher
22:52:46 DISPATCHER: Trying to submit another job.
22:52:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:52:46 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:52:46 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:52:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:52:46 WORKER: start processing job (0, 0, 24)
22:52:46 WORKER: args: ()
22:52:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 400.0, 'working_directory': '.'}
22:53:28 DISPATCHER: Starting worker discovery
22:53:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:28 DISPATCHER: Finished worker discovery
22:54:28 DISPATCHER: Starting worker discovery
22:54:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:28 DISPATCHER: Finished worker discovery
22:55:28 DISPATCHER: Starting worker discovery
22:55:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:28 DISPATCHER: Finished worker discovery
22:56:28 DISPATCHER: Starting worker discovery
22:56:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:28 DISPATCHER: Finished worker discovery
22:57:28 DISPATCHER: Starting worker discovery
22:57:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:28 DISPATCHER: Finished worker discovery
22:58:28 DISPATCHER: Starting worker discovery
22:58:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:28 DISPATCHER: Finished worker discovery
22:59:28 DISPATCHER: Starting worker discovery
22:59:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:28 DISPATCHER: Finished worker discovery
22:59:33 WORKER: done with job (0, 0, 24), trying to register it.
22:59:33 WORKER: registered result for job (0, 0, 24) with dispatcher
22:59:33 DISPATCHER: job (0, 0, 24) finished
22:59:33 DISPATCHER: register_result: lock acquired
22:59:33 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:59:33 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6018693161308254, 'info': {'data02': 0.6018693161308254, 'config': "{'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}"}}
exception: None

22:59:33 job_callback for (0, 0, 24) started
22:59:33 job_callback for (0, 0, 24) got condition
22:59:33 DISPATCHER: Trying to submit another job.
22:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:59:33 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:59:33 HBMASTER: Trying to run another job!
22:59:33 job_callback for (0, 0, 24) finished
22:59:33 HBMASTER: schedule new run for iteration 0
22:59:33 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
22:59:33 HBMASTER: submitting job (0, 0, 26) to dispatcher
22:59:33 DISPATCHER: trying to submit job (0, 0, 26)
22:59:33 DISPATCHER: trying to notify the job_runner thread.
22:59:33 HBMASTER: job (0, 0, 26) submitted to dispatcher
22:59:33 DISPATCHER: Trying to submit another job.
22:59:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:59:33 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:59:33 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:59:33 WORKER: start processing job (0, 0, 26)
22:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:59:33 WORKER: args: ()
22:59:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}, 'budget': 400.0, 'working_directory': '.'}
23:00:28 DISPATCHER: Starting worker discovery
23:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:28 DISPATCHER: Finished worker discovery
23:01:28 DISPATCHER: Starting worker discovery
23:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:28 DISPATCHER: Finished worker discovery
23:02:28 DISPATCHER: Starting worker discovery
23:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:28 DISPATCHER: Finished worker discovery
23:03:28 DISPATCHER: Starting worker discovery
23:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:28 DISPATCHER: Finished worker discovery
23:04:28 DISPATCHER: Starting worker discovery
23:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:28 DISPATCHER: Finished worker discovery
23:05:28 DISPATCHER: Starting worker discovery
23:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:28 DISPATCHER: Finished worker discovery
23:06:21 WORKER: done with job (0, 0, 26), trying to register it.
23:06:21 WORKER: registered result for job (0, 0, 26) with dispatcher
23:06:21 DISPATCHER: job (0, 0, 26) finished
23:06:21 DISPATCHER: register_result: lock acquired
23:06:21 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:06:21 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5792716419965063, 'info': {'data02': 0.5792716419965063, 'config': "{'batch_size': 128, 'hidden_dim': 468, 'last_n_outputs': 41, 'leak_rate': 0.9455039776501881, 'lr': 0.01787216852158576, 'optimizer': 'SGD', 'sparsity': 0.8513764673413815, 'steps_to_train': 82, 'weight_decay': 0.07095769535324231}"}}
exception: None

23:06:21 job_callback for (0, 0, 26) started
23:06:21 job_callback for (0, 0, 26) got condition
23:06:21 DISPATCHER: Trying to submit another job.
23:06:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:21 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:06:21 HBMASTER: Trying to run another job!
23:06:21 job_callback for (0, 0, 26) finished
23:06:21 ITERATION: Advancing config (0, 0, 24) to next budget 1200.000000
23:06:21 HBMASTER: schedule new run for iteration 0
23:06:21 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:06:21 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:06:21 DISPATCHER: trying to submit job (0, 0, 24)
23:06:21 DISPATCHER: trying to notify the job_runner thread.
23:06:21 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:06:21 DISPATCHER: Trying to submit another job.
23:06:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:21 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:06:21 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:06:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:21 WORKER: start processing job (0, 0, 24)
23:06:21 WORKER: args: ()
23:06:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 1200.0, 'working_directory': '.'}
23:06:28 DISPATCHER: Starting worker discovery
23:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:28 DISPATCHER: Finished worker discovery
23:07:28 DISPATCHER: Starting worker discovery
23:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:29 DISPATCHER: Finished worker discovery
23:08:29 DISPATCHER: Starting worker discovery
23:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:29 DISPATCHER: Finished worker discovery
23:09:29 DISPATCHER: Starting worker discovery
23:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:29 DISPATCHER: Finished worker discovery
23:10:29 DISPATCHER: Starting worker discovery
23:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:29 DISPATCHER: Finished worker discovery
23:11:29 DISPATCHER: Starting worker discovery
23:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:29 DISPATCHER: Finished worker discovery
23:12:29 DISPATCHER: Starting worker discovery
23:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:29 DISPATCHER: Finished worker discovery
23:13:29 DISPATCHER: Starting worker discovery
23:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:29 DISPATCHER: Finished worker discovery
23:14:29 DISPATCHER: Starting worker discovery
23:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:29 DISPATCHER: Finished worker discovery
23:15:29 DISPATCHER: Starting worker discovery
23:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:29 DISPATCHER: Finished worker discovery
23:16:29 DISPATCHER: Starting worker discovery
23:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:29 DISPATCHER: Finished worker discovery
23:17:29 DISPATCHER: Starting worker discovery
23:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:29 DISPATCHER: Finished worker discovery
23:18:29 DISPATCHER: Starting worker discovery
23:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:29 DISPATCHER: Finished worker discovery
23:19:29 DISPATCHER: Starting worker discovery
23:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:29 DISPATCHER: Finished worker discovery
23:20:29 DISPATCHER: Starting worker discovery
23:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:29 DISPATCHER: Finished worker discovery
23:21:29 DISPATCHER: Starting worker discovery
23:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:29 DISPATCHER: Finished worker discovery
23:22:29 DISPATCHER: Starting worker discovery
23:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:29 DISPATCHER: Finished worker discovery
23:23:29 DISPATCHER: Starting worker discovery
23:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:29 DISPATCHER: Finished worker discovery
23:24:29 DISPATCHER: Starting worker discovery
23:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:29 DISPATCHER: Finished worker discovery
23:25:29 DISPATCHER: Starting worker discovery
23:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:29 DISPATCHER: Finished worker discovery
23:26:29 DISPATCHER: Starting worker discovery
23:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:29 DISPATCHER: Finished worker discovery
23:26:34 WORKER: done with job (0, 0, 24), trying to register it.
23:26:34 WORKER: registered result for job (0, 0, 24) with dispatcher
23:26:34 DISPATCHER: job (0, 0, 24) finished
23:26:34 DISPATCHER: register_result: lock acquired
23:26:34 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:26:34 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5726458956736993, 'info': {'data02': 0.5726458956736993, 'config': "{'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 45, 'leak_rate': 0.994848141288409, 'lr': 0.013024441805853916, 'optimizer': 'SGD', 'sparsity': 0.9681391112094411, 'steps_to_train': 13, 'weight_decay': 0.013263152475891842}"}}
exception: None

23:26:34 job_callback for (0, 0, 24) started
23:26:34 job_callback for (0, 0, 24) got condition
23:26:34 DISPATCHER: Trying to submit another job.
23:26:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:26:34 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:26:34 HBMASTER: Trying to run another job!
23:26:34 job_callback for (0, 0, 24) finished
23:26:34 start sampling a new configuration.
23:26:34 best_vector: [3, 0.9902000827748944, 0.8493925738236626, 0.9868927759431726, 0.06079040822160031, 1, 0.889664215624096, 0.2590883917814881, 0.043038367115686066], 0.0052668175415165495, 0.009103405722130614, 4.794597694485965e-05
23:26:34 done sampling a new configuration.
23:26:34 HBMASTER: schedule new run for iteration 1
23:26:34 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
23:26:34 HBMASTER: submitting job (1, 0, 0) to dispatcher
23:26:34 DISPATCHER: trying to submit job (1, 0, 0)
23:26:34 DISPATCHER: trying to notify the job_runner thread.
23:26:34 HBMASTER: job (1, 0, 0) submitted to dispatcher
23:26:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:26:34 DISPATCHER: Trying to submit another job.
23:26:34 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:26:34 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:26:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:26:34 WORKER: start processing job (1, 0, 0)
23:26:34 WORKER: args: ()
23:26:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:27:29 DISPATCHER: Starting worker discovery
23:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:29 DISPATCHER: Finished worker discovery
23:28:29 DISPATCHER: Starting worker discovery
23:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:29 DISPATCHER: Finished worker discovery
23:28:53 WORKER: done with job (1, 0, 0), trying to register it.
23:28:53 WORKER: registered result for job (1, 0, 0) with dispatcher
23:28:53 DISPATCHER: job (1, 0, 0) finished
23:28:53 DISPATCHER: register_result: lock acquired
23:28:53 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:28:53 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.616247438691923, 'info': {'data02': 0.616247438691923, 'config': "{'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}"}}
exception: None

23:28:53 job_callback for (1, 0, 0) started
23:28:53 DISPATCHER: Trying to submit another job.
23:28:53 job_callback for (1, 0, 0) got condition
23:28:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:28:53 HBMASTER: Trying to run another job!
23:28:53 job_callback for (1, 0, 0) finished
23:28:53 start sampling a new configuration.
23:28:53 best_vector: [1, 0.9888567405040078, 0.8794514667066501, 0.9036810823644246, 0.47114924402562086, 1, 0.8008019167355136, 0.42020561622505365, 0.18196455765857464], 0.001660960022043154, 0.18970678134623709, 0.0003150953797265817
23:28:53 done sampling a new configuration.
23:28:53 HBMASTER: schedule new run for iteration 1
23:28:53 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
23:28:53 HBMASTER: submitting job (1, 0, 1) to dispatcher
23:28:53 DISPATCHER: trying to submit job (1, 0, 1)
23:28:53 DISPATCHER: trying to notify the job_runner thread.
23:28:53 HBMASTER: job (1, 0, 1) submitted to dispatcher
23:28:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:28:53 DISPATCHER: Trying to submit another job.
23:28:53 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:28:53 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:28:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:28:53 WORKER: start processing job (1, 0, 1)
23:28:53 WORKER: args: ()
23:28:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 992, 'last_n_outputs': 46, 'leak_rate': 0.9759202705911061, 'lr': 0.00875585353153128, 'optimizer': 'SGD', 'sparsity': 0.9421924600165232, 'steps_to_train': 48, 'weight_decay': 0.017248103424289424}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:29:29 DISPATCHER: Starting worker discovery
23:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:29 DISPATCHER: Finished worker discovery
23:30:29 DISPATCHER: Starting worker discovery
23:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:29 DISPATCHER: Finished worker discovery
23:31:11 WORKER: done with job (1, 0, 1), trying to register it.
23:31:11 WORKER: registered result for job (1, 0, 1) with dispatcher
23:31:11 DISPATCHER: job (1, 0, 1) finished
23:31:11 DISPATCHER: register_result: lock acquired
23:31:11 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:31:11 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 992, 'last_n_outputs': 46, 'leak_rate': 0.9759202705911061, 'lr': 0.00875585353153128, 'optimizer': 'SGD', 'sparsity': 0.9421924600165232, 'steps_to_train': 48, 'weight_decay': 0.017248103424289424}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6058680322280431, 'info': {'data02': 0.6058680322280431, 'config': "{'batch_size': 32, 'hidden_dim': 992, 'last_n_outputs': 46, 'leak_rate': 0.9759202705911061, 'lr': 0.00875585353153128, 'optimizer': 'SGD', 'sparsity': 0.9421924600165232, 'steps_to_train': 48, 'weight_decay': 0.017248103424289424}"}}
exception: None

23:31:11 job_callback for (1, 0, 1) started
23:31:11 job_callback for (1, 0, 1) got condition
23:31:11 DISPATCHER: Trying to submit another job.
23:31:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:11 HBMASTER: Trying to run another job!
23:31:11 job_callback for (1, 0, 1) finished
23:31:11 start sampling a new configuration.
23:31:12 best_vector: [3, 0.6503861451225478, 0.8483049554297502, 0.5821305220648809, 0.6520367594581982, 1, 0.9431622595110433, 0.29063062305843856, 0.01184555005520993], 0.006017855053654987, 0.30020956062181836, 0.0018066176215435527
23:31:12 done sampling a new configuration.
23:31:12 HBMASTER: schedule new run for iteration 1
23:31:12 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
23:31:12 HBMASTER: submitting job (1, 0, 2) to dispatcher
23:31:12 DISPATCHER: trying to submit job (1, 0, 2)
23:31:12 DISPATCHER: trying to notify the job_runner thread.
23:31:12 HBMASTER: job (1, 0, 2) submitted to dispatcher
23:31:12 DISPATCHER: Trying to submit another job.
23:31:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:12 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:31:12 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:12 WORKER: start processing job (1, 0, 2)
23:31:12 WORKER: args: ()
23:31:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 720, 'last_n_outputs': 44, 'leak_rate': 0.8955326305162202, 'lr': 0.020140651691293712, 'optimizer': 'SGD', 'sparsity': 0.9763589422826504, 'steps_to_train': 36, 'weight_decay': 0.010361232423903669}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:31:29 DISPATCHER: Starting worker discovery
23:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:29 DISPATCHER: Finished worker discovery
23:32:29 DISPATCHER: Starting worker discovery
23:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:29 DISPATCHER: Finished worker discovery
23:33:29 DISPATCHER: Starting worker discovery
23:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:29 DISPATCHER: Finished worker discovery
23:33:31 WORKER: done with job (1, 0, 2), trying to register it.
23:33:31 WORKER: registered result for job (1, 0, 2) with dispatcher
23:33:31 DISPATCHER: job (1, 0, 2) finished
23:33:31 DISPATCHER: register_result: lock acquired
23:33:31 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:33:31 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 720, 'last_n_outputs': 44, 'leak_rate': 0.8955326305162202, 'lr': 0.020140651691293712, 'optimizer': 'SGD', 'sparsity': 0.9763589422826504, 'steps_to_train': 36, 'weight_decay': 0.010361232423903669}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5983882957415203, 'info': {'data02': 0.5983882957415203, 'config': "{'batch_size': 128, 'hidden_dim': 720, 'last_n_outputs': 44, 'leak_rate': 0.8955326305162202, 'lr': 0.020140651691293712, 'optimizer': 'SGD', 'sparsity': 0.9763589422826504, 'steps_to_train': 36, 'weight_decay': 0.010361232423903669}"}}
exception: None

23:33:31 job_callback for (1, 0, 2) started
23:33:31 job_callback for (1, 0, 2) got condition
23:33:31 DISPATCHER: Trying to submit another job.
23:33:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:31 HBMASTER: Trying to run another job!
23:33:31 job_callback for (1, 0, 2) finished
23:33:31 start sampling a new configuration.
23:33:31 best_vector: [2, 0.7926473394032959, 0.6079690051841771, 0.4988908338979667, 0.4870919595506875, 1, 0.11084760848451852, 0.827964117464996, 0.7322161702422163], 0.0182512537130578, 0.0333177027907328, 0.0006080898467699183
23:33:31 done sampling a new configuration.
23:33:31 HBMASTER: schedule new run for iteration 1
23:33:31 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
23:33:31 HBMASTER: submitting job (1, 0, 3) to dispatcher
23:33:31 DISPATCHER: trying to submit job (1, 0, 3)
23:33:31 DISPATCHER: trying to notify the job_runner thread.
23:33:31 HBMASTER: job (1, 0, 3) submitted to dispatcher
23:33:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:31 DISPATCHER: Trying to submit another job.
23:33:31 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:33:31 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:33:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:31 WORKER: start processing job (1, 0, 3)
23:33:31 WORKER: args: ()
23:33:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 834, 'last_n_outputs': 34, 'leak_rate': 0.8747227084744916, 'lr': 0.009422885612378765, 'optimizer': 'SGD', 'sparsity': 0.7766034260362844, 'steps_to_train': 85, 'weight_decay': 0.08966752876855907}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:34:29 DISPATCHER: Starting worker discovery
23:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:29 DISPATCHER: Finished worker discovery
23:35:29 DISPATCHER: Starting worker discovery
23:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:29 DISPATCHER: Finished worker discovery
23:35:52 WORKER: done with job (1, 0, 3), trying to register it.
23:35:52 WORKER: registered result for job (1, 0, 3) with dispatcher
23:35:52 DISPATCHER: job (1, 0, 3) finished
23:35:52 DISPATCHER: register_result: lock acquired
23:35:52 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:35:52 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 834, 'last_n_outputs': 34, 'leak_rate': 0.8747227084744916, 'lr': 0.009422885612378765, 'optimizer': 'SGD', 'sparsity': 0.7766034260362844, 'steps_to_train': 85, 'weight_decay': 0.08966752876855907}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4860839787113229, 'info': {'data02': 0.4860839787113229, 'config': "{'batch_size': 64, 'hidden_dim': 834, 'last_n_outputs': 34, 'leak_rate': 0.8747227084744916, 'lr': 0.009422885612378765, 'optimizer': 'SGD', 'sparsity': 0.7766034260362844, 'steps_to_train': 85, 'weight_decay': 0.08966752876855907}"}}
exception: None

23:35:52 job_callback for (1, 0, 3) started
23:35:52 job_callback for (1, 0, 3) got condition
23:35:52 DISPATCHER: Trying to submit another job.
23:35:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:35:52 HBMASTER: Trying to run another job!
23:35:52 job_callback for (1, 0, 3) finished
23:35:52 start sampling a new configuration.
23:35:52 best_vector: [2, 0.30064732568905583, 0.813275944745049, 0.31832517742521677, 0.31091576250160363, 1, 0.08935790819485306, 0.8916466475225812, 0.8039282197050457], 0.008221041213548672, 0.020576210313639376, 0.00016915787300707456
23:35:52 done sampling a new configuration.
23:35:52 HBMASTER: schedule new run for iteration 1
23:35:52 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
23:35:52 HBMASTER: submitting job (1, 0, 4) to dispatcher
23:35:52 DISPATCHER: trying to submit job (1, 0, 4)
23:35:52 DISPATCHER: trying to notify the job_runner thread.
23:35:52 HBMASTER: job (1, 0, 4) submitted to dispatcher
23:35:52 DISPATCHER: Trying to submit another job.
23:35:52 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:35:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:35:52 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:35:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:35:52 WORKER: start processing job (1, 0, 4)
23:35:52 WORKER: args: ()
23:35:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 440, 'last_n_outputs': 43, 'leak_rate': 0.8295812943563042, 'lr': 0.00418631134868682, 'optimizer': 'SGD', 'sparsity': 0.7714458979667648, 'steps_to_train': 91, 'weight_decay': 0.11115646533615614}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:36:29 DISPATCHER: Starting worker discovery
23:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:29 DISPATCHER: Finished worker discovery
23:37:29 DISPATCHER: Starting worker discovery
23:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:29 DISPATCHER: Finished worker discovery
23:38:13 WORKER: done with job (1, 0, 4), trying to register it.
23:38:13 WORKER: registered result for job (1, 0, 4) with dispatcher
23:38:13 DISPATCHER: job (1, 0, 4) finished
23:38:13 DISPATCHER: register_result: lock acquired
23:38:13 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:38:13 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 440, 'last_n_outputs': 43, 'leak_rate': 0.8295812943563042, 'lr': 0.00418631134868682, 'optimizer': 'SGD', 'sparsity': 0.7714458979667648, 'steps_to_train': 91, 'weight_decay': 0.11115646533615614}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5786121280926672, 'info': {'data02': 0.5786121280926672, 'config': "{'batch_size': 64, 'hidden_dim': 440, 'last_n_outputs': 43, 'leak_rate': 0.8295812943563042, 'lr': 0.00418631134868682, 'optimizer': 'SGD', 'sparsity': 0.7714458979667648, 'steps_to_train': 91, 'weight_decay': 0.11115646533615614}"}}
exception: None

23:38:13 job_callback for (1, 0, 4) started
23:38:13 job_callback for (1, 0, 4) got condition
23:38:13 DISPATCHER: Trying to submit another job.
23:38:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:13 HBMASTER: Trying to run another job!
23:38:13 job_callback for (1, 0, 4) finished
23:38:13 start sampling a new configuration.
23:38:13 best_vector: [1, 0.9813824100871704, 0.7612082894823788, 0.9186172923326354, 0.3909118300158937, 1, 0.23389372810123588, 0.15452451583031163, 0.7361993600365624], 0.012282077249602568, 0.34660403082400426, 0.00425701748160405
23:38:13 done sampling a new configuration.
23:38:13 HBMASTER: schedule new run for iteration 1
23:38:13 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
23:38:13 HBMASTER: submitting job (1, 0, 5) to dispatcher
23:38:13 DISPATCHER: trying to submit job (1, 0, 5)
23:38:13 DISPATCHER: trying to notify the job_runner thread.
23:38:13 HBMASTER: job (1, 0, 5) submitted to dispatcher
23:38:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:13 DISPATCHER: Trying to submit another job.
23:38:13 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:13 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:13 WORKER: start processing job (1, 0, 5)
23:38:13 WORKER: args: ()
23:38:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 986, 'last_n_outputs': 41, 'leak_rate': 0.9796543230831589, 'lr': 0.006050951333812282, 'optimizer': 'SGD', 'sparsity': 0.8061344947442967, 'steps_to_train': 24, 'weight_decay': 0.0907439020299837}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:38:29 DISPATCHER: Starting worker discovery
23:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:29 DISPATCHER: Finished worker discovery
23:39:29 DISPATCHER: Starting worker discovery
23:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:29 DISPATCHER: Finished worker discovery
23:40:29 DISPATCHER: Starting worker discovery
23:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:29 DISPATCHER: Finished worker discovery
23:40:31 WORKER: done with job (1, 0, 5), trying to register it.
23:40:31 WORKER: registered result for job (1, 0, 5) with dispatcher
23:40:31 DISPATCHER: job (1, 0, 5) finished
23:40:31 DISPATCHER: register_result: lock acquired
23:40:31 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:40:31 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 986, 'last_n_outputs': 41, 'leak_rate': 0.9796543230831589, 'lr': 0.006050951333812282, 'optimizer': 'SGD', 'sparsity': 0.8061344947442967, 'steps_to_train': 24, 'weight_decay': 0.0907439020299837}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6023431532108228, 'info': {'data02': 0.6023431532108228, 'config': "{'batch_size': 32, 'hidden_dim': 986, 'last_n_outputs': 41, 'leak_rate': 0.9796543230831589, 'lr': 0.006050951333812282, 'optimizer': 'SGD', 'sparsity': 0.8061344947442967, 'steps_to_train': 24, 'weight_decay': 0.0907439020299837}"}}
exception: None

23:40:31 job_callback for (1, 0, 5) started
23:40:31 DISPATCHER: Trying to submit another job.
23:40:31 job_callback for (1, 0, 5) got condition
23:40:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:31 HBMASTER: Trying to run another job!
23:40:31 job_callback for (1, 0, 5) finished
23:40:31 start sampling a new configuration.
23:40:31 done sampling a new configuration.
23:40:31 HBMASTER: schedule new run for iteration 1
23:40:31 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
23:40:31 HBMASTER: submitting job (1, 0, 6) to dispatcher
23:40:31 DISPATCHER: trying to submit job (1, 0, 6)
23:40:31 DISPATCHER: trying to notify the job_runner thread.
23:40:31 HBMASTER: job (1, 0, 6) submitted to dispatcher
23:40:31 DISPATCHER: Trying to submit another job.
23:40:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:31 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:40:31 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:40:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:31 WORKER: start processing job (1, 0, 6)
23:40:31 WORKER: args: ()
23:40:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 478, 'last_n_outputs': 19, 'leak_rate': 0.9531035526725123, 'lr': 0.00453733032882329, 'optimizer': 'SGD', 'sparsity': 0.8724734941859441, 'steps_to_train': 39, 'weight_decay': 0.09231133747025871}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:41:29 DISPATCHER: Starting worker discovery
23:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:29 DISPATCHER: Finished worker discovery
23:42:29 DISPATCHER: Starting worker discovery
23:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:29 DISPATCHER: Finished worker discovery
23:42:49 WORKER: done with job (1, 0, 6), trying to register it.
23:42:49 WORKER: registered result for job (1, 0, 6) with dispatcher
23:42:49 DISPATCHER: job (1, 0, 6) finished
23:42:49 DISPATCHER: register_result: lock acquired
23:42:49 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:42:49 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 478, 'last_n_outputs': 19, 'leak_rate': 0.9531035526725123, 'lr': 0.00453733032882329, 'optimizer': 'SGD', 'sparsity': 0.8724734941859441, 'steps_to_train': 39, 'weight_decay': 0.09231133747025871}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5359918828571298, 'info': {'data02': 0.5359918828571298, 'config': "{'batch_size': 32, 'hidden_dim': 478, 'last_n_outputs': 19, 'leak_rate': 0.9531035526725123, 'lr': 0.00453733032882329, 'optimizer': 'SGD', 'sparsity': 0.8724734941859441, 'steps_to_train': 39, 'weight_decay': 0.09231133747025871}"}}
exception: None

23:42:49 job_callback for (1, 0, 6) started
23:42:49 DISPATCHER: Trying to submit another job.
23:42:49 job_callback for (1, 0, 6) got condition
23:42:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:42:49 HBMASTER: Trying to run another job!
23:42:49 job_callback for (1, 0, 6) finished
23:42:49 start sampling a new configuration.
23:42:49 done sampling a new configuration.
23:42:49 HBMASTER: schedule new run for iteration 1
23:42:49 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
23:42:49 HBMASTER: submitting job (1, 0, 7) to dispatcher
23:42:49 DISPATCHER: trying to submit job (1, 0, 7)
23:42:49 DISPATCHER: trying to notify the job_runner thread.
23:42:49 HBMASTER: job (1, 0, 7) submitted to dispatcher
23:42:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:42:49 DISPATCHER: Trying to submit another job.
23:42:49 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:42:49 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:42:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:42:49 WORKER: start processing job (1, 0, 7)
23:42:49 WORKER: args: ()
23:42:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 564, 'last_n_outputs': 12, 'leak_rate': 0.8155652586686095, 'lr': 0.006796734129886789, 'optimizer': 'Adam', 'sparsity': 0.9526226628722897, 'steps_to_train': 63, 'weight_decay': 0.019367177560856753}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:43:29 DISPATCHER: Starting worker discovery
23:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:29 DISPATCHER: Finished worker discovery
23:44:29 DISPATCHER: Starting worker discovery
23:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:29 DISPATCHER: Finished worker discovery
23:45:07 WORKER: done with job (1, 0, 7), trying to register it.
23:45:07 WORKER: registered result for job (1, 0, 7) with dispatcher
23:45:07 DISPATCHER: job (1, 0, 7) finished
23:45:07 DISPATCHER: register_result: lock acquired
23:45:07 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:45:07 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 564, 'last_n_outputs': 12, 'leak_rate': 0.8155652586686095, 'lr': 0.006796734129886789, 'optimizer': 'Adam', 'sparsity': 0.9526226628722897, 'steps_to_train': 63, 'weight_decay': 0.019367177560856753}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4856410754668112, 'info': {'data02': 0.4856410754668112, 'config': "{'batch_size': 32, 'hidden_dim': 564, 'last_n_outputs': 12, 'leak_rate': 0.8155652586686095, 'lr': 0.006796734129886789, 'optimizer': 'Adam', 'sparsity': 0.9526226628722897, 'steps_to_train': 63, 'weight_decay': 0.019367177560856753}"}}
exception: None

23:45:07 job_callback for (1, 0, 7) started
23:45:07 job_callback for (1, 0, 7) got condition
23:45:07 DISPATCHER: Trying to submit another job.
23:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:45:07 HBMASTER: Trying to run another job!
23:45:07 job_callback for (1, 0, 7) finished
23:45:07 start sampling a new configuration.
23:45:07 done sampling a new configuration.
23:45:07 HBMASTER: schedule new run for iteration 1
23:45:07 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
23:45:07 HBMASTER: submitting job (1, 0, 8) to dispatcher
23:45:07 DISPATCHER: trying to submit job (1, 0, 8)
23:45:07 DISPATCHER: trying to notify the job_runner thread.
23:45:07 HBMASTER: job (1, 0, 8) submitted to dispatcher
23:45:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:45:07 DISPATCHER: Trying to submit another job.
23:45:07 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:45:07 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:45:07 WORKER: start processing job (1, 0, 8)
23:45:07 WORKER: args: ()
23:45:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 323, 'last_n_outputs': 45, 'leak_rate': 0.9063902031696481, 'lr': 0.0014375881613925326, 'optimizer': 'SGD', 'sparsity': 0.8315283709257503, 'steps_to_train': 80, 'weight_decay': 0.10989292300079428}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:45:29 DISPATCHER: Starting worker discovery
23:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:29 DISPATCHER: Finished worker discovery
23:46:29 DISPATCHER: Starting worker discovery
23:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:29 DISPATCHER: Finished worker discovery
23:47:28 WORKER: done with job (1, 0, 8), trying to register it.
23:47:28 WORKER: registered result for job (1, 0, 8) with dispatcher
23:47:28 DISPATCHER: job (1, 0, 8) finished
23:47:28 DISPATCHER: register_result: lock acquired
23:47:28 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:47:28 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 323, 'last_n_outputs': 45, 'leak_rate': 0.9063902031696481, 'lr': 0.0014375881613925326, 'optimizer': 'SGD', 'sparsity': 0.8315283709257503, 'steps_to_train': 80, 'weight_decay': 0.10989292300079428}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6307224941843625, 'info': {'data02': 0.6307224941843625, 'config': "{'batch_size': 64, 'hidden_dim': 323, 'last_n_outputs': 45, 'leak_rate': 0.9063902031696481, 'lr': 0.0014375881613925326, 'optimizer': 'SGD', 'sparsity': 0.8315283709257503, 'steps_to_train': 80, 'weight_decay': 0.10989292300079428}"}}
exception: None

23:47:28 job_callback for (1, 0, 8) started
23:47:28 job_callback for (1, 0, 8) got condition
23:47:28 DISPATCHER: Trying to submit another job.
23:47:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:47:28 HBMASTER: Trying to run another job!
23:47:28 job_callback for (1, 0, 8) finished
23:47:28 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
23:47:28 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
23:47:28 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
23:47:28 HBMASTER: schedule new run for iteration 1
23:47:28 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
23:47:28 HBMASTER: submitting job (1, 0, 0) to dispatcher
23:47:28 DISPATCHER: trying to submit job (1, 0, 0)
23:47:28 DISPATCHER: trying to notify the job_runner thread.
23:47:28 HBMASTER: job (1, 0, 0) submitted to dispatcher
23:47:28 DISPATCHER: Trying to submit another job.
23:47:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:47:28 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:47:28 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:47:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:47:28 WORKER: start processing job (1, 0, 0)
23:47:28 WORKER: args: ()
23:47:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}, 'budget': 400.0, 'working_directory': '.'}
23:47:29 DISPATCHER: Starting worker discovery
23:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:29 DISPATCHER: Finished worker discovery
23:48:29 DISPATCHER: Starting worker discovery
23:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:29 DISPATCHER: Finished worker discovery
23:49:29 DISPATCHER: Starting worker discovery
23:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:29 DISPATCHER: Finished worker discovery
23:50:29 DISPATCHER: Starting worker discovery
23:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:29 DISPATCHER: Finished worker discovery
23:51:29 DISPATCHER: Starting worker discovery
23:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:29 DISPATCHER: Finished worker discovery
23:52:29 DISPATCHER: Starting worker discovery
23:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:29 DISPATCHER: Finished worker discovery
23:53:29 DISPATCHER: Starting worker discovery
23:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:29 DISPATCHER: Finished worker discovery
23:54:15 WORKER: done with job (1, 0, 0), trying to register it.
23:54:15 WORKER: registered result for job (1, 0, 0) with dispatcher
23:54:15 DISPATCHER: job (1, 0, 0) finished
23:54:15 DISPATCHER: register_result: lock acquired
23:54:15 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:54:15 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6046840655328616, 'info': {'data02': 0.6046840655328616, 'config': "{'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}"}}
exception: None

23:54:15 job_callback for (1, 0, 0) started
23:54:15 DISPATCHER: Trying to submit another job.
23:54:15 job_callback for (1, 0, 0) got condition
23:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:15 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:54:15 HBMASTER: Trying to run another job!
23:54:15 job_callback for (1, 0, 0) finished
23:54:15 HBMASTER: schedule new run for iteration 1
23:54:15 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
23:54:15 HBMASTER: submitting job (1, 0, 1) to dispatcher
23:54:15 DISPATCHER: trying to submit job (1, 0, 1)
23:54:15 DISPATCHER: trying to notify the job_runner thread.
23:54:15 HBMASTER: job (1, 0, 1) submitted to dispatcher
23:54:15 DISPATCHER: Trying to submit another job.
23:54:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:15 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:54:15 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:15 WORKER: start processing job (1, 0, 1)
23:54:15 WORKER: args: ()
23:54:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 992, 'last_n_outputs': 46, 'leak_rate': 0.9759202705911061, 'lr': 0.00875585353153128, 'optimizer': 'SGD', 'sparsity': 0.9421924600165232, 'steps_to_train': 48, 'weight_decay': 0.017248103424289424}, 'budget': 400.0, 'working_directory': '.'}
23:54:29 DISPATCHER: Starting worker discovery
23:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:29 DISPATCHER: Finished worker discovery
23:55:29 DISPATCHER: Starting worker discovery
23:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:29 DISPATCHER: Finished worker discovery
23:56:29 DISPATCHER: Starting worker discovery
23:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:29 DISPATCHER: Finished worker discovery
23:57:29 DISPATCHER: Starting worker discovery
23:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:29 DISPATCHER: Finished worker discovery
23:58:29 DISPATCHER: Starting worker discovery
23:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:29 DISPATCHER: Finished worker discovery
23:59:29 DISPATCHER: Starting worker discovery
23:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:29 DISPATCHER: Finished worker discovery
00:00:29 DISPATCHER: Starting worker discovery
00:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:29 DISPATCHER: Finished worker discovery
00:01:02 WORKER: done with job (1, 0, 1), trying to register it.
00:01:02 WORKER: registered result for job (1, 0, 1) with dispatcher
00:01:02 DISPATCHER: job (1, 0, 1) finished
00:01:02 DISPATCHER: register_result: lock acquired
00:01:02 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:01:02 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 992, 'last_n_outputs': 46, 'leak_rate': 0.9759202705911061, 'lr': 0.00875585353153128, 'optimizer': 'SGD', 'sparsity': 0.9421924600165232, 'steps_to_train': 48, 'weight_decay': 0.017248103424289424}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5966891680155317, 'info': {'data02': 0.5966891680155317, 'config': "{'batch_size': 32, 'hidden_dim': 992, 'last_n_outputs': 46, 'leak_rate': 0.9759202705911061, 'lr': 0.00875585353153128, 'optimizer': 'SGD', 'sparsity': 0.9421924600165232, 'steps_to_train': 48, 'weight_decay': 0.017248103424289424}"}}
exception: None

00:01:02 job_callback for (1, 0, 1) started
00:01:02 job_callback for (1, 0, 1) got condition
00:01:02 DISPATCHER: Trying to submit another job.
00:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:02 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:01:02 HBMASTER: Trying to run another job!
00:01:02 job_callback for (1, 0, 1) finished
00:01:02 HBMASTER: schedule new run for iteration 1
00:01:02 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:01:02 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:01:02 DISPATCHER: trying to submit job (1, 0, 8)
00:01:02 DISPATCHER: trying to notify the job_runner thread.
00:01:02 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:01:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:02 DISPATCHER: Trying to submit another job.
00:01:02 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:01:02 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:02 WORKER: start processing job (1, 0, 8)
00:01:02 WORKER: args: ()
00:01:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 323, 'last_n_outputs': 45, 'leak_rate': 0.9063902031696481, 'lr': 0.0014375881613925326, 'optimizer': 'SGD', 'sparsity': 0.8315283709257503, 'steps_to_train': 80, 'weight_decay': 0.10989292300079428}, 'budget': 400.0, 'working_directory': '.'}
00:01:29 DISPATCHER: Starting worker discovery
00:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:29 DISPATCHER: Finished worker discovery
00:02:29 DISPATCHER: Starting worker discovery
00:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:29 DISPATCHER: Finished worker discovery
00:03:29 DISPATCHER: Starting worker discovery
00:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:29 DISPATCHER: Finished worker discovery
00:04:29 DISPATCHER: Starting worker discovery
00:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:29 DISPATCHER: Finished worker discovery
00:05:29 DISPATCHER: Starting worker discovery
00:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:29 DISPATCHER: Finished worker discovery
00:06:29 DISPATCHER: Starting worker discovery
00:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:29 DISPATCHER: Finished worker discovery
00:07:29 DISPATCHER: Starting worker discovery
00:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:29 DISPATCHER: Finished worker discovery
00:07:49 WORKER: done with job (1, 0, 8), trying to register it.
00:07:49 WORKER: registered result for job (1, 0, 8) with dispatcher
00:07:49 DISPATCHER: job (1, 0, 8) finished
00:07:49 DISPATCHER: register_result: lock acquired
00:07:49 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:07:49 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 323, 'last_n_outputs': 45, 'leak_rate': 0.9063902031696481, 'lr': 0.0014375881613925326, 'optimizer': 'SGD', 'sparsity': 0.8315283709257503, 'steps_to_train': 80, 'weight_decay': 0.10989292300079428}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5956626886417282, 'info': {'data02': 0.5956626886417282, 'config': "{'batch_size': 64, 'hidden_dim': 323, 'last_n_outputs': 45, 'leak_rate': 0.9063902031696481, 'lr': 0.0014375881613925326, 'optimizer': 'SGD', 'sparsity': 0.8315283709257503, 'steps_to_train': 80, 'weight_decay': 0.10989292300079428}"}}
exception: None

00:07:49 job_callback for (1, 0, 8) started
00:07:49 job_callback for (1, 0, 8) got condition
00:07:49 DISPATCHER: Trying to submit another job.
00:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:49 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:07:49 HBMASTER: Trying to run another job!
00:07:49 job_callback for (1, 0, 8) finished
00:07:49 ITERATION: Advancing config (1, 0, 0) to next budget 1200.000000
00:07:49 HBMASTER: schedule new run for iteration 1
00:07:49 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:07:49 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:07:49 DISPATCHER: trying to submit job (1, 0, 0)
00:07:49 DISPATCHER: trying to notify the job_runner thread.
00:07:49 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:07:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:49 DISPATCHER: Trying to submit another job.
00:07:49 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:07:49 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:49 WORKER: start processing job (1, 0, 0)
00:07:49 WORKER: args: ()
00:07:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}, 'budget': 1200.0, 'working_directory': '.'}
00:08:29 DISPATCHER: Starting worker discovery
00:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:29 DISPATCHER: Finished worker discovery
00:09:29 DISPATCHER: Starting worker discovery
00:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:29 DISPATCHER: Finished worker discovery
00:10:29 DISPATCHER: Starting worker discovery
00:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:29 DISPATCHER: Finished worker discovery
00:11:29 DISPATCHER: Starting worker discovery
00:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:29 DISPATCHER: Finished worker discovery
00:12:29 DISPATCHER: Starting worker discovery
00:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:29 DISPATCHER: Finished worker discovery
00:13:29 DISPATCHER: Starting worker discovery
00:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:29 DISPATCHER: Finished worker discovery
00:14:29 DISPATCHER: Starting worker discovery
00:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:29 DISPATCHER: Finished worker discovery
00:15:29 DISPATCHER: Starting worker discovery
00:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:29 DISPATCHER: Finished worker discovery
00:16:29 DISPATCHER: Starting worker discovery
00:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:29 DISPATCHER: Finished worker discovery
00:17:29 DISPATCHER: Starting worker discovery
00:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:29 DISPATCHER: Finished worker discovery
00:18:29 DISPATCHER: Starting worker discovery
00:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:29 DISPATCHER: Finished worker discovery
00:19:29 DISPATCHER: Starting worker discovery
00:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:29 DISPATCHER: Finished worker discovery
00:20:29 DISPATCHER: Starting worker discovery
00:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:29 DISPATCHER: Finished worker discovery
00:21:29 DISPATCHER: Starting worker discovery
00:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:29 DISPATCHER: Finished worker discovery
00:22:29 DISPATCHER: Starting worker discovery
00:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:29 DISPATCHER: Finished worker discovery
00:23:29 DISPATCHER: Starting worker discovery
00:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:29 DISPATCHER: Finished worker discovery
00:24:29 DISPATCHER: Starting worker discovery
00:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:29 DISPATCHER: Finished worker discovery
00:25:29 DISPATCHER: Starting worker discovery
00:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:29 DISPATCHER: Finished worker discovery
00:26:29 DISPATCHER: Starting worker discovery
00:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:29 DISPATCHER: Finished worker discovery
00:27:29 DISPATCHER: Starting worker discovery
00:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:29 DISPATCHER: Finished worker discovery
00:27:57 WORKER: done with job (1, 0, 0), trying to register it.
00:27:57 WORKER: registered result for job (1, 0, 0) with dispatcher
00:27:57 DISPATCHER: job (1, 0, 0) finished
00:27:57 DISPATCHER: register_result: lock acquired
00:27:57 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:27:57 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.617083122948551, 'info': {'data02': 0.617083122948551, 'config': "{'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 44, 'leak_rate': 0.9967231939857931, 'lr': 0.0013230638897462385, 'optimizer': 'SGD', 'sparsity': 0.9635194117497831, 'steps_to_train': 33, 'weight_decay': 0.011376121101607939}"}}
exception: None

00:27:57 job_callback for (1, 0, 0) started
00:27:57 DISPATCHER: Trying to submit another job.
00:27:57 job_callback for (1, 0, 0) got condition
00:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:27:57 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:27:57 HBMASTER: Trying to run another job!
00:27:57 job_callback for (1, 0, 0) finished
00:27:57 start sampling a new configuration.
00:27:57 done sampling a new configuration.
00:27:57 HBMASTER: schedule new run for iteration 2
00:27:57 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
00:27:57 HBMASTER: submitting job (2, 0, 0) to dispatcher
00:27:57 DISPATCHER: trying to submit job (2, 0, 0)
00:27:57 DISPATCHER: trying to notify the job_runner thread.
00:27:57 HBMASTER: job (2, 0, 0) submitted to dispatcher
00:27:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:27:57 DISPATCHER: Trying to submit another job.
00:27:57 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:27:57 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:27:57 WORKER: start processing job (2, 0, 0)
00:27:57 WORKER: args: ()
00:27:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 585, 'last_n_outputs': 42, 'leak_rate': 0.766281465257621, 'lr': 0.013999424773654037, 'optimizer': 'Adam', 'sparsity': 0.9663499512126582, 'steps_to_train': 36, 'weight_decay': 0.011210131789498933}, 'budget': 400.0, 'working_directory': '.'}
00:28:29 DISPATCHER: Starting worker discovery
00:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:29 DISPATCHER: Finished worker discovery
00:29:29 DISPATCHER: Starting worker discovery
00:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:29 DISPATCHER: Finished worker discovery
00:30:29 DISPATCHER: Starting worker discovery
00:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:29 DISPATCHER: Finished worker discovery
00:31:29 DISPATCHER: Starting worker discovery
00:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:29 DISPATCHER: Finished worker discovery
00:32:29 DISPATCHER: Starting worker discovery
00:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:29 DISPATCHER: Finished worker discovery
00:33:29 DISPATCHER: Starting worker discovery
00:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:29 DISPATCHER: Finished worker discovery
00:34:29 DISPATCHER: Starting worker discovery
00:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:29 DISPATCHER: Finished worker discovery
00:34:43 WORKER: done with job (2, 0, 0), trying to register it.
00:34:43 WORKER: registered result for job (2, 0, 0) with dispatcher
00:34:43 DISPATCHER: job (2, 0, 0) finished
00:34:43 DISPATCHER: register_result: lock acquired
00:34:43 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:34:43 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 585, 'last_n_outputs': 42, 'leak_rate': 0.766281465257621, 'lr': 0.013999424773654037, 'optimizer': 'Adam', 'sparsity': 0.9663499512126582, 'steps_to_train': 36, 'weight_decay': 0.011210131789498933}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4807613861652007, 'info': {'data02': 0.4807613861652007, 'config': "{'batch_size': 32, 'hidden_dim': 585, 'last_n_outputs': 42, 'leak_rate': 0.766281465257621, 'lr': 0.013999424773654037, 'optimizer': 'Adam', 'sparsity': 0.9663499512126582, 'steps_to_train': 36, 'weight_decay': 0.011210131789498933}"}}
exception: None

00:34:43 job_callback for (2, 0, 0) started
00:34:43 DISPATCHER: Trying to submit another job.
00:34:43 job_callback for (2, 0, 0) got condition
00:34:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:34:43 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:34:43 HBMASTER: Trying to run another job!
00:34:43 job_callback for (2, 0, 0) finished
00:34:43 start sampling a new configuration.
00:34:43 best_vector: [0, 0.2422286085814249, 0.35505673558996836, 0.8573008395804763, 0.530240105542846, 1, 0.34909405091501144, 0.8791841845036598, 0.9973333353790965], 0.004435897090242785, 0.044099308063995354, 0.0001956199923227972
00:34:43 done sampling a new configuration.
00:34:43 HBMASTER: schedule new run for iteration 2
00:34:43 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
00:34:43 HBMASTER: submitting job (2, 0, 1) to dispatcher
00:34:43 DISPATCHER: trying to submit job (2, 0, 1)
00:34:43 DISPATCHER: trying to notify the job_runner thread.
00:34:43 HBMASTER: job (2, 0, 1) submitted to dispatcher
00:34:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:34:43 DISPATCHER: Trying to submit another job.
00:34:43 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:34:43 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:34:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:34:43 WORKER: start processing job (2, 0, 1)
00:34:43 WORKER: args: ()
00:34:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 394, 'last_n_outputs': 24, 'leak_rate': 0.964325209895119, 'lr': 0.011494238679704628, 'optimizer': 'SGD', 'sparsity': 0.8337825722196027, 'steps_to_train': 90, 'weight_decay': 0.19840864218066684}, 'budget': 400.0, 'working_directory': '.'}
00:35:29 DISPATCHER: Starting worker discovery
00:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:29 DISPATCHER: Finished worker discovery
00:36:29 DISPATCHER: Starting worker discovery
00:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:29 DISPATCHER: Finished worker discovery
00:37:29 DISPATCHER: Starting worker discovery
00:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:29 DISPATCHER: Finished worker discovery
00:38:29 DISPATCHER: Starting worker discovery
00:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:29 DISPATCHER: Finished worker discovery
00:39:29 DISPATCHER: Starting worker discovery
00:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:29 DISPATCHER: Finished worker discovery
00:40:29 DISPATCHER: Starting worker discovery
00:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:29 DISPATCHER: Finished worker discovery
00:41:29 WORKER: done with job (2, 0, 1), trying to register it.
00:41:29 WORKER: registered result for job (2, 0, 1) with dispatcher
00:41:29 DISPATCHER: job (2, 0, 1) finished
00:41:29 DISPATCHER: register_result: lock acquired
00:41:29 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:41:29 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 394, 'last_n_outputs': 24, 'leak_rate': 0.964325209895119, 'lr': 0.011494238679704628, 'optimizer': 'SGD', 'sparsity': 0.8337825722196027, 'steps_to_train': 90, 'weight_decay': 0.19840864218066684}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45523561925688294, 'info': {'data02': 0.45523561925688294, 'config': "{'batch_size': 16, 'hidden_dim': 394, 'last_n_outputs': 24, 'leak_rate': 0.964325209895119, 'lr': 0.011494238679704628, 'optimizer': 'SGD', 'sparsity': 0.8337825722196027, 'steps_to_train': 90, 'weight_decay': 0.19840864218066684}"}}
exception: None

00:41:29 job_callback for (2, 0, 1) started
00:41:29 job_callback for (2, 0, 1) got condition
00:41:29 DISPATCHER: Trying to submit another job.
00:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:41:29 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:41:29 HBMASTER: Trying to run another job!
00:41:29 job_callback for (2, 0, 1) finished
00:41:29 start sampling a new configuration.
00:41:29 best_vector: [3, 0.8863756158727856, 0.40903516350019337, 0.11853056506734555, 0.09745907008851318, 0, 0.19449278130534087, 0.9440840438110375, 0.4122529348195818], 0.016724681879778106, 0.046825034163655285, 0.0007831338003968764
00:41:29 done sampling a new configuration.
00:41:29 HBMASTER: schedule new run for iteration 2
00:41:29 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
00:41:29 HBMASTER: submitting job (2, 0, 2) to dispatcher
00:41:29 DISPATCHER: trying to submit job (2, 0, 2)
00:41:29 DISPATCHER: trying to notify the job_runner thread.
00:41:29 HBMASTER: job (2, 0, 2) submitted to dispatcher
00:41:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:41:29 DISPATCHER: Trying to submit another job.
00:41:29 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:41:29 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:41:29 WORKER: start processing job (2, 0, 2)
00:41:29 WORKER: args: ()
00:41:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 909, 'last_n_outputs': 26, 'leak_rate': 0.7796326412668364, 'lr': 0.0015664557822698238, 'optimizer': 'Adam', 'sparsity': 0.7966782675132819, 'steps_to_train': 95, 'weight_decay': 0.03438376532313308}, 'budget': 400.0, 'working_directory': '.'}
00:41:29 DISPATCHER: Starting worker discovery
00:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:29 DISPATCHER: Finished worker discovery
00:42:29 DISPATCHER: Starting worker discovery
00:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:29 DISPATCHER: Finished worker discovery
00:43:29 DISPATCHER: Starting worker discovery
00:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:29 DISPATCHER: Finished worker discovery
00:44:29 DISPATCHER: Starting worker discovery
00:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:29 DISPATCHER: Finished worker discovery
00:45:29 DISPATCHER: Starting worker discovery
00:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:29 DISPATCHER: Finished worker discovery
00:46:29 DISPATCHER: Starting worker discovery
00:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:29 DISPATCHER: Finished worker discovery
00:47:29 DISPATCHER: Starting worker discovery
00:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:29 DISPATCHER: Finished worker discovery
00:48:20 WORKER: done with job (2, 0, 2), trying to register it.
00:48:20 WORKER: registered result for job (2, 0, 2) with dispatcher
00:48:20 DISPATCHER: job (2, 0, 2) finished
00:48:20 DISPATCHER: register_result: lock acquired
00:48:20 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:48:20 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 909, 'last_n_outputs': 26, 'leak_rate': 0.7796326412668364, 'lr': 0.0015664557822698238, 'optimizer': 'Adam', 'sparsity': 0.7966782675132819, 'steps_to_train': 95, 'weight_decay': 0.03438376532313308}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5582862152764907, 'info': {'data02': 0.5582862152764907, 'config': "{'batch_size': 128, 'hidden_dim': 909, 'last_n_outputs': 26, 'leak_rate': 0.7796326412668364, 'lr': 0.0015664557822698238, 'optimizer': 'Adam', 'sparsity': 0.7966782675132819, 'steps_to_train': 95, 'weight_decay': 0.03438376532313308}"}}
exception: None

00:48:20 job_callback for (2, 0, 2) started
00:48:20 job_callback for (2, 0, 2) got condition
00:48:20 DISPATCHER: Trying to submit another job.
00:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:48:20 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:48:20 HBMASTER: Trying to run another job!
00:48:20 job_callback for (2, 0, 2) finished
00:48:20 start sampling a new configuration.
00:48:20 done sampling a new configuration.
00:48:20 HBMASTER: schedule new run for iteration 2
00:48:20 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
00:48:20 HBMASTER: submitting job (2, 0, 3) to dispatcher
00:48:20 DISPATCHER: trying to submit job (2, 0, 3)
00:48:20 DISPATCHER: trying to notify the job_runner thread.
00:48:20 HBMASTER: job (2, 0, 3) submitted to dispatcher
00:48:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:48:20 DISPATCHER: Trying to submit another job.
00:48:20 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:48:20 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:48:20 WORKER: start processing job (2, 0, 3)
00:48:20 WORKER: args: ()
00:48:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 327, 'last_n_outputs': 13, 'leak_rate': 0.8986388488568647, 'lr': 0.007424980844696266, 'optimizer': 'Adam', 'sparsity': 0.8689290129767382, 'steps_to_train': 17, 'weight_decay': 0.020774881457643737}, 'budget': 400.0, 'working_directory': '.'}
00:48:29 DISPATCHER: Starting worker discovery
00:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:29 DISPATCHER: Finished worker discovery
00:49:29 DISPATCHER: Starting worker discovery
00:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:29 DISPATCHER: Finished worker discovery
00:50:29 DISPATCHER: Starting worker discovery
00:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:29 DISPATCHER: Finished worker discovery
00:51:29 DISPATCHER: Starting worker discovery
00:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:29 DISPATCHER: Finished worker discovery
00:52:29 DISPATCHER: Starting worker discovery
00:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:29 DISPATCHER: Finished worker discovery
00:53:29 DISPATCHER: Starting worker discovery
00:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:29 DISPATCHER: Finished worker discovery
00:54:29 DISPATCHER: Starting worker discovery
00:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:29 DISPATCHER: Finished worker discovery
00:55:06 WORKER: done with job (2, 0, 3), trying to register it.
00:55:06 WORKER: registered result for job (2, 0, 3) with dispatcher
00:55:06 DISPATCHER: job (2, 0, 3) finished
00:55:06 DISPATCHER: register_result: lock acquired
00:55:06 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:55:06 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 327, 'last_n_outputs': 13, 'leak_rate': 0.8986388488568647, 'lr': 0.007424980844696266, 'optimizer': 'Adam', 'sparsity': 0.8689290129767382, 'steps_to_train': 17, 'weight_decay': 0.020774881457643737}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2986966851977149, 'info': {'data02': 0.2986966851977149, 'config': "{'batch_size': 64, 'hidden_dim': 327, 'last_n_outputs': 13, 'leak_rate': 0.8986388488568647, 'lr': 0.007424980844696266, 'optimizer': 'Adam', 'sparsity': 0.8689290129767382, 'steps_to_train': 17, 'weight_decay': 0.020774881457643737}"}}
exception: None

00:55:06 job_callback for (2, 0, 3) started
00:55:06 DISPATCHER: Trying to submit another job.
00:55:06 job_callback for (2, 0, 3) got condition
00:55:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:55:06 HBMASTER: Trying to run another job!
00:55:06 job_callback for (2, 0, 3) finished
00:55:06 start sampling a new configuration.
00:55:06 done sampling a new configuration.
00:55:06 HBMASTER: schedule new run for iteration 2
00:55:06 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
00:55:06 HBMASTER: submitting job (2, 0, 4) to dispatcher
00:55:06 DISPATCHER: trying to submit job (2, 0, 4)
00:55:06 DISPATCHER: trying to notify the job_runner thread.
00:55:06 HBMASTER: job (2, 0, 4) submitted to dispatcher
00:55:06 DISPATCHER: Trying to submit another job.
00:55:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:55:06 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:55:06 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:55:06 WORKER: start processing job (2, 0, 4)
00:55:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:55:06 WORKER: args: ()
00:55:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 362, 'last_n_outputs': 36, 'leak_rate': 0.7688279630520183, 'lr': 0.0021694170128998035, 'optimizer': 'Adam', 'sparsity': 0.9556978469670501, 'steps_to_train': 75, 'weight_decay': 0.06966292941984345}, 'budget': 400.0, 'working_directory': '.'}
00:55:29 DISPATCHER: Starting worker discovery
00:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:29 DISPATCHER: Finished worker discovery
00:56:29 DISPATCHER: Starting worker discovery
00:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:29 DISPATCHER: Finished worker discovery
00:57:29 DISPATCHER: Starting worker discovery
00:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:29 DISPATCHER: Finished worker discovery
00:58:29 DISPATCHER: Starting worker discovery
00:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:29 DISPATCHER: Finished worker discovery
00:59:29 DISPATCHER: Starting worker discovery
00:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:29 DISPATCHER: Finished worker discovery
01:00:29 DISPATCHER: Starting worker discovery
01:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:29 DISPATCHER: Finished worker discovery
01:01:29 DISPATCHER: Starting worker discovery
01:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:29 DISPATCHER: Finished worker discovery
01:01:53 WORKER: done with job (2, 0, 4), trying to register it.
01:01:53 WORKER: registered result for job (2, 0, 4) with dispatcher
01:01:53 DISPATCHER: job (2, 0, 4) finished
01:01:53 DISPATCHER: register_result: lock acquired
01:01:53 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:01:53 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 362, 'last_n_outputs': 36, 'leak_rate': 0.7688279630520183, 'lr': 0.0021694170128998035, 'optimizer': 'Adam', 'sparsity': 0.9556978469670501, 'steps_to_train': 75, 'weight_decay': 0.06966292941984345}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4119180901849785, 'info': {'data02': 0.4119180901849785, 'config': "{'batch_size': 16, 'hidden_dim': 362, 'last_n_outputs': 36, 'leak_rate': 0.7688279630520183, 'lr': 0.0021694170128998035, 'optimizer': 'Adam', 'sparsity': 0.9556978469670501, 'steps_to_train': 75, 'weight_decay': 0.06966292941984345}"}}
exception: None

01:01:53 job_callback for (2, 0, 4) started
01:01:53 DISPATCHER: Trying to submit another job.
01:01:53 job_callback for (2, 0, 4) got condition
01:01:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:01:53 HBMASTER: Trying to run another job!
01:01:53 job_callback for (2, 0, 4) finished
01:01:53 start sampling a new configuration.
01:01:53 done sampling a new configuration.
01:01:53 HBMASTER: schedule new run for iteration 2
01:01:53 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
01:01:53 HBMASTER: submitting job (2, 0, 5) to dispatcher
01:01:53 DISPATCHER: trying to submit job (2, 0, 5)
01:01:53 DISPATCHER: trying to notify the job_runner thread.
01:01:53 HBMASTER: job (2, 0, 5) submitted to dispatcher
01:01:53 DISPATCHER: Trying to submit another job.
01:01:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:01:53 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:01:53 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:01:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:01:53 WORKER: start processing job (2, 0, 5)
01:01:53 WORKER: args: ()
01:01:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 562, 'last_n_outputs': 11, 'leak_rate': 0.837171018522185, 'lr': 0.024956586128028514, 'optimizer': 'Adam', 'sparsity': 0.8444748838093086, 'steps_to_train': 77, 'weight_decay': 0.02213536759527476}, 'budget': 400.0, 'working_directory': '.'}
01:02:29 DISPATCHER: Starting worker discovery
01:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:29 DISPATCHER: Finished worker discovery
01:03:29 DISPATCHER: Starting worker discovery
01:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:29 DISPATCHER: Finished worker discovery
01:04:29 DISPATCHER: Starting worker discovery
01:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:29 DISPATCHER: Finished worker discovery
01:05:29 DISPATCHER: Starting worker discovery
01:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:29 DISPATCHER: Finished worker discovery
01:06:29 DISPATCHER: Starting worker discovery
01:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:29 DISPATCHER: Finished worker discovery
01:07:29 DISPATCHER: Starting worker discovery
01:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:29 DISPATCHER: Finished worker discovery
01:08:29 DISPATCHER: Starting worker discovery
01:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:29 DISPATCHER: Finished worker discovery
01:08:40 WORKER: done with job (2, 0, 5), trying to register it.
01:08:40 WORKER: registered result for job (2, 0, 5) with dispatcher
01:08:40 DISPATCHER: job (2, 0, 5) finished
01:08:40 DISPATCHER: register_result: lock acquired
01:08:40 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:08:40 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 562, 'last_n_outputs': 11, 'leak_rate': 0.837171018522185, 'lr': 0.024956586128028514, 'optimizer': 'Adam', 'sparsity': 0.8444748838093086, 'steps_to_train': 77, 'weight_decay': 0.02213536759527476}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16110785846528927, 'info': {'data02': 0.16110785846528927, 'config': "{'batch_size': 64, 'hidden_dim': 562, 'last_n_outputs': 11, 'leak_rate': 0.837171018522185, 'lr': 0.024956586128028514, 'optimizer': 'Adam', 'sparsity': 0.8444748838093086, 'steps_to_train': 77, 'weight_decay': 0.02213536759527476}"}}
exception: None

01:08:40 job_callback for (2, 0, 5) started
01:08:40 DISPATCHER: Trying to submit another job.
01:08:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:08:40 job_callback for (2, 0, 5) got condition
01:08:40 HBMASTER: Trying to run another job!
01:08:40 job_callback for (2, 0, 5) finished
01:08:40 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
01:08:40 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
01:08:40 HBMASTER: schedule new run for iteration 2
01:08:40 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
01:08:40 HBMASTER: submitting job (2, 0, 0) to dispatcher
01:08:40 DISPATCHER: trying to submit job (2, 0, 0)
01:08:40 DISPATCHER: trying to notify the job_runner thread.
01:08:40 HBMASTER: job (2, 0, 0) submitted to dispatcher
01:08:40 DISPATCHER: Trying to submit another job.
01:08:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:08:40 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:08:40 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:08:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:08:40 WORKER: start processing job (2, 0, 0)
01:08:40 WORKER: args: ()
01:08:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 585, 'last_n_outputs': 42, 'leak_rate': 0.766281465257621, 'lr': 0.013999424773654037, 'optimizer': 'Adam', 'sparsity': 0.9663499512126582, 'steps_to_train': 36, 'weight_decay': 0.011210131789498933}, 'budget': 1200.0, 'working_directory': '.'}
01:09:29 DISPATCHER: Starting worker discovery
01:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:29 DISPATCHER: Finished worker discovery
01:10:29 DISPATCHER: Starting worker discovery
01:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:29 DISPATCHER: Finished worker discovery
01:11:29 DISPATCHER: Starting worker discovery
01:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:29 DISPATCHER: Finished worker discovery
01:12:29 DISPATCHER: Starting worker discovery
01:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:29 DISPATCHER: Finished worker discovery
01:13:29 DISPATCHER: Starting worker discovery
01:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:29 DISPATCHER: Finished worker discovery
01:14:29 DISPATCHER: Starting worker discovery
01:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:29 DISPATCHER: Finished worker discovery
01:15:29 DISPATCHER: Starting worker discovery
01:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:29 DISPATCHER: Finished worker discovery
01:16:29 DISPATCHER: Starting worker discovery
01:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:29 DISPATCHER: Finished worker discovery
01:17:29 DISPATCHER: Starting worker discovery
01:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:29 DISPATCHER: Finished worker discovery
01:18:29 DISPATCHER: Starting worker discovery
01:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:29 DISPATCHER: Finished worker discovery
01:19:29 DISPATCHER: Starting worker discovery
01:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:29 DISPATCHER: Finished worker discovery
01:20:29 DISPATCHER: Starting worker discovery
01:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:29 DISPATCHER: Finished worker discovery
01:21:29 DISPATCHER: Starting worker discovery
01:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:29 DISPATCHER: Finished worker discovery
01:22:29 DISPATCHER: Starting worker discovery
01:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:30 DISPATCHER: Finished worker discovery
01:23:30 DISPATCHER: Starting worker discovery
01:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:30 DISPATCHER: Finished worker discovery
01:24:30 DISPATCHER: Starting worker discovery
01:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:30 DISPATCHER: Finished worker discovery
01:25:30 DISPATCHER: Starting worker discovery
01:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:30 DISPATCHER: Finished worker discovery
01:26:30 DISPATCHER: Starting worker discovery
01:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:30 DISPATCHER: Finished worker discovery
01:27:30 DISPATCHER: Starting worker discovery
01:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:30 DISPATCHER: Finished worker discovery
01:28:30 DISPATCHER: Starting worker discovery
01:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:30 DISPATCHER: Finished worker discovery
01:28:47 WORKER: done with job (2, 0, 0), trying to register it.
01:28:47 WORKER: registered result for job (2, 0, 0) with dispatcher
01:28:47 DISPATCHER: job (2, 0, 0) finished
01:28:47 DISPATCHER: register_result: lock acquired
01:28:47 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:28:47 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 585, 'last_n_outputs': 42, 'leak_rate': 0.766281465257621, 'lr': 0.013999424773654037, 'optimizer': 'Adam', 'sparsity': 0.9663499512126582, 'steps_to_train': 36, 'weight_decay': 0.011210131789498933}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4569250004240379, 'info': {'data02': 0.4569250004240379, 'config': "{'batch_size': 32, 'hidden_dim': 585, 'last_n_outputs': 42, 'leak_rate': 0.766281465257621, 'lr': 0.013999424773654037, 'optimizer': 'Adam', 'sparsity': 0.9663499512126582, 'steps_to_train': 36, 'weight_decay': 0.011210131789498933}"}}
exception: None

01:28:47 job_callback for (2, 0, 0) started
01:28:47 DISPATCHER: Trying to submit another job.
01:28:47 job_callback for (2, 0, 0) got condition
01:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:28:47 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:28:47 HBMASTER: Trying to run another job!
01:28:47 job_callback for (2, 0, 0) finished
01:28:47 HBMASTER: schedule new run for iteration 2
01:28:47 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
01:28:47 HBMASTER: submitting job (2, 0, 2) to dispatcher
01:28:47 DISPATCHER: trying to submit job (2, 0, 2)
01:28:47 DISPATCHER: trying to notify the job_runner thread.
01:28:47 HBMASTER: job (2, 0, 2) submitted to dispatcher
01:28:47 DISPATCHER: Trying to submit another job.
01:28:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:28:47 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:28:47 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:28:47 WORKER: start processing job (2, 0, 2)
01:28:47 WORKER: args: ()
01:28:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 909, 'last_n_outputs': 26, 'leak_rate': 0.7796326412668364, 'lr': 0.0015664557822698238, 'optimizer': 'Adam', 'sparsity': 0.7966782675132819, 'steps_to_train': 95, 'weight_decay': 0.03438376532313308}, 'budget': 1200.0, 'working_directory': '.'}
01:29:30 DISPATCHER: Starting worker discovery
01:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:30 DISPATCHER: Finished worker discovery
01:30:30 DISPATCHER: Starting worker discovery
01:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:30 DISPATCHER: Finished worker discovery
01:31:30 DISPATCHER: Starting worker discovery
01:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:30 DISPATCHER: Finished worker discovery
01:32:30 DISPATCHER: Starting worker discovery
01:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:30 DISPATCHER: Finished worker discovery
01:33:30 DISPATCHER: Starting worker discovery
01:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:30 DISPATCHER: Finished worker discovery
01:34:30 DISPATCHER: Starting worker discovery
01:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:30 DISPATCHER: Finished worker discovery
01:35:30 DISPATCHER: Starting worker discovery
01:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:30 DISPATCHER: Finished worker discovery
01:36:30 DISPATCHER: Starting worker discovery
01:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:30 DISPATCHER: Finished worker discovery
01:37:30 DISPATCHER: Starting worker discovery
01:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:30 DISPATCHER: Finished worker discovery
01:38:30 DISPATCHER: Starting worker discovery
01:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:30 DISPATCHER: Finished worker discovery
01:39:30 DISPATCHER: Starting worker discovery
01:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:30 DISPATCHER: Finished worker discovery
01:40:30 DISPATCHER: Starting worker discovery
01:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:30 DISPATCHER: Finished worker discovery
01:41:30 DISPATCHER: Starting worker discovery
01:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:30 DISPATCHER: Finished worker discovery
01:42:30 DISPATCHER: Starting worker discovery
01:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:30 DISPATCHER: Finished worker discovery
01:43:30 DISPATCHER: Starting worker discovery
01:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:30 DISPATCHER: Finished worker discovery
01:44:30 DISPATCHER: Starting worker discovery
01:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:30 DISPATCHER: Finished worker discovery
01:45:30 DISPATCHER: Starting worker discovery
01:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:30 DISPATCHER: Finished worker discovery
01:46:30 DISPATCHER: Starting worker discovery
01:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:30 DISPATCHER: Finished worker discovery
01:47:30 DISPATCHER: Starting worker discovery
01:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:30 DISPATCHER: Finished worker discovery
01:48:30 DISPATCHER: Starting worker discovery
01:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:30 DISPATCHER: Finished worker discovery
01:48:52 WORKER: done with job (2, 0, 2), trying to register it.
01:48:52 WORKER: registered result for job (2, 0, 2) with dispatcher
01:48:52 DISPATCHER: job (2, 0, 2) finished
01:48:52 DISPATCHER: register_result: lock acquired
01:48:52 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:48:52 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 909, 'last_n_outputs': 26, 'leak_rate': 0.7796326412668364, 'lr': 0.0015664557822698238, 'optimizer': 'Adam', 'sparsity': 0.7966782675132819, 'steps_to_train': 95, 'weight_decay': 0.03438376532313308}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5632749962021744, 'info': {'data02': 0.5632749962021744, 'config': "{'batch_size': 128, 'hidden_dim': 909, 'last_n_outputs': 26, 'leak_rate': 0.7796326412668364, 'lr': 0.0015664557822698238, 'optimizer': 'Adam', 'sparsity': 0.7966782675132819, 'steps_to_train': 95, 'weight_decay': 0.03438376532313308}"}}
exception: None

01:48:52 job_callback for (2, 0, 2) started
01:48:52 DISPATCHER: Trying to submit another job.
01:48:52 job_callback for (2, 0, 2) got condition
01:48:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:48:52 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:48:52 HBMASTER: Trying to run another job!
01:48:52 job_callback for (2, 0, 2) finished
01:48:52 start sampling a new configuration.
01:48:52 done sampling a new configuration.
01:48:52 HBMASTER: schedule new run for iteration 3
01:48:52 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
01:48:52 HBMASTER: submitting job (3, 0, 0) to dispatcher
01:48:52 DISPATCHER: trying to submit job (3, 0, 0)
01:48:52 DISPATCHER: trying to notify the job_runner thread.
01:48:52 HBMASTER: job (3, 0, 0) submitted to dispatcher
01:48:52 DISPATCHER: Trying to submit another job.
01:48:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:48:52 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:48:52 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:48:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:48:52 WORKER: start processing job (3, 0, 0)
01:48:52 WORKER: args: ()
01:48:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 861, 'last_n_outputs': 36, 'leak_rate': 0.8766499080119475, 'lr': 0.02890532021840671, 'optimizer': 'Adam', 'sparsity': 0.8206963569408467, 'steps_to_train': 39, 'weight_decay': 0.01335367299502098}, 'budget': 1200.0, 'working_directory': '.'}
01:49:30 DISPATCHER: Starting worker discovery
01:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:30 DISPATCHER: Finished worker discovery
01:50:30 DISPATCHER: Starting worker discovery
01:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:30 DISPATCHER: Finished worker discovery
01:51:30 DISPATCHER: Starting worker discovery
01:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:30 DISPATCHER: Finished worker discovery
01:52:30 DISPATCHER: Starting worker discovery
01:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:30 DISPATCHER: Finished worker discovery
01:53:30 DISPATCHER: Starting worker discovery
01:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:30 DISPATCHER: Finished worker discovery
01:54:30 DISPATCHER: Starting worker discovery
01:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:30 DISPATCHER: Finished worker discovery
01:55:30 DISPATCHER: Starting worker discovery
01:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:30 DISPATCHER: Finished worker discovery
01:56:30 DISPATCHER: Starting worker discovery
01:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:30 DISPATCHER: Finished worker discovery
01:57:30 DISPATCHER: Starting worker discovery
01:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:30 DISPATCHER: Finished worker discovery
01:58:30 DISPATCHER: Starting worker discovery
01:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:30 DISPATCHER: Finished worker discovery
01:59:30 DISPATCHER: Starting worker discovery
01:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:30 DISPATCHER: Finished worker discovery
02:00:30 DISPATCHER: Starting worker discovery
02:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:30 DISPATCHER: Finished worker discovery
02:01:30 DISPATCHER: Starting worker discovery
02:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:30 DISPATCHER: Finished worker discovery
02:02:30 DISPATCHER: Starting worker discovery
02:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:30 DISPATCHER: Finished worker discovery
02:03:30 DISPATCHER: Starting worker discovery
02:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:30 DISPATCHER: Finished worker discovery
02:04:30 DISPATCHER: Starting worker discovery
02:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:30 DISPATCHER: Finished worker discovery
02:05:30 DISPATCHER: Starting worker discovery
02:05:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:30 DISPATCHER: Finished worker discovery
02:06:30 DISPATCHER: Starting worker discovery
02:06:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:30 DISPATCHER: Finished worker discovery
02:07:30 DISPATCHER: Starting worker discovery
02:07:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:30 DISPATCHER: Finished worker discovery
02:08:30 DISPATCHER: Starting worker discovery
02:08:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:30 DISPATCHER: Finished worker discovery
02:08:59 WORKER: done with job (3, 0, 0), trying to register it.
02:08:59 WORKER: registered result for job (3, 0, 0) with dispatcher
02:08:59 DISPATCHER: job (3, 0, 0) finished
02:08:59 DISPATCHER: register_result: lock acquired
02:08:59 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:08:59 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 861, 'last_n_outputs': 36, 'leak_rate': 0.8766499080119475, 'lr': 0.02890532021840671, 'optimizer': 'Adam', 'sparsity': 0.8206963569408467, 'steps_to_train': 39, 'weight_decay': 0.01335367299502098}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.34601076057420577, 'info': {'data02': 0.34601076057420577, 'config': "{'batch_size': 64, 'hidden_dim': 861, 'last_n_outputs': 36, 'leak_rate': 0.8766499080119475, 'lr': 0.02890532021840671, 'optimizer': 'Adam', 'sparsity': 0.8206963569408467, 'steps_to_train': 39, 'weight_decay': 0.01335367299502098}"}}
exception: None

02:08:59 job_callback for (3, 0, 0) started
02:08:59 DISPATCHER: Trying to submit another job.
02:08:59 job_callback for (3, 0, 0) got condition
02:08:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:59 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:08:59 HBMASTER: Trying to run another job!
02:08:59 job_callback for (3, 0, 0) finished
02:08:59 start sampling a new configuration.
02:08:59 done sampling a new configuration.
02:08:59 HBMASTER: schedule new run for iteration 3
02:08:59 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
02:08:59 HBMASTER: submitting job (3, 0, 1) to dispatcher
02:08:59 DISPATCHER: trying to submit job (3, 0, 1)
02:08:59 DISPATCHER: trying to notify the job_runner thread.
02:08:59 HBMASTER: job (3, 0, 1) submitted to dispatcher
02:08:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:59 DISPATCHER: Trying to submit another job.
02:08:59 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:08:59 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:08:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:59 WORKER: start processing job (3, 0, 1)
02:08:59 WORKER: args: ()
02:08:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 417, 'last_n_outputs': 48, 'leak_rate': 0.8242822379625743, 'lr': 0.0036411216390548266, 'optimizer': 'SGD', 'sparsity': 0.8506089366173535, 'steps_to_train': 24, 'weight_decay': 0.01810557946398302}, 'budget': 1200.0, 'working_directory': '.'}
02:09:30 DISPATCHER: Starting worker discovery
02:09:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:30 DISPATCHER: Finished worker discovery
02:10:30 DISPATCHER: Starting worker discovery
02:10:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:30 DISPATCHER: Finished worker discovery
02:11:30 DISPATCHER: Starting worker discovery
02:11:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:30 DISPATCHER: Finished worker discovery
02:12:30 DISPATCHER: Starting worker discovery
02:12:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:30 DISPATCHER: Finished worker discovery
02:13:30 DISPATCHER: Starting worker discovery
02:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:30 DISPATCHER: Finished worker discovery
02:14:30 DISPATCHER: Starting worker discovery
02:14:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:30 DISPATCHER: Finished worker discovery
02:15:30 DISPATCHER: Starting worker discovery
02:15:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:30 DISPATCHER: Finished worker discovery
02:16:30 DISPATCHER: Starting worker discovery
02:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:30 DISPATCHER: Finished worker discovery
02:17:30 DISPATCHER: Starting worker discovery
02:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:30 DISPATCHER: Finished worker discovery
02:18:30 DISPATCHER: Starting worker discovery
02:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:30 DISPATCHER: Finished worker discovery
02:19:30 DISPATCHER: Starting worker discovery
02:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:30 DISPATCHER: Finished worker discovery
02:20:30 DISPATCHER: Starting worker discovery
02:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:30 DISPATCHER: Finished worker discovery
02:21:30 DISPATCHER: Starting worker discovery
02:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:30 DISPATCHER: Finished worker discovery
02:22:30 DISPATCHER: Starting worker discovery
02:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:30 DISPATCHER: Finished worker discovery
02:23:30 DISPATCHER: Starting worker discovery
02:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:30 DISPATCHER: Finished worker discovery
02:24:30 DISPATCHER: Starting worker discovery
02:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:30 DISPATCHER: Finished worker discovery
02:25:30 DISPATCHER: Starting worker discovery
02:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:30 DISPATCHER: Finished worker discovery
02:26:30 DISPATCHER: Starting worker discovery
02:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:30 DISPATCHER: Finished worker discovery
02:27:30 DISPATCHER: Starting worker discovery
02:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:30 DISPATCHER: Finished worker discovery
02:28:30 DISPATCHER: Starting worker discovery
02:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:30 DISPATCHER: Finished worker discovery
02:29:07 WORKER: done with job (3, 0, 1), trying to register it.
02:29:07 WORKER: registered result for job (3, 0, 1) with dispatcher
02:29:07 DISPATCHER: job (3, 0, 1) finished
02:29:07 DISPATCHER: register_result: lock acquired
02:29:07 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:29:07 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 417, 'last_n_outputs': 48, 'leak_rate': 0.8242822379625743, 'lr': 0.0036411216390548266, 'optimizer': 'SGD', 'sparsity': 0.8506089366173535, 'steps_to_train': 24, 'weight_decay': 0.01810557946398302}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5831292448984735, 'info': {'data02': 0.5831292448984735, 'config': "{'batch_size': 64, 'hidden_dim': 417, 'last_n_outputs': 48, 'leak_rate': 0.8242822379625743, 'lr': 0.0036411216390548266, 'optimizer': 'SGD', 'sparsity': 0.8506089366173535, 'steps_to_train': 24, 'weight_decay': 0.01810557946398302}"}}
exception: None

02:29:07 job_callback for (3, 0, 1) started
02:29:07 job_callback for (3, 0, 1) got condition
02:29:07 DISPATCHER: Trying to submit another job.
02:29:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:29:07 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:29:07 HBMASTER: Trying to run another job!
02:29:07 job_callback for (3, 0, 1) finished
02:29:07 start sampling a new configuration.
02:29:07 done sampling a new configuration.
02:29:07 HBMASTER: schedule new run for iteration 3
02:29:07 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
02:29:07 HBMASTER: submitting job (3, 0, 2) to dispatcher
02:29:07 DISPATCHER: trying to submit job (3, 0, 2)
02:29:07 DISPATCHER: trying to notify the job_runner thread.
02:29:07 HBMASTER: job (3, 0, 2) submitted to dispatcher
02:29:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:29:07 DISPATCHER: Trying to submit another job.
02:29:07 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:29:07 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:29:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:29:07 WORKER: start processing job (3, 0, 2)
02:29:07 WORKER: args: ()
02:29:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 29, 'leak_rate': 0.9517652236207821, 'lr': 0.06233704683160746, 'optimizer': 'Adam', 'sparsity': 0.9160758998424662, 'steps_to_train': 100, 'weight_decay': 0.05828884769392592}, 'budget': 1200.0, 'working_directory': '.'}
02:29:30 DISPATCHER: Starting worker discovery
02:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:30 DISPATCHER: Finished worker discovery
02:30:30 DISPATCHER: Starting worker discovery
02:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:30 DISPATCHER: Finished worker discovery
02:31:30 DISPATCHER: Starting worker discovery
02:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:30 DISPATCHER: Finished worker discovery
02:32:30 DISPATCHER: Starting worker discovery
02:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:30 DISPATCHER: Finished worker discovery
02:33:30 DISPATCHER: Starting worker discovery
02:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:30 DISPATCHER: Finished worker discovery
02:34:30 DISPATCHER: Starting worker discovery
02:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:30 DISPATCHER: Finished worker discovery
02:35:30 DISPATCHER: Starting worker discovery
02:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:30 DISPATCHER: Finished worker discovery
02:36:30 DISPATCHER: Starting worker discovery
02:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:30 DISPATCHER: Finished worker discovery
02:37:30 DISPATCHER: Starting worker discovery
02:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:30 DISPATCHER: Finished worker discovery
02:38:30 DISPATCHER: Starting worker discovery
02:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:30 DISPATCHER: Finished worker discovery
02:39:30 DISPATCHER: Starting worker discovery
02:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:30 DISPATCHER: Finished worker discovery
02:40:30 DISPATCHER: Starting worker discovery
02:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:30 DISPATCHER: Finished worker discovery
02:41:30 DISPATCHER: Starting worker discovery
02:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:30 DISPATCHER: Finished worker discovery
02:42:30 DISPATCHER: Starting worker discovery
02:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:30 DISPATCHER: Finished worker discovery
02:43:30 DISPATCHER: Starting worker discovery
02:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:30 DISPATCHER: Finished worker discovery
02:44:30 DISPATCHER: Starting worker discovery
02:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:30 DISPATCHER: Finished worker discovery
02:45:30 DISPATCHER: Starting worker discovery
02:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:30 DISPATCHER: Finished worker discovery
02:46:30 DISPATCHER: Starting worker discovery
02:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:30 DISPATCHER: Finished worker discovery
02:47:30 DISPATCHER: Starting worker discovery
02:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:30 DISPATCHER: Finished worker discovery
02:48:30 DISPATCHER: Starting worker discovery
02:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:30 DISPATCHER: Finished worker discovery
02:49:17 WORKER: done with job (3, 0, 2), trying to register it.
02:49:17 WORKER: registered result for job (3, 0, 2) with dispatcher
02:49:17 DISPATCHER: job (3, 0, 2) finished
02:49:17 DISPATCHER: register_result: lock acquired
02:49:17 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:49:17 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 29, 'leak_rate': 0.9517652236207821, 'lr': 0.06233704683160746, 'optimizer': 'Adam', 'sparsity': 0.9160758998424662, 'steps_to_train': 100, 'weight_decay': 0.05828884769392592}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1420933987170493, 'info': {'data02': 0.1420933987170493, 'config': "{'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 29, 'leak_rate': 0.9517652236207821, 'lr': 0.06233704683160746, 'optimizer': 'Adam', 'sparsity': 0.9160758998424662, 'steps_to_train': 100, 'weight_decay': 0.05828884769392592}"}}
exception: None

02:49:17 job_callback for (3, 0, 2) started
02:49:17 job_callback for (3, 0, 2) got condition
02:49:17 DISPATCHER: Trying to submit another job.
02:49:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:49:17 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:49:17 HBMASTER: Trying to run another job!
02:49:17 job_callback for (3, 0, 2) finished
02:49:17 start sampling a new configuration.
02:49:17 done sampling a new configuration.
02:49:17 HBMASTER: schedule new run for iteration 3
02:49:17 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
02:49:17 HBMASTER: submitting job (3, 0, 3) to dispatcher
02:49:17 DISPATCHER: trying to submit job (3, 0, 3)
02:49:17 DISPATCHER: trying to notify the job_runner thread.
02:49:17 HBMASTER: job (3, 0, 3) submitted to dispatcher
02:49:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:49:17 DISPATCHER: Trying to submit another job.
02:49:17 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:49:17 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:49:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:49:17 WORKER: start processing job (3, 0, 3)
02:49:17 WORKER: args: ()
02:49:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 36, 'leak_rate': 0.8411378849285928, 'lr': 0.012620048040368412, 'optimizer': 'Adam', 'sparsity': 0.8555098535262653, 'steps_to_train': 14, 'weight_decay': 0.0313115795792851}, 'budget': 1200.0, 'working_directory': '.'}
02:49:30 DISPATCHER: Starting worker discovery
02:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:30 DISPATCHER: Finished worker discovery
02:50:30 DISPATCHER: Starting worker discovery
02:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:30 DISPATCHER: Finished worker discovery
02:51:30 DISPATCHER: Starting worker discovery
02:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:30 DISPATCHER: Finished worker discovery
02:52:30 DISPATCHER: Starting worker discovery
02:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:30 DISPATCHER: Finished worker discovery
02:53:30 DISPATCHER: Starting worker discovery
02:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:30 DISPATCHER: Finished worker discovery
02:54:30 DISPATCHER: Starting worker discovery
02:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:30 DISPATCHER: Finished worker discovery
02:55:30 DISPATCHER: Starting worker discovery
02:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:30 DISPATCHER: Finished worker discovery
02:56:30 DISPATCHER: Starting worker discovery
02:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:30 DISPATCHER: Finished worker discovery
02:57:30 DISPATCHER: Starting worker discovery
02:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:30 DISPATCHER: Finished worker discovery
02:58:30 DISPATCHER: Starting worker discovery
02:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:30 DISPATCHER: Finished worker discovery
02:59:30 DISPATCHER: Starting worker discovery
02:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:30 DISPATCHER: Finished worker discovery
03:00:30 DISPATCHER: Starting worker discovery
03:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:30 DISPATCHER: Finished worker discovery
03:01:30 DISPATCHER: Starting worker discovery
03:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:30 DISPATCHER: Finished worker discovery
03:02:30 DISPATCHER: Starting worker discovery
03:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:30 DISPATCHER: Finished worker discovery
03:03:30 DISPATCHER: Starting worker discovery
03:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:30 DISPATCHER: Finished worker discovery
03:04:30 DISPATCHER: Starting worker discovery
03:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:30 DISPATCHER: Finished worker discovery
03:05:30 DISPATCHER: Starting worker discovery
03:05:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:30 DISPATCHER: Finished worker discovery
03:06:30 DISPATCHER: Starting worker discovery
03:06:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:30 DISPATCHER: Finished worker discovery
03:07:30 DISPATCHER: Starting worker discovery
03:07:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:30 DISPATCHER: Finished worker discovery
03:08:30 DISPATCHER: Starting worker discovery
03:08:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:30 DISPATCHER: Finished worker discovery
03:09:27 WORKER: done with job (3, 0, 3), trying to register it.
03:09:27 WORKER: registered result for job (3, 0, 3) with dispatcher
03:09:27 DISPATCHER: job (3, 0, 3) finished
03:09:27 DISPATCHER: register_result: lock acquired
03:09:27 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:09:27 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 36, 'leak_rate': 0.8411378849285928, 'lr': 0.012620048040368412, 'optimizer': 'Adam', 'sparsity': 0.8555098535262653, 'steps_to_train': 14, 'weight_decay': 0.0313115795792851}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2812670797578587, 'info': {'data02': 0.2812670797578587, 'config': "{'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 36, 'leak_rate': 0.8411378849285928, 'lr': 0.012620048040368412, 'optimizer': 'Adam', 'sparsity': 0.8555098535262653, 'steps_to_train': 14, 'weight_decay': 0.0313115795792851}"}}
exception: None

03:09:27 job_callback for (3, 0, 3) started
03:09:27 DISPATCHER: Trying to submit another job.
03:09:27 job_callback for (3, 0, 3) got condition
03:09:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:27 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:09:27 HBMASTER: Trying to run another job!
03:09:27 job_callback for (3, 0, 3) finished
03:09:27 start sampling a new configuration.
03:09:27 done sampling a new configuration.
03:09:27 HBMASTER: schedule new run for iteration 4
03:09:27 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
03:09:27 HBMASTER: submitting job (4, 0, 0) to dispatcher
03:09:27 DISPATCHER: trying to submit job (4, 0, 0)
03:09:27 DISPATCHER: trying to notify the job_runner thread.
03:09:27 HBMASTER: job (4, 0, 0) submitted to dispatcher
03:09:27 DISPATCHER: Trying to submit another job.
03:09:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:27 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:09:27 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:09:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:27 WORKER: start processing job (4, 0, 0)
03:09:27 WORKER: args: ()
03:09:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 213, 'last_n_outputs': 25, 'leak_rate': 0.751673989450508, 'lr': 0.004952559780333379, 'optimizer': 'Adam', 'sparsity': 0.9317585663302811, 'steps_to_train': 28, 'weight_decay': 0.019729572384177618}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:09:30 DISPATCHER: Starting worker discovery
03:09:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:30 DISPATCHER: Finished worker discovery
03:10:17 WORKER: done with job (4, 0, 0), trying to register it.
03:10:17 WORKER: registered result for job (4, 0, 0) with dispatcher
03:10:17 DISPATCHER: job (4, 0, 0) finished
03:10:17 DISPATCHER: register_result: lock acquired
03:10:17 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:10:17 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 213, 'last_n_outputs': 25, 'leak_rate': 0.751673989450508, 'lr': 0.004952559780333379, 'optimizer': 'Adam', 'sparsity': 0.9317585663302811, 'steps_to_train': 28, 'weight_decay': 0.019729572384177618}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5214861892039462, 'info': {'data02': 0.5214861892039462, 'config': "{'batch_size': 32, 'hidden_dim': 213, 'last_n_outputs': 25, 'leak_rate': 0.751673989450508, 'lr': 0.004952559780333379, 'optimizer': 'Adam', 'sparsity': 0.9317585663302811, 'steps_to_train': 28, 'weight_decay': 0.019729572384177618}"}}
exception: None

03:10:17 job_callback for (4, 0, 0) started
03:10:17 DISPATCHER: Trying to submit another job.
03:10:17 job_callback for (4, 0, 0) got condition
03:10:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:10:17 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.620315





03:10:17 HBMASTER: Trying to run another job!
03:10:17 job_callback for (4, 0, 0) finished
03:10:17 start sampling a new configuration.
03:10:17 best_vector: [2, 0.7983801457186823, 0.04575909951421231, 0.657702797203809, 0.23325069061925713, 1, 0.27940077869115654, 0.792272394908314, 0.37215555943956335], 0.02841253719025362, 0.03438511398168419, 0.0009769683297957117
03:10:17 done sampling a new configuration.
03:10:17 HBMASTER: schedule new run for iteration 4
03:10:17 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
03:10:17 HBMASTER: submitting job (4, 0, 1) to dispatcher
03:10:17 DISPATCHER: trying to submit job (4, 0, 1)
03:10:17 DISPATCHER: trying to notify the job_runner thread.
03:10:17 HBMASTER: job (4, 0, 1) submitted to dispatcher
03:10:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:10:17 DISPATCHER: Trying to submit another job.
03:10:17 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:10:17 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:10:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:10:17 WORKER: start processing job (4, 0, 1)
03:10:17 WORKER: args: ()
03:10:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 11, 'leak_rate': 0.9144256993009523, 'lr': 0.0029275301821278733, 'optimizer': 'SGD', 'sparsity': 0.8170561868858776, 'steps_to_train': 82, 'weight_decay': 0.03049197435817987}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:10:30 DISPATCHER: Starting worker discovery
03:10:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:30 DISPATCHER: Finished worker discovery
03:11:09 WORKER: done with job (4, 0, 1), trying to register it.
03:11:09 WORKER: registered result for job (4, 0, 1) with dispatcher
03:11:09 DISPATCHER: job (4, 0, 1) finished
03:11:09 DISPATCHER: register_result: lock acquired
03:11:09 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:11:09 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 11, 'leak_rate': 0.9144256993009523, 'lr': 0.0029275301821278733, 'optimizer': 'SGD', 'sparsity': 0.8170561868858776, 'steps_to_train': 82, 'weight_decay': 0.03049197435817987}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5728814728121348, 'info': {'data02': 0.5728814728121348, 'config': "{'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 11, 'leak_rate': 0.9144256993009523, 'lr': 0.0029275301821278733, 'optimizer': 'SGD', 'sparsity': 0.8170561868858776, 'steps_to_train': 82, 'weight_decay': 0.03049197435817987}"}}
exception: None

03:11:09 job_callback for (4, 0, 1) started
03:11:09 DISPATCHER: Trying to submit another job.
03:11:09 job_callback for (4, 0, 1) got condition
03:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:11:09 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.620315





03:11:09 HBMASTER: Trying to run another job!
03:11:09 job_callback for (4, 0, 1) finished
03:11:09 start sampling a new configuration.
03:11:09 done sampling a new configuration.
03:11:09 HBMASTER: schedule new run for iteration 4
03:11:09 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
03:11:09 HBMASTER: submitting job (4, 0, 2) to dispatcher
03:11:09 DISPATCHER: trying to submit job (4, 0, 2)
03:11:09 DISPATCHER: trying to notify the job_runner thread.
03:11:09 HBMASTER: job (4, 0, 2) submitted to dispatcher
03:11:09 DISPATCHER: Trying to submit another job.
03:11:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:11:09 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:11:09 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:11:09 WORKER: start processing job (4, 0, 2)
03:11:09 WORKER: args: ()
03:11:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 24, 'leak_rate': 0.9952491160105782, 'lr': 0.004682233747249774, 'optimizer': 'SGD', 'sparsity': 0.967979195399607, 'steps_to_train': 23, 'weight_decay': 0.10172088940985828}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:11:30 DISPATCHER: Starting worker discovery
03:11:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:30 DISPATCHER: Finished worker discovery
03:11:57 WORKER: done with job (4, 0, 2), trying to register it.
03:11:57 WORKER: registered result for job (4, 0, 2) with dispatcher
03:11:57 DISPATCHER: job (4, 0, 2) finished
03:11:57 DISPATCHER: register_result: lock acquired
03:11:57 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:11:57 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 24, 'leak_rate': 0.9952491160105782, 'lr': 0.004682233747249774, 'optimizer': 'SGD', 'sparsity': 0.967979195399607, 'steps_to_train': 23, 'weight_decay': 0.10172088940985828}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4318098193957426, 'info': {'data02': 0.4318098193957426, 'config': "{'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 24, 'leak_rate': 0.9952491160105782, 'lr': 0.004682233747249774, 'optimizer': 'SGD', 'sparsity': 0.967979195399607, 'steps_to_train': 23, 'weight_decay': 0.10172088940985828}"}}
exception: None

03:11:57 job_callback for (4, 0, 2) started
03:11:57 DISPATCHER: Trying to submit another job.
03:11:57 job_callback for (4, 0, 2) got condition
03:11:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:11:57 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.620315





03:11:57 HBMASTER: Trying to run another job!
03:11:57 job_callback for (4, 0, 2) finished
03:11:57 start sampling a new configuration.
03:11:57 done sampling a new configuration.
03:11:57 HBMASTER: schedule new run for iteration 4
03:11:57 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
03:11:57 HBMASTER: submitting job (4, 0, 3) to dispatcher
03:11:57 DISPATCHER: trying to submit job (4, 0, 3)
03:11:57 DISPATCHER: trying to notify the job_runner thread.
03:11:57 HBMASTER: job (4, 0, 3) submitted to dispatcher
03:11:57 DISPATCHER: Trying to submit another job.
03:11:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:11:57 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:11:57 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:11:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:11:57 WORKER: start processing job (4, 0, 3)
03:11:57 WORKER: args: ()
03:11:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 246, 'last_n_outputs': 29, 'leak_rate': 0.9175447275205805, 'lr': 0.022550162593157074, 'optimizer': 'SGD', 'sparsity': 0.8516369099457937, 'steps_to_train': 93, 'weight_decay': 0.11673729827328265}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:12:30 DISPATCHER: Starting worker discovery
03:12:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:30 DISPATCHER: Finished worker discovery
03:12:48 WORKER: done with job (4, 0, 3), trying to register it.
03:12:48 WORKER: registered result for job (4, 0, 3) with dispatcher
03:12:48 DISPATCHER: job (4, 0, 3) finished
03:12:48 DISPATCHER: register_result: lock acquired
03:12:48 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:12:48 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 246, 'last_n_outputs': 29, 'leak_rate': 0.9175447275205805, 'lr': 0.022550162593157074, 'optimizer': 'SGD', 'sparsity': 0.8516369099457937, 'steps_to_train': 93, 'weight_decay': 0.11673729827328265}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5470194825045156, 'info': {'data02': 0.5470194825045156, 'config': "{'batch_size': 128, 'hidden_dim': 246, 'last_n_outputs': 29, 'leak_rate': 0.9175447275205805, 'lr': 0.022550162593157074, 'optimizer': 'SGD', 'sparsity': 0.8516369099457937, 'steps_to_train': 93, 'weight_decay': 0.11673729827328265}"}}
exception: None

03:12:48 job_callback for (4, 0, 3) started
03:12:48 job_callback for (4, 0, 3) got condition
03:12:48 DISPATCHER: Trying to submit another job.
03:12:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:12:48 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.620315





03:12:48 HBMASTER: Trying to run another job!
03:12:48 job_callback for (4, 0, 3) finished
03:12:48 start sampling a new configuration.
03:12:48 done sampling a new configuration.
03:12:48 HBMASTER: schedule new run for iteration 4
03:12:48 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
03:12:48 HBMASTER: submitting job (4, 0, 4) to dispatcher
03:12:48 DISPATCHER: trying to submit job (4, 0, 4)
03:12:48 DISPATCHER: trying to notify the job_runner thread.
03:12:48 HBMASTER: job (4, 0, 4) submitted to dispatcher
03:12:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:12:48 DISPATCHER: Trying to submit another job.
03:12:48 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:12:48 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:12:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:12:48 WORKER: start processing job (4, 0, 4)
03:12:48 WORKER: args: ()
03:12:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 355, 'last_n_outputs': 35, 'leak_rate': 0.8151307683845136, 'lr': 0.054464322076754404, 'optimizer': 'Adam', 'sparsity': 0.7802567617300987, 'steps_to_train': 72, 'weight_decay': 0.04904872055166408}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:13:30 DISPATCHER: Starting worker discovery
03:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:30 DISPATCHER: Finished worker discovery
03:13:37 WORKER: done with job (4, 0, 4), trying to register it.
03:13:37 WORKER: registered result for job (4, 0, 4) with dispatcher
03:13:37 DISPATCHER: job (4, 0, 4) finished
03:13:37 DISPATCHER: register_result: lock acquired
03:13:37 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:13:37 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 355, 'last_n_outputs': 35, 'leak_rate': 0.8151307683845136, 'lr': 0.054464322076754404, 'optimizer': 'Adam', 'sparsity': 0.7802567617300987, 'steps_to_train': 72, 'weight_decay': 0.04904872055166408}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10974233502865123, 'info': {'data02': 0.10974233502865123, 'config': "{'batch_size': 16, 'hidden_dim': 355, 'last_n_outputs': 35, 'leak_rate': 0.8151307683845136, 'lr': 0.054464322076754404, 'optimizer': 'Adam', 'sparsity': 0.7802567617300987, 'steps_to_train': 72, 'weight_decay': 0.04904872055166408}"}}
exception: None

03:13:37 job_callback for (4, 0, 4) started
03:13:37 DISPATCHER: Trying to submit another job.
03:13:37 job_callback for (4, 0, 4) got condition
03:13:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:13:37 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.620315





03:13:37 HBMASTER: Trying to run another job!
03:13:37 job_callback for (4, 0, 4) finished
03:13:37 start sampling a new configuration.
03:13:38 best_vector: [2, 0.7292607769166968, 0.7505670777186675, 0.9350299674520196, 0.7329341822137678, 1, 0.06018425072209574, 0.8754989746341062, 0.5619503159080732], 0.028222233396023637, 0.04859677428736804, 0.0013715095062319812
03:13:38 done sampling a new configuration.
03:13:38 HBMASTER: schedule new run for iteration 4
03:13:38 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
03:13:38 HBMASTER: submitting job (4, 0, 5) to dispatcher
03:13:38 DISPATCHER: trying to submit job (4, 0, 5)
03:13:38 DISPATCHER: trying to notify the job_runner thread.
03:13:38 HBMASTER: job (4, 0, 5) submitted to dispatcher
03:13:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:13:38 DISPATCHER: Trying to submit another job.
03:13:38 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:13:38 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:13:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:13:38 WORKER: start processing job (4, 0, 5)
03:13:38 WORKER: args: ()
03:13:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 784, 'last_n_outputs': 40, 'leak_rate': 0.9837574918630049, 'lr': 0.02923266195405487, 'optimizer': 'SGD', 'sparsity': 0.7644442201733029, 'steps_to_train': 89, 'weight_decay': 0.053841136313657285}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:14:28 WORKER: done with job (4, 0, 5), trying to register it.
03:14:28 WORKER: registered result for job (4, 0, 5) with dispatcher
03:14:28 DISPATCHER: job (4, 0, 5) finished
03:14:28 DISPATCHER: register_result: lock acquired
03:14:28 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:14:28 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 784, 'last_n_outputs': 40, 'leak_rate': 0.9837574918630049, 'lr': 0.02923266195405487, 'optimizer': 'SGD', 'sparsity': 0.7644442201733029, 'steps_to_train': 89, 'weight_decay': 0.053841136313657285}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5839047039102269, 'info': {'data02': 0.5839047039102269, 'config': "{'batch_size': 64, 'hidden_dim': 784, 'last_n_outputs': 40, 'leak_rate': 0.9837574918630049, 'lr': 0.02923266195405487, 'optimizer': 'SGD', 'sparsity': 0.7644442201733029, 'steps_to_train': 89, 'weight_decay': 0.053841136313657285}"}}
exception: None

03:14:28 job_callback for (4, 0, 5) started
03:14:28 DISPATCHER: Trying to submit another job.
03:14:28 job_callback for (4, 0, 5) got condition
03:14:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:14:28 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.620315





03:14:28 HBMASTER: Trying to run another job!
03:14:28 job_callback for (4, 0, 5) finished
03:14:28 start sampling a new configuration.
03:14:28 best_vector: [3, 0.4439170368599877, 0.17826615392268927, 0.6973430463908207, 0.19407889539792036, 1, 0.11539538148945627, 0.9918083263334148, 0.38770191903372775], 0.0021546489486493864, 0.22059856411164502, 0.00047531246423672017
03:14:28 done sampling a new configuration.
03:14:28 HBMASTER: schedule new run for iteration 4
03:14:28 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
03:14:28 HBMASTER: submitting job (4, 0, 6) to dispatcher
03:14:28 DISPATCHER: trying to submit job (4, 0, 6)
03:14:28 DISPATCHER: trying to notify the job_runner thread.
03:14:28 HBMASTER: job (4, 0, 6) submitted to dispatcher
03:14:28 DISPATCHER: Trying to submit another job.
03:14:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:14:28 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:14:28 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:14:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:14:28 WORKER: start processing job (4, 0, 6)
03:14:28 WORKER: args: ()
03:14:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 555, 'last_n_outputs': 17, 'leak_rate': 0.9243357615977051, 'lr': 0.0024443184776308732, 'optimizer': 'SGD', 'sparsity': 0.7776948915574695, 'steps_to_train': 100, 'weight_decay': 0.03194565712524427}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:14:30 DISPATCHER: Starting worker discovery
03:14:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:30 DISPATCHER: Finished worker discovery
03:15:18 WORKER: done with job (4, 0, 6), trying to register it.
03:15:18 WORKER: registered result for job (4, 0, 6) with dispatcher
03:15:18 DISPATCHER: job (4, 0, 6) finished
03:15:18 DISPATCHER: register_result: lock acquired
03:15:18 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:15:18 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 555, 'last_n_outputs': 17, 'leak_rate': 0.9243357615977051, 'lr': 0.0024443184776308732, 'optimizer': 'SGD', 'sparsity': 0.7776948915574695, 'steps_to_train': 100, 'weight_decay': 0.03194565712524427}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5240606876931979, 'info': {'data02': 0.5240606876931979, 'config': "{'batch_size': 128, 'hidden_dim': 555, 'last_n_outputs': 17, 'leak_rate': 0.9243357615977051, 'lr': 0.0024443184776308732, 'optimizer': 'SGD', 'sparsity': 0.7776948915574695, 'steps_to_train': 100, 'weight_decay': 0.03194565712524427}"}}
exception: None

03:15:18 job_callback for (4, 0, 6) started
03:15:18 job_callback for (4, 0, 6) got condition
03:15:18 DISPATCHER: Trying to submit another job.
03:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:18 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.620315





03:15:18 HBMASTER: Trying to run another job!
03:15:18 job_callback for (4, 0, 6) finished
03:15:18 start sampling a new configuration.
03:15:18 best_vector: [2, 0.47061908885950254, 0.759582530989014, 0.9999321618627977, 0.6427350245744307, 1, 0.07619913814164316, 0.9337527878238185, 0.7090171237394176], 0.002510200130925882, 0.3076166453336708, 0.000772179343391561
03:15:18 done sampling a new configuration.
03:15:18 HBMASTER: schedule new run for iteration 4
03:15:18 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
03:15:18 HBMASTER: submitting job (4, 0, 7) to dispatcher
03:15:18 DISPATCHER: trying to submit job (4, 0, 7)
03:15:18 DISPATCHER: trying to notify the job_runner thread.
03:15:18 HBMASTER: job (4, 0, 7) submitted to dispatcher
03:15:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:18 DISPATCHER: Trying to submit another job.
03:15:18 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:15:18 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:18 WORKER: start processing job (4, 0, 7)
03:15:18 WORKER: args: ()
03:15:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 576, 'last_n_outputs': 41, 'leak_rate': 0.9999830404656994, 'lr': 0.019296122570814166, 'optimizer': 'SGD', 'sparsity': 0.7682877931539943, 'steps_to_train': 94, 'weight_decay': 0.08364741907342318}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:15:30 DISPATCHER: Starting worker discovery
03:15:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:30 DISPATCHER: Finished worker discovery
03:16:09 WORKER: done with job (4, 0, 7), trying to register it.
03:16:09 WORKER: registered result for job (4, 0, 7) with dispatcher
03:16:09 DISPATCHER: job (4, 0, 7) finished
03:16:09 DISPATCHER: register_result: lock acquired
03:16:09 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:16:09 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 576, 'last_n_outputs': 41, 'leak_rate': 0.9999830404656994, 'lr': 0.019296122570814166, 'optimizer': 'SGD', 'sparsity': 0.7682877931539943, 'steps_to_train': 94, 'weight_decay': 0.08364741907342318}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5618413718109492, 'info': {'data02': 0.5618413718109492, 'config': "{'batch_size': 64, 'hidden_dim': 576, 'last_n_outputs': 41, 'leak_rate': 0.9999830404656994, 'lr': 0.019296122570814166, 'optimizer': 'SGD', 'sparsity': 0.7682877931539943, 'steps_to_train': 94, 'weight_decay': 0.08364741907342318}"}}
exception: None

03:16:09 job_callback for (4, 0, 7) started
03:16:09 job_callback for (4, 0, 7) got condition
03:16:09 DISPATCHER: Trying to submit another job.
03:16:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:16:09 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.620315





03:16:09 HBMASTER: Trying to run another job!
03:16:09 job_callback for (4, 0, 7) finished
03:16:09 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
03:16:09 best_vector: [0, 0.46132232798899847, 0.9588039708054246, 0.9071410070339002, 0.29915241649216656, 1, 0.14750813037016772, 0.7424280209258434, 0.8150285758970787], 0.0012020249038395187, 0.08283747364797293, 9.957270629601334e-05
03:16:09 done sampling a new configuration.
03:16:09 HBMASTER: schedule new run for iteration 4
03:16:09 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
03:16:09 HBMASTER: submitting job (4, 0, 8) to dispatcher
03:16:09 DISPATCHER: trying to submit job (4, 0, 8)
03:16:09 DISPATCHER: trying to notify the job_runner thread.
03:16:09 HBMASTER: job (4, 0, 8) submitted to dispatcher
03:16:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:16:09 DISPATCHER: Trying to submit another job.
03:16:09 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:16:09 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:16:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:16:09 WORKER: start processing job (4, 0, 8)
03:16:09 WORKER: args: ()
03:16:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 569, 'last_n_outputs': 49, 'leak_rate': 0.9767852517584751, 'lr': 0.003965562809872602, 'optimizer': 'SGD', 'sparsity': 0.7854019512888403, 'steps_to_train': 77, 'weight_decay': 0.11491497437864392}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:16:30 DISPATCHER: Starting worker discovery
03:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:30 DISPATCHER: Finished worker discovery
03:17:00 WORKER: done with job (4, 0, 8), trying to register it.
03:17:00 WORKER: registered result for job (4, 0, 8) with dispatcher
03:17:00 DISPATCHER: job (4, 0, 8) finished
03:17:00 DISPATCHER: register_result: lock acquired
03:17:00 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:17:00 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 569, 'last_n_outputs': 49, 'leak_rate': 0.9767852517584751, 'lr': 0.003965562809872602, 'optimizer': 'SGD', 'sparsity': 0.7854019512888403, 'steps_to_train': 77, 'weight_decay': 0.11491497437864392}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5815869829960301, 'info': {'data02': 0.5815869829960301, 'config': "{'batch_size': 16, 'hidden_dim': 569, 'last_n_outputs': 49, 'leak_rate': 0.9767852517584751, 'lr': 0.003965562809872602, 'optimizer': 'SGD', 'sparsity': 0.7854019512888403, 'steps_to_train': 77, 'weight_decay': 0.11491497437864392}"}}
exception: None

03:17:00 job_callback for (4, 0, 8) started
03:17:00 DISPATCHER: Trying to submit another job.
03:17:00 job_callback for (4, 0, 8) got condition
03:17:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:17:00 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.620315





03:17:00 HBMASTER: Trying to run another job!
03:17:00 job_callback for (4, 0, 8) finished
03:17:00 start sampling a new configuration.
03:17:00 done sampling a new configuration.
03:17:00 HBMASTER: schedule new run for iteration 4
03:17:00 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
03:17:00 HBMASTER: submitting job (4, 0, 9) to dispatcher
03:17:00 DISPATCHER: trying to submit job (4, 0, 9)
03:17:00 DISPATCHER: trying to notify the job_runner thread.
03:17:00 HBMASTER: job (4, 0, 9) submitted to dispatcher
03:17:00 DISPATCHER: Trying to submit another job.
03:17:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:17:00 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:17:00 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:17:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:17:00 WORKER: start processing job (4, 0, 9)
03:17:00 WORKER: args: ()
03:17:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 812, 'last_n_outputs': 32, 'leak_rate': 0.9507446030052717, 'lr': 0.006376361809370765, 'optimizer': 'SGD', 'sparsity': 0.9602917214402675, 'steps_to_train': 36, 'weight_decay': 0.014919518953675439}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:17:30 DISPATCHER: Starting worker discovery
03:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:30 DISPATCHER: Finished worker discovery
03:17:49 WORKER: done with job (4, 0, 9), trying to register it.
03:17:49 WORKER: registered result for job (4, 0, 9) with dispatcher
03:17:49 DISPATCHER: job (4, 0, 9) finished
03:17:49 DISPATCHER: register_result: lock acquired
03:17:49 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:17:49 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 812, 'last_n_outputs': 32, 'leak_rate': 0.9507446030052717, 'lr': 0.006376361809370765, 'optimizer': 'SGD', 'sparsity': 0.9602917214402675, 'steps_to_train': 36, 'weight_decay': 0.014919518953675439}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46289040248298424, 'info': {'data02': 0.46289040248298424, 'config': "{'batch_size': 64, 'hidden_dim': 812, 'last_n_outputs': 32, 'leak_rate': 0.9507446030052717, 'lr': 0.006376361809370765, 'optimizer': 'SGD', 'sparsity': 0.9602917214402675, 'steps_to_train': 36, 'weight_decay': 0.014919518953675439}"}}
exception: None

03:17:49 job_callback for (4, 0, 9) started
03:17:49 DISPATCHER: Trying to submit another job.
03:17:49 job_callback for (4, 0, 9) got condition
03:17:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:17:49 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.620315





03:17:49 HBMASTER: Trying to run another job!
03:17:49 job_callback for (4, 0, 9) finished
03:17:49 start sampling a new configuration.
03:17:49 best_vector: [3, 0.3639142311269449, 0.8587359411002097, 0.7881553442547593, 0.24211468123043928, 1, 0.22282290508088456, 0.7018601351809435, 0.6325502435692162], 0.00508638009489864, 1.266563666110203, 0.0064422242202247845
03:17:49 done sampling a new configuration.
03:17:49 HBMASTER: schedule new run for iteration 4
03:17:49 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
03:17:49 HBMASTER: submitting job (4, 0, 10) to dispatcher
03:17:49 DISPATCHER: trying to submit job (4, 0, 10)
03:17:49 DISPATCHER: trying to notify the job_runner thread.
03:17:49 HBMASTER: job (4, 0, 10) submitted to dispatcher
03:17:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:17:49 DISPATCHER: Trying to submit another job.
03:17:49 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:17:49 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:17:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:17:49 WORKER: start processing job (4, 0, 10)
03:17:49 WORKER: args: ()
03:17:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:18:30 DISPATCHER: Starting worker discovery
03:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:30 DISPATCHER: Finished worker discovery
03:18:40 WORKER: done with job (4, 0, 10), trying to register it.
03:18:40 WORKER: registered result for job (4, 0, 10) with dispatcher
03:18:40 DISPATCHER: job (4, 0, 10) finished
03:18:40 DISPATCHER: register_result: lock acquired
03:18:40 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:18:40 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5971640926982263, 'info': {'data02': 0.5971640926982263, 'config': "{'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}"}}
exception: None

03:18:40 job_callback for (4, 0, 10) started
03:18:40 job_callback for (4, 0, 10) got condition
03:18:40 DISPATCHER: Trying to submit another job.
03:18:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:18:40 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.620315





03:18:40 HBMASTER: Trying to run another job!
03:18:40 job_callback for (4, 0, 10) finished
03:18:40 start sampling a new configuration.
03:18:40 done sampling a new configuration.
03:18:40 HBMASTER: schedule new run for iteration 4
03:18:40 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
03:18:40 HBMASTER: submitting job (4, 0, 11) to dispatcher
03:18:40 DISPATCHER: trying to submit job (4, 0, 11)
03:18:40 DISPATCHER: trying to notify the job_runner thread.
03:18:40 HBMASTER: job (4, 0, 11) submitted to dispatcher
03:18:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:18:40 DISPATCHER: Trying to submit another job.
03:18:40 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:18:40 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:18:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:18:40 WORKER: start processing job (4, 0, 11)
03:18:40 WORKER: args: ()
03:18:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 277, 'last_n_outputs': 36, 'leak_rate': 0.7981758975276504, 'lr': 0.05608311015046095, 'optimizer': 'SGD', 'sparsity': 0.831467188023204, 'steps_to_train': 98, 'weight_decay': 0.06975309662140182}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:19:30 DISPATCHER: Starting worker discovery
03:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:30 DISPATCHER: Finished worker discovery
03:19:33 WORKER: done with job (4, 0, 11), trying to register it.
03:19:33 WORKER: registered result for job (4, 0, 11) with dispatcher
03:19:33 DISPATCHER: job (4, 0, 11) finished
03:19:33 DISPATCHER: register_result: lock acquired
03:19:33 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:19:33 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 277, 'last_n_outputs': 36, 'leak_rate': 0.7981758975276504, 'lr': 0.05608311015046095, 'optimizer': 'SGD', 'sparsity': 0.831467188023204, 'steps_to_train': 98, 'weight_decay': 0.06975309662140182}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.359292446314184, 'info': {'data02': 0.359292446314184, 'config': "{'batch_size': 16, 'hidden_dim': 277, 'last_n_outputs': 36, 'leak_rate': 0.7981758975276504, 'lr': 0.05608311015046095, 'optimizer': 'SGD', 'sparsity': 0.831467188023204, 'steps_to_train': 98, 'weight_decay': 0.06975309662140182}"}}
exception: None

03:19:33 job_callback for (4, 0, 11) started
03:19:33 DISPATCHER: Trying to submit another job.
03:19:33 job_callback for (4, 0, 11) got condition
03:19:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:19:33 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.620315





03:19:33 HBMASTER: Trying to run another job!
03:19:33 job_callback for (4, 0, 11) finished
03:19:33 start sampling a new configuration.
03:19:33 best_vector: [0, 0.3388287129370835, 0.7481493173745579, 0.9949475146506599, 0.10357115058230887, 1, 0.3247133374347636, 0.32765109542355164, 0.7533858361372803], 0.008864264961909563, 0.38451681999709997, 0.0034084589747651797
03:19:33 done sampling a new configuration.
03:19:33 HBMASTER: schedule new run for iteration 4
03:19:33 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
03:19:33 HBMASTER: submitting job (4, 0, 12) to dispatcher
03:19:33 DISPATCHER: trying to submit job (4, 0, 12)
03:19:33 DISPATCHER: trying to notify the job_runner thread.
03:19:33 HBMASTER: job (4, 0, 12) submitted to dispatcher
03:19:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:19:33 DISPATCHER: Trying to submit another job.
03:19:33 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:19:33 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:19:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:19:33 WORKER: start processing job (4, 0, 12)
03:19:33 WORKER: args: ()
03:19:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:20:22 WORKER: done with job (4, 0, 12), trying to register it.
03:20:22 WORKER: registered result for job (4, 0, 12) with dispatcher
03:20:22 DISPATCHER: job (4, 0, 12) finished
03:20:22 DISPATCHER: register_result: lock acquired
03:20:22 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:20:22 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5653705268513267, 'info': {'data02': 0.5653705268513267, 'config': "{'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}"}}
exception: None

03:20:22 job_callback for (4, 0, 12) started
03:20:22 job_callback for (4, 0, 12) got condition
03:20:22 DISPATCHER: Trying to submit another job.
03:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:20:22 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.620315





03:20:22 HBMASTER: Trying to run another job!
03:20:22 job_callback for (4, 0, 12) finished
03:20:22 start sampling a new configuration.
03:20:22 done sampling a new configuration.
03:20:22 HBMASTER: schedule new run for iteration 4
03:20:22 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
03:20:22 HBMASTER: submitting job (4, 0, 13) to dispatcher
03:20:22 DISPATCHER: trying to submit job (4, 0, 13)
03:20:22 DISPATCHER: trying to notify the job_runner thread.
03:20:22 HBMASTER: job (4, 0, 13) submitted to dispatcher
03:20:22 DISPATCHER: Trying to submit another job.
03:20:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:20:22 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:20:22 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:20:22 WORKER: start processing job (4, 0, 13)
03:20:22 WORKER: args: ()
03:20:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 276, 'last_n_outputs': 45, 'leak_rate': 0.8343306067506966, 'lr': 0.019690732250123508, 'optimizer': 'SGD', 'sparsity': 0.930244891194412, 'steps_to_train': 56, 'weight_decay': 0.07416505822824689}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:20:30 DISPATCHER: Starting worker discovery
03:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:30 DISPATCHER: Finished worker discovery
03:21:10 WORKER: done with job (4, 0, 13), trying to register it.
03:21:10 WORKER: registered result for job (4, 0, 13) with dispatcher
03:21:10 DISPATCHER: job (4, 0, 13) finished
03:21:10 DISPATCHER: register_result: lock acquired
03:21:10 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:21:10 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 276, 'last_n_outputs': 45, 'leak_rate': 0.8343306067506966, 'lr': 0.019690732250123508, 'optimizer': 'SGD', 'sparsity': 0.930244891194412, 'steps_to_train': 56, 'weight_decay': 0.07416505822824689}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5546652045562586, 'info': {'data02': 0.5546652045562586, 'config': "{'batch_size': 32, 'hidden_dim': 276, 'last_n_outputs': 45, 'leak_rate': 0.8343306067506966, 'lr': 0.019690732250123508, 'optimizer': 'SGD', 'sparsity': 0.930244891194412, 'steps_to_train': 56, 'weight_decay': 0.07416505822824689}"}}
exception: None

03:21:10 job_callback for (4, 0, 13) started
03:21:10 DISPATCHER: Trying to submit another job.
03:21:10 job_callback for (4, 0, 13) got condition
03:21:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:21:10 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.620315





03:21:10 HBMASTER: Trying to run another job!
03:21:10 job_callback for (4, 0, 13) finished
03:21:10 start sampling a new configuration.
03:21:10 best_vector: [1, 0.870534001277417, 0.19307335877092452, 0.8462733513743512, 0.19054958682749923, 1, 0.31963295055520546, 0.8736907419037935, 0.06670121723035205], 0.015795513291651467, 0.6110188290344104, 0.009651356035462345
03:21:10 done sampling a new configuration.
03:21:10 HBMASTER: schedule new run for iteration 4
03:21:10 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
03:21:10 HBMASTER: submitting job (4, 0, 14) to dispatcher
03:21:10 DISPATCHER: trying to submit job (4, 0, 14)
03:21:10 DISPATCHER: trying to notify the job_runner thread.
03:21:10 HBMASTER: job (4, 0, 14) submitted to dispatcher
03:21:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:21:10 DISPATCHER: Trying to submit another job.
03:21:10 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:21:10 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:21:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:21:10 WORKER: start processing job (4, 0, 14)
03:21:10 WORKER: args: ()
03:21:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 897, 'last_n_outputs': 17, 'leak_rate': 0.9615683378435878, 'lr': 0.00240491191284277, 'optimizer': 'SGD', 'sparsity': 0.8267119081332494, 'steps_to_train': 89, 'weight_decay': 0.012211816910077009}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:21:30 DISPATCHER: Starting worker discovery
03:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:30 DISPATCHER: Finished worker discovery
03:22:01 WORKER: done with job (4, 0, 14), trying to register it.
03:22:01 WORKER: registered result for job (4, 0, 14) with dispatcher
03:22:01 DISPATCHER: job (4, 0, 14) finished
03:22:01 DISPATCHER: register_result: lock acquired
03:22:01 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:22:01 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 897, 'last_n_outputs': 17, 'leak_rate': 0.9615683378435878, 'lr': 0.00240491191284277, 'optimizer': 'SGD', 'sparsity': 0.8267119081332494, 'steps_to_train': 89, 'weight_decay': 0.012211816910077009}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5843523675721825, 'info': {'data02': 0.5843523675721825, 'config': "{'batch_size': 32, 'hidden_dim': 897, 'last_n_outputs': 17, 'leak_rate': 0.9615683378435878, 'lr': 0.00240491191284277, 'optimizer': 'SGD', 'sparsity': 0.8267119081332494, 'steps_to_train': 89, 'weight_decay': 0.012211816910077009}"}}
exception: None

03:22:01 job_callback for (4, 0, 14) started
03:22:01 DISPATCHER: Trying to submit another job.
03:22:01 job_callback for (4, 0, 14) got condition
03:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:01 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.620315





03:22:01 HBMASTER: Trying to run another job!
03:22:01 job_callback for (4, 0, 14) finished
03:22:01 start sampling a new configuration.
03:22:01 done sampling a new configuration.
03:22:01 HBMASTER: schedule new run for iteration 4
03:22:01 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
03:22:01 HBMASTER: submitting job (4, 0, 15) to dispatcher
03:22:01 DISPATCHER: trying to submit job (4, 0, 15)
03:22:01 DISPATCHER: trying to notify the job_runner thread.
03:22:01 HBMASTER: job (4, 0, 15) submitted to dispatcher
03:22:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:01 DISPATCHER: Trying to submit another job.
03:22:01 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:22:01 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:01 WORKER: start processing job (4, 0, 15)
03:22:01 WORKER: args: ()
03:22:01 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 661, 'last_n_outputs': 26, 'leak_rate': 0.8654115212587177, 'lr': 0.032643232085985525, 'optimizer': 'Adam', 'sparsity': 0.8723111661882694, 'steps_to_train': 55, 'weight_decay': 0.011219996628883268}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:22:30 DISPATCHER: Starting worker discovery
03:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:30 DISPATCHER: Finished worker discovery
03:22:52 WORKER: done with job (4, 0, 15), trying to register it.
03:22:52 WORKER: registered result for job (4, 0, 15) with dispatcher
03:22:52 DISPATCHER: job (4, 0, 15) finished
03:22:52 DISPATCHER: register_result: lock acquired
03:22:52 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:22:52 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 661, 'last_n_outputs': 26, 'leak_rate': 0.8654115212587177, 'lr': 0.032643232085985525, 'optimizer': 'Adam', 'sparsity': 0.8723111661882694, 'steps_to_train': 55, 'weight_decay': 0.011219996628883268}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24272312389068496, 'info': {'data02': 0.24272312389068496, 'config': "{'batch_size': 32, 'hidden_dim': 661, 'last_n_outputs': 26, 'leak_rate': 0.8654115212587177, 'lr': 0.032643232085985525, 'optimizer': 'Adam', 'sparsity': 0.8723111661882694, 'steps_to_train': 55, 'weight_decay': 0.011219996628883268}"}}
exception: None

03:22:52 job_callback for (4, 0, 15) started
03:22:52 DISPATCHER: Trying to submit another job.
03:22:52 job_callback for (4, 0, 15) got condition
03:22:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:52 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.620315





03:22:52 HBMASTER: Trying to run another job!
03:22:52 job_callback for (4, 0, 15) finished
03:22:52 start sampling a new configuration.
03:22:52 done sampling a new configuration.
03:22:52 HBMASTER: schedule new run for iteration 4
03:22:52 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
03:22:52 HBMASTER: submitting job (4, 0, 16) to dispatcher
03:22:52 DISPATCHER: trying to submit job (4, 0, 16)
03:22:52 DISPATCHER: trying to notify the job_runner thread.
03:22:52 HBMASTER: job (4, 0, 16) submitted to dispatcher
03:22:52 DISPATCHER: Trying to submit another job.
03:22:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:52 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:22:52 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:22:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:52 WORKER: start processing job (4, 0, 16)
03:22:52 WORKER: args: ()
03:22:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 383, 'last_n_outputs': 50, 'leak_rate': 0.8869785404985476, 'lr': 0.004882545047322973, 'optimizer': 'Adam', 'sparsity': 0.9545722950109624, 'steps_to_train': 69, 'weight_decay': 0.05628690556695788}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:23:30 DISPATCHER: Starting worker discovery
03:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:30 DISPATCHER: Finished worker discovery
03:23:41 WORKER: done with job (4, 0, 16), trying to register it.
03:23:41 WORKER: registered result for job (4, 0, 16) with dispatcher
03:23:41 DISPATCHER: job (4, 0, 16) finished
03:23:41 DISPATCHER: register_result: lock acquired
03:23:41 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:23:41 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 383, 'last_n_outputs': 50, 'leak_rate': 0.8869785404985476, 'lr': 0.004882545047322973, 'optimizer': 'Adam', 'sparsity': 0.9545722950109624, 'steps_to_train': 69, 'weight_decay': 0.05628690556695788}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5421842845953146, 'info': {'data02': 0.5421842845953146, 'config': "{'batch_size': 128, 'hidden_dim': 383, 'last_n_outputs': 50, 'leak_rate': 0.8869785404985476, 'lr': 0.004882545047322973, 'optimizer': 'Adam', 'sparsity': 0.9545722950109624, 'steps_to_train': 69, 'weight_decay': 0.05628690556695788}"}}
exception: None

03:23:41 job_callback for (4, 0, 16) started
03:23:41 job_callback for (4, 0, 16) got condition
03:23:41 DISPATCHER: Trying to submit another job.
03:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:23:41 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.620315





03:23:41 HBMASTER: Trying to run another job!
03:23:41 job_callback for (4, 0, 16) finished
03:23:41 start sampling a new configuration.
03:23:41 done sampling a new configuration.
03:23:41 HBMASTER: schedule new run for iteration 4
03:23:41 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
03:23:41 HBMASTER: submitting job (4, 0, 17) to dispatcher
03:23:41 DISPATCHER: trying to submit job (4, 0, 17)
03:23:41 DISPATCHER: trying to notify the job_runner thread.
03:23:41 HBMASTER: job (4, 0, 17) submitted to dispatcher
03:23:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:23:41 DISPATCHER: Trying to submit another job.
03:23:41 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:23:41 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:23:41 WORKER: start processing job (4, 0, 17)
03:23:41 WORKER: args: ()
03:23:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 355, 'last_n_outputs': 30, 'leak_rate': 0.8443133472712118, 'lr': 0.09112561081808895, 'optimizer': 'SGD', 'sparsity': 0.973602821265563, 'steps_to_train': 98, 'weight_decay': 0.013647690390670124}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:24:29 WORKER: done with job (4, 0, 17), trying to register it.
03:24:29 WORKER: registered result for job (4, 0, 17) with dispatcher
03:24:29 DISPATCHER: job (4, 0, 17) finished
03:24:29 DISPATCHER: register_result: lock acquired
03:24:29 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:24:29 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 355, 'last_n_outputs': 30, 'leak_rate': 0.8443133472712118, 'lr': 0.09112561081808895, 'optimizer': 'SGD', 'sparsity': 0.973602821265563, 'steps_to_train': 98, 'weight_decay': 0.013647690390670124}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4259487179062823, 'info': {'data02': 0.4259487179062823, 'config': "{'batch_size': 64, 'hidden_dim': 355, 'last_n_outputs': 30, 'leak_rate': 0.8443133472712118, 'lr': 0.09112561081808895, 'optimizer': 'SGD', 'sparsity': 0.973602821265563, 'steps_to_train': 98, 'weight_decay': 0.013647690390670124}"}}
exception: None

03:24:29 job_callback for (4, 0, 17) started
03:24:29 job_callback for (4, 0, 17) got condition
03:24:29 DISPATCHER: Trying to submit another job.
03:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:24:29 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.620315





03:24:29 HBMASTER: Trying to run another job!
03:24:29 job_callback for (4, 0, 17) finished
03:24:29 start sampling a new configuration.
03:24:29 done sampling a new configuration.
03:24:29 HBMASTER: schedule new run for iteration 4
03:24:29 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
03:24:29 HBMASTER: submitting job (4, 0, 18) to dispatcher
03:24:29 DISPATCHER: trying to submit job (4, 0, 18)
03:24:29 DISPATCHER: trying to notify the job_runner thread.
03:24:29 HBMASTER: job (4, 0, 18) submitted to dispatcher
03:24:29 DISPATCHER: Trying to submit another job.
03:24:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:24:29 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:24:29 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:24:29 WORKER: start processing job (4, 0, 18)
03:24:29 WORKER: args: ()
03:24:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 868, 'last_n_outputs': 15, 'leak_rate': 0.8586514497692659, 'lr': 0.005240328839603755, 'optimizer': 'SGD', 'sparsity': 0.8568655064758276, 'steps_to_train': 57, 'weight_decay': 0.015084771737435661}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:24:30 DISPATCHER: Starting worker discovery
03:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:30 DISPATCHER: Finished worker discovery
03:25:19 WORKER: done with job (4, 0, 18), trying to register it.
03:25:19 WORKER: registered result for job (4, 0, 18) with dispatcher
03:25:19 DISPATCHER: job (4, 0, 18) finished
03:25:19 DISPATCHER: register_result: lock acquired
03:25:19 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:25:19 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 868, 'last_n_outputs': 15, 'leak_rate': 0.8586514497692659, 'lr': 0.005240328839603755, 'optimizer': 'SGD', 'sparsity': 0.8568655064758276, 'steps_to_train': 57, 'weight_decay': 0.015084771737435661}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5197506357321737, 'info': {'data02': 0.5197506357321737, 'config': "{'batch_size': 16, 'hidden_dim': 868, 'last_n_outputs': 15, 'leak_rate': 0.8586514497692659, 'lr': 0.005240328839603755, 'optimizer': 'SGD', 'sparsity': 0.8568655064758276, 'steps_to_train': 57, 'weight_decay': 0.015084771737435661}"}}
exception: None

03:25:19 job_callback for (4, 0, 18) started
03:25:19 DISPATCHER: Trying to submit another job.
03:25:19 job_callback for (4, 0, 18) got condition
03:25:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:25:19 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.620315





03:25:19 HBMASTER: Trying to run another job!
03:25:19 job_callback for (4, 0, 18) finished
03:25:19 start sampling a new configuration.
03:25:19 done sampling a new configuration.
03:25:19 HBMASTER: schedule new run for iteration 4
03:25:19 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
03:25:19 HBMASTER: submitting job (4, 0, 19) to dispatcher
03:25:19 DISPATCHER: trying to submit job (4, 0, 19)
03:25:19 DISPATCHER: trying to notify the job_runner thread.
03:25:19 HBMASTER: job (4, 0, 19) submitted to dispatcher
03:25:19 DISPATCHER: Trying to submit another job.
03:25:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:25:19 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:25:19 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:25:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:25:19 WORKER: start processing job (4, 0, 19)
03:25:19 WORKER: args: ()
03:25:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 656, 'last_n_outputs': 11, 'leak_rate': 0.8675616885123466, 'lr': 0.001328978560948127, 'optimizer': 'Adam', 'sparsity': 0.7886346942488364, 'steps_to_train': 43, 'weight_decay': 0.0188527605073764}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:25:30 DISPATCHER: Starting worker discovery
03:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:30 DISPATCHER: Finished worker discovery
03:26:10 WORKER: done with job (4, 0, 19), trying to register it.
03:26:10 WORKER: registered result for job (4, 0, 19) with dispatcher
03:26:10 DISPATCHER: job (4, 0, 19) finished
03:26:10 DISPATCHER: register_result: lock acquired
03:26:10 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:26:10 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 656, 'last_n_outputs': 11, 'leak_rate': 0.8675616885123466, 'lr': 0.001328978560948127, 'optimizer': 'Adam', 'sparsity': 0.7886346942488364, 'steps_to_train': 43, 'weight_decay': 0.0188527605073764}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4988443671325903, 'info': {'data02': 0.4988443671325903, 'config': "{'batch_size': 32, 'hidden_dim': 656, 'last_n_outputs': 11, 'leak_rate': 0.8675616885123466, 'lr': 0.001328978560948127, 'optimizer': 'Adam', 'sparsity': 0.7886346942488364, 'steps_to_train': 43, 'weight_decay': 0.0188527605073764}"}}
exception: None

03:26:10 job_callback for (4, 0, 19) started
03:26:10 DISPATCHER: Trying to submit another job.
03:26:10 job_callback for (4, 0, 19) got condition
03:26:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:26:10 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.620315





03:26:10 HBMASTER: Trying to run another job!
03:26:10 job_callback for (4, 0, 19) finished
03:26:10 start sampling a new configuration.
03:26:10 best_vector: [3, 0.8441624114899455, 0.770384684484033, 0.8403817316449947, 0.4858227442802501, 1, 0.18539101469345579, 0.0848329467695722, 0.1830121169313541], 0.03366887943216669, 0.15735940177419455, 0.005298114725853234
03:26:10 done sampling a new configuration.
03:26:10 HBMASTER: schedule new run for iteration 4
03:26:10 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
03:26:10 HBMASTER: submitting job (4, 0, 20) to dispatcher
03:26:10 DISPATCHER: trying to submit job (4, 0, 20)
03:26:10 DISPATCHER: trying to notify the job_runner thread.
03:26:10 HBMASTER: job (4, 0, 20) submitted to dispatcher
03:26:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:26:10 DISPATCHER: Trying to submit another job.
03:26:10 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:26:10 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:26:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:26:10 WORKER: start processing job (4, 0, 20)
03:26:10 WORKER: args: ()
03:26:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:26:30 DISPATCHER: Starting worker discovery
03:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:30 DISPATCHER: Finished worker discovery
03:27:00 WORKER: done with job (4, 0, 20), trying to register it.
03:27:00 WORKER: registered result for job (4, 0, 20) with dispatcher
03:27:00 DISPATCHER: job (4, 0, 20) finished
03:27:00 DISPATCHER: register_result: lock acquired
03:27:00 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:27:00 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5890590299159223, 'info': {'data02': 0.5890590299159223, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}"}}
exception: None

03:27:00 job_callback for (4, 0, 20) started
03:27:00 DISPATCHER: Trying to submit another job.
03:27:00 job_callback for (4, 0, 20) got condition
03:27:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:27:00 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.620315





03:27:00 HBMASTER: Trying to run another job!
03:27:00 job_callback for (4, 0, 20) finished
03:27:00 start sampling a new configuration.
03:27:00 done sampling a new configuration.
03:27:00 HBMASTER: schedule new run for iteration 4
03:27:00 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
03:27:00 HBMASTER: submitting job (4, 0, 21) to dispatcher
03:27:00 DISPATCHER: trying to submit job (4, 0, 21)
03:27:00 DISPATCHER: trying to notify the job_runner thread.
03:27:00 HBMASTER: job (4, 0, 21) submitted to dispatcher
03:27:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:27:00 DISPATCHER: Trying to submit another job.
03:27:00 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:27:00 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:27:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:27:00 WORKER: start processing job (4, 0, 21)
03:27:00 WORKER: args: ()
03:27:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 351, 'last_n_outputs': 43, 'leak_rate': 0.8962718420978251, 'lr': 0.03760078898513477, 'optimizer': 'Adam', 'sparsity': 0.9400856836988252, 'steps_to_train': 48, 'weight_decay': 0.18939748186263922}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:27:30 DISPATCHER: Starting worker discovery
03:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:30 DISPATCHER: Finished worker discovery
03:27:52 WORKER: done with job (4, 0, 21), trying to register it.
03:27:52 WORKER: registered result for job (4, 0, 21) with dispatcher
03:27:52 DISPATCHER: job (4, 0, 21) finished
03:27:52 DISPATCHER: register_result: lock acquired
03:27:52 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:27:52 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 351, 'last_n_outputs': 43, 'leak_rate': 0.8962718420978251, 'lr': 0.03760078898513477, 'optimizer': 'Adam', 'sparsity': 0.9400856836988252, 'steps_to_train': 48, 'weight_decay': 0.18939748186263922}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14154291327379945, 'info': {'data02': 0.14154291327379945, 'config': "{'batch_size': 64, 'hidden_dim': 351, 'last_n_outputs': 43, 'leak_rate': 0.8962718420978251, 'lr': 0.03760078898513477, 'optimizer': 'Adam', 'sparsity': 0.9400856836988252, 'steps_to_train': 48, 'weight_decay': 0.18939748186263922}"}}
exception: None

03:27:52 job_callback for (4, 0, 21) started
03:27:52 job_callback for (4, 0, 21) got condition
03:27:52 DISPATCHER: Trying to submit another job.
03:27:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:27:52 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.620315





03:27:52 HBMASTER: Trying to run another job!
03:27:52 job_callback for (4, 0, 21) finished
03:27:52 start sampling a new configuration.
03:27:52 best_vector: [1, 0.8870304660403148, 0.9572334186138808, 0.9355796447765242, 0.5629111574259459, 1, 0.2347487890014919, 0.007417093573554134, 0.8381871506375762], 0.0010085670421687693, 1.6510206756531016, 0.0016651650394029316
03:27:52 done sampling a new configuration.
03:27:52 HBMASTER: schedule new run for iteration 4
03:27:52 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
03:27:52 HBMASTER: submitting job (4, 0, 22) to dispatcher
03:27:52 DISPATCHER: trying to submit job (4, 0, 22)
03:27:52 DISPATCHER: trying to notify the job_runner thread.
03:27:52 HBMASTER: job (4, 0, 22) submitted to dispatcher
03:27:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:27:52 DISPATCHER: Trying to submit another job.
03:27:52 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:27:52 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:27:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:27:52 WORKER: start processing job (4, 0, 22)
03:27:52 WORKER: args: ()
03:27:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 49, 'leak_rate': 0.9838949111941311, 'lr': 0.013360487801603442, 'optimizer': 'SGD', 'sparsity': 0.806339709360358, 'steps_to_train': 10, 'weight_decay': 0.12317047746744746}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:28:30 DISPATCHER: Starting worker discovery
03:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:30 DISPATCHER: Finished worker discovery
03:28:41 WORKER: done with job (4, 0, 22), trying to register it.
03:28:41 WORKER: registered result for job (4, 0, 22) with dispatcher
03:28:41 DISPATCHER: job (4, 0, 22) finished
03:28:41 DISPATCHER: register_result: lock acquired
03:28:41 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:28:41 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 49, 'leak_rate': 0.9838949111941311, 'lr': 0.013360487801603442, 'optimizer': 'SGD', 'sparsity': 0.806339709360358, 'steps_to_train': 10, 'weight_decay': 0.12317047746744746}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5673552185711616, 'info': {'data02': 0.5673552185711616, 'config': "{'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 49, 'leak_rate': 0.9838949111941311, 'lr': 0.013360487801603442, 'optimizer': 'SGD', 'sparsity': 0.806339709360358, 'steps_to_train': 10, 'weight_decay': 0.12317047746744746}"}}
exception: None

03:28:41 job_callback for (4, 0, 22) started
03:28:41 DISPATCHER: Trying to submit another job.
03:28:41 job_callback for (4, 0, 22) got condition
03:28:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:28:41 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.620315





03:28:41 HBMASTER: Trying to run another job!
03:28:41 job_callback for (4, 0, 22) finished
03:28:41 start sampling a new configuration.
03:28:41 best_vector: [0, 0.4313592561203034, 0.29150545573370273, 0.8257887378388434, 0.35728775903200244, 1, 0.7496449851225664, 0.8813591536905774, 0.3079383785019463], 0.007879260005301453, 1.7338346755005112, 0.013661334214476
03:28:41 done sampling a new configuration.
03:28:41 HBMASTER: schedule new run for iteration 4
03:28:41 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
03:28:41 HBMASTER: submitting job (4, 0, 23) to dispatcher
03:28:41 DISPATCHER: trying to submit job (4, 0, 23)
03:28:41 DISPATCHER: trying to notify the job_runner thread.
03:28:41 HBMASTER: job (4, 0, 23) submitted to dispatcher
03:28:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:28:41 DISPATCHER: Trying to submit another job.
03:28:41 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:28:41 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:28:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:28:41 WORKER: start processing job (4, 0, 23)
03:28:41 WORKER: args: ()
03:28:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 545, 'last_n_outputs': 21, 'leak_rate': 0.9564471844597109, 'lr': 0.005182932085030926, 'optimizer': 'SGD', 'sparsity': 0.9299147964294159, 'steps_to_train': 90, 'weight_decay': 0.02515573825461445}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:29:30 DISPATCHER: Starting worker discovery
03:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:30 DISPATCHER: Finished worker discovery
03:29:31 WORKER: done with job (4, 0, 23), trying to register it.
03:29:31 WORKER: registered result for job (4, 0, 23) with dispatcher
03:29:31 DISPATCHER: job (4, 0, 23) finished
03:29:31 DISPATCHER: register_result: lock acquired
03:29:31 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:29:31 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 545, 'last_n_outputs': 21, 'leak_rate': 0.9564471844597109, 'lr': 0.005182932085030926, 'optimizer': 'SGD', 'sparsity': 0.9299147964294159, 'steps_to_train': 90, 'weight_decay': 0.02515573825461445}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5534104876490571, 'info': {'data02': 0.5534104876490571, 'config': "{'batch_size': 16, 'hidden_dim': 545, 'last_n_outputs': 21, 'leak_rate': 0.9564471844597109, 'lr': 0.005182932085030926, 'optimizer': 'SGD', 'sparsity': 0.9299147964294159, 'steps_to_train': 90, 'weight_decay': 0.02515573825461445}"}}
exception: None

03:29:31 job_callback for (4, 0, 23) started
03:29:31 job_callback for (4, 0, 23) got condition
03:29:31 DISPATCHER: Trying to submit another job.
03:29:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:31 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.620315





03:29:31 HBMASTER: Trying to run another job!
03:29:31 job_callback for (4, 0, 23) finished
03:29:31 start sampling a new configuration.
03:29:31 best_vector: [2, 0.20479251642295127, 0.9466187046869502, 0.9128582314138826, 0.2607541815129323, 1, 0.1516231615971242, 0.8876549456839734, 0.8030021012159858], 0.004018792944830183, 3.7669559041612453, 0.015138615811129616
03:29:31 done sampling a new configuration.
03:29:31 HBMASTER: schedule new run for iteration 4
03:29:31 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
03:29:31 HBMASTER: submitting job (4, 0, 24) to dispatcher
03:29:31 DISPATCHER: trying to submit job (4, 0, 24)
03:29:31 DISPATCHER: trying to notify the job_runner thread.
03:29:31 HBMASTER: job (4, 0, 24) submitted to dispatcher
03:29:31 DISPATCHER: Trying to submit another job.
03:29:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:29:31 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:29:31 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:29:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:29:31 WORKER: start processing job (4, 0, 24)
03:29:31 WORKER: args: ()
03:29:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 364, 'last_n_outputs': 48, 'leak_rate': 0.9782145578534707, 'lr': 0.003322831837867437, 'optimizer': 'SGD', 'sparsity': 0.7863895587833098, 'steps_to_train': 90, 'weight_decay': 0.11084849990770836}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:30:21 WORKER: done with job (4, 0, 24), trying to register it.
03:30:21 WORKER: registered result for job (4, 0, 24) with dispatcher
03:30:21 DISPATCHER: job (4, 0, 24) finished
03:30:21 DISPATCHER: register_result: lock acquired
03:30:21 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:30:21 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 364, 'last_n_outputs': 48, 'leak_rate': 0.9782145578534707, 'lr': 0.003322831837867437, 'optimizer': 'SGD', 'sparsity': 0.7863895587833098, 'steps_to_train': 90, 'weight_decay': 0.11084849990770836}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5657053995882312, 'info': {'data02': 0.5657053995882312, 'config': "{'batch_size': 64, 'hidden_dim': 364, 'last_n_outputs': 48, 'leak_rate': 0.9782145578534707, 'lr': 0.003322831837867437, 'optimizer': 'SGD', 'sparsity': 0.7863895587833098, 'steps_to_train': 90, 'weight_decay': 0.11084849990770836}"}}
exception: None

03:30:21 job_callback for (4, 0, 24) started
03:30:21 job_callback for (4, 0, 24) got condition
03:30:21 DISPATCHER: Trying to submit another job.
03:30:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:21 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.620315





03:30:21 HBMASTER: Trying to run another job!
03:30:21 job_callback for (4, 0, 24) finished
03:30:21 start sampling a new configuration.
03:30:21 done sampling a new configuration.
03:30:21 HBMASTER: schedule new run for iteration 4
03:30:21 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
03:30:21 HBMASTER: submitting job (4, 0, 25) to dispatcher
03:30:21 DISPATCHER: trying to submit job (4, 0, 25)
03:30:21 DISPATCHER: trying to notify the job_runner thread.
03:30:21 HBMASTER: job (4, 0, 25) submitted to dispatcher
03:30:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:21 DISPATCHER: Trying to submit another job.
03:30:21 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:30:21 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:30:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:21 WORKER: start processing job (4, 0, 25)
03:30:21 WORKER: args: ()
03:30:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 23, 'leak_rate': 0.9212854324071493, 'lr': 0.03473695909454915, 'optimizer': 'Adam', 'sparsity': 0.7918815962419256, 'steps_to_train': 98, 'weight_decay': 0.01649114520321344}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:30:30 DISPATCHER: Starting worker discovery
03:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:30 DISPATCHER: Finished worker discovery
03:31:11 WORKER: done with job (4, 0, 25), trying to register it.
03:31:11 WORKER: registered result for job (4, 0, 25) with dispatcher
03:31:11 DISPATCHER: job (4, 0, 25) finished
03:31:11 DISPATCHER: register_result: lock acquired
03:31:11 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:31:11 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 23, 'leak_rate': 0.9212854324071493, 'lr': 0.03473695909454915, 'optimizer': 'Adam', 'sparsity': 0.7918815962419256, 'steps_to_train': 98, 'weight_decay': 0.01649114520321344}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21251686339343748, 'info': {'data02': 0.21251686339343748, 'config': "{'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 23, 'leak_rate': 0.9212854324071493, 'lr': 0.03473695909454915, 'optimizer': 'Adam', 'sparsity': 0.7918815962419256, 'steps_to_train': 98, 'weight_decay': 0.01649114520321344}"}}
exception: None

03:31:11 job_callback for (4, 0, 25) started
03:31:11 DISPATCHER: Trying to submit another job.
03:31:11 job_callback for (4, 0, 25) got condition
03:31:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:31:11 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.620315





03:31:11 HBMASTER: Trying to run another job!
03:31:11 job_callback for (4, 0, 25) finished
03:31:11 start sampling a new configuration.
03:31:11 done sampling a new configuration.
03:31:11 HBMASTER: schedule new run for iteration 4
03:31:11 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
03:31:11 HBMASTER: submitting job (4, 0, 26) to dispatcher
03:31:11 DISPATCHER: trying to submit job (4, 0, 26)
03:31:11 DISPATCHER: trying to notify the job_runner thread.
03:31:11 HBMASTER: job (4, 0, 26) submitted to dispatcher
03:31:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:31:11 DISPATCHER: Trying to submit another job.
03:31:11 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:31:11 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:31:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:31:11 WORKER: start processing job (4, 0, 26)
03:31:11 WORKER: args: ()
03:31:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 900, 'last_n_outputs': 38, 'leak_rate': 0.8171810406579971, 'lr': 0.003456287562187275, 'optimizer': 'Adam', 'sparsity': 0.9544182678176144, 'steps_to_train': 87, 'weight_decay': 0.15351653917465244}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:31:30 DISPATCHER: Starting worker discovery
03:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:30 DISPATCHER: Finished worker discovery
03:32:01 WORKER: done with job (4, 0, 26), trying to register it.
03:32:01 WORKER: registered result for job (4, 0, 26) with dispatcher
03:32:01 DISPATCHER: job (4, 0, 26) finished
03:32:01 DISPATCHER: register_result: lock acquired
03:32:01 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:32:01 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 900, 'last_n_outputs': 38, 'leak_rate': 0.8171810406579971, 'lr': 0.003456287562187275, 'optimizer': 'Adam', 'sparsity': 0.9544182678176144, 'steps_to_train': 87, 'weight_decay': 0.15351653917465244}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3775803891327564, 'info': {'data02': 0.3775803891327564, 'config': "{'batch_size': 32, 'hidden_dim': 900, 'last_n_outputs': 38, 'leak_rate': 0.8171810406579971, 'lr': 0.003456287562187275, 'optimizer': 'Adam', 'sparsity': 0.9544182678176144, 'steps_to_train': 87, 'weight_decay': 0.15351653917465244}"}}
exception: None

03:32:01 job_callback for (4, 0, 26) started
03:32:01 DISPATCHER: Trying to submit another job.
03:32:01 job_callback for (4, 0, 26) got condition
03:32:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:32:01 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.620315





03:32:01 HBMASTER: Trying to run another job!
03:32:01 job_callback for (4, 0, 26) finished
03:32:01 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
03:32:01 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
03:32:01 HBMASTER: schedule new run for iteration 4
03:32:01 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
03:32:01 HBMASTER: submitting job (4, 0, 1) to dispatcher
03:32:01 DISPATCHER: trying to submit job (4, 0, 1)
03:32:01 DISPATCHER: trying to notify the job_runner thread.
03:32:01 HBMASTER: job (4, 0, 1) submitted to dispatcher
03:32:01 DISPATCHER: Trying to submit another job.
03:32:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:32:01 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:32:01 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:32:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:32:01 WORKER: start processing job (4, 0, 1)
03:32:01 WORKER: args: ()
03:32:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 11, 'leak_rate': 0.9144256993009523, 'lr': 0.0029275301821278733, 'optimizer': 'SGD', 'sparsity': 0.8170561868858776, 'steps_to_train': 82, 'weight_decay': 0.03049197435817987}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:32:30 DISPATCHER: Starting worker discovery
03:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:30 DISPATCHER: Finished worker discovery
03:33:30 DISPATCHER: Starting worker discovery
03:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:30 DISPATCHER: Finished worker discovery
03:34:20 WORKER: done with job (4, 0, 1), trying to register it.
03:34:20 WORKER: registered result for job (4, 0, 1) with dispatcher
03:34:20 DISPATCHER: job (4, 0, 1) finished
03:34:20 DISPATCHER: register_result: lock acquired
03:34:20 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:34:20 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 11, 'leak_rate': 0.9144256993009523, 'lr': 0.0029275301821278733, 'optimizer': 'SGD', 'sparsity': 0.8170561868858776, 'steps_to_train': 82, 'weight_decay': 0.03049197435817987}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.499346152366397, 'info': {'data02': 0.499346152366397, 'config': "{'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 11, 'leak_rate': 0.9144256993009523, 'lr': 0.0029275301821278733, 'optimizer': 'SGD', 'sparsity': 0.8170561868858776, 'steps_to_train': 82, 'weight_decay': 0.03049197435817987}"}}
exception: None

03:34:20 job_callback for (4, 0, 1) started
03:34:20 job_callback for (4, 0, 1) got condition
03:34:20 DISPATCHER: Trying to submit another job.
03:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:34:20 HBMASTER: Trying to run another job!
03:34:20 job_callback for (4, 0, 1) finished
03:34:20 HBMASTER: schedule new run for iteration 4
03:34:20 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
03:34:20 HBMASTER: submitting job (4, 0, 5) to dispatcher
03:34:20 DISPATCHER: trying to submit job (4, 0, 5)
03:34:20 DISPATCHER: trying to notify the job_runner thread.
03:34:20 HBMASTER: job (4, 0, 5) submitted to dispatcher
03:34:20 DISPATCHER: Trying to submit another job.
03:34:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:34:20 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:34:20 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:34:20 WORKER: start processing job (4, 0, 5)
03:34:20 WORKER: args: ()
03:34:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 784, 'last_n_outputs': 40, 'leak_rate': 0.9837574918630049, 'lr': 0.02923266195405487, 'optimizer': 'SGD', 'sparsity': 0.7644442201733029, 'steps_to_train': 89, 'weight_decay': 0.053841136313657285}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:34:30 DISPATCHER: Starting worker discovery
03:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:30 DISPATCHER: Finished worker discovery
03:35:30 DISPATCHER: Starting worker discovery
03:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:30 DISPATCHER: Finished worker discovery
03:36:30 DISPATCHER: Starting worker discovery
03:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:30 DISPATCHER: Finished worker discovery
03:36:39 WORKER: done with job (4, 0, 5), trying to register it.
03:36:39 WORKER: registered result for job (4, 0, 5) with dispatcher
03:36:39 DISPATCHER: job (4, 0, 5) finished
03:36:39 DISPATCHER: register_result: lock acquired
03:36:39 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:36:39 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 784, 'last_n_outputs': 40, 'leak_rate': 0.9837574918630049, 'lr': 0.02923266195405487, 'optimizer': 'SGD', 'sparsity': 0.7644442201733029, 'steps_to_train': 89, 'weight_decay': 0.053841136313657285}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47990670023769244, 'info': {'data02': 0.47990670023769244, 'config': "{'batch_size': 64, 'hidden_dim': 784, 'last_n_outputs': 40, 'leak_rate': 0.9837574918630049, 'lr': 0.02923266195405487, 'optimizer': 'SGD', 'sparsity': 0.7644442201733029, 'steps_to_train': 89, 'weight_decay': 0.053841136313657285}"}}
exception: None

03:36:39 job_callback for (4, 0, 5) started
03:36:39 job_callback for (4, 0, 5) got condition
03:36:39 DISPATCHER: Trying to submit another job.
03:36:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:36:39 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.630722





03:36:39 HBMASTER: Trying to run another job!
03:36:39 job_callback for (4, 0, 5) finished
03:36:39 HBMASTER: schedule new run for iteration 4
03:36:39 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
03:36:39 HBMASTER: submitting job (4, 0, 8) to dispatcher
03:36:39 DISPATCHER: trying to submit job (4, 0, 8)
03:36:39 DISPATCHER: trying to notify the job_runner thread.
03:36:39 HBMASTER: job (4, 0, 8) submitted to dispatcher
03:36:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:36:39 DISPATCHER: Trying to submit another job.
03:36:39 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:36:39 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:36:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:36:39 WORKER: start processing job (4, 0, 8)
03:36:39 WORKER: args: ()
03:36:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 569, 'last_n_outputs': 49, 'leak_rate': 0.9767852517584751, 'lr': 0.003965562809872602, 'optimizer': 'SGD', 'sparsity': 0.7854019512888403, 'steps_to_train': 77, 'weight_decay': 0.11491497437864392}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:37:30 DISPATCHER: Starting worker discovery
03:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:30 DISPATCHER: Finished worker discovery
03:38:30 DISPATCHER: Starting worker discovery
03:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:30 DISPATCHER: Finished worker discovery
03:38:59 WORKER: done with job (4, 0, 8), trying to register it.
03:38:59 WORKER: registered result for job (4, 0, 8) with dispatcher
03:38:59 DISPATCHER: job (4, 0, 8) finished
03:38:59 DISPATCHER: register_result: lock acquired
03:38:59 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:38:59 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 569, 'last_n_outputs': 49, 'leak_rate': 0.9767852517584751, 'lr': 0.003965562809872602, 'optimizer': 'SGD', 'sparsity': 0.7854019512888403, 'steps_to_train': 77, 'weight_decay': 0.11491497437864392}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5790769090500558, 'info': {'data02': 0.5790769090500558, 'config': "{'batch_size': 16, 'hidden_dim': 569, 'last_n_outputs': 49, 'leak_rate': 0.9767852517584751, 'lr': 0.003965562809872602, 'optimizer': 'SGD', 'sparsity': 0.7854019512888403, 'steps_to_train': 77, 'weight_decay': 0.11491497437864392}"}}
exception: None

03:38:59 job_callback for (4, 0, 8) started
03:38:59 DISPATCHER: Trying to submit another job.
03:38:59 job_callback for (4, 0, 8) got condition
03:38:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:38:59 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.630722





03:38:59 HBMASTER: Trying to run another job!
03:38:59 job_callback for (4, 0, 8) finished
03:38:59 HBMASTER: schedule new run for iteration 4
03:38:59 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
03:38:59 HBMASTER: submitting job (4, 0, 10) to dispatcher
03:38:59 DISPATCHER: trying to submit job (4, 0, 10)
03:38:59 DISPATCHER: trying to notify the job_runner thread.
03:38:59 HBMASTER: job (4, 0, 10) submitted to dispatcher
03:38:59 DISPATCHER: Trying to submit another job.
03:38:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:38:59 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:38:59 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:38:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:38:59 WORKER: start processing job (4, 0, 10)
03:38:59 WORKER: args: ()
03:38:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:39:30 DISPATCHER: Starting worker discovery
03:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:30 DISPATCHER: Finished worker discovery
03:40:30 DISPATCHER: Starting worker discovery
03:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:30 DISPATCHER: Finished worker discovery
03:41:19 WORKER: done with job (4, 0, 10), trying to register it.
03:41:19 WORKER: registered result for job (4, 0, 10) with dispatcher
03:41:19 DISPATCHER: job (4, 0, 10) finished
03:41:19 DISPATCHER: register_result: lock acquired
03:41:19 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:41:19 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5965282949384205, 'info': {'data02': 0.5965282949384205, 'config': "{'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}"}}
exception: None

03:41:19 job_callback for (4, 0, 10) started
03:41:19 job_callback for (4, 0, 10) got condition
03:41:19 DISPATCHER: Trying to submit another job.
03:41:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:41:19 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.630722





03:41:19 HBMASTER: Trying to run another job!
03:41:19 job_callback for (4, 0, 10) finished
03:41:19 HBMASTER: schedule new run for iteration 4
03:41:19 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
03:41:19 HBMASTER: submitting job (4, 0, 12) to dispatcher
03:41:19 DISPATCHER: trying to submit job (4, 0, 12)
03:41:19 DISPATCHER: trying to notify the job_runner thread.
03:41:19 HBMASTER: job (4, 0, 12) submitted to dispatcher
03:41:19 DISPATCHER: Trying to submit another job.
03:41:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:41:19 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:41:19 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:41:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:41:19 WORKER: start processing job (4, 0, 12)
03:41:19 WORKER: args: ()
03:41:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:41:30 DISPATCHER: Starting worker discovery
03:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:30 DISPATCHER: Finished worker discovery
03:42:30 DISPATCHER: Starting worker discovery
03:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:30 DISPATCHER: Finished worker discovery
03:43:30 DISPATCHER: Starting worker discovery
03:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:30 DISPATCHER: Finished worker discovery
03:43:38 WORKER: done with job (4, 0, 12), trying to register it.
03:43:38 WORKER: registered result for job (4, 0, 12) with dispatcher
03:43:38 DISPATCHER: job (4, 0, 12) finished
03:43:38 DISPATCHER: register_result: lock acquired
03:43:38 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:43:38 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6111176226806132, 'info': {'data02': 0.6111176226806132, 'config': "{'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}"}}
exception: None

03:43:38 job_callback for (4, 0, 12) started
03:43:38 DISPATCHER: Trying to submit another job.
03:43:38 job_callback for (4, 0, 12) got condition
03:43:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:43:38 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.630722





03:43:38 HBMASTER: Trying to run another job!
03:43:38 job_callback for (4, 0, 12) finished
03:43:38 HBMASTER: schedule new run for iteration 4
03:43:38 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
03:43:38 HBMASTER: submitting job (4, 0, 14) to dispatcher
03:43:38 DISPATCHER: trying to submit job (4, 0, 14)
03:43:38 DISPATCHER: trying to notify the job_runner thread.
03:43:38 HBMASTER: job (4, 0, 14) submitted to dispatcher
03:43:38 DISPATCHER: Trying to submit another job.
03:43:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:43:38 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:43:38 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:43:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:43:38 WORKER: start processing job (4, 0, 14)
03:43:38 WORKER: args: ()
03:43:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 897, 'last_n_outputs': 17, 'leak_rate': 0.9615683378435878, 'lr': 0.00240491191284277, 'optimizer': 'SGD', 'sparsity': 0.8267119081332494, 'steps_to_train': 89, 'weight_decay': 0.012211816910077009}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:44:30 DISPATCHER: Starting worker discovery
03:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:30 DISPATCHER: Finished worker discovery
03:45:30 DISPATCHER: Starting worker discovery
03:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:30 DISPATCHER: Finished worker discovery
03:46:00 WORKER: done with job (4, 0, 14), trying to register it.
03:46:00 WORKER: registered result for job (4, 0, 14) with dispatcher
03:46:00 DISPATCHER: job (4, 0, 14) finished
03:46:00 DISPATCHER: register_result: lock acquired
03:46:00 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:46:00 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 897, 'last_n_outputs': 17, 'leak_rate': 0.9615683378435878, 'lr': 0.00240491191284277, 'optimizer': 'SGD', 'sparsity': 0.8267119081332494, 'steps_to_train': 89, 'weight_decay': 0.012211816910077009}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.543188056088916, 'info': {'data02': 0.543188056088916, 'config': "{'batch_size': 32, 'hidden_dim': 897, 'last_n_outputs': 17, 'leak_rate': 0.9615683378435878, 'lr': 0.00240491191284277, 'optimizer': 'SGD', 'sparsity': 0.8267119081332494, 'steps_to_train': 89, 'weight_decay': 0.012211816910077009}"}}
exception: None

03:46:00 job_callback for (4, 0, 14) started
03:46:00 job_callback for (4, 0, 14) got condition
03:46:00 DISPATCHER: Trying to submit another job.
03:46:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:46:00 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.630722





03:46:00 HBMASTER: Trying to run another job!
03:46:00 job_callback for (4, 0, 14) finished
03:46:00 HBMASTER: schedule new run for iteration 4
03:46:00 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
03:46:00 HBMASTER: submitting job (4, 0, 20) to dispatcher
03:46:00 DISPATCHER: trying to submit job (4, 0, 20)
03:46:00 DISPATCHER: trying to notify the job_runner thread.
03:46:00 HBMASTER: job (4, 0, 20) submitted to dispatcher
03:46:00 DISPATCHER: Trying to submit another job.
03:46:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:46:00 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:46:00 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:46:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:46:00 WORKER: start processing job (4, 0, 20)
03:46:00 WORKER: args: ()
03:46:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:46:30 DISPATCHER: Starting worker discovery
03:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:30 DISPATCHER: Finished worker discovery
03:47:30 DISPATCHER: Starting worker discovery
03:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:30 DISPATCHER: Finished worker discovery
03:48:19 WORKER: done with job (4, 0, 20), trying to register it.
03:48:19 WORKER: registered result for job (4, 0, 20) with dispatcher
03:48:19 DISPATCHER: job (4, 0, 20) finished
03:48:19 DISPATCHER: register_result: lock acquired
03:48:19 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:48:19 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6011480522971835, 'info': {'data02': 0.6011480522971835, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}"}}
exception: None

03:48:19 job_callback for (4, 0, 20) started
03:48:19 DISPATCHER: Trying to submit another job.
03:48:19 job_callback for (4, 0, 20) got condition
03:48:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:48:19 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.630722





03:48:19 HBMASTER: Trying to run another job!
03:48:19 job_callback for (4, 0, 20) finished
03:48:19 HBMASTER: schedule new run for iteration 4
03:48:19 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
03:48:19 HBMASTER: submitting job (4, 0, 22) to dispatcher
03:48:19 DISPATCHER: trying to submit job (4, 0, 22)
03:48:19 DISPATCHER: trying to notify the job_runner thread.
03:48:19 HBMASTER: job (4, 0, 22) submitted to dispatcher
03:48:19 DISPATCHER: Trying to submit another job.
03:48:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:48:19 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:48:19 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:48:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:48:19 WORKER: start processing job (4, 0, 22)
03:48:19 WORKER: args: ()
03:48:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 49, 'leak_rate': 0.9838949111941311, 'lr': 0.013360487801603442, 'optimizer': 'SGD', 'sparsity': 0.806339709360358, 'steps_to_train': 10, 'weight_decay': 0.12317047746744746}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:48:30 DISPATCHER: Starting worker discovery
03:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:30 DISPATCHER: Finished worker discovery
03:49:30 DISPATCHER: Starting worker discovery
03:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:30 DISPATCHER: Finished worker discovery
03:50:30 DISPATCHER: Starting worker discovery
03:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:31 DISPATCHER: Finished worker discovery
03:50:38 WORKER: done with job (4, 0, 22), trying to register it.
03:50:38 WORKER: registered result for job (4, 0, 22) with dispatcher
03:50:38 DISPATCHER: job (4, 0, 22) finished
03:50:38 DISPATCHER: register_result: lock acquired
03:50:38 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:50:38 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 49, 'leak_rate': 0.9838949111941311, 'lr': 0.013360487801603442, 'optimizer': 'SGD', 'sparsity': 0.806339709360358, 'steps_to_train': 10, 'weight_decay': 0.12317047746744746}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5906846765591535, 'info': {'data02': 0.5906846765591535, 'config': "{'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 49, 'leak_rate': 0.9838949111941311, 'lr': 0.013360487801603442, 'optimizer': 'SGD', 'sparsity': 0.806339709360358, 'steps_to_train': 10, 'weight_decay': 0.12317047746744746}"}}
exception: None

03:50:38 job_callback for (4, 0, 22) started
03:50:38 job_callback for (4, 0, 22) got condition
03:50:38 DISPATCHER: Trying to submit another job.
03:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:50:38 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.630722





03:50:38 HBMASTER: Trying to run another job!
03:50:38 job_callback for (4, 0, 22) finished
03:50:38 HBMASTER: schedule new run for iteration 4
03:50:38 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
03:50:38 HBMASTER: submitting job (4, 0, 24) to dispatcher
03:50:38 DISPATCHER: trying to submit job (4, 0, 24)
03:50:38 DISPATCHER: trying to notify the job_runner thread.
03:50:38 HBMASTER: job (4, 0, 24) submitted to dispatcher
03:50:38 DISPATCHER: Trying to submit another job.
03:50:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:50:38 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:50:38 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:50:38 WORKER: start processing job (4, 0, 24)
03:50:38 WORKER: args: ()
03:50:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 364, 'last_n_outputs': 48, 'leak_rate': 0.9782145578534707, 'lr': 0.003322831837867437, 'optimizer': 'SGD', 'sparsity': 0.7863895587833098, 'steps_to_train': 90, 'weight_decay': 0.11084849990770836}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:51:31 DISPATCHER: Starting worker discovery
03:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:31 DISPATCHER: Finished worker discovery
03:52:31 DISPATCHER: Starting worker discovery
03:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:31 DISPATCHER: Finished worker discovery
03:52:58 WORKER: done with job (4, 0, 24), trying to register it.
03:52:58 WORKER: registered result for job (4, 0, 24) with dispatcher
03:52:58 DISPATCHER: job (4, 0, 24) finished
03:52:58 DISPATCHER: register_result: lock acquired
03:52:58 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:52:58 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 364, 'last_n_outputs': 48, 'leak_rate': 0.9782145578534707, 'lr': 0.003322831837867437, 'optimizer': 'SGD', 'sparsity': 0.7863895587833098, 'steps_to_train': 90, 'weight_decay': 0.11084849990770836}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5823746413138087, 'info': {'data02': 0.5823746413138087, 'config': "{'batch_size': 64, 'hidden_dim': 364, 'last_n_outputs': 48, 'leak_rate': 0.9782145578534707, 'lr': 0.003322831837867437, 'optimizer': 'SGD', 'sparsity': 0.7863895587833098, 'steps_to_train': 90, 'weight_decay': 0.11084849990770836}"}}
exception: None

03:52:58 job_callback for (4, 0, 24) started
03:52:58 DISPATCHER: Trying to submit another job.
03:52:58 job_callback for (4, 0, 24) got condition
03:52:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:52:58 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.630722





03:52:58 HBMASTER: Trying to run another job!
03:52:58 job_callback for (4, 0, 24) finished
03:52:58 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
03:52:58 ITERATION: Advancing config (4, 0, 12) to next budget 400.000000
03:52:58 ITERATION: Advancing config (4, 0, 20) to next budget 400.000000
03:52:58 HBMASTER: schedule new run for iteration 4
03:52:58 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
03:52:58 HBMASTER: submitting job (4, 0, 10) to dispatcher
03:52:58 DISPATCHER: trying to submit job (4, 0, 10)
03:52:58 DISPATCHER: trying to notify the job_runner thread.
03:52:58 HBMASTER: job (4, 0, 10) submitted to dispatcher
03:52:58 DISPATCHER: Trying to submit another job.
03:52:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:52:58 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:52:58 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:52:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:52:58 WORKER: start processing job (4, 0, 10)
03:52:58 WORKER: args: ()
03:52:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}, 'budget': 400.0, 'working_directory': '.'}
03:53:31 DISPATCHER: Starting worker discovery
03:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:31 DISPATCHER: Finished worker discovery
03:54:31 DISPATCHER: Starting worker discovery
03:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:31 DISPATCHER: Finished worker discovery
03:55:31 DISPATCHER: Starting worker discovery
03:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:31 DISPATCHER: Finished worker discovery
03:56:31 DISPATCHER: Starting worker discovery
03:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:31 DISPATCHER: Finished worker discovery
03:57:31 DISPATCHER: Starting worker discovery
03:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:31 DISPATCHER: Finished worker discovery
03:58:31 DISPATCHER: Starting worker discovery
03:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:31 DISPATCHER: Finished worker discovery
03:59:31 DISPATCHER: Starting worker discovery
03:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:31 DISPATCHER: Finished worker discovery
03:59:45 WORKER: done with job (4, 0, 10), trying to register it.
03:59:45 WORKER: registered result for job (4, 0, 10) with dispatcher
03:59:45 DISPATCHER: job (4, 0, 10) finished
03:59:45 DISPATCHER: register_result: lock acquired
03:59:45 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:59:45 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5760904803770868, 'info': {'data02': 0.5760904803770868, 'config': "{'batch_size': 128, 'hidden_dim': 491, 'last_n_outputs': 45, 'leak_rate': 0.9470388360636899, 'lr': 0.003049505089125899, 'optimizer': 'SGD', 'sparsity': 0.8034774972194123, 'steps_to_train': 73, 'weight_decay': 0.06652223630522414}"}}
exception: None

03:59:45 job_callback for (4, 0, 10) started
03:59:45 job_callback for (4, 0, 10) got condition
03:59:45 DISPATCHER: Trying to submit another job.
03:59:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:59:45 HBMASTER: Trying to run another job!
03:59:45 job_callback for (4, 0, 10) finished
03:59:45 HBMASTER: schedule new run for iteration 4
03:59:45 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
03:59:45 HBMASTER: submitting job (4, 0, 12) to dispatcher
03:59:45 DISPATCHER: trying to submit job (4, 0, 12)
03:59:45 DISPATCHER: trying to notify the job_runner thread.
03:59:45 HBMASTER: job (4, 0, 12) submitted to dispatcher
03:59:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:59:45 DISPATCHER: Trying to submit another job.
03:59:45 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:59:45 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:59:45 WORKER: start processing job (4, 0, 12)
03:59:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:59:45 WORKER: args: ()
03:59:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}, 'budget': 400.0, 'working_directory': '.'}
04:00:31 DISPATCHER: Starting worker discovery
04:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:31 DISPATCHER: Finished worker discovery
04:01:31 DISPATCHER: Starting worker discovery
04:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:31 DISPATCHER: Finished worker discovery
04:02:31 DISPATCHER: Starting worker discovery
04:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:31 DISPATCHER: Finished worker discovery
04:03:31 DISPATCHER: Starting worker discovery
04:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:31 DISPATCHER: Finished worker discovery
04:04:31 DISPATCHER: Starting worker discovery
04:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:31 DISPATCHER: Finished worker discovery
04:05:31 DISPATCHER: Starting worker discovery
04:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:31 DISPATCHER: Finished worker discovery
04:06:30 WORKER: done with job (4, 0, 12), trying to register it.
04:06:30 WORKER: registered result for job (4, 0, 12) with dispatcher
04:06:30 DISPATCHER: job (4, 0, 12) finished
04:06:30 DISPATCHER: register_result: lock acquired
04:06:30 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:06:30 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.565979905679828, 'info': {'data02': 0.565979905679828, 'config': "{'batch_size': 16, 'hidden_dim': 471, 'last_n_outputs': 40, 'leak_rate': 0.9987368786626649, 'lr': 0.001611173466667482, 'optimizer': 'SGD', 'sparsity': 0.8279312009843433, 'steps_to_train': 39, 'weight_decay': 0.09553831361800665}"}}
exception: None

04:06:30 job_callback for (4, 0, 12) started
04:06:30 DISPATCHER: Trying to submit another job.
04:06:30 job_callback for (4, 0, 12) got condition
04:06:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:30 HBMASTER: Trying to run another job!
04:06:30 job_callback for (4, 0, 12) finished
04:06:30 HBMASTER: schedule new run for iteration 4
04:06:30 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:06:30 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:06:30 DISPATCHER: trying to submit job (4, 0, 20)
04:06:30 DISPATCHER: trying to notify the job_runner thread.
04:06:30 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:06:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:30 DISPATCHER: Trying to submit another job.
04:06:30 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:06:30 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:06:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:30 WORKER: start processing job (4, 0, 20)
04:06:30 WORKER: args: ()
04:06:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 400.0, 'working_directory': '.'}
04:06:31 DISPATCHER: Starting worker discovery
04:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:31 DISPATCHER: Finished worker discovery
04:07:31 DISPATCHER: Starting worker discovery
04:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:31 DISPATCHER: Finished worker discovery
04:08:31 DISPATCHER: Starting worker discovery
04:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:31 DISPATCHER: Finished worker discovery
04:09:31 DISPATCHER: Starting worker discovery
04:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:31 DISPATCHER: Finished worker discovery
04:10:31 DISPATCHER: Starting worker discovery
04:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:31 DISPATCHER: Finished worker discovery
04:11:31 DISPATCHER: Starting worker discovery
04:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:31 DISPATCHER: Finished worker discovery
04:12:31 DISPATCHER: Starting worker discovery
04:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:31 DISPATCHER: Finished worker discovery
04:13:17 WORKER: done with job (4, 0, 20), trying to register it.
04:13:17 WORKER: registered result for job (4, 0, 20) with dispatcher
04:13:17 DISPATCHER: job (4, 0, 20) finished
04:13:17 DISPATCHER: register_result: lock acquired
04:13:17 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:13:17 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5823615673911459, 'info': {'data02': 0.5823615673911459, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}"}}
exception: None

04:13:17 job_callback for (4, 0, 20) started
04:13:17 job_callback for (4, 0, 20) got condition
04:13:17 DISPATCHER: Trying to submit another job.
04:13:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:17 HBMASTER: Trying to run another job!
04:13:17 job_callback for (4, 0, 20) finished
04:13:17 ITERATION: Advancing config (4, 0, 20) to next budget 1200.000000
04:13:17 HBMASTER: schedule new run for iteration 4
04:13:17 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:13:17 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:13:17 DISPATCHER: trying to submit job (4, 0, 20)
04:13:17 DISPATCHER: trying to notify the job_runner thread.
04:13:17 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:13:17 DISPATCHER: Trying to submit another job.
04:13:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:17 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:13:17 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:13:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:17 WORKER: start processing job (4, 0, 20)
04:13:17 WORKER: args: ()
04:13:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 1200.0, 'working_directory': '.'}
04:13:31 DISPATCHER: Starting worker discovery
04:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:31 DISPATCHER: Finished worker discovery
04:14:31 DISPATCHER: Starting worker discovery
04:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:31 DISPATCHER: Finished worker discovery
04:15:31 DISPATCHER: Starting worker discovery
04:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:31 DISPATCHER: Finished worker discovery
04:16:31 DISPATCHER: Starting worker discovery
04:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:31 DISPATCHER: Finished worker discovery
04:17:31 DISPATCHER: Starting worker discovery
04:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:31 DISPATCHER: Finished worker discovery
04:18:31 DISPATCHER: Starting worker discovery
04:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:31 DISPATCHER: Finished worker discovery
04:19:31 DISPATCHER: Starting worker discovery
04:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:31 DISPATCHER: Finished worker discovery
04:20:31 DISPATCHER: Starting worker discovery
04:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:31 DISPATCHER: Finished worker discovery
04:21:31 DISPATCHER: Starting worker discovery
04:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:31 DISPATCHER: Finished worker discovery
04:22:31 DISPATCHER: Starting worker discovery
04:22:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:31 DISPATCHER: Finished worker discovery
04:23:31 DISPATCHER: Starting worker discovery
04:23:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:31 DISPATCHER: Finished worker discovery
04:24:31 DISPATCHER: Starting worker discovery
04:24:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:31 DISPATCHER: Finished worker discovery
04:25:31 DISPATCHER: Starting worker discovery
04:25:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:31 DISPATCHER: Finished worker discovery
04:26:31 DISPATCHER: Starting worker discovery
04:26:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:31 DISPATCHER: Finished worker discovery
04:27:31 DISPATCHER: Starting worker discovery
04:27:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:31 DISPATCHER: Finished worker discovery
04:28:31 DISPATCHER: Starting worker discovery
04:28:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:31 DISPATCHER: Finished worker discovery
04:29:31 DISPATCHER: Starting worker discovery
04:29:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:31 DISPATCHER: Finished worker discovery
04:30:31 DISPATCHER: Starting worker discovery
04:30:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:31 DISPATCHER: Finished worker discovery
04:31:31 DISPATCHER: Starting worker discovery
04:31:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:31 DISPATCHER: Finished worker discovery
04:32:31 DISPATCHER: Starting worker discovery
04:32:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:31 DISPATCHER: Finished worker discovery
04:33:26 WORKER: done with job (4, 0, 20), trying to register it.
04:33:26 WORKER: registered result for job (4, 0, 20) with dispatcher
04:33:26 DISPATCHER: job (4, 0, 20) finished
04:33:26 DISPATCHER: register_result: lock acquired
04:33:26 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:33:26 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6144376515955631, 'info': {'data02': 0.6144376515955631, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 41, 'leak_rate': 0.9600954329112487, 'lr': 0.009367969941311116, 'optimizer': 'SGD', 'sparsity': 0.7944938435264294, 'steps_to_train': 17, 'weight_decay': 0.017302316566837814}"}}
exception: None

04:33:26 job_callback for (4, 0, 20) started
04:33:26 job_callback for (4, 0, 20) got condition
04:33:26 DISPATCHER: Trying to submit another job.
04:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:33:26 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
04:33:26 HBMASTER: Trying to run another job!
04:33:26 job_callback for (4, 0, 20) finished
04:33:26 start sampling a new configuration.
04:33:27 best_vector: [2, 0.9363003466417943, 0.8601161128620214, 0.9880777286907658, 0.21283677056889128, 1, 0.6937909750753791, 0.13341123878740577, 0.5108789421772835], 0.0009623712352838977, 2.3071844476420167, 0.002220367946905045
04:33:27 done sampling a new configuration.
04:33:27 HBMASTER: schedule new run for iteration 5
04:33:27 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
04:33:27 HBMASTER: submitting job (5, 0, 0) to dispatcher
04:33:27 DISPATCHER: trying to submit job (5, 0, 0)
04:33:27 DISPATCHER: trying to notify the job_runner thread.
04:33:27 HBMASTER: job (5, 0, 0) submitted to dispatcher
04:33:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:33:27 DISPATCHER: Trying to submit another job.
04:33:27 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:33:27 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:33:27 WORKER: start processing job (5, 0, 0)
04:33:27 WORKER: args: ()
04:33:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 949, 'last_n_outputs': 45, 'leak_rate': 0.9970194321726915, 'lr': 0.002664854741972471, 'optimizer': 'SGD', 'sparsity': 0.916509834018091, 'steps_to_train': 22, 'weight_decay': 0.046202856628119085}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:33:31 DISPATCHER: Starting worker discovery
04:33:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:31 DISPATCHER: Finished worker discovery
04:34:31 DISPATCHER: Starting worker discovery
04:34:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:31 DISPATCHER: Finished worker discovery
04:35:31 DISPATCHER: Starting worker discovery
04:35:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:31 DISPATCHER: Finished worker discovery
04:35:46 WORKER: done with job (5, 0, 0), trying to register it.
04:35:46 WORKER: registered result for job (5, 0, 0) with dispatcher
04:35:46 DISPATCHER: job (5, 0, 0) finished
04:35:46 DISPATCHER: register_result: lock acquired
04:35:46 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:35:46 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 949, 'last_n_outputs': 45, 'leak_rate': 0.9970194321726915, 'lr': 0.002664854741972471, 'optimizer': 'SGD', 'sparsity': 0.916509834018091, 'steps_to_train': 22, 'weight_decay': 0.046202856628119085}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5825117436321285, 'info': {'data02': 0.5825117436321285, 'config': "{'batch_size': 64, 'hidden_dim': 949, 'last_n_outputs': 45, 'leak_rate': 0.9970194321726915, 'lr': 0.002664854741972471, 'optimizer': 'SGD', 'sparsity': 0.916509834018091, 'steps_to_train': 22, 'weight_decay': 0.046202856628119085}"}}
exception: None

04:35:46 job_callback for (5, 0, 0) started
04:35:46 DISPATCHER: Trying to submit another job.
04:35:46 job_callback for (5, 0, 0) got condition
04:35:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:35:46 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.630722





04:35:46 HBMASTER: Trying to run another job!
04:35:46 job_callback for (5, 0, 0) finished
04:35:46 start sampling a new configuration.
04:35:46 best_vector: [2, 0.27250512311454916, 0.8279852172808032, 0.398120584440226, 0.738392845697024, 1, 0.9112252787846823, 0.36236929453949906, 0.25916704482902636], 0.014977079121435184, 0.6239886125270885, 0.009345526820692765
04:35:46 done sampling a new configuration.
04:35:46 HBMASTER: schedule new run for iteration 5
04:35:46 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
04:35:46 HBMASTER: submitting job (5, 0, 1) to dispatcher
04:35:46 DISPATCHER: trying to submit job (5, 0, 1)
04:35:46 DISPATCHER: trying to notify the job_runner thread.
04:35:46 HBMASTER: job (5, 0, 1) submitted to dispatcher
04:35:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:35:46 DISPATCHER: Trying to submit another job.
04:35:46 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:35:46 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:35:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:35:46 WORKER: start processing job (5, 0, 1)
04:35:46 WORKER: args: ()
04:35:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 43, 'leak_rate': 0.8495301461100565, 'lr': 0.02997682905947882, 'optimizer': 'SGD', 'sparsity': 0.9686940669083237, 'steps_to_train': 42, 'weight_decay': 0.021736223910338925}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:36:31 DISPATCHER: Starting worker discovery
04:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:31 DISPATCHER: Finished worker discovery
04:37:31 DISPATCHER: Starting worker discovery
04:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:31 DISPATCHER: Finished worker discovery
04:38:05 WORKER: done with job (5, 0, 1), trying to register it.
04:38:05 WORKER: registered result for job (5, 0, 1) with dispatcher
04:38:05 DISPATCHER: job (5, 0, 1) finished
04:38:05 DISPATCHER: register_result: lock acquired
04:38:05 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:38:05 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 43, 'leak_rate': 0.8495301461100565, 'lr': 0.02997682905947882, 'optimizer': 'SGD', 'sparsity': 0.9686940669083237, 'steps_to_train': 42, 'weight_decay': 0.021736223910338925}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6282351384013041, 'info': {'data02': 0.6282351384013041, 'config': "{'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 43, 'leak_rate': 0.8495301461100565, 'lr': 0.02997682905947882, 'optimizer': 'SGD', 'sparsity': 0.9686940669083237, 'steps_to_train': 42, 'weight_decay': 0.021736223910338925}"}}
exception: None

04:38:05 job_callback for (5, 0, 1) started
04:38:05 job_callback for (5, 0, 1) got condition
04:38:05 DISPATCHER: Trying to submit another job.
04:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:38:05 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.630722





04:38:05 HBMASTER: Trying to run another job!
04:38:05 job_callback for (5, 0, 1) finished
04:38:05 start sampling a new configuration.
04:38:05 done sampling a new configuration.
04:38:05 HBMASTER: schedule new run for iteration 5
04:38:05 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
04:38:05 HBMASTER: submitting job (5, 0, 2) to dispatcher
04:38:05 DISPATCHER: trying to submit job (5, 0, 2)
04:38:05 DISPATCHER: trying to notify the job_runner thread.
04:38:05 HBMASTER: job (5, 0, 2) submitted to dispatcher
04:38:05 DISPATCHER: Trying to submit another job.
04:38:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:38:05 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:38:05 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:38:05 WORKER: start processing job (5, 0, 2)
04:38:05 WORKER: args: ()
04:38:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 854, 'last_n_outputs': 12, 'leak_rate': 0.7900803787414167, 'lr': 0.0376789381568327, 'optimizer': 'SGD', 'sparsity': 0.8432751705648973, 'steps_to_train': 46, 'weight_decay': 0.010046963902803099}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:38:31 DISPATCHER: Starting worker discovery
04:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:31 DISPATCHER: Finished worker discovery
04:39:31 DISPATCHER: Starting worker discovery
04:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:31 DISPATCHER: Finished worker discovery
04:40:24 WORKER: done with job (5, 0, 2), trying to register it.
04:40:24 WORKER: registered result for job (5, 0, 2) with dispatcher
04:40:24 DISPATCHER: job (5, 0, 2) finished
04:40:24 DISPATCHER: register_result: lock acquired
04:40:24 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:40:24 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 854, 'last_n_outputs': 12, 'leak_rate': 0.7900803787414167, 'lr': 0.0376789381568327, 'optimizer': 'SGD', 'sparsity': 0.8432751705648973, 'steps_to_train': 46, 'weight_decay': 0.010046963902803099}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49177043486480576, 'info': {'data02': 0.49177043486480576, 'config': "{'batch_size': 16, 'hidden_dim': 854, 'last_n_outputs': 12, 'leak_rate': 0.7900803787414167, 'lr': 0.0376789381568327, 'optimizer': 'SGD', 'sparsity': 0.8432751705648973, 'steps_to_train': 46, 'weight_decay': 0.010046963902803099}"}}
exception: None

04:40:24 job_callback for (5, 0, 2) started
04:40:24 DISPATCHER: Trying to submit another job.
04:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:40:24 job_callback for (5, 0, 2) got condition
04:40:24 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.630722





04:40:24 HBMASTER: Trying to run another job!
04:40:24 job_callback for (5, 0, 2) finished
04:40:24 start sampling a new configuration.
04:40:24 best_vector: [1, 0.09857698031761025, 0.6988198855377787, 0.23695228723803363, 0.8954747746645132, 1, 0.8327301201283106, 0.2545851031607544, 0.03652242620596341], 0.002623068117911161, 0.042552274337274806, 0.00011161751415871482
04:40:24 done sampling a new configuration.
04:40:24 HBMASTER: schedule new run for iteration 5
04:40:24 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
04:40:24 HBMASTER: submitting job (5, 0, 3) to dispatcher
04:40:24 DISPATCHER: trying to submit job (5, 0, 3)
04:40:24 DISPATCHER: trying to notify the job_runner thread.
04:40:24 HBMASTER: job (5, 0, 3) submitted to dispatcher
04:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:40:24 DISPATCHER: Trying to submit another job.
04:40:24 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:40:24 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:40:24 WORKER: start processing job (5, 0, 3)
04:40:24 WORKER: args: ()
04:40:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 278, 'last_n_outputs': 38, 'leak_rate': 0.8092380718095085, 'lr': 0.06179446112200112, 'optimizer': 'SGD', 'sparsity': 0.9498552288307945, 'steps_to_train': 33, 'weight_decay': 0.011156212346691542}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:40:31 DISPATCHER: Starting worker discovery
04:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:31 DISPATCHER: Finished worker discovery
04:41:31 DISPATCHER: Starting worker discovery
04:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:31 DISPATCHER: Finished worker discovery
04:42:31 DISPATCHER: Starting worker discovery
04:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:31 DISPATCHER: Finished worker discovery
04:42:42 WORKER: done with job (5, 0, 3), trying to register it.
04:42:42 WORKER: registered result for job (5, 0, 3) with dispatcher
04:42:42 DISPATCHER: job (5, 0, 3) finished
04:42:42 DISPATCHER: register_result: lock acquired
04:42:42 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:42:42 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 278, 'last_n_outputs': 38, 'leak_rate': 0.8092380718095085, 'lr': 0.06179446112200112, 'optimizer': 'SGD', 'sparsity': 0.9498552288307945, 'steps_to_train': 33, 'weight_decay': 0.011156212346691542}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5759877331643628, 'info': {'data02': 0.5759877331643628, 'config': "{'batch_size': 32, 'hidden_dim': 278, 'last_n_outputs': 38, 'leak_rate': 0.8092380718095085, 'lr': 0.06179446112200112, 'optimizer': 'SGD', 'sparsity': 0.9498552288307945, 'steps_to_train': 33, 'weight_decay': 0.011156212346691542}"}}
exception: None

04:42:42 job_callback for (5, 0, 3) started
04:42:42 DISPATCHER: Trying to submit another job.
04:42:42 job_callback for (5, 0, 3) got condition
04:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:42:42 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.630722





04:42:42 HBMASTER: Trying to run another job!
04:42:42 job_callback for (5, 0, 3) finished
04:42:42 start sampling a new configuration.
04:42:42 done sampling a new configuration.
04:42:42 HBMASTER: schedule new run for iteration 5
04:42:42 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
04:42:42 HBMASTER: submitting job (5, 0, 4) to dispatcher
04:42:42 DISPATCHER: trying to submit job (5, 0, 4)
04:42:42 DISPATCHER: trying to notify the job_runner thread.
04:42:42 HBMASTER: job (5, 0, 4) submitted to dispatcher
04:42:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:42:42 DISPATCHER: Trying to submit another job.
04:42:42 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:42:42 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:42:42 WORKER: start processing job (5, 0, 4)
04:42:42 WORKER: args: ()
04:42:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 688, 'last_n_outputs': 13, 'leak_rate': 0.9151061030483446, 'lr': 0.012928150394224671, 'optimizer': 'Adam', 'sparsity': 0.8731676833960339, 'steps_to_train': 45, 'weight_decay': 0.03267898357658019}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:43:31 DISPATCHER: Starting worker discovery
04:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:31 DISPATCHER: Finished worker discovery
04:44:31 DISPATCHER: Starting worker discovery
04:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:31 DISPATCHER: Finished worker discovery
04:45:02 WORKER: done with job (5, 0, 4), trying to register it.
04:45:02 WORKER: registered result for job (5, 0, 4) with dispatcher
04:45:02 DISPATCHER: job (5, 0, 4) finished
04:45:02 DISPATCHER: register_result: lock acquired
04:45:02 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:45:02 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 688, 'last_n_outputs': 13, 'leak_rate': 0.9151061030483446, 'lr': 0.012928150394224671, 'optimizer': 'Adam', 'sparsity': 0.8731676833960339, 'steps_to_train': 45, 'weight_decay': 0.03267898357658019}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.24477931657114887, 'info': {'data02': 0.24477931657114887, 'config': "{'batch_size': 32, 'hidden_dim': 688, 'last_n_outputs': 13, 'leak_rate': 0.9151061030483446, 'lr': 0.012928150394224671, 'optimizer': 'Adam', 'sparsity': 0.8731676833960339, 'steps_to_train': 45, 'weight_decay': 0.03267898357658019}"}}
exception: None

04:45:02 job_callback for (5, 0, 4) started
04:45:02 job_callback for (5, 0, 4) got condition
04:45:02 DISPATCHER: Trying to submit another job.
04:45:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:02 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.630722





04:45:02 HBMASTER: Trying to run another job!
04:45:02 job_callback for (5, 0, 4) finished
04:45:02 start sampling a new configuration.
04:45:02 done sampling a new configuration.
04:45:02 HBMASTER: schedule new run for iteration 5
04:45:02 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
04:45:02 HBMASTER: submitting job (5, 0, 5) to dispatcher
04:45:02 DISPATCHER: trying to submit job (5, 0, 5)
04:45:02 DISPATCHER: trying to notify the job_runner thread.
04:45:02 HBMASTER: job (5, 0, 5) submitted to dispatcher
04:45:02 DISPATCHER: Trying to submit another job.
04:45:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:02 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:45:02 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:45:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:02 WORKER: start processing job (5, 0, 5)
04:45:02 WORKER: args: ()
04:45:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 780, 'last_n_outputs': 50, 'leak_rate': 0.7755156648974553, 'lr': 0.049985032085167275, 'optimizer': 'SGD', 'sparsity': 0.9243561968250031, 'steps_to_train': 65, 'weight_decay': 0.19974067528576317}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:45:31 DISPATCHER: Starting worker discovery
04:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:31 DISPATCHER: Finished worker discovery
04:46:31 DISPATCHER: Starting worker discovery
04:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:31 DISPATCHER: Finished worker discovery
04:47:22 WORKER: done with job (5, 0, 5), trying to register it.
04:47:22 WORKER: registered result for job (5, 0, 5) with dispatcher
04:47:22 DISPATCHER: job (5, 0, 5) finished
04:47:22 DISPATCHER: register_result: lock acquired
04:47:22 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:47:22 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 780, 'last_n_outputs': 50, 'leak_rate': 0.7755156648974553, 'lr': 0.049985032085167275, 'optimizer': 'SGD', 'sparsity': 0.9243561968250031, 'steps_to_train': 65, 'weight_decay': 0.19974067528576317}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.28040424985775214, 'info': {'data02': 0.28040424985775214, 'config': "{'batch_size': 64, 'hidden_dim': 780, 'last_n_outputs': 50, 'leak_rate': 0.7755156648974553, 'lr': 0.049985032085167275, 'optimizer': 'SGD', 'sparsity': 0.9243561968250031, 'steps_to_train': 65, 'weight_decay': 0.19974067528576317}"}}
exception: None

04:47:22 job_callback for (5, 0, 5) started
04:47:22 job_callback for (5, 0, 5) got condition
04:47:22 DISPATCHER: Trying to submit another job.
04:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:47:22 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.630722





04:47:22 HBMASTER: Trying to run another job!
04:47:22 job_callback for (5, 0, 5) finished
04:47:22 start sampling a new configuration.
04:47:22 best_vector: [1, 0.8082556421678041, 0.8850093608509865, 0.6676517457729558, 0.641887594533485, 1, 0.9724220385617355, 0.232621287389643, 0.10135513923972296], 0.0013530470069555013, 4.2394004906091975, 0.005736108145104458
04:47:22 done sampling a new configuration.
04:47:22 HBMASTER: schedule new run for iteration 5
04:47:22 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
04:47:22 HBMASTER: submitting job (5, 0, 6) to dispatcher
04:47:22 DISPATCHER: trying to submit job (5, 0, 6)
04:47:22 DISPATCHER: trying to notify the job_runner thread.
04:47:22 HBMASTER: job (5, 0, 6) submitted to dispatcher
04:47:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:47:22 DISPATCHER: Trying to submit another job.
04:47:22 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:47:22 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:47:22 WORKER: start processing job (5, 0, 6)
04:47:22 WORKER: args: ()
04:47:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:47:31 DISPATCHER: Starting worker discovery
04:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:31 DISPATCHER: Finished worker discovery
04:48:31 DISPATCHER: Starting worker discovery
04:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:31 DISPATCHER: Finished worker discovery
04:49:31 DISPATCHER: Starting worker discovery
04:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:31 DISPATCHER: Finished worker discovery
04:49:40 WORKER: done with job (5, 0, 6), trying to register it.
04:49:40 WORKER: registered result for job (5, 0, 6) with dispatcher
04:49:40 DISPATCHER: job (5, 0, 6) finished
04:49:40 DISPATCHER: register_result: lock acquired
04:49:40 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:49:40 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5896797088831922, 'info': {'data02': 0.5896797088831922, 'config': "{'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}"}}
exception: None

04:49:40 job_callback for (5, 0, 6) started
04:49:40 job_callback for (5, 0, 6) got condition
04:49:40 DISPATCHER: Trying to submit another job.
04:49:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:49:40 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.630722





04:49:40 HBMASTER: Trying to run another job!
04:49:40 job_callback for (5, 0, 6) finished
04:49:40 start sampling a new configuration.
04:49:40 best_vector: [0, 0.9711997572120206, 0.9072084363471262, 0.9821349467320314, 0.3625756629915993, 1, 0.6484443282693306, 0.6462423862859052, 0.13947433632595535], 0.004989264485546469, 3.03479629619865, 0.015141401381491887
04:49:40 done sampling a new configuration.
04:49:40 HBMASTER: schedule new run for iteration 5
04:49:40 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
04:49:40 HBMASTER: submitting job (5, 0, 7) to dispatcher
04:49:40 DISPATCHER: trying to submit job (5, 0, 7)
04:49:40 DISPATCHER: trying to notify the job_runner thread.
04:49:40 HBMASTER: job (5, 0, 7) submitted to dispatcher
04:49:40 DISPATCHER: Trying to submit another job.
04:49:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:49:40 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:49:40 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:49:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:49:40 WORKER: start processing job (5, 0, 7)
04:49:40 WORKER: args: ()
04:49:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 977, 'last_n_outputs': 47, 'leak_rate': 0.9955337366830078, 'lr': 0.005310694583440953, 'optimizer': 'SGD', 'sparsity': 0.9056266387846393, 'steps_to_train': 68, 'weight_decay': 0.01518659094229874}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:50:31 DISPATCHER: Starting worker discovery
04:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:31 DISPATCHER: Finished worker discovery
04:51:31 DISPATCHER: Starting worker discovery
04:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:31 DISPATCHER: Finished worker discovery
04:51:58 WORKER: done with job (5, 0, 7), trying to register it.
04:51:58 WORKER: registered result for job (5, 0, 7) with dispatcher
04:51:58 DISPATCHER: job (5, 0, 7) finished
04:51:58 DISPATCHER: register_result: lock acquired
04:51:58 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:51:58 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 977, 'last_n_outputs': 47, 'leak_rate': 0.9955337366830078, 'lr': 0.005310694583440953, 'optimizer': 'SGD', 'sparsity': 0.9056266387846393, 'steps_to_train': 68, 'weight_decay': 0.01518659094229874}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5874708449888794, 'info': {'data02': 0.5874708449888794, 'config': "{'batch_size': 16, 'hidden_dim': 977, 'last_n_outputs': 47, 'leak_rate': 0.9955337366830078, 'lr': 0.005310694583440953, 'optimizer': 'SGD', 'sparsity': 0.9056266387846393, 'steps_to_train': 68, 'weight_decay': 0.01518659094229874}"}}
exception: None

04:51:58 job_callback for (5, 0, 7) started
04:51:58 job_callback for (5, 0, 7) got condition
04:51:58 DISPATCHER: Trying to submit another job.
04:51:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:51:58 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.630722





04:51:58 HBMASTER: Trying to run another job!
04:51:58 job_callback for (5, 0, 7) finished
04:51:58 start sampling a new configuration.
04:51:58 done sampling a new configuration.
04:51:58 HBMASTER: schedule new run for iteration 5
04:51:58 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
04:51:58 HBMASTER: submitting job (5, 0, 8) to dispatcher
04:51:58 DISPATCHER: trying to submit job (5, 0, 8)
04:51:58 DISPATCHER: trying to notify the job_runner thread.
04:51:58 HBMASTER: job (5, 0, 8) submitted to dispatcher
04:51:58 DISPATCHER: Trying to submit another job.
04:51:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:51:58 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:51:58 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:51:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:51:58 WORKER: start processing job (5, 0, 8)
04:51:58 WORKER: args: ()
04:51:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 772, 'last_n_outputs': 29, 'leak_rate': 0.8061678533257788, 'lr': 0.002404223847715588, 'optimizer': 'SGD', 'sparsity': 0.8525578121602739, 'steps_to_train': 14, 'weight_decay': 0.07350345446470226}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:52:31 DISPATCHER: Starting worker discovery
04:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:31 DISPATCHER: Finished worker discovery
04:53:31 DISPATCHER: Starting worker discovery
04:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:31 DISPATCHER: Finished worker discovery
04:54:17 WORKER: done with job (5, 0, 8), trying to register it.
04:54:17 WORKER: registered result for job (5, 0, 8) with dispatcher
04:54:17 DISPATCHER: job (5, 0, 8) finished
04:54:17 DISPATCHER: register_result: lock acquired
04:54:17 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:54:17 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 772, 'last_n_outputs': 29, 'leak_rate': 0.8061678533257788, 'lr': 0.002404223847715588, 'optimizer': 'SGD', 'sparsity': 0.8525578121602739, 'steps_to_train': 14, 'weight_decay': 0.07350345446470226}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5701753532935716, 'info': {'data02': 0.5701753532935716, 'config': "{'batch_size': 128, 'hidden_dim': 772, 'last_n_outputs': 29, 'leak_rate': 0.8061678533257788, 'lr': 0.002404223847715588, 'optimizer': 'SGD', 'sparsity': 0.8525578121602739, 'steps_to_train': 14, 'weight_decay': 0.07350345446470226}"}}
exception: None

04:54:17 job_callback for (5, 0, 8) started
04:54:17 DISPATCHER: Trying to submit another job.
04:54:17 job_callback for (5, 0, 8) got condition
04:54:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:54:17 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.630722





04:54:17 HBMASTER: Trying to run another job!
04:54:17 job_callback for (5, 0, 8) finished
04:54:17 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
04:54:17 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
04:54:17 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
04:54:17 HBMASTER: schedule new run for iteration 5
04:54:17 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
04:54:17 HBMASTER: submitting job (5, 0, 1) to dispatcher
04:54:17 DISPATCHER: trying to submit job (5, 0, 1)
04:54:17 DISPATCHER: trying to notify the job_runner thread.
04:54:17 HBMASTER: job (5, 0, 1) submitted to dispatcher
04:54:17 DISPATCHER: Trying to submit another job.
04:54:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:54:17 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:54:17 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:54:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:54:17 WORKER: start processing job (5, 0, 1)
04:54:17 WORKER: args: ()
04:54:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 43, 'leak_rate': 0.8495301461100565, 'lr': 0.02997682905947882, 'optimizer': 'SGD', 'sparsity': 0.9686940669083237, 'steps_to_train': 42, 'weight_decay': 0.021736223910338925}, 'budget': 400.0, 'working_directory': '.'}
04:54:31 DISPATCHER: Starting worker discovery
04:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:31 DISPATCHER: Finished worker discovery
04:55:31 DISPATCHER: Starting worker discovery
04:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:31 DISPATCHER: Finished worker discovery
04:56:31 DISPATCHER: Starting worker discovery
04:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:31 DISPATCHER: Finished worker discovery
04:57:31 DISPATCHER: Starting worker discovery
04:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:31 DISPATCHER: Finished worker discovery
04:58:31 DISPATCHER: Starting worker discovery
04:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:31 DISPATCHER: Finished worker discovery
04:59:31 DISPATCHER: Starting worker discovery
04:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:31 DISPATCHER: Finished worker discovery
05:00:31 DISPATCHER: Starting worker discovery
05:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:31 DISPATCHER: Finished worker discovery
05:01:02 WORKER: done with job (5, 0, 1), trying to register it.
05:01:02 WORKER: registered result for job (5, 0, 1) with dispatcher
05:01:02 DISPATCHER: job (5, 0, 1) finished
05:01:02 DISPATCHER: register_result: lock acquired
05:01:02 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:01:02 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 43, 'leak_rate': 0.8495301461100565, 'lr': 0.02997682905947882, 'optimizer': 'SGD', 'sparsity': 0.9686940669083237, 'steps_to_train': 42, 'weight_decay': 0.021736223910338925}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.572445732111464, 'info': {'data02': 0.572445732111464, 'config': "{'batch_size': 64, 'hidden_dim': 418, 'last_n_outputs': 43, 'leak_rate': 0.8495301461100565, 'lr': 0.02997682905947882, 'optimizer': 'SGD', 'sparsity': 0.9686940669083237, 'steps_to_train': 42, 'weight_decay': 0.021736223910338925}"}}
exception: None

05:01:02 job_callback for (5, 0, 1) started
05:01:02 job_callback for (5, 0, 1) got condition
05:01:02 DISPATCHER: Trying to submit another job.
05:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:01:02 HBMASTER: Trying to run another job!
05:01:02 job_callback for (5, 0, 1) finished
05:01:02 HBMASTER: schedule new run for iteration 5
05:01:02 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:01:02 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:01:02 DISPATCHER: trying to submit job (5, 0, 6)
05:01:02 DISPATCHER: trying to notify the job_runner thread.
05:01:02 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:01:02 DISPATCHER: Trying to submit another job.
05:01:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:01:02 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:01:02 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:01:02 WORKER: start processing job (5, 0, 6)
05:01:02 WORKER: args: ()
05:01:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}, 'budget': 400.0, 'working_directory': '.'}
05:01:31 DISPATCHER: Starting worker discovery
05:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:31 DISPATCHER: Finished worker discovery
05:02:31 DISPATCHER: Starting worker discovery
05:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:31 DISPATCHER: Finished worker discovery
05:03:31 DISPATCHER: Starting worker discovery
05:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:31 DISPATCHER: Finished worker discovery
05:04:31 DISPATCHER: Starting worker discovery
05:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:31 DISPATCHER: Finished worker discovery
05:05:31 DISPATCHER: Starting worker discovery
05:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:31 DISPATCHER: Finished worker discovery
05:06:31 DISPATCHER: Starting worker discovery
05:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:31 DISPATCHER: Finished worker discovery
05:07:31 DISPATCHER: Starting worker discovery
05:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:31 DISPATCHER: Finished worker discovery
05:07:48 WORKER: done with job (5, 0, 6), trying to register it.
05:07:48 WORKER: registered result for job (5, 0, 6) with dispatcher
05:07:48 DISPATCHER: job (5, 0, 6) finished
05:07:48 DISPATCHER: register_result: lock acquired
05:07:48 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:07:48 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5982719834743283, 'info': {'data02': 0.5982719834743283, 'config': "{'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}"}}
exception: None

05:07:48 job_callback for (5, 0, 6) started
05:07:48 DISPATCHER: Trying to submit another job.
05:07:48 job_callback for (5, 0, 6) got condition
05:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:07:48 HBMASTER: Trying to run another job!
05:07:48 job_callback for (5, 0, 6) finished
05:07:48 HBMASTER: schedule new run for iteration 5
05:07:48 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
05:07:48 HBMASTER: submitting job (5, 0, 7) to dispatcher
05:07:48 DISPATCHER: trying to submit job (5, 0, 7)
05:07:48 DISPATCHER: trying to notify the job_runner thread.
05:07:48 HBMASTER: job (5, 0, 7) submitted to dispatcher
05:07:48 DISPATCHER: Trying to submit another job.
05:07:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:07:48 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:07:48 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:07:48 WORKER: start processing job (5, 0, 7)
05:07:48 WORKER: args: ()
05:07:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 977, 'last_n_outputs': 47, 'leak_rate': 0.9955337366830078, 'lr': 0.005310694583440953, 'optimizer': 'SGD', 'sparsity': 0.9056266387846393, 'steps_to_train': 68, 'weight_decay': 0.01518659094229874}, 'budget': 400.0, 'working_directory': '.'}
05:08:31 DISPATCHER: Starting worker discovery
05:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:31 DISPATCHER: Finished worker discovery
05:09:31 DISPATCHER: Starting worker discovery
05:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:31 DISPATCHER: Finished worker discovery
05:10:31 DISPATCHER: Starting worker discovery
05:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:31 DISPATCHER: Finished worker discovery
05:11:31 DISPATCHER: Starting worker discovery
05:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:31 DISPATCHER: Finished worker discovery
05:12:31 DISPATCHER: Starting worker discovery
05:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:31 DISPATCHER: Finished worker discovery
05:13:31 DISPATCHER: Starting worker discovery
05:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:31 DISPATCHER: Finished worker discovery
05:14:31 DISPATCHER: Starting worker discovery
05:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:31 DISPATCHER: Finished worker discovery
05:14:33 WORKER: done with job (5, 0, 7), trying to register it.
05:14:33 WORKER: registered result for job (5, 0, 7) with dispatcher
05:14:33 DISPATCHER: job (5, 0, 7) finished
05:14:33 DISPATCHER: register_result: lock acquired
05:14:33 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:14:33 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 977, 'last_n_outputs': 47, 'leak_rate': 0.9955337366830078, 'lr': 0.005310694583440953, 'optimizer': 'SGD', 'sparsity': 0.9056266387846393, 'steps_to_train': 68, 'weight_decay': 0.01518659094229874}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5753973370727589, 'info': {'data02': 0.5753973370727589, 'config': "{'batch_size': 16, 'hidden_dim': 977, 'last_n_outputs': 47, 'leak_rate': 0.9955337366830078, 'lr': 0.005310694583440953, 'optimizer': 'SGD', 'sparsity': 0.9056266387846393, 'steps_to_train': 68, 'weight_decay': 0.01518659094229874}"}}
exception: None

05:14:33 job_callback for (5, 0, 7) started
05:14:33 DISPATCHER: Trying to submit another job.
05:14:33 job_callback for (5, 0, 7) got condition
05:14:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:14:33 HBMASTER: Trying to run another job!
05:14:33 job_callback for (5, 0, 7) finished
05:14:33 ITERATION: Advancing config (5, 0, 6) to next budget 1200.000000
05:14:33 HBMASTER: schedule new run for iteration 5
05:14:33 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:14:33 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:14:33 DISPATCHER: trying to submit job (5, 0, 6)
05:14:33 DISPATCHER: trying to notify the job_runner thread.
05:14:33 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:14:33 DISPATCHER: Trying to submit another job.
05:14:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:14:33 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:14:33 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:14:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:14:33 WORKER: start processing job (5, 0, 6)
05:14:33 WORKER: args: ()
05:14:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}, 'budget': 1200.0, 'working_directory': '.'}
05:15:31 DISPATCHER: Starting worker discovery
05:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:31 DISPATCHER: Finished worker discovery
05:16:31 DISPATCHER: Starting worker discovery
05:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:31 DISPATCHER: Finished worker discovery
05:17:31 DISPATCHER: Starting worker discovery
05:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:31 DISPATCHER: Finished worker discovery
05:18:31 DISPATCHER: Starting worker discovery
05:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:31 DISPATCHER: Finished worker discovery
05:19:31 DISPATCHER: Starting worker discovery
05:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:31 DISPATCHER: Finished worker discovery
05:20:31 DISPATCHER: Starting worker discovery
05:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:31 DISPATCHER: Finished worker discovery
05:21:31 DISPATCHER: Starting worker discovery
05:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:31 DISPATCHER: Finished worker discovery
05:22:31 DISPATCHER: Starting worker discovery
05:22:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:31 DISPATCHER: Finished worker discovery
05:23:31 DISPATCHER: Starting worker discovery
05:23:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:31 DISPATCHER: Finished worker discovery
05:24:31 DISPATCHER: Starting worker discovery
05:24:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:31 DISPATCHER: Finished worker discovery
05:25:31 DISPATCHER: Starting worker discovery
05:25:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:31 DISPATCHER: Finished worker discovery
05:26:31 DISPATCHER: Starting worker discovery
05:26:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:31 DISPATCHER: Finished worker discovery
05:27:31 DISPATCHER: Starting worker discovery
05:27:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:31 DISPATCHER: Finished worker discovery
05:28:31 DISPATCHER: Starting worker discovery
05:28:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:31 DISPATCHER: Finished worker discovery
05:29:31 DISPATCHER: Starting worker discovery
05:29:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:31 DISPATCHER: Finished worker discovery
05:30:31 DISPATCHER: Starting worker discovery
05:30:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:31 DISPATCHER: Finished worker discovery
05:31:31 DISPATCHER: Starting worker discovery
05:31:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:31 DISPATCHER: Finished worker discovery
05:32:31 DISPATCHER: Starting worker discovery
05:32:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:31 DISPATCHER: Finished worker discovery
05:33:31 DISPATCHER: Starting worker discovery
05:33:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:31 DISPATCHER: Finished worker discovery
05:34:31 DISPATCHER: Starting worker discovery
05:34:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:31 DISPATCHER: Finished worker discovery
05:34:41 WORKER: done with job (5, 0, 6), trying to register it.
05:34:41 WORKER: registered result for job (5, 0, 6) with dispatcher
05:34:41 DISPATCHER: job (5, 0, 6) finished
05:34:41 DISPATCHER: register_result: lock acquired
05:34:41 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:34:41 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5647314307160773, 'info': {'data02': 0.5647314307160773, 'config': "{'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 46, 'leak_rate': 0.9169129364432389, 'lr': 0.01922096505195257, 'optimizer': 'SGD', 'sparsity': 0.9833812892548165, 'steps_to_train': 31, 'weight_decay': 0.013547715762548155}"}}
exception: None

05:34:41 job_callback for (5, 0, 6) started
05:34:41 job_callback for (5, 0, 6) got condition
05:34:41 DISPATCHER: Trying to submit another job.
05:34:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:34:41 HBMASTER: Trying to run another job!
05:34:41 job_callback for (5, 0, 6) finished
05:34:41 start sampling a new configuration.
05:34:41 best_vector: [1, 0.3555470344768312, 0.8727730073342219, 0.6886601469584832, 0.19446304022887084, 1, 0.8358643370131482, 0.6934633140389047, 0.8776291813665452], 0.00466197774504884, 1.451192952222086, 0.006765429247031089
05:34:41 done sampling a new configuration.
05:34:41 HBMASTER: schedule new run for iteration 6
05:34:41 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
05:34:41 HBMASTER: submitting job (6, 0, 0) to dispatcher
05:34:41 DISPATCHER: trying to submit job (6, 0, 0)
05:34:41 DISPATCHER: trying to notify the job_runner thread.
05:34:41 HBMASTER: job (6, 0, 0) submitted to dispatcher
05:34:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:34:41 DISPATCHER: Trying to submit another job.
05:34:41 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:34:41 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:34:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:34:41 WORKER: start processing job (6, 0, 0)
05:34:41 WORKER: args: ()
05:34:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.9221650367396208, 'lr': 0.002448646431971015, 'optimizer': 'SGD', 'sparsity': 0.9506074408831555, 'steps_to_train': 73, 'weight_decay': 0.13861872183755103}, 'budget': 400.0, 'working_directory': '.'}
05:35:31 DISPATCHER: Starting worker discovery
05:35:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:31 DISPATCHER: Finished worker discovery
05:36:31 DISPATCHER: Starting worker discovery
05:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:31 DISPATCHER: Finished worker discovery
05:37:31 DISPATCHER: Starting worker discovery
05:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:31 DISPATCHER: Finished worker discovery
05:38:31 DISPATCHER: Starting worker discovery
05:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:31 DISPATCHER: Finished worker discovery
05:39:31 DISPATCHER: Starting worker discovery
05:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:31 DISPATCHER: Finished worker discovery
05:40:31 DISPATCHER: Starting worker discovery
05:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:31 DISPATCHER: Finished worker discovery
05:41:28 WORKER: done with job (6, 0, 0), trying to register it.
05:41:28 WORKER: registered result for job (6, 0, 0) with dispatcher
05:41:28 DISPATCHER: job (6, 0, 0) finished
05:41:28 DISPATCHER: register_result: lock acquired
05:41:28 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:41:28 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.9221650367396208, 'lr': 0.002448646431971015, 'optimizer': 'SGD', 'sparsity': 0.9506074408831555, 'steps_to_train': 73, 'weight_decay': 0.13861872183755103}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5841931502197149, 'info': {'data02': 0.5841931502197149, 'config': "{'batch_size': 32, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.9221650367396208, 'lr': 0.002448646431971015, 'optimizer': 'SGD', 'sparsity': 0.9506074408831555, 'steps_to_train': 73, 'weight_decay': 0.13861872183755103}"}}
exception: None

05:41:28 job_callback for (6, 0, 0) started
05:41:28 DISPATCHER: Trying to submit another job.
05:41:28 job_callback for (6, 0, 0) got condition
05:41:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:41:28 HBMASTER: Trying to run another job!
05:41:28 job_callback for (6, 0, 0) finished
05:41:28 start sampling a new configuration.
05:41:28 best_vector: [1, 0.8699974787544948, 0.83918181724234, 0.9298279992266111, 0.11144742943613017, 1, 0.9321830682414414, 0.09188683571576328, 0.17883069333673923], 0.01075297500781207, 5.03794527724837, 0.054172899656976574
05:41:28 done sampling a new configuration.
05:41:28 HBMASTER: schedule new run for iteration 6
05:41:28 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
05:41:28 HBMASTER: submitting job (6, 0, 1) to dispatcher
05:41:28 DISPATCHER: trying to submit job (6, 0, 1)
05:41:28 DISPATCHER: trying to notify the job_runner thread.
05:41:28 HBMASTER: job (6, 0, 1) submitted to dispatcher
05:41:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:41:28 DISPATCHER: Trying to submit another job.
05:41:28 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:41:28 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:41:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:41:28 WORKER: start processing job (6, 0, 1)
05:41:28 WORKER: args: ()
05:41:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 896, 'last_n_outputs': 44, 'leak_rate': 0.9824569998066528, 'lr': 0.0016706860982678624, 'optimizer': 'SGD', 'sparsity': 0.973723936377946, 'steps_to_train': 18, 'weight_decay': 0.017086932199923507}, 'budget': 400.0, 'working_directory': '.'}
05:41:31 DISPATCHER: Starting worker discovery
05:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:31 DISPATCHER: Finished worker discovery
05:42:31 DISPATCHER: Starting worker discovery
05:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:31 DISPATCHER: Finished worker discovery
05:43:31 DISPATCHER: Starting worker discovery
05:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:31 DISPATCHER: Finished worker discovery
05:44:31 DISPATCHER: Starting worker discovery
05:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:31 DISPATCHER: Finished worker discovery
05:45:31 DISPATCHER: Starting worker discovery
05:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:31 DISPATCHER: Finished worker discovery
05:46:31 DISPATCHER: Starting worker discovery
05:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:31 DISPATCHER: Finished worker discovery
05:47:31 DISPATCHER: Starting worker discovery
05:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:31 DISPATCHER: Finished worker discovery
05:48:15 WORKER: done with job (6, 0, 1), trying to register it.
05:48:15 WORKER: registered result for job (6, 0, 1) with dispatcher
05:48:15 DISPATCHER: job (6, 0, 1) finished
05:48:15 DISPATCHER: register_result: lock acquired
05:48:15 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:48:15 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 896, 'last_n_outputs': 44, 'leak_rate': 0.9824569998066528, 'lr': 0.0016706860982678624, 'optimizer': 'SGD', 'sparsity': 0.973723936377946, 'steps_to_train': 18, 'weight_decay': 0.017086932199923507}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5634176206739114, 'info': {'data02': 0.5634176206739114, 'config': "{'batch_size': 32, 'hidden_dim': 896, 'last_n_outputs': 44, 'leak_rate': 0.9824569998066528, 'lr': 0.0016706860982678624, 'optimizer': 'SGD', 'sparsity': 0.973723936377946, 'steps_to_train': 18, 'weight_decay': 0.017086932199923507}"}}
exception: None

05:48:15 job_callback for (6, 0, 1) started
05:48:15 DISPATCHER: Trying to submit another job.
05:48:15 job_callback for (6, 0, 1) got condition
05:48:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:48:15 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.604684





05:48:15 HBMASTER: Trying to run another job!
05:48:15 job_callback for (6, 0, 1) finished
05:48:15 start sampling a new configuration.
05:48:15 best_vector: [0, 0.6916116371820346, 0.779426921339248, 0.8455463139241363, 0.6389229411569568, 1, 0.15732494506374803, 0.42454603253352313, 0.9920031695004141], 0.006293688461203077, 0.2146713969935123, 0.0013510748942084131
05:48:15 done sampling a new configuration.
05:48:15 HBMASTER: schedule new run for iteration 6
05:48:15 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
05:48:15 HBMASTER: submitting job (6, 0, 2) to dispatcher
05:48:15 DISPATCHER: trying to submit job (6, 0, 2)
05:48:15 DISPATCHER: trying to notify the job_runner thread.
05:48:15 HBMASTER: job (6, 0, 2) submitted to dispatcher
05:48:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:48:15 DISPATCHER: Trying to submit another job.
05:48:15 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:48:15 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:48:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:48:15 WORKER: start processing job (6, 0, 2)
05:48:15 WORKER: args: ()
05:48:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 41, 'leak_rate': 0.961386578481034, 'lr': 0.018960329583273587, 'optimizer': 'SGD', 'sparsity': 0.7877579868152995, 'steps_to_train': 48, 'weight_decay': 0.19526566253165292}, 'budget': 400.0, 'working_directory': '.'}
05:48:31 DISPATCHER: Starting worker discovery
05:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:31 DISPATCHER: Finished worker discovery
05:49:31 DISPATCHER: Starting worker discovery
05:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:31 DISPATCHER: Finished worker discovery
05:50:31 DISPATCHER: Starting worker discovery
05:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:31 DISPATCHER: Finished worker discovery
05:51:31 DISPATCHER: Starting worker discovery
05:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:31 DISPATCHER: Finished worker discovery
05:52:31 DISPATCHER: Starting worker discovery
05:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:31 DISPATCHER: Finished worker discovery
05:53:31 DISPATCHER: Starting worker discovery
05:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:31 DISPATCHER: Finished worker discovery
05:54:31 DISPATCHER: Starting worker discovery
05:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:31 DISPATCHER: Finished worker discovery
05:55:01 WORKER: done with job (6, 0, 2), trying to register it.
05:55:01 WORKER: registered result for job (6, 0, 2) with dispatcher
05:55:01 DISPATCHER: job (6, 0, 2) finished
05:55:01 DISPATCHER: register_result: lock acquired
05:55:01 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:55:01 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 41, 'leak_rate': 0.961386578481034, 'lr': 0.018960329583273587, 'optimizer': 'SGD', 'sparsity': 0.7877579868152995, 'steps_to_train': 48, 'weight_decay': 0.19526566253165292}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3212055261801478, 'info': {'data02': 0.3212055261801478, 'config': "{'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 41, 'leak_rate': 0.961386578481034, 'lr': 0.018960329583273587, 'optimizer': 'SGD', 'sparsity': 0.7877579868152995, 'steps_to_train': 48, 'weight_decay': 0.19526566253165292}"}}
exception: None

05:55:01 job_callback for (6, 0, 2) started
05:55:01 DISPATCHER: Trying to submit another job.
05:55:01 job_callback for (6, 0, 2) got condition
05:55:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:55:01 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.604684





05:55:01 HBMASTER: Trying to run another job!
05:55:01 job_callback for (6, 0, 2) finished
05:55:01 start sampling a new configuration.
05:55:01 best_vector: [0, 0.19083062938251116, 0.749226091303173, 0.9032474167987703, 0.330353789579693, 1, 0.04311937990922976, 0.9104935450640276, 0.3739806233296952], 0.002866179567121921, 0.5112276070069458, 0.0014652701213519435
05:55:01 done sampling a new configuration.
05:55:01 HBMASTER: schedule new run for iteration 6
05:55:01 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
05:55:01 HBMASTER: submitting job (6, 0, 3) to dispatcher
05:55:01 DISPATCHER: trying to submit job (6, 0, 3)
05:55:01 DISPATCHER: trying to notify the job_runner thread.
05:55:01 HBMASTER: job (6, 0, 3) submitted to dispatcher
05:55:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:55:01 DISPATCHER: Trying to submit another job.
05:55:01 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:55:01 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:55:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:55:01 WORKER: start processing job (6, 0, 3)
05:55:01 WORKER: args: ()
05:55:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 352, 'last_n_outputs': 40, 'leak_rate': 0.9758118541996925, 'lr': 0.004578335126765098, 'optimizer': 'SGD', 'sparsity': 0.7603486511782152, 'steps_to_train': 92, 'weight_decay': 0.030659142836350017}, 'budget': 400.0, 'working_directory': '.'}
05:55:31 DISPATCHER: Starting worker discovery
05:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:31 DISPATCHER: Finished worker discovery
05:56:31 DISPATCHER: Starting worker discovery
05:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:31 DISPATCHER: Finished worker discovery
05:57:31 DISPATCHER: Starting worker discovery
05:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:31 DISPATCHER: Finished worker discovery
05:58:31 DISPATCHER: Starting worker discovery
05:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:31 DISPATCHER: Finished worker discovery
05:59:31 DISPATCHER: Starting worker discovery
05:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:31 DISPATCHER: Finished worker discovery
06:00:31 DISPATCHER: Starting worker discovery
06:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:31 DISPATCHER: Finished worker discovery
06:01:31 DISPATCHER: Starting worker discovery
06:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:31 DISPATCHER: Finished worker discovery
06:01:49 WORKER: done with job (6, 0, 3), trying to register it.
06:01:49 WORKER: registered result for job (6, 0, 3) with dispatcher
06:01:49 DISPATCHER: job (6, 0, 3) finished
06:01:49 DISPATCHER: register_result: lock acquired
06:01:49 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:01:49 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 352, 'last_n_outputs': 40, 'leak_rate': 0.9758118541996925, 'lr': 0.004578335126765098, 'optimizer': 'SGD', 'sparsity': 0.7603486511782152, 'steps_to_train': 92, 'weight_decay': 0.030659142836350017}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5620568345607028, 'info': {'data02': 0.5620568345607028, 'config': "{'batch_size': 16, 'hidden_dim': 352, 'last_n_outputs': 40, 'leak_rate': 0.9758118541996925, 'lr': 0.004578335126765098, 'optimizer': 'SGD', 'sparsity': 0.7603486511782152, 'steps_to_train': 92, 'weight_decay': 0.030659142836350017}"}}
exception: None

06:01:49 job_callback for (6, 0, 3) started
06:01:49 DISPATCHER: Trying to submit another job.
06:01:49 job_callback for (6, 0, 3) got condition
06:01:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:01:49 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.604684





06:01:49 HBMASTER: Trying to run another job!
06:01:49 job_callback for (6, 0, 3) finished
06:01:49 start sampling a new configuration.
06:01:49 done sampling a new configuration.
06:01:49 HBMASTER: schedule new run for iteration 6
06:01:49 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
06:01:49 HBMASTER: submitting job (6, 0, 4) to dispatcher
06:01:49 DISPATCHER: trying to submit job (6, 0, 4)
06:01:49 DISPATCHER: trying to notify the job_runner thread.
06:01:49 HBMASTER: job (6, 0, 4) submitted to dispatcher
06:01:49 DISPATCHER: Trying to submit another job.
06:01:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:01:49 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:01:49 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:01:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:01:49 WORKER: start processing job (6, 0, 4)
06:01:49 WORKER: args: ()
06:01:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 908, 'last_n_outputs': 37, 'leak_rate': 0.7829314749916906, 'lr': 0.01073653057503789, 'optimizer': 'Adam', 'sparsity': 0.7771274507118876, 'steps_to_train': 58, 'weight_decay': 0.07093552745902933}, 'budget': 400.0, 'working_directory': '.'}
06:02:31 DISPATCHER: Starting worker discovery
06:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:31 DISPATCHER: Finished worker discovery
06:03:31 DISPATCHER: Starting worker discovery
06:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:31 DISPATCHER: Finished worker discovery
06:04:31 DISPATCHER: Starting worker discovery
06:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:31 DISPATCHER: Finished worker discovery
06:05:31 DISPATCHER: Starting worker discovery
06:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:31 DISPATCHER: Finished worker discovery
06:06:31 DISPATCHER: Starting worker discovery
06:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:31 DISPATCHER: Finished worker discovery
06:07:31 DISPATCHER: Starting worker discovery
06:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:31 DISPATCHER: Finished worker discovery
06:08:31 DISPATCHER: Starting worker discovery
06:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:31 DISPATCHER: Finished worker discovery
06:08:35 WORKER: done with job (6, 0, 4), trying to register it.
06:08:35 WORKER: registered result for job (6, 0, 4) with dispatcher
06:08:35 DISPATCHER: job (6, 0, 4) finished
06:08:35 DISPATCHER: register_result: lock acquired
06:08:35 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:08:35 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 908, 'last_n_outputs': 37, 'leak_rate': 0.7829314749916906, 'lr': 0.01073653057503789, 'optimizer': 'Adam', 'sparsity': 0.7771274507118876, 'steps_to_train': 58, 'weight_decay': 0.07093552745902933}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23026517481268863, 'info': {'data02': 0.23026517481268863, 'config': "{'batch_size': 64, 'hidden_dim': 908, 'last_n_outputs': 37, 'leak_rate': 0.7829314749916906, 'lr': 0.01073653057503789, 'optimizer': 'Adam', 'sparsity': 0.7771274507118876, 'steps_to_train': 58, 'weight_decay': 0.07093552745902933}"}}
exception: None

06:08:35 job_callback for (6, 0, 4) started
06:08:35 DISPATCHER: Trying to submit another job.
06:08:35 job_callback for (6, 0, 4) got condition
06:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:08:35 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.604684





06:08:35 HBMASTER: Trying to run another job!
06:08:35 job_callback for (6, 0, 4) finished
06:08:35 start sampling a new configuration.
06:08:35 best_vector: [1, 0.4990812552679304, 0.9138980738832351, 0.9066579173981549, 0.4162014558009125, 1, 0.7021123453097093, 0.09168442086224884, 0.18662141123940829], 0.012959207979960486, 1.442739853982901, 0.01869676582874224
06:08:35 done sampling a new configuration.
06:08:35 HBMASTER: schedule new run for iteration 6
06:08:35 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
06:08:35 HBMASTER: submitting job (6, 0, 5) to dispatcher
06:08:35 DISPATCHER: trying to submit job (6, 0, 5)
06:08:35 DISPATCHER: trying to notify the job_runner thread.
06:08:35 HBMASTER: job (6, 0, 5) submitted to dispatcher
06:08:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:08:35 DISPATCHER: Trying to submit another job.
06:08:35 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:08:35 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:08:35 WORKER: start processing job (6, 0, 5)
06:08:35 WORKER: args: ()
06:08:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 47, 'leak_rate': 0.9766644793495387, 'lr': 0.006798340481905544, 'optimizer': 'SGD', 'sparsity': 0.9185069628743302, 'steps_to_train': 18, 'weight_decay': 0.017490412568598818}, 'budget': 400.0, 'working_directory': '.'}
06:09:31 DISPATCHER: Starting worker discovery
06:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:31 DISPATCHER: Finished worker discovery
06:10:31 DISPATCHER: Starting worker discovery
06:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:31 DISPATCHER: Finished worker discovery
06:11:31 DISPATCHER: Starting worker discovery
06:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:31 DISPATCHER: Finished worker discovery
06:12:31 DISPATCHER: Starting worker discovery
06:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:31 DISPATCHER: Finished worker discovery
06:13:31 DISPATCHER: Starting worker discovery
06:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:31 DISPATCHER: Finished worker discovery
06:14:31 DISPATCHER: Starting worker discovery
06:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:31 DISPATCHER: Finished worker discovery
06:15:22 WORKER: done with job (6, 0, 5), trying to register it.
06:15:22 WORKER: registered result for job (6, 0, 5) with dispatcher
06:15:22 DISPATCHER: job (6, 0, 5) finished
06:15:22 DISPATCHER: register_result: lock acquired
06:15:22 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:15:22 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 47, 'leak_rate': 0.9766644793495387, 'lr': 0.006798340481905544, 'optimizer': 'SGD', 'sparsity': 0.9185069628743302, 'steps_to_train': 18, 'weight_decay': 0.017490412568598818}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.575495879954184, 'info': {'data02': 0.575495879954184, 'config': "{'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 47, 'leak_rate': 0.9766644793495387, 'lr': 0.006798340481905544, 'optimizer': 'SGD', 'sparsity': 0.9185069628743302, 'steps_to_train': 18, 'weight_decay': 0.017490412568598818}"}}
exception: None

06:15:22 job_callback for (6, 0, 5) started
06:15:22 job_callback for (6, 0, 5) got condition
06:15:22 DISPATCHER: Trying to submit another job.
06:15:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:15:22 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.604684





06:15:22 HBMASTER: Trying to run another job!
06:15:22 job_callback for (6, 0, 5) finished
06:15:22 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
06:15:22 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
06:15:22 HBMASTER: schedule new run for iteration 6
06:15:22 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
06:15:22 HBMASTER: submitting job (6, 0, 0) to dispatcher
06:15:22 DISPATCHER: trying to submit job (6, 0, 0)
06:15:22 DISPATCHER: trying to notify the job_runner thread.
06:15:22 HBMASTER: job (6, 0, 0) submitted to dispatcher
06:15:22 DISPATCHER: Trying to submit another job.
06:15:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:15:22 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:15:22 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:15:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:15:22 WORKER: start processing job (6, 0, 0)
06:15:22 WORKER: args: ()
06:15:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.9221650367396208, 'lr': 0.002448646431971015, 'optimizer': 'SGD', 'sparsity': 0.9506074408831555, 'steps_to_train': 73, 'weight_decay': 0.13861872183755103}, 'budget': 1200.0, 'working_directory': '.'}
06:15:31 DISPATCHER: Starting worker discovery
06:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:31 DISPATCHER: Finished worker discovery
06:16:31 DISPATCHER: Starting worker discovery
06:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:31 DISPATCHER: Finished worker discovery
06:17:31 DISPATCHER: Starting worker discovery
06:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:31 DISPATCHER: Finished worker discovery
06:18:31 DISPATCHER: Starting worker discovery
06:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:31 DISPATCHER: Finished worker discovery
06:19:31 DISPATCHER: Starting worker discovery
06:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:31 DISPATCHER: Finished worker discovery
06:20:31 DISPATCHER: Starting worker discovery
06:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:31 DISPATCHER: Finished worker discovery
06:21:31 DISPATCHER: Starting worker discovery
06:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:32 DISPATCHER: Finished worker discovery
06:22:32 DISPATCHER: Starting worker discovery
06:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:32 DISPATCHER: Finished worker discovery
06:23:32 DISPATCHER: Starting worker discovery
06:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:32 DISPATCHER: Finished worker discovery
06:24:32 DISPATCHER: Starting worker discovery
06:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:32 DISPATCHER: Finished worker discovery
06:25:32 DISPATCHER: Starting worker discovery
06:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:32 DISPATCHER: Finished worker discovery
06:26:32 DISPATCHER: Starting worker discovery
06:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:32 DISPATCHER: Finished worker discovery
06:27:32 DISPATCHER: Starting worker discovery
06:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:32 DISPATCHER: Finished worker discovery
06:28:32 DISPATCHER: Starting worker discovery
06:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:32 DISPATCHER: Finished worker discovery
06:29:32 DISPATCHER: Starting worker discovery
06:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:32 DISPATCHER: Finished worker discovery
06:30:32 DISPATCHER: Starting worker discovery
06:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:32 DISPATCHER: Finished worker discovery
06:31:32 DISPATCHER: Starting worker discovery
06:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:32 DISPATCHER: Finished worker discovery
06:32:32 DISPATCHER: Starting worker discovery
06:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:32 DISPATCHER: Finished worker discovery
06:33:32 DISPATCHER: Starting worker discovery
06:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:32 DISPATCHER: Finished worker discovery
06:34:32 DISPATCHER: Starting worker discovery
06:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:32 DISPATCHER: Finished worker discovery
06:35:29 WORKER: done with job (6, 0, 0), trying to register it.
06:35:29 WORKER: registered result for job (6, 0, 0) with dispatcher
06:35:29 DISPATCHER: job (6, 0, 0) finished
06:35:29 DISPATCHER: register_result: lock acquired
06:35:29 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:35:29 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.9221650367396208, 'lr': 0.002448646431971015, 'optimizer': 'SGD', 'sparsity': 0.9506074408831555, 'steps_to_train': 73, 'weight_decay': 0.13861872183755103}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5932795872353774, 'info': {'data02': 0.5932795872353774, 'config': "{'batch_size': 32, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.9221650367396208, 'lr': 0.002448646431971015, 'optimizer': 'SGD', 'sparsity': 0.9506074408831555, 'steps_to_train': 73, 'weight_decay': 0.13861872183755103}"}}
exception: None

06:35:29 job_callback for (6, 0, 0) started
06:35:29 job_callback for (6, 0, 0) got condition
06:35:29 DISPATCHER: Trying to submit another job.
06:35:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:35:29 HBMASTER: Trying to run another job!
06:35:29 job_callback for (6, 0, 0) finished
06:35:29 HBMASTER: schedule new run for iteration 6
06:35:29 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
06:35:29 HBMASTER: submitting job (6, 0, 5) to dispatcher
06:35:29 DISPATCHER: trying to submit job (6, 0, 5)
06:35:29 DISPATCHER: trying to notify the job_runner thread.
06:35:29 HBMASTER: job (6, 0, 5) submitted to dispatcher
06:35:29 DISPATCHER: Trying to submit another job.
06:35:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:35:29 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:35:29 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:35:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:35:29 WORKER: start processing job (6, 0, 5)
06:35:29 WORKER: args: ()
06:35:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 47, 'leak_rate': 0.9766644793495387, 'lr': 0.006798340481905544, 'optimizer': 'SGD', 'sparsity': 0.9185069628743302, 'steps_to_train': 18, 'weight_decay': 0.017490412568598818}, 'budget': 1200.0, 'working_directory': '.'}
06:35:32 DISPATCHER: Starting worker discovery
06:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:32 DISPATCHER: Finished worker discovery
06:36:32 DISPATCHER: Starting worker discovery
06:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:32 DISPATCHER: Finished worker discovery
06:37:32 DISPATCHER: Starting worker discovery
06:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:32 DISPATCHER: Finished worker discovery
06:38:32 DISPATCHER: Starting worker discovery
06:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:32 DISPATCHER: Finished worker discovery
06:39:32 DISPATCHER: Starting worker discovery
06:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:32 DISPATCHER: Finished worker discovery
06:40:32 DISPATCHER: Starting worker discovery
06:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:32 DISPATCHER: Finished worker discovery
06:41:32 DISPATCHER: Starting worker discovery
06:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:32 DISPATCHER: Finished worker discovery
06:42:32 DISPATCHER: Starting worker discovery
06:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:32 DISPATCHER: Finished worker discovery
06:43:32 DISPATCHER: Starting worker discovery
06:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:32 DISPATCHER: Finished worker discovery
06:44:32 DISPATCHER: Starting worker discovery
06:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:32 DISPATCHER: Finished worker discovery
06:45:32 DISPATCHER: Starting worker discovery
06:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:32 DISPATCHER: Finished worker discovery
06:46:32 DISPATCHER: Starting worker discovery
06:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:32 DISPATCHER: Finished worker discovery
06:47:32 DISPATCHER: Starting worker discovery
06:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:32 DISPATCHER: Finished worker discovery
06:48:32 DISPATCHER: Starting worker discovery
06:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:32 DISPATCHER: Finished worker discovery
06:49:32 DISPATCHER: Starting worker discovery
06:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:32 DISPATCHER: Finished worker discovery
06:50:32 DISPATCHER: Starting worker discovery
06:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:32 DISPATCHER: Finished worker discovery
06:51:32 DISPATCHER: Starting worker discovery
06:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:32 DISPATCHER: Finished worker discovery
06:52:32 DISPATCHER: Starting worker discovery
06:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:32 DISPATCHER: Finished worker discovery
06:53:32 DISPATCHER: Starting worker discovery
06:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:32 DISPATCHER: Finished worker discovery
06:54:32 DISPATCHER: Starting worker discovery
06:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:32 DISPATCHER: Finished worker discovery
06:55:32 DISPATCHER: Starting worker discovery
06:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:32 DISPATCHER: Finished worker discovery
06:55:39 WORKER: done with job (6, 0, 5), trying to register it.
06:55:39 WORKER: registered result for job (6, 0, 5) with dispatcher
06:55:39 DISPATCHER: job (6, 0, 5) finished
06:55:39 DISPATCHER: register_result: lock acquired
06:55:39 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:55:39 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 47, 'leak_rate': 0.9766644793495387, 'lr': 0.006798340481905544, 'optimizer': 'SGD', 'sparsity': 0.9185069628743302, 'steps_to_train': 18, 'weight_decay': 0.017490412568598818}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5725982670006912, 'info': {'data02': 0.5725982670006912, 'config': "{'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 47, 'leak_rate': 0.9766644793495387, 'lr': 0.006798340481905544, 'optimizer': 'SGD', 'sparsity': 0.9185069628743302, 'steps_to_train': 18, 'weight_decay': 0.017490412568598818}"}}
exception: None

06:55:39 job_callback for (6, 0, 5) started
06:55:39 DISPATCHER: Trying to submit another job.
06:55:39 job_callback for (6, 0, 5) got condition
06:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:55:40 HBMASTER: Trying to run another job!
06:55:40 job_callback for (6, 0, 5) finished
06:55:40 start sampling a new configuration.
06:55:40 done sampling a new configuration.
06:55:40 HBMASTER: schedule new run for iteration 7
06:55:40 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
06:55:40 HBMASTER: submitting job (7, 0, 0) to dispatcher
06:55:40 DISPATCHER: trying to submit job (7, 0, 0)
06:55:40 DISPATCHER: trying to notify the job_runner thread.
06:55:40 HBMASTER: job (7, 0, 0) submitted to dispatcher
06:55:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:55:40 DISPATCHER: Trying to submit another job.
06:55:40 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:55:40 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:55:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:55:40 WORKER: start processing job (7, 0, 0)
06:55:40 WORKER: args: ()
06:55:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 935, 'last_n_outputs': 48, 'leak_rate': 0.7717409139567167, 'lr': 0.005423386636694895, 'optimizer': 'SGD', 'sparsity': 0.9396646123293046, 'steps_to_train': 95, 'weight_decay': 0.054914419255773964}, 'budget': 1200.0, 'working_directory': '.'}
06:56:32 DISPATCHER: Starting worker discovery
06:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:32 DISPATCHER: Finished worker discovery
06:57:32 DISPATCHER: Starting worker discovery
06:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:32 DISPATCHER: Finished worker discovery
06:58:32 DISPATCHER: Starting worker discovery
06:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:32 DISPATCHER: Finished worker discovery
06:59:32 DISPATCHER: Starting worker discovery
06:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:32 DISPATCHER: Finished worker discovery
07:00:32 DISPATCHER: Starting worker discovery
07:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:32 DISPATCHER: Finished worker discovery
07:01:32 DISPATCHER: Starting worker discovery
07:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:32 DISPATCHER: Finished worker discovery
07:02:32 DISPATCHER: Starting worker discovery
07:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:32 DISPATCHER: Finished worker discovery
07:03:32 DISPATCHER: Starting worker discovery
07:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:32 DISPATCHER: Finished worker discovery
07:04:32 DISPATCHER: Starting worker discovery
07:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:32 DISPATCHER: Finished worker discovery
07:05:32 DISPATCHER: Starting worker discovery
07:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:32 DISPATCHER: Finished worker discovery
07:06:32 DISPATCHER: Starting worker discovery
07:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:32 DISPATCHER: Finished worker discovery
07:07:32 DISPATCHER: Starting worker discovery
07:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:32 DISPATCHER: Finished worker discovery
07:08:32 DISPATCHER: Starting worker discovery
07:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:32 DISPATCHER: Finished worker discovery
07:09:32 DISPATCHER: Starting worker discovery
07:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:32 DISPATCHER: Finished worker discovery
07:10:32 DISPATCHER: Starting worker discovery
07:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:32 DISPATCHER: Finished worker discovery
07:11:32 DISPATCHER: Starting worker discovery
07:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:32 DISPATCHER: Finished worker discovery
07:12:32 DISPATCHER: Starting worker discovery
07:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:32 DISPATCHER: Finished worker discovery
07:13:32 DISPATCHER: Starting worker discovery
07:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:32 DISPATCHER: Finished worker discovery
07:14:32 DISPATCHER: Starting worker discovery
07:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:32 DISPATCHER: Finished worker discovery
07:15:32 DISPATCHER: Starting worker discovery
07:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:32 DISPATCHER: Finished worker discovery
07:15:48 WORKER: done with job (7, 0, 0), trying to register it.
07:15:48 WORKER: registered result for job (7, 0, 0) with dispatcher
07:15:48 DISPATCHER: job (7, 0, 0) finished
07:15:48 DISPATCHER: register_result: lock acquired
07:15:48 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:15:48 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 935, 'last_n_outputs': 48, 'leak_rate': 0.7717409139567167, 'lr': 0.005423386636694895, 'optimizer': 'SGD', 'sparsity': 0.9396646123293046, 'steps_to_train': 95, 'weight_decay': 0.054914419255773964}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5926680599676006, 'info': {'data02': 0.5926680599676006, 'config': "{'batch_size': 64, 'hidden_dim': 935, 'last_n_outputs': 48, 'leak_rate': 0.7717409139567167, 'lr': 0.005423386636694895, 'optimizer': 'SGD', 'sparsity': 0.9396646123293046, 'steps_to_train': 95, 'weight_decay': 0.054914419255773964}"}}
exception: None

07:15:48 job_callback for (7, 0, 0) started
07:15:48 job_callback for (7, 0, 0) got condition
07:15:48 DISPATCHER: Trying to submit another job.
07:15:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:15:48 HBMASTER: Trying to run another job!
07:15:48 job_callback for (7, 0, 0) finished
07:15:48 start sampling a new configuration.
07:15:48 best_vector: [0, 0.9762758351046285, 0.9124334336846719, 0.6132098725716242, 0.9499104424064417, 1, 0.7338346004414822, 0.39197440010320983, 0.31078782488346246], 0.006406359448940884, 0.37538186560133174, 0.0024048311616561486
07:15:48 done sampling a new configuration.
07:15:48 HBMASTER: schedule new run for iteration 7
07:15:48 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
07:15:48 HBMASTER: submitting job (7, 0, 1) to dispatcher
07:15:48 DISPATCHER: trying to submit job (7, 0, 1)
07:15:48 DISPATCHER: trying to notify the job_runner thread.
07:15:48 HBMASTER: job (7, 0, 1) submitted to dispatcher
07:15:48 DISPATCHER: Trying to submit another job.
07:15:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:15:48 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:15:48 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:15:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:15:48 WORKER: start processing job (7, 0, 1)
07:15:48 WORKER: args: ()
07:15:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 981, 'last_n_outputs': 47, 'leak_rate': 0.903302468142906, 'lr': 0.07940006990981045, 'optimizer': 'SGD', 'sparsity': 0.9261203041059557, 'steps_to_train': 45, 'weight_decay': 0.025371391243039575}, 'budget': 1200.0, 'working_directory': '.'}
07:16:32 DISPATCHER: Starting worker discovery
07:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:32 DISPATCHER: Finished worker discovery
07:17:32 DISPATCHER: Starting worker discovery
07:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:32 DISPATCHER: Finished worker discovery
07:18:32 DISPATCHER: Starting worker discovery
07:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:32 DISPATCHER: Finished worker discovery
07:19:32 DISPATCHER: Starting worker discovery
07:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:32 DISPATCHER: Finished worker discovery
07:20:32 DISPATCHER: Starting worker discovery
07:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:32 DISPATCHER: Finished worker discovery
07:21:32 DISPATCHER: Starting worker discovery
07:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:32 DISPATCHER: Finished worker discovery
07:22:32 DISPATCHER: Starting worker discovery
07:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:32 DISPATCHER: Finished worker discovery
07:23:32 DISPATCHER: Starting worker discovery
07:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:32 DISPATCHER: Finished worker discovery
07:24:32 DISPATCHER: Starting worker discovery
07:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:32 DISPATCHER: Finished worker discovery
07:25:32 DISPATCHER: Starting worker discovery
07:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:32 DISPATCHER: Finished worker discovery
07:26:32 DISPATCHER: Starting worker discovery
07:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:32 DISPATCHER: Finished worker discovery
07:27:32 DISPATCHER: Starting worker discovery
07:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:32 DISPATCHER: Finished worker discovery
07:28:32 DISPATCHER: Starting worker discovery
07:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:32 DISPATCHER: Finished worker discovery
07:29:32 DISPATCHER: Starting worker discovery
07:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:32 DISPATCHER: Finished worker discovery
07:30:32 DISPATCHER: Starting worker discovery
07:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:32 DISPATCHER: Finished worker discovery
07:31:32 DISPATCHER: Starting worker discovery
07:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:32 DISPATCHER: Finished worker discovery
07:32:32 DISPATCHER: Starting worker discovery
07:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:32 DISPATCHER: Finished worker discovery
07:33:32 DISPATCHER: Starting worker discovery
07:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:32 DISPATCHER: Finished worker discovery
07:34:32 DISPATCHER: Starting worker discovery
07:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:32 DISPATCHER: Finished worker discovery
07:35:32 DISPATCHER: Starting worker discovery
07:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:32 DISPATCHER: Finished worker discovery
07:35:56 WORKER: done with job (7, 0, 1), trying to register it.
07:35:56 WORKER: registered result for job (7, 0, 1) with dispatcher
07:35:56 DISPATCHER: job (7, 0, 1) finished
07:35:56 DISPATCHER: register_result: lock acquired
07:35:56 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:35:56 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 981, 'last_n_outputs': 47, 'leak_rate': 0.903302468142906, 'lr': 0.07940006990981045, 'optimizer': 'SGD', 'sparsity': 0.9261203041059557, 'steps_to_train': 45, 'weight_decay': 0.025371391243039575}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4811973653432799, 'info': {'data02': 0.4811973653432799, 'config': "{'batch_size': 16, 'hidden_dim': 981, 'last_n_outputs': 47, 'leak_rate': 0.903302468142906, 'lr': 0.07940006990981045, 'optimizer': 'SGD', 'sparsity': 0.9261203041059557, 'steps_to_train': 45, 'weight_decay': 0.025371391243039575}"}}
exception: None

07:35:56 job_callback for (7, 0, 1) started
07:35:56 DISPATCHER: Trying to submit another job.
07:35:56 job_callback for (7, 0, 1) got condition
07:35:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:35:56 HBMASTER: Trying to run another job!
07:35:56 job_callback for (7, 0, 1) finished
07:35:56 start sampling a new configuration.
07:35:56 best_vector: [1, 0.2589718974229944, 0.7992826291552453, 0.6222650800768132, 0.7364956585442053, 1, 0.7925538108592651, 0.9220031999415258, 0.7169889104570035], 0.018435440012201487, 0.43892404381828776, 0.00809175787972494
07:35:56 done sampling a new configuration.
07:35:56 HBMASTER: schedule new run for iteration 7
07:35:56 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
07:35:56 HBMASTER: submitting job (7, 0, 2) to dispatcher
07:35:56 DISPATCHER: trying to submit job (7, 0, 2)
07:35:56 DISPATCHER: trying to notify the job_runner thread.
07:35:56 HBMASTER: job (7, 0, 2) submitted to dispatcher
07:35:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:35:56 DISPATCHER: Trying to submit another job.
07:35:56 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:35:56 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:35:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:35:56 WORKER: start processing job (7, 0, 2)
07:35:56 WORKER: args: ()
07:35:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 407, 'last_n_outputs': 42, 'leak_rate': 0.9055662700192033, 'lr': 0.02971606619388654, 'optimizer': 'SGD', 'sparsity': 0.9402129146062237, 'steps_to_train': 93, 'weight_decay': 0.08566907527054168}, 'budget': 1200.0, 'working_directory': '.'}
07:36:32 DISPATCHER: Starting worker discovery
07:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:32 DISPATCHER: Finished worker discovery
07:37:32 DISPATCHER: Starting worker discovery
07:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:32 DISPATCHER: Finished worker discovery
07:38:32 DISPATCHER: Starting worker discovery
07:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:32 DISPATCHER: Finished worker discovery
07:39:32 DISPATCHER: Starting worker discovery
07:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:32 DISPATCHER: Finished worker discovery
07:40:32 DISPATCHER: Starting worker discovery
07:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:32 DISPATCHER: Finished worker discovery
07:41:32 DISPATCHER: Starting worker discovery
07:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:32 DISPATCHER: Finished worker discovery
07:42:32 DISPATCHER: Starting worker discovery
07:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:32 DISPATCHER: Finished worker discovery
07:43:32 DISPATCHER: Starting worker discovery
07:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:32 DISPATCHER: Finished worker discovery
07:44:32 DISPATCHER: Starting worker discovery
07:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:32 DISPATCHER: Finished worker discovery
07:45:32 DISPATCHER: Starting worker discovery
07:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:32 DISPATCHER: Finished worker discovery
07:46:32 DISPATCHER: Starting worker discovery
07:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:32 DISPATCHER: Finished worker discovery
07:47:32 DISPATCHER: Starting worker discovery
07:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:32 DISPATCHER: Finished worker discovery
07:48:32 DISPATCHER: Starting worker discovery
07:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:32 DISPATCHER: Finished worker discovery
07:49:32 DISPATCHER: Starting worker discovery
07:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:32 DISPATCHER: Finished worker discovery
07:50:32 DISPATCHER: Starting worker discovery
07:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:32 DISPATCHER: Finished worker discovery
07:51:32 DISPATCHER: Starting worker discovery
07:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:32 DISPATCHER: Finished worker discovery
07:52:32 DISPATCHER: Starting worker discovery
07:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:32 DISPATCHER: Finished worker discovery
07:53:32 DISPATCHER: Starting worker discovery
07:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:32 DISPATCHER: Finished worker discovery
07:54:32 DISPATCHER: Starting worker discovery
07:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:32 DISPATCHER: Finished worker discovery
07:55:32 DISPATCHER: Starting worker discovery
07:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:32 DISPATCHER: Finished worker discovery
07:56:02 WORKER: done with job (7, 0, 2), trying to register it.
07:56:02 WORKER: registered result for job (7, 0, 2) with dispatcher
07:56:02 DISPATCHER: job (7, 0, 2) finished
07:56:02 DISPATCHER: register_result: lock acquired
07:56:02 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:56:02 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 407, 'last_n_outputs': 42, 'leak_rate': 0.9055662700192033, 'lr': 0.02971606619388654, 'optimizer': 'SGD', 'sparsity': 0.9402129146062237, 'steps_to_train': 93, 'weight_decay': 0.08566907527054168}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4924290684529274, 'info': {'data02': 0.4924290684529274, 'config': "{'batch_size': 32, 'hidden_dim': 407, 'last_n_outputs': 42, 'leak_rate': 0.9055662700192033, 'lr': 0.02971606619388654, 'optimizer': 'SGD', 'sparsity': 0.9402129146062237, 'steps_to_train': 93, 'weight_decay': 0.08566907527054168}"}}
exception: None

07:56:02 job_callback for (7, 0, 2) started
07:56:02 job_callback for (7, 0, 2) got condition
07:56:02 DISPATCHER: Trying to submit another job.
07:56:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:56:02 HBMASTER: Trying to run another job!
07:56:02 job_callback for (7, 0, 2) finished
07:56:02 start sampling a new configuration.
07:56:02 best_vector: [0, 0.7187312594886086, 0.9004667725184703, 0.9059494142279882, 0.24303643994274324, 1, 0.17232470198906624, 0.8482400391751308, 0.6934161329833677], 0.012299111433325651, 0.8996954466361698, 0.011065454554233944
07:56:02 done sampling a new configuration.
07:56:02 HBMASTER: schedule new run for iteration 7
07:56:02 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
07:56:02 HBMASTER: submitting job (7, 0, 3) to dispatcher
07:56:02 DISPATCHER: trying to submit job (7, 0, 3)
07:56:02 DISPATCHER: trying to notify the job_runner thread.
07:56:02 HBMASTER: job (7, 0, 3) submitted to dispatcher
07:56:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:56:02 DISPATCHER: Trying to submit another job.
07:56:02 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:56:02 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:56:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:56:02 WORKER: start processing job (7, 0, 3)
07:56:02 WORKER: args: ()
07:56:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 775, 'last_n_outputs': 46, 'leak_rate': 0.9764873535569971, 'lr': 0.0030624773114369154, 'optimizer': 'SGD', 'sparsity': 0.7913579284773758, 'steps_to_train': 87, 'weight_decay': 0.07982798894139498}, 'budget': 1200.0, 'working_directory': '.'}
07:56:32 DISPATCHER: Starting worker discovery
07:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:32 DISPATCHER: Finished worker discovery
07:57:32 DISPATCHER: Starting worker discovery
07:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:32 DISPATCHER: Finished worker discovery
07:58:32 DISPATCHER: Starting worker discovery
07:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:32 DISPATCHER: Finished worker discovery
07:59:32 DISPATCHER: Starting worker discovery
07:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:32 DISPATCHER: Finished worker discovery
08:00:32 DISPATCHER: Starting worker discovery
08:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:32 DISPATCHER: Finished worker discovery
08:01:32 DISPATCHER: Starting worker discovery
08:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:32 DISPATCHER: Finished worker discovery
08:02:32 DISPATCHER: Starting worker discovery
08:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:32 DISPATCHER: Finished worker discovery
08:03:32 DISPATCHER: Starting worker discovery
08:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:32 DISPATCHER: Finished worker discovery
08:04:32 DISPATCHER: Starting worker discovery
08:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:32 DISPATCHER: Finished worker discovery
08:05:32 DISPATCHER: Starting worker discovery
08:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:32 DISPATCHER: Finished worker discovery
08:06:32 DISPATCHER: Starting worker discovery
08:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:32 DISPATCHER: Finished worker discovery
08:07:32 DISPATCHER: Starting worker discovery
08:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:32 DISPATCHER: Finished worker discovery
08:08:32 DISPATCHER: Starting worker discovery
08:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:32 DISPATCHER: Finished worker discovery
08:09:32 DISPATCHER: Starting worker discovery
08:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:32 DISPATCHER: Finished worker discovery
08:10:32 DISPATCHER: Starting worker discovery
08:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:32 DISPATCHER: Finished worker discovery
08:11:32 DISPATCHER: Starting worker discovery
08:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:32 DISPATCHER: Finished worker discovery
08:12:32 DISPATCHER: Starting worker discovery
08:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:32 DISPATCHER: Finished worker discovery
08:13:32 DISPATCHER: Starting worker discovery
08:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:32 DISPATCHER: Finished worker discovery
08:14:32 DISPATCHER: Starting worker discovery
08:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:32 DISPATCHER: Finished worker discovery
08:15:32 DISPATCHER: Starting worker discovery
08:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:32 DISPATCHER: Finished worker discovery
08:16:11 WORKER: done with job (7, 0, 3), trying to register it.
08:16:11 WORKER: registered result for job (7, 0, 3) with dispatcher
08:16:11 DISPATCHER: job (7, 0, 3) finished
08:16:11 DISPATCHER: register_result: lock acquired
08:16:11 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:16:11 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 775, 'last_n_outputs': 46, 'leak_rate': 0.9764873535569971, 'lr': 0.0030624773114369154, 'optimizer': 'SGD', 'sparsity': 0.7913579284773758, 'steps_to_train': 87, 'weight_decay': 0.07982798894139498}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5813836775749046, 'info': {'data02': 0.5813836775749046, 'config': "{'batch_size': 16, 'hidden_dim': 775, 'last_n_outputs': 46, 'leak_rate': 0.9764873535569971, 'lr': 0.0030624773114369154, 'optimizer': 'SGD', 'sparsity': 0.7913579284773758, 'steps_to_train': 87, 'weight_decay': 0.07982798894139498}"}}
exception: None

08:16:11 job_callback for (7, 0, 3) started
08:16:11 DISPATCHER: Trying to submit another job.
08:16:11 job_callback for (7, 0, 3) got condition
08:16:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:16:11 HBMASTER: Trying to run another job!
08:16:11 job_callback for (7, 0, 3) finished
08:16:11 start sampling a new configuration.
08:16:11 done sampling a new configuration.
08:16:11 HBMASTER: schedule new run for iteration 8
08:16:11 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
08:16:11 HBMASTER: submitting job (8, 0, 0) to dispatcher
08:16:11 DISPATCHER: trying to submit job (8, 0, 0)
08:16:11 DISPATCHER: trying to notify the job_runner thread.
08:16:11 HBMASTER: job (8, 0, 0) submitted to dispatcher
08:16:11 DISPATCHER: Trying to submit another job.
08:16:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:16:11 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:16:11 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:16:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:16:11 WORKER: start processing job (8, 0, 0)
08:16:11 WORKER: args: ()
08:16:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 28, 'leak_rate': 0.8594078736532025, 'lr': 0.027475983514222264, 'optimizer': 'SGD', 'sparsity': 0.9207570444125829, 'steps_to_train': 37, 'weight_decay': 0.010672465365113085}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:16:32 DISPATCHER: Starting worker discovery
08:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:32 DISPATCHER: Finished worker discovery
08:17:02 WORKER: done with job (8, 0, 0), trying to register it.
08:17:02 WORKER: registered result for job (8, 0, 0) with dispatcher
08:17:02 DISPATCHER: job (8, 0, 0) finished
08:17:02 DISPATCHER: register_result: lock acquired
08:17:02 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:17:02 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 28, 'leak_rate': 0.8594078736532025, 'lr': 0.027475983514222264, 'optimizer': 'SGD', 'sparsity': 0.9207570444125829, 'steps_to_train': 37, 'weight_decay': 0.010672465365113085}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5812028156795006, 'info': {'data02': 0.5812028156795006, 'config': "{'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 28, 'leak_rate': 0.8594078736532025, 'lr': 0.027475983514222264, 'optimizer': 'SGD', 'sparsity': 0.9207570444125829, 'steps_to_train': 37, 'weight_decay': 0.010672465365113085}"}}
exception: None

08:17:02 job_callback for (8, 0, 0) started
08:17:02 job_callback for (8, 0, 0) got condition
08:17:02 DISPATCHER: Trying to submit another job.
08:17:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:17:02 HBMASTER: Trying to run another job!
08:17:02 job_callback for (8, 0, 0) finished
08:17:02 start sampling a new configuration.
08:17:02 best_vector: [1, 0.18585382282991358, 0.8933474493648295, 0.6168956550522732, 0.12349770176181452, 1, 0.5024859510339591, 0.7519122649948169, 0.6609704285615645], 0.009643859001899385, 4.235258171460073, 0.04084423264220315
08:17:02 done sampling a new configuration.
08:17:02 HBMASTER: schedule new run for iteration 8
08:17:02 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
08:17:02 HBMASTER: submitting job (8, 0, 1) to dispatcher
08:17:02 DISPATCHER: trying to submit job (8, 0, 1)
08:17:02 DISPATCHER: trying to notify the job_runner thread.
08:17:02 HBMASTER: job (8, 0, 1) submitted to dispatcher
08:17:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:17:02 DISPATCHER: Trying to submit another job.
08:17:02 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:17:02 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:17:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:17:02 WORKER: start processing job (8, 0, 1)
08:17:02 WORKER: args: ()
08:17:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 348, 'last_n_outputs': 46, 'leak_rate': 0.9042239137630683, 'lr': 0.001766019129432892, 'optimizer': 'SGD', 'sparsity': 0.8705966282481502, 'steps_to_train': 78, 'weight_decay': 0.07243398082550546}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:17:32 DISPATCHER: Starting worker discovery
08:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:32 DISPATCHER: Finished worker discovery
08:17:52 WORKER: done with job (8, 0, 1), trying to register it.
08:17:52 WORKER: registered result for job (8, 0, 1) with dispatcher
08:17:52 DISPATCHER: job (8, 0, 1) finished
08:17:52 DISPATCHER: register_result: lock acquired
08:17:52 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:17:52 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 348, 'last_n_outputs': 46, 'leak_rate': 0.9042239137630683, 'lr': 0.001766019129432892, 'optimizer': 'SGD', 'sparsity': 0.8705966282481502, 'steps_to_train': 78, 'weight_decay': 0.07243398082550546}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6024323045488366, 'info': {'data02': 0.6024323045488366, 'config': "{'batch_size': 32, 'hidden_dim': 348, 'last_n_outputs': 46, 'leak_rate': 0.9042239137630683, 'lr': 0.001766019129432892, 'optimizer': 'SGD', 'sparsity': 0.8705966282481502, 'steps_to_train': 78, 'weight_decay': 0.07243398082550546}"}}
exception: None

08:17:52 job_callback for (8, 0, 1) started
08:17:52 DISPATCHER: Trying to submit another job.
08:17:52 job_callback for (8, 0, 1) got condition
08:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:17:52 HBMASTER: Trying to run another job!
08:17:52 job_callback for (8, 0, 1) finished
08:17:52 start sampling a new configuration.
08:17:52 done sampling a new configuration.
08:17:52 HBMASTER: schedule new run for iteration 8
08:17:52 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
08:17:52 HBMASTER: submitting job (8, 0, 2) to dispatcher
08:17:52 DISPATCHER: trying to submit job (8, 0, 2)
08:17:52 DISPATCHER: trying to notify the job_runner thread.
08:17:52 HBMASTER: job (8, 0, 2) submitted to dispatcher
08:17:52 DISPATCHER: Trying to submit another job.
08:17:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:17:52 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:17:52 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:17:52 WORKER: start processing job (8, 0, 2)
08:17:52 WORKER: args: ()
08:17:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:18:32 DISPATCHER: Starting worker discovery
08:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:32 DISPATCHER: Finished worker discovery
08:18:45 WORKER: done with job (8, 0, 2), trying to register it.
08:18:45 WORKER: registered result for job (8, 0, 2) with dispatcher
08:18:45 DISPATCHER: job (8, 0, 2) finished
08:18:45 DISPATCHER: register_result: lock acquired
08:18:45 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:18:45 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6180899409393571, 'info': {'data02': 0.6180899409393571, 'config': "{'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}"}}
exception: None

08:18:45 job_callback for (8, 0, 2) started
08:18:45 DISPATCHER: Trying to submit another job.
08:18:45 job_callback for (8, 0, 2) got condition
08:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:45 HBMASTER: Trying to run another job!
08:18:45 job_callback for (8, 0, 2) finished
08:18:45 start sampling a new configuration.
08:18:46 best_vector: [1, 0.4278569460159526, 0.7736733233961015, 0.8367363117049467, 0.9061523018757648, 1, 0.6216445787812122, 0.9159078800894703, 0.37904394035332006], 0.0067666987844830235, 0.5531570904825903, 0.00374304741179671
08:18:46 done sampling a new configuration.
08:18:46 HBMASTER: schedule new run for iteration 8
08:18:46 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
08:18:46 HBMASTER: submitting job (8, 0, 3) to dispatcher
08:18:46 DISPATCHER: trying to submit job (8, 0, 3)
08:18:46 DISPATCHER: trying to notify the job_runner thread.
08:18:46 HBMASTER: job (8, 0, 3) submitted to dispatcher
08:18:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:46 DISPATCHER: Trying to submit another job.
08:18:46 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:18:46 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:18:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:46 WORKER: start processing job (8, 0, 3)
08:18:46 WORKER: args: ()
08:18:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 41, 'leak_rate': 0.9591840779262366, 'lr': 0.06490895297881742, 'optimizer': 'SGD', 'sparsity': 0.8991946989074909, 'steps_to_train': 93, 'weight_decay': 0.031127736114224078}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:19:32 DISPATCHER: Starting worker discovery
08:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:32 DISPATCHER: Finished worker discovery
08:19:35 WORKER: done with job (8, 0, 3), trying to register it.
08:19:35 WORKER: registered result for job (8, 0, 3) with dispatcher
08:19:35 DISPATCHER: job (8, 0, 3) finished
08:19:35 DISPATCHER: register_result: lock acquired
08:19:35 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:19:35 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 41, 'leak_rate': 0.9591840779262366, 'lr': 0.06490895297881742, 'optimizer': 'SGD', 'sparsity': 0.8991946989074909, 'steps_to_train': 93, 'weight_decay': 0.031127736114224078}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5045298292763605, 'info': {'data02': 0.5045298292763605, 'config': "{'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 41, 'leak_rate': 0.9591840779262366, 'lr': 0.06490895297881742, 'optimizer': 'SGD', 'sparsity': 0.8991946989074909, 'steps_to_train': 93, 'weight_decay': 0.031127736114224078}"}}
exception: None

08:19:35 job_callback for (8, 0, 3) started
08:19:35 DISPATCHER: Trying to submit another job.
08:19:35 job_callback for (8, 0, 3) got condition
08:19:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:19:35 HBMASTER: Trying to run another job!
08:19:35 job_callback for (8, 0, 3) finished
08:19:35 start sampling a new configuration.
08:19:35 done sampling a new configuration.
08:19:35 HBMASTER: schedule new run for iteration 8
08:19:35 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
08:19:35 HBMASTER: submitting job (8, 0, 4) to dispatcher
08:19:35 DISPATCHER: trying to submit job (8, 0, 4)
08:19:35 DISPATCHER: trying to notify the job_runner thread.
08:19:35 HBMASTER: job (8, 0, 4) submitted to dispatcher
08:19:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:19:35 DISPATCHER: Trying to submit another job.
08:19:35 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:19:35 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:19:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:19:35 WORKER: start processing job (8, 0, 4)
08:19:35 WORKER: args: ()
08:19:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 12, 'leak_rate': 0.815279958499534, 'lr': 0.017408328861934354, 'optimizer': 'Adam', 'sparsity': 0.93687558981373, 'steps_to_train': 73, 'weight_decay': 0.05106082697785545}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:20:26 WORKER: done with job (8, 0, 4), trying to register it.
08:20:26 WORKER: registered result for job (8, 0, 4) with dispatcher
08:20:26 DISPATCHER: job (8, 0, 4) finished
08:20:26 DISPATCHER: register_result: lock acquired
08:20:26 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:20:26 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 12, 'leak_rate': 0.815279958499534, 'lr': 0.017408328861934354, 'optimizer': 'Adam', 'sparsity': 0.93687558981373, 'steps_to_train': 73, 'weight_decay': 0.05106082697785545}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21391356427912678, 'info': {'data02': 0.21391356427912678, 'config': "{'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 12, 'leak_rate': 0.815279958499534, 'lr': 0.017408328861934354, 'optimizer': 'Adam', 'sparsity': 0.93687558981373, 'steps_to_train': 73, 'weight_decay': 0.05106082697785545}"}}
exception: None

08:20:26 job_callback for (8, 0, 4) started
08:20:26 job_callback for (8, 0, 4) got condition
08:20:26 DISPATCHER: Trying to submit another job.
08:20:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:20:26 HBMASTER: Trying to run another job!
08:20:26 job_callback for (8, 0, 4) finished
08:20:26 start sampling a new configuration.
08:20:26 best_vector: [1, 0.1954317867308084, 0.8704743117365686, 0.7913132135371173, 0.6655538755992569, 1, 0.8558299006178076, 0.7849541292320775, 0.7631858578702135], 0.012109426886334746, 0.6467714050392877, 0.00783203104149525
08:20:26 done sampling a new configuration.
08:20:26 HBMASTER: schedule new run for iteration 8
08:20:26 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
08:20:26 HBMASTER: submitting job (8, 0, 5) to dispatcher
08:20:26 DISPATCHER: trying to submit job (8, 0, 5)
08:20:26 DISPATCHER: trying to notify the job_runner thread.
08:20:26 HBMASTER: job (8, 0, 5) submitted to dispatcher
08:20:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:20:26 DISPATCHER: Trying to submit another job.
08:20:26 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:20:26 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:20:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:20:26 WORKER: start processing job (8, 0, 5)
08:20:26 WORKER: args: ()
08:20:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.9478283033842794, 'lr': 0.021434223317459342, 'optimizer': 'SGD', 'sparsity': 0.9553991761482739, 'steps_to_train': 81, 'weight_decay': 0.09838472892234987}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:20:32 DISPATCHER: Starting worker discovery
08:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:32 DISPATCHER: Finished worker discovery
08:21:18 WORKER: done with job (8, 0, 5), trying to register it.
08:21:18 WORKER: registered result for job (8, 0, 5) with dispatcher
08:21:18 DISPATCHER: job (8, 0, 5) finished
08:21:18 DISPATCHER: register_result: lock acquired
08:21:18 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:21:18 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.9478283033842794, 'lr': 0.021434223317459342, 'optimizer': 'SGD', 'sparsity': 0.9553991761482739, 'steps_to_train': 81, 'weight_decay': 0.09838472892234987}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6165636622648217, 'info': {'data02': 0.6165636622648217, 'config': "{'batch_size': 32, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.9478283033842794, 'lr': 0.021434223317459342, 'optimizer': 'SGD', 'sparsity': 0.9553991761482739, 'steps_to_train': 81, 'weight_decay': 0.09838472892234987}"}}
exception: None

08:21:18 job_callback for (8, 0, 5) started
08:21:18 DISPATCHER: Trying to submit another job.
08:21:18 job_callback for (8, 0, 5) got condition
08:21:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:21:18 HBMASTER: Trying to run another job!
08:21:18 job_callback for (8, 0, 5) finished
08:21:18 start sampling a new configuration.
08:21:18 done sampling a new configuration.
08:21:18 HBMASTER: schedule new run for iteration 8
08:21:18 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
08:21:18 HBMASTER: submitting job (8, 0, 6) to dispatcher
08:21:18 DISPATCHER: trying to submit job (8, 0, 6)
08:21:18 DISPATCHER: trying to notify the job_runner thread.
08:21:18 HBMASTER: job (8, 0, 6) submitted to dispatcher
08:21:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:21:18 DISPATCHER: Trying to submit another job.
08:21:18 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:21:18 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:21:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:21:18 WORKER: start processing job (8, 0, 6)
08:21:18 WORKER: args: ()
08:21:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 29, 'leak_rate': 0.8615074699482068, 'lr': 0.0010364859277042248, 'optimizer': 'Adam', 'sparsity': 0.9628747553004009, 'steps_to_train': 100, 'weight_decay': 0.0370889518170954}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:21:32 DISPATCHER: Starting worker discovery
08:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:32 DISPATCHER: Finished worker discovery
08:22:08 WORKER: done with job (8, 0, 6), trying to register it.
08:22:08 WORKER: registered result for job (8, 0, 6) with dispatcher
08:22:08 DISPATCHER: job (8, 0, 6) finished
08:22:08 DISPATCHER: register_result: lock acquired
08:22:08 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:22:08 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 29, 'leak_rate': 0.8615074699482068, 'lr': 0.0010364859277042248, 'optimizer': 'Adam', 'sparsity': 0.9628747553004009, 'steps_to_train': 100, 'weight_decay': 0.0370889518170954}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4544326076316533, 'info': {'data02': 0.4544326076316533, 'config': "{'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 29, 'leak_rate': 0.8615074699482068, 'lr': 0.0010364859277042248, 'optimizer': 'Adam', 'sparsity': 0.9628747553004009, 'steps_to_train': 100, 'weight_decay': 0.0370889518170954}"}}
exception: None

08:22:08 job_callback for (8, 0, 6) started
08:22:08 job_callback for (8, 0, 6) got condition
08:22:08 DISPATCHER: Trying to submit another job.
08:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:22:08 HBMASTER: Trying to run another job!
08:22:08 job_callback for (8, 0, 6) finished
08:22:08 start sampling a new configuration.
08:22:08 done sampling a new configuration.
08:22:08 HBMASTER: schedule new run for iteration 8
08:22:08 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
08:22:08 HBMASTER: submitting job (8, 0, 7) to dispatcher
08:22:08 DISPATCHER: trying to submit job (8, 0, 7)
08:22:08 DISPATCHER: trying to notify the job_runner thread.
08:22:08 HBMASTER: job (8, 0, 7) submitted to dispatcher
08:22:08 DISPATCHER: Trying to submit another job.
08:22:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:22:08 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:22:08 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:22:08 WORKER: start processing job (8, 0, 7)
08:22:08 WORKER: args: ()
08:22:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 945, 'last_n_outputs': 17, 'leak_rate': 0.901741156346818, 'lr': 0.08648165365054546, 'optimizer': 'Adam', 'sparsity': 0.8151265142044766, 'steps_to_train': 39, 'weight_decay': 0.09359805507243665}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:22:32 DISPATCHER: Starting worker discovery
08:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:32 DISPATCHER: Finished worker discovery
08:22:58 WORKER: done with job (8, 0, 7), trying to register it.
08:22:58 WORKER: registered result for job (8, 0, 7) with dispatcher
08:22:58 DISPATCHER: job (8, 0, 7) finished
08:22:58 DISPATCHER: register_result: lock acquired
08:22:58 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:22:58 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 945, 'last_n_outputs': 17, 'leak_rate': 0.901741156346818, 'lr': 0.08648165365054546, 'optimizer': 'Adam', 'sparsity': 0.8151265142044766, 'steps_to_train': 39, 'weight_decay': 0.09359805507243665}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009613890148753088, 'info': {'data02': 0.009613890148753088, 'config': "{'batch_size': 32, 'hidden_dim': 945, 'last_n_outputs': 17, 'leak_rate': 0.901741156346818, 'lr': 0.08648165365054546, 'optimizer': 'Adam', 'sparsity': 0.8151265142044766, 'steps_to_train': 39, 'weight_decay': 0.09359805507243665}"}}
exception: None

08:22:58 job_callback for (8, 0, 7) started
08:22:58 DISPATCHER: Trying to submit another job.
08:22:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:22:58 job_callback for (8, 0, 7) got condition
08:22:58 HBMASTER: Trying to run another job!
08:22:58 job_callback for (8, 0, 7) finished
08:22:58 start sampling a new configuration.
08:22:58 best_vector: [2, 0.7916299873013044, 0.6989329590837066, 0.697983183808295, 0.11204525497086101, 1, 0.9321960019631631, 0.8005625704404546, 0.9974878003152521], 0.005469496312076146, 0.2189526380656916, 0.0011975606464196434
08:22:58 done sampling a new configuration.
08:22:58 HBMASTER: schedule new run for iteration 8
08:22:58 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
08:22:58 HBMASTER: submitting job (8, 0, 8) to dispatcher
08:22:58 DISPATCHER: trying to submit job (8, 0, 8)
08:22:58 DISPATCHER: trying to notify the job_runner thread.
08:22:58 HBMASTER: job (8, 0, 8) submitted to dispatcher
08:22:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:22:58 DISPATCHER: Trying to submit another job.
08:22:58 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:22:58 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:22:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:22:58 WORKER: start processing job (8, 0, 8)
08:22:58 WORKER: args: ()
08:22:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 834, 'last_n_outputs': 38, 'leak_rate': 0.9244957959520738, 'lr': 0.0016752919819594963, 'optimizer': 'SGD', 'sparsity': 0.9737270404711591, 'steps_to_train': 82, 'weight_decay': 0.19850047416696093}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:23:32 DISPATCHER: Starting worker discovery
08:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:32 DISPATCHER: Finished worker discovery
08:23:52 WORKER: done with job (8, 0, 8), trying to register it.
08:23:52 WORKER: registered result for job (8, 0, 8) with dispatcher
08:23:52 DISPATCHER: job (8, 0, 8) finished
08:23:52 DISPATCHER: register_result: lock acquired
08:23:52 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:23:52 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 834, 'last_n_outputs': 38, 'leak_rate': 0.9244957959520738, 'lr': 0.0016752919819594963, 'optimizer': 'SGD', 'sparsity': 0.9737270404711591, 'steps_to_train': 82, 'weight_decay': 0.19850047416696093}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5672877635830817, 'info': {'data02': 0.5672877635830817, 'config': "{'batch_size': 64, 'hidden_dim': 834, 'last_n_outputs': 38, 'leak_rate': 0.9244957959520738, 'lr': 0.0016752919819594963, 'optimizer': 'SGD', 'sparsity': 0.9737270404711591, 'steps_to_train': 82, 'weight_decay': 0.19850047416696093}"}}
exception: None

08:23:52 job_callback for (8, 0, 8) started
08:23:52 DISPATCHER: Trying to submit another job.
08:23:52 job_callback for (8, 0, 8) got condition
08:23:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:23:52 HBMASTER: Trying to run another job!
08:23:52 job_callback for (8, 0, 8) finished
08:23:52 start sampling a new configuration.
08:23:52 done sampling a new configuration.
08:23:52 HBMASTER: schedule new run for iteration 8
08:23:52 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
08:23:52 HBMASTER: submitting job (8, 0, 9) to dispatcher
08:23:52 DISPATCHER: trying to submit job (8, 0, 9)
08:23:52 DISPATCHER: trying to notify the job_runner thread.
08:23:52 HBMASTER: job (8, 0, 9) submitted to dispatcher
08:23:52 DISPATCHER: Trying to submit another job.
08:23:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:23:52 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:23:52 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:23:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:23:52 WORKER: start processing job (8, 0, 9)
08:23:52 WORKER: args: ()
08:23:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 841, 'last_n_outputs': 14, 'leak_rate': 0.893727153959489, 'lr': 0.003111308365028233, 'optimizer': 'SGD', 'sparsity': 0.8070913585598998, 'steps_to_train': 67, 'weight_decay': 0.011613411364625221}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:24:32 DISPATCHER: Starting worker discovery
08:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:32 DISPATCHER: Finished worker discovery
08:24:43 WORKER: done with job (8, 0, 9), trying to register it.
08:24:43 WORKER: registered result for job (8, 0, 9) with dispatcher
08:24:43 DISPATCHER: job (8, 0, 9) finished
08:24:43 DISPATCHER: register_result: lock acquired
08:24:43 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:24:43 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 841, 'last_n_outputs': 14, 'leak_rate': 0.893727153959489, 'lr': 0.003111308365028233, 'optimizer': 'SGD', 'sparsity': 0.8070913585598998, 'steps_to_train': 67, 'weight_decay': 0.011613411364625221}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5171702789961046, 'info': {'data02': 0.5171702789961046, 'config': "{'batch_size': 16, 'hidden_dim': 841, 'last_n_outputs': 14, 'leak_rate': 0.893727153959489, 'lr': 0.003111308365028233, 'optimizer': 'SGD', 'sparsity': 0.8070913585598998, 'steps_to_train': 67, 'weight_decay': 0.011613411364625221}"}}
exception: None

08:24:43 job_callback for (8, 0, 9) started
08:24:43 DISPATCHER: Trying to submit another job.
08:24:43 job_callback for (8, 0, 9) got condition
08:24:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:24:43 HBMASTER: Trying to run another job!
08:24:43 job_callback for (8, 0, 9) finished
08:24:43 start sampling a new configuration.
08:24:43 best_vector: [0, 0.22817337247958702, 0.8318250958468918, 0.6584789831189163, 0.42649857009455516, 1, 0.7415298206426992, 0.9728161317650053, 0.8116929417586412], 0.004412198372373475, 1.6261476106152617, 0.007174885840795673
08:24:43 done sampling a new configuration.
08:24:43 HBMASTER: schedule new run for iteration 8
08:24:43 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
08:24:43 HBMASTER: submitting job (8, 0, 10) to dispatcher
08:24:43 DISPATCHER: trying to submit job (8, 0, 10)
08:24:43 DISPATCHER: trying to notify the job_runner thread.
08:24:43 HBMASTER: job (8, 0, 10) submitted to dispatcher
08:24:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:24:43 DISPATCHER: Trying to submit another job.
08:24:43 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:24:43 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:24:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:24:43 WORKER: start processing job (8, 0, 10)
08:24:43 WORKER: args: ()
08:24:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 382, 'last_n_outputs': 44, 'leak_rate': 0.914619745779729, 'lr': 0.007128483360347658, 'optimizer': 'SGD', 'sparsity': 0.9279671569542478, 'steps_to_train': 98, 'weight_decay': 0.11377238558676807}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:25:32 WORKER: done with job (8, 0, 10), trying to register it.
08:25:32 WORKER: registered result for job (8, 0, 10) with dispatcher
08:25:32 DISPATCHER: job (8, 0, 10) finished
08:25:32 DISPATCHER: register_result: lock acquired
08:25:32 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:25:32 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 382, 'last_n_outputs': 44, 'leak_rate': 0.914619745779729, 'lr': 0.007128483360347658, 'optimizer': 'SGD', 'sparsity': 0.9279671569542478, 'steps_to_train': 98, 'weight_decay': 0.11377238558676807}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6093937493651199, 'info': {'data02': 0.6093937493651199, 'config': "{'batch_size': 16, 'hidden_dim': 382, 'last_n_outputs': 44, 'leak_rate': 0.914619745779729, 'lr': 0.007128483360347658, 'optimizer': 'SGD', 'sparsity': 0.9279671569542478, 'steps_to_train': 98, 'weight_decay': 0.11377238558676807}"}}
exception: None

08:25:32 job_callback for (8, 0, 10) started
08:25:32 DISPATCHER: Trying to submit another job.
08:25:32 job_callback for (8, 0, 10) got condition
08:25:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:32 HBMASTER: Trying to run another job!
08:25:32 job_callback for (8, 0, 10) finished
08:25:32 start sampling a new configuration.
08:25:32 done sampling a new configuration.
08:25:32 HBMASTER: schedule new run for iteration 8
08:25:32 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
08:25:32 HBMASTER: submitting job (8, 0, 11) to dispatcher
08:25:32 DISPATCHER: trying to submit job (8, 0, 11)
08:25:32 DISPATCHER: trying to notify the job_runner thread.
08:25:32 HBMASTER: job (8, 0, 11) submitted to dispatcher
08:25:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:25:32 DISPATCHER: Trying to submit another job.
08:25:32 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:25:32 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:25:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:25:32 WORKER: start processing job (8, 0, 11)
08:25:32 WORKER: args: ()
08:25:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 270, 'last_n_outputs': 11, 'leak_rate': 0.9014667515734902, 'lr': 0.0014909607434677567, 'optimizer': 'Adam', 'sparsity': 0.7752562997245316, 'steps_to_train': 57, 'weight_decay': 0.07999795513817068}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:25:32 DISPATCHER: Starting worker discovery
08:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:32 DISPATCHER: Finished worker discovery
08:26:22 WORKER: done with job (8, 0, 11), trying to register it.
08:26:22 WORKER: registered result for job (8, 0, 11) with dispatcher
08:26:22 DISPATCHER: job (8, 0, 11) finished
08:26:22 DISPATCHER: register_result: lock acquired
08:26:22 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:26:22 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 270, 'last_n_outputs': 11, 'leak_rate': 0.9014667515734902, 'lr': 0.0014909607434677567, 'optimizer': 'Adam', 'sparsity': 0.7752562997245316, 'steps_to_train': 57, 'weight_decay': 0.07999795513817068}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36426641210878863, 'info': {'data02': 0.36426641210878863, 'config': "{'batch_size': 128, 'hidden_dim': 270, 'last_n_outputs': 11, 'leak_rate': 0.9014667515734902, 'lr': 0.0014909607434677567, 'optimizer': 'Adam', 'sparsity': 0.7752562997245316, 'steps_to_train': 57, 'weight_decay': 0.07999795513817068}"}}
exception: None

08:26:22 job_callback for (8, 0, 11) started
08:26:22 job_callback for (8, 0, 11) got condition
08:26:22 DISPATCHER: Trying to submit another job.
08:26:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:26:22 HBMASTER: Trying to run another job!
08:26:22 job_callback for (8, 0, 11) finished
08:26:22 start sampling a new configuration.
08:26:22 done sampling a new configuration.
08:26:22 HBMASTER: schedule new run for iteration 8
08:26:22 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
08:26:22 HBMASTER: submitting job (8, 0, 12) to dispatcher
08:26:22 DISPATCHER: trying to submit job (8, 0, 12)
08:26:22 DISPATCHER: trying to notify the job_runner thread.
08:26:22 HBMASTER: job (8, 0, 12) submitted to dispatcher
08:26:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:26:22 DISPATCHER: Trying to submit another job.
08:26:22 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:26:22 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:26:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:26:22 WORKER: start processing job (8, 0, 12)
08:26:22 WORKER: args: ()
08:26:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 695, 'last_n_outputs': 30, 'leak_rate': 0.8868347026805227, 'lr': 0.06298941653535771, 'optimizer': 'Adam', 'sparsity': 0.8929809183317434, 'steps_to_train': 76, 'weight_decay': 0.03295526966048545}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:26:32 DISPATCHER: Starting worker discovery
08:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:32 DISPATCHER: Finished worker discovery
08:27:13 WORKER: done with job (8, 0, 12), trying to register it.
08:27:13 WORKER: registered result for job (8, 0, 12) with dispatcher
08:27:13 DISPATCHER: job (8, 0, 12) finished
08:27:13 DISPATCHER: register_result: lock acquired
08:27:13 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:27:13 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 695, 'last_n_outputs': 30, 'leak_rate': 0.8868347026805227, 'lr': 0.06298941653535771, 'optimizer': 'Adam', 'sparsity': 0.8929809183317434, 'steps_to_train': 76, 'weight_decay': 0.03295526966048545}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10555922156242803, 'info': {'data02': 0.10555922156242803, 'config': "{'batch_size': 128, 'hidden_dim': 695, 'last_n_outputs': 30, 'leak_rate': 0.8868347026805227, 'lr': 0.06298941653535771, 'optimizer': 'Adam', 'sparsity': 0.8929809183317434, 'steps_to_train': 76, 'weight_decay': 0.03295526966048545}"}}
exception: None

08:27:13 job_callback for (8, 0, 12) started
08:27:13 job_callback for (8, 0, 12) got condition
08:27:13 DISPATCHER: Trying to submit another job.
08:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:27:13 HBMASTER: Trying to run another job!
08:27:13 job_callback for (8, 0, 12) finished
08:27:13 start sampling a new configuration.
08:27:13 done sampling a new configuration.
08:27:13 HBMASTER: schedule new run for iteration 8
08:27:13 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
08:27:13 HBMASTER: submitting job (8, 0, 13) to dispatcher
08:27:13 DISPATCHER: trying to submit job (8, 0, 13)
08:27:13 DISPATCHER: trying to notify the job_runner thread.
08:27:13 HBMASTER: job (8, 0, 13) submitted to dispatcher
08:27:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:27:13 DISPATCHER: Trying to submit another job.
08:27:13 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:27:13 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:27:13 WORKER: start processing job (8, 0, 13)
08:27:13 WORKER: args: ()
08:27:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 976, 'last_n_outputs': 24, 'leak_rate': 0.7519631025165057, 'lr': 0.0020225809023563046, 'optimizer': 'SGD', 'sparsity': 0.8997067692787427, 'steps_to_train': 17, 'weight_decay': 0.055301004084674664}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:27:32 DISPATCHER: Starting worker discovery
08:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:32 DISPATCHER: Finished worker discovery
08:28:03 WORKER: done with job (8, 0, 13), trying to register it.
08:28:03 WORKER: registered result for job (8, 0, 13) with dispatcher
08:28:03 DISPATCHER: job (8, 0, 13) finished
08:28:03 DISPATCHER: register_result: lock acquired
08:28:03 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:28:03 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 976, 'last_n_outputs': 24, 'leak_rate': 0.7519631025165057, 'lr': 0.0020225809023563046, 'optimizer': 'SGD', 'sparsity': 0.8997067692787427, 'steps_to_train': 17, 'weight_decay': 0.055301004084674664}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4954646196257655, 'info': {'data02': 0.4954646196257655, 'config': "{'batch_size': 64, 'hidden_dim': 976, 'last_n_outputs': 24, 'leak_rate': 0.7519631025165057, 'lr': 0.0020225809023563046, 'optimizer': 'SGD', 'sparsity': 0.8997067692787427, 'steps_to_train': 17, 'weight_decay': 0.055301004084674664}"}}
exception: None

08:28:03 job_callback for (8, 0, 13) started
08:28:03 DISPATCHER: Trying to submit another job.
08:28:03 job_callback for (8, 0, 13) got condition
08:28:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:28:03 HBMASTER: Trying to run another job!
08:28:03 job_callback for (8, 0, 13) finished
08:28:03 start sampling a new configuration.
08:28:03 best_vector: [3, 0.19178376454715965, 0.8235442441738883, 0.6771831561517749, 0.01757918012982751, 1, 0.9880757203974772, 0.9772048611792632, 0.7607703312328385], 0.008213378348023277, 1.209220310700068, 0.009931783917893918
08:28:03 done sampling a new configuration.
08:28:03 HBMASTER: schedule new run for iteration 8
08:28:03 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
08:28:03 HBMASTER: submitting job (8, 0, 14) to dispatcher
08:28:03 DISPATCHER: trying to submit job (8, 0, 14)
08:28:03 DISPATCHER: trying to notify the job_runner thread.
08:28:03 HBMASTER: job (8, 0, 14) submitted to dispatcher
08:28:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:28:03 DISPATCHER: Trying to submit another job.
08:28:03 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:28:03 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:28:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:28:03 WORKER: start processing job (8, 0, 14)
08:28:03 WORKER: args: ()
08:28:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 353, 'last_n_outputs': 43, 'leak_rate': 0.9192957890379437, 'lr': 0.0010843222270029158, 'optimizer': 'SGD', 'sparsity': 0.9871381728953945, 'steps_to_train': 98, 'weight_decay': 0.09767536003945407}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:28:32 DISPATCHER: Starting worker discovery
08:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:32 DISPATCHER: Finished worker discovery
08:28:53 WORKER: done with job (8, 0, 14), trying to register it.
08:28:53 WORKER: registered result for job (8, 0, 14) with dispatcher
08:28:53 DISPATCHER: job (8, 0, 14) finished
08:28:53 DISPATCHER: register_result: lock acquired
08:28:53 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:28:53 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 353, 'last_n_outputs': 43, 'leak_rate': 0.9192957890379437, 'lr': 0.0010843222270029158, 'optimizer': 'SGD', 'sparsity': 0.9871381728953945, 'steps_to_train': 98, 'weight_decay': 0.09767536003945407}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4062678885497716, 'info': {'data02': 0.4062678885497716, 'config': "{'batch_size': 128, 'hidden_dim': 353, 'last_n_outputs': 43, 'leak_rate': 0.9192957890379437, 'lr': 0.0010843222270029158, 'optimizer': 'SGD', 'sparsity': 0.9871381728953945, 'steps_to_train': 98, 'weight_decay': 0.09767536003945407}"}}
exception: None

08:28:53 job_callback for (8, 0, 14) started
08:28:53 job_callback for (8, 0, 14) got condition
08:28:53 DISPATCHER: Trying to submit another job.
08:28:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:28:53 HBMASTER: Trying to run another job!
08:28:53 job_callback for (8, 0, 14) finished
08:28:53 start sampling a new configuration.
08:28:53 done sampling a new configuration.
08:28:53 HBMASTER: schedule new run for iteration 8
08:28:53 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
08:28:53 HBMASTER: submitting job (8, 0, 15) to dispatcher
08:28:53 DISPATCHER: trying to submit job (8, 0, 15)
08:28:53 DISPATCHER: trying to notify the job_runner thread.
08:28:53 HBMASTER: job (8, 0, 15) submitted to dispatcher
08:28:53 DISPATCHER: Trying to submit another job.
08:28:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:28:53 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:28:53 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:28:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:28:53 WORKER: start processing job (8, 0, 15)
08:28:53 WORKER: args: ()
08:28:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 727, 'last_n_outputs': 50, 'leak_rate': 0.8510360157536643, 'lr': 0.0016084881314199053, 'optimizer': 'SGD', 'sparsity': 0.9332489910154469, 'steps_to_train': 23, 'weight_decay': 0.02270192164945138}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:29:32 DISPATCHER: Starting worker discovery
08:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:32 DISPATCHER: Finished worker discovery
08:29:43 WORKER: done with job (8, 0, 15), trying to register it.
08:29:43 WORKER: registered result for job (8, 0, 15) with dispatcher
08:29:43 DISPATCHER: job (8, 0, 15) finished
08:29:43 DISPATCHER: register_result: lock acquired
08:29:43 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:29:43 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 727, 'last_n_outputs': 50, 'leak_rate': 0.8510360157536643, 'lr': 0.0016084881314199053, 'optimizer': 'SGD', 'sparsity': 0.9332489910154469, 'steps_to_train': 23, 'weight_decay': 0.02270192164945138}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5534821722647638, 'info': {'data02': 0.5534821722647638, 'config': "{'batch_size': 128, 'hidden_dim': 727, 'last_n_outputs': 50, 'leak_rate': 0.8510360157536643, 'lr': 0.0016084881314199053, 'optimizer': 'SGD', 'sparsity': 0.9332489910154469, 'steps_to_train': 23, 'weight_decay': 0.02270192164945138}"}}
exception: None

08:29:43 job_callback for (8, 0, 15) started
08:29:43 DISPATCHER: Trying to submit another job.
08:29:43 job_callback for (8, 0, 15) got condition
08:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:29:43 HBMASTER: Trying to run another job!
08:29:43 job_callback for (8, 0, 15) finished
08:29:43 start sampling a new configuration.
08:29:43 best_vector: [1, 0.8834145040198846, 0.9640877660357863, 0.7267088543269146, 0.7425200361300398, 0, 0.9727488104849682, 0.1560273498349583, 0.1370132974093134], 0.0, inf, 0.00971905941430268
08:29:43 done sampling a new configuration.
08:29:43 HBMASTER: schedule new run for iteration 8
08:29:43 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
08:29:43 HBMASTER: submitting job (8, 0, 16) to dispatcher
08:29:43 DISPATCHER: trying to submit job (8, 0, 16)
08:29:43 DISPATCHER: trying to notify the job_runner thread.
08:29:43 HBMASTER: job (8, 0, 16) submitted to dispatcher
08:29:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:29:43 DISPATCHER: Trying to submit another job.
08:29:43 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:29:43 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:29:43 WORKER: start processing job (8, 0, 16)
08:29:43 WORKER: args: ()
08:29:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 907, 'last_n_outputs': 49, 'leak_rate': 0.9316772135817286, 'lr': 0.03055203003145894, 'optimizer': 'Adam', 'sparsity': 0.9834597145163924, 'steps_to_train': 24, 'weight_decay': 0.015075037798136506}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:30:32 DISPATCHER: Starting worker discovery
08:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:32 DISPATCHER: Finished worker discovery
08:30:33 WORKER: done with job (8, 0, 16), trying to register it.
08:30:33 WORKER: registered result for job (8, 0, 16) with dispatcher
08:30:33 DISPATCHER: job (8, 0, 16) finished
08:30:33 DISPATCHER: register_result: lock acquired
08:30:33 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:30:33 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 907, 'last_n_outputs': 49, 'leak_rate': 0.9316772135817286, 'lr': 0.03055203003145894, 'optimizer': 'Adam', 'sparsity': 0.9834597145163924, 'steps_to_train': 24, 'weight_decay': 0.015075037798136506}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42105367872579885, 'info': {'data02': 0.42105367872579885, 'config': "{'batch_size': 32, 'hidden_dim': 907, 'last_n_outputs': 49, 'leak_rate': 0.9316772135817286, 'lr': 0.03055203003145894, 'optimizer': 'Adam', 'sparsity': 0.9834597145163924, 'steps_to_train': 24, 'weight_decay': 0.015075037798136506}"}}
exception: None

08:30:33 job_callback for (8, 0, 16) started
08:30:33 job_callback for (8, 0, 16) got condition
08:30:33 DISPATCHER: Trying to submit another job.
08:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:30:33 HBMASTER: Trying to run another job!
08:30:33 job_callback for (8, 0, 16) finished
08:30:33 start sampling a new configuration.
08:30:33 best_vector: [0, 0.5143000957744133, 0.8796917150760446, 0.7030755215781107, 0.26251761304613286, 1, 0.7143898545002716, 0.8803526457118814, 0.8429680823101784], 0.0014571874231019567, 3.488929175773161, 0.005084023715030126
08:30:33 done sampling a new configuration.
08:30:33 HBMASTER: schedule new run for iteration 8
08:30:33 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
08:30:33 HBMASTER: submitting job (8, 0, 17) to dispatcher
08:30:33 DISPATCHER: trying to submit job (8, 0, 17)
08:30:33 DISPATCHER: trying to notify the job_runner thread.
08:30:33 HBMASTER: job (8, 0, 17) submitted to dispatcher
08:30:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:30:33 DISPATCHER: Trying to submit another job.
08:30:33 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:30:33 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:30:33 WORKER: start processing job (8, 0, 17)
08:30:33 WORKER: args: ()
08:30:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:31:23 WORKER: done with job (8, 0, 17), trying to register it.
08:31:23 WORKER: registered result for job (8, 0, 17) with dispatcher
08:31:23 DISPATCHER: job (8, 0, 17) finished
08:31:23 DISPATCHER: register_result: lock acquired
08:31:23 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:31:23 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5977223149615154, 'info': {'data02': 0.5977223149615154, 'config': "{'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}"}}
exception: None

08:31:23 job_callback for (8, 0, 17) started
08:31:23 job_callback for (8, 0, 17) got condition
08:31:23 DISPATCHER: Trying to submit another job.
08:31:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:31:23 HBMASTER: Trying to run another job!
08:31:23 job_callback for (8, 0, 17) finished
08:31:23 start sampling a new configuration.
08:31:23 done sampling a new configuration.
08:31:23 HBMASTER: schedule new run for iteration 8
08:31:23 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
08:31:23 HBMASTER: submitting job (8, 0, 18) to dispatcher
08:31:23 DISPATCHER: trying to submit job (8, 0, 18)
08:31:23 DISPATCHER: trying to notify the job_runner thread.
08:31:23 HBMASTER: job (8, 0, 18) submitted to dispatcher
08:31:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:31:23 DISPATCHER: Trying to submit another job.
08:31:23 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:31:23 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:31:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:31:23 WORKER: start processing job (8, 0, 18)
08:31:23 WORKER: args: ()
08:31:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 987, 'last_n_outputs': 22, 'leak_rate': 0.8644729908625108, 'lr': 0.012190807998271956, 'optimizer': 'SGD', 'sparsity': 0.9030360476236321, 'steps_to_train': 72, 'weight_decay': 0.026863396331784733}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:31:32 DISPATCHER: Starting worker discovery
08:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:32 DISPATCHER: Finished worker discovery
08:32:13 WORKER: done with job (8, 0, 18), trying to register it.
08:32:13 WORKER: registered result for job (8, 0, 18) with dispatcher
08:32:13 DISPATCHER: job (8, 0, 18) finished
08:32:13 DISPATCHER: register_result: lock acquired
08:32:13 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:32:13 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 987, 'last_n_outputs': 22, 'leak_rate': 0.8644729908625108, 'lr': 0.012190807998271956, 'optimizer': 'SGD', 'sparsity': 0.9030360476236321, 'steps_to_train': 72, 'weight_decay': 0.026863396331784733}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46925818555241655, 'info': {'data02': 0.46925818555241655, 'config': "{'batch_size': 128, 'hidden_dim': 987, 'last_n_outputs': 22, 'leak_rate': 0.8644729908625108, 'lr': 0.012190807998271956, 'optimizer': 'SGD', 'sparsity': 0.9030360476236321, 'steps_to_train': 72, 'weight_decay': 0.026863396331784733}"}}
exception: None

08:32:13 job_callback for (8, 0, 18) started
08:32:13 job_callback for (8, 0, 18) got condition
08:32:13 DISPATCHER: Trying to submit another job.
08:32:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:32:13 HBMASTER: Trying to run another job!
08:32:13 job_callback for (8, 0, 18) finished
08:32:13 start sampling a new configuration.
08:32:13 best_vector: [1, 0.8772959747524967, 0.6428531885584967, 0.9029008647865643, 0.7997448429272075, 1, 0.08160510274383298, 0.5649768502188373, 0.02421264515167154], 0.01933383194597485, 0.06908046368841542, 0.0013355900757018415
08:32:13 done sampling a new configuration.
08:32:13 HBMASTER: schedule new run for iteration 8
08:32:13 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
08:32:13 HBMASTER: submitting job (8, 0, 19) to dispatcher
08:32:13 DISPATCHER: trying to submit job (8, 0, 19)
08:32:13 DISPATCHER: trying to notify the job_runner thread.
08:32:13 HBMASTER: job (8, 0, 19) submitted to dispatcher
08:32:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:32:13 DISPATCHER: Trying to submit another job.
08:32:13 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:32:13 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:32:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:32:13 WORKER: start processing job (8, 0, 19)
08:32:13 WORKER: args: ()
08:32:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 902, 'last_n_outputs': 36, 'leak_rate': 0.9757252161966411, 'lr': 0.039763965273963135, 'optimizer': 'SGD', 'sparsity': 0.7695852246585199, 'steps_to_train': 61, 'weight_decay': 0.010752300111025652}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:32:32 DISPATCHER: Starting worker discovery
08:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:32 DISPATCHER: Finished worker discovery
08:33:05 WORKER: done with job (8, 0, 19), trying to register it.
08:33:05 WORKER: registered result for job (8, 0, 19) with dispatcher
08:33:05 DISPATCHER: job (8, 0, 19) finished
08:33:05 DISPATCHER: register_result: lock acquired
08:33:05 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:33:05 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 902, 'last_n_outputs': 36, 'leak_rate': 0.9757252161966411, 'lr': 0.039763965273963135, 'optimizer': 'SGD', 'sparsity': 0.7695852246585199, 'steps_to_train': 61, 'weight_decay': 0.010752300111025652}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.569021148863055, 'info': {'data02': 0.569021148863055, 'config': "{'batch_size': 32, 'hidden_dim': 902, 'last_n_outputs': 36, 'leak_rate': 0.9757252161966411, 'lr': 0.039763965273963135, 'optimizer': 'SGD', 'sparsity': 0.7695852246585199, 'steps_to_train': 61, 'weight_decay': 0.010752300111025652}"}}
exception: None

08:33:05 job_callback for (8, 0, 19) started
08:33:05 job_callback for (8, 0, 19) got condition
08:33:05 DISPATCHER: Trying to submit another job.
08:33:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:33:05 HBMASTER: Trying to run another job!
08:33:05 job_callback for (8, 0, 19) finished
08:33:05 start sampling a new configuration.
08:33:05 done sampling a new configuration.
08:33:05 HBMASTER: schedule new run for iteration 8
08:33:05 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
08:33:05 HBMASTER: submitting job (8, 0, 20) to dispatcher
08:33:05 DISPATCHER: trying to submit job (8, 0, 20)
08:33:05 DISPATCHER: trying to notify the job_runner thread.
08:33:05 HBMASTER: job (8, 0, 20) submitted to dispatcher
08:33:05 DISPATCHER: Trying to submit another job.
08:33:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:33:05 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:33:05 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:33:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:33:05 WORKER: start processing job (8, 0, 20)
08:33:05 WORKER: args: ()
08:33:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:33:32 DISPATCHER: Starting worker discovery
08:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:32 DISPATCHER: Finished worker discovery
08:33:54 WORKER: done with job (8, 0, 20), trying to register it.
08:33:54 WORKER: registered result for job (8, 0, 20) with dispatcher
08:33:54 DISPATCHER: job (8, 0, 20) finished
08:33:54 DISPATCHER: register_result: lock acquired
08:33:54 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:33:54 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6048373485723068, 'info': {'data02': 0.6048373485723068, 'config': "{'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}"}}
exception: None

08:33:54 job_callback for (8, 0, 20) started
08:33:54 DISPATCHER: Trying to submit another job.
08:33:54 job_callback for (8, 0, 20) got condition
08:33:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:33:54 HBMASTER: Trying to run another job!
08:33:54 job_callback for (8, 0, 20) finished
08:33:54 start sampling a new configuration.
08:33:54 best_vector: [2, 0.6193739911103613, 0.7741125083389502, 0.893480887164629, 0.9292885002061577, 1, 0.486657785193815, 0.707265129699377, 0.27498048537496217], 0.015024207502104198, 0.16916024769264765, 0.002541498662441681
08:33:54 done sampling a new configuration.
08:33:54 HBMASTER: schedule new run for iteration 8
08:33:54 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
08:33:54 HBMASTER: submitting job (8, 0, 21) to dispatcher
08:33:54 DISPATCHER: trying to submit job (8, 0, 21)
08:33:54 DISPATCHER: trying to notify the job_runner thread.
08:33:54 HBMASTER: job (8, 0, 21) submitted to dispatcher
08:33:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:33:54 DISPATCHER: Trying to submit another job.
08:33:54 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:33:54 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:33:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:33:54 WORKER: start processing job (8, 0, 21)
08:33:54 WORKER: args: ()
08:33:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 696, 'last_n_outputs': 41, 'leak_rate': 0.9733702217911573, 'lr': 0.07220661739224074, 'optimizer': 'SGD', 'sparsity': 0.8667978684465156, 'steps_to_train': 74, 'weight_decay': 0.022790710247099746}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:34:32 DISPATCHER: Starting worker discovery
08:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:32 DISPATCHER: Finished worker discovery
08:34:46 WORKER: done with job (8, 0, 21), trying to register it.
08:34:46 WORKER: registered result for job (8, 0, 21) with dispatcher
08:34:46 DISPATCHER: job (8, 0, 21) finished
08:34:46 DISPATCHER: register_result: lock acquired
08:34:46 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:34:46 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 696, 'last_n_outputs': 41, 'leak_rate': 0.9733702217911573, 'lr': 0.07220661739224074, 'optimizer': 'SGD', 'sparsity': 0.8667978684465156, 'steps_to_train': 74, 'weight_decay': 0.022790710247099746}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5237149944173018, 'info': {'data02': 0.5237149944173018, 'config': "{'batch_size': 64, 'hidden_dim': 696, 'last_n_outputs': 41, 'leak_rate': 0.9733702217911573, 'lr': 0.07220661739224074, 'optimizer': 'SGD', 'sparsity': 0.8667978684465156, 'steps_to_train': 74, 'weight_decay': 0.022790710247099746}"}}
exception: None

08:34:46 job_callback for (8, 0, 21) started
08:34:46 DISPATCHER: Trying to submit another job.
08:34:46 job_callback for (8, 0, 21) got condition
08:34:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:34:46 HBMASTER: Trying to run another job!
08:34:46 job_callback for (8, 0, 21) finished
08:34:46 start sampling a new configuration.
08:34:46 done sampling a new configuration.
08:34:46 HBMASTER: schedule new run for iteration 8
08:34:46 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
08:34:46 HBMASTER: submitting job (8, 0, 22) to dispatcher
08:34:46 DISPATCHER: trying to submit job (8, 0, 22)
08:34:46 DISPATCHER: trying to notify the job_runner thread.
08:34:46 HBMASTER: job (8, 0, 22) submitted to dispatcher
08:34:46 DISPATCHER: Trying to submit another job.
08:34:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:34:46 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:34:46 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:34:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:34:46 WORKER: start processing job (8, 0, 22)
08:34:46 WORKER: args: ()
08:34:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 912, 'last_n_outputs': 47, 'leak_rate': 0.9969741524282257, 'lr': 0.06277910890822745, 'optimizer': 'SGD', 'sparsity': 0.891401765138929, 'steps_to_train': 93, 'weight_decay': 0.1585865759466749}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:35:32 DISPATCHER: Starting worker discovery
08:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:32 DISPATCHER: Finished worker discovery
08:35:35 WORKER: done with job (8, 0, 22), trying to register it.
08:35:35 WORKER: registered result for job (8, 0, 22) with dispatcher
08:35:35 DISPATCHER: job (8, 0, 22) finished
08:35:35 DISPATCHER: register_result: lock acquired
08:35:35 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:35:35 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 912, 'last_n_outputs': 47, 'leak_rate': 0.9969741524282257, 'lr': 0.06277910890822745, 'optimizer': 'SGD', 'sparsity': 0.891401765138929, 'steps_to_train': 93, 'weight_decay': 0.1585865759466749}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44862383442500614, 'info': {'data02': 0.44862383442500614, 'config': "{'batch_size': 128, 'hidden_dim': 912, 'last_n_outputs': 47, 'leak_rate': 0.9969741524282257, 'lr': 0.06277910890822745, 'optimizer': 'SGD', 'sparsity': 0.891401765138929, 'steps_to_train': 93, 'weight_decay': 0.1585865759466749}"}}
exception: None

08:35:35 job_callback for (8, 0, 22) started
08:35:35 DISPATCHER: Trying to submit another job.
08:35:35 job_callback for (8, 0, 22) got condition
08:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:35:35 HBMASTER: Trying to run another job!
08:35:35 job_callback for (8, 0, 22) finished
08:35:35 start sampling a new configuration.
08:35:35 best_vector: [0, 0.7009605646559919, 0.5236336986784631, 0.7610506784926241, 0.5150330221104384, 1, 0.8723921897347658, 0.8823477634848962, 0.1668481306932983], 0.007475609524396822, 1.0631843727476966, 0.007947951223102542
08:35:35 done sampling a new configuration.
08:35:35 HBMASTER: schedule new run for iteration 8
08:35:35 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
08:35:35 HBMASTER: submitting job (8, 0, 23) to dispatcher
08:35:35 DISPATCHER: trying to submit job (8, 0, 23)
08:35:35 DISPATCHER: trying to notify the job_runner thread.
08:35:35 HBMASTER: job (8, 0, 23) submitted to dispatcher
08:35:35 DISPATCHER: Trying to submit another job.
08:35:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:35:35 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:35:35 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:35:35 WORKER: start processing job (8, 0, 23)
08:35:35 WORKER: args: ()
08:35:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 761, 'last_n_outputs': 31, 'leak_rate': 0.940262669623156, 'lr': 0.01071682266181842, 'optimizer': 'SGD', 'sparsity': 0.9593741255363438, 'steps_to_train': 90, 'weight_decay': 0.016484448526140817}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:36:27 WORKER: done with job (8, 0, 23), trying to register it.
08:36:27 WORKER: registered result for job (8, 0, 23) with dispatcher
08:36:27 DISPATCHER: job (8, 0, 23) finished
08:36:27 DISPATCHER: register_result: lock acquired
08:36:27 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:36:27 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 761, 'last_n_outputs': 31, 'leak_rate': 0.940262669623156, 'lr': 0.01071682266181842, 'optimizer': 'SGD', 'sparsity': 0.9593741255363438, 'steps_to_train': 90, 'weight_decay': 0.016484448526140817}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46301858249480304, 'info': {'data02': 0.46301858249480304, 'config': "{'batch_size': 16, 'hidden_dim': 761, 'last_n_outputs': 31, 'leak_rate': 0.940262669623156, 'lr': 0.01071682266181842, 'optimizer': 'SGD', 'sparsity': 0.9593741255363438, 'steps_to_train': 90, 'weight_decay': 0.016484448526140817}"}}
exception: None

08:36:27 job_callback for (8, 0, 23) started
08:36:27 DISPATCHER: Trying to submit another job.
08:36:27 job_callback for (8, 0, 23) got condition
08:36:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:36:27 HBMASTER: Trying to run another job!
08:36:27 job_callback for (8, 0, 23) finished
08:36:27 start sampling a new configuration.
08:36:27 best_vector: [2, 0.8942847983408804, 0.7738913038632802, 0.9252173944770552, 0.7759614753327582, 1, 0.19639628921774233, 0.23714660216113864, 0.08254643222794186], 0.003517232892064496, 0.9166854744570676, 0.0032241963024381465
08:36:27 done sampling a new configuration.
08:36:27 HBMASTER: schedule new run for iteration 8
08:36:27 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
08:36:27 HBMASTER: submitting job (8, 0, 24) to dispatcher
08:36:27 DISPATCHER: trying to submit job (8, 0, 24)
08:36:27 DISPATCHER: trying to notify the job_runner thread.
08:36:27 HBMASTER: job (8, 0, 24) submitted to dispatcher
08:36:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:36:27 DISPATCHER: Trying to submit another job.
08:36:27 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:36:27 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:36:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:36:27 WORKER: start processing job (8, 0, 24)
08:36:27 WORKER: args: ()
08:36:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 916, 'last_n_outputs': 41, 'leak_rate': 0.9813043486192639, 'lr': 0.03563879000957838, 'optimizer': 'SGD', 'sparsity': 0.7971351094122582, 'steps_to_train': 31, 'weight_decay': 0.012805465911160191}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:36:32 DISPATCHER: Starting worker discovery
08:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:32 DISPATCHER: Finished worker discovery
08:37:18 WORKER: done with job (8, 0, 24), trying to register it.
08:37:18 WORKER: registered result for job (8, 0, 24) with dispatcher
08:37:18 DISPATCHER: job (8, 0, 24) finished
08:37:18 DISPATCHER: register_result: lock acquired
08:37:18 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:37:18 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 916, 'last_n_outputs': 41, 'leak_rate': 0.9813043486192639, 'lr': 0.03563879000957838, 'optimizer': 'SGD', 'sparsity': 0.7971351094122582, 'steps_to_train': 31, 'weight_decay': 0.012805465911160191}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6000964370338133, 'info': {'data02': 0.6000964370338133, 'config': "{'batch_size': 64, 'hidden_dim': 916, 'last_n_outputs': 41, 'leak_rate': 0.9813043486192639, 'lr': 0.03563879000957838, 'optimizer': 'SGD', 'sparsity': 0.7971351094122582, 'steps_to_train': 31, 'weight_decay': 0.012805465911160191}"}}
exception: None

08:37:18 job_callback for (8, 0, 24) started
08:37:18 DISPATCHER: Trying to submit another job.
08:37:18 job_callback for (8, 0, 24) got condition
08:37:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:37:18 HBMASTER: Trying to run another job!
08:37:18 job_callback for (8, 0, 24) finished
08:37:18 start sampling a new configuration.
08:37:18 best_vector: [0, 0.34859450912263534, 0.8316532837862288, 0.5890847085549062, 0.08858706907848146, 1, 0.473133942947808, 0.809775770872334, 0.4150696025211976], 0.00985118255627604, 1.6023219877903305, 0.015784766415657656
08:37:18 done sampling a new configuration.
08:37:18 HBMASTER: schedule new run for iteration 8
08:37:18 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
08:37:18 HBMASTER: submitting job (8, 0, 25) to dispatcher
08:37:18 DISPATCHER: trying to submit job (8, 0, 25)
08:37:18 DISPATCHER: trying to notify the job_runner thread.
08:37:18 HBMASTER: job (8, 0, 25) submitted to dispatcher
08:37:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:37:18 DISPATCHER: Trying to submit another job.
08:37:18 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:37:18 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:37:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:37:18 WORKER: start processing job (8, 0, 25)
08:37:18 WORKER: args: ()
08:37:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 479, 'last_n_outputs': 44, 'leak_rate': 0.8972711771387265, 'lr': 0.0015037447986543443, 'optimizer': 'SGD', 'sparsity': 0.8635521463074739, 'steps_to_train': 83, 'weight_decay': 0.0346751224319936}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:37:32 DISPATCHER: Starting worker discovery
08:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:32 DISPATCHER: Finished worker discovery
08:38:09 WORKER: done with job (8, 0, 25), trying to register it.
08:38:09 WORKER: registered result for job (8, 0, 25) with dispatcher
08:38:09 DISPATCHER: job (8, 0, 25) finished
08:38:09 DISPATCHER: register_result: lock acquired
08:38:09 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:38:09 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 479, 'last_n_outputs': 44, 'leak_rate': 0.8972711771387265, 'lr': 0.0015037447986543443, 'optimizer': 'SGD', 'sparsity': 0.8635521463074739, 'steps_to_train': 83, 'weight_decay': 0.0346751224319936}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.572562154441044, 'info': {'data02': 0.572562154441044, 'config': "{'batch_size': 16, 'hidden_dim': 479, 'last_n_outputs': 44, 'leak_rate': 0.8972711771387265, 'lr': 0.0015037447986543443, 'optimizer': 'SGD', 'sparsity': 0.8635521463074739, 'steps_to_train': 83, 'weight_decay': 0.0346751224319936}"}}
exception: None

08:38:09 job_callback for (8, 0, 25) started
08:38:09 job_callback for (8, 0, 25) got condition
08:38:09 DISPATCHER: Trying to submit another job.
08:38:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:38:09 HBMASTER: Trying to run another job!
08:38:09 job_callback for (8, 0, 25) finished
08:38:09 start sampling a new configuration.
08:38:09 best_vector: [2, 0.862473115066891, 0.8283595014677788, 0.6910721194913892, 0.8068458794383903, 1, 0.9580238534566929, 0.2696261049245668, 0.028910235077291513], 0.004464363203031509, 2.7461237536378906, 0.012259693836711763
08:38:09 done sampling a new configuration.
08:38:09 HBMASTER: schedule new run for iteration 8
08:38:09 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
08:38:09 HBMASTER: submitting job (8, 0, 26) to dispatcher
08:38:09 DISPATCHER: trying to submit job (8, 0, 26)
08:38:09 DISPATCHER: trying to notify the job_runner thread.
08:38:09 HBMASTER: job (8, 0, 26) submitted to dispatcher
08:38:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:38:09 DISPATCHER: Trying to submit another job.
08:38:09 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:38:09 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:38:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:38:09 WORKER: start processing job (8, 0, 26)
08:38:09 WORKER: args: ()
08:38:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 890, 'last_n_outputs': 43, 'leak_rate': 0.9227680298728473, 'lr': 0.04108580105412767, 'optimizer': 'SGD', 'sparsity': 0.9799257248296063, 'steps_to_train': 34, 'weight_decay': 0.01090468395148099}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:38:32 DISPATCHER: Starting worker discovery
08:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:32 DISPATCHER: Finished worker discovery
08:39:00 WORKER: done with job (8, 0, 26), trying to register it.
08:39:00 WORKER: registered result for job (8, 0, 26) with dispatcher
08:39:00 DISPATCHER: job (8, 0, 26) finished
08:39:00 DISPATCHER: register_result: lock acquired
08:39:00 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:39:00 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 890, 'last_n_outputs': 43, 'leak_rate': 0.9227680298728473, 'lr': 0.04108580105412767, 'optimizer': 'SGD', 'sparsity': 0.9799257248296063, 'steps_to_train': 34, 'weight_decay': 0.01090468395148099}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5657430771734563, 'info': {'data02': 0.5657430771734563, 'config': "{'batch_size': 64, 'hidden_dim': 890, 'last_n_outputs': 43, 'leak_rate': 0.9227680298728473, 'lr': 0.04108580105412767, 'optimizer': 'SGD', 'sparsity': 0.9799257248296063, 'steps_to_train': 34, 'weight_decay': 0.01090468395148099}"}}
exception: None

08:39:00 job_callback for (8, 0, 26) started
08:39:00 DISPATCHER: Trying to submit another job.
08:39:00 job_callback for (8, 0, 26) got condition
08:39:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:39:00 HBMASTER: Trying to run another job!
08:39:00 job_callback for (8, 0, 26) finished
08:39:00 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
08:39:00 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
08:39:00 HBMASTER: schedule new run for iteration 8
08:39:00 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
08:39:00 HBMASTER: submitting job (8, 0, 0) to dispatcher
08:39:00 DISPATCHER: trying to submit job (8, 0, 0)
08:39:00 DISPATCHER: trying to notify the job_runner thread.
08:39:00 HBMASTER: job (8, 0, 0) submitted to dispatcher
08:39:00 DISPATCHER: Trying to submit another job.
08:39:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:39:00 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:39:00 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:39:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:39:00 WORKER: start processing job (8, 0, 0)
08:39:00 WORKER: args: ()
08:39:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 28, 'leak_rate': 0.8594078736532025, 'lr': 0.027475983514222264, 'optimizer': 'SGD', 'sparsity': 0.9207570444125829, 'steps_to_train': 37, 'weight_decay': 0.010672465365113085}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:39:32 DISPATCHER: Starting worker discovery
08:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:32 DISPATCHER: Finished worker discovery
08:40:32 DISPATCHER: Starting worker discovery
08:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:32 DISPATCHER: Finished worker discovery
08:41:18 WORKER: done with job (8, 0, 0), trying to register it.
08:41:18 WORKER: registered result for job (8, 0, 0) with dispatcher
08:41:18 DISPATCHER: job (8, 0, 0) finished
08:41:18 DISPATCHER: register_result: lock acquired
08:41:18 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:41:18 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 28, 'leak_rate': 0.8594078736532025, 'lr': 0.027475983514222264, 'optimizer': 'SGD', 'sparsity': 0.9207570444125829, 'steps_to_train': 37, 'weight_decay': 0.010672465365113085}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5819034091219116, 'info': {'data02': 0.5819034091219116, 'config': "{'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 28, 'leak_rate': 0.8594078736532025, 'lr': 0.027475983514222264, 'optimizer': 'SGD', 'sparsity': 0.9207570444125829, 'steps_to_train': 37, 'weight_decay': 0.010672465365113085}"}}
exception: None

08:41:18 job_callback for (8, 0, 0) started
08:41:18 DISPATCHER: Trying to submit another job.
08:41:18 job_callback for (8, 0, 0) got condition
08:41:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:41:18 HBMASTER: Trying to run another job!
08:41:18 job_callback for (8, 0, 0) finished
08:41:18 HBMASTER: schedule new run for iteration 8
08:41:18 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
08:41:18 HBMASTER: submitting job (8, 0, 1) to dispatcher
08:41:18 DISPATCHER: trying to submit job (8, 0, 1)
08:41:18 DISPATCHER: trying to notify the job_runner thread.
08:41:18 HBMASTER: job (8, 0, 1) submitted to dispatcher
08:41:18 DISPATCHER: Trying to submit another job.
08:41:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:41:18 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:41:18 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:41:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:41:18 WORKER: start processing job (8, 0, 1)
08:41:18 WORKER: args: ()
08:41:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 348, 'last_n_outputs': 46, 'leak_rate': 0.9042239137630683, 'lr': 0.001766019129432892, 'optimizer': 'SGD', 'sparsity': 0.8705966282481502, 'steps_to_train': 78, 'weight_decay': 0.07243398082550546}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:41:32 DISPATCHER: Starting worker discovery
08:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:32 DISPATCHER: Finished worker discovery
08:42:32 DISPATCHER: Starting worker discovery
08:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:32 DISPATCHER: Finished worker discovery
08:43:32 DISPATCHER: Starting worker discovery
08:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:32 DISPATCHER: Finished worker discovery
08:43:39 WORKER: done with job (8, 0, 1), trying to register it.
08:43:39 WORKER: registered result for job (8, 0, 1) with dispatcher
08:43:39 DISPATCHER: job (8, 0, 1) finished
08:43:39 DISPATCHER: register_result: lock acquired
08:43:39 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:43:39 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 348, 'last_n_outputs': 46, 'leak_rate': 0.9042239137630683, 'lr': 0.001766019129432892, 'optimizer': 'SGD', 'sparsity': 0.8705966282481502, 'steps_to_train': 78, 'weight_decay': 0.07243398082550546}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5641458691961304, 'info': {'data02': 0.5641458691961304, 'config': "{'batch_size': 32, 'hidden_dim': 348, 'last_n_outputs': 46, 'leak_rate': 0.9042239137630683, 'lr': 0.001766019129432892, 'optimizer': 'SGD', 'sparsity': 0.8705966282481502, 'steps_to_train': 78, 'weight_decay': 0.07243398082550546}"}}
exception: None

08:43:39 job_callback for (8, 0, 1) started
08:43:39 DISPATCHER: Trying to submit another job.
08:43:39 job_callback for (8, 0, 1) got condition
08:43:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:43:39 HBMASTER: Trying to run another job!
08:43:39 job_callback for (8, 0, 1) finished
08:43:39 HBMASTER: schedule new run for iteration 8
08:43:39 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
08:43:39 HBMASTER: submitting job (8, 0, 2) to dispatcher
08:43:39 DISPATCHER: trying to submit job (8, 0, 2)
08:43:39 DISPATCHER: trying to notify the job_runner thread.
08:43:39 HBMASTER: job (8, 0, 2) submitted to dispatcher
08:43:39 DISPATCHER: Trying to submit another job.
08:43:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:43:39 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:43:39 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:43:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:43:39 WORKER: start processing job (8, 0, 2)
08:43:39 WORKER: args: ()
08:43:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:44:32 DISPATCHER: Starting worker discovery
08:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:32 DISPATCHER: Finished worker discovery
08:45:32 DISPATCHER: Starting worker discovery
08:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:32 DISPATCHER: Finished worker discovery
08:45:59 WORKER: done with job (8, 0, 2), trying to register it.
08:45:59 WORKER: registered result for job (8, 0, 2) with dispatcher
08:45:59 DISPATCHER: job (8, 0, 2) finished
08:45:59 DISPATCHER: register_result: lock acquired
08:45:59 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:45:59 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6050791069983618, 'info': {'data02': 0.6050791069983618, 'config': "{'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}"}}
exception: None

08:45:59 job_callback for (8, 0, 2) started
08:45:59 DISPATCHER: Trying to submit another job.
08:45:59 job_callback for (8, 0, 2) got condition
08:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:45:59 HBMASTER: Trying to run another job!
08:45:59 job_callback for (8, 0, 2) finished
08:45:59 HBMASTER: schedule new run for iteration 8
08:45:59 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
08:45:59 HBMASTER: submitting job (8, 0, 5) to dispatcher
08:45:59 DISPATCHER: trying to submit job (8, 0, 5)
08:45:59 DISPATCHER: trying to notify the job_runner thread.
08:45:59 HBMASTER: job (8, 0, 5) submitted to dispatcher
08:45:59 DISPATCHER: Trying to submit another job.
08:45:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:45:59 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:45:59 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:45:59 WORKER: start processing job (8, 0, 5)
08:45:59 WORKER: args: ()
08:45:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.9478283033842794, 'lr': 0.021434223317459342, 'optimizer': 'SGD', 'sparsity': 0.9553991761482739, 'steps_to_train': 81, 'weight_decay': 0.09838472892234987}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:46:32 DISPATCHER: Starting worker discovery
08:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:32 DISPATCHER: Finished worker discovery
08:47:32 DISPATCHER: Starting worker discovery
08:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:33 DISPATCHER: Finished worker discovery
08:48:18 WORKER: done with job (8, 0, 5), trying to register it.
08:48:18 WORKER: registered result for job (8, 0, 5) with dispatcher
08:48:18 DISPATCHER: job (8, 0, 5) finished
08:48:18 DISPATCHER: register_result: lock acquired
08:48:18 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:48:18 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.9478283033842794, 'lr': 0.021434223317459342, 'optimizer': 'SGD', 'sparsity': 0.9553991761482739, 'steps_to_train': 81, 'weight_decay': 0.09838472892234987}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5357699518959335, 'info': {'data02': 0.5357699518959335, 'config': "{'batch_size': 32, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.9478283033842794, 'lr': 0.021434223317459342, 'optimizer': 'SGD', 'sparsity': 0.9553991761482739, 'steps_to_train': 81, 'weight_decay': 0.09838472892234987}"}}
exception: None

08:48:18 job_callback for (8, 0, 5) started
08:48:18 DISPATCHER: Trying to submit another job.
08:48:18 job_callback for (8, 0, 5) got condition
08:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:48:18 HBMASTER: Trying to run another job!
08:48:18 job_callback for (8, 0, 5) finished
08:48:18 HBMASTER: schedule new run for iteration 8
08:48:18 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
08:48:18 HBMASTER: submitting job (8, 0, 10) to dispatcher
08:48:18 DISPATCHER: trying to submit job (8, 0, 10)
08:48:18 DISPATCHER: trying to notify the job_runner thread.
08:48:18 HBMASTER: job (8, 0, 10) submitted to dispatcher
08:48:18 DISPATCHER: Trying to submit another job.
08:48:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:48:18 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:48:18 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:48:18 WORKER: start processing job (8, 0, 10)
08:48:18 WORKER: args: ()
08:48:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 382, 'last_n_outputs': 44, 'leak_rate': 0.914619745779729, 'lr': 0.007128483360347658, 'optimizer': 'SGD', 'sparsity': 0.9279671569542478, 'steps_to_train': 98, 'weight_decay': 0.11377238558676807}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:48:33 DISPATCHER: Starting worker discovery
08:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:33 DISPATCHER: Finished worker discovery
08:49:33 DISPATCHER: Starting worker discovery
08:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:33 DISPATCHER: Finished worker discovery
08:50:33 DISPATCHER: Starting worker discovery
08:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:33 DISPATCHER: Finished worker discovery
08:50:37 WORKER: done with job (8, 0, 10), trying to register it.
08:50:37 WORKER: registered result for job (8, 0, 10) with dispatcher
08:50:37 DISPATCHER: job (8, 0, 10) finished
08:50:37 DISPATCHER: register_result: lock acquired
08:50:37 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:50:37 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 382, 'last_n_outputs': 44, 'leak_rate': 0.914619745779729, 'lr': 0.007128483360347658, 'optimizer': 'SGD', 'sparsity': 0.9279671569542478, 'steps_to_train': 98, 'weight_decay': 0.11377238558676807}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5949150535001853, 'info': {'data02': 0.5949150535001853, 'config': "{'batch_size': 16, 'hidden_dim': 382, 'last_n_outputs': 44, 'leak_rate': 0.914619745779729, 'lr': 0.007128483360347658, 'optimizer': 'SGD', 'sparsity': 0.9279671569542478, 'steps_to_train': 98, 'weight_decay': 0.11377238558676807}"}}
exception: None

08:50:37 job_callback for (8, 0, 10) started
08:50:37 job_callback for (8, 0, 10) got condition
08:50:37 DISPATCHER: Trying to submit another job.
08:50:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:50:37 HBMASTER: Trying to run another job!
08:50:37 job_callback for (8, 0, 10) finished
08:50:37 HBMASTER: schedule new run for iteration 8
08:50:37 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
08:50:37 HBMASTER: submitting job (8, 0, 17) to dispatcher
08:50:37 DISPATCHER: trying to submit job (8, 0, 17)
08:50:37 DISPATCHER: trying to notify the job_runner thread.
08:50:37 HBMASTER: job (8, 0, 17) submitted to dispatcher
08:50:37 DISPATCHER: Trying to submit another job.
08:50:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:50:37 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:50:37 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:50:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:50:37 WORKER: start processing job (8, 0, 17)
08:50:37 WORKER: args: ()
08:50:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:51:33 DISPATCHER: Starting worker discovery
08:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:33 DISPATCHER: Finished worker discovery
08:52:33 DISPATCHER: Starting worker discovery
08:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:33 DISPATCHER: Finished worker discovery
08:53:00 WORKER: done with job (8, 0, 17), trying to register it.
08:53:00 WORKER: registered result for job (8, 0, 17) with dispatcher
08:53:00 DISPATCHER: job (8, 0, 17) finished
08:53:00 DISPATCHER: register_result: lock acquired
08:53:00 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:53:00 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6166050499076365, 'info': {'data02': 0.6166050499076365, 'config': "{'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}"}}
exception: None

08:53:00 job_callback for (8, 0, 17) started
08:53:00 job_callback for (8, 0, 17) got condition
08:53:00 DISPATCHER: Trying to submit another job.
08:53:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:53:00 HBMASTER: Trying to run another job!
08:53:00 job_callback for (8, 0, 17) finished
08:53:00 HBMASTER: schedule new run for iteration 8
08:53:00 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
08:53:00 HBMASTER: submitting job (8, 0, 20) to dispatcher
08:53:00 DISPATCHER: trying to submit job (8, 0, 20)
08:53:00 DISPATCHER: trying to notify the job_runner thread.
08:53:00 HBMASTER: job (8, 0, 20) submitted to dispatcher
08:53:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:53:00 DISPATCHER: Trying to submit another job.
08:53:00 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:53:00 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:53:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:53:00 WORKER: start processing job (8, 0, 20)
08:53:00 WORKER: args: ()
08:53:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:53:33 DISPATCHER: Starting worker discovery
08:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:33 DISPATCHER: Finished worker discovery
08:54:33 DISPATCHER: Starting worker discovery
08:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:33 DISPATCHER: Finished worker discovery
08:55:17 WORKER: done with job (8, 0, 20), trying to register it.
08:55:17 WORKER: registered result for job (8, 0, 20) with dispatcher
08:55:17 DISPATCHER: job (8, 0, 20) finished
08:55:17 DISPATCHER: register_result: lock acquired
08:55:17 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:55:17 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6053344738801443, 'info': {'data02': 0.6053344738801443, 'config': "{'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}"}}
exception: None

08:55:17 job_callback for (8, 0, 20) started
08:55:17 DISPATCHER: Trying to submit another job.
08:55:17 job_callback for (8, 0, 20) got condition
08:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:55:17 HBMASTER: Trying to run another job!
08:55:17 job_callback for (8, 0, 20) finished
08:55:17 HBMASTER: schedule new run for iteration 8
08:55:17 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
08:55:17 HBMASTER: submitting job (8, 0, 24) to dispatcher
08:55:17 DISPATCHER: trying to submit job (8, 0, 24)
08:55:17 DISPATCHER: trying to notify the job_runner thread.
08:55:17 HBMASTER: job (8, 0, 24) submitted to dispatcher
08:55:17 DISPATCHER: Trying to submit another job.
08:55:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:55:17 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:55:17 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:55:17 WORKER: start processing job (8, 0, 24)
08:55:17 WORKER: args: ()
08:55:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 916, 'last_n_outputs': 41, 'leak_rate': 0.9813043486192639, 'lr': 0.03563879000957838, 'optimizer': 'SGD', 'sparsity': 0.7971351094122582, 'steps_to_train': 31, 'weight_decay': 0.012805465911160191}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:55:33 DISPATCHER: Starting worker discovery
08:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:33 DISPATCHER: Finished worker discovery
08:56:33 DISPATCHER: Starting worker discovery
08:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:33 DISPATCHER: Finished worker discovery
08:57:33 DISPATCHER: Starting worker discovery
08:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:33 DISPATCHER: Finished worker discovery
08:57:37 WORKER: done with job (8, 0, 24), trying to register it.
08:57:37 WORKER: registered result for job (8, 0, 24) with dispatcher
08:57:37 DISPATCHER: job (8, 0, 24) finished
08:57:37 DISPATCHER: register_result: lock acquired
08:57:37 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:57:37 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 916, 'last_n_outputs': 41, 'leak_rate': 0.9813043486192639, 'lr': 0.03563879000957838, 'optimizer': 'SGD', 'sparsity': 0.7971351094122582, 'steps_to_train': 31, 'weight_decay': 0.012805465911160191}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5649989395268838, 'info': {'data02': 0.5649989395268838, 'config': "{'batch_size': 64, 'hidden_dim': 916, 'last_n_outputs': 41, 'leak_rate': 0.9813043486192639, 'lr': 0.03563879000957838, 'optimizer': 'SGD', 'sparsity': 0.7971351094122582, 'steps_to_train': 31, 'weight_decay': 0.012805465911160191}"}}
exception: None

08:57:37 job_callback for (8, 0, 24) started
08:57:37 job_callback for (8, 0, 24) got condition
08:57:37 DISPATCHER: Trying to submit another job.
08:57:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:37 HBMASTER: Trying to run another job!
08:57:37 job_callback for (8, 0, 24) finished
08:57:37 HBMASTER: schedule new run for iteration 8
08:57:37 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
08:57:37 HBMASTER: submitting job (8, 0, 25) to dispatcher
08:57:37 DISPATCHER: trying to submit job (8, 0, 25)
08:57:37 DISPATCHER: trying to notify the job_runner thread.
08:57:37 HBMASTER: job (8, 0, 25) submitted to dispatcher
08:57:37 DISPATCHER: Trying to submit another job.
08:57:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:37 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:57:37 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:57:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:37 WORKER: start processing job (8, 0, 25)
08:57:37 WORKER: args: ()
08:57:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 479, 'last_n_outputs': 44, 'leak_rate': 0.8972711771387265, 'lr': 0.0015037447986543443, 'optimizer': 'SGD', 'sparsity': 0.8635521463074739, 'steps_to_train': 83, 'weight_decay': 0.0346751224319936}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:58:33 DISPATCHER: Starting worker discovery
08:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:33 DISPATCHER: Finished worker discovery
08:59:33 DISPATCHER: Starting worker discovery
08:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:33 DISPATCHER: Finished worker discovery
08:59:59 WORKER: done with job (8, 0, 25), trying to register it.
08:59:59 WORKER: registered result for job (8, 0, 25) with dispatcher
08:59:59 DISPATCHER: job (8, 0, 25) finished
08:59:59 DISPATCHER: register_result: lock acquired
08:59:59 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:59:59 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 479, 'last_n_outputs': 44, 'leak_rate': 0.8972711771387265, 'lr': 0.0015037447986543443, 'optimizer': 'SGD', 'sparsity': 0.8635521463074739, 'steps_to_train': 83, 'weight_decay': 0.0346751224319936}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6044105348487492, 'info': {'data02': 0.6044105348487492, 'config': "{'batch_size': 16, 'hidden_dim': 479, 'last_n_outputs': 44, 'leak_rate': 0.8972711771387265, 'lr': 0.0015037447986543443, 'optimizer': 'SGD', 'sparsity': 0.8635521463074739, 'steps_to_train': 83, 'weight_decay': 0.0346751224319936}"}}
exception: None

08:59:59 job_callback for (8, 0, 25) started
08:59:59 DISPATCHER: Trying to submit another job.
08:59:59 job_callback for (8, 0, 25) got condition
08:59:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:59:59 HBMASTER: Trying to run another job!
08:59:59 job_callback for (8, 0, 25) finished
08:59:59 ITERATION: Advancing config (8, 0, 2) to next budget 400.000000
08:59:59 ITERATION: Advancing config (8, 0, 17) to next budget 400.000000
08:59:59 ITERATION: Advancing config (8, 0, 20) to next budget 400.000000
08:59:59 HBMASTER: schedule new run for iteration 8
08:59:59 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
08:59:59 HBMASTER: submitting job (8, 0, 2) to dispatcher
08:59:59 DISPATCHER: trying to submit job (8, 0, 2)
08:59:59 DISPATCHER: trying to notify the job_runner thread.
08:59:59 HBMASTER: job (8, 0, 2) submitted to dispatcher
08:59:59 DISPATCHER: Trying to submit another job.
08:59:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:59:59 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:59:59 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:59:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:59:59 WORKER: start processing job (8, 0, 2)
08:59:59 WORKER: args: ()
08:59:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}, 'budget': 400.0, 'working_directory': '.'}
09:00:33 DISPATCHER: Starting worker discovery
09:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:33 DISPATCHER: Finished worker discovery
09:01:33 DISPATCHER: Starting worker discovery
09:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:33 DISPATCHER: Finished worker discovery
09:02:33 DISPATCHER: Starting worker discovery
09:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:33 DISPATCHER: Finished worker discovery
09:03:33 DISPATCHER: Starting worker discovery
09:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:33 DISPATCHER: Finished worker discovery
09:04:33 DISPATCHER: Starting worker discovery
09:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:33 DISPATCHER: Finished worker discovery
09:05:33 DISPATCHER: Starting worker discovery
09:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:33 DISPATCHER: Finished worker discovery
09:06:33 DISPATCHER: Starting worker discovery
09:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:33 DISPATCHER: Finished worker discovery
09:06:46 WORKER: done with job (8, 0, 2), trying to register it.
09:06:46 WORKER: registered result for job (8, 0, 2) with dispatcher
09:06:46 DISPATCHER: job (8, 0, 2) finished
09:06:46 DISPATCHER: register_result: lock acquired
09:06:46 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:06:46 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5822945680406038, 'info': {'data02': 0.5822945680406038, 'config': "{'batch_size': 32, 'hidden_dim': 259, 'last_n_outputs': 36, 'leak_rate': 0.8743359503496253, 'lr': 0.012719069625010817, 'optimizer': 'SGD', 'sparsity': 0.9839505529042223, 'steps_to_train': 88, 'weight_decay': 0.05842146225944932}"}}
exception: None

09:06:46 job_callback for (8, 0, 2) started
09:06:46 DISPATCHER: Trying to submit another job.
09:06:46 job_callback for (8, 0, 2) got condition
09:06:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:06:46 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.604684





09:06:46 HBMASTER: Trying to run another job!
09:06:46 job_callback for (8, 0, 2) finished
09:06:46 HBMASTER: schedule new run for iteration 8
09:06:46 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
09:06:46 HBMASTER: submitting job (8, 0, 17) to dispatcher
09:06:46 DISPATCHER: trying to submit job (8, 0, 17)
09:06:46 DISPATCHER: trying to notify the job_runner thread.
09:06:46 HBMASTER: job (8, 0, 17) submitted to dispatcher
09:06:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:06:46 DISPATCHER: Trying to submit another job.
09:06:46 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:06:46 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:06:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:06:46 WORKER: start processing job (8, 0, 17)
09:06:46 WORKER: args: ()
09:06:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}, 'budget': 400.0, 'working_directory': '.'}
09:07:33 DISPATCHER: Starting worker discovery
09:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:33 DISPATCHER: Finished worker discovery
09:08:33 DISPATCHER: Starting worker discovery
09:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:33 DISPATCHER: Finished worker discovery
09:09:33 DISPATCHER: Starting worker discovery
09:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:33 DISPATCHER: Finished worker discovery
09:10:33 DISPATCHER: Starting worker discovery
09:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:33 DISPATCHER: Finished worker discovery
09:11:33 DISPATCHER: Starting worker discovery
09:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:33 DISPATCHER: Finished worker discovery
09:12:33 DISPATCHER: Starting worker discovery
09:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:33 DISPATCHER: Finished worker discovery
09:13:32 WORKER: done with job (8, 0, 17), trying to register it.
09:13:32 WORKER: registered result for job (8, 0, 17) with dispatcher
09:13:32 DISPATCHER: job (8, 0, 17) finished
09:13:32 DISPATCHER: register_result: lock acquired
09:13:32 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:13:32 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.581273384539021, 'info': {'data02': 0.581273384539021, 'config': "{'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.9257688803945276, 'lr': 0.0033499260966656395, 'optimizer': 'SGD', 'sparsity': 0.9214535650800652, 'steps_to_train': 90, 'weight_decay': 0.12494726680682082}"}}
exception: None

09:13:32 job_callback for (8, 0, 17) started
09:13:32 DISPATCHER: Trying to submit another job.
09:13:32 job_callback for (8, 0, 17) got condition
09:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:13:32 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.604684





09:13:32 HBMASTER: Trying to run another job!
09:13:32 job_callback for (8, 0, 17) finished
09:13:32 HBMASTER: schedule new run for iteration 8
09:13:32 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
09:13:32 HBMASTER: submitting job (8, 0, 20) to dispatcher
09:13:32 DISPATCHER: trying to submit job (8, 0, 20)
09:13:32 DISPATCHER: trying to notify the job_runner thread.
09:13:32 HBMASTER: job (8, 0, 20) submitted to dispatcher
09:13:32 DISPATCHER: Trying to submit another job.
09:13:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:13:32 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:13:32 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:13:32 WORKER: start processing job (8, 0, 20)
09:13:32 WORKER: args: ()
09:13:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 400.0, 'working_directory': '.'}
09:13:33 DISPATCHER: Starting worker discovery
09:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:33 DISPATCHER: Finished worker discovery
09:14:33 DISPATCHER: Starting worker discovery
09:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:33 DISPATCHER: Finished worker discovery
09:15:33 DISPATCHER: Starting worker discovery
09:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:33 DISPATCHER: Finished worker discovery
09:16:33 DISPATCHER: Starting worker discovery
09:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:33 DISPATCHER: Finished worker discovery
09:17:33 DISPATCHER: Starting worker discovery
09:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:33 DISPATCHER: Finished worker discovery
09:18:33 DISPATCHER: Starting worker discovery
09:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:33 DISPATCHER: Finished worker discovery
09:19:33 DISPATCHER: Starting worker discovery
09:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:33 DISPATCHER: Finished worker discovery
09:20:18 WORKER: done with job (8, 0, 20), trying to register it.
09:20:18 WORKER: registered result for job (8, 0, 20) with dispatcher
09:20:18 DISPATCHER: job (8, 0, 20) finished
09:20:18 DISPATCHER: register_result: lock acquired
09:20:18 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:20:18 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6152084930680847, 'info': {'data02': 0.6152084930680847, 'config': "{'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}"}}
exception: None

09:20:18 job_callback for (8, 0, 20) started
09:20:18 DISPATCHER: Trying to submit another job.
09:20:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:20:18 job_callback for (8, 0, 20) got condition
09:20:18 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.615208





09:20:18 HBMASTER: Trying to run another job!
09:20:18 job_callback for (8, 0, 20) finished
09:20:18 ITERATION: Advancing config (8, 0, 20) to next budget 1200.000000
09:20:18 HBMASTER: schedule new run for iteration 8
09:20:18 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
09:20:18 HBMASTER: submitting job (8, 0, 20) to dispatcher
09:20:18 DISPATCHER: trying to submit job (8, 0, 20)
09:20:18 DISPATCHER: trying to notify the job_runner thread.
09:20:18 HBMASTER: job (8, 0, 20) submitted to dispatcher
09:20:18 DISPATCHER: Trying to submit another job.
09:20:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:20:18 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:20:18 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:20:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:20:18 WORKER: start processing job (8, 0, 20)
09:20:18 WORKER: args: ()
09:20:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 1200.0, 'working_directory': '.'}
09:20:33 DISPATCHER: Starting worker discovery
09:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:33 DISPATCHER: Finished worker discovery
09:21:33 DISPATCHER: Starting worker discovery
09:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:33 DISPATCHER: Finished worker discovery
09:22:33 DISPATCHER: Starting worker discovery
09:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:33 DISPATCHER: Finished worker discovery
09:23:33 DISPATCHER: Starting worker discovery
09:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:33 DISPATCHER: Finished worker discovery
09:24:33 DISPATCHER: Starting worker discovery
09:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:33 DISPATCHER: Finished worker discovery
09:25:33 DISPATCHER: Starting worker discovery
09:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:33 DISPATCHER: Finished worker discovery
09:26:33 DISPATCHER: Starting worker discovery
09:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:33 DISPATCHER: Finished worker discovery
09:27:33 DISPATCHER: Starting worker discovery
09:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:33 DISPATCHER: Finished worker discovery
09:28:33 DISPATCHER: Starting worker discovery
09:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:33 DISPATCHER: Finished worker discovery
09:29:33 DISPATCHER: Starting worker discovery
09:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:33 DISPATCHER: Finished worker discovery
09:30:33 DISPATCHER: Starting worker discovery
09:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:33 DISPATCHER: Finished worker discovery
09:31:33 DISPATCHER: Starting worker discovery
09:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:33 DISPATCHER: Finished worker discovery
09:32:33 DISPATCHER: Starting worker discovery
09:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:33 DISPATCHER: Finished worker discovery
09:33:33 DISPATCHER: Starting worker discovery
09:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:33 DISPATCHER: Finished worker discovery
09:34:33 DISPATCHER: Starting worker discovery
09:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:33 DISPATCHER: Finished worker discovery
09:35:33 DISPATCHER: Starting worker discovery
09:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:33 DISPATCHER: Finished worker discovery
09:36:33 DISPATCHER: Starting worker discovery
09:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:33 DISPATCHER: Finished worker discovery
09:37:33 DISPATCHER: Starting worker discovery
09:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:33 DISPATCHER: Finished worker discovery
09:38:33 DISPATCHER: Starting worker discovery
09:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:33 DISPATCHER: Finished worker discovery
09:39:33 DISPATCHER: Starting worker discovery
09:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:33 DISPATCHER: Finished worker discovery
09:40:26 WORKER: done with job (8, 0, 20), trying to register it.
09:40:26 WORKER: registered result for job (8, 0, 20) with dispatcher
09:40:26 DISPATCHER: job (8, 0, 20) finished
09:40:26 DISPATCHER: register_result: lock acquired
09:40:26 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:40:26 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6095456013869354, 'info': {'data02': 0.6095456013869354, 'config': "{'batch_size': 64, 'hidden_dim': 293, 'last_n_outputs': 45, 'leak_rate': 0.9640826676608873, 'lr': 0.0018190811796514911, 'optimizer': 'SGD', 'sparsity': 0.8208761213548068, 'steps_to_train': 19, 'weight_decay': 0.036692021609233925}"}}
exception: None

09:40:26 job_callback for (8, 0, 20) started
09:40:26 DISPATCHER: Trying to submit another job.
09:40:26 job_callback for (8, 0, 20) got condition
09:40:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:26 HBMASTER: Trying to run another job!
09:40:26 job_callback for (8, 0, 20) finished
09:40:26 start sampling a new configuration.
09:40:26 best_vector: [1, 0.5388940960810349, 0.9643119956506769, 0.8605881033051866, 0.5614714776143553, 1, 0.10492190425052106, 0.03697191766568742, 0.13731820970584668], 0.006532448978106699, 0.30916571854007846, 0.0020196092821427587
09:40:26 done sampling a new configuration.
09:40:26 HBMASTER: schedule new run for iteration 9
09:40:26 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
09:40:26 HBMASTER: submitting job (9, 0, 0) to dispatcher
09:40:26 DISPATCHER: trying to submit job (9, 0, 0)
09:40:26 DISPATCHER: trying to notify the job_runner thread.
09:40:26 HBMASTER: job (9, 0, 0) submitted to dispatcher
09:40:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:26 DISPATCHER: Trying to submit another job.
09:40:26 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:40:26 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:40:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:26 WORKER: start processing job (9, 0, 0)
09:40:26 WORKER: args: ()
09:40:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 631, 'last_n_outputs': 49, 'leak_rate': 0.9651470258262966, 'lr': 0.013272201153338846, 'optimizer': 'SGD', 'sparsity': 0.7751812570201251, 'steps_to_train': 13, 'weight_decay': 0.01508881416539747}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:40:33 DISPATCHER: Starting worker discovery
09:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:33 DISPATCHER: Finished worker discovery
09:41:33 DISPATCHER: Starting worker discovery
09:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:33 DISPATCHER: Finished worker discovery
09:42:33 DISPATCHER: Starting worker discovery
09:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:33 DISPATCHER: Finished worker discovery
09:42:44 WORKER: done with job (9, 0, 0), trying to register it.
09:42:44 WORKER: registered result for job (9, 0, 0) with dispatcher
09:42:44 DISPATCHER: job (9, 0, 0) finished
09:42:44 DISPATCHER: register_result: lock acquired
09:42:44 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:42:44 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 631, 'last_n_outputs': 49, 'leak_rate': 0.9651470258262966, 'lr': 0.013272201153338846, 'optimizer': 'SGD', 'sparsity': 0.7751812570201251, 'steps_to_train': 13, 'weight_decay': 0.01508881416539747}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.56771309292697, 'info': {'data02': 0.56771309292697, 'config': "{'batch_size': 32, 'hidden_dim': 631, 'last_n_outputs': 49, 'leak_rate': 0.9651470258262966, 'lr': 0.013272201153338846, 'optimizer': 'SGD', 'sparsity': 0.7751812570201251, 'steps_to_train': 13, 'weight_decay': 0.01508881416539747}"}}
exception: None

09:42:44 job_callback for (9, 0, 0) started
09:42:44 DISPATCHER: Trying to submit another job.
09:42:44 job_callback for (9, 0, 0) got condition
09:42:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:42:44 HBMASTER: Trying to run another job!
09:42:44 job_callback for (9, 0, 0) finished
09:42:44 start sampling a new configuration.
09:42:44 best_vector: [1, 0.8875749399144012, 0.6252026446455294, 0.9400309796819942, 0.4293939360885378, 1, 0.16516921224802977, 0.0774887731320277, 0.42455772548712467], 0.01233258485217273, 0.5440688663576931, 0.0067097754597816766
09:42:44 done sampling a new configuration.
09:42:44 HBMASTER: schedule new run for iteration 9
09:42:44 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
09:42:44 HBMASTER: submitting job (9, 0, 1) to dispatcher
09:42:44 DISPATCHER: trying to submit job (9, 0, 1)
09:42:44 DISPATCHER: trying to notify the job_runner thread.
09:42:44 HBMASTER: job (9, 0, 1) submitted to dispatcher
09:42:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:42:44 DISPATCHER: Trying to submit another job.
09:42:44 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:42:44 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:42:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:42:44 WORKER: start processing job (9, 0, 1)
09:42:44 WORKER: args: ()
09:42:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 35, 'leak_rate': 0.9850077449204986, 'lr': 0.007224168584151924, 'optimizer': 'SGD', 'sparsity': 0.7896406109395271, 'steps_to_train': 17, 'weight_decay': 0.0356748647869975}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:43:33 DISPATCHER: Starting worker discovery
09:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:33 DISPATCHER: Finished worker discovery
09:44:33 DISPATCHER: Starting worker discovery
09:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:33 DISPATCHER: Finished worker discovery
09:45:03 WORKER: done with job (9, 0, 1), trying to register it.
09:45:03 WORKER: registered result for job (9, 0, 1) with dispatcher
09:45:03 DISPATCHER: job (9, 0, 1) finished
09:45:03 DISPATCHER: register_result: lock acquired
09:45:03 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:45:03 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 35, 'leak_rate': 0.9850077449204986, 'lr': 0.007224168584151924, 'optimizer': 'SGD', 'sparsity': 0.7896406109395271, 'steps_to_train': 17, 'weight_decay': 0.0356748647869975}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6335668153569353, 'info': {'data02': 0.6335668153569353, 'config': "{'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 35, 'leak_rate': 0.9850077449204986, 'lr': 0.007224168584151924, 'optimizer': 'SGD', 'sparsity': 0.7896406109395271, 'steps_to_train': 17, 'weight_decay': 0.0356748647869975}"}}
exception: None

09:45:03 job_callback for (9, 0, 1) started
09:45:03 job_callback for (9, 0, 1) got condition
09:45:03 DISPATCHER: Trying to submit another job.
09:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:03 HBMASTER: Trying to run another job!
09:45:03 job_callback for (9, 0, 1) finished
09:45:03 start sampling a new configuration.
09:45:03 best_vector: [1, 0.9031715830098204, 0.898907864574779, 0.8457248267652623, 0.7861452937388, 1, 0.7085082866246557, 0.5794377994029086, 0.15155479714875555], 0.0401408087307171, 0.5589288165262378, 0.022435854718265782
09:45:03 done sampling a new configuration.
09:45:03 HBMASTER: schedule new run for iteration 9
09:45:03 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
09:45:03 HBMASTER: submitting job (9, 0, 2) to dispatcher
09:45:03 DISPATCHER: trying to submit job (9, 0, 2)
09:45:03 DISPATCHER: trying to notify the job_runner thread.
09:45:03 HBMASTER: job (9, 0, 2) submitted to dispatcher
09:45:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:03 DISPATCHER: Trying to submit another job.
09:45:03 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:45:03 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:03 WORKER: start processing job (9, 0, 2)
09:45:03 WORKER: args: ()
09:45:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 46, 'leak_rate': 0.9614312066913155, 'lr': 0.037349998394022754, 'optimizer': 'SGD', 'sparsity': 0.9200419887899174, 'steps_to_train': 62, 'weight_decay': 0.015746257059677294}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:45:33 DISPATCHER: Starting worker discovery
09:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:33 DISPATCHER: Finished worker discovery
09:46:33 DISPATCHER: Starting worker discovery
09:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:33 DISPATCHER: Finished worker discovery
09:47:22 WORKER: done with job (9, 0, 2), trying to register it.
09:47:22 WORKER: registered result for job (9, 0, 2) with dispatcher
09:47:22 DISPATCHER: job (9, 0, 2) finished
09:47:22 DISPATCHER: register_result: lock acquired
09:47:22 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:47:22 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 46, 'leak_rate': 0.9614312066913155, 'lr': 0.037349998394022754, 'optimizer': 'SGD', 'sparsity': 0.9200419887899174, 'steps_to_train': 62, 'weight_decay': 0.015746257059677294}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.573703770875382, 'info': {'data02': 0.573703770875382, 'config': "{'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 46, 'leak_rate': 0.9614312066913155, 'lr': 0.037349998394022754, 'optimizer': 'SGD', 'sparsity': 0.9200419887899174, 'steps_to_train': 62, 'weight_decay': 0.015746257059677294}"}}
exception: None

09:47:22 job_callback for (9, 0, 2) started
09:47:22 DISPATCHER: Trying to submit another job.
09:47:22 job_callback for (9, 0, 2) got condition
09:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:22 HBMASTER: Trying to run another job!
09:47:22 job_callback for (9, 0, 2) finished
09:47:22 start sampling a new configuration.
09:47:22 best_vector: [0, 0.3285302978851151, 0.8292556129837636, 0.6787497610681423, 0.19206043142643514, 1, 0.922409907098842, 0.8093849645645914, 0.6985371165232432], 0.010963413630425686, 1.9095404300117, 0.020935081578239197
09:47:22 done sampling a new configuration.
09:47:22 HBMASTER: schedule new run for iteration 9
09:47:22 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
09:47:22 HBMASTER: submitting job (9, 0, 3) to dispatcher
09:47:22 DISPATCHER: trying to submit job (9, 0, 3)
09:47:22 DISPATCHER: trying to notify the job_runner thread.
09:47:22 HBMASTER: job (9, 0, 3) submitted to dispatcher
09:47:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:22 DISPATCHER: Trying to submit another job.
09:47:22 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:47:22 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:22 WORKER: start processing job (9, 0, 3)
09:47:22 WORKER: args: ()
09:47:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:47:33 DISPATCHER: Starting worker discovery
09:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:33 DISPATCHER: Finished worker discovery
09:48:33 DISPATCHER: Starting worker discovery
09:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:33 DISPATCHER: Finished worker discovery
09:49:33 DISPATCHER: Starting worker discovery
09:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:33 DISPATCHER: Finished worker discovery
09:49:42 WORKER: done with job (9, 0, 3), trying to register it.
09:49:42 WORKER: registered result for job (9, 0, 3) with dispatcher
09:49:42 DISPATCHER: job (9, 0, 3) finished
09:49:42 DISPATCHER: register_result: lock acquired
09:49:42 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:49:42 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6059733137694009, 'info': {'data02': 0.6059733137694009, 'config': "{'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}"}}
exception: None

09:49:42 job_callback for (9, 0, 3) started
09:49:42 DISPATCHER: Trying to submit another job.
09:49:42 job_callback for (9, 0, 3) got condition
09:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:42 HBMASTER: Trying to run another job!
09:49:42 job_callback for (9, 0, 3) finished
09:49:42 start sampling a new configuration.
09:49:42 best_vector: [3, 0.8165045625039382, 0.7845960055073675, 0.7035109938500617, 0.5771989430345306, 1, 0.9427246290446679, 0.6510094317659589, 0.06663439579563513], 0.06768081315932045, 0.7885836357270919, 0.05337198171014293
09:49:42 done sampling a new configuration.
09:49:42 HBMASTER: schedule new run for iteration 9
09:49:42 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
09:49:42 HBMASTER: submitting job (9, 0, 4) to dispatcher
09:49:42 DISPATCHER: trying to submit job (9, 0, 4)
09:49:42 DISPATCHER: trying to notify the job_runner thread.
09:49:42 HBMASTER: job (9, 0, 4) submitted to dispatcher
09:49:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:49:42 DISPATCHER: Trying to submit another job.
09:49:42 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:49:42 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:49:42 WORKER: start processing job (9, 0, 4)
09:49:42 WORKER: args: ()
09:49:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 854, 'last_n_outputs': 42, 'leak_rate': 0.9258777484625154, 'lr': 0.01426914286048801, 'optimizer': 'SGD', 'sparsity': 0.9762539109707202, 'steps_to_train': 69, 'weight_decay': 0.01220937260386769}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:50:33 DISPATCHER: Starting worker discovery
09:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:33 DISPATCHER: Finished worker discovery
09:51:33 DISPATCHER: Starting worker discovery
09:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:33 DISPATCHER: Finished worker discovery
09:52:03 WORKER: done with job (9, 0, 4), trying to register it.
09:52:03 WORKER: registered result for job (9, 0, 4) with dispatcher
09:52:03 DISPATCHER: job (9, 0, 4) finished
09:52:03 DISPATCHER: register_result: lock acquired
09:52:03 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:52:03 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 854, 'last_n_outputs': 42, 'leak_rate': 0.9258777484625154, 'lr': 0.01426914286048801, 'optimizer': 'SGD', 'sparsity': 0.9762539109707202, 'steps_to_train': 69, 'weight_decay': 0.01220937260386769}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5961380237732996, 'info': {'data02': 0.5961380237732996, 'config': "{'batch_size': 128, 'hidden_dim': 854, 'last_n_outputs': 42, 'leak_rate': 0.9258777484625154, 'lr': 0.01426914286048801, 'optimizer': 'SGD', 'sparsity': 0.9762539109707202, 'steps_to_train': 69, 'weight_decay': 0.01220937260386769}"}}
exception: None

09:52:03 job_callback for (9, 0, 4) started
09:52:03 job_callback for (9, 0, 4) got condition
09:52:03 DISPATCHER: Trying to submit another job.
09:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:52:03 HBMASTER: Trying to run another job!
09:52:03 job_callback for (9, 0, 4) finished
09:52:03 start sampling a new configuration.
09:52:03 best_vector: [2, 0.8165336456210305, 0.9412866456634795, 0.8591362183042884, 0.7574046137485178, 1, 0.81813778419687, 0.3832545607212825, 0.3307573698401038], 0.01883657089812985, 1.1321514713516245, 0.0213258514575369
09:52:03 done sampling a new configuration.
09:52:03 HBMASTER: schedule new run for iteration 9
09:52:03 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
09:52:03 HBMASTER: submitting job (9, 0, 5) to dispatcher
09:52:03 DISPATCHER: trying to submit job (9, 0, 5)
09:52:03 DISPATCHER: trying to notify the job_runner thread.
09:52:03 HBMASTER: job (9, 0, 5) submitted to dispatcher
09:52:03 DISPATCHER: Trying to submit another job.
09:52:03 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:52:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:52:03 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:52:03 WORKER: start processing job (9, 0, 5)
09:52:03 WORKER: args: ()
09:52:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 48, 'leak_rate': 0.9647840545760721, 'lr': 0.032719693553439164, 'optimizer': 'SGD', 'sparsity': 0.9463530682072487, 'steps_to_train': 44, 'weight_decay': 0.026935513504707635}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:52:33 DISPATCHER: Starting worker discovery
09:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:33 DISPATCHER: Finished worker discovery
09:53:33 DISPATCHER: Starting worker discovery
09:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:33 DISPATCHER: Finished worker discovery
09:54:22 WORKER: done with job (9, 0, 5), trying to register it.
09:54:22 WORKER: registered result for job (9, 0, 5) with dispatcher
09:54:22 DISPATCHER: job (9, 0, 5) finished
09:54:22 DISPATCHER: register_result: lock acquired
09:54:22 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:54:22 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 48, 'leak_rate': 0.9647840545760721, 'lr': 0.032719693553439164, 'optimizer': 'SGD', 'sparsity': 0.9463530682072487, 'steps_to_train': 44, 'weight_decay': 0.026935513504707635}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6014274166569366, 'info': {'data02': 0.6014274166569366, 'config': "{'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 48, 'leak_rate': 0.9647840545760721, 'lr': 0.032719693553439164, 'optimizer': 'SGD', 'sparsity': 0.9463530682072487, 'steps_to_train': 44, 'weight_decay': 0.026935513504707635}"}}
exception: None

09:54:22 job_callback for (9, 0, 5) started
09:54:22 DISPATCHER: Trying to submit another job.
09:54:22 job_callback for (9, 0, 5) got condition
09:54:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:54:22 HBMASTER: Trying to run another job!
09:54:22 job_callback for (9, 0, 5) finished
09:54:22 start sampling a new configuration.
09:54:22 best_vector: [0, 0.06472644073053527, 0.7645483993491464, 0.6507591383803258, 0.047028713152093116, 1, 0.1210593838704441, 0.06039248506349198, 0.09416717161114091], 0.004250546815382577, 0.17627007992336116, 0.000749244226865475
09:54:22 done sampling a new configuration.
09:54:22 HBMASTER: schedule new run for iteration 9
09:54:22 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
09:54:22 HBMASTER: submitting job (9, 0, 6) to dispatcher
09:54:22 DISPATCHER: trying to submit job (9, 0, 6)
09:54:22 DISPATCHER: trying to notify the job_runner thread.
09:54:22 HBMASTER: job (9, 0, 6) submitted to dispatcher
09:54:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:54:22 DISPATCHER: Trying to submit another job.
09:54:22 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:54:22 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:54:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:54:22 WORKER: start processing job (9, 0, 6)
09:54:22 WORKER: args: ()
09:54:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 251, 'last_n_outputs': 41, 'leak_rate': 0.9126897845950814, 'lr': 0.0012418165008310598, 'optimizer': 'SGD', 'sparsity': 0.7790542521289066, 'steps_to_train': 15, 'weight_decay': 0.013259108206693123}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:54:33 DISPATCHER: Starting worker discovery
09:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:33 DISPATCHER: Finished worker discovery
09:55:33 DISPATCHER: Starting worker discovery
09:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:33 DISPATCHER: Finished worker discovery
09:56:33 DISPATCHER: Starting worker discovery
09:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:33 DISPATCHER: Finished worker discovery
09:56:40 WORKER: done with job (9, 0, 6), trying to register it.
09:56:40 WORKER: registered result for job (9, 0, 6) with dispatcher
09:56:40 DISPATCHER: job (9, 0, 6) finished
09:56:40 DISPATCHER: register_result: lock acquired
09:56:40 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:56:40 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 251, 'last_n_outputs': 41, 'leak_rate': 0.9126897845950814, 'lr': 0.0012418165008310598, 'optimizer': 'SGD', 'sparsity': 0.7790542521289066, 'steps_to_train': 15, 'weight_decay': 0.013259108206693123}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5576477446168517, 'info': {'data02': 0.5576477446168517, 'config': "{'batch_size': 16, 'hidden_dim': 251, 'last_n_outputs': 41, 'leak_rate': 0.9126897845950814, 'lr': 0.0012418165008310598, 'optimizer': 'SGD', 'sparsity': 0.7790542521289066, 'steps_to_train': 15, 'weight_decay': 0.013259108206693123}"}}
exception: None

09:56:40 job_callback for (9, 0, 6) started
09:56:40 DISPATCHER: Trying to submit another job.
09:56:40 job_callback for (9, 0, 6) got condition
09:56:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:56:40 HBMASTER: Trying to run another job!
09:56:40 job_callback for (9, 0, 6) finished
09:56:40 start sampling a new configuration.
09:56:41 best_vector: [3, 0.26112217255527315, 0.5355393028558777, 0.8943325782779531, 0.45796658299957727, 1, 0.9250299759105256, 0.5529066107645935, 0.19473647797116667], 0.016202099188964196, 1.2381910079843954, 0.020061293526246735
09:56:41 done sampling a new configuration.
09:56:41 HBMASTER: schedule new run for iteration 9
09:56:41 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
09:56:41 HBMASTER: submitting job (9, 0, 7) to dispatcher
09:56:41 DISPATCHER: trying to submit job (9, 0, 7)
09:56:41 DISPATCHER: trying to notify the job_runner thread.
09:56:41 HBMASTER: job (9, 0, 7) submitted to dispatcher
09:56:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:56:41 DISPATCHER: Trying to submit another job.
09:56:41 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:56:41 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:56:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:56:41 WORKER: start processing job (9, 0, 7)
09:56:41 WORKER: args: ()
09:56:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 409, 'last_n_outputs': 31, 'leak_rate': 0.9735831445694882, 'lr': 0.008240112973540265, 'optimizer': 'SGD', 'sparsity': 0.9720071942185261, 'steps_to_train': 60, 'weight_decay': 0.017920825008189926}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:57:33 DISPATCHER: Starting worker discovery
09:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:33 DISPATCHER: Finished worker discovery
09:58:33 DISPATCHER: Starting worker discovery
09:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:33 DISPATCHER: Finished worker discovery
09:59:00 WORKER: done with job (9, 0, 7), trying to register it.
09:59:00 WORKER: registered result for job (9, 0, 7) with dispatcher
09:59:00 DISPATCHER: job (9, 0, 7) finished
09:59:00 DISPATCHER: register_result: lock acquired
09:59:00 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:59:00 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 409, 'last_n_outputs': 31, 'leak_rate': 0.9735831445694882, 'lr': 0.008240112973540265, 'optimizer': 'SGD', 'sparsity': 0.9720071942185261, 'steps_to_train': 60, 'weight_decay': 0.017920825008189926}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5881224993768507, 'info': {'data02': 0.5881224993768507, 'config': "{'batch_size': 128, 'hidden_dim': 409, 'last_n_outputs': 31, 'leak_rate': 0.9735831445694882, 'lr': 0.008240112973540265, 'optimizer': 'SGD', 'sparsity': 0.9720071942185261, 'steps_to_train': 60, 'weight_decay': 0.017920825008189926}"}}
exception: None

09:59:00 job_callback for (9, 0, 7) started
09:59:00 DISPATCHER: Trying to submit another job.
09:59:00 job_callback for (9, 0, 7) got condition
09:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:00 HBMASTER: Trying to run another job!
09:59:00 job_callback for (9, 0, 7) finished
09:59:00 start sampling a new configuration.
09:59:00 done sampling a new configuration.
09:59:00 HBMASTER: schedule new run for iteration 9
09:59:00 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
09:59:00 HBMASTER: submitting job (9, 0, 8) to dispatcher
09:59:00 DISPATCHER: trying to submit job (9, 0, 8)
09:59:00 DISPATCHER: trying to notify the job_runner thread.
09:59:00 HBMASTER: job (9, 0, 8) submitted to dispatcher
09:59:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:00 DISPATCHER: Trying to submit another job.
09:59:00 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:59:00 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:00 WORKER: start processing job (9, 0, 8)
09:59:00 WORKER: args: ()
09:59:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 38, 'leak_rate': 0.9472777321836885, 'lr': 0.02170869402984038, 'optimizer': 'SGD', 'sparsity': 0.7596370362074015, 'steps_to_train': 42, 'weight_decay': 0.022314553541259646}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:59:33 DISPATCHER: Starting worker discovery
09:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:33 DISPATCHER: Finished worker discovery
10:00:33 DISPATCHER: Starting worker discovery
10:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:33 DISPATCHER: Finished worker discovery
10:01:19 WORKER: done with job (9, 0, 8), trying to register it.
10:01:19 WORKER: registered result for job (9, 0, 8) with dispatcher
10:01:19 DISPATCHER: job (9, 0, 8) finished
10:01:19 DISPATCHER: register_result: lock acquired
10:01:19 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:01:19 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 38, 'leak_rate': 0.9472777321836885, 'lr': 0.02170869402984038, 'optimizer': 'SGD', 'sparsity': 0.7596370362074015, 'steps_to_train': 42, 'weight_decay': 0.022314553541259646}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.57824319661167, 'info': {'data02': 0.57824319661167, 'config': "{'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 38, 'leak_rate': 0.9472777321836885, 'lr': 0.02170869402984038, 'optimizer': 'SGD', 'sparsity': 0.7596370362074015, 'steps_to_train': 42, 'weight_decay': 0.022314553541259646}"}}
exception: None

10:01:19 job_callback for (9, 0, 8) started
10:01:19 job_callback for (9, 0, 8) got condition
10:01:19 DISPATCHER: Trying to submit another job.
10:01:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:01:19 HBMASTER: Trying to run another job!
10:01:19 job_callback for (9, 0, 8) finished
10:01:19 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
10:01:19 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
10:01:19 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
10:01:19 HBMASTER: schedule new run for iteration 9
10:01:19 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
10:01:19 HBMASTER: submitting job (9, 0, 1) to dispatcher
10:01:19 DISPATCHER: trying to submit job (9, 0, 1)
10:01:19 DISPATCHER: trying to notify the job_runner thread.
10:01:19 HBMASTER: job (9, 0, 1) submitted to dispatcher
10:01:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:01:19 DISPATCHER: Trying to submit another job.
10:01:19 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:01:19 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:01:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:01:19 WORKER: start processing job (9, 0, 1)
10:01:19 WORKER: args: ()
10:01:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 35, 'leak_rate': 0.9850077449204986, 'lr': 0.007224168584151924, 'optimizer': 'SGD', 'sparsity': 0.7896406109395271, 'steps_to_train': 17, 'weight_decay': 0.0356748647869975}, 'budget': 400.0, 'working_directory': '.'}
10:01:33 DISPATCHER: Starting worker discovery
10:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:33 DISPATCHER: Finished worker discovery
10:02:33 DISPATCHER: Starting worker discovery
10:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:33 DISPATCHER: Finished worker discovery
10:03:33 DISPATCHER: Starting worker discovery
10:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:33 DISPATCHER: Finished worker discovery
10:04:33 DISPATCHER: Starting worker discovery
10:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:33 DISPATCHER: Finished worker discovery
10:05:33 DISPATCHER: Starting worker discovery
10:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:33 DISPATCHER: Finished worker discovery
10:06:33 DISPATCHER: Starting worker discovery
10:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:33 DISPATCHER: Finished worker discovery
10:07:33 DISPATCHER: Starting worker discovery
10:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:33 DISPATCHER: Finished worker discovery
10:08:05 WORKER: done with job (9, 0, 1), trying to register it.
10:08:05 WORKER: registered result for job (9, 0, 1) with dispatcher
10:08:05 DISPATCHER: job (9, 0, 1) finished
10:08:05 DISPATCHER: register_result: lock acquired
10:08:05 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:08:05 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 35, 'leak_rate': 0.9850077449204986, 'lr': 0.007224168584151924, 'optimizer': 'SGD', 'sparsity': 0.7896406109395271, 'steps_to_train': 17, 'weight_decay': 0.0356748647869975}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5702391285232233, 'info': {'data02': 0.5702391285232233, 'config': "{'batch_size': 32, 'hidden_dim': 910, 'last_n_outputs': 35, 'leak_rate': 0.9850077449204986, 'lr': 0.007224168584151924, 'optimizer': 'SGD', 'sparsity': 0.7896406109395271, 'steps_to_train': 17, 'weight_decay': 0.0356748647869975}"}}
exception: None

10:08:05 job_callback for (9, 0, 1) started
10:08:05 DISPATCHER: Trying to submit another job.
10:08:05 job_callback for (9, 0, 1) got condition
10:08:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:08:05 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.615208





10:08:05 HBMASTER: Trying to run another job!
10:08:05 job_callback for (9, 0, 1) finished
10:08:05 HBMASTER: schedule new run for iteration 9
10:08:05 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
10:08:05 HBMASTER: submitting job (9, 0, 3) to dispatcher
10:08:05 DISPATCHER: trying to submit job (9, 0, 3)
10:08:05 DISPATCHER: trying to notify the job_runner thread.
10:08:05 HBMASTER: job (9, 0, 3) submitted to dispatcher
10:08:05 DISPATCHER: Trying to submit another job.
10:08:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:08:05 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:08:05 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:08:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:08:05 WORKER: start processing job (9, 0, 3)
10:08:05 WORKER: args: ()
10:08:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}, 'budget': 400.0, 'working_directory': '.'}
10:08:33 DISPATCHER: Starting worker discovery
10:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:33 DISPATCHER: Finished worker discovery
10:09:33 DISPATCHER: Starting worker discovery
10:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:33 DISPATCHER: Finished worker discovery
10:10:33 DISPATCHER: Starting worker discovery
10:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:33 DISPATCHER: Finished worker discovery
10:11:33 DISPATCHER: Starting worker discovery
10:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:33 DISPATCHER: Finished worker discovery
10:12:33 DISPATCHER: Starting worker discovery
10:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:33 DISPATCHER: Finished worker discovery
10:13:33 DISPATCHER: Starting worker discovery
10:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:33 DISPATCHER: Finished worker discovery
10:14:33 DISPATCHER: Starting worker discovery
10:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:33 DISPATCHER: Finished worker discovery
10:14:50 WORKER: done with job (9, 0, 3), trying to register it.
10:14:50 WORKER: registered result for job (9, 0, 3) with dispatcher
10:14:50 DISPATCHER: job (9, 0, 3) finished
10:14:50 DISPATCHER: register_result: lock acquired
10:14:50 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:14:50 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.618804650442161, 'info': {'data02': 0.618804650442161, 'config': "{'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}"}}
exception: None

10:14:50 job_callback for (9, 0, 3) started
10:14:50 DISPATCHER: Trying to submit another job.
10:14:50 job_callback for (9, 0, 3) got condition
10:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:14:50 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.618805





10:14:50 HBMASTER: Trying to run another job!
10:14:50 job_callback for (9, 0, 3) finished
10:14:50 HBMASTER: schedule new run for iteration 9
10:14:50 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
10:14:50 HBMASTER: submitting job (9, 0, 5) to dispatcher
10:14:50 DISPATCHER: trying to submit job (9, 0, 5)
10:14:50 DISPATCHER: trying to notify the job_runner thread.
10:14:50 HBMASTER: job (9, 0, 5) submitted to dispatcher
10:14:50 DISPATCHER: Trying to submit another job.
10:14:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:14:50 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:14:50 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:14:50 WORKER: start processing job (9, 0, 5)
10:14:50 WORKER: args: ()
10:14:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 48, 'leak_rate': 0.9647840545760721, 'lr': 0.032719693553439164, 'optimizer': 'SGD', 'sparsity': 0.9463530682072487, 'steps_to_train': 44, 'weight_decay': 0.026935513504707635}, 'budget': 400.0, 'working_directory': '.'}
10:15:33 DISPATCHER: Starting worker discovery
10:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:33 DISPATCHER: Finished worker discovery
10:16:33 DISPATCHER: Starting worker discovery
10:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:33 DISPATCHER: Finished worker discovery
10:17:33 DISPATCHER: Starting worker discovery
10:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:33 DISPATCHER: Finished worker discovery
10:18:33 DISPATCHER: Starting worker discovery
10:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:33 DISPATCHER: Finished worker discovery
10:19:33 DISPATCHER: Starting worker discovery
10:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:33 DISPATCHER: Finished worker discovery
10:20:33 DISPATCHER: Starting worker discovery
10:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:33 DISPATCHER: Finished worker discovery
10:21:33 DISPATCHER: Starting worker discovery
10:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:33 DISPATCHER: Finished worker discovery
10:21:37 WORKER: done with job (9, 0, 5), trying to register it.
10:21:37 WORKER: registered result for job (9, 0, 5) with dispatcher
10:21:37 DISPATCHER: job (9, 0, 5) finished
10:21:37 DISPATCHER: register_result: lock acquired
10:21:37 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:21:37 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 48, 'leak_rate': 0.9647840545760721, 'lr': 0.032719693553439164, 'optimizer': 'SGD', 'sparsity': 0.9463530682072487, 'steps_to_train': 44, 'weight_decay': 0.026935513504707635}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5777094230841053, 'info': {'data02': 0.5777094230841053, 'config': "{'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 48, 'leak_rate': 0.9647840545760721, 'lr': 0.032719693553439164, 'optimizer': 'SGD', 'sparsity': 0.9463530682072487, 'steps_to_train': 44, 'weight_decay': 0.026935513504707635}"}}
exception: None

10:21:37 job_callback for (9, 0, 5) started
10:21:37 job_callback for (9, 0, 5) got condition
10:21:37 DISPATCHER: Trying to submit another job.
10:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:21:37 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.618805





10:21:37 HBMASTER: Trying to run another job!
10:21:37 job_callback for (9, 0, 5) finished
10:21:37 ITERATION: Advancing config (9, 0, 3) to next budget 1200.000000
10:21:37 HBMASTER: schedule new run for iteration 9
10:21:37 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
10:21:37 HBMASTER: submitting job (9, 0, 3) to dispatcher
10:21:37 DISPATCHER: trying to submit job (9, 0, 3)
10:21:37 DISPATCHER: trying to notify the job_runner thread.
10:21:37 HBMASTER: job (9, 0, 3) submitted to dispatcher
10:21:37 DISPATCHER: Trying to submit another job.
10:21:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:21:37 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:21:37 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:21:37 WORKER: start processing job (9, 0, 3)
10:21:37 WORKER: args: ()
10:21:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}, 'budget': 1200.0, 'working_directory': '.'}
10:22:33 DISPATCHER: Starting worker discovery
10:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:33 DISPATCHER: Finished worker discovery
10:23:33 DISPATCHER: Starting worker discovery
10:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:33 DISPATCHER: Finished worker discovery
10:24:33 DISPATCHER: Starting worker discovery
10:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:33 DISPATCHER: Finished worker discovery
10:25:33 DISPATCHER: Starting worker discovery
10:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:33 DISPATCHER: Finished worker discovery
10:26:33 DISPATCHER: Starting worker discovery
10:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:33 DISPATCHER: Finished worker discovery
10:27:33 DISPATCHER: Starting worker discovery
10:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:33 DISPATCHER: Finished worker discovery
10:28:33 DISPATCHER: Starting worker discovery
10:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:33 DISPATCHER: Finished worker discovery
10:29:33 DISPATCHER: Starting worker discovery
10:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:33 DISPATCHER: Finished worker discovery
10:30:33 DISPATCHER: Starting worker discovery
10:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:33 DISPATCHER: Finished worker discovery
10:31:33 DISPATCHER: Starting worker discovery
10:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:33 DISPATCHER: Finished worker discovery
10:32:33 DISPATCHER: Starting worker discovery
10:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:33 DISPATCHER: Finished worker discovery
10:33:33 DISPATCHER: Starting worker discovery
10:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:33 DISPATCHER: Finished worker discovery
10:34:33 DISPATCHER: Starting worker discovery
10:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:33 DISPATCHER: Finished worker discovery
10:35:33 DISPATCHER: Starting worker discovery
10:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:33 DISPATCHER: Finished worker discovery
10:36:33 DISPATCHER: Starting worker discovery
10:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:33 DISPATCHER: Finished worker discovery
10:37:33 DISPATCHER: Starting worker discovery
10:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:33 DISPATCHER: Finished worker discovery
10:38:33 DISPATCHER: Starting worker discovery
10:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:33 DISPATCHER: Finished worker discovery
10:39:33 DISPATCHER: Starting worker discovery
10:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:33 DISPATCHER: Finished worker discovery
10:40:33 DISPATCHER: Starting worker discovery
10:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:33 DISPATCHER: Finished worker discovery
10:41:33 DISPATCHER: Starting worker discovery
10:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:33 DISPATCHER: Finished worker discovery
10:41:42 WORKER: done with job (9, 0, 3), trying to register it.
10:41:42 WORKER: registered result for job (9, 0, 3) with dispatcher
10:41:42 DISPATCHER: job (9, 0, 3) finished
10:41:42 DISPATCHER: register_result: lock acquired
10:41:42 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:41:42 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5867539867726259, 'info': {'data02': 0.5867539867726259, 'config': "{'batch_size': 16, 'hidden_dim': 463, 'last_n_outputs': 43, 'leak_rate': 0.9196874402670356, 'lr': 0.0024217029056269324, 'optimizer': 'SGD', 'sparsity': 0.971378377703722, 'steps_to_train': 83, 'weight_decay': 0.0810620797051112}"}}
exception: None

10:41:42 job_callback for (9, 0, 3) started
10:41:42 job_callback for (9, 0, 3) got condition
10:41:42 DISPATCHER: Trying to submit another job.
10:41:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:41:42 HBMASTER: Trying to run another job!
10:41:42 job_callback for (9, 0, 3) finished
10:41:42 HBMASTER: shutdown initiated, shutdown_workers = True
10:41:42 WORKER: shutting down now!
10:41:42 DISPATCHER: Dispatcher shutting down
10:41:42 DISPATCHER: discover_workers shutting down
10:41:42 DISPATCHER: 'discover_worker' thread exited
10:41:42 DISPATCHER: Trying to submit another job.
10:41:42 DISPATCHER: job_runner shutting down
10:41:42 DISPATCHER: 'job_runner' thread exited
10:41:42 DISPATCHER: shut down complete
10:41:42 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f5c54282160; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:30345>
10:41:42 WORKER: No dispatcher found. Waiting for one to initiate contact.
10:41:42 WORKER: start listening for jobs
10:41:42 wait_for_workers trying to get the condition
10:41:42 DISPATCHER: started the 'discover_worker' thread
10:41:42 DISPATCHER: started the 'job_runner' thread
10:41:42 DISPATCHER: Pyro daemon running on localhost:45379
10:41:42 DISPATCHER: Starting worker discovery
10:41:42 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
10:41:42 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1575140037953214272
10:41:42 HBMASTER: number of workers changed to 1
10:41:42 Enough workers to start this run!
10:41:42 adjust_queue_size: lock accquired
10:41:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:41:42 HBMASTER: starting run at 1583833302.9770854
10:41:42 HBMASTER: adjusted queue size to (0, 1)
10:41:42 DISPATCHER: Finished worker discovery
10:41:42 start sampling a new configuration.
10:41:42 DISPATCHER: Trying to submit another job.
10:41:42 done sampling a new configuration.
10:41:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:41:42 HBMASTER: schedule new run for iteration 0
10:41:42 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
10:41:42 HBMASTER: submitting job (0, 0, 0) to dispatcher
10:41:42 DISPATCHER: trying to submit job (0, 0, 0)
10:41:42 DISPATCHER: trying to notify the job_runner thread.
10:41:42 HBMASTER: job (0, 0, 0) submitted to dispatcher
10:41:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:41:42 DISPATCHER: Trying to submit another job.
10:41:42 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:41:42 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:41:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:41:42 WORKER: start processing job (0, 0, 0)
10:41:42 WORKER: args: ()
10:41:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014120087129876875, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06292852354538761}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:42:31 WORKER: done with job (0, 0, 0), trying to register it.
10:42:31 WORKER: registered result for job (0, 0, 0) with dispatcher
10:42:31 DISPATCHER: job (0, 0, 0) finished
10:42:31 DISPATCHER: register_result: lock acquired
10:42:31 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:42:31 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014120087129876875, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06292852354538761}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4206849502890678, 'info': {'data02': 0.4206849502890678, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014120087129876875, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06292852354538761}"}}
exception: None

10:42:31 job_callback for (0, 0, 0) started
10:42:31 DISPATCHER: Trying to submit another job.
10:42:31 job_callback for (0, 0, 0) got condition
10:42:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:42:31 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:42:31 HBMASTER: Trying to run another job!
10:42:31 job_callback for (0, 0, 0) finished
10:42:31 start sampling a new configuration.
10:42:31 done sampling a new configuration.
10:42:31 HBMASTER: schedule new run for iteration 0
10:42:31 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
10:42:31 HBMASTER: submitting job (0, 0, 1) to dispatcher
10:42:31 DISPATCHER: trying to submit job (0, 0, 1)
10:42:31 DISPATCHER: trying to notify the job_runner thread.
10:42:31 HBMASTER: job (0, 0, 1) submitted to dispatcher
10:42:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:42:31 DISPATCHER: Trying to submit another job.
10:42:31 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:42:31 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:42:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:42:31 WORKER: start processing job (0, 0, 1)
10:42:31 WORKER: args: ()
10:42:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0053357854066305435, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04703412444252491, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:42:42 DISPATCHER: Starting worker discovery
10:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:42 DISPATCHER: Finished worker discovery
10:43:21 WORKER: done with job (0, 0, 1), trying to register it.
10:43:21 WORKER: registered result for job (0, 0, 1) with dispatcher
10:43:21 DISPATCHER: job (0, 0, 1) finished
10:43:21 DISPATCHER: register_result: lock acquired
10:43:21 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:43:21 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0053357854066305435, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04703412444252491, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6571279824075398, 'info': {'data02': 0.6571279824075398, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0053357854066305435, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04703412444252491, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 26}"}}
exception: None

10:43:21 job_callback for (0, 0, 1) started
10:43:21 DISPATCHER: Trying to submit another job.
10:43:21 job_callback for (0, 0, 1) got condition
10:43:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:43:21 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:43:21 HBMASTER: Trying to run another job!
10:43:21 job_callback for (0, 0, 1) finished
10:43:21 start sampling a new configuration.
10:43:21 done sampling a new configuration.
10:43:21 HBMASTER: schedule new run for iteration 0
10:43:21 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
10:43:21 HBMASTER: submitting job (0, 0, 2) to dispatcher
10:43:21 DISPATCHER: trying to submit job (0, 0, 2)
10:43:21 DISPATCHER: trying to notify the job_runner thread.
10:43:21 HBMASTER: job (0, 0, 2) submitted to dispatcher
10:43:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:43:21 DISPATCHER: Trying to submit another job.
10:43:21 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:43:21 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:43:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:43:21 WORKER: start processing job (0, 0, 2)
10:43:21 WORKER: args: ()
10:43:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08138625648862609, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015383347098721533, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:43:42 DISPATCHER: Starting worker discovery
10:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:42 DISPATCHER: Finished worker discovery
10:44:11 WORKER: done with job (0, 0, 2), trying to register it.
10:44:11 WORKER: registered result for job (0, 0, 2) with dispatcher
10:44:11 DISPATCHER: job (0, 0, 2) finished
10:44:11 DISPATCHER: register_result: lock acquired
10:44:11 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:44:11 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08138625648862609, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015383347098721533, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3811738572211348, 'info': {'data02': 0.3811738572211348, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08138625648862609, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015383347098721533, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 91}"}}
exception: None

10:44:11 job_callback for (0, 0, 2) started
10:44:11 DISPATCHER: Trying to submit another job.
10:44:11 job_callback for (0, 0, 2) got condition
10:44:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:44:11 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:44:11 HBMASTER: Trying to run another job!
10:44:11 job_callback for (0, 0, 2) finished
10:44:11 start sampling a new configuration.
10:44:11 done sampling a new configuration.
10:44:11 HBMASTER: schedule new run for iteration 0
10:44:11 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
10:44:11 HBMASTER: submitting job (0, 0, 3) to dispatcher
10:44:11 DISPATCHER: trying to submit job (0, 0, 3)
10:44:11 DISPATCHER: trying to notify the job_runner thread.
10:44:11 HBMASTER: job (0, 0, 3) submitted to dispatcher
10:44:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:44:11 DISPATCHER: Trying to submit another job.
10:44:11 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:44:11 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:44:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:44:11 WORKER: start processing job (0, 0, 3)
10:44:11 WORKER: args: ()
10:44:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.09070663549052652, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.1884032993417445}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:44:42 DISPATCHER: Starting worker discovery
10:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:43 DISPATCHER: Finished worker discovery
10:45:00 WORKER: done with job (0, 0, 3), trying to register it.
10:45:00 WORKER: registered result for job (0, 0, 3) with dispatcher
10:45:00 DISPATCHER: job (0, 0, 3) finished
10:45:00 DISPATCHER: register_result: lock acquired
10:45:00 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:45:00 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.09070663549052652, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.1884032993417445}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3102321810886315, 'info': {'data02': 0.3102321810886315, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.09070663549052652, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.1884032993417445}"}}
exception: None

10:45:00 job_callback for (0, 0, 3) started
10:45:00 DISPATCHER: Trying to submit another job.
10:45:00 job_callback for (0, 0, 3) got condition
10:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:45:00 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:45:00 HBMASTER: Trying to run another job!
10:45:00 job_callback for (0, 0, 3) finished
10:45:00 start sampling a new configuration.
10:45:00 done sampling a new configuration.
10:45:00 HBMASTER: schedule new run for iteration 0
10:45:00 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
10:45:00 HBMASTER: submitting job (0, 0, 4) to dispatcher
10:45:00 DISPATCHER: trying to submit job (0, 0, 4)
10:45:00 DISPATCHER: trying to notify the job_runner thread.
10:45:00 HBMASTER: job (0, 0, 4) submitted to dispatcher
10:45:00 DISPATCHER: Trying to submit another job.
10:45:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:45:00 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:45:00 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:45:00 WORKER: start processing job (0, 0, 4)
10:45:00 WORKER: args: ()
10:45:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03219640142875465, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.024498888421251475, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 83, 'num_filters_3': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:45:43 DISPATCHER: Starting worker discovery
10:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:43 DISPATCHER: Finished worker discovery
10:45:49 WORKER: done with job (0, 0, 4), trying to register it.
10:45:49 WORKER: registered result for job (0, 0, 4) with dispatcher
10:45:49 DISPATCHER: job (0, 0, 4) finished
10:45:49 DISPATCHER: register_result: lock acquired
10:45:49 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:45:49 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03219640142875465, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.024498888421251475, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 83, 'num_filters_3': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6204603471784474, 'info': {'data02': 0.6204603471784474, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03219640142875465, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.024498888421251475, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 83, 'num_filters_3': 60}"}}
exception: None

10:45:49 job_callback for (0, 0, 4) started
10:45:49 DISPATCHER: Trying to submit another job.
10:45:49 job_callback for (0, 0, 4) got condition
10:45:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:45:49 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:45:49 HBMASTER: Trying to run another job!
10:45:49 job_callback for (0, 0, 4) finished
10:45:49 start sampling a new configuration.
10:45:49 done sampling a new configuration.
10:45:49 HBMASTER: schedule new run for iteration 0
10:45:49 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
10:45:49 HBMASTER: submitting job (0, 0, 5) to dispatcher
10:45:49 DISPATCHER: trying to submit job (0, 0, 5)
10:45:49 DISPATCHER: trying to notify the job_runner thread.
10:45:49 HBMASTER: job (0, 0, 5) submitted to dispatcher
10:45:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:45:49 DISPATCHER: Trying to submit another job.
10:45:49 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:45:49 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:45:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:45:49 WORKER: start processing job (0, 0, 5)
10:45:49 WORKER: args: ()
10:45:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013274561006360687, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.09039274466889793}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:46:38 WORKER: done with job (0, 0, 5), trying to register it.
10:46:38 WORKER: registered result for job (0, 0, 5) with dispatcher
10:46:38 DISPATCHER: job (0, 0, 5) finished
10:46:38 DISPATCHER: register_result: lock acquired
10:46:38 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:46:38 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013274561006360687, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.09039274466889793}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41311581434303374, 'info': {'data02': 0.41311581434303374, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013274561006360687, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.09039274466889793}"}}
exception: None

10:46:38 job_callback for (0, 0, 5) started
10:46:38 DISPATCHER: Trying to submit another job.
10:46:38 job_callback for (0, 0, 5) got condition
10:46:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:46:38 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:46:38 HBMASTER: Trying to run another job!
10:46:38 job_callback for (0, 0, 5) finished
10:46:38 start sampling a new configuration.
10:46:38 done sampling a new configuration.
10:46:38 HBMASTER: schedule new run for iteration 0
10:46:38 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
10:46:38 HBMASTER: submitting job (0, 0, 6) to dispatcher
10:46:38 DISPATCHER: trying to submit job (0, 0, 6)
10:46:38 DISPATCHER: trying to notify the job_runner thread.
10:46:38 HBMASTER: job (0, 0, 6) submitted to dispatcher
10:46:38 DISPATCHER: Trying to submit another job.
10:46:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:46:38 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:46:38 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:46:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:46:38 WORKER: start processing job (0, 0, 6)
10:46:38 WORKER: args: ()
10:46:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06519903882993047, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.0874569300265544, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 48, 'num_filters_4': 23, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:46:43 DISPATCHER: Starting worker discovery
10:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:43 DISPATCHER: Finished worker discovery
10:47:27 WORKER: done with job (0, 0, 6), trying to register it.
10:47:27 WORKER: registered result for job (0, 0, 6) with dispatcher
10:47:27 DISPATCHER: job (0, 0, 6) finished
10:47:27 DISPATCHER: register_result: lock acquired
10:47:27 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:47:27 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06519903882993047, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.0874569300265544, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 48, 'num_filters_4': 23, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16742203760493923, 'info': {'data02': 0.16742203760493923, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06519903882993047, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.0874569300265544, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 48, 'num_filters_4': 23, 'num_filters_5': 37}"}}
exception: None

10:47:27 job_callback for (0, 0, 6) started
10:47:27 job_callback for (0, 0, 6) got condition
10:47:27 DISPATCHER: Trying to submit another job.
10:47:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:47:27 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:47:27 HBMASTER: Trying to run another job!
10:47:27 job_callback for (0, 0, 6) finished
10:47:27 start sampling a new configuration.
10:47:27 done sampling a new configuration.
10:47:27 HBMASTER: schedule new run for iteration 0
10:47:27 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
10:47:27 HBMASTER: submitting job (0, 0, 7) to dispatcher
10:47:27 DISPATCHER: trying to submit job (0, 0, 7)
10:47:27 DISPATCHER: trying to notify the job_runner thread.
10:47:27 HBMASTER: job (0, 0, 7) submitted to dispatcher
10:47:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:47:27 DISPATCHER: Trying to submit another job.
10:47:27 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:47:27 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:47:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:47:27 WORKER: start processing job (0, 0, 7)
10:47:27 WORKER: args: ()
10:47:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.06679286505574016, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.1266411118159608, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 108, 'num_filters_3': 41, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:47:43 DISPATCHER: Starting worker discovery
10:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:43 DISPATCHER: Finished worker discovery
10:48:16 WORKER: done with job (0, 0, 7), trying to register it.
10:48:16 WORKER: registered result for job (0, 0, 7) with dispatcher
10:48:16 DISPATCHER: job (0, 0, 7) finished
10:48:16 DISPATCHER: register_result: lock acquired
10:48:16 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:48:16 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.06679286505574016, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.1266411118159608, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 108, 'num_filters_3': 41, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.06679286505574016, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.1266411118159608, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 108, 'num_filters_3': 41, 'num_filters_4': 26}"}}
exception: None

10:48:16 job_callback for (0, 0, 7) started
10:48:16 DISPATCHER: Trying to submit another job.
10:48:16 job_callback for (0, 0, 7) got condition
10:48:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:48:16 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:48:16 HBMASTER: Trying to run another job!
10:48:16 job_callback for (0, 0, 7) finished
10:48:16 start sampling a new configuration.
10:48:16 done sampling a new configuration.
10:48:16 HBMASTER: schedule new run for iteration 0
10:48:16 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
10:48:16 HBMASTER: submitting job (0, 0, 8) to dispatcher
10:48:16 DISPATCHER: trying to submit job (0, 0, 8)
10:48:16 DISPATCHER: trying to notify the job_runner thread.
10:48:16 HBMASTER: job (0, 0, 8) submitted to dispatcher
10:48:16 DISPATCHER: Trying to submit another job.
10:48:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:48:16 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:48:16 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:48:16 WORKER: start processing job (0, 0, 8)
10:48:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:48:16 WORKER: args: ()
10:48:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.07932404797360947, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.1590108312855638, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 51, 'num_filters_4': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:48:43 DISPATCHER: Starting worker discovery
10:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:43 DISPATCHER: Finished worker discovery
10:49:05 WORKER: done with job (0, 0, 8), trying to register it.
10:49:05 WORKER: registered result for job (0, 0, 8) with dispatcher
10:49:05 DISPATCHER: job (0, 0, 8) finished
10:49:05 DISPATCHER: register_result: lock acquired
10:49:05 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:49:05 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.07932404797360947, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.1590108312855638, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 51, 'num_filters_4': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.07932404797360947, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.1590108312855638, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 51, 'num_filters_4': 37}"}}
exception: None

10:49:05 job_callback for (0, 0, 8) started
10:49:05 job_callback for (0, 0, 8) got condition
10:49:05 DISPATCHER: Trying to submit another job.
10:49:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:49:05 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:49:05 HBMASTER: Trying to run another job!
10:49:05 job_callback for (0, 0, 8) finished
10:49:05 start sampling a new configuration.
10:49:05 done sampling a new configuration.
10:49:05 HBMASTER: schedule new run for iteration 0
10:49:05 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
10:49:05 HBMASTER: submitting job (0, 0, 9) to dispatcher
10:49:05 DISPATCHER: trying to submit job (0, 0, 9)
10:49:05 DISPATCHER: trying to notify the job_runner thread.
10:49:05 HBMASTER: job (0, 0, 9) submitted to dispatcher
10:49:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:49:05 DISPATCHER: Trying to submit another job.
10:49:05 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:49:05 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:49:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:49:05 WORKER: start processing job (0, 0, 9)
10:49:05 WORKER: args: ()
10:49:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0058600338093318565, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.03779381642045416}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:49:43 DISPATCHER: Starting worker discovery
10:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:43 DISPATCHER: Finished worker discovery
10:49:53 WORKER: done with job (0, 0, 9), trying to register it.
10:49:53 WORKER: registered result for job (0, 0, 9) with dispatcher
10:49:53 DISPATCHER: job (0, 0, 9) finished
10:49:53 DISPATCHER: register_result: lock acquired
10:49:53 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:49:53 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0058600338093318565, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.03779381642045416}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4084642421134707, 'info': {'data02': 0.4084642421134707, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0058600338093318565, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.03779381642045416}"}}
exception: None

10:49:53 job_callback for (0, 0, 9) started
10:49:53 job_callback for (0, 0, 9) got condition
10:49:53 DISPATCHER: Trying to submit another job.
10:49:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:49:53 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:49:53 HBMASTER: Trying to run another job!
10:49:53 job_callback for (0, 0, 9) finished
10:49:53 start sampling a new configuration.
10:49:53 done sampling a new configuration.
10:49:53 HBMASTER: schedule new run for iteration 0
10:49:53 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
10:49:53 HBMASTER: submitting job (0, 0, 10) to dispatcher
10:49:53 DISPATCHER: trying to submit job (0, 0, 10)
10:49:53 DISPATCHER: trying to notify the job_runner thread.
10:49:53 HBMASTER: job (0, 0, 10) submitted to dispatcher
10:49:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:49:53 DISPATCHER: Trying to submit another job.
10:49:53 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:49:53 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:49:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:49:53 WORKER: start processing job (0, 0, 10)
10:49:53 WORKER: args: ()
10:49:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04786860404418015, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02121302634962019, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:50:42 WORKER: done with job (0, 0, 10), trying to register it.
10:50:42 WORKER: registered result for job (0, 0, 10) with dispatcher
10:50:42 DISPATCHER: job (0, 0, 10) finished
10:50:42 DISPATCHER: register_result: lock acquired
10:50:42 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:50:42 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04786860404418015, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02121302634962019, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.464320167649688, 'info': {'data02': 0.464320167649688, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04786860404418015, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02121302634962019, 'kernel_size_2': 7, 'num_filters_2': 37}"}}
exception: None

10:50:42 job_callback for (0, 0, 10) started
10:50:42 DISPATCHER: Trying to submit another job.
10:50:42 job_callback for (0, 0, 10) got condition
10:50:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:42 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:50:42 HBMASTER: Trying to run another job!
10:50:42 job_callback for (0, 0, 10) finished
10:50:42 start sampling a new configuration.
10:50:42 done sampling a new configuration.
10:50:42 HBMASTER: schedule new run for iteration 0
10:50:42 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
10:50:42 HBMASTER: submitting job (0, 0, 11) to dispatcher
10:50:42 DISPATCHER: trying to submit job (0, 0, 11)
10:50:42 DISPATCHER: trying to notify the job_runner thread.
10:50:42 HBMASTER: job (0, 0, 11) submitted to dispatcher
10:50:42 DISPATCHER: Trying to submit another job.
10:50:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:42 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:50:42 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:50:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:42 WORKER: start processing job (0, 0, 11)
10:50:42 WORKER: args: ()
10:50:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:50:43 DISPATCHER: Starting worker discovery
10:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:43 DISPATCHER: Finished worker discovery
10:51:31 WORKER: done with job (0, 0, 11), trying to register it.
10:51:31 WORKER: registered result for job (0, 0, 11) with dispatcher
10:51:31 DISPATCHER: job (0, 0, 11) finished
10:51:31 DISPATCHER: register_result: lock acquired
10:51:31 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:51:31 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5870743440106556, 'info': {'data02': 0.5870743440106556, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}"}}
exception: None

10:51:31 job_callback for (0, 0, 11) started
10:51:31 job_callback for (0, 0, 11) got condition
10:51:31 DISPATCHER: Trying to submit another job.
10:51:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:51:31 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:51:31 HBMASTER: Trying to run another job!
10:51:31 job_callback for (0, 0, 11) finished
10:51:31 start sampling a new configuration.
10:51:31 done sampling a new configuration.
10:51:31 HBMASTER: schedule new run for iteration 0
10:51:31 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
10:51:31 HBMASTER: submitting job (0, 0, 12) to dispatcher
10:51:31 DISPATCHER: trying to submit job (0, 0, 12)
10:51:31 DISPATCHER: trying to notify the job_runner thread.
10:51:31 HBMASTER: job (0, 0, 12) submitted to dispatcher
10:51:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:51:31 DISPATCHER: Trying to submit another job.
10:51:31 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:51:31 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:51:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:51:31 WORKER: start processing job (0, 0, 12)
10:51:31 WORKER: args: ()
10:51:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.025719351547707145, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.03967475272732594, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 87, 'num_filters_3': 116}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:51:43 DISPATCHER: Starting worker discovery
10:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:43 DISPATCHER: Finished worker discovery
10:52:19 WORKER: done with job (0, 0, 12), trying to register it.
10:52:19 WORKER: registered result for job (0, 0, 12) with dispatcher
10:52:19 DISPATCHER: job (0, 0, 12) finished
10:52:19 DISPATCHER: register_result: lock acquired
10:52:19 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:52:19 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.025719351547707145, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.03967475272732594, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 87, 'num_filters_3': 116}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4106213647144457, 'info': {'data02': 0.4106213647144457, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.025719351547707145, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.03967475272732594, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 87, 'num_filters_3': 116}"}}
exception: None

10:52:19 job_callback for (0, 0, 12) started
10:52:19 job_callback for (0, 0, 12) got condition
10:52:19 DISPATCHER: Trying to submit another job.
10:52:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:52:19 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:52:19 HBMASTER: Trying to run another job!
10:52:19 job_callback for (0, 0, 12) finished
10:52:19 start sampling a new configuration.
10:52:19 done sampling a new configuration.
10:52:19 HBMASTER: schedule new run for iteration 0
10:52:19 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:52:19 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:52:19 DISPATCHER: trying to submit job (0, 0, 13)
10:52:19 DISPATCHER: trying to notify the job_runner thread.
10:52:19 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:52:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:52:19 DISPATCHER: Trying to submit another job.
10:52:19 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:52:19 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:52:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:52:19 WORKER: start processing job (0, 0, 13)
10:52:19 WORKER: args: ()
10:52:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017668059591198423, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.16602381357086518, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:52:43 DISPATCHER: Starting worker discovery
10:52:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:43 DISPATCHER: Finished worker discovery
10:53:09 WORKER: done with job (0, 0, 13), trying to register it.
10:53:09 WORKER: registered result for job (0, 0, 13) with dispatcher
10:53:09 DISPATCHER: job (0, 0, 13) finished
10:53:09 DISPATCHER: register_result: lock acquired
10:53:09 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:53:09 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017668059591198423, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.16602381357086518, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09455529436003653, 'info': {'data02': 0.09455529436003653, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017668059591198423, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.16602381357086518, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 17}"}}
exception: None

10:53:09 job_callback for (0, 0, 13) started
10:53:09 DISPATCHER: Trying to submit another job.
10:53:09 job_callback for (0, 0, 13) got condition
10:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:53:09 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:53:09 HBMASTER: Trying to run another job!
10:53:09 job_callback for (0, 0, 13) finished
10:53:09 start sampling a new configuration.
10:53:09 done sampling a new configuration.
10:53:09 HBMASTER: schedule new run for iteration 0
10:53:09 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
10:53:09 HBMASTER: submitting job (0, 0, 14) to dispatcher
10:53:09 DISPATCHER: trying to submit job (0, 0, 14)
10:53:09 DISPATCHER: trying to notify the job_runner thread.
10:53:09 HBMASTER: job (0, 0, 14) submitted to dispatcher
10:53:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:53:09 DISPATCHER: Trying to submit another job.
10:53:09 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:53:09 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:53:09 WORKER: start processing job (0, 0, 14)
10:53:09 WORKER: args: ()
10:53:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0383797835354877, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.08283070168216167, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:53:43 DISPATCHER: Starting worker discovery
10:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:43 DISPATCHER: Finished worker discovery
10:53:58 WORKER: done with job (0, 0, 14), trying to register it.
10:53:58 WORKER: registered result for job (0, 0, 14) with dispatcher
10:53:58 DISPATCHER: job (0, 0, 14) finished
10:53:58 DISPATCHER: register_result: lock acquired
10:53:58 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:53:58 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0383797835354877, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.08283070168216167, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6047142835018248, 'info': {'data02': 0.6047142835018248, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0383797835354877, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.08283070168216167, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 63}"}}
exception: None

10:53:58 job_callback for (0, 0, 14) started
10:53:58 job_callback for (0, 0, 14) got condition
10:53:58 DISPATCHER: Trying to submit another job.
10:53:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:53:58 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:53:58 HBMASTER: Trying to run another job!
10:53:58 job_callback for (0, 0, 14) finished
10:53:58 start sampling a new configuration.
10:53:58 done sampling a new configuration.
10:53:58 HBMASTER: schedule new run for iteration 0
10:53:58 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
10:53:58 HBMASTER: submitting job (0, 0, 15) to dispatcher
10:53:58 DISPATCHER: trying to submit job (0, 0, 15)
10:53:58 DISPATCHER: trying to notify the job_runner thread.
10:53:58 HBMASTER: job (0, 0, 15) submitted to dispatcher
10:53:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:53:58 DISPATCHER: Trying to submit another job.
10:53:58 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:53:58 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:53:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:53:58 WORKER: start processing job (0, 0, 15)
10:53:58 WORKER: args: ()
10:53:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005932116961667076, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01084037101761128, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 89, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:54:43 DISPATCHER: Starting worker discovery
10:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:43 DISPATCHER: Finished worker discovery
10:54:48 WORKER: done with job (0, 0, 15), trying to register it.
10:54:48 WORKER: registered result for job (0, 0, 15) with dispatcher
10:54:48 DISPATCHER: job (0, 0, 15) finished
10:54:48 DISPATCHER: register_result: lock acquired
10:54:48 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:54:48 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005932116961667076, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01084037101761128, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 89, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5992497724604201, 'info': {'data02': 0.5992497724604201, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005932116961667076, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01084037101761128, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 89, 'num_filters_3': 27}"}}
exception: None

10:54:48 job_callback for (0, 0, 15) started
10:54:48 job_callback for (0, 0, 15) got condition
10:54:48 DISPATCHER: Trying to submit another job.
10:54:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:54:48 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:54:48 HBMASTER: Trying to run another job!
10:54:48 job_callback for (0, 0, 15) finished
10:54:48 start sampling a new configuration.
10:54:48 done sampling a new configuration.
10:54:48 HBMASTER: schedule new run for iteration 0
10:54:48 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
10:54:48 HBMASTER: submitting job (0, 0, 16) to dispatcher
10:54:48 DISPATCHER: trying to submit job (0, 0, 16)
10:54:48 DISPATCHER: trying to notify the job_runner thread.
10:54:48 HBMASTER: job (0, 0, 16) submitted to dispatcher
10:54:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:54:48 DISPATCHER: Trying to submit another job.
10:54:48 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:54:48 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:54:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:54:48 WORKER: start processing job (0, 0, 16)
10:54:48 WORKER: args: ()
10:54:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:55:36 WORKER: done with job (0, 0, 16), trying to register it.
10:55:36 WORKER: registered result for job (0, 0, 16) with dispatcher
10:55:36 DISPATCHER: job (0, 0, 16) finished
10:55:36 DISPATCHER: register_result: lock acquired
10:55:36 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:55:36 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6373178352524529, 'info': {'data02': 0.6373178352524529, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}"}}
exception: None

10:55:36 job_callback for (0, 0, 16) started
10:55:36 DISPATCHER: Trying to submit another job.
10:55:36 job_callback for (0, 0, 16) got condition
10:55:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:55:36 HBMASTER: Trying to run another job!
10:55:36 job_callback for (0, 0, 16) finished
10:55:36 start sampling a new configuration.
10:55:36 done sampling a new configuration.
10:55:36 HBMASTER: schedule new run for iteration 0
10:55:36 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
10:55:36 HBMASTER: submitting job (0, 0, 17) to dispatcher
10:55:36 DISPATCHER: trying to submit job (0, 0, 17)
10:55:36 DISPATCHER: trying to notify the job_runner thread.
10:55:36 HBMASTER: job (0, 0, 17) submitted to dispatcher
10:55:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:55:36 DISPATCHER: Trying to submit another job.
10:55:36 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:55:36 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:55:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:55:36 WORKER: start processing job (0, 0, 17)
10:55:36 WORKER: args: ()
10:55:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:55:43 DISPATCHER: Starting worker discovery
10:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:43 DISPATCHER: Finished worker discovery
10:56:26 WORKER: done with job (0, 0, 17), trying to register it.
10:56:26 WORKER: registered result for job (0, 0, 17) with dispatcher
10:56:26 DISPATCHER: job (0, 0, 17) finished
10:56:26 DISPATCHER: register_result: lock acquired
10:56:26 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:56:26 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7652849832683667, 'info': {'data02': 0.7652849832683667, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}"}}
exception: None

10:56:26 job_callback for (0, 0, 17) started
10:56:26 DISPATCHER: Trying to submit another job.
10:56:26 job_callback for (0, 0, 17) got condition
10:56:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:56:26 HBMASTER: Trying to run another job!
10:56:26 job_callback for (0, 0, 17) finished
10:56:26 start sampling a new configuration.
10:56:26 done sampling a new configuration.
10:56:26 HBMASTER: schedule new run for iteration 0
10:56:26 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
10:56:26 HBMASTER: submitting job (0, 0, 18) to dispatcher
10:56:26 DISPATCHER: trying to submit job (0, 0, 18)
10:56:26 DISPATCHER: trying to notify the job_runner thread.
10:56:26 HBMASTER: job (0, 0, 18) submitted to dispatcher
10:56:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:56:26 DISPATCHER: Trying to submit another job.
10:56:26 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:56:26 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:56:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:56:26 WORKER: start processing job (0, 0, 18)
10:56:26 WORKER: args: ()
10:56:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04866167898409836, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.014910887347250101, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 60, 'num_filters_4': 94, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:56:43 DISPATCHER: Starting worker discovery
10:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:43 DISPATCHER: Finished worker discovery
10:57:15 WORKER: done with job (0, 0, 18), trying to register it.
10:57:15 WORKER: registered result for job (0, 0, 18) with dispatcher
10:57:15 DISPATCHER: job (0, 0, 18) finished
10:57:15 DISPATCHER: register_result: lock acquired
10:57:15 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:57:15 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04866167898409836, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.014910887347250101, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 60, 'num_filters_4': 94, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19600845957814697, 'info': {'data02': 0.19600845957814697, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04866167898409836, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.014910887347250101, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 60, 'num_filters_4': 94, 'num_filters_5': 30}"}}
exception: None

10:57:15 job_callback for (0, 0, 18) started
10:57:15 DISPATCHER: Trying to submit another job.
10:57:15 job_callback for (0, 0, 18) got condition
10:57:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:57:15 HBMASTER: Trying to run another job!
10:57:15 job_callback for (0, 0, 18) finished
10:57:15 start sampling a new configuration.
10:57:15 done sampling a new configuration.
10:57:15 HBMASTER: schedule new run for iteration 0
10:57:15 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
10:57:15 HBMASTER: submitting job (0, 0, 19) to dispatcher
10:57:15 DISPATCHER: trying to submit job (0, 0, 19)
10:57:15 DISPATCHER: trying to notify the job_runner thread.
10:57:15 HBMASTER: job (0, 0, 19) submitted to dispatcher
10:57:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:57:15 DISPATCHER: Trying to submit another job.
10:57:15 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:57:15 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:57:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:57:15 WORKER: start processing job (0, 0, 19)
10:57:15 WORKER: args: ()
10:57:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011834312558065309, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.048295712197574434, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 43, 'num_filters_4': 111, 'num_filters_5': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:57:43 DISPATCHER: Starting worker discovery
10:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:43 DISPATCHER: Finished worker discovery
10:58:03 WORKER: done with job (0, 0, 19), trying to register it.
10:58:03 WORKER: registered result for job (0, 0, 19) with dispatcher
10:58:03 DISPATCHER: job (0, 0, 19) finished
10:58:03 DISPATCHER: register_result: lock acquired
10:58:03 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:58:03 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011834312558065309, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.048295712197574434, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 43, 'num_filters_4': 111, 'num_filters_5': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5203904799677826, 'info': {'data02': 0.5203904799677826, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011834312558065309, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.048295712197574434, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 43, 'num_filters_4': 111, 'num_filters_5': 46}"}}
exception: None

10:58:03 job_callback for (0, 0, 19) started
10:58:03 DISPATCHER: Trying to submit another job.
10:58:03 job_callback for (0, 0, 19) got condition
10:58:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:58:03 HBMASTER: Trying to run another job!
10:58:03 job_callback for (0, 0, 19) finished
10:58:03 start sampling a new configuration.
10:58:03 done sampling a new configuration.
10:58:03 HBMASTER: schedule new run for iteration 0
10:58:03 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
10:58:03 HBMASTER: submitting job (0, 0, 20) to dispatcher
10:58:03 DISPATCHER: trying to submit job (0, 0, 20)
10:58:03 DISPATCHER: trying to notify the job_runner thread.
10:58:03 HBMASTER: job (0, 0, 20) submitted to dispatcher
10:58:03 DISPATCHER: Trying to submit another job.
10:58:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:58:03 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:58:03 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:58:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:58:03 WORKER: start processing job (0, 0, 20)
10:58:03 WORKER: args: ()
10:58:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07112660990867545, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.11111805186384502, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:58:43 DISPATCHER: Starting worker discovery
10:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:43 DISPATCHER: Finished worker discovery
10:58:52 WORKER: done with job (0, 0, 20), trying to register it.
10:58:52 WORKER: registered result for job (0, 0, 20) with dispatcher
10:58:52 DISPATCHER: job (0, 0, 20) finished
10:58:52 DISPATCHER: register_result: lock acquired
10:58:52 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:58:52 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07112660990867545, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.11111805186384502, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07112660990867545, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.11111805186384502, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 109}"}}
exception: None

10:58:52 job_callback for (0, 0, 20) started
10:58:52 DISPATCHER: Trying to submit another job.
10:58:52 job_callback for (0, 0, 20) got condition
10:58:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:58:52 HBMASTER: Trying to run another job!
10:58:52 job_callback for (0, 0, 20) finished
10:58:52 start sampling a new configuration.
10:58:52 done sampling a new configuration.
10:58:52 HBMASTER: schedule new run for iteration 0
10:58:52 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
10:58:52 HBMASTER: submitting job (0, 0, 21) to dispatcher
10:58:52 DISPATCHER: trying to submit job (0, 0, 21)
10:58:52 DISPATCHER: trying to notify the job_runner thread.
10:58:52 HBMASTER: job (0, 0, 21) submitted to dispatcher
10:58:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:58:52 DISPATCHER: Trying to submit another job.
10:58:52 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:58:52 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:58:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:58:52 WORKER: start processing job (0, 0, 21)
10:58:52 WORKER: args: ()
10:58:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017982177843967034, 'num_filters_1': 125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.1535579525375872, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 19, 'num_filters_4': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:59:41 WORKER: done with job (0, 0, 21), trying to register it.
10:59:41 WORKER: registered result for job (0, 0, 21) with dispatcher
10:59:41 DISPATCHER: job (0, 0, 21) finished
10:59:41 DISPATCHER: register_result: lock acquired
10:59:41 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:59:41 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017982177843967034, 'num_filters_1': 125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.1535579525375872, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 19, 'num_filters_4': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017982177843967034, 'num_filters_1': 125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.1535579525375872, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 19, 'num_filters_4': 28}"}}
exception: None

10:59:41 job_callback for (0, 0, 21) started
10:59:41 job_callback for (0, 0, 21) got condition
10:59:41 DISPATCHER: Trying to submit another job.
10:59:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:59:41 HBMASTER: Trying to run another job!
10:59:41 job_callback for (0, 0, 21) finished
10:59:41 start sampling a new configuration.
10:59:41 done sampling a new configuration.
10:59:41 HBMASTER: schedule new run for iteration 0
10:59:41 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
10:59:41 HBMASTER: submitting job (0, 0, 22) to dispatcher
10:59:41 DISPATCHER: trying to submit job (0, 0, 22)
10:59:41 DISPATCHER: trying to notify the job_runner thread.
10:59:41 HBMASTER: job (0, 0, 22) submitted to dispatcher
10:59:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:59:41 DISPATCHER: Trying to submit another job.
10:59:41 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:59:41 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:59:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:59:41 WORKER: start processing job (0, 0, 22)
10:59:41 WORKER: args: ()
10:59:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008601648776011453, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.023858387753146436, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:59:43 DISPATCHER: Starting worker discovery
10:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:43 DISPATCHER: Finished worker discovery
11:00:30 WORKER: done with job (0, 0, 22), trying to register it.
11:00:30 WORKER: registered result for job (0, 0, 22) with dispatcher
11:00:30 DISPATCHER: job (0, 0, 22) finished
11:00:30 DISPATCHER: register_result: lock acquired
11:00:30 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:00:30 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008601648776011453, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.023858387753146436, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.575100693835039, 'info': {'data02': 0.575100693835039, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008601648776011453, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.023858387753146436, 'kernel_size_2': 5, 'num_filters_2': 42}"}}
exception: None

11:00:30 job_callback for (0, 0, 22) started
11:00:30 job_callback for (0, 0, 22) got condition
11:00:30 DISPATCHER: Trying to submit another job.
11:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:00:30 HBMASTER: Trying to run another job!
11:00:30 job_callback for (0, 0, 22) finished
11:00:30 start sampling a new configuration.
11:00:30 done sampling a new configuration.
11:00:30 HBMASTER: schedule new run for iteration 0
11:00:30 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
11:00:30 HBMASTER: submitting job (0, 0, 23) to dispatcher
11:00:30 DISPATCHER: trying to submit job (0, 0, 23)
11:00:30 DISPATCHER: trying to notify the job_runner thread.
11:00:30 HBMASTER: job (0, 0, 23) submitted to dispatcher
11:00:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:00:30 DISPATCHER: Trying to submit another job.
11:00:30 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:00:30 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:00:30 WORKER: start processing job (0, 0, 23)
11:00:30 WORKER: args: ()
11:00:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007506041003011389, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.012618094628996736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 77, 'num_filters_3': 30, 'num_filters_4': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:00:43 DISPATCHER: Starting worker discovery
11:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:43 DISPATCHER: Finished worker discovery
11:01:19 WORKER: done with job (0, 0, 23), trying to register it.
11:01:19 WORKER: registered result for job (0, 0, 23) with dispatcher
11:01:19 DISPATCHER: job (0, 0, 23) finished
11:01:19 DISPATCHER: register_result: lock acquired
11:01:19 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:01:19 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007506041003011389, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.012618094628996736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 77, 'num_filters_3': 30, 'num_filters_4': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6422206563436211, 'info': {'data02': 0.6422206563436211, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007506041003011389, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.012618094628996736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 77, 'num_filters_3': 30, 'num_filters_4': 89}"}}
exception: None

11:01:19 job_callback for (0, 0, 23) started
11:01:19 job_callback for (0, 0, 23) got condition
11:01:19 DISPATCHER: Trying to submit another job.
11:01:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:01:19 HBMASTER: Trying to run another job!
11:01:19 job_callback for (0, 0, 23) finished
11:01:19 start sampling a new configuration.
11:01:19 done sampling a new configuration.
11:01:19 HBMASTER: schedule new run for iteration 0
11:01:19 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
11:01:19 HBMASTER: submitting job (0, 0, 24) to dispatcher
11:01:19 DISPATCHER: trying to submit job (0, 0, 24)
11:01:19 DISPATCHER: trying to notify the job_runner thread.
11:01:19 HBMASTER: job (0, 0, 24) submitted to dispatcher
11:01:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:01:19 DISPATCHER: Trying to submit another job.
11:01:19 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:01:19 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:01:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:01:19 WORKER: start processing job (0, 0, 24)
11:01:19 WORKER: args: ()
11:01:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05178056380612213, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.023649008587432012, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:01:43 DISPATCHER: Starting worker discovery
11:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:43 DISPATCHER: Finished worker discovery
11:02:08 WORKER: done with job (0, 0, 24), trying to register it.
11:02:08 WORKER: registered result for job (0, 0, 24) with dispatcher
11:02:08 DISPATCHER: job (0, 0, 24) finished
11:02:08 DISPATCHER: register_result: lock acquired
11:02:08 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:02:08 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05178056380612213, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.023649008587432012, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4259842385439418, 'info': {'data02': 0.4259842385439418, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05178056380612213, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.023649008587432012, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 28}"}}
exception: None

11:02:08 job_callback for (0, 0, 24) started
11:02:08 DISPATCHER: Trying to submit another job.
11:02:08 job_callback for (0, 0, 24) got condition
11:02:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:08 HBMASTER: Trying to run another job!
11:02:08 job_callback for (0, 0, 24) finished
11:02:08 start sampling a new configuration.
11:02:08 done sampling a new configuration.
11:02:08 HBMASTER: schedule new run for iteration 0
11:02:08 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
11:02:08 HBMASTER: submitting job (0, 0, 25) to dispatcher
11:02:08 DISPATCHER: trying to submit job (0, 0, 25)
11:02:08 DISPATCHER: trying to notify the job_runner thread.
11:02:08 HBMASTER: job (0, 0, 25) submitted to dispatcher
11:02:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:08 DISPATCHER: Trying to submit another job.
11:02:08 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:02:08 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:02:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:08 WORKER: start processing job (0, 0, 25)
11:02:08 WORKER: args: ()
11:02:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011070053264257657, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.05623693659183935, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:02:43 DISPATCHER: Starting worker discovery
11:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:43 DISPATCHER: Finished worker discovery
11:02:57 WORKER: done with job (0, 0, 25), trying to register it.
11:02:57 WORKER: registered result for job (0, 0, 25) with dispatcher
11:02:57 DISPATCHER: job (0, 0, 25) finished
11:02:57 DISPATCHER: register_result: lock acquired
11:02:57 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:02:57 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011070053264257657, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.05623693659183935, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011070053264257657, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.05623693659183935, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 59}"}}
exception: None

11:02:57 job_callback for (0, 0, 25) started
11:02:57 job_callback for (0, 0, 25) got condition
11:02:57 DISPATCHER: Trying to submit another job.
11:02:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:57 HBMASTER: Trying to run another job!
11:02:57 job_callback for (0, 0, 25) finished
11:02:57 start sampling a new configuration.
11:02:57 done sampling a new configuration.
11:02:57 HBMASTER: schedule new run for iteration 0
11:02:57 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
11:02:57 HBMASTER: submitting job (0, 0, 26) to dispatcher
11:02:57 DISPATCHER: trying to submit job (0, 0, 26)
11:02:57 DISPATCHER: trying to notify the job_runner thread.
11:02:57 HBMASTER: job (0, 0, 26) submitted to dispatcher
11:02:57 DISPATCHER: Trying to submit another job.
11:02:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:57 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:02:57 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:02:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:57 WORKER: start processing job (0, 0, 26)
11:02:57 WORKER: args: ()
11:02:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04140588794773838, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02843811419190606, 'kernel_size_2': 5, 'num_filters_2': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:03:43 DISPATCHER: Starting worker discovery
11:03:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:43 DISPATCHER: Finished worker discovery
11:03:46 WORKER: done with job (0, 0, 26), trying to register it.
11:03:46 WORKER: registered result for job (0, 0, 26) with dispatcher
11:03:46 DISPATCHER: job (0, 0, 26) finished
11:03:46 DISPATCHER: register_result: lock acquired
11:03:46 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:03:46 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04140588794773838, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02843811419190606, 'kernel_size_2': 5, 'num_filters_2': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20891827493747525, 'info': {'data02': 0.20891827493747525, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04140588794773838, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02843811419190606, 'kernel_size_2': 5, 'num_filters_2': 40}"}}
exception: None

11:03:46 job_callback for (0, 0, 26) started
11:03:46 DISPATCHER: Trying to submit another job.
11:03:46 job_callback for (0, 0, 26) got condition
11:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:03:46 HBMASTER: Trying to run another job!
11:03:46 job_callback for (0, 0, 26) finished
11:03:46 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
11:03:46 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
11:03:46 HBMASTER: schedule new run for iteration 0
11:03:46 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
11:03:46 HBMASTER: submitting job (0, 0, 1) to dispatcher
11:03:46 DISPATCHER: trying to submit job (0, 0, 1)
11:03:46 DISPATCHER: trying to notify the job_runner thread.
11:03:46 HBMASTER: job (0, 0, 1) submitted to dispatcher
11:03:46 DISPATCHER: Trying to submit another job.
11:03:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:03:46 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:03:46 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:03:46 WORKER: start processing job (0, 0, 1)
11:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:03:46 WORKER: args: ()
11:03:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0053357854066305435, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04703412444252491, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:04:43 DISPATCHER: Starting worker discovery
11:04:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:43 DISPATCHER: Finished worker discovery
11:05:43 DISPATCHER: Starting worker discovery
11:05:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:43 DISPATCHER: Finished worker discovery
11:06:05 WORKER: done with job (0, 0, 1), trying to register it.
11:06:05 WORKER: registered result for job (0, 0, 1) with dispatcher
11:06:05 DISPATCHER: job (0, 0, 1) finished
11:06:05 DISPATCHER: register_result: lock acquired
11:06:05 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:06:05 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0053357854066305435, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04703412444252491, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.563121950819505, 'info': {'data02': 0.563121950819505, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0053357854066305435, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04703412444252491, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 26}"}}
exception: None

11:06:05 job_callback for (0, 0, 1) started
11:06:05 DISPATCHER: Trying to submit another job.
11:06:05 job_callback for (0, 0, 1) got condition
11:06:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:06:05 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:06:05 HBMASTER: Trying to run another job!
11:06:05 job_callback for (0, 0, 1) finished
11:06:05 HBMASTER: schedule new run for iteration 0
11:06:05 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
11:06:05 HBMASTER: submitting job (0, 0, 4) to dispatcher
11:06:05 DISPATCHER: trying to submit job (0, 0, 4)
11:06:05 DISPATCHER: trying to notify the job_runner thread.
11:06:05 HBMASTER: job (0, 0, 4) submitted to dispatcher
11:06:05 DISPATCHER: Trying to submit another job.
11:06:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:06:05 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:06:05 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:06:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:06:05 WORKER: start processing job (0, 0, 4)
11:06:05 WORKER: args: ()
11:06:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03219640142875465, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.024498888421251475, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 83, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:06:43 DISPATCHER: Starting worker discovery
11:06:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:43 DISPATCHER: Finished worker discovery
11:07:43 DISPATCHER: Starting worker discovery
11:07:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:43 DISPATCHER: Finished worker discovery
11:08:23 WORKER: done with job (0, 0, 4), trying to register it.
11:08:23 WORKER: registered result for job (0, 0, 4) with dispatcher
11:08:23 DISPATCHER: job (0, 0, 4) finished
11:08:23 DISPATCHER: register_result: lock acquired
11:08:23 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:08:23 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03219640142875465, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.024498888421251475, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 83, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4404656886609512, 'info': {'data02': 0.4404656886609512, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03219640142875465, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.024498888421251475, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 83, 'num_filters_3': 60}"}}
exception: None

11:08:23 job_callback for (0, 0, 4) started
11:08:23 job_callback for (0, 0, 4) got condition
11:08:23 DISPATCHER: Trying to submit another job.
11:08:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:08:23 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:08:23 HBMASTER: Trying to run another job!
11:08:23 job_callback for (0, 0, 4) finished
11:08:23 HBMASTER: schedule new run for iteration 0
11:08:23 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
11:08:23 HBMASTER: submitting job (0, 0, 11) to dispatcher
11:08:23 DISPATCHER: trying to submit job (0, 0, 11)
11:08:23 DISPATCHER: trying to notify the job_runner thread.
11:08:23 HBMASTER: job (0, 0, 11) submitted to dispatcher
11:08:23 DISPATCHER: Trying to submit another job.
11:08:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:08:23 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:08:23 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:08:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:08:23 WORKER: start processing job (0, 0, 11)
11:08:23 WORKER: args: ()
11:08:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:08:43 DISPATCHER: Starting worker discovery
11:08:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:43 DISPATCHER: Finished worker discovery
11:09:43 DISPATCHER: Starting worker discovery
11:09:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:43 DISPATCHER: Finished worker discovery
11:10:42 WORKER: done with job (0, 0, 11), trying to register it.
11:10:42 WORKER: registered result for job (0, 0, 11) with dispatcher
11:10:42 DISPATCHER: job (0, 0, 11) finished
11:10:42 DISPATCHER: register_result: lock acquired
11:10:42 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:10:42 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6633726068279525, 'info': {'data02': 0.6633726068279525, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}"}}
exception: None

11:10:42 job_callback for (0, 0, 11) started
11:10:42 DISPATCHER: Trying to submit another job.
11:10:42 job_callback for (0, 0, 11) got condition
11:10:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:10:42 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:10:42 HBMASTER: Trying to run another job!
11:10:42 job_callback for (0, 0, 11) finished
11:10:42 HBMASTER: schedule new run for iteration 0
11:10:42 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
11:10:42 HBMASTER: submitting job (0, 0, 14) to dispatcher
11:10:42 DISPATCHER: trying to submit job (0, 0, 14)
11:10:42 DISPATCHER: trying to notify the job_runner thread.
11:10:42 HBMASTER: job (0, 0, 14) submitted to dispatcher
11:10:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:10:42 DISPATCHER: Trying to submit another job.
11:10:42 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:10:42 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:10:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:10:42 WORKER: start processing job (0, 0, 14)
11:10:42 WORKER: args: ()
11:10:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0383797835354877, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.08283070168216167, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:10:43 DISPATCHER: Starting worker discovery
11:10:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:43 DISPATCHER: Finished worker discovery
11:11:43 DISPATCHER: Starting worker discovery
11:11:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:43 DISPATCHER: Finished worker discovery
11:12:43 DISPATCHER: Starting worker discovery
11:12:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:43 DISPATCHER: Finished worker discovery
11:13:00 WORKER: done with job (0, 0, 14), trying to register it.
11:13:00 WORKER: registered result for job (0, 0, 14) with dispatcher
11:13:00 DISPATCHER: job (0, 0, 14) finished
11:13:00 DISPATCHER: register_result: lock acquired
11:13:00 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:13:00 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0383797835354877, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.08283070168216167, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4745868327243797, 'info': {'data02': 0.4745868327243797, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0383797835354877, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.08283070168216167, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 63}"}}
exception: None

11:13:00 job_callback for (0, 0, 14) started
11:13:00 DISPATCHER: Trying to submit another job.
11:13:00 job_callback for (0, 0, 14) got condition
11:13:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:13:00 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:13:00 HBMASTER: Trying to run another job!
11:13:00 job_callback for (0, 0, 14) finished
11:13:00 HBMASTER: schedule new run for iteration 0
11:13:00 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
11:13:00 HBMASTER: submitting job (0, 0, 15) to dispatcher
11:13:00 DISPATCHER: trying to submit job (0, 0, 15)
11:13:00 DISPATCHER: trying to notify the job_runner thread.
11:13:00 HBMASTER: job (0, 0, 15) submitted to dispatcher
11:13:00 DISPATCHER: Trying to submit another job.
11:13:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:13:00 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:13:00 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:13:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:13:00 WORKER: start processing job (0, 0, 15)
11:13:00 WORKER: args: ()
11:13:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005932116961667076, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01084037101761128, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 89, 'num_filters_3': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:13:43 DISPATCHER: Starting worker discovery
11:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:43 DISPATCHER: Finished worker discovery
11:14:43 DISPATCHER: Starting worker discovery
11:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:43 DISPATCHER: Finished worker discovery
11:15:17 WORKER: done with job (0, 0, 15), trying to register it.
11:15:17 WORKER: registered result for job (0, 0, 15) with dispatcher
11:15:17 DISPATCHER: job (0, 0, 15) finished
11:15:17 DISPATCHER: register_result: lock acquired
11:15:17 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:15:17 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005932116961667076, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01084037101761128, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 89, 'num_filters_3': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6340667212060731, 'info': {'data02': 0.6340667212060731, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005932116961667076, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01084037101761128, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 89, 'num_filters_3': 27}"}}
exception: None

11:15:17 job_callback for (0, 0, 15) started
11:15:17 DISPATCHER: Trying to submit another job.
11:15:17 job_callback for (0, 0, 15) got condition
11:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:15:17 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:15:17 HBMASTER: Trying to run another job!
11:15:17 job_callback for (0, 0, 15) finished
11:15:17 HBMASTER: schedule new run for iteration 0
11:15:17 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:15:17 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:15:17 DISPATCHER: trying to submit job (0, 0, 16)
11:15:17 DISPATCHER: trying to notify the job_runner thread.
11:15:17 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:15:17 DISPATCHER: Trying to submit another job.
11:15:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:15:17 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:15:17 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:15:17 WORKER: start processing job (0, 0, 16)
11:15:17 WORKER: args: ()
11:15:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:15:43 DISPATCHER: Starting worker discovery
11:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:43 DISPATCHER: Finished worker discovery
11:16:43 DISPATCHER: Starting worker discovery
11:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:43 DISPATCHER: Finished worker discovery
11:17:35 WORKER: done with job (0, 0, 16), trying to register it.
11:17:35 WORKER: registered result for job (0, 0, 16) with dispatcher
11:17:35 DISPATCHER: job (0, 0, 16) finished
11:17:35 DISPATCHER: register_result: lock acquired
11:17:35 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:17:35 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6798214292021757, 'info': {'data02': 0.6798214292021757, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}"}}
exception: None

11:17:35 job_callback for (0, 0, 16) started
11:17:35 DISPATCHER: Trying to submit another job.
11:17:35 job_callback for (0, 0, 16) got condition
11:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:17:35 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:17:35 HBMASTER: Trying to run another job!
11:17:35 job_callback for (0, 0, 16) finished
11:17:35 HBMASTER: schedule new run for iteration 0
11:17:35 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
11:17:35 HBMASTER: submitting job (0, 0, 17) to dispatcher
11:17:35 DISPATCHER: trying to submit job (0, 0, 17)
11:17:35 DISPATCHER: trying to notify the job_runner thread.
11:17:35 HBMASTER: job (0, 0, 17) submitted to dispatcher
11:17:35 DISPATCHER: Trying to submit another job.
11:17:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:17:35 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:17:35 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:17:35 WORKER: start processing job (0, 0, 17)
11:17:35 WORKER: args: ()
11:17:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:17:43 DISPATCHER: Starting worker discovery
11:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:43 DISPATCHER: Finished worker discovery
11:18:43 DISPATCHER: Starting worker discovery
11:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:43 DISPATCHER: Finished worker discovery
11:19:43 DISPATCHER: Starting worker discovery
11:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:43 DISPATCHER: Finished worker discovery
11:19:53 WORKER: done with job (0, 0, 17), trying to register it.
11:19:53 WORKER: registered result for job (0, 0, 17) with dispatcher
11:19:53 DISPATCHER: job (0, 0, 17) finished
11:19:53 DISPATCHER: register_result: lock acquired
11:19:53 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:19:53 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7032277158920814, 'info': {'data02': 0.7032277158920814, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}"}}
exception: None

11:19:53 job_callback for (0, 0, 17) started
11:19:53 job_callback for (0, 0, 17) got condition
11:19:53 DISPATCHER: Trying to submit another job.
11:19:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:19:53 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:19:53 HBMASTER: Trying to run another job!
11:19:53 job_callback for (0, 0, 17) finished
11:19:53 HBMASTER: schedule new run for iteration 0
11:19:53 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
11:19:53 HBMASTER: submitting job (0, 0, 22) to dispatcher
11:19:53 DISPATCHER: trying to submit job (0, 0, 22)
11:19:53 DISPATCHER: trying to notify the job_runner thread.
11:19:53 HBMASTER: job (0, 0, 22) submitted to dispatcher
11:19:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:19:53 DISPATCHER: Trying to submit another job.
11:19:53 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:19:53 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:19:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:19:53 WORKER: start processing job (0, 0, 22)
11:19:53 WORKER: args: ()
11:19:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008601648776011453, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.023858387753146436, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:20:43 DISPATCHER: Starting worker discovery
11:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:43 DISPATCHER: Finished worker discovery
11:21:43 DISPATCHER: Starting worker discovery
11:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:43 DISPATCHER: Finished worker discovery
11:22:11 WORKER: done with job (0, 0, 22), trying to register it.
11:22:11 WORKER: registered result for job (0, 0, 22) with dispatcher
11:22:11 DISPATCHER: job (0, 0, 22) finished
11:22:11 DISPATCHER: register_result: lock acquired
11:22:11 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:22:11 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008601648776011453, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.023858387753146436, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5680696159575763, 'info': {'data02': 0.5680696159575763, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008601648776011453, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.023858387753146436, 'kernel_size_2': 5, 'num_filters_2': 42}"}}
exception: None

11:22:11 job_callback for (0, 0, 22) started
11:22:11 DISPATCHER: Trying to submit another job.
11:22:11 job_callback for (0, 0, 22) got condition
11:22:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:22:11 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:22:11 HBMASTER: Trying to run another job!
11:22:11 job_callback for (0, 0, 22) finished
11:22:11 HBMASTER: schedule new run for iteration 0
11:22:11 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
11:22:11 HBMASTER: submitting job (0, 0, 23) to dispatcher
11:22:11 DISPATCHER: trying to submit job (0, 0, 23)
11:22:11 DISPATCHER: trying to notify the job_runner thread.
11:22:11 HBMASTER: job (0, 0, 23) submitted to dispatcher
11:22:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:22:11 DISPATCHER: Trying to submit another job.
11:22:11 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:22:11 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:22:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:22:11 WORKER: start processing job (0, 0, 23)
11:22:11 WORKER: args: ()
11:22:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007506041003011389, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.012618094628996736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 77, 'num_filters_3': 30, 'num_filters_4': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:22:43 DISPATCHER: Starting worker discovery
11:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:43 DISPATCHER: Finished worker discovery
11:23:43 DISPATCHER: Starting worker discovery
11:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:43 DISPATCHER: Finished worker discovery
11:24:30 WORKER: done with job (0, 0, 23), trying to register it.
11:24:30 WORKER: registered result for job (0, 0, 23) with dispatcher
11:24:30 DISPATCHER: job (0, 0, 23) finished
11:24:30 DISPATCHER: register_result: lock acquired
11:24:30 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:24:30 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007506041003011389, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.012618094628996736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 77, 'num_filters_3': 30, 'num_filters_4': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5798011659929979, 'info': {'data02': 0.5798011659929979, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007506041003011389, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.012618094628996736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 77, 'num_filters_3': 30, 'num_filters_4': 89}"}}
exception: None

11:24:30 job_callback for (0, 0, 23) started
11:24:30 DISPATCHER: Trying to submit another job.
11:24:30 job_callback for (0, 0, 23) got condition
11:24:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:24:30 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:24:30 HBMASTER: Trying to run another job!
11:24:30 job_callback for (0, 0, 23) finished
11:24:30 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
11:24:30 ITERATION: Advancing config (0, 0, 16) to next budget 400.000000
11:24:30 ITERATION: Advancing config (0, 0, 17) to next budget 400.000000
11:24:30 HBMASTER: schedule new run for iteration 0
11:24:30 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
11:24:30 HBMASTER: submitting job (0, 0, 11) to dispatcher
11:24:30 DISPATCHER: trying to submit job (0, 0, 11)
11:24:30 DISPATCHER: trying to notify the job_runner thread.
11:24:30 HBMASTER: job (0, 0, 11) submitted to dispatcher
11:24:30 DISPATCHER: Trying to submit another job.
11:24:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:24:30 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:24:30 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:24:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:24:30 WORKER: start processing job (0, 0, 11)
11:24:30 WORKER: args: ()
11:24:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}, 'budget': 400.0, 'working_directory': '.'}
11:24:43 DISPATCHER: Starting worker discovery
11:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:43 DISPATCHER: Finished worker discovery
11:25:43 DISPATCHER: Starting worker discovery
11:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:43 DISPATCHER: Finished worker discovery
11:26:43 DISPATCHER: Starting worker discovery
11:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:43 DISPATCHER: Finished worker discovery
11:27:43 DISPATCHER: Starting worker discovery
11:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:43 DISPATCHER: Finished worker discovery
11:28:43 DISPATCHER: Starting worker discovery
11:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:43 DISPATCHER: Finished worker discovery
11:29:43 DISPATCHER: Starting worker discovery
11:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:43 DISPATCHER: Finished worker discovery
11:30:43 DISPATCHER: Starting worker discovery
11:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:43 DISPATCHER: Finished worker discovery
11:31:16 WORKER: done with job (0, 0, 11), trying to register it.
11:31:16 WORKER: registered result for job (0, 0, 11) with dispatcher
11:31:16 DISPATCHER: job (0, 0, 11) finished
11:31:16 DISPATCHER: register_result: lock acquired
11:31:16 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:31:16 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6370854926127956, 'info': {'data02': 0.6370854926127956, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011616459302764277, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.010599967087378008, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 113, 'num_filters_3': 38, 'num_filters_4': 26}"}}
exception: None

11:31:16 job_callback for (0, 0, 11) started
11:31:16 DISPATCHER: Trying to submit another job.
11:31:16 job_callback for (0, 0, 11) got condition
11:31:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:31:16 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:31:16 HBMASTER: Trying to run another job!
11:31:16 job_callback for (0, 0, 11) finished
11:31:16 HBMASTER: schedule new run for iteration 0
11:31:16 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:31:16 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:31:16 DISPATCHER: trying to submit job (0, 0, 16)
11:31:16 DISPATCHER: trying to notify the job_runner thread.
11:31:16 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:31:16 DISPATCHER: Trying to submit another job.
11:31:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:31:16 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:31:16 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:31:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:31:16 WORKER: start processing job (0, 0, 16)
11:31:16 WORKER: args: ()
11:31:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 400.0, 'working_directory': '.'}
11:31:43 DISPATCHER: Starting worker discovery
11:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:43 DISPATCHER: Finished worker discovery
11:32:43 DISPATCHER: Starting worker discovery
11:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:43 DISPATCHER: Finished worker discovery
11:33:43 DISPATCHER: Starting worker discovery
11:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:43 DISPATCHER: Finished worker discovery
11:34:43 DISPATCHER: Starting worker discovery
11:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:43 DISPATCHER: Finished worker discovery
11:35:43 DISPATCHER: Starting worker discovery
11:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:43 DISPATCHER: Finished worker discovery
11:36:43 DISPATCHER: Starting worker discovery
11:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:43 DISPATCHER: Finished worker discovery
11:37:43 DISPATCHER: Starting worker discovery
11:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:43 DISPATCHER: Finished worker discovery
11:38:02 WORKER: done with job (0, 0, 16), trying to register it.
11:38:02 WORKER: registered result for job (0, 0, 16) with dispatcher
11:38:02 DISPATCHER: job (0, 0, 16) finished
11:38:02 DISPATCHER: register_result: lock acquired
11:38:02 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:38:02 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.692490449260472, 'info': {'data02': 0.692490449260472, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}"}}
exception: None

11:38:02 job_callback for (0, 0, 16) started
11:38:02 DISPATCHER: Trying to submit another job.
11:38:02 job_callback for (0, 0, 16) got condition
11:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:38:02 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:38:02 HBMASTER: Trying to run another job!
11:38:02 job_callback for (0, 0, 16) finished
11:38:02 HBMASTER: schedule new run for iteration 0
11:38:02 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
11:38:02 HBMASTER: submitting job (0, 0, 17) to dispatcher
11:38:02 DISPATCHER: trying to submit job (0, 0, 17)
11:38:02 DISPATCHER: trying to notify the job_runner thread.
11:38:02 HBMASTER: job (0, 0, 17) submitted to dispatcher
11:38:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:38:02 DISPATCHER: Trying to submit another job.
11:38:02 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:38:02 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:38:02 WORKER: start processing job (0, 0, 17)
11:38:02 WORKER: args: ()
11:38:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}, 'budget': 400.0, 'working_directory': '.'}
11:38:43 DISPATCHER: Starting worker discovery
11:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:43 DISPATCHER: Finished worker discovery
11:39:43 DISPATCHER: Starting worker discovery
11:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:43 DISPATCHER: Finished worker discovery
11:40:43 DISPATCHER: Starting worker discovery
11:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:43 DISPATCHER: Finished worker discovery
11:41:43 DISPATCHER: Starting worker discovery
11:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:43 DISPATCHER: Finished worker discovery
11:42:43 DISPATCHER: Starting worker discovery
11:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:43 DISPATCHER: Finished worker discovery
11:43:43 DISPATCHER: Starting worker discovery
11:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:43 DISPATCHER: Finished worker discovery
11:44:43 DISPATCHER: Starting worker discovery
11:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:43 DISPATCHER: Finished worker discovery
11:44:48 WORKER: done with job (0, 0, 17), trying to register it.
11:44:48 WORKER: registered result for job (0, 0, 17) with dispatcher
11:44:48 DISPATCHER: job (0, 0, 17) finished
11:44:48 DISPATCHER: register_result: lock acquired
11:44:48 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:44:48 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5876994425107178, 'info': {'data02': 0.5876994425107178, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001351057030581916, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.08915382944934505, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 47}"}}
exception: None

11:44:48 job_callback for (0, 0, 17) started
11:44:48 job_callback for (0, 0, 17) got condition
11:44:48 DISPATCHER: Trying to submit another job.
11:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:44:48 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:44:48 HBMASTER: Trying to run another job!
11:44:48 job_callback for (0, 0, 17) finished
11:44:48 ITERATION: Advancing config (0, 0, 16) to next budget 1200.000000
11:44:48 HBMASTER: schedule new run for iteration 0
11:44:48 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:44:48 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:44:48 DISPATCHER: trying to submit job (0, 0, 16)
11:44:48 DISPATCHER: trying to notify the job_runner thread.
11:44:48 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:44:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:44:48 DISPATCHER: Trying to submit another job.
11:44:48 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:44:48 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:44:48 WORKER: start processing job (0, 0, 16)
11:44:48 WORKER: args: ()
11:44:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 1200.0, 'working_directory': '.'}
11:45:43 DISPATCHER: Starting worker discovery
11:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:43 DISPATCHER: Finished worker discovery
11:46:43 DISPATCHER: Starting worker discovery
11:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:43 DISPATCHER: Finished worker discovery
11:47:43 DISPATCHER: Starting worker discovery
11:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:43 DISPATCHER: Finished worker discovery
11:48:43 DISPATCHER: Starting worker discovery
11:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:43 DISPATCHER: Finished worker discovery
11:49:43 DISPATCHER: Starting worker discovery
11:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:43 DISPATCHER: Finished worker discovery
11:50:43 DISPATCHER: Starting worker discovery
11:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:43 DISPATCHER: Finished worker discovery
11:51:43 DISPATCHER: Starting worker discovery
11:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:43 DISPATCHER: Finished worker discovery
11:52:43 DISPATCHER: Starting worker discovery
11:52:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:43 DISPATCHER: Finished worker discovery
11:53:43 DISPATCHER: Starting worker discovery
11:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:43 DISPATCHER: Finished worker discovery
11:54:43 DISPATCHER: Starting worker discovery
11:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:43 DISPATCHER: Finished worker discovery
11:55:43 DISPATCHER: Starting worker discovery
11:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:43 DISPATCHER: Finished worker discovery
11:56:43 DISPATCHER: Starting worker discovery
11:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:43 DISPATCHER: Finished worker discovery
11:57:43 DISPATCHER: Starting worker discovery
11:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:43 DISPATCHER: Finished worker discovery
11:58:43 DISPATCHER: Starting worker discovery
11:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:43 DISPATCHER: Finished worker discovery
11:59:43 DISPATCHER: Starting worker discovery
11:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:43 DISPATCHER: Finished worker discovery
12:00:43 DISPATCHER: Starting worker discovery
12:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:43 DISPATCHER: Finished worker discovery
12:01:43 DISPATCHER: Starting worker discovery
12:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:43 DISPATCHER: Finished worker discovery
12:02:43 DISPATCHER: Starting worker discovery
12:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:43 DISPATCHER: Finished worker discovery
12:03:43 DISPATCHER: Starting worker discovery
12:03:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:43 DISPATCHER: Finished worker discovery
12:04:43 DISPATCHER: Starting worker discovery
12:04:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:43 DISPATCHER: Finished worker discovery
12:04:58 WORKER: done with job (0, 0, 16), trying to register it.
12:04:58 WORKER: registered result for job (0, 0, 16) with dispatcher
12:04:58 DISPATCHER: job (0, 0, 16) finished
12:04:58 DISPATCHER: register_result: lock acquired
12:04:58 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:04:58 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6705613158475212, 'info': {'data02': 0.6705613158475212, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004855704546488405, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.012266856789990972, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 126, 'num_filters_4': 89}"}}
exception: None

12:04:58 job_callback for (0, 0, 16) started
12:04:58 DISPATCHER: Trying to submit another job.
12:04:58 job_callback for (0, 0, 16) got condition
12:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:58 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:04:58 HBMASTER: Trying to run another job!
12:04:58 job_callback for (0, 0, 16) finished
12:04:58 start sampling a new configuration.
12:04:58 done sampling a new configuration.
12:04:58 HBMASTER: schedule new run for iteration 1
12:04:58 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
12:04:58 HBMASTER: submitting job (1, 0, 0) to dispatcher
12:04:58 DISPATCHER: trying to submit job (1, 0, 0)
12:04:58 DISPATCHER: trying to notify the job_runner thread.
12:04:58 HBMASTER: job (1, 0, 0) submitted to dispatcher
12:04:58 DISPATCHER: Trying to submit another job.
12:04:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:58 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:04:58 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:58 WORKER: start processing job (1, 0, 0)
12:04:58 WORKER: args: ()
12:04:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:05:43 DISPATCHER: Starting worker discovery
12:05:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:43 DISPATCHER: Finished worker discovery
12:06:43 DISPATCHER: Starting worker discovery
12:06:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:43 DISPATCHER: Finished worker discovery
12:07:18 WORKER: done with job (1, 0, 0), trying to register it.
12:07:18 WORKER: registered result for job (1, 0, 0) with dispatcher
12:07:18 DISPATCHER: job (1, 0, 0) finished
12:07:18 DISPATCHER: register_result: lock acquired
12:07:18 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:07:18 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.501443074747311, 'info': {'data02': 0.501443074747311, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}"}}
exception: None

12:07:18 job_callback for (1, 0, 0) started
12:07:18 DISPATCHER: Trying to submit another job.
12:07:18 job_callback for (1, 0, 0) got condition
12:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:18 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:07:18 HBMASTER: Trying to run another job!
12:07:18 job_callback for (1, 0, 0) finished
12:07:18 start sampling a new configuration.
12:07:18 done sampling a new configuration.
12:07:18 HBMASTER: schedule new run for iteration 1
12:07:18 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
12:07:18 HBMASTER: submitting job (1, 0, 1) to dispatcher
12:07:18 DISPATCHER: trying to submit job (1, 0, 1)
12:07:18 DISPATCHER: trying to notify the job_runner thread.
12:07:18 HBMASTER: job (1, 0, 1) submitted to dispatcher
12:07:18 DISPATCHER: Trying to submit another job.
12:07:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:18 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:07:18 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:18 WORKER: start processing job (1, 0, 1)
12:07:18 WORKER: args: ()
12:07:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014040190540402453, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.12216494760741241, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 57, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:07:43 DISPATCHER: Starting worker discovery
12:07:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:43 DISPATCHER: Finished worker discovery
12:08:43 DISPATCHER: Starting worker discovery
12:08:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:43 DISPATCHER: Finished worker discovery
12:09:36 WORKER: done with job (1, 0, 1), trying to register it.
12:09:36 WORKER: registered result for job (1, 0, 1) with dispatcher
12:09:36 DISPATCHER: job (1, 0, 1) finished
12:09:36 DISPATCHER: register_result: lock acquired
12:09:36 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:09:36 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014040190540402453, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.12216494760741241, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 57, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13049600075372975, 'info': {'data02': 0.13049600075372975, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014040190540402453, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.12216494760741241, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 57, 'num_filters_4': 20}"}}
exception: None

12:09:36 job_callback for (1, 0, 1) started
12:09:36 job_callback for (1, 0, 1) got condition
12:09:36 DISPATCHER: Trying to submit another job.
12:09:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:09:36 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:09:36 HBMASTER: Trying to run another job!
12:09:36 job_callback for (1, 0, 1) finished
12:09:36 start sampling a new configuration.
12:09:36 done sampling a new configuration.
12:09:36 HBMASTER: schedule new run for iteration 1
12:09:36 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
12:09:36 HBMASTER: submitting job (1, 0, 2) to dispatcher
12:09:36 DISPATCHER: trying to submit job (1, 0, 2)
12:09:36 DISPATCHER: trying to notify the job_runner thread.
12:09:36 HBMASTER: job (1, 0, 2) submitted to dispatcher
12:09:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:09:36 DISPATCHER: Trying to submit another job.
12:09:36 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:09:36 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:09:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:09:36 WORKER: start processing job (1, 0, 2)
12:09:36 WORKER: args: ()
12:09:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001188685447507943, 'num_filters_1': 96, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.12247604658868341}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:09:43 DISPATCHER: Starting worker discovery
12:09:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:43 DISPATCHER: Finished worker discovery
12:10:43 DISPATCHER: Starting worker discovery
12:10:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:43 DISPATCHER: Finished worker discovery
12:11:43 DISPATCHER: Starting worker discovery
12:11:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:43 DISPATCHER: Finished worker discovery
12:11:54 WORKER: done with job (1, 0, 2), trying to register it.
12:11:54 WORKER: registered result for job (1, 0, 2) with dispatcher
12:11:54 DISPATCHER: job (1, 0, 2) finished
12:11:54 DISPATCHER: register_result: lock acquired
12:11:54 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:11:54 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001188685447507943, 'num_filters_1': 96, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.12247604658868341}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4317521557326685, 'info': {'data02': 0.4317521557326685, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001188685447507943, 'num_filters_1': 96, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.12247604658868341}"}}
exception: None

12:11:54 job_callback for (1, 0, 2) started
12:11:54 DISPATCHER: Trying to submit another job.
12:11:54 job_callback for (1, 0, 2) got condition
12:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:11:54 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:11:54 HBMASTER: Trying to run another job!
12:11:54 job_callback for (1, 0, 2) finished
12:11:54 start sampling a new configuration.
12:11:54 done sampling a new configuration.
12:11:54 HBMASTER: schedule new run for iteration 1
12:11:54 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
12:11:54 HBMASTER: submitting job (1, 0, 3) to dispatcher
12:11:54 DISPATCHER: trying to submit job (1, 0, 3)
12:11:54 DISPATCHER: trying to notify the job_runner thread.
12:11:54 HBMASTER: job (1, 0, 3) submitted to dispatcher
12:11:54 DISPATCHER: Trying to submit another job.
12:11:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:11:54 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:11:54 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:11:54 WORKER: start processing job (1, 0, 3)
12:11:54 WORKER: args: ()
12:11:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.015406225277174739, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.09790969032611321, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 23, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:12:43 DISPATCHER: Starting worker discovery
12:12:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:43 DISPATCHER: Finished worker discovery
12:13:43 DISPATCHER: Starting worker discovery
12:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:43 DISPATCHER: Finished worker discovery
12:14:11 WORKER: done with job (1, 0, 3), trying to register it.
12:14:11 WORKER: registered result for job (1, 0, 3) with dispatcher
12:14:11 DISPATCHER: job (1, 0, 3) finished
12:14:11 DISPATCHER: register_result: lock acquired
12:14:11 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:14:11 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.015406225277174739, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.09790969032611321, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 23, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4713266301448789, 'info': {'data02': 0.4713266301448789, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.015406225277174739, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.09790969032611321, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 23, 'num_filters_3': 59}"}}
exception: None

12:14:11 job_callback for (1, 0, 3) started
12:14:11 DISPATCHER: Trying to submit another job.
12:14:11 job_callback for (1, 0, 3) got condition
12:14:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:11 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:14:11 HBMASTER: Trying to run another job!
12:14:11 job_callback for (1, 0, 3) finished
12:14:11 start sampling a new configuration.
12:14:11 done sampling a new configuration.
12:14:11 HBMASTER: schedule new run for iteration 1
12:14:11 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
12:14:11 HBMASTER: submitting job (1, 0, 4) to dispatcher
12:14:11 DISPATCHER: trying to submit job (1, 0, 4)
12:14:11 DISPATCHER: trying to notify the job_runner thread.
12:14:11 HBMASTER: job (1, 0, 4) submitted to dispatcher
12:14:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:11 DISPATCHER: Trying to submit another job.
12:14:11 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:14:11 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:14:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:11 WORKER: start processing job (1, 0, 4)
12:14:11 WORKER: args: ()
12:14:11 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06512859558380514, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.06142147214761087}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:14:43 DISPATCHER: Starting worker discovery
12:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:43 DISPATCHER: Finished worker discovery
12:15:43 DISPATCHER: Starting worker discovery
12:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:43 DISPATCHER: Finished worker discovery
12:16:30 WORKER: done with job (1, 0, 4), trying to register it.
12:16:30 WORKER: registered result for job (1, 0, 4) with dispatcher
12:16:30 DISPATCHER: job (1, 0, 4) finished
12:16:30 DISPATCHER: register_result: lock acquired
12:16:30 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:16:30 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06512859558380514, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.06142147214761087}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42149992645632484, 'info': {'data02': 0.42149992645632484, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06512859558380514, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.06142147214761087}"}}
exception: None

12:16:30 job_callback for (1, 0, 4) started
12:16:30 DISPATCHER: Trying to submit another job.
12:16:30 job_callback for (1, 0, 4) got condition
12:16:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:16:30 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:16:30 HBMASTER: Trying to run another job!
12:16:30 job_callback for (1, 0, 4) finished
12:16:30 start sampling a new configuration.
12:16:30 done sampling a new configuration.
12:16:30 HBMASTER: schedule new run for iteration 1
12:16:30 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
12:16:30 HBMASTER: submitting job (1, 0, 5) to dispatcher
12:16:30 DISPATCHER: trying to submit job (1, 0, 5)
12:16:30 DISPATCHER: trying to notify the job_runner thread.
12:16:30 HBMASTER: job (1, 0, 5) submitted to dispatcher
12:16:30 DISPATCHER: Trying to submit another job.
12:16:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:16:30 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:16:30 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:16:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:16:30 WORKER: start processing job (1, 0, 5)
12:16:30 WORKER: args: ()
12:16:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012823307650973842, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.084758223460291, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:16:43 DISPATCHER: Starting worker discovery
12:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:43 DISPATCHER: Finished worker discovery
12:17:43 DISPATCHER: Starting worker discovery
12:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:43 DISPATCHER: Finished worker discovery
12:18:43 DISPATCHER: Starting worker discovery
12:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:43 DISPATCHER: Finished worker discovery
12:18:48 WORKER: done with job (1, 0, 5), trying to register it.
12:18:48 WORKER: registered result for job (1, 0, 5) with dispatcher
12:18:48 DISPATCHER: job (1, 0, 5) finished
12:18:48 DISPATCHER: register_result: lock acquired
12:18:48 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:18:48 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012823307650973842, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.084758223460291, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4750333423899545, 'info': {'data02': 0.4750333423899545, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012823307650973842, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.084758223460291, 'kernel_size_2': 7, 'num_filters_2': 33}"}}
exception: None

12:18:48 job_callback for (1, 0, 5) started
12:18:48 job_callback for (1, 0, 5) got condition
12:18:48 DISPATCHER: Trying to submit another job.
12:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:18:48 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:18:48 HBMASTER: Trying to run another job!
12:18:48 job_callback for (1, 0, 5) finished
12:18:48 start sampling a new configuration.
12:18:48 done sampling a new configuration.
12:18:48 HBMASTER: schedule new run for iteration 1
12:18:48 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
12:18:48 HBMASTER: submitting job (1, 0, 6) to dispatcher
12:18:48 DISPATCHER: trying to submit job (1, 0, 6)
12:18:48 DISPATCHER: trying to notify the job_runner thread.
12:18:48 HBMASTER: job (1, 0, 6) submitted to dispatcher
12:18:48 DISPATCHER: Trying to submit another job.
12:18:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:18:48 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:18:48 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:18:48 WORKER: start processing job (1, 0, 6)
12:18:48 WORKER: args: ()
12:18:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04802004440803841, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.046235900360440285}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:19:43 DISPATCHER: Starting worker discovery
12:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:43 DISPATCHER: Finished worker discovery
12:20:43 DISPATCHER: Starting worker discovery
12:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:43 DISPATCHER: Finished worker discovery
12:21:06 WORKER: done with job (1, 0, 6), trying to register it.
12:21:06 WORKER: registered result for job (1, 0, 6) with dispatcher
12:21:06 DISPATCHER: job (1, 0, 6) finished
12:21:06 DISPATCHER: register_result: lock acquired
12:21:06 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:21:06 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04802004440803841, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.046235900360440285}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41953824927077715, 'info': {'data02': 0.41953824927077715, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04802004440803841, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.046235900360440285}"}}
exception: None

12:21:06 job_callback for (1, 0, 6) started
12:21:06 job_callback for (1, 0, 6) got condition
12:21:06 DISPATCHER: Trying to submit another job.
12:21:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:21:06 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:21:06 HBMASTER: Trying to run another job!
12:21:06 job_callback for (1, 0, 6) finished
12:21:06 start sampling a new configuration.
12:21:06 done sampling a new configuration.
12:21:06 HBMASTER: schedule new run for iteration 1
12:21:06 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
12:21:06 HBMASTER: submitting job (1, 0, 7) to dispatcher
12:21:06 DISPATCHER: trying to submit job (1, 0, 7)
12:21:06 DISPATCHER: trying to notify the job_runner thread.
12:21:06 HBMASTER: job (1, 0, 7) submitted to dispatcher
12:21:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:21:06 DISPATCHER: Trying to submit another job.
12:21:06 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:21:06 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:21:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:21:06 WORKER: start processing job (1, 0, 7)
12:21:06 WORKER: args: ()
12:21:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013633247998479294, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.16697910276780578, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 27, 'num_filters_3': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:21:43 DISPATCHER: Starting worker discovery
12:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:43 DISPATCHER: Finished worker discovery
12:22:43 DISPATCHER: Starting worker discovery
12:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:43 DISPATCHER: Finished worker discovery
12:23:24 WORKER: done with job (1, 0, 7), trying to register it.
12:23:24 WORKER: registered result for job (1, 0, 7) with dispatcher
12:23:24 DISPATCHER: job (1, 0, 7) finished
12:23:24 DISPATCHER: register_result: lock acquired
12:23:24 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:23:24 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013633247998479294, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.16697910276780578, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 27, 'num_filters_3': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31012713452184215, 'info': {'data02': 0.31012713452184215, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013633247998479294, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.16697910276780578, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 27, 'num_filters_3': 70}"}}
exception: None

12:23:24 job_callback for (1, 0, 7) started
12:23:24 DISPATCHER: Trying to submit another job.
12:23:24 job_callback for (1, 0, 7) got condition
12:23:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:23:24 HBMASTER: Trying to run another job!
12:23:24 job_callback for (1, 0, 7) finished
12:23:24 start sampling a new configuration.
12:23:24 done sampling a new configuration.
12:23:24 HBMASTER: schedule new run for iteration 1
12:23:24 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
12:23:24 HBMASTER: submitting job (1, 0, 8) to dispatcher
12:23:24 DISPATCHER: trying to submit job (1, 0, 8)
12:23:24 DISPATCHER: trying to notify the job_runner thread.
12:23:24 HBMASTER: job (1, 0, 8) submitted to dispatcher
12:23:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:23:24 DISPATCHER: Trying to submit another job.
12:23:24 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:23:24 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:23:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:23:24 WORKER: start processing job (1, 0, 8)
12:23:24 WORKER: args: ()
12:23:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09779564335941891, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.044821059413436504}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:23:43 DISPATCHER: Starting worker discovery
12:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:43 DISPATCHER: Finished worker discovery
12:24:43 DISPATCHER: Starting worker discovery
12:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:43 DISPATCHER: Finished worker discovery
12:25:42 WORKER: done with job (1, 0, 8), trying to register it.
12:25:42 WORKER: registered result for job (1, 0, 8) with dispatcher
12:25:42 DISPATCHER: job (1, 0, 8) finished
12:25:42 DISPATCHER: register_result: lock acquired
12:25:42 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:25:42 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09779564335941891, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.044821059413436504}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5117289500413558, 'info': {'data02': 0.5117289500413558, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09779564335941891, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.044821059413436504}"}}
exception: None

12:25:42 job_callback for (1, 0, 8) started
12:25:42 job_callback for (1, 0, 8) got condition
12:25:42 DISPATCHER: Trying to submit another job.
12:25:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:25:42 HBMASTER: Trying to run another job!
12:25:42 job_callback for (1, 0, 8) finished
12:25:42 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
12:25:42 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
12:25:42 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
12:25:42 HBMASTER: schedule new run for iteration 1
12:25:42 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
12:25:42 HBMASTER: submitting job (1, 0, 0) to dispatcher
12:25:42 DISPATCHER: trying to submit job (1, 0, 0)
12:25:42 DISPATCHER: trying to notify the job_runner thread.
12:25:42 HBMASTER: job (1, 0, 0) submitted to dispatcher
12:25:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:25:42 DISPATCHER: Trying to submit another job.
12:25:42 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:25:42 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:25:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:25:42 WORKER: start processing job (1, 0, 0)
12:25:42 WORKER: args: ()
12:25:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}, 'budget': 400.0, 'working_directory': '.'}
12:25:43 DISPATCHER: Starting worker discovery
12:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:43 DISPATCHER: Finished worker discovery
12:26:43 DISPATCHER: Starting worker discovery
12:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:43 DISPATCHER: Finished worker discovery
12:27:43 DISPATCHER: Starting worker discovery
12:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:43 DISPATCHER: Finished worker discovery
12:28:43 DISPATCHER: Starting worker discovery
12:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:43 DISPATCHER: Finished worker discovery
12:29:43 DISPATCHER: Starting worker discovery
12:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:43 DISPATCHER: Finished worker discovery
12:30:43 DISPATCHER: Starting worker discovery
12:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:43 DISPATCHER: Finished worker discovery
12:31:43 DISPATCHER: Starting worker discovery
12:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:43 DISPATCHER: Finished worker discovery
12:32:28 WORKER: done with job (1, 0, 0), trying to register it.
12:32:28 WORKER: registered result for job (1, 0, 0) with dispatcher
12:32:28 DISPATCHER: job (1, 0, 0) finished
12:32:28 DISPATCHER: register_result: lock acquired
12:32:28 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:32:28 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.49737264923048863, 'info': {'data02': 0.49737264923048863, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}"}}
exception: None

12:32:28 job_callback for (1, 0, 0) started
12:32:28 job_callback for (1, 0, 0) got condition
12:32:28 DISPATCHER: Trying to submit another job.
12:32:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:32:28 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:32:28 HBMASTER: Trying to run another job!
12:32:28 job_callback for (1, 0, 0) finished
12:32:28 HBMASTER: schedule new run for iteration 1
12:32:28 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
12:32:28 HBMASTER: submitting job (1, 0, 5) to dispatcher
12:32:28 DISPATCHER: trying to submit job (1, 0, 5)
12:32:28 DISPATCHER: trying to notify the job_runner thread.
12:32:28 HBMASTER: job (1, 0, 5) submitted to dispatcher
12:32:28 DISPATCHER: Trying to submit another job.
12:32:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:32:28 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:32:28 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:32:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:32:28 WORKER: start processing job (1, 0, 5)
12:32:28 WORKER: args: ()
12:32:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012823307650973842, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.084758223460291, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 400.0, 'working_directory': '.'}
12:32:43 DISPATCHER: Starting worker discovery
12:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:43 DISPATCHER: Finished worker discovery
12:33:43 DISPATCHER: Starting worker discovery
12:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:43 DISPATCHER: Finished worker discovery
12:34:43 DISPATCHER: Starting worker discovery
12:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:43 DISPATCHER: Finished worker discovery
12:35:43 DISPATCHER: Starting worker discovery
12:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:43 DISPATCHER: Finished worker discovery
12:36:43 DISPATCHER: Starting worker discovery
12:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:43 DISPATCHER: Finished worker discovery
12:37:43 DISPATCHER: Starting worker discovery
12:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:43 DISPATCHER: Finished worker discovery
12:38:43 DISPATCHER: Starting worker discovery
12:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:43 DISPATCHER: Finished worker discovery
12:39:15 WORKER: done with job (1, 0, 5), trying to register it.
12:39:15 WORKER: registered result for job (1, 0, 5) with dispatcher
12:39:15 DISPATCHER: job (1, 0, 5) finished
12:39:15 DISPATCHER: register_result: lock acquired
12:39:15 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:39:15 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012823307650973842, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.084758223460291, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3968965179003775, 'info': {'data02': 0.3968965179003775, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012823307650973842, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.084758223460291, 'kernel_size_2': 7, 'num_filters_2': 33}"}}
exception: None

12:39:15 job_callback for (1, 0, 5) started
12:39:15 DISPATCHER: Trying to submit another job.
12:39:15 job_callback for (1, 0, 5) got condition
12:39:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:39:15 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:39:15 HBMASTER: Trying to run another job!
12:39:15 job_callback for (1, 0, 5) finished
12:39:15 HBMASTER: schedule new run for iteration 1
12:39:15 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
12:39:15 HBMASTER: submitting job (1, 0, 8) to dispatcher
12:39:15 DISPATCHER: trying to submit job (1, 0, 8)
12:39:15 DISPATCHER: trying to notify the job_runner thread.
12:39:15 HBMASTER: job (1, 0, 8) submitted to dispatcher
12:39:15 DISPATCHER: Trying to submit another job.
12:39:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:39:15 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:39:15 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:39:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:39:15 WORKER: start processing job (1, 0, 8)
12:39:15 WORKER: args: ()
12:39:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09779564335941891, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.044821059413436504}, 'budget': 400.0, 'working_directory': '.'}
12:39:43 DISPATCHER: Starting worker discovery
12:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:43 DISPATCHER: Finished worker discovery
12:40:43 DISPATCHER: Starting worker discovery
12:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:43 DISPATCHER: Finished worker discovery
12:41:43 DISPATCHER: Starting worker discovery
12:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:43 DISPATCHER: Finished worker discovery
12:42:43 DISPATCHER: Starting worker discovery
12:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:43 DISPATCHER: Finished worker discovery
12:43:43 DISPATCHER: Starting worker discovery
12:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:43 DISPATCHER: Finished worker discovery
12:44:43 DISPATCHER: Starting worker discovery
12:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:43 DISPATCHER: Finished worker discovery
12:45:43 DISPATCHER: Starting worker discovery
12:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:43 DISPATCHER: Finished worker discovery
12:46:02 WORKER: done with job (1, 0, 8), trying to register it.
12:46:02 WORKER: registered result for job (1, 0, 8) with dispatcher
12:46:02 DISPATCHER: job (1, 0, 8) finished
12:46:02 DISPATCHER: register_result: lock acquired
12:46:02 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:46:02 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09779564335941891, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.044821059413436504}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4193150168068842, 'info': {'data02': 0.4193150168068842, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09779564335941891, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.044821059413436504}"}}
exception: None

12:46:02 job_callback for (1, 0, 8) started
12:46:02 DISPATCHER: Trying to submit another job.
12:46:02 job_callback for (1, 0, 8) got condition
12:46:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:46:02 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:46:02 HBMASTER: Trying to run another job!
12:46:02 job_callback for (1, 0, 8) finished
12:46:02 ITERATION: Advancing config (1, 0, 0) to next budget 1200.000000
12:46:02 HBMASTER: schedule new run for iteration 1
12:46:02 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
12:46:02 HBMASTER: submitting job (1, 0, 0) to dispatcher
12:46:02 DISPATCHER: trying to submit job (1, 0, 0)
12:46:02 DISPATCHER: trying to notify the job_runner thread.
12:46:02 HBMASTER: job (1, 0, 0) submitted to dispatcher
12:46:02 DISPATCHER: Trying to submit another job.
12:46:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:46:02 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:46:02 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:46:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:46:02 WORKER: start processing job (1, 0, 0)
12:46:02 WORKER: args: ()
12:46:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}, 'budget': 1200.0, 'working_directory': '.'}
12:46:43 DISPATCHER: Starting worker discovery
12:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:43 DISPATCHER: Finished worker discovery
12:47:43 DISPATCHER: Starting worker discovery
12:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:43 DISPATCHER: Finished worker discovery
12:48:43 DISPATCHER: Starting worker discovery
12:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:43 DISPATCHER: Finished worker discovery
12:49:43 DISPATCHER: Starting worker discovery
12:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:43 DISPATCHER: Finished worker discovery
12:50:43 DISPATCHER: Starting worker discovery
12:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:43 DISPATCHER: Finished worker discovery
12:51:43 DISPATCHER: Starting worker discovery
12:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:44 DISPATCHER: Finished worker discovery
12:52:44 DISPATCHER: Starting worker discovery
12:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:44 DISPATCHER: Finished worker discovery
12:53:44 DISPATCHER: Starting worker discovery
12:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:44 DISPATCHER: Finished worker discovery
12:54:44 DISPATCHER: Starting worker discovery
12:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:44 DISPATCHER: Finished worker discovery
12:55:44 DISPATCHER: Starting worker discovery
12:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:44 DISPATCHER: Finished worker discovery
12:56:44 DISPATCHER: Starting worker discovery
12:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:44 DISPATCHER: Finished worker discovery
12:57:44 DISPATCHER: Starting worker discovery
12:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:44 DISPATCHER: Finished worker discovery
12:58:44 DISPATCHER: Starting worker discovery
12:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:44 DISPATCHER: Finished worker discovery
12:59:44 DISPATCHER: Starting worker discovery
12:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:44 DISPATCHER: Finished worker discovery
13:00:44 DISPATCHER: Starting worker discovery
13:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:44 DISPATCHER: Finished worker discovery
13:01:44 DISPATCHER: Starting worker discovery
13:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:44 DISPATCHER: Finished worker discovery
13:02:44 DISPATCHER: Starting worker discovery
13:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:44 DISPATCHER: Finished worker discovery
13:03:44 DISPATCHER: Starting worker discovery
13:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:44 DISPATCHER: Finished worker discovery
13:04:44 DISPATCHER: Starting worker discovery
13:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:44 DISPATCHER: Finished worker discovery
13:05:44 DISPATCHER: Starting worker discovery
13:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:44 DISPATCHER: Finished worker discovery
13:06:09 WORKER: done with job (1, 0, 0), trying to register it.
13:06:09 WORKER: registered result for job (1, 0, 0) with dispatcher
13:06:09 DISPATCHER: job (1, 0, 0) finished
13:06:09 DISPATCHER: register_result: lock acquired
13:06:09 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:06:09 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3754954409786207, 'info': {'data02': 0.3754954409786207, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05578283363694442, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04607291786349837, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 31}"}}
exception: None

13:06:09 job_callback for (1, 0, 0) started
13:06:09 DISPATCHER: Trying to submit another job.
13:06:09 job_callback for (1, 0, 0) got condition
13:06:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:06:09 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:06:09 HBMASTER: Trying to run another job!
13:06:09 job_callback for (1, 0, 0) finished
13:06:09 start sampling a new configuration.
13:06:09 done sampling a new configuration.
13:06:09 HBMASTER: schedule new run for iteration 2
13:06:09 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
13:06:09 HBMASTER: submitting job (2, 0, 0) to dispatcher
13:06:09 DISPATCHER: trying to submit job (2, 0, 0)
13:06:09 DISPATCHER: trying to notify the job_runner thread.
13:06:09 HBMASTER: job (2, 0, 0) submitted to dispatcher
13:06:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:06:09 DISPATCHER: Trying to submit another job.
13:06:09 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:06:09 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:06:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:06:09 WORKER: start processing job (2, 0, 0)
13:06:09 WORKER: args: ()
13:06:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0464247584994966, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05487336494364645}, 'budget': 400.0, 'working_directory': '.'}
13:06:44 DISPATCHER: Starting worker discovery
13:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:44 DISPATCHER: Finished worker discovery
13:07:44 DISPATCHER: Starting worker discovery
13:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:44 DISPATCHER: Finished worker discovery
13:08:44 DISPATCHER: Starting worker discovery
13:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:44 DISPATCHER: Finished worker discovery
13:09:44 DISPATCHER: Starting worker discovery
13:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:44 DISPATCHER: Finished worker discovery
13:10:44 DISPATCHER: Starting worker discovery
13:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:44 DISPATCHER: Finished worker discovery
13:11:44 DISPATCHER: Starting worker discovery
13:11:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:44 DISPATCHER: Finished worker discovery
13:12:44 DISPATCHER: Starting worker discovery
13:12:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:44 DISPATCHER: Finished worker discovery
13:12:55 WORKER: done with job (2, 0, 0), trying to register it.
13:12:55 WORKER: registered result for job (2, 0, 0) with dispatcher
13:12:55 DISPATCHER: job (2, 0, 0) finished
13:12:55 DISPATCHER: register_result: lock acquired
13:12:55 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:12:55 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0464247584994966, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05487336494364645}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.345370088091364, 'info': {'data02': 0.345370088091364, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0464247584994966, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05487336494364645}"}}
exception: None

13:12:55 job_callback for (2, 0, 0) started
13:12:55 job_callback for (2, 0, 0) got condition
13:12:55 DISPATCHER: Trying to submit another job.
13:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:12:55 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:12:55 HBMASTER: Trying to run another job!
13:12:55 job_callback for (2, 0, 0) finished
13:12:55 start sampling a new configuration.
13:12:55 done sampling a new configuration.
13:12:55 HBMASTER: schedule new run for iteration 2
13:12:55 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
13:12:55 HBMASTER: submitting job (2, 0, 1) to dispatcher
13:12:55 DISPATCHER: trying to submit job (2, 0, 1)
13:12:55 DISPATCHER: trying to notify the job_runner thread.
13:12:55 HBMASTER: job (2, 0, 1) submitted to dispatcher
13:12:55 DISPATCHER: Trying to submit another job.
13:12:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:12:55 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:12:55 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:12:55 WORKER: start processing job (2, 0, 1)
13:12:55 WORKER: args: ()
13:12:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03630217782190372, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.030328274613495628, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 36, 'num_filters_3': 77}, 'budget': 400.0, 'working_directory': '.'}
13:13:44 DISPATCHER: Starting worker discovery
13:13:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:44 DISPATCHER: Finished worker discovery
13:14:44 DISPATCHER: Starting worker discovery
13:14:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:44 DISPATCHER: Finished worker discovery
13:15:44 DISPATCHER: Starting worker discovery
13:15:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:44 DISPATCHER: Finished worker discovery
13:16:44 DISPATCHER: Starting worker discovery
13:16:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:44 DISPATCHER: Finished worker discovery
13:17:44 DISPATCHER: Starting worker discovery
13:17:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:44 DISPATCHER: Finished worker discovery
13:18:44 DISPATCHER: Starting worker discovery
13:18:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:44 DISPATCHER: Finished worker discovery
13:19:43 WORKER: done with job (2, 0, 1), trying to register it.
13:19:43 WORKER: registered result for job (2, 0, 1) with dispatcher
13:19:43 DISPATCHER: job (2, 0, 1) finished
13:19:43 DISPATCHER: register_result: lock acquired
13:19:43 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:19:43 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03630217782190372, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.030328274613495628, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 36, 'num_filters_3': 77}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03630217782190372, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.030328274613495628, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 36, 'num_filters_3': 77}"}}
exception: None

13:19:43 job_callback for (2, 0, 1) started
13:19:43 job_callback for (2, 0, 1) got condition
13:19:43 DISPATCHER: Trying to submit another job.
13:19:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:19:43 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:19:43 HBMASTER: Trying to run another job!
13:19:43 job_callback for (2, 0, 1) finished
13:19:43 start sampling a new configuration.
13:19:43 done sampling a new configuration.
13:19:43 HBMASTER: schedule new run for iteration 2
13:19:43 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
13:19:43 HBMASTER: submitting job (2, 0, 2) to dispatcher
13:19:43 DISPATCHER: trying to submit job (2, 0, 2)
13:19:43 DISPATCHER: trying to notify the job_runner thread.
13:19:43 HBMASTER: job (2, 0, 2) submitted to dispatcher
13:19:43 DISPATCHER: Trying to submit another job.
13:19:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:19:43 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:19:43 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:19:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:19:43 WORKER: start processing job (2, 0, 2)
13:19:43 WORKER: args: ()
13:19:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003260633697594683, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.15617476280644085, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 73, 'num_filters_3': 20, 'num_filters_4': 20, 'num_filters_5': 38}, 'budget': 400.0, 'working_directory': '.'}
13:19:44 DISPATCHER: Starting worker discovery
13:19:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:44 DISPATCHER: Finished worker discovery
13:20:44 DISPATCHER: Starting worker discovery
13:20:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:44 DISPATCHER: Finished worker discovery
13:21:44 DISPATCHER: Starting worker discovery
13:21:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:44 DISPATCHER: Finished worker discovery
13:22:44 DISPATCHER: Starting worker discovery
13:22:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:44 DISPATCHER: Finished worker discovery
13:23:44 DISPATCHER: Starting worker discovery
13:23:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:44 DISPATCHER: Finished worker discovery
13:24:44 DISPATCHER: Starting worker discovery
13:24:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:44 DISPATCHER: Finished worker discovery
13:25:44 DISPATCHER: Starting worker discovery
13:25:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:44 DISPATCHER: Finished worker discovery
13:26:29 WORKER: done with job (2, 0, 2), trying to register it.
13:26:29 WORKER: registered result for job (2, 0, 2) with dispatcher
13:26:29 DISPATCHER: job (2, 0, 2) finished
13:26:29 DISPATCHER: register_result: lock acquired
13:26:29 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:26:29 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003260633697594683, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.15617476280644085, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 73, 'num_filters_3': 20, 'num_filters_4': 20, 'num_filters_5': 38}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6025671260809692, 'info': {'data02': 0.6025671260809692, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003260633697594683, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.15617476280644085, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 73, 'num_filters_3': 20, 'num_filters_4': 20, 'num_filters_5': 38}"}}
exception: None

13:26:29 job_callback for (2, 0, 2) started
13:26:29 DISPATCHER: Trying to submit another job.
13:26:29 job_callback for (2, 0, 2) got condition
13:26:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:26:29 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:26:29 HBMASTER: Trying to run another job!
13:26:29 job_callback for (2, 0, 2) finished
13:26:29 start sampling a new configuration.
13:26:29 done sampling a new configuration.
13:26:29 HBMASTER: schedule new run for iteration 2
13:26:29 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
13:26:29 HBMASTER: submitting job (2, 0, 3) to dispatcher
13:26:29 DISPATCHER: trying to submit job (2, 0, 3)
13:26:29 DISPATCHER: trying to notify the job_runner thread.
13:26:29 HBMASTER: job (2, 0, 3) submitted to dispatcher
13:26:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:26:29 DISPATCHER: Trying to submit another job.
13:26:29 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:26:29 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:26:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:26:29 WORKER: start processing job (2, 0, 3)
13:26:29 WORKER: args: ()
13:26:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.08694981819319905, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.0687551358370445}, 'budget': 400.0, 'working_directory': '.'}
13:26:44 DISPATCHER: Starting worker discovery
13:26:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:44 DISPATCHER: Finished worker discovery
13:27:44 DISPATCHER: Starting worker discovery
13:27:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:44 DISPATCHER: Finished worker discovery
13:28:44 DISPATCHER: Starting worker discovery
13:28:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:44 DISPATCHER: Finished worker discovery
13:29:44 DISPATCHER: Starting worker discovery
13:29:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:44 DISPATCHER: Finished worker discovery
13:30:44 DISPATCHER: Starting worker discovery
13:30:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:44 DISPATCHER: Finished worker discovery
13:31:44 DISPATCHER: Starting worker discovery
13:31:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:44 DISPATCHER: Finished worker discovery
13:32:44 DISPATCHER: Starting worker discovery
13:32:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:44 DISPATCHER: Finished worker discovery
13:33:27 WORKER: done with job (2, 0, 3), trying to register it.
13:33:27 WORKER: registered result for job (2, 0, 3) with dispatcher
13:33:27 DISPATCHER: job (2, 0, 3) finished
13:33:27 DISPATCHER: register_result: lock acquired
13:33:27 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:33:27 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.08694981819319905, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.0687551358370445}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.060156416959742845, 'info': {'data02': 0.060156416959742845, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.08694981819319905, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.0687551358370445}"}}
exception: None

13:33:27 job_callback for (2, 0, 3) started
13:33:27 job_callback for (2, 0, 3) got condition
13:33:27 DISPATCHER: Trying to submit another job.
13:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:33:27 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:33:27 HBMASTER: Trying to run another job!
13:33:27 job_callback for (2, 0, 3) finished
13:33:27 start sampling a new configuration.
13:33:27 done sampling a new configuration.
13:33:27 HBMASTER: schedule new run for iteration 2
13:33:27 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
13:33:27 HBMASTER: submitting job (2, 0, 4) to dispatcher
13:33:27 DISPATCHER: trying to submit job (2, 0, 4)
13:33:27 DISPATCHER: trying to notify the job_runner thread.
13:33:27 HBMASTER: job (2, 0, 4) submitted to dispatcher
13:33:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:33:27 DISPATCHER: Trying to submit another job.
13:33:27 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:33:27 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:33:27 WORKER: start processing job (2, 0, 4)
13:33:27 WORKER: args: ()
13:33:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02076069888744071, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.059603037001802785, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 104, 'num_filters_3': 50}, 'budget': 400.0, 'working_directory': '.'}
13:33:44 DISPATCHER: Starting worker discovery
13:33:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:44 DISPATCHER: Finished worker discovery
13:34:44 DISPATCHER: Starting worker discovery
13:34:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:44 DISPATCHER: Finished worker discovery
13:35:44 DISPATCHER: Starting worker discovery
13:35:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:44 DISPATCHER: Finished worker discovery
13:36:44 DISPATCHER: Starting worker discovery
13:36:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:44 DISPATCHER: Finished worker discovery
13:37:44 DISPATCHER: Starting worker discovery
13:37:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:44 DISPATCHER: Finished worker discovery
13:38:44 DISPATCHER: Starting worker discovery
13:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:44 DISPATCHER: Finished worker discovery
13:39:44 DISPATCHER: Starting worker discovery
13:39:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:44 DISPATCHER: Finished worker discovery
13:40:13 WORKER: done with job (2, 0, 4), trying to register it.
13:40:13 WORKER: registered result for job (2, 0, 4) with dispatcher
13:40:13 DISPATCHER: job (2, 0, 4) finished
13:40:13 DISPATCHER: register_result: lock acquired
13:40:13 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:40:13 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02076069888744071, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.059603037001802785, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 104, 'num_filters_3': 50}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2971284021917117, 'info': {'data02': 0.2971284021917117, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02076069888744071, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.059603037001802785, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 104, 'num_filters_3': 50}"}}
exception: None

13:40:13 job_callback for (2, 0, 4) started
13:40:13 DISPATCHER: Trying to submit another job.
13:40:13 job_callback for (2, 0, 4) got condition
13:40:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:40:13 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:40:13 HBMASTER: Trying to run another job!
13:40:13 job_callback for (2, 0, 4) finished
13:40:13 start sampling a new configuration.
13:40:13 done sampling a new configuration.
13:40:13 HBMASTER: schedule new run for iteration 2
13:40:13 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
13:40:13 HBMASTER: submitting job (2, 0, 5) to dispatcher
13:40:13 DISPATCHER: trying to submit job (2, 0, 5)
13:40:13 DISPATCHER: trying to notify the job_runner thread.
13:40:13 HBMASTER: job (2, 0, 5) submitted to dispatcher
13:40:13 DISPATCHER: Trying to submit another job.
13:40:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:40:13 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:40:13 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:40:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:40:13 WORKER: start processing job (2, 0, 5)
13:40:13 WORKER: args: ()
13:40:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020990876413102846, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.02368810489052055, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 28}, 'budget': 400.0, 'working_directory': '.'}
13:40:44 DISPATCHER: Starting worker discovery
13:40:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:44 DISPATCHER: Finished worker discovery
13:41:44 DISPATCHER: Starting worker discovery
13:41:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:44 DISPATCHER: Finished worker discovery
13:42:44 DISPATCHER: Starting worker discovery
13:42:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:44 DISPATCHER: Finished worker discovery
13:43:44 DISPATCHER: Starting worker discovery
13:43:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:44 DISPATCHER: Finished worker discovery
13:44:44 DISPATCHER: Starting worker discovery
13:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:44 DISPATCHER: Finished worker discovery
13:45:44 DISPATCHER: Starting worker discovery
13:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:44 DISPATCHER: Finished worker discovery
13:46:44 DISPATCHER: Starting worker discovery
13:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:44 DISPATCHER: Finished worker discovery
13:47:03 WORKER: done with job (2, 0, 5), trying to register it.
13:47:03 WORKER: registered result for job (2, 0, 5) with dispatcher
13:47:03 DISPATCHER: job (2, 0, 5) finished
13:47:03 DISPATCHER: register_result: lock acquired
13:47:03 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:47:03 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020990876413102846, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.02368810489052055, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 28}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -6.393450180721687e-05, 'info': {'data02': 6.393450180721687e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020990876413102846, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.02368810489052055, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 28}"}}
exception: None

13:47:03 job_callback for (2, 0, 5) started
13:47:03 job_callback for (2, 0, 5) got condition
13:47:03 DISPATCHER: Trying to submit another job.
13:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:47:03 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:47:03 HBMASTER: Trying to run another job!
13:47:03 job_callback for (2, 0, 5) finished
13:47:03 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
13:47:03 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
13:47:03 HBMASTER: schedule new run for iteration 2
13:47:03 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
13:47:03 HBMASTER: submitting job (2, 0, 0) to dispatcher
13:47:03 DISPATCHER: trying to submit job (2, 0, 0)
13:47:03 DISPATCHER: trying to notify the job_runner thread.
13:47:03 HBMASTER: job (2, 0, 0) submitted to dispatcher
13:47:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:47:03 DISPATCHER: Trying to submit another job.
13:47:03 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:47:03 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:47:03 WORKER: start processing job (2, 0, 0)
13:47:03 WORKER: args: ()
13:47:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0464247584994966, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05487336494364645}, 'budget': 1200.0, 'working_directory': '.'}
13:47:44 DISPATCHER: Starting worker discovery
13:47:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:44 DISPATCHER: Finished worker discovery
13:48:44 DISPATCHER: Starting worker discovery
13:48:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:44 DISPATCHER: Finished worker discovery
13:49:44 DISPATCHER: Starting worker discovery
13:49:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:44 DISPATCHER: Finished worker discovery
13:50:44 DISPATCHER: Starting worker discovery
13:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:44 DISPATCHER: Finished worker discovery
13:51:44 DISPATCHER: Starting worker discovery
13:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:44 DISPATCHER: Finished worker discovery
13:52:44 DISPATCHER: Starting worker discovery
13:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:44 DISPATCHER: Finished worker discovery
13:53:44 DISPATCHER: Starting worker discovery
13:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:44 DISPATCHER: Finished worker discovery
13:54:44 DISPATCHER: Starting worker discovery
13:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:44 DISPATCHER: Finished worker discovery
13:55:44 DISPATCHER: Starting worker discovery
13:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:44 DISPATCHER: Finished worker discovery
13:56:44 DISPATCHER: Starting worker discovery
13:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:44 DISPATCHER: Finished worker discovery
13:57:44 DISPATCHER: Starting worker discovery
13:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:44 DISPATCHER: Finished worker discovery
13:58:44 DISPATCHER: Starting worker discovery
13:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:44 DISPATCHER: Finished worker discovery
13:59:44 DISPATCHER: Starting worker discovery
13:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:44 DISPATCHER: Finished worker discovery
14:00:44 DISPATCHER: Starting worker discovery
14:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:44 DISPATCHER: Finished worker discovery
14:01:44 DISPATCHER: Starting worker discovery
14:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:44 DISPATCHER: Finished worker discovery
14:02:44 DISPATCHER: Starting worker discovery
14:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:44 DISPATCHER: Finished worker discovery
14:03:44 DISPATCHER: Starting worker discovery
14:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:44 DISPATCHER: Finished worker discovery
14:04:44 DISPATCHER: Starting worker discovery
14:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:44 DISPATCHER: Finished worker discovery
14:05:44 DISPATCHER: Starting worker discovery
14:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:44 DISPATCHER: Finished worker discovery
14:06:44 DISPATCHER: Starting worker discovery
14:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:44 DISPATCHER: Finished worker discovery
14:07:14 WORKER: done with job (2, 0, 0), trying to register it.
14:07:14 WORKER: registered result for job (2, 0, 0) with dispatcher
14:07:14 DISPATCHER: job (2, 0, 0) finished
14:07:14 DISPATCHER: register_result: lock acquired
14:07:14 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:07:14 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0464247584994966, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05487336494364645}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.30786839549714334, 'info': {'data02': 0.30786839549714334, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0464247584994966, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05487336494364645}"}}
exception: None

14:07:14 job_callback for (2, 0, 0) started
14:07:14 DISPATCHER: Trying to submit another job.
14:07:14 job_callback for (2, 0, 0) got condition
14:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:07:14 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:07:14 HBMASTER: Trying to run another job!
14:07:14 job_callback for (2, 0, 0) finished
14:07:14 HBMASTER: schedule new run for iteration 2
14:07:14 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
14:07:14 HBMASTER: submitting job (2, 0, 2) to dispatcher
14:07:14 DISPATCHER: trying to submit job (2, 0, 2)
14:07:14 DISPATCHER: trying to notify the job_runner thread.
14:07:14 HBMASTER: job (2, 0, 2) submitted to dispatcher
14:07:14 DISPATCHER: Trying to submit another job.
14:07:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:07:14 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:07:14 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:07:14 WORKER: start processing job (2, 0, 2)
14:07:14 WORKER: args: ()
14:07:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003260633697594683, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.15617476280644085, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 73, 'num_filters_3': 20, 'num_filters_4': 20, 'num_filters_5': 38}, 'budget': 1200.0, 'working_directory': '.'}
14:07:44 DISPATCHER: Starting worker discovery
14:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:44 DISPATCHER: Finished worker discovery
14:08:44 DISPATCHER: Starting worker discovery
14:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:44 DISPATCHER: Finished worker discovery
14:09:44 DISPATCHER: Starting worker discovery
14:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:44 DISPATCHER: Finished worker discovery
14:10:44 DISPATCHER: Starting worker discovery
14:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:44 DISPATCHER: Finished worker discovery
14:11:44 DISPATCHER: Starting worker discovery
14:11:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:44 DISPATCHER: Finished worker discovery
14:12:44 DISPATCHER: Starting worker discovery
14:12:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:44 DISPATCHER: Finished worker discovery
14:13:44 DISPATCHER: Starting worker discovery
14:13:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:44 DISPATCHER: Finished worker discovery
14:14:44 DISPATCHER: Starting worker discovery
14:14:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:44 DISPATCHER: Finished worker discovery
14:15:44 DISPATCHER: Starting worker discovery
14:15:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:44 DISPATCHER: Finished worker discovery
14:16:44 DISPATCHER: Starting worker discovery
14:16:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:44 DISPATCHER: Finished worker discovery
14:17:44 DISPATCHER: Starting worker discovery
14:17:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:44 DISPATCHER: Finished worker discovery
14:18:44 DISPATCHER: Starting worker discovery
14:18:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:44 DISPATCHER: Finished worker discovery
14:19:44 DISPATCHER: Starting worker discovery
14:19:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:44 DISPATCHER: Finished worker discovery
14:20:44 DISPATCHER: Starting worker discovery
14:20:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:44 DISPATCHER: Finished worker discovery
14:21:44 DISPATCHER: Starting worker discovery
14:21:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:44 DISPATCHER: Finished worker discovery
14:22:44 DISPATCHER: Starting worker discovery
14:22:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:44 DISPATCHER: Finished worker discovery
14:23:44 DISPATCHER: Starting worker discovery
14:23:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:44 DISPATCHER: Finished worker discovery
14:24:44 DISPATCHER: Starting worker discovery
14:24:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:44 DISPATCHER: Finished worker discovery
14:25:44 DISPATCHER: Starting worker discovery
14:25:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:44 DISPATCHER: Finished worker discovery
14:26:44 DISPATCHER: Starting worker discovery
14:26:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:44 DISPATCHER: Finished worker discovery
14:27:21 WORKER: done with job (2, 0, 2), trying to register it.
14:27:21 WORKER: registered result for job (2, 0, 2) with dispatcher
14:27:21 DISPATCHER: job (2, 0, 2) finished
14:27:21 DISPATCHER: register_result: lock acquired
14:27:21 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:27:21 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003260633697594683, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.15617476280644085, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 73, 'num_filters_3': 20, 'num_filters_4': 20, 'num_filters_5': 38}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6008893169460411, 'info': {'data02': 0.6008893169460411, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003260633697594683, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.15617476280644085, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 73, 'num_filters_3': 20, 'num_filters_4': 20, 'num_filters_5': 38}"}}
exception: None

14:27:21 job_callback for (2, 0, 2) started
14:27:21 DISPATCHER: Trying to submit another job.
14:27:21 job_callback for (2, 0, 2) got condition
14:27:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:27:21 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:27:21 HBMASTER: Trying to run another job!
14:27:21 job_callback for (2, 0, 2) finished
14:27:21 start sampling a new configuration.
14:27:21 done sampling a new configuration.
14:27:21 HBMASTER: schedule new run for iteration 3
14:27:21 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
14:27:21 HBMASTER: submitting job (3, 0, 0) to dispatcher
14:27:21 DISPATCHER: trying to submit job (3, 0, 0)
14:27:21 DISPATCHER: trying to notify the job_runner thread.
14:27:21 HBMASTER: job (3, 0, 0) submitted to dispatcher
14:27:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:27:21 DISPATCHER: Trying to submit another job.
14:27:21 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:27:21 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:27:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:27:21 WORKER: start processing job (3, 0, 0)
14:27:21 WORKER: args: ()
14:27:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06434428718584, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.06402975006464623, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 19, 'num_filters_4': 54, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
14:27:44 DISPATCHER: Starting worker discovery
14:27:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:44 DISPATCHER: Finished worker discovery
14:28:44 DISPATCHER: Starting worker discovery
14:28:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:44 DISPATCHER: Finished worker discovery
14:29:44 DISPATCHER: Starting worker discovery
14:29:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:44 DISPATCHER: Finished worker discovery
14:30:44 DISPATCHER: Starting worker discovery
14:30:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:44 DISPATCHER: Finished worker discovery
14:31:44 DISPATCHER: Starting worker discovery
14:31:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:44 DISPATCHER: Finished worker discovery
14:32:44 DISPATCHER: Starting worker discovery
14:32:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:44 DISPATCHER: Finished worker discovery
14:33:44 DISPATCHER: Starting worker discovery
14:33:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:44 DISPATCHER: Finished worker discovery
14:34:44 DISPATCHER: Starting worker discovery
14:34:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:44 DISPATCHER: Finished worker discovery
14:35:44 DISPATCHER: Starting worker discovery
14:35:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:44 DISPATCHER: Finished worker discovery
14:36:44 DISPATCHER: Starting worker discovery
14:36:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:44 DISPATCHER: Finished worker discovery
14:37:44 DISPATCHER: Starting worker discovery
14:37:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:44 DISPATCHER: Finished worker discovery
14:38:44 DISPATCHER: Starting worker discovery
14:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:44 DISPATCHER: Finished worker discovery
14:39:44 DISPATCHER: Starting worker discovery
14:39:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:44 DISPATCHER: Finished worker discovery
14:40:44 DISPATCHER: Starting worker discovery
14:40:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:44 DISPATCHER: Finished worker discovery
14:41:44 DISPATCHER: Starting worker discovery
14:41:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:44 DISPATCHER: Finished worker discovery
14:42:44 DISPATCHER: Starting worker discovery
14:42:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:44 DISPATCHER: Finished worker discovery
14:43:44 DISPATCHER: Starting worker discovery
14:43:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:44 DISPATCHER: Finished worker discovery
14:44:44 DISPATCHER: Starting worker discovery
14:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:44 DISPATCHER: Finished worker discovery
14:45:44 DISPATCHER: Starting worker discovery
14:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:44 DISPATCHER: Finished worker discovery
14:46:44 DISPATCHER: Starting worker discovery
14:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:44 DISPATCHER: Finished worker discovery
14:47:29 WORKER: done with job (3, 0, 0), trying to register it.
14:47:29 WORKER: registered result for job (3, 0, 0) with dispatcher
14:47:29 DISPATCHER: job (3, 0, 0) finished
14:47:29 DISPATCHER: register_result: lock acquired
14:47:29 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:47:29 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06434428718584, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.06402975006464623, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 19, 'num_filters_4': 54, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -9.555896381521184e-05, 'info': {'data02': 9.555896381521184e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06434428718584, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.06402975006464623, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 19, 'num_filters_4': 54, 'num_filters_5': 24}"}}
exception: None

14:47:29 job_callback for (3, 0, 0) started
14:47:29 job_callback for (3, 0, 0) got condition
14:47:29 DISPATCHER: Trying to submit another job.
14:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:47:29 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:47:29 HBMASTER: Trying to run another job!
14:47:29 job_callback for (3, 0, 0) finished
14:47:29 start sampling a new configuration.
14:47:29 done sampling a new configuration.
14:47:29 HBMASTER: schedule new run for iteration 3
14:47:29 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
14:47:29 HBMASTER: submitting job (3, 0, 1) to dispatcher
14:47:29 DISPATCHER: trying to submit job (3, 0, 1)
14:47:29 DISPATCHER: trying to notify the job_runner thread.
14:47:29 HBMASTER: job (3, 0, 1) submitted to dispatcher
14:47:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:47:29 DISPATCHER: Trying to submit another job.
14:47:29 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:47:29 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:47:29 WORKER: start processing job (3, 0, 1)
14:47:29 WORKER: args: ()
14:47:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004777992265143173, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.016673928717620665, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 28, 'num_filters_4': 49}, 'budget': 1200.0, 'working_directory': '.'}
14:47:44 DISPATCHER: Starting worker discovery
14:47:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:44 DISPATCHER: Finished worker discovery
14:48:44 DISPATCHER: Starting worker discovery
14:48:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:44 DISPATCHER: Finished worker discovery
14:49:44 DISPATCHER: Starting worker discovery
14:49:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:44 DISPATCHER: Finished worker discovery
14:50:44 DISPATCHER: Starting worker discovery
14:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:44 DISPATCHER: Finished worker discovery
14:51:44 DISPATCHER: Starting worker discovery
14:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:44 DISPATCHER: Finished worker discovery
14:52:44 DISPATCHER: Starting worker discovery
14:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:44 DISPATCHER: Finished worker discovery
14:53:44 DISPATCHER: Starting worker discovery
14:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:44 DISPATCHER: Finished worker discovery
14:54:44 DISPATCHER: Starting worker discovery
14:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:44 DISPATCHER: Finished worker discovery
14:55:44 DISPATCHER: Starting worker discovery
14:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:44 DISPATCHER: Finished worker discovery
14:56:44 DISPATCHER: Starting worker discovery
14:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:44 DISPATCHER: Finished worker discovery
14:57:44 DISPATCHER: Starting worker discovery
14:57:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:45 DISPATCHER: Finished worker discovery
14:58:45 DISPATCHER: Starting worker discovery
14:58:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:45 DISPATCHER: Finished worker discovery
14:59:45 DISPATCHER: Starting worker discovery
14:59:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:45 DISPATCHER: Finished worker discovery
15:00:45 DISPATCHER: Starting worker discovery
15:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:45 DISPATCHER: Finished worker discovery
15:01:45 DISPATCHER: Starting worker discovery
15:01:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:45 DISPATCHER: Finished worker discovery
15:02:45 DISPATCHER: Starting worker discovery
15:02:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:45 DISPATCHER: Finished worker discovery
15:03:45 DISPATCHER: Starting worker discovery
15:03:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:45 DISPATCHER: Finished worker discovery
15:04:45 DISPATCHER: Starting worker discovery
15:04:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:45 DISPATCHER: Finished worker discovery
15:05:45 DISPATCHER: Starting worker discovery
15:05:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:45 DISPATCHER: Finished worker discovery
15:06:45 DISPATCHER: Starting worker discovery
15:06:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:45 DISPATCHER: Finished worker discovery
15:07:38 WORKER: done with job (3, 0, 1), trying to register it.
15:07:38 WORKER: registered result for job (3, 0, 1) with dispatcher
15:07:38 DISPATCHER: job (3, 0, 1) finished
15:07:38 DISPATCHER: register_result: lock acquired
15:07:38 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:07:38 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004777992265143173, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.016673928717620665, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 28, 'num_filters_4': 49}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6768944735724045, 'info': {'data02': 0.6768944735724045, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004777992265143173, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.016673928717620665, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 28, 'num_filters_4': 49}"}}
exception: None

15:07:38 job_callback for (3, 0, 1) started
15:07:38 job_callback for (3, 0, 1) got condition
15:07:38 DISPATCHER: Trying to submit another job.
15:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:07:38 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:07:38 HBMASTER: Trying to run another job!
15:07:38 job_callback for (3, 0, 1) finished
15:07:38 start sampling a new configuration.
15:07:38 done sampling a new configuration.
15:07:38 HBMASTER: schedule new run for iteration 3
15:07:38 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
15:07:38 HBMASTER: submitting job (3, 0, 2) to dispatcher
15:07:38 DISPATCHER: trying to submit job (3, 0, 2)
15:07:38 DISPATCHER: trying to notify the job_runner thread.
15:07:38 HBMASTER: job (3, 0, 2) submitted to dispatcher
15:07:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:07:38 DISPATCHER: Trying to submit another job.
15:07:38 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:07:38 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:07:38 WORKER: start processing job (3, 0, 2)
15:07:38 WORKER: args: ()
15:07:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012153664140646134, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.021722917781524506, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 47, 'num_filters_4': 23, 'num_filters_5': 21}, 'budget': 1200.0, 'working_directory': '.'}
15:07:45 DISPATCHER: Starting worker discovery
15:07:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:45 DISPATCHER: Finished worker discovery
15:08:45 DISPATCHER: Starting worker discovery
15:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:45 DISPATCHER: Finished worker discovery
15:09:45 DISPATCHER: Starting worker discovery
15:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:45 DISPATCHER: Finished worker discovery
15:10:45 DISPATCHER: Starting worker discovery
15:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:45 DISPATCHER: Finished worker discovery
15:11:45 DISPATCHER: Starting worker discovery
15:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:45 DISPATCHER: Finished worker discovery
15:12:45 DISPATCHER: Starting worker discovery
15:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:45 DISPATCHER: Finished worker discovery
15:13:45 DISPATCHER: Starting worker discovery
15:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:45 DISPATCHER: Finished worker discovery
15:14:45 DISPATCHER: Starting worker discovery
15:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:45 DISPATCHER: Finished worker discovery
15:15:45 DISPATCHER: Starting worker discovery
15:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:45 DISPATCHER: Finished worker discovery
15:16:45 DISPATCHER: Starting worker discovery
15:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:45 DISPATCHER: Finished worker discovery
15:17:45 DISPATCHER: Starting worker discovery
15:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:45 DISPATCHER: Finished worker discovery
15:18:45 DISPATCHER: Starting worker discovery
15:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:45 DISPATCHER: Finished worker discovery
15:19:45 DISPATCHER: Starting worker discovery
15:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:45 DISPATCHER: Finished worker discovery
15:20:45 DISPATCHER: Starting worker discovery
15:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:45 DISPATCHER: Finished worker discovery
15:21:45 DISPATCHER: Starting worker discovery
15:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:45 DISPATCHER: Finished worker discovery
15:22:45 DISPATCHER: Starting worker discovery
15:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:45 DISPATCHER: Finished worker discovery
15:23:45 DISPATCHER: Starting worker discovery
15:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:45 DISPATCHER: Finished worker discovery
15:24:45 DISPATCHER: Starting worker discovery
15:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:45 DISPATCHER: Finished worker discovery
15:25:45 DISPATCHER: Starting worker discovery
15:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:45 DISPATCHER: Finished worker discovery
15:26:45 DISPATCHER: Starting worker discovery
15:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:45 DISPATCHER: Finished worker discovery
15:27:45 DISPATCHER: Starting worker discovery
15:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:45 DISPATCHER: Finished worker discovery
15:27:45 WORKER: done with job (3, 0, 2), trying to register it.
15:27:45 WORKER: registered result for job (3, 0, 2) with dispatcher
15:27:45 DISPATCHER: job (3, 0, 2) finished
15:27:45 DISPATCHER: register_result: lock acquired
15:27:45 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:27:45 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012153664140646134, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.021722917781524506, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 47, 'num_filters_4': 23, 'num_filters_5': 21}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5462076210307305, 'info': {'data02': 0.5462076210307305, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012153664140646134, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.021722917781524506, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 47, 'num_filters_4': 23, 'num_filters_5': 21}"}}
exception: None

15:27:45 job_callback for (3, 0, 2) started
15:27:45 DISPATCHER: Trying to submit another job.
15:27:45 job_callback for (3, 0, 2) got condition
15:27:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:27:45 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:27:45 HBMASTER: Trying to run another job!
15:27:45 job_callback for (3, 0, 2) finished
15:27:45 start sampling a new configuration.
15:27:45 done sampling a new configuration.
15:27:45 HBMASTER: schedule new run for iteration 3
15:27:45 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
15:27:45 HBMASTER: submitting job (3, 0, 3) to dispatcher
15:27:45 DISPATCHER: trying to submit job (3, 0, 3)
15:27:45 DISPATCHER: trying to notify the job_runner thread.
15:27:45 HBMASTER: job (3, 0, 3) submitted to dispatcher
15:27:45 DISPATCHER: Trying to submit another job.
15:27:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:27:45 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:27:45 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:27:45 WORKER: start processing job (3, 0, 3)
15:27:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:27:45 WORKER: args: ()
15:27:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010437813347091622, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.03342488165322357}, 'budget': 1200.0, 'working_directory': '.'}
15:28:45 DISPATCHER: Starting worker discovery
15:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:45 DISPATCHER: Finished worker discovery
15:29:45 DISPATCHER: Starting worker discovery
15:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:45 DISPATCHER: Finished worker discovery
15:30:45 DISPATCHER: Starting worker discovery
15:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:45 DISPATCHER: Finished worker discovery
15:31:45 DISPATCHER: Starting worker discovery
15:31:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:45 DISPATCHER: Finished worker discovery
15:32:45 DISPATCHER: Starting worker discovery
15:32:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:45 DISPATCHER: Finished worker discovery
15:33:45 DISPATCHER: Starting worker discovery
15:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:45 DISPATCHER: Finished worker discovery
15:34:45 DISPATCHER: Starting worker discovery
15:34:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:45 DISPATCHER: Finished worker discovery
15:35:45 DISPATCHER: Starting worker discovery
15:35:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:45 DISPATCHER: Finished worker discovery
15:36:45 DISPATCHER: Starting worker discovery
15:36:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:45 DISPATCHER: Finished worker discovery
15:37:45 DISPATCHER: Starting worker discovery
15:37:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:45 DISPATCHER: Finished worker discovery
15:38:45 DISPATCHER: Starting worker discovery
15:38:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:45 DISPATCHER: Finished worker discovery
15:39:45 DISPATCHER: Starting worker discovery
15:39:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:45 DISPATCHER: Finished worker discovery
15:40:45 DISPATCHER: Starting worker discovery
15:40:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:45 DISPATCHER: Finished worker discovery
15:41:45 DISPATCHER: Starting worker discovery
15:41:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:45 DISPATCHER: Finished worker discovery
15:42:45 DISPATCHER: Starting worker discovery
15:42:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:45 DISPATCHER: Finished worker discovery
15:43:45 DISPATCHER: Starting worker discovery
15:43:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:45 DISPATCHER: Finished worker discovery
15:44:45 DISPATCHER: Starting worker discovery
15:44:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:45 DISPATCHER: Finished worker discovery
15:45:45 DISPATCHER: Starting worker discovery
15:45:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:45 DISPATCHER: Finished worker discovery
15:46:45 DISPATCHER: Starting worker discovery
15:46:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:45 DISPATCHER: Finished worker discovery
15:47:45 DISPATCHER: Starting worker discovery
15:47:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:45 DISPATCHER: Finished worker discovery
15:48:04 WORKER: done with job (3, 0, 3), trying to register it.
15:48:04 WORKER: registered result for job (3, 0, 3) with dispatcher
15:48:04 DISPATCHER: job (3, 0, 3) finished
15:48:04 DISPATCHER: register_result: lock acquired
15:48:04 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:48:04 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010437813347091622, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.03342488165322357}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.42280125841984284, 'info': {'data02': 0.42280125841984284, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010437813347091622, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.03342488165322357}"}}
exception: None

15:48:04 job_callback for (3, 0, 3) started
15:48:04 DISPATCHER: Trying to submit another job.
15:48:04 job_callback for (3, 0, 3) got condition
15:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:04 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:48:04 HBMASTER: Trying to run another job!
15:48:04 job_callback for (3, 0, 3) finished
15:48:04 start sampling a new configuration.
15:48:04 done sampling a new configuration.
15:48:04 HBMASTER: schedule new run for iteration 4
15:48:04 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
15:48:04 HBMASTER: submitting job (4, 0, 0) to dispatcher
15:48:04 DISPATCHER: trying to submit job (4, 0, 0)
15:48:04 DISPATCHER: trying to notify the job_runner thread.
15:48:04 HBMASTER: job (4, 0, 0) submitted to dispatcher
15:48:04 DISPATCHER: Trying to submit another job.
15:48:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:04 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:48:04 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:48:04 WORKER: start processing job (4, 0, 0)
15:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:04 WORKER: args: ()
15:48:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.043666860599137096, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.02896892307910016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 20, 'num_filters_4': 21, 'num_filters_5': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:48:45 DISPATCHER: Starting worker discovery
15:48:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:45 DISPATCHER: Finished worker discovery
15:48:53 WORKER: done with job (4, 0, 0), trying to register it.
15:48:53 WORKER: registered result for job (4, 0, 0) with dispatcher
15:48:53 DISPATCHER: job (4, 0, 0) finished
15:48:53 DISPATCHER: register_result: lock acquired
15:48:53 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:48:53 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.043666860599137096, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.02896892307910016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 20, 'num_filters_4': 21, 'num_filters_5': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.043666860599137096, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.02896892307910016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 20, 'num_filters_4': 21, 'num_filters_5': 96}"}}
exception: None

15:48:53 job_callback for (4, 0, 0) started
15:48:53 DISPATCHER: Trying to submit another job.
15:48:53 job_callback for (4, 0, 0) got condition
15:48:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:53 HBMASTER: Trying to run another job!
15:48:53 job_callback for (4, 0, 0) finished
15:48:53 start sampling a new configuration.
15:48:53 done sampling a new configuration.
15:48:53 HBMASTER: schedule new run for iteration 4
15:48:53 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
15:48:53 HBMASTER: submitting job (4, 0, 1) to dispatcher
15:48:53 DISPATCHER: trying to submit job (4, 0, 1)
15:48:53 DISPATCHER: trying to notify the job_runner thread.
15:48:53 HBMASTER: job (4, 0, 1) submitted to dispatcher
15:48:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:53 DISPATCHER: Trying to submit another job.
15:48:53 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:48:53 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:48:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:53 WORKER: start processing job (4, 0, 1)
15:48:53 WORKER: args: ()
15:48:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.07031904669017185, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.04637754830813018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 37, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:49:42 WORKER: done with job (4, 0, 1), trying to register it.
15:49:42 WORKER: registered result for job (4, 0, 1) with dispatcher
15:49:42 DISPATCHER: job (4, 0, 1) finished
15:49:42 DISPATCHER: register_result: lock acquired
15:49:42 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:49:42 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.07031904669017185, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.04637754830813018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 37, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4463470509433518, 'info': {'data02': 0.4463470509433518, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.07031904669017185, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.04637754830813018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 37, 'num_filters_4': 19}"}}
exception: None

15:49:42 job_callback for (4, 0, 1) started
15:49:42 job_callback for (4, 0, 1) got condition
15:49:42 DISPATCHER: Trying to submit another job.
15:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:49:42 HBMASTER: Trying to run another job!
15:49:42 job_callback for (4, 0, 1) finished
15:49:42 start sampling a new configuration.
15:49:42 done sampling a new configuration.
15:49:42 HBMASTER: schedule new run for iteration 4
15:49:42 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
15:49:42 HBMASTER: submitting job (4, 0, 2) to dispatcher
15:49:42 DISPATCHER: trying to submit job (4, 0, 2)
15:49:42 DISPATCHER: trying to notify the job_runner thread.
15:49:42 HBMASTER: job (4, 0, 2) submitted to dispatcher
15:49:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:49:42 DISPATCHER: Trying to submit another job.
15:49:42 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:49:42 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:49:42 WORKER: start processing job (4, 0, 2)
15:49:42 WORKER: args: ()
15:49:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:49:45 DISPATCHER: Starting worker discovery
15:49:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:45 DISPATCHER: Finished worker discovery
15:50:31 WORKER: done with job (4, 0, 2), trying to register it.
15:50:31 WORKER: registered result for job (4, 0, 2) with dispatcher
15:50:31 DISPATCHER: job (4, 0, 2) finished
15:50:31 DISPATCHER: register_result: lock acquired
15:50:31 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:50:31 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6451056503784927, 'info': {'data02': 0.6451056503784927, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}"}}
exception: None

15:50:31 job_callback for (4, 0, 2) started
15:50:31 job_callback for (4, 0, 2) got condition
15:50:31 DISPATCHER: Trying to submit another job.
15:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:50:31 HBMASTER: Trying to run another job!
15:50:31 job_callback for (4, 0, 2) finished
15:50:31 start sampling a new configuration.
15:50:31 done sampling a new configuration.
15:50:31 HBMASTER: schedule new run for iteration 4
15:50:31 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
15:50:31 HBMASTER: submitting job (4, 0, 3) to dispatcher
15:50:31 DISPATCHER: trying to submit job (4, 0, 3)
15:50:31 DISPATCHER: trying to notify the job_runner thread.
15:50:31 HBMASTER: job (4, 0, 3) submitted to dispatcher
15:50:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:50:31 DISPATCHER: Trying to submit another job.
15:50:31 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:50:31 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:50:31 WORKER: start processing job (4, 0, 3)
15:50:31 WORKER: args: ()
15:50:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005083650692829057, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.029749315514398553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 48, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:50:45 DISPATCHER: Starting worker discovery
15:50:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:45 DISPATCHER: Finished worker discovery
15:51:20 WORKER: done with job (4, 0, 3), trying to register it.
15:51:20 WORKER: registered result for job (4, 0, 3) with dispatcher
15:51:20 DISPATCHER: job (4, 0, 3) finished
15:51:20 DISPATCHER: register_result: lock acquired
15:51:20 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:51:20 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005083650692829057, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.029749315514398553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 48, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5536517107462343, 'info': {'data02': 0.5536517107462343, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005083650692829057, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.029749315514398553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 48, 'num_filters_3': 65}"}}
exception: None

15:51:20 job_callback for (4, 0, 3) started
15:51:20 DISPATCHER: Trying to submit another job.
15:51:20 job_callback for (4, 0, 3) got condition
15:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:51:20 HBMASTER: Trying to run another job!
15:51:20 job_callback for (4, 0, 3) finished
15:51:20 start sampling a new configuration.
15:51:20 done sampling a new configuration.
15:51:20 HBMASTER: schedule new run for iteration 4
15:51:20 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
15:51:20 HBMASTER: submitting job (4, 0, 4) to dispatcher
15:51:20 DISPATCHER: trying to submit job (4, 0, 4)
15:51:20 DISPATCHER: trying to notify the job_runner thread.
15:51:20 HBMASTER: job (4, 0, 4) submitted to dispatcher
15:51:20 DISPATCHER: Trying to submit another job.
15:51:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:51:20 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:51:20 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:51:20 WORKER: start processing job (4, 0, 4)
15:51:20 WORKER: args: ()
15:51:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005250553619544226, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.11786939029549368, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 39, 'num_filters_4': 77, 'num_filters_5': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:51:45 DISPATCHER: Starting worker discovery
15:51:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:45 DISPATCHER: Finished worker discovery
15:52:10 WORKER: done with job (4, 0, 4), trying to register it.
15:52:10 WORKER: registered result for job (4, 0, 4) with dispatcher
15:52:10 DISPATCHER: job (4, 0, 4) finished
15:52:10 DISPATCHER: register_result: lock acquired
15:52:10 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:52:10 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005250553619544226, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.11786939029549368, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 39, 'num_filters_4': 77, 'num_filters_5': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005250553619544226, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.11786939029549368, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 39, 'num_filters_4': 77, 'num_filters_5': 31}"}}
exception: None

15:52:10 job_callback for (4, 0, 4) started
15:52:10 DISPATCHER: Trying to submit another job.
15:52:10 job_callback for (4, 0, 4) got condition
15:52:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:52:10 HBMASTER: Trying to run another job!
15:52:10 job_callback for (4, 0, 4) finished
15:52:10 start sampling a new configuration.
15:52:10 done sampling a new configuration.
15:52:10 HBMASTER: schedule new run for iteration 4
15:52:10 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
15:52:10 HBMASTER: submitting job (4, 0, 5) to dispatcher
15:52:10 DISPATCHER: trying to submit job (4, 0, 5)
15:52:10 DISPATCHER: trying to notify the job_runner thread.
15:52:10 HBMASTER: job (4, 0, 5) submitted to dispatcher
15:52:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:52:10 DISPATCHER: Trying to submit another job.
15:52:10 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:52:10 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:52:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:52:10 WORKER: start processing job (4, 0, 5)
15:52:10 WORKER: args: ()
15:52:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019846709361945318, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.03275651199505678, 'kernel_size_2': 3, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:52:45 DISPATCHER: Starting worker discovery
15:52:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:45 DISPATCHER: Finished worker discovery
15:52:59 WORKER: done with job (4, 0, 5), trying to register it.
15:52:59 WORKER: registered result for job (4, 0, 5) with dispatcher
15:52:59 DISPATCHER: job (4, 0, 5) finished
15:52:59 DISPATCHER: register_result: lock acquired
15:52:59 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:52:59 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019846709361945318, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.03275651199505678, 'kernel_size_2': 3, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.479648419598241, 'info': {'data02': 0.479648419598241, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019846709361945318, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.03275651199505678, 'kernel_size_2': 3, 'num_filters_2': 16}"}}
exception: None

15:52:59 job_callback for (4, 0, 5) started
15:52:59 job_callback for (4, 0, 5) got condition
15:52:59 DISPATCHER: Trying to submit another job.
15:52:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:52:59 HBMASTER: Trying to run another job!
15:52:59 job_callback for (4, 0, 5) finished
15:52:59 start sampling a new configuration.
15:52:59 done sampling a new configuration.
15:52:59 HBMASTER: schedule new run for iteration 4
15:52:59 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
15:52:59 HBMASTER: submitting job (4, 0, 6) to dispatcher
15:52:59 DISPATCHER: trying to submit job (4, 0, 6)
15:52:59 DISPATCHER: trying to notify the job_runner thread.
15:52:59 HBMASTER: job (4, 0, 6) submitted to dispatcher
15:52:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:52:59 DISPATCHER: Trying to submit another job.
15:52:59 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:52:59 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:52:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:52:59 WORKER: start processing job (4, 0, 6)
15:52:59 WORKER: args: ()
15:52:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019182824353914019, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.0174158501947663, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 21, 'num_filters_4': 23, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:53:45 DISPATCHER: Starting worker discovery
15:53:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:45 DISPATCHER: Finished worker discovery
15:53:48 WORKER: done with job (4, 0, 6), trying to register it.
15:53:48 WORKER: registered result for job (4, 0, 6) with dispatcher
15:53:48 DISPATCHER: job (4, 0, 6) finished
15:53:48 DISPATCHER: register_result: lock acquired
15:53:48 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:53:48 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019182824353914019, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.0174158501947663, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 21, 'num_filters_4': 23, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46796424519017865, 'info': {'data02': 0.46796424519017865, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019182824353914019, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.0174158501947663, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 21, 'num_filters_4': 23, 'num_filters_5': 39}"}}
exception: None

15:53:48 job_callback for (4, 0, 6) started
15:53:48 job_callback for (4, 0, 6) got condition
15:53:48 DISPATCHER: Trying to submit another job.
15:53:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:53:48 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.765285





15:53:48 HBMASTER: Trying to run another job!
15:53:48 job_callback for (4, 0, 6) finished
15:53:48 start sampling a new configuration.
15:53:48 done sampling a new configuration.
15:53:48 HBMASTER: schedule new run for iteration 4
15:53:48 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
15:53:48 HBMASTER: submitting job (4, 0, 7) to dispatcher
15:53:48 DISPATCHER: trying to submit job (4, 0, 7)
15:53:48 DISPATCHER: trying to notify the job_runner thread.
15:53:48 HBMASTER: job (4, 0, 7) submitted to dispatcher
15:53:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:53:48 DISPATCHER: Trying to submit another job.
15:53:48 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:53:48 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:53:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:53:48 WORKER: start processing job (4, 0, 7)
15:53:48 WORKER: args: ()
15:53:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.06119741894673742, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.16244008285009198, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:54:37 WORKER: done with job (4, 0, 7), trying to register it.
15:54:37 WORKER: registered result for job (4, 0, 7) with dispatcher
15:54:37 DISPATCHER: job (4, 0, 7) finished
15:54:37 DISPATCHER: register_result: lock acquired
15:54:37 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:54:37 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.06119741894673742, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.16244008285009198, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1552533321283146, 'info': {'data02': 0.1552533321283146, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.06119741894673742, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.16244008285009198, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 16}"}}
exception: None

15:54:37 job_callback for (4, 0, 7) started
15:54:37 job_callback for (4, 0, 7) got condition
15:54:37 DISPATCHER: Trying to submit another job.
15:54:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:54:37 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.765285





15:54:37 HBMASTER: Trying to run another job!
15:54:37 job_callback for (4, 0, 7) finished
15:54:37 start sampling a new configuration.
15:54:37 best_vector: [2, 2, 0.2949030479048037, 0.7860337580331469, 0.11547213745291651, 1, 0.1664214173333517, 0.13134465648080268, 0, 1, 1, 0, 0.018800752377192143, 0.8972346661304004, 0.3086595264782446, 0.4312980886093152], 8.773088964957891e-29, 0.00011398493780175633, -1.2101875159417313e-05
15:54:37 done sampling a new configuration.
15:54:37 HBMASTER: schedule new run for iteration 4
15:54:37 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
15:54:37 HBMASTER: submitting job (4, 0, 8) to dispatcher
15:54:37 DISPATCHER: trying to submit job (4, 0, 8)
15:54:37 DISPATCHER: trying to notify the job_runner thread.
15:54:37 HBMASTER: job (4, 0, 8) submitted to dispatcher
15:54:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:54:37 DISPATCHER: Trying to submit another job.
15:54:37 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:54:37 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:54:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:54:37 WORKER: start processing job (4, 0, 8)
15:54:37 WORKER: args: ()
15:54:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003888714825398463, 'num_filters_1': 82, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.014821198979154569}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:54:45 DISPATCHER: Starting worker discovery
15:54:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:45 DISPATCHER: Finished worker discovery
15:55:26 WORKER: done with job (4, 0, 8), trying to register it.
15:55:26 WORKER: registered result for job (4, 0, 8) with dispatcher
15:55:26 DISPATCHER: job (4, 0, 8) finished
15:55:26 DISPATCHER: register_result: lock acquired
15:55:26 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:55:26 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003888714825398463, 'num_filters_1': 82, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.014821198979154569}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4635222416056792, 'info': {'data02': 0.4635222416056792, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003888714825398463, 'num_filters_1': 82, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.014821198979154569}"}}
exception: None

15:55:26 job_callback for (4, 0, 8) started
15:55:26 job_callback for (4, 0, 8) got condition
15:55:26 DISPATCHER: Trying to submit another job.
15:55:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:55:26 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.765285





15:55:26 HBMASTER: Trying to run another job!
15:55:26 job_callback for (4, 0, 8) finished
15:55:26 start sampling a new configuration.
15:55:26 best_vector: [0, 2, 0.0664994200901064, 0.09647348912336393, 0.8556602204924292, 0, 0.6814888741910846, 0.40008914112314825, 2, 2, 2, 0, 0.8343991716021459, 0.08485974475814811, 0.39737734558536536, 0.501617144719839], 0.0007270679145772518, 0.00010382740083557097, 7.5489571801495e-08
15:55:26 done sampling a new configuration.
15:55:26 HBMASTER: schedule new run for iteration 4
15:55:26 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
15:55:26 HBMASTER: submitting job (4, 0, 9) to dispatcher
15:55:26 DISPATCHER: trying to submit job (4, 0, 9)
15:55:26 DISPATCHER: trying to notify the job_runner thread.
15:55:26 HBMASTER: job (4, 0, 9) submitted to dispatcher
15:55:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:55:26 DISPATCHER: Trying to submit another job.
15:55:26 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:55:26 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:55:26 WORKER: start processing job (4, 0, 9)
15:55:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:55:26 WORKER: args: ()
15:55:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013583098191021772, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03315339237074248, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 19, 'num_filters_4': 36, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:55:45 DISPATCHER: Starting worker discovery
15:55:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:45 DISPATCHER: Finished worker discovery
15:56:15 WORKER: done with job (4, 0, 9), trying to register it.
15:56:15 WORKER: registered result for job (4, 0, 9) with dispatcher
15:56:15 DISPATCHER: job (4, 0, 9) finished
15:56:15 DISPATCHER: register_result: lock acquired
15:56:15 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:56:15 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013583098191021772, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03315339237074248, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 19, 'num_filters_4': 36, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5895834939096339, 'info': {'data02': 0.5895834939096339, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013583098191021772, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03315339237074248, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 19, 'num_filters_4': 36, 'num_filters_5': 45}"}}
exception: None

15:56:15 job_callback for (4, 0, 9) started
15:56:15 DISPATCHER: Trying to submit another job.
15:56:15 job_callback for (4, 0, 9) got condition
15:56:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:56:15 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.765285





15:56:15 HBMASTER: Trying to run another job!
15:56:15 job_callback for (4, 0, 9) finished
15:56:15 start sampling a new configuration.
15:56:15 best_vector: [2, 0, 0.13007175572989896, 0.20423208357392403, 0.8066052477671573, 1, 0.9102120677636263, 0.3122952074069228, 1, 1, 0, 1, 0.7503390697682822, 0.21001208747409875, 0.481352307290005, 0.4581615108808903], 0.000266639666919298, 0.005022848194863064, 1.3392905696644845e-06
15:56:15 done sampling a new configuration.
15:56:15 HBMASTER: schedule new run for iteration 4
15:56:15 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
15:56:15 HBMASTER: submitting job (4, 0, 10) to dispatcher
15:56:15 DISPATCHER: trying to submit job (4, 0, 10)
15:56:15 DISPATCHER: trying to notify the job_runner thread.
15:56:15 HBMASTER: job (4, 0, 10) submitted to dispatcher
15:56:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:56:15 DISPATCHER: Trying to submit another job.
15:56:15 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:56:15 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:56:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:56:15 WORKER: start processing job (4, 0, 10)
15:56:15 WORKER: args: ()
15:56:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018203022732953451, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025486220274133595, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 76, 'num_filters_3': 24, 'num_filters_4': 43, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:56:45 DISPATCHER: Starting worker discovery
15:56:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:45 DISPATCHER: Finished worker discovery
15:57:04 WORKER: done with job (4, 0, 10), trying to register it.
15:57:04 WORKER: registered result for job (4, 0, 10) with dispatcher
15:57:04 DISPATCHER: job (4, 0, 10) finished
15:57:04 DISPATCHER: register_result: lock acquired
15:57:04 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:57:04 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018203022732953451, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025486220274133595, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 76, 'num_filters_3': 24, 'num_filters_4': 43, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38088707270853334, 'info': {'data02': 0.38088707270853334, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018203022732953451, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025486220274133595, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 76, 'num_filters_3': 24, 'num_filters_4': 43, 'num_filters_5': 41}"}}
exception: None

15:57:04 job_callback for (4, 0, 10) started
15:57:04 DISPATCHER: Trying to submit another job.
15:57:04 job_callback for (4, 0, 10) got condition
15:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:57:04 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.765285





15:57:04 HBMASTER: Trying to run another job!
15:57:04 job_callback for (4, 0, 10) finished
15:57:04 start sampling a new configuration.
15:57:04 best_vector: [0, 0, 0.6720001291180273, 0.8066688412986562, 0.35256164756104585, 0, 0.8743842671683488, 0.07919895539332861, 2, 0, 2, 0, 0.4602333777150839, 0.5137075170693404, 0.6926820988826543, 0.5089902902461458], 0.002032422267289459, 0.005266364028526714, 1.0703475519229914e-05
15:57:04 done sampling a new configuration.
15:57:04 HBMASTER: schedule new run for iteration 4
15:57:04 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
15:57:04 HBMASTER: submitting job (4, 0, 11) to dispatcher
15:57:04 DISPATCHER: trying to submit job (4, 0, 11)
15:57:04 DISPATCHER: trying to notify the job_runner thread.
15:57:04 HBMASTER: job (4, 0, 11) submitted to dispatcher
15:57:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:57:04 DISPATCHER: Trying to submit another job.
15:57:04 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:57:04 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:57:04 WORKER: start processing job (4, 0, 11)
15:57:04 WORKER: args: ()
15:57:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022080060459220667, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012677692585499238, 'kernel_size_2': 7, 'num_filters_2': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:57:45 DISPATCHER: Starting worker discovery
15:57:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:45 DISPATCHER: Finished worker discovery
15:57:52 WORKER: done with job (4, 0, 11), trying to register it.
15:57:52 WORKER: registered result for job (4, 0, 11) with dispatcher
15:57:52 DISPATCHER: job (4, 0, 11) finished
15:57:52 DISPATCHER: register_result: lock acquired
15:57:52 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:57:52 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022080060459220667, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012677692585499238, 'kernel_size_2': 7, 'num_filters_2': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5460776672539159, 'info': {'data02': 0.5460776672539159, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022080060459220667, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012677692585499238, 'kernel_size_2': 7, 'num_filters_2': 41}"}}
exception: None

15:57:52 job_callback for (4, 0, 11) started
15:57:52 DISPATCHER: Trying to submit another job.
15:57:52 job_callback for (4, 0, 11) got condition
15:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:57:52 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.765285





15:57:52 HBMASTER: Trying to run another job!
15:57:52 job_callback for (4, 0, 11) finished
15:57:52 start sampling a new configuration.
15:57:52 best_vector: [2, 0, 0.9045231547718879, 0.15998956125646158, 0.028608892530349483, 1, 0.7456609587750636, 0.10899153782296557, 0, 1, 2, 0, 0.4529505823674767, 0.6023919606458442, 0.3508756171862303, 0.4210698880810951], 0.002545395469837655, 0.003934533641327436, 1.001494410655871e-05
15:57:52 done sampling a new configuration.
15:57:52 HBMASTER: schedule new run for iteration 4
15:57:52 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
15:57:52 HBMASTER: submitting job (4, 0, 12) to dispatcher
15:57:52 DISPATCHER: trying to submit job (4, 0, 12)
15:57:52 DISPATCHER: trying to notify the job_runner thread.
15:57:52 HBMASTER: job (4, 0, 12) submitted to dispatcher
15:57:52 DISPATCHER: Trying to submit another job.
15:57:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:57:52 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:57:52 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:57:52 WORKER: start processing job (4, 0, 12)
15:57:52 WORKER: args: ()
15:57:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06442379580189386, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.013861213726671191}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:58:41 WORKER: done with job (4, 0, 12), trying to register it.
15:58:41 WORKER: registered result for job (4, 0, 12) with dispatcher
15:58:41 DISPATCHER: job (4, 0, 12) finished
15:58:41 DISPATCHER: register_result: lock acquired
15:58:41 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:58:41 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06442379580189386, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.013861213726671191}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4767556397440654, 'info': {'data02': 0.4767556397440654, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06442379580189386, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.013861213726671191}"}}
exception: None

15:58:41 job_callback for (4, 0, 12) started
15:58:41 job_callback for (4, 0, 12) got condition
15:58:41 DISPATCHER: Trying to submit another job.
15:58:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:58:41 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.765285





15:58:41 HBMASTER: Trying to run another job!
15:58:41 job_callback for (4, 0, 12) finished
15:58:41 start sampling a new configuration.
15:58:41 done sampling a new configuration.
15:58:41 HBMASTER: schedule new run for iteration 4
15:58:41 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
15:58:41 HBMASTER: submitting job (4, 0, 13) to dispatcher
15:58:41 DISPATCHER: trying to submit job (4, 0, 13)
15:58:41 DISPATCHER: trying to notify the job_runner thread.
15:58:41 HBMASTER: job (4, 0, 13) submitted to dispatcher
15:58:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:58:41 DISPATCHER: Trying to submit another job.
15:58:41 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:58:41 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:58:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:58:41 WORKER: start processing job (4, 0, 13)
15:58:41 WORKER: args: ()
15:58:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018139508021149141, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.08571593124589666}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:58:45 DISPATCHER: Starting worker discovery
15:58:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:45 DISPATCHER: Finished worker discovery
15:59:29 WORKER: done with job (4, 0, 13), trying to register it.
15:59:29 WORKER: registered result for job (4, 0, 13) with dispatcher
15:59:29 DISPATCHER: job (4, 0, 13) finished
15:59:29 DISPATCHER: register_result: lock acquired
15:59:29 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:59:29 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018139508021149141, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.08571593124589666}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.430665889284509, 'info': {'data02': 0.430665889284509, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018139508021149141, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.08571593124589666}"}}
exception: None

15:59:29 job_callback for (4, 0, 13) started
15:59:29 DISPATCHER: Trying to submit another job.
15:59:29 job_callback for (4, 0, 13) got condition
15:59:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:59:29 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.765285





15:59:29 HBMASTER: Trying to run another job!
15:59:29 job_callback for (4, 0, 13) finished
15:59:29 start sampling a new configuration.
15:59:29 best_vector: [3, 0, 0.18336048497954666, 0.3023295319055586, 0.5081439317323457, 1, 0.4746798514813261, 0.058678821823515886, 1, 1, 1, 2, 0.8423877957286197, 0.044222048490326446, 0.9967073202942023, 0.46818234713440315], 0.0007698088272963671, 0.003965893829142776, 3.0529800777942995e-06
15:59:29 done sampling a new configuration.
15:59:29 HBMASTER: schedule new run for iteration 4
15:59:29 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
15:59:29 HBMASTER: submitting job (4, 0, 14) to dispatcher
15:59:29 DISPATCHER: trying to submit job (4, 0, 14)
15:59:29 DISPATCHER: trying to notify the job_runner thread.
15:59:29 HBMASTER: job (4, 0, 14) submitted to dispatcher
15:59:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:59:29 DISPATCHER: Trying to submit another job.
15:59:29 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:59:29 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:59:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:59:29 WORKER: start processing job (4, 0, 14)
15:59:29 WORKER: args: ()
15:59:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023265959617601714, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011921829522665019, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:59:45 DISPATCHER: Starting worker discovery
15:59:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:45 DISPATCHER: Finished worker discovery
16:00:18 WORKER: done with job (4, 0, 14), trying to register it.
16:00:18 WORKER: registered result for job (4, 0, 14) with dispatcher
16:00:18 DISPATCHER: job (4, 0, 14) finished
16:00:18 DISPATCHER: register_result: lock acquired
16:00:18 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:00:18 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023265959617601714, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011921829522665019, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6246214602780226, 'info': {'data02': 0.6246214602780226, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023265959617601714, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011921829522665019, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 17}"}}
exception: None

16:00:18 job_callback for (4, 0, 14) started
16:00:18 job_callback for (4, 0, 14) got condition
16:00:18 DISPATCHER: Trying to submit another job.
16:00:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:00:18 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.765285





16:00:18 HBMASTER: Trying to run another job!
16:00:18 job_callback for (4, 0, 14) finished
16:00:18 start sampling a new configuration.
16:00:18 done sampling a new configuration.
16:00:18 HBMASTER: schedule new run for iteration 4
16:00:18 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
16:00:18 HBMASTER: submitting job (4, 0, 15) to dispatcher
16:00:18 DISPATCHER: trying to submit job (4, 0, 15)
16:00:18 DISPATCHER: trying to notify the job_runner thread.
16:00:18 HBMASTER: job (4, 0, 15) submitted to dispatcher
16:00:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:00:18 DISPATCHER: Trying to submit another job.
16:00:18 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:00:18 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:00:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:00:18 WORKER: start processing job (4, 0, 15)
16:00:18 WORKER: args: ()
16:00:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05658519903998734, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.03616612079060886, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:00:45 DISPATCHER: Starting worker discovery
16:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:45 DISPATCHER: Finished worker discovery
16:01:06 WORKER: done with job (4, 0, 15), trying to register it.
16:01:06 WORKER: registered result for job (4, 0, 15) with dispatcher
16:01:06 DISPATCHER: job (4, 0, 15) finished
16:01:06 DISPATCHER: register_result: lock acquired
16:01:06 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:01:06 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05658519903998734, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.03616612079060886, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5249404565553977, 'info': {'data02': 0.5249404565553977, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05658519903998734, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.03616612079060886, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 29}"}}
exception: None

16:01:06 job_callback for (4, 0, 15) started
16:01:06 job_callback for (4, 0, 15) got condition
16:01:06 DISPATCHER: Trying to submit another job.
16:01:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:01:06 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.765285





16:01:06 HBMASTER: Trying to run another job!
16:01:06 job_callback for (4, 0, 15) finished
16:01:06 start sampling a new configuration.
16:01:06 done sampling a new configuration.
16:01:06 HBMASTER: schedule new run for iteration 4
16:01:06 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
16:01:06 HBMASTER: submitting job (4, 0, 16) to dispatcher
16:01:06 DISPATCHER: trying to submit job (4, 0, 16)
16:01:06 DISPATCHER: trying to notify the job_runner thread.
16:01:06 HBMASTER: job (4, 0, 16) submitted to dispatcher
16:01:06 DISPATCHER: Trying to submit another job.
16:01:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:01:06 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:01:06 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:01:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:01:06 WORKER: start processing job (4, 0, 16)
16:01:06 WORKER: args: ()
16:01:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010580579044814728, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.037846065351064814, 'kernel_size_2': 3, 'num_filters_2': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:01:45 DISPATCHER: Starting worker discovery
16:01:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:45 DISPATCHER: Finished worker discovery
16:01:55 WORKER: done with job (4, 0, 16), trying to register it.
16:01:55 WORKER: registered result for job (4, 0, 16) with dispatcher
16:01:55 DISPATCHER: job (4, 0, 16) finished
16:01:55 DISPATCHER: register_result: lock acquired
16:01:55 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:01:55 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010580579044814728, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.037846065351064814, 'kernel_size_2': 3, 'num_filters_2': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43067977382758704, 'info': {'data02': 0.43067977382758704, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010580579044814728, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.037846065351064814, 'kernel_size_2': 3, 'num_filters_2': 66}"}}
exception: None

16:01:55 job_callback for (4, 0, 16) started
16:01:55 DISPATCHER: Trying to submit another job.
16:01:55 job_callback for (4, 0, 16) got condition
16:01:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:01:55 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.765285





16:01:55 HBMASTER: Trying to run another job!
16:01:55 job_callback for (4, 0, 16) finished
16:01:55 start sampling a new configuration.
16:01:55 done sampling a new configuration.
16:01:55 HBMASTER: schedule new run for iteration 4
16:01:55 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
16:01:55 HBMASTER: submitting job (4, 0, 17) to dispatcher
16:01:55 DISPATCHER: trying to submit job (4, 0, 17)
16:01:55 DISPATCHER: trying to notify the job_runner thread.
16:01:55 HBMASTER: job (4, 0, 17) submitted to dispatcher
16:01:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:01:55 DISPATCHER: Trying to submit another job.
16:01:55 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:01:55 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:01:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:01:55 WORKER: start processing job (4, 0, 17)
16:01:55 WORKER: args: ()
16:01:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012707798898112847, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.010465103526461746, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:02:43 WORKER: done with job (4, 0, 17), trying to register it.
16:02:43 WORKER: registered result for job (4, 0, 17) with dispatcher
16:02:43 DISPATCHER: job (4, 0, 17) finished
16:02:43 DISPATCHER: register_result: lock acquired
16:02:43 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:02:43 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012707798898112847, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.010465103526461746, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5276788434491967, 'info': {'data02': 0.5276788434491967, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012707798898112847, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.010465103526461746, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 26}"}}
exception: None

16:02:43 job_callback for (4, 0, 17) started
16:02:43 DISPATCHER: Trying to submit another job.
16:02:43 job_callback for (4, 0, 17) got condition
16:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:02:43 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.765285





16:02:43 HBMASTER: Trying to run another job!
16:02:43 job_callback for (4, 0, 17) finished
16:02:43 start sampling a new configuration.
16:02:43 best_vector: [2, 2, 0.058893154042969686, 0.9958708067219386, 0.4300182209235247, 0, 0.6304791468480967, 0.2605952626999237, 0, 1, 0, 0, 0.8202358270672987, 0.1466010091825084, 0.8530106131360697, 0.5129726436446962], 0.00018165668762062283, 0.005722967410644908, 1.0396153031785267e-06
16:02:43 done sampling a new configuration.
16:02:43 HBMASTER: schedule new run for iteration 4
16:02:43 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
16:02:43 HBMASTER: submitting job (4, 0, 18) to dispatcher
16:02:43 DISPATCHER: trying to submit job (4, 0, 18)
16:02:43 DISPATCHER: trying to notify the job_runner thread.
16:02:43 HBMASTER: job (4, 0, 18) submitted to dispatcher
16:02:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:02:43 DISPATCHER: Trying to submit another job.
16:02:43 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:02:43 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:02:43 WORKER: start processing job (4, 0, 18)
16:02:43 WORKER: args: ()
16:02:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013115543979942028, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021829422849447194, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:02:45 DISPATCHER: Starting worker discovery
16:02:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:45 DISPATCHER: Finished worker discovery
16:03:32 WORKER: done with job (4, 0, 18), trying to register it.
16:03:32 WORKER: registered result for job (4, 0, 18) with dispatcher
16:03:32 DISPATCHER: job (4, 0, 18) finished
16:03:32 DISPATCHER: register_result: lock acquired
16:03:32 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:03:32 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013115543979942028, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021829422849447194, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6832832597716594, 'info': {'data02': 0.6832832597716594, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013115543979942028, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021829422849447194, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 21}"}}
exception: None

16:03:32 job_callback for (4, 0, 18) started
16:03:32 job_callback for (4, 0, 18) got condition
16:03:32 DISPATCHER: Trying to submit another job.
16:03:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:03:32 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.765285





16:03:32 HBMASTER: Trying to run another job!
16:03:32 job_callback for (4, 0, 18) finished
16:03:32 start sampling a new configuration.
16:03:32 best_vector: [1, 2, 0.059556068777034045, 0.8465691890377667, 0.44229874511325357, 1, 0.5553542276807575, 0.7343961004597932, 2, 1, 2, 0, 0.9448114526513285, 0.629153799372756, 0.6455007487511684, 0.5025216102657656], 5.813962154278555e-05, 0.38107117344958, 2.2155333805223772e-05
16:03:32 done sampling a new configuration.
16:03:32 HBMASTER: schedule new run for iteration 4
16:03:32 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
16:03:32 HBMASTER: submitting job (4, 0, 19) to dispatcher
16:03:32 DISPATCHER: trying to submit job (4, 0, 19)
16:03:32 DISPATCHER: trying to notify the job_runner thread.
16:03:32 HBMASTER: job (4, 0, 19) submitted to dispatcher
16:03:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:03:32 DISPATCHER: Trying to submit another job.
16:03:32 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:03:32 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:03:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:03:32 WORKER: start processing job (4, 0, 19)
16:03:32 WORKER: args: ()
16:03:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001315564475324799, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.09025501763341193, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 114, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:03:45 DISPATCHER: Starting worker discovery
16:03:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:45 DISPATCHER: Finished worker discovery
16:04:21 WORKER: done with job (4, 0, 19), trying to register it.
16:04:21 WORKER: registered result for job (4, 0, 19) with dispatcher
16:04:21 DISPATCHER: job (4, 0, 19) finished
16:04:21 DISPATCHER: register_result: lock acquired
16:04:21 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:04:21 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001315564475324799, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.09025501763341193, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 114, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6236232426584968, 'info': {'data02': 0.6236232426584968, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001315564475324799, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.09025501763341193, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 114, 'num_filters_3': 59}"}}
exception: None

16:04:21 job_callback for (4, 0, 19) started
16:04:21 DISPATCHER: Trying to submit another job.
16:04:21 job_callback for (4, 0, 19) got condition
16:04:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:04:21 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.765285





16:04:21 HBMASTER: Trying to run another job!
16:04:21 job_callback for (4, 0, 19) finished
16:04:21 start sampling a new configuration.
16:04:21 best_vector: [1, 0, 0.022463359532399557, 0.9300145804782933, 0.4828748964307923, 1, 0.9791745835318374, 0.10304164476843176, 2, 1, 2, 0, 0.9717206976114481, 0.9223805977339288, 0.13546718333771682, 0.5035510133998686], 2.0193898585497594e-05, 0.04939204734100532, 9.974179949343576e-07
16:04:21 done sampling a new configuration.
16:04:21 HBMASTER: schedule new run for iteration 4
16:04:21 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
16:04:21 HBMASTER: submitting job (4, 0, 20) to dispatcher
16:04:21 DISPATCHER: trying to submit job (4, 0, 20)
16:04:21 DISPATCHER: trying to notify the job_runner thread.
16:04:21 HBMASTER: job (4, 0, 20) submitted to dispatcher
16:04:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:04:21 DISPATCHER: Trying to submit another job.
16:04:21 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:04:21 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:04:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:04:21 WORKER: start processing job (4, 0, 20)
16:04:21 WORKER: args: ()
16:04:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:04:45 DISPATCHER: Starting worker discovery
16:04:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:45 DISPATCHER: Finished worker discovery
16:05:10 WORKER: done with job (4, 0, 20), trying to register it.
16:05:10 WORKER: registered result for job (4, 0, 20) with dispatcher
16:05:10 DISPATCHER: job (4, 0, 20) finished
16:05:10 DISPATCHER: register_result: lock acquired
16:05:10 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:05:10 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7099830677373449, 'info': {'data02': 0.7099830677373449, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}"}}
exception: None

16:05:10 job_callback for (4, 0, 20) started
16:05:10 DISPATCHER: Trying to submit another job.
16:05:10 job_callback for (4, 0, 20) got condition
16:05:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:05:10 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.765285





16:05:10 HBMASTER: Trying to run another job!
16:05:10 job_callback for (4, 0, 20) finished
16:05:10 start sampling a new configuration.
16:05:10 best_vector: [2, 1, 0.34644521862358835, 0.9878350090541512, 0.6572136511827723, 0, 0.6066121032898162, 0.6626750032153038, 2, 2, 1, 0, 0.851019695320091, 0.8509168080983001, 0.9336691920122133, 0.5049775731026571], 7.028414861528703e-05, 0.8702001248110256, 6.116127489725945e-05
16:05:10 done sampling a new configuration.
16:05:10 HBMASTER: schedule new run for iteration 4
16:05:10 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
16:05:10 HBMASTER: submitting job (4, 0, 21) to dispatcher
16:05:10 DISPATCHER: trying to submit job (4, 0, 21)
16:05:10 DISPATCHER: trying to notify the job_runner thread.
16:05:10 HBMASTER: job (4, 0, 21) submitted to dispatcher
16:05:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:05:10 DISPATCHER: Trying to submit another job.
16:05:10 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:05:10 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:05:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:05:10 WORKER: start processing job (4, 0, 21)
16:05:10 WORKER: args: ()
16:05:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004930494029627779, 'num_filters_1': 125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.07280480727382652, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 94, 'num_filters_4': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:05:45 DISPATCHER: Starting worker discovery
16:05:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:45 DISPATCHER: Finished worker discovery
16:05:58 WORKER: done with job (4, 0, 21), trying to register it.
16:05:58 WORKER: registered result for job (4, 0, 21) with dispatcher
16:05:58 DISPATCHER: job (4, 0, 21) finished
16:05:58 DISPATCHER: register_result: lock acquired
16:05:58 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:05:58 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004930494029627779, 'num_filters_1': 125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.07280480727382652, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 94, 'num_filters_4': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4732842397582095, 'info': {'data02': 0.4732842397582095, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004930494029627779, 'num_filters_1': 125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.07280480727382652, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 94, 'num_filters_4': 112}"}}
exception: None

16:05:58 job_callback for (4, 0, 21) started
16:05:58 DISPATCHER: Trying to submit another job.
16:05:58 job_callback for (4, 0, 21) got condition
16:05:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:05:58 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.765285





16:05:58 HBMASTER: Trying to run another job!
16:05:58 job_callback for (4, 0, 21) finished
16:05:58 start sampling a new configuration.
16:05:59 best_vector: [2, 1, 0.07091078448412308, 0.8950317111565833, 0.41383249969044067, 1, 0.757853301308907, 0.5046348330334056, 1, 1, 0, 0, 0.7853937467202935, 0.5079548122651778, 0.31965954413069797, 0.5045324769668356], 3.2699313600157086e-05, 2.5293922375527593, 8.27093899935407e-05
16:05:59 done sampling a new configuration.
16:05:59 HBMASTER: schedule new run for iteration 4
16:05:59 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
16:05:59 HBMASTER: submitting job (4, 0, 22) to dispatcher
16:05:59 DISPATCHER: trying to submit job (4, 0, 22)
16:05:59 DISPATCHER: trying to notify the job_runner thread.
16:05:59 HBMASTER: job (4, 0, 22) submitted to dispatcher
16:05:59 DISPATCHER: Trying to submit another job.
16:05:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:05:59 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:05:59 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:05:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:05:59 WORKER: start processing job (4, 0, 22)
16:05:59 WORKER: args: ()
16:05:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013861861936131845, 'num_filters_1': 103, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.045346633890147016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 82, 'num_filters_3': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:06:45 DISPATCHER: Starting worker discovery
16:06:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:45 DISPATCHER: Finished worker discovery
16:06:47 WORKER: done with job (4, 0, 22), trying to register it.
16:06:47 WORKER: registered result for job (4, 0, 22) with dispatcher
16:06:47 DISPATCHER: job (4, 0, 22) finished
16:06:47 DISPATCHER: register_result: lock acquired
16:06:47 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:06:47 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013861861936131845, 'num_filters_1': 103, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.045346633890147016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 82, 'num_filters_3': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5171269651837297, 'info': {'data02': 0.5171269651837297, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013861861936131845, 'num_filters_1': 103, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.045346633890147016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 82, 'num_filters_3': 45}"}}
exception: None

16:06:47 job_callback for (4, 0, 22) started
16:06:47 job_callback for (4, 0, 22) got condition
16:06:47 DISPATCHER: Trying to submit another job.
16:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:06:47 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.765285





16:06:47 HBMASTER: Trying to run another job!
16:06:47 job_callback for (4, 0, 22) finished
16:06:47 start sampling a new configuration.
16:06:47 best_vector: [1, 1, 0.2627918518057037, 0.25720610970817087, 0.44730165178713144, 0, 0.6711087161916635, 0.013798753066801797, 2, 2, 0, 0, 0.5561645064758307, 0.3974103688152787, 0.5108930865359316, 0.5049922441369789], 1.1041212590994211e-05, 4.860237288307442, 5.3662913142879686e-05
16:06:47 done sampling a new configuration.
16:06:47 HBMASTER: schedule new run for iteration 4
16:06:47 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
16:06:47 HBMASTER: submitting job (4, 0, 23) to dispatcher
16:06:47 DISPATCHER: trying to submit job (4, 0, 23)
16:06:47 DISPATCHER: trying to notify the job_runner thread.
16:06:47 HBMASTER: job (4, 0, 23) submitted to dispatcher
16:06:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:06:47 DISPATCHER: Trying to submit another job.
16:06:47 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:06:47 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:06:47 WORKER: start processing job (4, 0, 23)
16:06:47 WORKER: args: ()
16:06:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033541594450853685, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010422036543807009, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 50, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:07:36 WORKER: done with job (4, 0, 23), trying to register it.
16:07:36 WORKER: registered result for job (4, 0, 23) with dispatcher
16:07:36 DISPATCHER: job (4, 0, 23) finished
16:07:36 DISPATCHER: register_result: lock acquired
16:07:36 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:07:36 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033541594450853685, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010422036543807009, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 50, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.603075996176295, 'info': {'data02': 0.603075996176295, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033541594450853685, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010422036543807009, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 50, 'num_filters_3': 36}"}}
exception: None

16:07:36 job_callback for (4, 0, 23) started
16:07:36 job_callback for (4, 0, 23) got condition
16:07:36 DISPATCHER: Trying to submit another job.
16:07:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:07:36 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.765285





16:07:36 HBMASTER: Trying to run another job!
16:07:36 job_callback for (4, 0, 23) finished
16:07:36 start sampling a new configuration.
16:07:36 best_vector: [2, 1, 0.1856743514094019, 0.492151236101291, 0.4506324692997701, 1, 0.6338833247261597, 0.00823256048642458, 1, 1, 2, 0, 0.6555595007533301, 0.07299601593990512, 0.9339354323516729, 0.5042928125550824], 5.039344899830311e-06, 3.5211486390198785, 1.7744282435589268e-05
16:07:36 done sampling a new configuration.
16:07:36 HBMASTER: schedule new run for iteration 4
16:07:36 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
16:07:36 HBMASTER: submitting job (4, 0, 24) to dispatcher
16:07:36 DISPATCHER: trying to submit job (4, 0, 24)
16:07:36 DISPATCHER: trying to notify the job_runner thread.
16:07:36 HBMASTER: job (4, 0, 24) submitted to dispatcher
16:07:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:07:36 DISPATCHER: Trying to submit another job.
16:07:36 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:07:36 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:07:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:07:36 WORKER: start processing job (4, 0, 24)
16:07:36 WORKER: args: ()
16:07:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:07:45 DISPATCHER: Starting worker discovery
16:07:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:45 DISPATCHER: Finished worker discovery
16:08:25 WORKER: done with job (4, 0, 24), trying to register it.
16:08:25 WORKER: registered result for job (4, 0, 24) with dispatcher
16:08:25 DISPATCHER: job (4, 0, 24) finished
16:08:25 DISPATCHER: register_result: lock acquired
16:08:25 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:08:25 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6533828968063036, 'info': {'data02': 0.6533828968063036, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}"}}
exception: None

16:08:25 job_callback for (4, 0, 24) started
16:08:25 DISPATCHER: Trying to submit another job.
16:08:25 job_callback for (4, 0, 24) got condition
16:08:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:08:25 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.765285





16:08:25 HBMASTER: Trying to run another job!
16:08:25 job_callback for (4, 0, 24) finished
16:08:25 start sampling a new configuration.
16:08:25 done sampling a new configuration.
16:08:25 HBMASTER: schedule new run for iteration 4
16:08:25 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
16:08:25 HBMASTER: submitting job (4, 0, 25) to dispatcher
16:08:25 DISPATCHER: trying to submit job (4, 0, 25)
16:08:25 DISPATCHER: trying to notify the job_runner thread.
16:08:25 HBMASTER: job (4, 0, 25) submitted to dispatcher
16:08:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:08:25 DISPATCHER: Trying to submit another job.
16:08:25 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:08:25 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:08:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:08:25 WORKER: start processing job (4, 0, 25)
16:08:25 WORKER: args: ()
16:08:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013452254255382353, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02661764773811199, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:08:45 DISPATCHER: Starting worker discovery
16:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:45 DISPATCHER: Finished worker discovery
16:09:14 WORKER: done with job (4, 0, 25), trying to register it.
16:09:14 WORKER: registered result for job (4, 0, 25) with dispatcher
16:09:14 DISPATCHER: job (4, 0, 25) finished
16:09:14 DISPATCHER: register_result: lock acquired
16:09:14 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:09:14 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013452254255382353, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02661764773811199, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6299602818717465, 'info': {'data02': 0.6299602818717465, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013452254255382353, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02661764773811199, 'kernel_size_2': 5, 'num_filters_2': 105}"}}
exception: None

16:09:14 job_callback for (4, 0, 25) started
16:09:14 job_callback for (4, 0, 25) got condition
16:09:14 DISPATCHER: Trying to submit another job.
16:09:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:09:14 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.765285





16:09:14 HBMASTER: Trying to run another job!
16:09:14 job_callback for (4, 0, 25) finished
16:09:14 start sampling a new configuration.
16:09:14 done sampling a new configuration.
16:09:14 HBMASTER: schedule new run for iteration 4
16:09:14 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
16:09:14 HBMASTER: submitting job (4, 0, 26) to dispatcher
16:09:14 DISPATCHER: trying to submit job (4, 0, 26)
16:09:14 DISPATCHER: trying to notify the job_runner thread.
16:09:14 HBMASTER: job (4, 0, 26) submitted to dispatcher
16:09:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:09:14 DISPATCHER: Trying to submit another job.
16:09:14 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:09:14 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:09:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:09:14 WORKER: start processing job (4, 0, 26)
16:09:14 WORKER: args: ()
16:09:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02827684334171098, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.061790012688497604, 'kernel_size_2': 5, 'num_filters_2': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:09:45 DISPATCHER: Starting worker discovery
16:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:45 DISPATCHER: Finished worker discovery
16:10:02 WORKER: done with job (4, 0, 26), trying to register it.
16:10:02 WORKER: registered result for job (4, 0, 26) with dispatcher
16:10:02 DISPATCHER: job (4, 0, 26) finished
16:10:02 DISPATCHER: register_result: lock acquired
16:10:02 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:10:02 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02827684334171098, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.061790012688497604, 'kernel_size_2': 5, 'num_filters_2': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.584211046012221, 'info': {'data02': 0.584211046012221, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02827684334171098, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.061790012688497604, 'kernel_size_2': 5, 'num_filters_2': 126}"}}
exception: None

16:10:02 job_callback for (4, 0, 26) started
16:10:02 job_callback for (4, 0, 26) got condition
16:10:02 DISPATCHER: Trying to submit another job.
16:10:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:10:02 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.765285





16:10:02 HBMASTER: Trying to run another job!
16:10:02 job_callback for (4, 0, 26) finished
16:10:02 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 9) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
16:10:02 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
16:10:02 HBMASTER: schedule new run for iteration 4
16:10:02 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
16:10:02 HBMASTER: submitting job (4, 0, 2) to dispatcher
16:10:02 DISPATCHER: trying to submit job (4, 0, 2)
16:10:02 DISPATCHER: trying to notify the job_runner thread.
16:10:02 HBMASTER: job (4, 0, 2) submitted to dispatcher
16:10:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:10:02 DISPATCHER: Trying to submit another job.
16:10:02 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:10:02 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:10:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:10:02 WORKER: start processing job (4, 0, 2)
16:10:02 WORKER: args: ()
16:10:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:10:45 DISPATCHER: Starting worker discovery
16:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:45 DISPATCHER: Finished worker discovery
16:11:45 DISPATCHER: Starting worker discovery
16:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:45 DISPATCHER: Finished worker discovery
16:12:20 WORKER: done with job (4, 0, 2), trying to register it.
16:12:20 WORKER: registered result for job (4, 0, 2) with dispatcher
16:12:20 DISPATCHER: job (4, 0, 2) finished
16:12:20 DISPATCHER: register_result: lock acquired
16:12:20 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:12:20 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7152098255712426, 'info': {'data02': 0.7152098255712426, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}"}}
exception: None

16:12:20 job_callback for (4, 0, 2) started
16:12:20 DISPATCHER: Trying to submit another job.
16:12:20 job_callback for (4, 0, 2) got condition
16:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:12:20 HBMASTER: Trying to run another job!
16:12:20 job_callback for (4, 0, 2) finished
16:12:20 HBMASTER: schedule new run for iteration 4
16:12:20 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
16:12:20 HBMASTER: submitting job (4, 0, 9) to dispatcher
16:12:20 DISPATCHER: trying to submit job (4, 0, 9)
16:12:20 DISPATCHER: trying to notify the job_runner thread.
16:12:20 HBMASTER: job (4, 0, 9) submitted to dispatcher
16:12:20 DISPATCHER: Trying to submit another job.
16:12:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:12:20 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:12:20 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:12:20 WORKER: start processing job (4, 0, 9)
16:12:20 WORKER: args: ()
16:12:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013583098191021772, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03315339237074248, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 19, 'num_filters_4': 36, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:12:45 DISPATCHER: Starting worker discovery
16:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:45 DISPATCHER: Finished worker discovery
16:13:45 DISPATCHER: Starting worker discovery
16:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:45 DISPATCHER: Finished worker discovery
16:14:38 WORKER: done with job (4, 0, 9), trying to register it.
16:14:38 WORKER: registered result for job (4, 0, 9) with dispatcher
16:14:38 DISPATCHER: job (4, 0, 9) finished
16:14:38 DISPATCHER: register_result: lock acquired
16:14:38 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:14:38 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013583098191021772, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03315339237074248, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 19, 'num_filters_4': 36, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5637282994353636, 'info': {'data02': 0.5637282994353636, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013583098191021772, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03315339237074248, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 19, 'num_filters_4': 36, 'num_filters_5': 45}"}}
exception: None

16:14:38 job_callback for (4, 0, 9) started
16:14:38 DISPATCHER: Trying to submit another job.
16:14:38 job_callback for (4, 0, 9) got condition
16:14:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:14:38 HBMASTER: Trying to run another job!
16:14:38 job_callback for (4, 0, 9) finished
16:14:38 HBMASTER: schedule new run for iteration 4
16:14:38 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
16:14:38 HBMASTER: submitting job (4, 0, 14) to dispatcher
16:14:38 DISPATCHER: trying to submit job (4, 0, 14)
16:14:38 DISPATCHER: trying to notify the job_runner thread.
16:14:38 HBMASTER: job (4, 0, 14) submitted to dispatcher
16:14:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:14:38 DISPATCHER: Trying to submit another job.
16:14:38 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:14:38 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:14:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:14:38 WORKER: start processing job (4, 0, 14)
16:14:38 WORKER: args: ()
16:14:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023265959617601714, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011921829522665019, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:14:45 DISPATCHER: Starting worker discovery
16:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:45 DISPATCHER: Finished worker discovery
16:15:45 DISPATCHER: Starting worker discovery
16:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:45 DISPATCHER: Finished worker discovery
16:16:45 DISPATCHER: Starting worker discovery
16:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:45 DISPATCHER: Finished worker discovery
16:16:56 WORKER: done with job (4, 0, 14), trying to register it.
16:16:56 WORKER: registered result for job (4, 0, 14) with dispatcher
16:16:56 DISPATCHER: job (4, 0, 14) finished
16:16:56 DISPATCHER: register_result: lock acquired
16:16:56 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:16:56 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023265959617601714, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011921829522665019, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6007508036221406, 'info': {'data02': 0.6007508036221406, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023265959617601714, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011921829522665019, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 92, 'num_filters_3': 17}"}}
exception: None

16:16:56 job_callback for (4, 0, 14) started
16:16:56 DISPATCHER: Trying to submit another job.
16:16:56 job_callback for (4, 0, 14) got condition
16:16:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:16:56 HBMASTER: Trying to run another job!
16:16:56 job_callback for (4, 0, 14) finished
16:16:56 HBMASTER: schedule new run for iteration 4
16:16:56 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
16:16:56 HBMASTER: submitting job (4, 0, 18) to dispatcher
16:16:56 DISPATCHER: trying to submit job (4, 0, 18)
16:16:56 DISPATCHER: trying to notify the job_runner thread.
16:16:56 HBMASTER: job (4, 0, 18) submitted to dispatcher
16:16:56 DISPATCHER: Trying to submit another job.
16:16:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:16:56 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:16:56 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:16:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:16:56 WORKER: start processing job (4, 0, 18)
16:16:56 WORKER: args: ()
16:16:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013115543979942028, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021829422849447194, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:17:45 DISPATCHER: Starting worker discovery
16:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:45 DISPATCHER: Finished worker discovery
16:18:45 DISPATCHER: Starting worker discovery
16:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:45 DISPATCHER: Finished worker discovery
16:19:14 WORKER: done with job (4, 0, 18), trying to register it.
16:19:14 WORKER: registered result for job (4, 0, 18) with dispatcher
16:19:14 DISPATCHER: job (4, 0, 18) finished
16:19:14 DISPATCHER: register_result: lock acquired
16:19:14 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:19:14 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013115543979942028, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021829422849447194, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5317467250294794, 'info': {'data02': 0.5317467250294794, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013115543979942028, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021829422849447194, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 21}"}}
exception: None

16:19:14 job_callback for (4, 0, 18) started
16:19:14 DISPATCHER: Trying to submit another job.
16:19:14 job_callback for (4, 0, 18) got condition
16:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:19:14 HBMASTER: Trying to run another job!
16:19:14 job_callback for (4, 0, 18) finished
16:19:14 HBMASTER: schedule new run for iteration 4
16:19:14 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
16:19:14 HBMASTER: submitting job (4, 0, 19) to dispatcher
16:19:14 DISPATCHER: trying to submit job (4, 0, 19)
16:19:14 DISPATCHER: trying to notify the job_runner thread.
16:19:14 HBMASTER: job (4, 0, 19) submitted to dispatcher
16:19:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:19:14 DISPATCHER: Trying to submit another job.
16:19:14 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:19:14 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:19:14 WORKER: start processing job (4, 0, 19)
16:19:14 WORKER: args: ()
16:19:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001315564475324799, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.09025501763341193, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 114, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:19:45 DISPATCHER: Starting worker discovery
16:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:45 DISPATCHER: Finished worker discovery
16:20:45 DISPATCHER: Starting worker discovery
16:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:45 DISPATCHER: Finished worker discovery
16:21:32 WORKER: done with job (4, 0, 19), trying to register it.
16:21:32 WORKER: registered result for job (4, 0, 19) with dispatcher
16:21:32 DISPATCHER: job (4, 0, 19) finished
16:21:32 DISPATCHER: register_result: lock acquired
16:21:32 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:21:32 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001315564475324799, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.09025501763341193, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 114, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4866598858197962, 'info': {'data02': 0.4866598858197962, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001315564475324799, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.09025501763341193, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 114, 'num_filters_3': 59}"}}
exception: None

16:21:32 job_callback for (4, 0, 19) started
16:21:32 DISPATCHER: Trying to submit another job.
16:21:32 job_callback for (4, 0, 19) got condition
16:21:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:21:32 HBMASTER: Trying to run another job!
16:21:32 job_callback for (4, 0, 19) finished
16:21:32 HBMASTER: schedule new run for iteration 4
16:21:32 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
16:21:32 HBMASTER: submitting job (4, 0, 20) to dispatcher
16:21:32 DISPATCHER: trying to submit job (4, 0, 20)
16:21:32 DISPATCHER: trying to notify the job_runner thread.
16:21:32 HBMASTER: job (4, 0, 20) submitted to dispatcher
16:21:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:21:32 DISPATCHER: Trying to submit another job.
16:21:32 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:21:32 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:21:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:21:32 WORKER: start processing job (4, 0, 20)
16:21:32 WORKER: args: ()
16:21:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:21:45 DISPATCHER: Starting worker discovery
16:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:45 DISPATCHER: Finished worker discovery
16:22:45 DISPATCHER: Starting worker discovery
16:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:45 DISPATCHER: Finished worker discovery
16:23:45 DISPATCHER: Starting worker discovery
16:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:45 DISPATCHER: Finished worker discovery
16:23:51 WORKER: done with job (4, 0, 20), trying to register it.
16:23:51 WORKER: registered result for job (4, 0, 20) with dispatcher
16:23:51 DISPATCHER: job (4, 0, 20) finished
16:23:51 DISPATCHER: register_result: lock acquired
16:23:51 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:23:51 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7010233299712618, 'info': {'data02': 0.7010233299712618, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}"}}
exception: None

16:23:51 job_callback for (4, 0, 20) started
16:23:51 job_callback for (4, 0, 20) got condition
16:23:51 DISPATCHER: Trying to submit another job.
16:23:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:23:51 HBMASTER: Trying to run another job!
16:23:51 job_callback for (4, 0, 20) finished
16:23:51 HBMASTER: schedule new run for iteration 4
16:23:51 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
16:23:51 HBMASTER: submitting job (4, 0, 23) to dispatcher
16:23:51 DISPATCHER: trying to submit job (4, 0, 23)
16:23:51 DISPATCHER: trying to notify the job_runner thread.
16:23:51 HBMASTER: job (4, 0, 23) submitted to dispatcher
16:23:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:23:51 DISPATCHER: Trying to submit another job.
16:23:51 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:23:51 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:23:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:23:51 WORKER: start processing job (4, 0, 23)
16:23:51 WORKER: args: ()
16:23:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033541594450853685, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010422036543807009, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 50, 'num_filters_3': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:24:45 DISPATCHER: Starting worker discovery
16:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:45 DISPATCHER: Finished worker discovery
16:25:45 DISPATCHER: Starting worker discovery
16:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:45 DISPATCHER: Finished worker discovery
16:26:09 WORKER: done with job (4, 0, 23), trying to register it.
16:26:09 WORKER: registered result for job (4, 0, 23) with dispatcher
16:26:09 DISPATCHER: job (4, 0, 23) finished
16:26:09 DISPATCHER: register_result: lock acquired
16:26:09 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:26:09 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033541594450853685, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010422036543807009, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 50, 'num_filters_3': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5983139733185182, 'info': {'data02': 0.5983139733185182, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033541594450853685, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010422036543807009, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 50, 'num_filters_3': 36}"}}
exception: None

16:26:09 job_callback for (4, 0, 23) started
16:26:09 DISPATCHER: Trying to submit another job.
16:26:09 job_callback for (4, 0, 23) got condition
16:26:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:26:09 HBMASTER: Trying to run another job!
16:26:09 job_callback for (4, 0, 23) finished
16:26:09 HBMASTER: schedule new run for iteration 4
16:26:09 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
16:26:09 HBMASTER: submitting job (4, 0, 24) to dispatcher
16:26:09 DISPATCHER: trying to submit job (4, 0, 24)
16:26:09 DISPATCHER: trying to notify the job_runner thread.
16:26:09 HBMASTER: job (4, 0, 24) submitted to dispatcher
16:26:09 DISPATCHER: Trying to submit another job.
16:26:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:26:09 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:26:09 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:26:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:26:09 WORKER: start processing job (4, 0, 24)
16:26:09 WORKER: args: ()
16:26:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:26:45 DISPATCHER: Starting worker discovery
16:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:45 DISPATCHER: Finished worker discovery
16:27:45 DISPATCHER: Starting worker discovery
16:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:45 DISPATCHER: Finished worker discovery
16:28:27 WORKER: done with job (4, 0, 24), trying to register it.
16:28:27 WORKER: registered result for job (4, 0, 24) with dispatcher
16:28:27 DISPATCHER: job (4, 0, 24) finished
16:28:27 DISPATCHER: register_result: lock acquired
16:28:27 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:28:27 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.654927103352019, 'info': {'data02': 0.654927103352019, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}"}}
exception: None

16:28:27 job_callback for (4, 0, 24) started
16:28:27 DISPATCHER: Trying to submit another job.
16:28:27 job_callback for (4, 0, 24) got condition
16:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:28:28 HBMASTER: Trying to run another job!
16:28:28 job_callback for (4, 0, 24) finished
16:28:28 HBMASTER: schedule new run for iteration 4
16:28:28 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
16:28:28 HBMASTER: submitting job (4, 0, 25) to dispatcher
16:28:28 DISPATCHER: trying to submit job (4, 0, 25)
16:28:28 DISPATCHER: trying to notify the job_runner thread.
16:28:28 HBMASTER: job (4, 0, 25) submitted to dispatcher
16:28:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:28:28 DISPATCHER: Trying to submit another job.
16:28:28 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:28:28 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:28:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:28:28 WORKER: start processing job (4, 0, 25)
16:28:28 WORKER: args: ()
16:28:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013452254255382353, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02661764773811199, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:28:45 DISPATCHER: Starting worker discovery
16:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:45 DISPATCHER: Finished worker discovery
16:29:45 DISPATCHER: Starting worker discovery
16:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:45 DISPATCHER: Finished worker discovery
16:30:45 DISPATCHER: Starting worker discovery
16:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:46 DISPATCHER: Finished worker discovery
16:30:47 WORKER: done with job (4, 0, 25), trying to register it.
16:30:47 WORKER: registered result for job (4, 0, 25) with dispatcher
16:30:47 DISPATCHER: job (4, 0, 25) finished
16:30:47 DISPATCHER: register_result: lock acquired
16:30:47 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:30:47 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013452254255382353, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02661764773811199, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5579382641490667, 'info': {'data02': 0.5579382641490667, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013452254255382353, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02661764773811199, 'kernel_size_2': 5, 'num_filters_2': 105}"}}
exception: None

16:30:47 job_callback for (4, 0, 25) started
16:30:47 job_callback for (4, 0, 25) got condition
16:30:47 DISPATCHER: Trying to submit another job.
16:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:30:47 HBMASTER: Trying to run another job!
16:30:47 job_callback for (4, 0, 25) finished
16:30:47 ITERATION: Advancing config (4, 0, 2) to next budget 400.000000
16:30:47 ITERATION: Advancing config (4, 0, 20) to next budget 400.000000
16:30:47 ITERATION: Advancing config (4, 0, 24) to next budget 400.000000
16:30:47 HBMASTER: schedule new run for iteration 4
16:30:47 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
16:30:47 HBMASTER: submitting job (4, 0, 2) to dispatcher
16:30:47 DISPATCHER: trying to submit job (4, 0, 2)
16:30:47 DISPATCHER: trying to notify the job_runner thread.
16:30:47 HBMASTER: job (4, 0, 2) submitted to dispatcher
16:30:47 DISPATCHER: Trying to submit another job.
16:30:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:30:47 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:30:47 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:30:47 WORKER: start processing job (4, 0, 2)
16:30:47 WORKER: args: ()
16:30:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 400.0, 'working_directory': '.'}
16:31:46 DISPATCHER: Starting worker discovery
16:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:46 DISPATCHER: Finished worker discovery
16:32:46 DISPATCHER: Starting worker discovery
16:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:46 DISPATCHER: Finished worker discovery
16:33:46 DISPATCHER: Starting worker discovery
16:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:46 DISPATCHER: Finished worker discovery
16:34:46 DISPATCHER: Starting worker discovery
16:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:46 DISPATCHER: Finished worker discovery
16:35:46 DISPATCHER: Starting worker discovery
16:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:46 DISPATCHER: Finished worker discovery
16:36:46 DISPATCHER: Starting worker discovery
16:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:46 DISPATCHER: Finished worker discovery
16:37:33 WORKER: done with job (4, 0, 2), trying to register it.
16:37:33 WORKER: registered result for job (4, 0, 2) with dispatcher
16:37:33 DISPATCHER: job (4, 0, 2) finished
16:37:33 DISPATCHER: register_result: lock acquired
16:37:33 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:37:33 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7508498140821656, 'info': {'data02': 0.7508498140821656, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}"}}
exception: None

16:37:33 job_callback for (4, 0, 2) started
16:37:33 job_callback for (4, 0, 2) got condition
16:37:33 DISPATCHER: Trying to submit another job.
16:37:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:37:33 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:37:33 HBMASTER: Trying to run another job!
16:37:33 job_callback for (4, 0, 2) finished
16:37:33 HBMASTER: schedule new run for iteration 4
16:37:33 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
16:37:33 HBMASTER: submitting job (4, 0, 20) to dispatcher
16:37:33 DISPATCHER: trying to submit job (4, 0, 20)
16:37:33 DISPATCHER: trying to notify the job_runner thread.
16:37:33 HBMASTER: job (4, 0, 20) submitted to dispatcher
16:37:33 DISPATCHER: Trying to submit another job.
16:37:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:37:33 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:37:33 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:37:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:37:33 WORKER: start processing job (4, 0, 20)
16:37:33 WORKER: args: ()
16:37:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}, 'budget': 400.0, 'working_directory': '.'}
16:37:46 DISPATCHER: Starting worker discovery
16:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:46 DISPATCHER: Finished worker discovery
16:38:46 DISPATCHER: Starting worker discovery
16:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:46 DISPATCHER: Finished worker discovery
16:39:46 DISPATCHER: Starting worker discovery
16:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:46 DISPATCHER: Finished worker discovery
16:40:46 DISPATCHER: Starting worker discovery
16:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:46 DISPATCHER: Finished worker discovery
16:41:46 DISPATCHER: Starting worker discovery
16:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:46 DISPATCHER: Finished worker discovery
16:42:46 DISPATCHER: Starting worker discovery
16:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:46 DISPATCHER: Finished worker discovery
16:43:46 DISPATCHER: Starting worker discovery
16:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:46 DISPATCHER: Finished worker discovery
16:44:19 WORKER: done with job (4, 0, 20), trying to register it.
16:44:19 WORKER: registered result for job (4, 0, 20) with dispatcher
16:44:19 DISPATCHER: job (4, 0, 20) finished
16:44:19 DISPATCHER: register_result: lock acquired
16:44:19 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:44:19 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7061004679709262, 'info': {'data02': 0.7061004679709262, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011089876737858083, 'num_filters_1': 111, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013616336345441122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 109}"}}
exception: None

16:44:19 job_callback for (4, 0, 20) started
16:44:19 job_callback for (4, 0, 20) got condition
16:44:19 DISPATCHER: Trying to submit another job.
16:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:44:19 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:44:19 HBMASTER: Trying to run another job!
16:44:19 job_callback for (4, 0, 20) finished
16:44:19 HBMASTER: schedule new run for iteration 4
16:44:19 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
16:44:19 HBMASTER: submitting job (4, 0, 24) to dispatcher
16:44:19 DISPATCHER: trying to submit job (4, 0, 24)
16:44:19 DISPATCHER: trying to notify the job_runner thread.
16:44:19 HBMASTER: job (4, 0, 24) submitted to dispatcher
16:44:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:44:19 DISPATCHER: Trying to submit another job.
16:44:19 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:44:19 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:44:19 WORKER: start processing job (4, 0, 24)
16:44:19 WORKER: args: ()
16:44:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
16:44:46 DISPATCHER: Starting worker discovery
16:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:46 DISPATCHER: Finished worker discovery
16:45:46 DISPATCHER: Starting worker discovery
16:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:46 DISPATCHER: Finished worker discovery
16:46:46 DISPATCHER: Starting worker discovery
16:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:46 DISPATCHER: Finished worker discovery
16:47:46 DISPATCHER: Starting worker discovery
16:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:46 DISPATCHER: Finished worker discovery
16:48:46 DISPATCHER: Starting worker discovery
16:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:46 DISPATCHER: Finished worker discovery
16:49:46 DISPATCHER: Starting worker discovery
16:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:46 DISPATCHER: Finished worker discovery
16:50:46 DISPATCHER: Starting worker discovery
16:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:46 DISPATCHER: Finished worker discovery
16:51:06 WORKER: done with job (4, 0, 24), trying to register it.
16:51:06 WORKER: registered result for job (4, 0, 24) with dispatcher
16:51:06 DISPATCHER: job (4, 0, 24) finished
16:51:06 DISPATCHER: register_result: lock acquired
16:51:06 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:51:06 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.643948259068259, 'info': {'data02': 0.643948259068259, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002351520140707945, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.010249691833798763, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 62, 'num_filters_3': 18}"}}
exception: None

16:51:06 job_callback for (4, 0, 24) started
16:51:06 job_callback for (4, 0, 24) got condition
16:51:06 DISPATCHER: Trying to submit another job.
16:51:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:51:06 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:51:06 HBMASTER: Trying to run another job!
16:51:06 job_callback for (4, 0, 24) finished
16:51:06 ITERATION: Advancing config (4, 0, 2) to next budget 1200.000000
16:51:06 HBMASTER: schedule new run for iteration 4
16:51:06 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
16:51:06 HBMASTER: submitting job (4, 0, 2) to dispatcher
16:51:06 DISPATCHER: trying to submit job (4, 0, 2)
16:51:06 DISPATCHER: trying to notify the job_runner thread.
16:51:06 HBMASTER: job (4, 0, 2) submitted to dispatcher
16:51:06 DISPATCHER: Trying to submit another job.
16:51:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:51:06 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:51:06 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:51:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:51:06 WORKER: start processing job (4, 0, 2)
16:51:06 WORKER: args: ()
16:51:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 1200.0, 'working_directory': '.'}
16:51:46 DISPATCHER: Starting worker discovery
16:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:46 DISPATCHER: Finished worker discovery
16:52:46 DISPATCHER: Starting worker discovery
16:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:46 DISPATCHER: Finished worker discovery
16:53:46 DISPATCHER: Starting worker discovery
16:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:46 DISPATCHER: Finished worker discovery
16:54:46 DISPATCHER: Starting worker discovery
16:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:46 DISPATCHER: Finished worker discovery
16:55:46 DISPATCHER: Starting worker discovery
16:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:46 DISPATCHER: Finished worker discovery
16:56:46 DISPATCHER: Starting worker discovery
16:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:46 DISPATCHER: Finished worker discovery
16:57:46 DISPATCHER: Starting worker discovery
16:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:46 DISPATCHER: Finished worker discovery
16:58:46 DISPATCHER: Starting worker discovery
16:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:46 DISPATCHER: Finished worker discovery
16:59:46 DISPATCHER: Starting worker discovery
16:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:46 DISPATCHER: Finished worker discovery
17:00:46 DISPATCHER: Starting worker discovery
17:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:46 DISPATCHER: Finished worker discovery
17:01:46 DISPATCHER: Starting worker discovery
17:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:46 DISPATCHER: Finished worker discovery
17:02:46 DISPATCHER: Starting worker discovery
17:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:46 DISPATCHER: Finished worker discovery
17:03:46 DISPATCHER: Starting worker discovery
17:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:46 DISPATCHER: Finished worker discovery
17:04:46 DISPATCHER: Starting worker discovery
17:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:46 DISPATCHER: Finished worker discovery
17:05:46 DISPATCHER: Starting worker discovery
17:05:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:46 DISPATCHER: Finished worker discovery
17:06:46 DISPATCHER: Starting worker discovery
17:06:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:46 DISPATCHER: Finished worker discovery
17:07:46 DISPATCHER: Starting worker discovery
17:07:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:46 DISPATCHER: Finished worker discovery
17:08:46 DISPATCHER: Starting worker discovery
17:08:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:46 DISPATCHER: Finished worker discovery
17:09:46 DISPATCHER: Starting worker discovery
17:09:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:46 DISPATCHER: Finished worker discovery
17:10:46 DISPATCHER: Starting worker discovery
17:10:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:46 DISPATCHER: Finished worker discovery
17:11:16 WORKER: done with job (4, 0, 2), trying to register it.
17:11:16 WORKER: registered result for job (4, 0, 2) with dispatcher
17:11:16 DISPATCHER: job (4, 0, 2) finished
17:11:16 DISPATCHER: register_result: lock acquired
17:11:16 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:11:16 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6215914474981006, 'info': {'data02': 0.6215914474981006, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002004345807895501, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02392145981809966, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 93}"}}
exception: None

17:11:16 job_callback for (4, 0, 2) started
17:11:16 job_callback for (4, 0, 2) got condition
17:11:16 DISPATCHER: Trying to submit another job.
17:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:11:16 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:11:16 HBMASTER: Trying to run another job!
17:11:16 job_callback for (4, 0, 2) finished
17:11:16 start sampling a new configuration.
17:11:16 done sampling a new configuration.
17:11:16 HBMASTER: schedule new run for iteration 5
17:11:16 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
17:11:16 HBMASTER: submitting job (5, 0, 0) to dispatcher
17:11:16 DISPATCHER: trying to submit job (5, 0, 0)
17:11:16 DISPATCHER: trying to notify the job_runner thread.
17:11:16 HBMASTER: job (5, 0, 0) submitted to dispatcher
17:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:11:16 DISPATCHER: Trying to submit another job.
17:11:16 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:11:16 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:11:16 WORKER: start processing job (5, 0, 0)
17:11:16 WORKER: args: ()
17:11:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011383054543801774, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.010647979833893203, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 23, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:11:46 DISPATCHER: Starting worker discovery
17:11:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:46 DISPATCHER: Finished worker discovery
17:12:46 DISPATCHER: Starting worker discovery
17:12:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:46 DISPATCHER: Finished worker discovery
17:13:34 WORKER: done with job (5, 0, 0), trying to register it.
17:13:34 WORKER: registered result for job (5, 0, 0) with dispatcher
17:13:34 DISPATCHER: job (5, 0, 0) finished
17:13:34 DISPATCHER: register_result: lock acquired
17:13:34 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:13:34 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011383054543801774, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.010647979833893203, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 23, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5781730457828141, 'info': {'data02': 0.5781730457828141, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011383054543801774, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.010647979833893203, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 23, 'num_filters_4': 17}"}}
exception: None

17:13:34 job_callback for (5, 0, 0) started
17:13:34 job_callback for (5, 0, 0) got condition
17:13:34 DISPATCHER: Trying to submit another job.
17:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:34 HBMASTER: Trying to run another job!
17:13:34 job_callback for (5, 0, 0) finished
17:13:34 start sampling a new configuration.
17:13:34 done sampling a new configuration.
17:13:34 HBMASTER: schedule new run for iteration 5
17:13:34 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
17:13:34 HBMASTER: submitting job (5, 0, 1) to dispatcher
17:13:34 DISPATCHER: trying to submit job (5, 0, 1)
17:13:34 DISPATCHER: trying to notify the job_runner thread.
17:13:34 HBMASTER: job (5, 0, 1) submitted to dispatcher
17:13:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:34 DISPATCHER: Trying to submit another job.
17:13:34 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:13:34 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:34 WORKER: start processing job (5, 0, 1)
17:13:34 WORKER: args: ()
17:13:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004351326099367205, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01396778777407964, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 28, 'num_filters_4': 75, 'num_filters_5': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:13:46 DISPATCHER: Starting worker discovery
17:13:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:46 DISPATCHER: Finished worker discovery
17:14:46 DISPATCHER: Starting worker discovery
17:14:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:46 DISPATCHER: Finished worker discovery
17:15:46 DISPATCHER: Starting worker discovery
17:15:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:46 DISPATCHER: Finished worker discovery
17:15:52 WORKER: done with job (5, 0, 1), trying to register it.
17:15:52 WORKER: registered result for job (5, 0, 1) with dispatcher
17:15:52 DISPATCHER: job (5, 0, 1) finished
17:15:52 DISPATCHER: register_result: lock acquired
17:15:52 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:15:52 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004351326099367205, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01396778777407964, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 28, 'num_filters_4': 75, 'num_filters_5': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5192732601816393, 'info': {'data02': 0.5192732601816393, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004351326099367205, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01396778777407964, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 28, 'num_filters_4': 75, 'num_filters_5': 55}"}}
exception: None

17:15:52 job_callback for (5, 0, 1) started
17:15:52 DISPATCHER: Trying to submit another job.
17:15:52 job_callback for (5, 0, 1) got condition
17:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:52 HBMASTER: Trying to run another job!
17:15:52 job_callback for (5, 0, 1) finished
17:15:52 start sampling a new configuration.
17:15:52 done sampling a new configuration.
17:15:52 HBMASTER: schedule new run for iteration 5
17:15:52 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
17:15:52 HBMASTER: submitting job (5, 0, 2) to dispatcher
17:15:52 DISPATCHER: trying to submit job (5, 0, 2)
17:15:52 DISPATCHER: trying to notify the job_runner thread.
17:15:52 HBMASTER: job (5, 0, 2) submitted to dispatcher
17:15:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:52 DISPATCHER: Trying to submit another job.
17:15:52 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:15:52 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:52 WORKER: start processing job (5, 0, 2)
17:15:52 WORKER: args: ()
17:15:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014783264155246435, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.04570474618345242, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 19, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:16:46 DISPATCHER: Starting worker discovery
17:16:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:46 DISPATCHER: Finished worker discovery
17:17:46 DISPATCHER: Starting worker discovery
17:17:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:46 DISPATCHER: Finished worker discovery
17:18:11 WORKER: done with job (5, 0, 2), trying to register it.
17:18:11 WORKER: registered result for job (5, 0, 2) with dispatcher
17:18:11 DISPATCHER: job (5, 0, 2) finished
17:18:11 DISPATCHER: register_result: lock acquired
17:18:11 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:18:11 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014783264155246435, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.04570474618345242, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 19, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46610347974699384, 'info': {'data02': 0.46610347974699384, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014783264155246435, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.04570474618345242, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 19, 'num_filters_4': 25}"}}
exception: None

17:18:11 job_callback for (5, 0, 2) started
17:18:11 job_callback for (5, 0, 2) got condition
17:18:11 DISPATCHER: Trying to submit another job.
17:18:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:18:11 HBMASTER: Trying to run another job!
17:18:11 job_callback for (5, 0, 2) finished
17:18:11 start sampling a new configuration.
17:18:11 best_vector: [0, 0, 0.18673321766771742, 0.324800757607998, 0.4857101107724678, 1, 0.8078468121168897, 0.065212739491408, 0, 1, 0, 0, 0.37290036148946715, 0.6083278602384531, 0.8070636110266074, 0.5032372105286216], 1.3096073552382434e-05, 3.605092843505157, 4.721256104171107e-05
17:18:11 done sampling a new configuration.
17:18:11 HBMASTER: schedule new run for iteration 5
17:18:11 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
17:18:11 HBMASTER: submitting job (5, 0, 3) to dispatcher
17:18:11 DISPATCHER: trying to submit job (5, 0, 3)
17:18:11 DISPATCHER: trying to notify the job_runner thread.
17:18:11 HBMASTER: job (5, 0, 3) submitted to dispatcher
17:18:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:18:11 DISPATCHER: Trying to submit another job.
17:18:11 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:18:11 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:18:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:18:11 WORKER: start processing job (5, 0, 3)
17:18:11 WORKER: args: ()
17:18:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:18:46 DISPATCHER: Starting worker discovery
17:18:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:46 DISPATCHER: Finished worker discovery
17:19:46 DISPATCHER: Starting worker discovery
17:19:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:46 DISPATCHER: Finished worker discovery
17:20:29 WORKER: done with job (5, 0, 3), trying to register it.
17:20:29 WORKER: registered result for job (5, 0, 3) with dispatcher
17:20:29 DISPATCHER: job (5, 0, 3) finished
17:20:29 DISPATCHER: register_result: lock acquired
17:20:29 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:20:29 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7093502937691092, 'info': {'data02': 0.7093502937691092, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}"}}
exception: None

17:20:29 job_callback for (5, 0, 3) started
17:20:29 DISPATCHER: Trying to submit another job.
17:20:29 job_callback for (5, 0, 3) got condition
17:20:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:29 HBMASTER: Trying to run another job!
17:20:29 job_callback for (5, 0, 3) finished
17:20:29 start sampling a new configuration.
17:20:30 best_vector: [1, 1, 0.23803872539772328, 0.7253709135038131, 0.7086494527675445, 0, 0.4340808432507833, 0.15711762922640676, 2, 1, 1, 0, 0.1699273905006773, 0.9186409204948423, 0.8652520481659312, 0.5041317054688356], 5.6971821763847684e-05, 0.5303938745062403, 3.021750528300612e-05
17:20:30 done sampling a new configuration.
17:20:30 HBMASTER: schedule new run for iteration 5
17:20:30 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
17:20:30 HBMASTER: submitting job (5, 0, 4) to dispatcher
17:20:30 DISPATCHER: trying to submit job (5, 0, 4)
17:20:30 DISPATCHER: trying to notify the job_runner thread.
17:20:30 HBMASTER: job (5, 0, 4) submitted to dispatcher
17:20:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:30 DISPATCHER: Trying to submit another job.
17:20:30 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:20:30 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:20:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:30 WORKER: start processing job (5, 0, 4)
17:20:30 WORKER: args: ()
17:20:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002992798315833405, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01601086326011086, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 22, 'num_filters_3': 108, 'num_filters_4': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:20:46 DISPATCHER: Starting worker discovery
17:20:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:46 DISPATCHER: Finished worker discovery
17:21:46 DISPATCHER: Starting worker discovery
17:21:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:46 DISPATCHER: Finished worker discovery
17:22:46 DISPATCHER: Starting worker discovery
17:22:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:46 DISPATCHER: Finished worker discovery
17:22:47 WORKER: done with job (5, 0, 4), trying to register it.
17:22:47 WORKER: registered result for job (5, 0, 4) with dispatcher
17:22:47 DISPATCHER: job (5, 0, 4) finished
17:22:47 DISPATCHER: register_result: lock acquired
17:22:47 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:22:47 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002992798315833405, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01601086326011086, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 22, 'num_filters_3': 108, 'num_filters_4': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.571163867036153, 'info': {'data02': 0.571163867036153, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002992798315833405, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01601086326011086, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 22, 'num_filters_3': 108, 'num_filters_4': 97}"}}
exception: None

17:22:47 job_callback for (5, 0, 4) started
17:22:47 DISPATCHER: Trying to submit another job.
17:22:47 job_callback for (5, 0, 4) got condition
17:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:22:47 HBMASTER: Trying to run another job!
17:22:47 job_callback for (5, 0, 4) finished
17:22:47 start sampling a new configuration.
17:22:48 best_vector: [2, 0, 0.15854631341820502, 0.24201068936803438, 0.3313388200304468, 1, 0.6562532741630964, 0.33551366581554226, 2, 1, 1, 0, 0.6932440920730815, 0.3460332842668202, 0.9996564211552099, 0.5031388719550176], 4.554877477425204e-05, 0.9505582802158021, 4.329676501534993e-05
17:22:48 done sampling a new configuration.
17:22:48 HBMASTER: schedule new run for iteration 5
17:22:48 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
17:22:48 HBMASTER: submitting job (5, 0, 5) to dispatcher
17:22:48 DISPATCHER: trying to submit job (5, 0, 5)
17:22:48 DISPATCHER: trying to notify the job_runner thread.
17:22:48 HBMASTER: job (5, 0, 5) submitted to dispatcher
17:22:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:22:48 DISPATCHER: Trying to submit another job.
17:22:48 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:22:48 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:22:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:22:48 WORKER: start processing job (5, 0, 5)
17:22:48 WORKER: args: ()
17:22:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002075356104639304, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.027322053863484835, 'kernel_size_2': 7, 'num_filters_2': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:23:46 DISPATCHER: Starting worker discovery
17:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:46 DISPATCHER: Finished worker discovery
17:24:46 DISPATCHER: Starting worker discovery
17:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:46 DISPATCHER: Finished worker discovery
17:25:06 WORKER: done with job (5, 0, 5), trying to register it.
17:25:06 WORKER: registered result for job (5, 0, 5) with dispatcher
17:25:06 DISPATCHER: job (5, 0, 5) finished
17:25:06 DISPATCHER: register_result: lock acquired
17:25:06 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:25:06 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002075356104639304, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.027322053863484835, 'kernel_size_2': 7, 'num_filters_2': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6409114235302732, 'info': {'data02': 0.6409114235302732, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002075356104639304, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.027322053863484835, 'kernel_size_2': 7, 'num_filters_2': 67}"}}
exception: None

17:25:06 job_callback for (5, 0, 5) started
17:25:06 job_callback for (5, 0, 5) got condition
17:25:06 DISPATCHER: Trying to submit another job.
17:25:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:25:06 HBMASTER: Trying to run another job!
17:25:06 job_callback for (5, 0, 5) finished
17:25:06 start sampling a new configuration.
17:25:06 best_vector: [3, 1, 0.2548627547084363, 0.5088495177055751, 0.7898476183386418, 1, 0.26602189671397075, 0.5050897673614702, 2, 2, 1, 0, 0.6275320954247541, 0.351875283363936, 0.9256734251520053, 0.5028354786307192], 8.518026772397333e-05, 0.7165935123946438, 6.103962723503816e-05
17:25:06 done sampling a new configuration.
17:25:06 HBMASTER: schedule new run for iteration 5
17:25:06 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
17:25:06 HBMASTER: submitting job (5, 0, 6) to dispatcher
17:25:06 DISPATCHER: trying to submit job (5, 0, 6)
17:25:06 DISPATCHER: trying to notify the job_runner thread.
17:25:06 HBMASTER: job (5, 0, 6) submitted to dispatcher
17:25:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:25:06 DISPATCHER: Trying to submit another job.
17:25:06 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:25:06 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:25:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:25:06 WORKER: start processing job (5, 0, 6)
17:25:06 WORKER: args: ()
17:25:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003233891980858773, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04540847720167498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 33, 'num_filters_4': 110}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:25:46 DISPATCHER: Starting worker discovery
17:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:46 DISPATCHER: Finished worker discovery
17:26:46 DISPATCHER: Starting worker discovery
17:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:46 DISPATCHER: Finished worker discovery
17:27:25 WORKER: done with job (5, 0, 6), trying to register it.
17:27:25 WORKER: registered result for job (5, 0, 6) with dispatcher
17:27:25 DISPATCHER: job (5, 0, 6) finished
17:27:25 DISPATCHER: register_result: lock acquired
17:27:25 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:27:25 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003233891980858773, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04540847720167498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 33, 'num_filters_4': 110}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6462668967884179, 'info': {'data02': 0.6462668967884179, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003233891980858773, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04540847720167498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 33, 'num_filters_4': 110}"}}
exception: None

17:27:25 job_callback for (5, 0, 6) started
17:27:25 job_callback for (5, 0, 6) got condition
17:27:25 DISPATCHER: Trying to submit another job.
17:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:27:25 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.715210





17:27:25 HBMASTER: Trying to run another job!
17:27:25 job_callback for (5, 0, 6) finished
17:27:25 start sampling a new configuration.
17:27:25 done sampling a new configuration.
17:27:25 HBMASTER: schedule new run for iteration 5
17:27:25 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
17:27:25 HBMASTER: submitting job (5, 0, 7) to dispatcher
17:27:25 DISPATCHER: trying to submit job (5, 0, 7)
17:27:25 DISPATCHER: trying to notify the job_runner thread.
17:27:25 HBMASTER: job (5, 0, 7) submitted to dispatcher
17:27:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:27:25 DISPATCHER: Trying to submit another job.
17:27:25 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:27:25 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:27:25 WORKER: start processing job (5, 0, 7)
17:27:25 WORKER: args: ()
17:27:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00731388910589468, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.01554165798351022}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:27:46 DISPATCHER: Starting worker discovery
17:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:46 DISPATCHER: Finished worker discovery
17:28:46 DISPATCHER: Starting worker discovery
17:28:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:46 DISPATCHER: Finished worker discovery
17:29:43 WORKER: done with job (5, 0, 7), trying to register it.
17:29:43 WORKER: registered result for job (5, 0, 7) with dispatcher
17:29:43 DISPATCHER: job (5, 0, 7) finished
17:29:43 DISPATCHER: register_result: lock acquired
17:29:43 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:29:43 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00731388910589468, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.01554165798351022}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47658437351279176, 'info': {'data02': 0.47658437351279176, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00731388910589468, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.01554165798351022}"}}
exception: None

17:29:43 job_callback for (5, 0, 7) started
17:29:43 DISPATCHER: Trying to submit another job.
17:29:43 job_callback for (5, 0, 7) got condition
17:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:29:43 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.715210





17:29:43 HBMASTER: Trying to run another job!
17:29:43 job_callback for (5, 0, 7) finished
17:29:43 start sampling a new configuration.
17:29:43 done sampling a new configuration.
17:29:43 HBMASTER: schedule new run for iteration 5
17:29:43 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
17:29:43 HBMASTER: submitting job (5, 0, 8) to dispatcher
17:29:43 DISPATCHER: trying to submit job (5, 0, 8)
17:29:43 DISPATCHER: trying to notify the job_runner thread.
17:29:43 HBMASTER: job (5, 0, 8) submitted to dispatcher
17:29:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:29:43 DISPATCHER: Trying to submit another job.
17:29:43 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:29:43 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:29:43 WORKER: start processing job (5, 0, 8)
17:29:43 WORKER: args: ()
17:29:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010877707907278104, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.13865941218666403, 'kernel_size_2': 7, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:29:46 DISPATCHER: Starting worker discovery
17:29:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:46 DISPATCHER: Finished worker discovery
17:30:46 DISPATCHER: Starting worker discovery
17:30:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:46 DISPATCHER: Finished worker discovery
17:31:46 DISPATCHER: Starting worker discovery
17:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:46 DISPATCHER: Finished worker discovery
17:32:01 WORKER: done with job (5, 0, 8), trying to register it.
17:32:01 WORKER: registered result for job (5, 0, 8) with dispatcher
17:32:01 DISPATCHER: job (5, 0, 8) finished
17:32:01 DISPATCHER: register_result: lock acquired
17:32:01 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:32:01 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010877707907278104, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.13865941218666403, 'kernel_size_2': 7, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.275593403216381, 'info': {'data02': 0.275593403216381, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010877707907278104, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.13865941218666403, 'kernel_size_2': 7, 'num_filters_2': 86}"}}
exception: None

17:32:01 job_callback for (5, 0, 8) started
17:32:01 DISPATCHER: Trying to submit another job.
17:32:01 job_callback for (5, 0, 8) got condition
17:32:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:01 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.715210





17:32:01 HBMASTER: Trying to run another job!
17:32:01 job_callback for (5, 0, 8) finished
17:32:01 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
17:32:01 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
17:32:01 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
17:32:01 HBMASTER: schedule new run for iteration 5
17:32:01 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
17:32:01 HBMASTER: submitting job (5, 0, 3) to dispatcher
17:32:01 DISPATCHER: trying to submit job (5, 0, 3)
17:32:01 DISPATCHER: trying to notify the job_runner thread.
17:32:01 HBMASTER: job (5, 0, 3) submitted to dispatcher
17:32:01 DISPATCHER: Trying to submit another job.
17:32:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:01 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:32:01 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:32:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:01 WORKER: start processing job (5, 0, 3)
17:32:01 WORKER: args: ()
17:32:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}, 'budget': 400.0, 'working_directory': '.'}
17:32:46 DISPATCHER: Starting worker discovery
17:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:46 DISPATCHER: Finished worker discovery
17:33:46 DISPATCHER: Starting worker discovery
17:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:46 DISPATCHER: Finished worker discovery
17:34:46 DISPATCHER: Starting worker discovery
17:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:46 DISPATCHER: Finished worker discovery
17:35:46 DISPATCHER: Starting worker discovery
17:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:46 DISPATCHER: Finished worker discovery
17:36:46 DISPATCHER: Starting worker discovery
17:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:46 DISPATCHER: Finished worker discovery
17:37:46 DISPATCHER: Starting worker discovery
17:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:46 DISPATCHER: Finished worker discovery
17:38:46 DISPATCHER: Starting worker discovery
17:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:46 DISPATCHER: Finished worker discovery
17:38:48 WORKER: done with job (5, 0, 3), trying to register it.
17:38:48 WORKER: registered result for job (5, 0, 3) with dispatcher
17:38:48 DISPATCHER: job (5, 0, 3) finished
17:38:48 DISPATCHER: register_result: lock acquired
17:38:48 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:38:48 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6718485079335647, 'info': {'data02': 0.6718485079335647, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}"}}
exception: None

17:38:48 job_callback for (5, 0, 3) started
17:38:48 job_callback for (5, 0, 3) got condition
17:38:48 DISPATCHER: Trying to submit another job.
17:38:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:38:48 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:38:48 HBMASTER: Trying to run another job!
17:38:48 job_callback for (5, 0, 3) finished
17:38:48 HBMASTER: schedule new run for iteration 5
17:38:48 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
17:38:48 HBMASTER: submitting job (5, 0, 5) to dispatcher
17:38:48 DISPATCHER: trying to submit job (5, 0, 5)
17:38:48 DISPATCHER: trying to notify the job_runner thread.
17:38:48 HBMASTER: job (5, 0, 5) submitted to dispatcher
17:38:48 DISPATCHER: Trying to submit another job.
17:38:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:38:48 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:38:48 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:38:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:38:48 WORKER: start processing job (5, 0, 5)
17:38:48 WORKER: args: ()
17:38:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002075356104639304, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.027322053863484835, 'kernel_size_2': 7, 'num_filters_2': 67}, 'budget': 400.0, 'working_directory': '.'}
17:39:46 DISPATCHER: Starting worker discovery
17:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:46 DISPATCHER: Finished worker discovery
17:40:46 DISPATCHER: Starting worker discovery
17:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:46 DISPATCHER: Finished worker discovery
17:41:46 DISPATCHER: Starting worker discovery
17:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:46 DISPATCHER: Finished worker discovery
17:42:46 DISPATCHER: Starting worker discovery
17:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:46 DISPATCHER: Finished worker discovery
17:43:46 DISPATCHER: Starting worker discovery
17:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:46 DISPATCHER: Finished worker discovery
17:44:46 DISPATCHER: Starting worker discovery
17:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:46 DISPATCHER: Finished worker discovery
17:45:34 WORKER: done with job (5, 0, 5), trying to register it.
17:45:34 WORKER: registered result for job (5, 0, 5) with dispatcher
17:45:34 DISPATCHER: job (5, 0, 5) finished
17:45:34 DISPATCHER: register_result: lock acquired
17:45:34 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:45:34 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002075356104639304, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.027322053863484835, 'kernel_size_2': 7, 'num_filters_2': 67}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5575645373938198, 'info': {'data02': 0.5575645373938198, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002075356104639304, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.027322053863484835, 'kernel_size_2': 7, 'num_filters_2': 67}"}}
exception: None

17:45:34 job_callback for (5, 0, 5) started
17:45:34 job_callback for (5, 0, 5) got condition
17:45:34 DISPATCHER: Trying to submit another job.
17:45:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:45:34 HBMASTER: Trying to run another job!
17:45:34 job_callback for (5, 0, 5) finished
17:45:34 HBMASTER: schedule new run for iteration 5
17:45:34 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
17:45:34 HBMASTER: submitting job (5, 0, 6) to dispatcher
17:45:34 DISPATCHER: trying to submit job (5, 0, 6)
17:45:34 DISPATCHER: trying to notify the job_runner thread.
17:45:34 HBMASTER: job (5, 0, 6) submitted to dispatcher
17:45:34 DISPATCHER: Trying to submit another job.
17:45:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:45:34 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:45:34 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:45:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:45:34 WORKER: start processing job (5, 0, 6)
17:45:34 WORKER: args: ()
17:45:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003233891980858773, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04540847720167498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 33, 'num_filters_4': 110}, 'budget': 400.0, 'working_directory': '.'}
17:45:46 DISPATCHER: Starting worker discovery
17:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:46 DISPATCHER: Finished worker discovery
17:46:46 DISPATCHER: Starting worker discovery
17:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:46 DISPATCHER: Finished worker discovery
17:47:46 DISPATCHER: Starting worker discovery
17:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:46 DISPATCHER: Finished worker discovery
17:48:46 DISPATCHER: Starting worker discovery
17:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:46 DISPATCHER: Finished worker discovery
17:49:46 DISPATCHER: Starting worker discovery
17:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:46 DISPATCHER: Finished worker discovery
17:50:46 DISPATCHER: Starting worker discovery
17:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:46 DISPATCHER: Finished worker discovery
17:51:46 DISPATCHER: Starting worker discovery
17:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:46 DISPATCHER: Finished worker discovery
17:52:20 WORKER: done with job (5, 0, 6), trying to register it.
17:52:20 WORKER: registered result for job (5, 0, 6) with dispatcher
17:52:20 DISPATCHER: job (5, 0, 6) finished
17:52:20 DISPATCHER: register_result: lock acquired
17:52:20 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:52:20 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003233891980858773, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04540847720167498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 33, 'num_filters_4': 110}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6475459164095742, 'info': {'data02': 0.6475459164095742, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003233891980858773, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04540847720167498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 33, 'num_filters_4': 110}"}}
exception: None

17:52:20 job_callback for (5, 0, 6) started
17:52:20 DISPATCHER: Trying to submit another job.
17:52:20 job_callback for (5, 0, 6) got condition
17:52:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:52:20 HBMASTER: Trying to run another job!
17:52:20 job_callback for (5, 0, 6) finished
17:52:20 ITERATION: Advancing config (5, 0, 3) to next budget 1200.000000
17:52:20 HBMASTER: schedule new run for iteration 5
17:52:20 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
17:52:20 HBMASTER: submitting job (5, 0, 3) to dispatcher
17:52:20 DISPATCHER: trying to submit job (5, 0, 3)
17:52:20 DISPATCHER: trying to notify the job_runner thread.
17:52:20 HBMASTER: job (5, 0, 3) submitted to dispatcher
17:52:20 DISPATCHER: Trying to submit another job.
17:52:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:52:20 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:52:20 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:52:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:52:20 WORKER: start processing job (5, 0, 3)
17:52:20 WORKER: args: ()
17:52:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}, 'budget': 1200.0, 'working_directory': '.'}
17:52:46 DISPATCHER: Starting worker discovery
17:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:46 DISPATCHER: Finished worker discovery
17:53:46 DISPATCHER: Starting worker discovery
17:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:46 DISPATCHER: Finished worker discovery
17:54:46 DISPATCHER: Starting worker discovery
17:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:46 DISPATCHER: Finished worker discovery
17:55:46 DISPATCHER: Starting worker discovery
17:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:46 DISPATCHER: Finished worker discovery
17:56:46 DISPATCHER: Starting worker discovery
17:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:46 DISPATCHER: Finished worker discovery
17:57:46 DISPATCHER: Starting worker discovery
17:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:46 DISPATCHER: Finished worker discovery
17:58:46 DISPATCHER: Starting worker discovery
17:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:46 DISPATCHER: Finished worker discovery
17:59:46 DISPATCHER: Starting worker discovery
17:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:46 DISPATCHER: Finished worker discovery
18:00:46 DISPATCHER: Starting worker discovery
18:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:46 DISPATCHER: Finished worker discovery
18:01:46 DISPATCHER: Starting worker discovery
18:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:46 DISPATCHER: Finished worker discovery
18:02:46 DISPATCHER: Starting worker discovery
18:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:46 DISPATCHER: Finished worker discovery
18:03:46 DISPATCHER: Starting worker discovery
18:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:46 DISPATCHER: Finished worker discovery
18:04:46 DISPATCHER: Starting worker discovery
18:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:46 DISPATCHER: Finished worker discovery
18:05:46 DISPATCHER: Starting worker discovery
18:05:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:46 DISPATCHER: Finished worker discovery
18:06:46 DISPATCHER: Starting worker discovery
18:06:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:46 DISPATCHER: Finished worker discovery
18:07:46 DISPATCHER: Starting worker discovery
18:07:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:46 DISPATCHER: Finished worker discovery
18:08:46 DISPATCHER: Starting worker discovery
18:08:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:46 DISPATCHER: Finished worker discovery
18:09:46 DISPATCHER: Starting worker discovery
18:09:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:46 DISPATCHER: Finished worker discovery
18:10:46 DISPATCHER: Starting worker discovery
18:10:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:46 DISPATCHER: Finished worker discovery
18:11:46 DISPATCHER: Starting worker discovery
18:11:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:46 DISPATCHER: Finished worker discovery
18:12:31 WORKER: done with job (5, 0, 3), trying to register it.
18:12:31 WORKER: registered result for job (5, 0, 3) with dispatcher
18:12:31 DISPATCHER: job (5, 0, 3) finished
18:12:31 DISPATCHER: register_result: lock acquired
18:12:31 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:12:31 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.552106641563302, 'info': {'data02': 0.552106641563302, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023630147653277813, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012157484657725166, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 56}"}}
exception: None

18:12:31 job_callback for (5, 0, 3) started
18:12:31 DISPATCHER: Trying to submit another job.
18:12:31 job_callback for (5, 0, 3) got condition
18:12:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:12:31 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:12:31 HBMASTER: Trying to run another job!
18:12:31 job_callback for (5, 0, 3) finished
18:12:31 start sampling a new configuration.
18:12:31 best_vector: [3, 0, 0.5427848668019548, 0.8314750149240571, 0.24293777863682112, 0, 0.6517636814910867, 0.21386244282254455, 0, 2, 1, 0, 0.5208891375500654, 0.10916675694665001, 0.8021735248034156, 0.5051459122722819], 3.351246819096708e-33, 2.98396404079106, 0.0
18:12:31 done sampling a new configuration.
18:12:31 HBMASTER: schedule new run for iteration 6
18:12:31 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
18:12:31 HBMASTER: submitting job (6, 0, 0) to dispatcher
18:12:31 DISPATCHER: trying to submit job (6, 0, 0)
18:12:31 DISPATCHER: trying to notify the job_runner thread.
18:12:31 HBMASTER: job (6, 0, 0) submitted to dispatcher
18:12:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:12:31 DISPATCHER: Trying to submit another job.
18:12:31 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:12:31 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:12:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:12:31 WORKER: start processing job (6, 0, 0)
18:12:31 WORKER: args: ()
18:12:31 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012177825135106592, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.018977607188066514, 'kernel_size_2': 3, 'num_filters_2': 47}, 'budget': 400.0, 'working_directory': '.'}
18:12:46 DISPATCHER: Starting worker discovery
18:12:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:46 DISPATCHER: Finished worker discovery
18:13:46 DISPATCHER: Starting worker discovery
18:13:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:46 DISPATCHER: Finished worker discovery
18:14:46 DISPATCHER: Starting worker discovery
18:14:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:46 DISPATCHER: Finished worker discovery
18:15:46 DISPATCHER: Starting worker discovery
18:15:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:46 DISPATCHER: Finished worker discovery
18:16:46 DISPATCHER: Starting worker discovery
18:16:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:46 DISPATCHER: Finished worker discovery
18:17:46 DISPATCHER: Starting worker discovery
18:17:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:46 DISPATCHER: Finished worker discovery
18:18:46 DISPATCHER: Starting worker discovery
18:18:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:46 DISPATCHER: Finished worker discovery
18:19:16 WORKER: done with job (6, 0, 0), trying to register it.
18:19:16 WORKER: registered result for job (6, 0, 0) with dispatcher
18:19:16 DISPATCHER: job (6, 0, 0) finished
18:19:16 DISPATCHER: register_result: lock acquired
18:19:16 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:19:16 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012177825135106592, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.018977607188066514, 'kernel_size_2': 3, 'num_filters_2': 47}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.44727514090079445, 'info': {'data02': 0.44727514090079445, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012177825135106592, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.018977607188066514, 'kernel_size_2': 3, 'num_filters_2': 47}"}}
exception: None

18:19:16 job_callback for (6, 0, 0) started
18:19:16 DISPATCHER: Trying to submit another job.
18:19:16 job_callback for (6, 0, 0) got condition
18:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:19:16 HBMASTER: Trying to run another job!
18:19:16 job_callback for (6, 0, 0) finished
18:19:16 start sampling a new configuration.
18:19:16 done sampling a new configuration.
18:19:16 HBMASTER: schedule new run for iteration 6
18:19:16 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
18:19:16 HBMASTER: submitting job (6, 0, 1) to dispatcher
18:19:16 DISPATCHER: trying to submit job (6, 0, 1)
18:19:16 DISPATCHER: trying to notify the job_runner thread.
18:19:16 HBMASTER: job (6, 0, 1) submitted to dispatcher
18:19:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:19:16 DISPATCHER: Trying to submit another job.
18:19:16 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:19:16 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:19:16 WORKER: start processing job (6, 0, 1)
18:19:16 WORKER: args: ()
18:19:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003077339945183295, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.13273376360419725, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 100}, 'budget': 400.0, 'working_directory': '.'}
18:19:46 DISPATCHER: Starting worker discovery
18:19:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:46 DISPATCHER: Finished worker discovery
18:20:46 DISPATCHER: Starting worker discovery
18:20:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:46 DISPATCHER: Finished worker discovery
18:21:46 DISPATCHER: Starting worker discovery
18:21:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:46 DISPATCHER: Finished worker discovery
18:22:46 DISPATCHER: Starting worker discovery
18:22:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:46 DISPATCHER: Finished worker discovery
18:23:46 DISPATCHER: Starting worker discovery
18:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:46 DISPATCHER: Finished worker discovery
18:24:46 DISPATCHER: Starting worker discovery
18:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:46 DISPATCHER: Finished worker discovery
18:25:46 DISPATCHER: Starting worker discovery
18:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:46 DISPATCHER: Finished worker discovery
18:26:03 WORKER: done with job (6, 0, 1), trying to register it.
18:26:03 WORKER: registered result for job (6, 0, 1) with dispatcher
18:26:03 DISPATCHER: job (6, 0, 1) finished
18:26:03 DISPATCHER: register_result: lock acquired
18:26:03 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:26:03 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003077339945183295, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.13273376360419725, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4529202128181611, 'info': {'data02': 0.4529202128181611, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003077339945183295, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.13273376360419725, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 100}"}}
exception: None

18:26:03 job_callback for (6, 0, 1) started
18:26:03 DISPATCHER: Trying to submit another job.
18:26:03 job_callback for (6, 0, 1) got condition
18:26:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:26:03 HBMASTER: Trying to run another job!
18:26:03 job_callback for (6, 0, 1) finished
18:26:03 start sampling a new configuration.
18:26:03 done sampling a new configuration.
18:26:03 HBMASTER: schedule new run for iteration 6
18:26:03 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
18:26:03 HBMASTER: submitting job (6, 0, 2) to dispatcher
18:26:03 DISPATCHER: trying to submit job (6, 0, 2)
18:26:03 DISPATCHER: trying to notify the job_runner thread.
18:26:03 HBMASTER: job (6, 0, 2) submitted to dispatcher
18:26:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:26:03 DISPATCHER: Trying to submit another job.
18:26:03 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:26:03 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:26:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:26:03 WORKER: start processing job (6, 0, 2)
18:26:03 WORKER: args: ()
18:26:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0024185694508323547, 'num_filters_1': 84, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.06007411912459953, 'kernel_size_2': 3, 'num_filters_2': 106}, 'budget': 400.0, 'working_directory': '.'}
18:26:46 DISPATCHER: Starting worker discovery
18:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:46 DISPATCHER: Finished worker discovery
18:27:46 DISPATCHER: Starting worker discovery
18:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:47 DISPATCHER: Finished worker discovery
18:28:47 DISPATCHER: Starting worker discovery
18:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:47 DISPATCHER: Finished worker discovery
18:29:47 DISPATCHER: Starting worker discovery
18:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:47 DISPATCHER: Finished worker discovery
18:30:47 DISPATCHER: Starting worker discovery
18:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:47 DISPATCHER: Finished worker discovery
18:31:47 DISPATCHER: Starting worker discovery
18:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:47 DISPATCHER: Finished worker discovery
18:32:47 DISPATCHER: Starting worker discovery
18:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:47 DISPATCHER: Finished worker discovery
18:32:53 WORKER: done with job (6, 0, 2), trying to register it.
18:32:53 WORKER: registered result for job (6, 0, 2) with dispatcher
18:32:53 DISPATCHER: job (6, 0, 2) finished
18:32:53 DISPATCHER: register_result: lock acquired
18:32:53 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:32:53 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0024185694508323547, 'num_filters_1': 84, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.06007411912459953, 'kernel_size_2': 3, 'num_filters_2': 106}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4359329211250957, 'info': {'data02': 0.4359329211250957, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0024185694508323547, 'num_filters_1': 84, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.06007411912459953, 'kernel_size_2': 3, 'num_filters_2': 106}"}}
exception: None

18:32:53 job_callback for (6, 0, 2) started
18:32:53 DISPATCHER: Trying to submit another job.
18:32:53 job_callback for (6, 0, 2) got condition
18:32:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:32:53 HBMASTER: Trying to run another job!
18:32:53 job_callback for (6, 0, 2) finished
18:32:53 start sampling a new configuration.
18:32:54 best_vector: [0, 0, 0.33817116355177235, 0.5796150457872107, 0.43917688198213356, 0, 0.6089549320457667, 0.11317057589023899, 0, 1, 2, 0, 0.4832871386479133, 0.7240922828941135, 0.42399669156092284, 0.503996236120742], 4.6132635340553215e-33, 2.167662854328513, 0.0
18:32:54 done sampling a new configuration.
18:32:54 HBMASTER: schedule new run for iteration 6
18:32:54 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
18:32:54 HBMASTER: submitting job (6, 0, 3) to dispatcher
18:32:54 DISPATCHER: trying to submit job (6, 0, 3)
18:32:54 DISPATCHER: trying to notify the job_runner thread.
18:32:54 HBMASTER: job (6, 0, 3) submitted to dispatcher
18:32:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:32:54 DISPATCHER: Trying to submit another job.
18:32:54 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:32:54 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:32:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:32:54 WORKER: start processing job (6, 0, 3)
18:32:54 WORKER: args: ()
18:32:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004746159478416626, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01403583692907333, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 72}, 'budget': 400.0, 'working_directory': '.'}
18:33:47 DISPATCHER: Starting worker discovery
18:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:47 DISPATCHER: Finished worker discovery
18:34:47 DISPATCHER: Starting worker discovery
18:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:47 DISPATCHER: Finished worker discovery
18:35:47 DISPATCHER: Starting worker discovery
18:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:47 DISPATCHER: Finished worker discovery
18:36:47 DISPATCHER: Starting worker discovery
18:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:47 DISPATCHER: Finished worker discovery
18:37:47 DISPATCHER: Starting worker discovery
18:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:47 DISPATCHER: Finished worker discovery
18:38:47 DISPATCHER: Starting worker discovery
18:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:47 DISPATCHER: Finished worker discovery
18:39:39 WORKER: done with job (6, 0, 3), trying to register it.
18:39:39 WORKER: registered result for job (6, 0, 3) with dispatcher
18:39:39 DISPATCHER: job (6, 0, 3) finished
18:39:39 DISPATCHER: register_result: lock acquired
18:39:39 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:39:39 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004746159478416626, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01403583692907333, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 72}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6111578920876923, 'info': {'data02': 0.6111578920876923, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004746159478416626, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01403583692907333, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 72}"}}
exception: None

18:39:39 job_callback for (6, 0, 3) started
18:39:39 DISPATCHER: Trying to submit another job.
18:39:39 job_callback for (6, 0, 3) got condition
18:39:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:39 HBMASTER: Trying to run another job!
18:39:39 job_callback for (6, 0, 3) finished
18:39:39 start sampling a new configuration.
18:39:40 best_vector: [1, 2, 0.39551471211969713, 0.358145143405879, 0.48119567442369204, 1, 0.4771640007419249, 0.011910719425369753, 2, 1, 2, 0, 0.9351605434663861, 0.3058846679873731, 0.39264819863928274, 0.5046098125913807], 5.737142925237137e-33, 1.7430278677581774, 0.0
18:39:40 done sampling a new configuration.
18:39:40 HBMASTER: schedule new run for iteration 6
18:39:40 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
18:39:40 HBMASTER: submitting job (6, 0, 4) to dispatcher
18:39:40 DISPATCHER: trying to submit job (6, 0, 4)
18:39:40 DISPATCHER: trying to notify the job_runner thread.
18:39:40 HBMASTER: job (6, 0, 4) submitted to dispatcher
18:39:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:40 DISPATCHER: Trying to submit another job.
18:39:40 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:39:40 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:39:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:40 WORKER: start processing job (6, 0, 4)
18:39:40 WORKER: args: ()
18:39:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006180582732897014, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.010363255444629602, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 30}, 'budget': 400.0, 'working_directory': '.'}
18:39:47 DISPATCHER: Starting worker discovery
18:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:47 DISPATCHER: Finished worker discovery
18:40:47 DISPATCHER: Starting worker discovery
18:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:47 DISPATCHER: Finished worker discovery
18:41:47 DISPATCHER: Starting worker discovery
18:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:47 DISPATCHER: Finished worker discovery
18:42:47 DISPATCHER: Starting worker discovery
18:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:47 DISPATCHER: Finished worker discovery
18:43:47 DISPATCHER: Starting worker discovery
18:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:47 DISPATCHER: Finished worker discovery
18:44:47 DISPATCHER: Starting worker discovery
18:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:47 DISPATCHER: Finished worker discovery
18:45:47 DISPATCHER: Starting worker discovery
18:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:47 DISPATCHER: Finished worker discovery
18:46:26 WORKER: done with job (6, 0, 4), trying to register it.
18:46:26 WORKER: registered result for job (6, 0, 4) with dispatcher
18:46:26 DISPATCHER: job (6, 0, 4) finished
18:46:26 DISPATCHER: register_result: lock acquired
18:46:26 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:46:26 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006180582732897014, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.010363255444629602, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6389925213948433, 'info': {'data02': 0.6389925213948433, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006180582732897014, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.010363255444629602, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 30}"}}
exception: None

18:46:26 job_callback for (6, 0, 4) started
18:46:26 job_callback for (6, 0, 4) got condition
18:46:26 DISPATCHER: Trying to submit another job.
18:46:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:26 HBMASTER: Trying to run another job!
18:46:26 job_callback for (6, 0, 4) finished
18:46:26 start sampling a new configuration.
18:46:26 best_vector: [0, 1, 0.35727324712288555, 0.5198599222583054, 0.6195100087761862, 0, 0.47089335899439805, 0.4293605088401, 1, 1, 0, 0, 0.1251927419209869, 0.6818937720928095, 0.7284389430310084, 0.5039526549220789], 7.895132699359448e-33, 1.2666031567539486, 0.0
18:46:26 done sampling a new configuration.
18:46:26 HBMASTER: schedule new run for iteration 6
18:46:26 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
18:46:26 HBMASTER: submitting job (6, 0, 5) to dispatcher
18:46:26 DISPATCHER: trying to submit job (6, 0, 5)
18:46:26 DISPATCHER: trying to notify the job_runner thread.
18:46:26 HBMASTER: job (6, 0, 5) submitted to dispatcher
18:46:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:26 DISPATCHER: Trying to submit another job.
18:46:26 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:46:26 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:46:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:26 WORKER: start processing job (6, 0, 5)
18:46:26 WORKER: args: ()
18:46:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0051825857222319955, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.03619185980629565, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 66, 'num_filters_4': 72}, 'budget': 400.0, 'working_directory': '.'}
18:46:47 DISPATCHER: Starting worker discovery
18:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:47 DISPATCHER: Finished worker discovery
18:47:47 DISPATCHER: Starting worker discovery
18:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:47 DISPATCHER: Finished worker discovery
18:48:47 DISPATCHER: Starting worker discovery
18:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:47 DISPATCHER: Finished worker discovery
18:49:47 DISPATCHER: Starting worker discovery
18:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:47 DISPATCHER: Finished worker discovery
18:50:47 DISPATCHER: Starting worker discovery
18:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:47 DISPATCHER: Finished worker discovery
18:51:47 DISPATCHER: Starting worker discovery
18:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:47 DISPATCHER: Finished worker discovery
18:52:47 DISPATCHER: Starting worker discovery
18:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:47 DISPATCHER: Finished worker discovery
18:53:14 WORKER: done with job (6, 0, 5), trying to register it.
18:53:14 WORKER: registered result for job (6, 0, 5) with dispatcher
18:53:14 DISPATCHER: job (6, 0, 5) finished
18:53:14 DISPATCHER: register_result: lock acquired
18:53:14 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:53:14 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0051825857222319955, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.03619185980629565, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 66, 'num_filters_4': 72}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0051825857222319955, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.03619185980629565, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 66, 'num_filters_4': 72}"}}
exception: None

18:53:14 job_callback for (6, 0, 5) started
18:53:14 job_callback for (6, 0, 5) got condition
18:53:14 DISPATCHER: Trying to submit another job.
18:53:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:14 HBMASTER: Trying to run another job!
18:53:14 job_callback for (6, 0, 5) finished
18:53:14 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
18:53:14 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
18:53:14 HBMASTER: schedule new run for iteration 6
18:53:14 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
18:53:14 HBMASTER: submitting job (6, 0, 3) to dispatcher
18:53:14 DISPATCHER: trying to submit job (6, 0, 3)
18:53:14 DISPATCHER: trying to notify the job_runner thread.
18:53:14 HBMASTER: job (6, 0, 3) submitted to dispatcher
18:53:14 DISPATCHER: Trying to submit another job.
18:53:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:14 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:53:14 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:53:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:14 WORKER: start processing job (6, 0, 3)
18:53:14 WORKER: args: ()
18:53:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004746159478416626, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01403583692907333, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 72}, 'budget': 1200.0, 'working_directory': '.'}
18:53:47 DISPATCHER: Starting worker discovery
18:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:47 DISPATCHER: Finished worker discovery
18:54:47 DISPATCHER: Starting worker discovery
18:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:47 DISPATCHER: Finished worker discovery
18:55:47 DISPATCHER: Starting worker discovery
18:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:47 DISPATCHER: Finished worker discovery
18:56:47 DISPATCHER: Starting worker discovery
18:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:47 DISPATCHER: Finished worker discovery
18:57:47 DISPATCHER: Starting worker discovery
18:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:47 DISPATCHER: Finished worker discovery
18:58:47 DISPATCHER: Starting worker discovery
18:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:47 DISPATCHER: Finished worker discovery
18:59:47 DISPATCHER: Starting worker discovery
18:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:47 DISPATCHER: Finished worker discovery
19:00:47 DISPATCHER: Starting worker discovery
19:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:47 DISPATCHER: Finished worker discovery
19:01:47 DISPATCHER: Starting worker discovery
19:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:47 DISPATCHER: Finished worker discovery
19:02:47 DISPATCHER: Starting worker discovery
19:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:47 DISPATCHER: Finished worker discovery
19:03:47 DISPATCHER: Starting worker discovery
19:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:47 DISPATCHER: Finished worker discovery
19:04:47 DISPATCHER: Starting worker discovery
19:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:47 DISPATCHER: Finished worker discovery
19:05:47 DISPATCHER: Starting worker discovery
19:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:47 DISPATCHER: Finished worker discovery
19:06:47 DISPATCHER: Starting worker discovery
19:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:47 DISPATCHER: Finished worker discovery
19:07:47 DISPATCHER: Starting worker discovery
19:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:47 DISPATCHER: Finished worker discovery
19:08:47 DISPATCHER: Starting worker discovery
19:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:47 DISPATCHER: Finished worker discovery
19:09:47 DISPATCHER: Starting worker discovery
19:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:47 DISPATCHER: Finished worker discovery
19:10:47 DISPATCHER: Starting worker discovery
19:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:47 DISPATCHER: Finished worker discovery
19:11:47 DISPATCHER: Starting worker discovery
19:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:47 DISPATCHER: Finished worker discovery
19:12:47 DISPATCHER: Starting worker discovery
19:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:47 DISPATCHER: Finished worker discovery
19:13:24 WORKER: done with job (6, 0, 3), trying to register it.
19:13:24 WORKER: registered result for job (6, 0, 3) with dispatcher
19:13:24 DISPATCHER: job (6, 0, 3) finished
19:13:24 DISPATCHER: register_result: lock acquired
19:13:24 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:13:24 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004746159478416626, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01403583692907333, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 72}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4427726275742243, 'info': {'data02': 0.4427726275742243, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004746159478416626, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01403583692907333, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 72}"}}
exception: None

19:13:24 job_callback for (6, 0, 3) started
19:13:24 job_callback for (6, 0, 3) got condition
19:13:24 DISPATCHER: Trying to submit another job.
19:13:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:13:24 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:13:24 HBMASTER: Trying to run another job!
19:13:24 job_callback for (6, 0, 3) finished
19:13:24 HBMASTER: schedule new run for iteration 6
19:13:24 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
19:13:24 HBMASTER: submitting job (6, 0, 4) to dispatcher
19:13:24 DISPATCHER: trying to submit job (6, 0, 4)
19:13:24 DISPATCHER: trying to notify the job_runner thread.
19:13:24 HBMASTER: job (6, 0, 4) submitted to dispatcher
19:13:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:13:24 DISPATCHER: Trying to submit another job.
19:13:24 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:13:24 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:13:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:13:24 WORKER: start processing job (6, 0, 4)
19:13:24 WORKER: args: ()
19:13:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006180582732897014, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.010363255444629602, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 30}, 'budget': 1200.0, 'working_directory': '.'}
19:13:47 DISPATCHER: Starting worker discovery
19:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:47 DISPATCHER: Finished worker discovery
19:14:47 DISPATCHER: Starting worker discovery
19:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:47 DISPATCHER: Finished worker discovery
19:15:47 DISPATCHER: Starting worker discovery
19:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:47 DISPATCHER: Finished worker discovery
19:16:47 DISPATCHER: Starting worker discovery
19:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:47 DISPATCHER: Finished worker discovery
19:17:47 DISPATCHER: Starting worker discovery
19:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:47 DISPATCHER: Finished worker discovery
19:18:47 DISPATCHER: Starting worker discovery
19:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:47 DISPATCHER: Finished worker discovery
19:19:47 DISPATCHER: Starting worker discovery
19:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:47 DISPATCHER: Finished worker discovery
19:20:47 DISPATCHER: Starting worker discovery
19:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:47 DISPATCHER: Finished worker discovery
19:21:47 DISPATCHER: Starting worker discovery
19:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:47 DISPATCHER: Finished worker discovery
19:22:47 DISPATCHER: Starting worker discovery
19:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:47 DISPATCHER: Finished worker discovery
19:23:47 DISPATCHER: Starting worker discovery
19:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:47 DISPATCHER: Finished worker discovery
19:24:47 DISPATCHER: Starting worker discovery
19:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:47 DISPATCHER: Finished worker discovery
19:25:47 DISPATCHER: Starting worker discovery
19:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:47 DISPATCHER: Finished worker discovery
19:26:47 DISPATCHER: Starting worker discovery
19:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:47 DISPATCHER: Finished worker discovery
19:27:47 DISPATCHER: Starting worker discovery
19:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:47 DISPATCHER: Finished worker discovery
19:28:47 DISPATCHER: Starting worker discovery
19:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:47 DISPATCHER: Finished worker discovery
19:29:47 DISPATCHER: Starting worker discovery
19:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:47 DISPATCHER: Finished worker discovery
19:30:47 DISPATCHER: Starting worker discovery
19:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:47 DISPATCHER: Finished worker discovery
19:31:47 DISPATCHER: Starting worker discovery
19:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:47 DISPATCHER: Finished worker discovery
19:32:47 DISPATCHER: Starting worker discovery
19:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:47 DISPATCHER: Finished worker discovery
19:33:36 WORKER: done with job (6, 0, 4), trying to register it.
19:33:36 WORKER: registered result for job (6, 0, 4) with dispatcher
19:33:36 DISPATCHER: job (6, 0, 4) finished
19:33:36 DISPATCHER: register_result: lock acquired
19:33:36 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:33:36 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006180582732897014, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.010363255444629602, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 30}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6082860463116622, 'info': {'data02': 0.6082860463116622, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006180582732897014, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.010363255444629602, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 30}"}}
exception: None

19:33:36 job_callback for (6, 0, 4) started
19:33:36 DISPATCHER: Trying to submit another job.
19:33:36 job_callback for (6, 0, 4) got condition
19:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:33:36 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:33:36 HBMASTER: Trying to run another job!
19:33:36 job_callback for (6, 0, 4) finished
19:33:36 start sampling a new configuration.
19:33:37 best_vector: [1, 1, 0.1899885495811855, 0.43984541011409145, 0.3218576117371088, 1, 0.746394030542352, 0.592060757086025, 1, 1, 0, 0, 0.903880404413884, 0.6878324559161321, 0.8758864942110383, 0.504555859701729], 3.909283777803652e-33, 2.558013326322984, 0.0
19:33:37 done sampling a new configuration.
19:33:37 HBMASTER: schedule new run for iteration 7
19:33:37 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
19:33:37 HBMASTER: submitting job (7, 0, 0) to dispatcher
19:33:37 DISPATCHER: trying to submit job (7, 0, 0)
19:33:37 DISPATCHER: trying to notify the job_runner thread.
19:33:37 HBMASTER: job (7, 0, 0) submitted to dispatcher
19:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:33:37 DISPATCHER: Trying to submit another job.
19:33:37 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:33:37 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:33:37 WORKER: start processing job (7, 0, 0)
19:33:37 WORKER: args: ()
19:33:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0023987064291903708, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.05892353644369666, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 1200.0, 'working_directory': '.'}
19:33:47 DISPATCHER: Starting worker discovery
19:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:47 DISPATCHER: Finished worker discovery
19:34:47 DISPATCHER: Starting worker discovery
19:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:47 DISPATCHER: Finished worker discovery
19:35:47 DISPATCHER: Starting worker discovery
19:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:47 DISPATCHER: Finished worker discovery
19:36:47 DISPATCHER: Starting worker discovery
19:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:47 DISPATCHER: Finished worker discovery
19:37:47 DISPATCHER: Starting worker discovery
19:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:47 DISPATCHER: Finished worker discovery
19:38:47 DISPATCHER: Starting worker discovery
19:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:47 DISPATCHER: Finished worker discovery
19:39:47 DISPATCHER: Starting worker discovery
19:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:47 DISPATCHER: Finished worker discovery
19:40:47 DISPATCHER: Starting worker discovery
19:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:47 DISPATCHER: Finished worker discovery
19:41:47 DISPATCHER: Starting worker discovery
19:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:47 DISPATCHER: Finished worker discovery
19:42:47 DISPATCHER: Starting worker discovery
19:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:47 DISPATCHER: Finished worker discovery
19:43:47 DISPATCHER: Starting worker discovery
19:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:47 DISPATCHER: Finished worker discovery
19:44:47 DISPATCHER: Starting worker discovery
19:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:47 DISPATCHER: Finished worker discovery
19:45:47 DISPATCHER: Starting worker discovery
19:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:47 DISPATCHER: Finished worker discovery
19:46:47 DISPATCHER: Starting worker discovery
19:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:47 DISPATCHER: Finished worker discovery
19:47:47 DISPATCHER: Starting worker discovery
19:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:47 DISPATCHER: Finished worker discovery
19:48:47 DISPATCHER: Starting worker discovery
19:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:47 DISPATCHER: Finished worker discovery
19:49:47 DISPATCHER: Starting worker discovery
19:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:47 DISPATCHER: Finished worker discovery
19:50:47 DISPATCHER: Starting worker discovery
19:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:47 DISPATCHER: Finished worker discovery
19:51:47 DISPATCHER: Starting worker discovery
19:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:47 DISPATCHER: Finished worker discovery
19:52:47 DISPATCHER: Starting worker discovery
19:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:47 DISPATCHER: Finished worker discovery
19:53:46 WORKER: done with job (7, 0, 0), trying to register it.
19:53:46 WORKER: registered result for job (7, 0, 0) with dispatcher
19:53:46 DISPATCHER: job (7, 0, 0) finished
19:53:46 DISPATCHER: register_result: lock acquired
19:53:46 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:53:46 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0023987064291903708, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.05892353644369666, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5519299109969243, 'info': {'data02': 0.5519299109969243, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0023987064291903708, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.05892353644369666, 'kernel_size_2': 5, 'num_filters_2': 105}"}}
exception: None

19:53:46 job_callback for (7, 0, 0) started
19:53:46 DISPATCHER: Trying to submit another job.
19:53:46 job_callback for (7, 0, 0) got condition
19:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:53:46 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:53:46 HBMASTER: Trying to run another job!
19:53:46 job_callback for (7, 0, 0) finished
19:53:46 start sampling a new configuration.
19:53:47 best_vector: [2, 1, 0.3744644942310307, 0.5766681041410995, 0.5931651375994499, 1, 0.8609450398584035, 0.34479970756450984, 2, 0, 0, 0, 0.33397627563239257, 0.9981736645497532, 0.7185729399013808, 0.5034738013744692], 1.0746756223303174e-32, 0.9305133374400069, 0.0
19:53:47 done sampling a new configuration.
19:53:47 HBMASTER: schedule new run for iteration 7
19:53:47 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
19:53:47 HBMASTER: submitting job (7, 0, 1) to dispatcher
19:53:47 DISPATCHER: trying to submit job (7, 0, 1)
19:53:47 DISPATCHER: trying to notify the job_runner thread.
19:53:47 HBMASTER: job (7, 0, 1) submitted to dispatcher
19:53:47 DISPATCHER: Trying to submit another job.
19:53:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:53:47 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:53:47 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:53:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:53:47 WORKER: start processing job (7, 0, 1)
19:53:47 WORKER: args: ()
19:53:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005609562465164862, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.02809278283831805, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 31, 'num_filters_3': 128}, 'budget': 1200.0, 'working_directory': '.'}
19:53:47 DISPATCHER: Starting worker discovery
19:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:47 DISPATCHER: Finished worker discovery
19:54:47 DISPATCHER: Starting worker discovery
19:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:47 DISPATCHER: Finished worker discovery
19:55:47 DISPATCHER: Starting worker discovery
19:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:47 DISPATCHER: Finished worker discovery
19:56:47 DISPATCHER: Starting worker discovery
19:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:47 DISPATCHER: Finished worker discovery
19:57:47 DISPATCHER: Starting worker discovery
19:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:47 DISPATCHER: Finished worker discovery
19:58:47 DISPATCHER: Starting worker discovery
19:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:47 DISPATCHER: Finished worker discovery
19:59:47 DISPATCHER: Starting worker discovery
19:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:47 DISPATCHER: Finished worker discovery
20:00:47 DISPATCHER: Starting worker discovery
20:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:47 DISPATCHER: Finished worker discovery
20:01:47 DISPATCHER: Starting worker discovery
20:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:47 DISPATCHER: Finished worker discovery
20:02:47 DISPATCHER: Starting worker discovery
20:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:47 DISPATCHER: Finished worker discovery
20:03:47 DISPATCHER: Starting worker discovery
20:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:47 DISPATCHER: Finished worker discovery
20:04:47 DISPATCHER: Starting worker discovery
20:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:47 DISPATCHER: Finished worker discovery
20:05:47 DISPATCHER: Starting worker discovery
20:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:47 DISPATCHER: Finished worker discovery
20:06:47 DISPATCHER: Starting worker discovery
20:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:47 DISPATCHER: Finished worker discovery
20:07:47 DISPATCHER: Starting worker discovery
20:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:47 DISPATCHER: Finished worker discovery
20:08:47 DISPATCHER: Starting worker discovery
20:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:47 DISPATCHER: Finished worker discovery
20:09:47 DISPATCHER: Starting worker discovery
20:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:47 DISPATCHER: Finished worker discovery
20:10:47 DISPATCHER: Starting worker discovery
20:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:47 DISPATCHER: Finished worker discovery
20:11:47 DISPATCHER: Starting worker discovery
20:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:47 DISPATCHER: Finished worker discovery
20:12:47 DISPATCHER: Starting worker discovery
20:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:47 DISPATCHER: Finished worker discovery
20:13:47 DISPATCHER: Starting worker discovery
20:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:47 DISPATCHER: Finished worker discovery
20:13:55 WORKER: done with job (7, 0, 1), trying to register it.
20:13:55 WORKER: registered result for job (7, 0, 1) with dispatcher
20:13:55 DISPATCHER: job (7, 0, 1) finished
20:13:55 DISPATCHER: register_result: lock acquired
20:13:55 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:13:55 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005609562465164862, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.02809278283831805, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 31, 'num_filters_3': 128}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6557312159857998, 'info': {'data02': 0.6557312159857998, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005609562465164862, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.02809278283831805, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 31, 'num_filters_3': 128}"}}
exception: None

20:13:55 job_callback for (7, 0, 1) started
20:13:55 DISPATCHER: Trying to submit another job.
20:13:55 job_callback for (7, 0, 1) got condition
20:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:13:55 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:13:55 HBMASTER: Trying to run another job!
20:13:55 job_callback for (7, 0, 1) finished
20:13:55 start sampling a new configuration.
20:13:55 done sampling a new configuration.
20:13:55 HBMASTER: schedule new run for iteration 7
20:13:55 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
20:13:55 HBMASTER: submitting job (7, 0, 2) to dispatcher
20:13:55 DISPATCHER: trying to submit job (7, 0, 2)
20:13:55 DISPATCHER: trying to notify the job_runner thread.
20:13:55 HBMASTER: job (7, 0, 2) submitted to dispatcher
20:13:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:13:55 DISPATCHER: Trying to submit another job.
20:13:55 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:13:55 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:13:55 WORKER: start processing job (7, 0, 2)
20:13:55 WORKER: args: ()
20:13:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0020781047758957356, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.011754582711801938}, 'budget': 1200.0, 'working_directory': '.'}
20:14:47 DISPATCHER: Starting worker discovery
20:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:47 DISPATCHER: Finished worker discovery
20:15:47 DISPATCHER: Starting worker discovery
20:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:47 DISPATCHER: Finished worker discovery
20:16:47 DISPATCHER: Starting worker discovery
20:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:47 DISPATCHER: Finished worker discovery
20:17:47 DISPATCHER: Starting worker discovery
20:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:47 DISPATCHER: Finished worker discovery
20:18:47 DISPATCHER: Starting worker discovery
20:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:47 DISPATCHER: Finished worker discovery
20:19:47 DISPATCHER: Starting worker discovery
20:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:47 DISPATCHER: Finished worker discovery
20:20:47 DISPATCHER: Starting worker discovery
20:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:47 DISPATCHER: Finished worker discovery
20:21:47 DISPATCHER: Starting worker discovery
20:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:47 DISPATCHER: Finished worker discovery
20:22:47 DISPATCHER: Starting worker discovery
20:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:47 DISPATCHER: Finished worker discovery
20:23:47 DISPATCHER: Starting worker discovery
20:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:47 DISPATCHER: Finished worker discovery
20:24:47 DISPATCHER: Starting worker discovery
20:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:47 DISPATCHER: Finished worker discovery
20:25:47 DISPATCHER: Starting worker discovery
20:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:47 DISPATCHER: Finished worker discovery
20:26:47 DISPATCHER: Starting worker discovery
20:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:47 DISPATCHER: Finished worker discovery
20:27:47 DISPATCHER: Starting worker discovery
20:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:47 DISPATCHER: Finished worker discovery
20:28:47 DISPATCHER: Starting worker discovery
20:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:47 DISPATCHER: Finished worker discovery
20:29:47 DISPATCHER: Starting worker discovery
20:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:47 DISPATCHER: Finished worker discovery
20:30:47 DISPATCHER: Starting worker discovery
20:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:47 DISPATCHER: Finished worker discovery
20:31:47 DISPATCHER: Starting worker discovery
20:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:47 DISPATCHER: Finished worker discovery
20:32:47 DISPATCHER: Starting worker discovery
20:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:47 DISPATCHER: Finished worker discovery
20:33:47 DISPATCHER: Starting worker discovery
20:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:47 DISPATCHER: Finished worker discovery
20:34:03 WORKER: done with job (7, 0, 2), trying to register it.
20:34:03 WORKER: registered result for job (7, 0, 2) with dispatcher
20:34:03 DISPATCHER: job (7, 0, 2) finished
20:34:03 DISPATCHER: register_result: lock acquired
20:34:03 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:34:03 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0020781047758957356, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.011754582711801938}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.43077518976032836, 'info': {'data02': 0.43077518976032836, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0020781047758957356, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.011754582711801938}"}}
exception: None

20:34:03 job_callback for (7, 0, 2) started
20:34:03 DISPATCHER: Trying to submit another job.
20:34:03 job_callback for (7, 0, 2) got condition
20:34:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:34:03 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:34:03 HBMASTER: Trying to run another job!
20:34:03 job_callback for (7, 0, 2) finished
20:34:03 start sampling a new configuration.
20:34:03 best_vector: [2, 2, 0.1647379307425235, 0.263267616065603, 0.4152836274188668, 1, 0.7623782384643399, 0.36534252993431227, 1, 2, 2, 0, 0.8146148973335053, 0.06362085964950097, 0.7090185238879806, 0.5023493006519588], 2.8430035444289667e-32, 0.3517406800141207, 0.0
20:34:03 done sampling a new configuration.
20:34:03 HBMASTER: schedule new run for iteration 7
20:34:03 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
20:34:03 HBMASTER: submitting job (7, 0, 3) to dispatcher
20:34:03 DISPATCHER: trying to submit job (7, 0, 3)
20:34:03 DISPATCHER: trying to notify the job_runner thread.
20:34:03 HBMASTER: job (7, 0, 3) submitted to dispatcher
20:34:03 DISPATCHER: Trying to submit another job.
20:34:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:34:03 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:34:03 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:34:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:34:03 WORKER: start processing job (7, 0, 3)
20:34:03 WORKER: args: ()
20:34:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002135383396037156, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.029875940795545623, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 18}, 'budget': 1200.0, 'working_directory': '.'}
20:34:47 DISPATCHER: Starting worker discovery
20:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:48 DISPATCHER: Finished worker discovery
20:35:48 DISPATCHER: Starting worker discovery
20:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:48 DISPATCHER: Finished worker discovery
20:36:48 DISPATCHER: Starting worker discovery
20:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:48 DISPATCHER: Finished worker discovery
20:37:48 DISPATCHER: Starting worker discovery
20:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:48 DISPATCHER: Finished worker discovery
20:38:48 DISPATCHER: Starting worker discovery
20:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:48 DISPATCHER: Finished worker discovery
20:39:48 DISPATCHER: Starting worker discovery
20:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:48 DISPATCHER: Finished worker discovery
20:40:48 DISPATCHER: Starting worker discovery
20:40:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:48 DISPATCHER: Finished worker discovery
20:41:48 DISPATCHER: Starting worker discovery
20:41:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:48 DISPATCHER: Finished worker discovery
20:42:48 DISPATCHER: Starting worker discovery
20:42:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:48 DISPATCHER: Finished worker discovery
20:43:48 DISPATCHER: Starting worker discovery
20:43:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:48 DISPATCHER: Finished worker discovery
20:44:48 DISPATCHER: Starting worker discovery
20:44:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:48 DISPATCHER: Finished worker discovery
20:45:48 DISPATCHER: Starting worker discovery
20:45:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:48 DISPATCHER: Finished worker discovery
20:46:48 DISPATCHER: Starting worker discovery
20:46:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:48 DISPATCHER: Finished worker discovery
20:47:48 DISPATCHER: Starting worker discovery
20:47:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:48 DISPATCHER: Finished worker discovery
20:48:48 DISPATCHER: Starting worker discovery
20:48:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:48 DISPATCHER: Finished worker discovery
20:49:48 DISPATCHER: Starting worker discovery
20:49:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:48 DISPATCHER: Finished worker discovery
20:50:48 DISPATCHER: Starting worker discovery
20:50:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:48 DISPATCHER: Finished worker discovery
20:51:48 DISPATCHER: Starting worker discovery
20:51:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:48 DISPATCHER: Finished worker discovery
20:52:48 DISPATCHER: Starting worker discovery
20:52:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:48 DISPATCHER: Finished worker discovery
20:53:48 DISPATCHER: Starting worker discovery
20:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:48 DISPATCHER: Finished worker discovery
20:54:11 WORKER: done with job (7, 0, 3), trying to register it.
20:54:11 WORKER: registered result for job (7, 0, 3) with dispatcher
20:54:11 DISPATCHER: job (7, 0, 3) finished
20:54:11 DISPATCHER: register_result: lock acquired
20:54:11 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:54:11 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002135383396037156, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.029875940795545623, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 18}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6465223392646953, 'info': {'data02': 0.6465223392646953, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002135383396037156, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.029875940795545623, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 18}"}}
exception: None

20:54:11 job_callback for (7, 0, 3) started
20:54:11 job_callback for (7, 0, 3) got condition
20:54:11 DISPATCHER: Trying to submit another job.
20:54:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:54:11 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:54:11 HBMASTER: Trying to run another job!
20:54:11 job_callback for (7, 0, 3) finished
20:54:11 start sampling a new configuration.
20:54:11 best_vector: [0, 1, 0.3401496475172881, 0.3491286554518553, 0.13295438758769557, 0, 0.5107904913995255, 0.39132289530532144, 0, 2, 1, 0, 0.7153766450092445, 0.8947073049996954, 0.7918932163011765, 0.5038476828702343], 1.8646629676807126e-32, 0.5362899447956595, 0.0
20:54:11 done sampling a new configuration.
20:54:11 HBMASTER: schedule new run for iteration 8
20:54:11 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
20:54:11 HBMASTER: submitting job (8, 0, 0) to dispatcher
20:54:11 DISPATCHER: trying to submit job (8, 0, 0)
20:54:11 DISPATCHER: trying to notify the job_runner thread.
20:54:11 HBMASTER: job (8, 0, 0) submitted to dispatcher
20:54:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:54:11 DISPATCHER: Trying to submit another job.
20:54:11 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:54:11 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:54:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:54:11 WORKER: start processing job (8, 0, 0)
20:54:11 WORKER: args: ()
20:54:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004789600550286602, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.03229407315830843}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:54:48 DISPATCHER: Starting worker discovery
20:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:48 DISPATCHER: Finished worker discovery
20:55:00 WORKER: done with job (8, 0, 0), trying to register it.
20:55:00 WORKER: registered result for job (8, 0, 0) with dispatcher
20:55:00 DISPATCHER: job (8, 0, 0) finished
20:55:00 DISPATCHER: register_result: lock acquired
20:55:00 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:55:00 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004789600550286602, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.03229407315830843}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4435233614757373, 'info': {'data02': 0.4435233614757373, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004789600550286602, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.03229407315830843}"}}
exception: None

20:55:00 job_callback for (8, 0, 0) started
20:55:00 DISPATCHER: Trying to submit another job.
20:55:00 job_callback for (8, 0, 0) got condition
20:55:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:00 HBMASTER: Trying to run another job!
20:55:00 job_callback for (8, 0, 0) finished
20:55:00 start sampling a new configuration.
20:55:00 best_vector: [1, 1, 0.03209673999272347, 0.027827398721722962, 0.8967874257051748, 0, 0.911812343999522, 0.5381885504880365, 2, 2, 0, 0, 0.6286693356129642, 0.09650678589382383, 0.583386998339833, 0.5048909016102449], 7.518955209060024e-33, 1.3299720136582835, 0.0
20:55:00 done sampling a new configuration.
20:55:00 HBMASTER: schedule new run for iteration 8
20:55:00 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
20:55:00 HBMASTER: submitting job (8, 0, 1) to dispatcher
20:55:00 DISPATCHER: trying to submit job (8, 0, 1)
20:55:00 DISPATCHER: trying to notify the job_runner thread.
20:55:00 HBMASTER: job (8, 0, 1) submitted to dispatcher
20:55:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:00 DISPATCHER: Trying to submit another job.
20:55:00 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:55:00 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:55:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:00 WORKER: start processing job (8, 0, 1)
20:55:00 WORKER: args: ()
20:55:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011592937112639983, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.050141745414717054, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 19, 'num_filters_4': 53, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:55:48 DISPATCHER: Starting worker discovery
20:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:48 DISPATCHER: Finished worker discovery
20:55:49 WORKER: done with job (8, 0, 1), trying to register it.
20:55:49 WORKER: registered result for job (8, 0, 1) with dispatcher
20:55:49 DISPATCHER: job (8, 0, 1) finished
20:55:49 DISPATCHER: register_result: lock acquired
20:55:49 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:55:49 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011592937112639983, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.050141745414717054, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 19, 'num_filters_4': 53, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5163010432106793, 'info': {'data02': 0.5163010432106793, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011592937112639983, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.050141745414717054, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 19, 'num_filters_4': 53, 'num_filters_5': 45}"}}
exception: None

20:55:49 job_callback for (8, 0, 1) started
20:55:49 DISPATCHER: Trying to submit another job.
20:55:49 job_callback for (8, 0, 1) got condition
20:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:49 HBMASTER: Trying to run another job!
20:55:49 job_callback for (8, 0, 1) finished
20:55:49 start sampling a new configuration.
20:55:49 best_vector: [2, 2, 0.23581115587144172, 0.8684536777286731, 0.686295894373877, 0, 0.9944786843343094, 0.37705867063794724, 0, 2, 1, 0, 0.6664459685759374, 0.5626810572226555, 0.7252227005345784, 0.5034648106155561], 3.0452520022662743e-32, 0.3283800484346782, 0.0
20:55:49 done sampling a new configuration.
20:55:49 HBMASTER: schedule new run for iteration 8
20:55:49 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
20:55:49 HBMASTER: submitting job (8, 0, 2) to dispatcher
20:55:49 DISPATCHER: trying to submit job (8, 0, 2)
20:55:49 DISPATCHER: trying to notify the job_runner thread.
20:55:49 HBMASTER: job (8, 0, 2) submitted to dispatcher
20:55:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:49 DISPATCHER: Trying to submit another job.
20:55:49 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:55:49 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:49 WORKER: start processing job (8, 0, 2)
20:55:49 WORKER: args: ()
20:55:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0029622541170203857, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.03094315840818699, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 51, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:56:38 WORKER: done with job (8, 0, 2), trying to register it.
20:56:38 WORKER: registered result for job (8, 0, 2) with dispatcher
20:56:38 DISPATCHER: job (8, 0, 2) finished
20:56:38 DISPATCHER: register_result: lock acquired
20:56:38 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:56:38 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0029622541170203857, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.03094315840818699, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 51, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.586598551451725, 'info': {'data02': 0.586598551451725, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0029622541170203857, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.03094315840818699, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 51, 'num_filters_4': 72}"}}
exception: None

20:56:38 job_callback for (8, 0, 2) started
20:56:38 job_callback for (8, 0, 2) got condition
20:56:38 DISPATCHER: Trying to submit another job.
20:56:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:56:38 HBMASTER: Trying to run another job!
20:56:38 job_callback for (8, 0, 2) finished
20:56:38 start sampling a new configuration.
20:56:38 done sampling a new configuration.
20:56:38 HBMASTER: schedule new run for iteration 8
20:56:38 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
20:56:38 HBMASTER: submitting job (8, 0, 3) to dispatcher
20:56:38 DISPATCHER: trying to submit job (8, 0, 3)
20:56:38 DISPATCHER: trying to notify the job_runner thread.
20:56:38 HBMASTER: job (8, 0, 3) submitted to dispatcher
20:56:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:56:38 DISPATCHER: Trying to submit another job.
20:56:38 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:56:38 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:56:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:56:38 WORKER: start processing job (8, 0, 3)
20:56:38 WORKER: args: ()
20:56:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.054000719172368934, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.041972877886003596}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:56:48 DISPATCHER: Starting worker discovery
20:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:48 DISPATCHER: Finished worker discovery
20:57:27 WORKER: done with job (8, 0, 3), trying to register it.
20:57:27 WORKER: registered result for job (8, 0, 3) with dispatcher
20:57:27 DISPATCHER: job (8, 0, 3) finished
20:57:27 DISPATCHER: register_result: lock acquired
20:57:27 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:57:27 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.054000719172368934, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.041972877886003596}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4745030324074334, 'info': {'data02': 0.4745030324074334, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.054000719172368934, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.041972877886003596}"}}
exception: None

20:57:27 job_callback for (8, 0, 3) started
20:57:27 DISPATCHER: Trying to submit another job.
20:57:27 job_callback for (8, 0, 3) got condition
20:57:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:57:27 HBMASTER: Trying to run another job!
20:57:27 job_callback for (8, 0, 3) finished
20:57:27 start sampling a new configuration.
20:57:27 best_vector: [2, 0, 0.3099599956829999, 0.8412321303479205, 0.8243846290077496, 1, 0.7672256395964958, 0.21757309700424826, 0, 1, 1, 0, 0.2939573060951314, 0.886642626951109, 0.851197760302224, 0.5029536598140212], 5.550537794311642e-33, 1.8016272243472158, 0.0
20:57:27 done sampling a new configuration.
20:57:27 HBMASTER: schedule new run for iteration 8
20:57:27 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
20:57:27 HBMASTER: submitting job (8, 0, 4) to dispatcher
20:57:27 DISPATCHER: trying to submit job (8, 0, 4)
20:57:27 DISPATCHER: trying to notify the job_runner thread.
20:57:27 HBMASTER: job (8, 0, 4) submitted to dispatcher
20:57:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:57:27 DISPATCHER: Trying to submit another job.
20:57:27 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:57:27 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:57:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:57:27 WORKER: start processing job (8, 0, 4)
20:57:27 WORKER: args: ()
20:57:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004167925920782361, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.019189741541746668, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 101, 'num_filters_4': 94, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:57:48 DISPATCHER: Starting worker discovery
20:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:48 DISPATCHER: Finished worker discovery
20:58:17 WORKER: done with job (8, 0, 4), trying to register it.
20:58:17 WORKER: registered result for job (8, 0, 4) with dispatcher
20:58:17 DISPATCHER: job (8, 0, 4) finished
20:58:17 DISPATCHER: register_result: lock acquired
20:58:17 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:58:17 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004167925920782361, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.019189741541746668, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 101, 'num_filters_4': 94, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6206027874145028, 'info': {'data02': 0.6206027874145028, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004167925920782361, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.019189741541746668, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 101, 'num_filters_4': 94, 'num_filters_5': 45}"}}
exception: None

20:58:17 job_callback for (8, 0, 4) started
20:58:17 job_callback for (8, 0, 4) got condition
20:58:17 DISPATCHER: Trying to submit another job.
20:58:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:17 HBMASTER: Trying to run another job!
20:58:17 job_callback for (8, 0, 4) finished
20:58:17 start sampling a new configuration.
20:58:17 done sampling a new configuration.
20:58:17 HBMASTER: schedule new run for iteration 8
20:58:17 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
20:58:17 HBMASTER: submitting job (8, 0, 5) to dispatcher
20:58:17 DISPATCHER: trying to submit job (8, 0, 5)
20:58:17 DISPATCHER: trying to notify the job_runner thread.
20:58:17 HBMASTER: job (8, 0, 5) submitted to dispatcher
20:58:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:17 DISPATCHER: Trying to submit another job.
20:58:17 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:58:17 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:58:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:17 WORKER: start processing job (8, 0, 5)
20:58:17 WORKER: args: ()
20:58:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004856681341646934, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05881248999820555, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:58:48 DISPATCHER: Starting worker discovery
20:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:48 DISPATCHER: Finished worker discovery
20:59:06 WORKER: done with job (8, 0, 5), trying to register it.
20:59:06 WORKER: registered result for job (8, 0, 5) with dispatcher
20:59:06 DISPATCHER: job (8, 0, 5) finished
20:59:06 DISPATCHER: register_result: lock acquired
20:59:06 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:59:06 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004856681341646934, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05881248999820555, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5271326031370234, 'info': {'data02': 0.5271326031370234, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004856681341646934, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05881248999820555, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 52}"}}
exception: None

20:59:06 job_callback for (8, 0, 5) started
20:59:06 DISPATCHER: Trying to submit another job.
20:59:06 job_callback for (8, 0, 5) got condition
20:59:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:59:06 HBMASTER: Trying to run another job!
20:59:06 job_callback for (8, 0, 5) finished
20:59:06 start sampling a new configuration.
20:59:06 best_vector: [2, 1, 0.17961692159399636, 0.9678534803120926, 0.6865044755828595, 1, 0.6086839624250713, 0.1795661313377514, 2, 0, 2, 0, 0.1395710915669648, 0.5129145311785495, 0.905830855411678, 0.5042179392278421], 8.509537342236413e-33, 1.1751520203531858, 0.0
20:59:06 done sampling a new configuration.
20:59:06 HBMASTER: schedule new run for iteration 8
20:59:06 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
20:59:06 HBMASTER: submitting job (8, 0, 6) to dispatcher
20:59:06 DISPATCHER: trying to submit job (8, 0, 6)
20:59:06 DISPATCHER: trying to notify the job_runner thread.
20:59:06 HBMASTER: job (8, 0, 6) submitted to dispatcher
20:59:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:59:06 DISPATCHER: Trying to submit another job.
20:59:06 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:59:06 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:59:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:59:06 WORKER: start processing job (8, 0, 6)
20:59:06 WORKER: args: ()
20:59:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:59:48 DISPATCHER: Starting worker discovery
20:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:48 DISPATCHER: Finished worker discovery
20:59:54 WORKER: done with job (8, 0, 6), trying to register it.
20:59:54 WORKER: registered result for job (8, 0, 6) with dispatcher
20:59:54 DISPATCHER: job (8, 0, 6) finished
20:59:54 DISPATCHER: register_result: lock acquired
20:59:54 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:59:54 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7431931038892707, 'info': {'data02': 0.7431931038892707, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}"}}
exception: None

20:59:54 job_callback for (8, 0, 6) started
20:59:54 DISPATCHER: Trying to submit another job.
20:59:54 job_callback for (8, 0, 6) got condition
20:59:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:59:54 HBMASTER: Trying to run another job!
20:59:54 job_callback for (8, 0, 6) finished
20:59:54 start sampling a new configuration.
20:59:54 done sampling a new configuration.
20:59:54 HBMASTER: schedule new run for iteration 8
20:59:54 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
20:59:54 HBMASTER: submitting job (8, 0, 7) to dispatcher
20:59:54 DISPATCHER: trying to submit job (8, 0, 7)
20:59:54 DISPATCHER: trying to notify the job_runner thread.
20:59:54 HBMASTER: job (8, 0, 7) submitted to dispatcher
20:59:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:59:54 DISPATCHER: Trying to submit another job.
20:59:54 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:59:54 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:59:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:59:54 WORKER: start processing job (8, 0, 7)
20:59:54 WORKER: args: ()
20:59:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.015341817490657312, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.047817906738692156}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:00:43 WORKER: done with job (8, 0, 7), trying to register it.
21:00:43 WORKER: registered result for job (8, 0, 7) with dispatcher
21:00:43 DISPATCHER: job (8, 0, 7) finished
21:00:43 DISPATCHER: register_result: lock acquired
21:00:43 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:00:43 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.015341817490657312, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.047817906738692156}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5859339722640138, 'info': {'data02': 0.5859339722640138, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.015341817490657312, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.047817906738692156}"}}
exception: None

21:00:43 job_callback for (8, 0, 7) started
21:00:43 DISPATCHER: Trying to submit another job.
21:00:43 job_callback for (8, 0, 7) got condition
21:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:00:43 HBMASTER: Trying to run another job!
21:00:43 job_callback for (8, 0, 7) finished
21:00:43 start sampling a new configuration.
21:00:43 done sampling a new configuration.
21:00:43 HBMASTER: schedule new run for iteration 8
21:00:43 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
21:00:43 HBMASTER: submitting job (8, 0, 8) to dispatcher
21:00:43 DISPATCHER: trying to submit job (8, 0, 8)
21:00:43 DISPATCHER: trying to notify the job_runner thread.
21:00:43 HBMASTER: job (8, 0, 8) submitted to dispatcher
21:00:43 DISPATCHER: Trying to submit another job.
21:00:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:00:43 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:00:43 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:00:43 WORKER: start processing job (8, 0, 8)
21:00:43 WORKER: args: ()
21:00:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.023329175245916448, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.016617873400798115, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 62, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:00:48 DISPATCHER: Starting worker discovery
21:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:48 DISPATCHER: Finished worker discovery
21:01:31 WORKER: done with job (8, 0, 8), trying to register it.
21:01:31 WORKER: registered result for job (8, 0, 8) with dispatcher
21:01:31 DISPATCHER: job (8, 0, 8) finished
21:01:31 DISPATCHER: register_result: lock acquired
21:01:31 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:01:31 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.023329175245916448, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.016617873400798115, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 62, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20449437060848175, 'info': {'data02': 0.20449437060848175, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.023329175245916448, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.016617873400798115, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 62, 'num_filters_3': 17}"}}
exception: None

21:01:31 job_callback for (8, 0, 8) started
21:01:31 DISPATCHER: Trying to submit another job.
21:01:31 job_callback for (8, 0, 8) got condition
21:01:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:01:32 HBMASTER: Trying to run another job!
21:01:32 job_callback for (8, 0, 8) finished
21:01:32 start sampling a new configuration.
21:01:32 best_vector: [2, 1, 0.40520113720387807, 0.9935090361156884, 0.7651993993529353, 1, 0.6242922105407638, 0.11251945634314736, 1, 1, 1, 0, 0.36212787857275, 0.5898292100893049, 0.980196697302878, 0.5035175020635889], 3.766732346100949e-33, 2.654820964476354, 0.0
21:01:32 done sampling a new configuration.
21:01:32 HBMASTER: schedule new run for iteration 8
21:01:32 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
21:01:32 HBMASTER: submitting job (8, 0, 9) to dispatcher
21:01:32 DISPATCHER: trying to submit job (8, 0, 9)
21:01:32 DISPATCHER: trying to notify the job_runner thread.
21:01:32 HBMASTER: job (8, 0, 9) submitted to dispatcher
21:01:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:01:32 DISPATCHER: Trying to submit another job.
21:01:32 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:01:32 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:01:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:01:32 WORKER: start processing job (8, 0, 9)
21:01:32 WORKER: args: ()
21:01:32 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:01:48 DISPATCHER: Starting worker discovery
21:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:48 DISPATCHER: Finished worker discovery
21:02:21 WORKER: done with job (8, 0, 9), trying to register it.
21:02:21 WORKER: registered result for job (8, 0, 9) with dispatcher
21:02:21 DISPATCHER: job (8, 0, 9) finished
21:02:21 DISPATCHER: register_result: lock acquired
21:02:21 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:02:21 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6959853664973541, 'info': {'data02': 0.6959853664973541, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}"}}
exception: None

21:02:21 job_callback for (8, 0, 9) started
21:02:21 job_callback for (8, 0, 9) got condition
21:02:21 DISPATCHER: Trying to submit another job.
21:02:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:02:21 HBMASTER: Trying to run another job!
21:02:21 job_callback for (8, 0, 9) finished
21:02:21 start sampling a new configuration.
21:02:21 done sampling a new configuration.
21:02:21 HBMASTER: schedule new run for iteration 8
21:02:21 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
21:02:21 HBMASTER: submitting job (8, 0, 10) to dispatcher
21:02:21 DISPATCHER: trying to submit job (8, 0, 10)
21:02:21 DISPATCHER: trying to notify the job_runner thread.
21:02:21 HBMASTER: job (8, 0, 10) submitted to dispatcher
21:02:21 DISPATCHER: Trying to submit another job.
21:02:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:02:21 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:02:21 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:02:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:02:21 WORKER: start processing job (8, 0, 10)
21:02:21 WORKER: args: ()
21:02:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.015614079301230542, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.0262036967933322, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 46, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:02:48 DISPATCHER: Starting worker discovery
21:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:48 DISPATCHER: Finished worker discovery
21:03:09 WORKER: done with job (8, 0, 10), trying to register it.
21:03:09 WORKER: registered result for job (8, 0, 10) with dispatcher
21:03:09 DISPATCHER: job (8, 0, 10) finished
21:03:09 DISPATCHER: register_result: lock acquired
21:03:09 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:03:09 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.015614079301230542, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.0262036967933322, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 46, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.015614079301230542, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.0262036967933322, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 46, 'num_filters_4': 54}"}}
exception: None

21:03:09 job_callback for (8, 0, 10) started
21:03:09 DISPATCHER: Trying to submit another job.
21:03:09 job_callback for (8, 0, 10) got condition
21:03:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:09 HBMASTER: Trying to run another job!
21:03:09 job_callback for (8, 0, 10) finished
21:03:09 start sampling a new configuration.
21:03:09 done sampling a new configuration.
21:03:09 HBMASTER: schedule new run for iteration 8
21:03:09 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
21:03:09 HBMASTER: submitting job (8, 0, 11) to dispatcher
21:03:09 DISPATCHER: trying to submit job (8, 0, 11)
21:03:09 DISPATCHER: trying to notify the job_runner thread.
21:03:09 HBMASTER: job (8, 0, 11) submitted to dispatcher
21:03:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:09 DISPATCHER: Trying to submit another job.
21:03:09 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:03:09 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:03:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:09 WORKER: start processing job (8, 0, 11)
21:03:09 WORKER: args: ()
21:03:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010138048287127473, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.028699727830833997}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:03:48 DISPATCHER: Starting worker discovery
21:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:48 DISPATCHER: Finished worker discovery
21:03:58 WORKER: done with job (8, 0, 11), trying to register it.
21:03:58 WORKER: registered result for job (8, 0, 11) with dispatcher
21:03:58 DISPATCHER: job (8, 0, 11) finished
21:03:58 DISPATCHER: register_result: lock acquired
21:03:58 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:03:58 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010138048287127473, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.028699727830833997}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4612251237434906, 'info': {'data02': 0.4612251237434906, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010138048287127473, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.028699727830833997}"}}
exception: None

21:03:58 job_callback for (8, 0, 11) started
21:03:58 job_callback for (8, 0, 11) got condition
21:03:58 DISPATCHER: Trying to submit another job.
21:03:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:58 HBMASTER: Trying to run another job!
21:03:58 job_callback for (8, 0, 11) finished
21:03:58 start sampling a new configuration.
21:03:58 best_vector: [1, 1, 0.30742896476090387, 0.1909266692442807, 0.49605993879043386, 0, 0.5215750190699131, 0.618494444925516, 0, 1, 0, 0, 0.5832538473818397, 0.21775217934021285, 0.976578395905902, 0.5040298248117736], 1.5191893756588296e-32, 0.6582457829303395, 0.0
21:03:58 done sampling a new configuration.
21:03:58 HBMASTER: schedule new run for iteration 8
21:03:58 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
21:03:58 HBMASTER: submitting job (8, 0, 12) to dispatcher
21:03:58 DISPATCHER: trying to submit job (8, 0, 12)
21:03:58 DISPATCHER: trying to notify the job_runner thread.
21:03:58 HBMASTER: job (8, 0, 12) submitted to dispatcher
21:03:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:58 DISPATCHER: Trying to submit another job.
21:03:58 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:03:58 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:03:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:58 WORKER: start processing job (8, 0, 12)
21:03:58 WORKER: args: ()
21:03:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00411962731945111, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.06377931124919853, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:04:47 WORKER: done with job (8, 0, 12), trying to register it.
21:04:47 WORKER: registered result for job (8, 0, 12) with dispatcher
21:04:47 DISPATCHER: job (8, 0, 12) finished
21:04:47 DISPATCHER: register_result: lock acquired
21:04:47 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:04:47 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00411962731945111, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.06377931124919853, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6416141277586622, 'info': {'data02': 0.6416141277586622, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00411962731945111, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.06377931124919853, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 25}"}}
exception: None

21:04:47 job_callback for (8, 0, 12) started
21:04:47 job_callback for (8, 0, 12) got condition
21:04:47 DISPATCHER: Trying to submit another job.
21:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:04:47 HBMASTER: Trying to run another job!
21:04:47 job_callback for (8, 0, 12) finished
21:04:47 start sampling a new configuration.
21:04:47 best_vector: [0, 1, 0.16270357485162693, 0.5486195165842155, 0.6327472381876245, 1, 0.46984165009591183, 0.0392641102330159, 0, 2, 1, 0, 0.8253535635536632, 0.229091035069589, 0.09684065234043826, 0.5038953773184979], 5.119973846815899e-33, 1.9531349766989492, 0.0
21:04:47 done sampling a new configuration.
21:04:47 HBMASTER: schedule new run for iteration 8
21:04:47 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
21:04:47 HBMASTER: submitting job (8, 0, 13) to dispatcher
21:04:47 DISPATCHER: trying to submit job (8, 0, 13)
21:04:47 DISPATCHER: trying to notify the job_runner thread.
21:04:47 HBMASTER: job (8, 0, 13) submitted to dispatcher
21:04:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:04:47 DISPATCHER: Trying to submit another job.
21:04:47 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:04:47 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:04:47 WORKER: start processing job (8, 0, 13)
21:04:47 WORKER: args: ()
21:04:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:04:48 DISPATCHER: Starting worker discovery
21:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:48 DISPATCHER: Finished worker discovery
21:05:35 WORKER: done with job (8, 0, 13), trying to register it.
21:05:35 WORKER: registered result for job (8, 0, 13) with dispatcher
21:05:35 DISPATCHER: job (8, 0, 13) finished
21:05:35 DISPATCHER: register_result: lock acquired
21:05:35 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:05:35 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6558735349639264, 'info': {'data02': 0.6558735349639264, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}"}}
exception: None

21:05:35 job_callback for (8, 0, 13) started
21:05:35 DISPATCHER: Trying to submit another job.
21:05:35 job_callback for (8, 0, 13) got condition
21:05:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:05:35 HBMASTER: Trying to run another job!
21:05:35 job_callback for (8, 0, 13) finished
21:05:35 start sampling a new configuration.
21:05:36 best_vector: [1, 0, 0.18891104585915833, 0.8686228029433489, 0.535091373639641, 1, 0.7700451688329573, 0.06382543684634007, 2, 1, 1, 0, 0.7554858860321072, 0.5487104319875973, 0.674077042237156, 0.5046167341910996], 9.059122798873104e-33, 1.1038596365250657, 0.0
21:05:36 done sampling a new configuration.
21:05:36 HBMASTER: schedule new run for iteration 8
21:05:36 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
21:05:36 HBMASTER: submitting job (8, 0, 14) to dispatcher
21:05:36 DISPATCHER: trying to submit job (8, 0, 14)
21:05:36 DISPATCHER: trying to notify the job_runner thread.
21:05:36 HBMASTER: job (8, 0, 14) submitted to dispatcher
21:05:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:05:36 DISPATCHER: Trying to submit another job.
21:05:36 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:05:36 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:05:36 WORKER: start processing job (8, 0, 14)
21:05:36 WORKER: args: ()
21:05:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002386833318835504, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.012107063153941574, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 77, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:05:48 DISPATCHER: Starting worker discovery
21:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:48 DISPATCHER: Finished worker discovery
21:06:24 WORKER: done with job (8, 0, 14), trying to register it.
21:06:24 WORKER: registered result for job (8, 0, 14) with dispatcher
21:06:24 DISPATCHER: job (8, 0, 14) finished
21:06:24 DISPATCHER: register_result: lock acquired
21:06:24 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:06:24 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002386833318835504, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.012107063153941574, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 77, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5104526722387687, 'info': {'data02': 0.5104526722387687, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002386833318835504, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.012107063153941574, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 77, 'num_filters_3': 49}"}}
exception: None

21:06:24 job_callback for (8, 0, 14) started
21:06:24 DISPATCHER: Trying to submit another job.
21:06:24 job_callback for (8, 0, 14) got condition
21:06:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:06:24 HBMASTER: Trying to run another job!
21:06:24 job_callback for (8, 0, 14) finished
21:06:24 start sampling a new configuration.
21:06:24 best_vector: [3, 0, 0.2683292007230487, 0.731676435445102, 0.6820763092871147, 0, 0.41093628223262935, 0.03352818049488415, 1, 1, 0, 0, 0.4967965429120889, 0.5185666185268859, 0.8612157821462982, 0.5035866267290383], 3.701418943544375e-33, 2.701666618268366, 0.0
21:06:24 done sampling a new configuration.
21:06:24 HBMASTER: schedule new run for iteration 8
21:06:24 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
21:06:24 HBMASTER: submitting job (8, 0, 15) to dispatcher
21:06:24 DISPATCHER: trying to submit job (8, 0, 15)
21:06:24 DISPATCHER: trying to notify the job_runner thread.
21:06:24 HBMASTER: job (8, 0, 15) submitted to dispatcher
21:06:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:06:24 DISPATCHER: Trying to submit another job.
21:06:24 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:06:24 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:06:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:06:24 WORKER: start processing job (8, 0, 15)
21:06:24 WORKER: args: ()
21:06:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003440791854646498, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.011056589061138407, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 44, 'num_filters_3': 46, 'num_filters_4': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:06:48 DISPATCHER: Starting worker discovery
21:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:48 DISPATCHER: Finished worker discovery
21:07:13 WORKER: done with job (8, 0, 15), trying to register it.
21:07:13 WORKER: registered result for job (8, 0, 15) with dispatcher
21:07:13 DISPATCHER: job (8, 0, 15) finished
21:07:13 DISPATCHER: register_result: lock acquired
21:07:13 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:07:13 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003440791854646498, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.011056589061138407, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 44, 'num_filters_3': 46, 'num_filters_4': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4995987611698778, 'info': {'data02': 0.4995987611698778, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003440791854646498, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.011056589061138407, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 44, 'num_filters_3': 46, 'num_filters_4': 96}"}}
exception: None

21:07:13 job_callback for (8, 0, 15) started
21:07:13 job_callback for (8, 0, 15) got condition
21:07:13 DISPATCHER: Trying to submit another job.
21:07:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:07:13 HBMASTER: Trying to run another job!
21:07:13 job_callback for (8, 0, 15) finished
21:07:13 start sampling a new configuration.
21:07:13 best_vector: [0, 0, 0.2909744705894837, 0.8906544970110291, 0.6157916839784727, 0, 0.40944710118910893, 0.028999889115760735, 2, 0, 0, 0, 0.3324372416218041, 0.6910509803476662, 0.8846711914377664, 0.5055245964366067], 8.6260696079363e-33, 1.159276525058369, 0.0
21:07:13 done sampling a new configuration.
21:07:13 HBMASTER: schedule new run for iteration 8
21:07:13 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
21:07:13 HBMASTER: submitting job (8, 0, 16) to dispatcher
21:07:13 DISPATCHER: trying to submit job (8, 0, 16)
21:07:13 DISPATCHER: trying to notify the job_runner thread.
21:07:13 HBMASTER: job (8, 0, 16) submitted to dispatcher
21:07:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:07:13 DISPATCHER: Trying to submit another job.
21:07:13 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:07:13 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:07:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:07:13 WORKER: start processing job (8, 0, 16)
21:07:13 WORKER: args: ()
21:07:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003818993693304715, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.010907613119345747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 67, 'num_filters_4': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:07:48 DISPATCHER: Starting worker discovery
21:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:48 DISPATCHER: Finished worker discovery
21:08:03 WORKER: done with job (8, 0, 16), trying to register it.
21:08:03 WORKER: registered result for job (8, 0, 16) with dispatcher
21:08:03 DISPATCHER: job (8, 0, 16) finished
21:08:03 DISPATCHER: register_result: lock acquired
21:08:03 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:08:03 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003818993693304715, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.010907613119345747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 67, 'num_filters_4': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6336217668769665, 'info': {'data02': 0.6336217668769665, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003818993693304715, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.010907613119345747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 67, 'num_filters_4': 101}"}}
exception: None

21:08:03 job_callback for (8, 0, 16) started
21:08:03 job_callback for (8, 0, 16) got condition
21:08:03 DISPATCHER: Trying to submit another job.
21:08:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:08:03 HBMASTER: Trying to run another job!
21:08:03 job_callback for (8, 0, 16) finished
21:08:03 start sampling a new configuration.
21:08:03 best_vector: [0, 2, 0.4116594543495721, 0.2238232973708155, 0.386265932222428, 0, 0.7847019130028818, 0.21594372155483027, 1, 0, 0, 0, 0.8318810293392696, 0.0894006496669775, 0.8351474948561283, 0.5057211192474546], 1.4077706415436954e-32, 0.710342985206345, 0.0
21:08:03 done sampling a new configuration.
21:08:03 HBMASTER: schedule new run for iteration 8
21:08:03 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
21:08:03 HBMASTER: submitting job (8, 0, 17) to dispatcher
21:08:03 DISPATCHER: trying to submit job (8, 0, 17)
21:08:03 DISPATCHER: trying to notify the job_runner thread.
21:08:03 HBMASTER: job (8, 0, 17) submitted to dispatcher
21:08:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:08:03 DISPATCHER: Trying to submit another job.
21:08:03 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:08:03 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:08:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:08:03 WORKER: start processing job (8, 0, 17)
21:08:03 WORKER: args: ()
21:08:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006657618552787971, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.019096301335169912, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:08:48 DISPATCHER: Starting worker discovery
21:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:48 DISPATCHER: Finished worker discovery
21:08:52 WORKER: done with job (8, 0, 17), trying to register it.
21:08:52 WORKER: registered result for job (8, 0, 17) with dispatcher
21:08:52 DISPATCHER: job (8, 0, 17) finished
21:08:52 DISPATCHER: register_result: lock acquired
21:08:52 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:08:52 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006657618552787971, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.019096301335169912, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5438152583370425, 'info': {'data02': 0.5438152583370425, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006657618552787971, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.019096301335169912, 'kernel_size_2': 5, 'num_filters_2': 90}"}}
exception: None

21:08:52 job_callback for (8, 0, 17) started
21:08:52 job_callback for (8, 0, 17) got condition
21:08:52 DISPATCHER: Trying to submit another job.
21:08:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:08:52 HBMASTER: Trying to run another job!
21:08:52 job_callback for (8, 0, 17) finished
21:08:52 start sampling a new configuration.
21:08:52 done sampling a new configuration.
21:08:52 HBMASTER: schedule new run for iteration 8
21:08:52 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
21:08:52 HBMASTER: submitting job (8, 0, 18) to dispatcher
21:08:52 DISPATCHER: trying to submit job (8, 0, 18)
21:08:52 DISPATCHER: trying to notify the job_runner thread.
21:08:52 HBMASTER: job (8, 0, 18) submitted to dispatcher
21:08:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:08:52 DISPATCHER: Trying to submit another job.
21:08:52 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:08:52 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:08:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:08:52 WORKER: start processing job (8, 0, 18)
21:08:52 WORKER: args: ()
21:08:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.023143563510606688, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.028909154721075418, 'kernel_size_2': 7, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:09:41 WORKER: done with job (8, 0, 18), trying to register it.
21:09:41 WORKER: registered result for job (8, 0, 18) with dispatcher
21:09:41 DISPATCHER: job (8, 0, 18) finished
21:09:41 DISPATCHER: register_result: lock acquired
21:09:41 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:09:41 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.023143563510606688, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.028909154721075418, 'kernel_size_2': 7, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44060881915857497, 'info': {'data02': 0.44060881915857497, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.023143563510606688, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.028909154721075418, 'kernel_size_2': 7, 'num_filters_2': 65}"}}
exception: None

21:09:41 job_callback for (8, 0, 18) started
21:09:41 DISPATCHER: Trying to submit another job.
21:09:41 job_callback for (8, 0, 18) got condition
21:09:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:09:41 HBMASTER: Trying to run another job!
21:09:41 job_callback for (8, 0, 18) finished
21:09:41 start sampling a new configuration.
21:09:41 best_vector: [2, 2, 0.18062015754572175, 0.0871971836499208, 0.9356248743244782, 1, 0.3805655519648398, 0.5652961618920662, 1, 2, 0, 0, 0.8726549716791674, 0.016483195622669977, 0.3752857229992794, 0.5028743522363037], 1.2817775874119178e-32, 0.7801665513742795, 0.0
21:09:41 done sampling a new configuration.
21:09:41 HBMASTER: schedule new run for iteration 8
21:09:41 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
21:09:41 HBMASTER: submitting job (8, 0, 19) to dispatcher
21:09:41 DISPATCHER: trying to submit job (8, 0, 19)
21:09:41 DISPATCHER: trying to notify the job_runner thread.
21:09:41 HBMASTER: job (8, 0, 19) submitted to dispatcher
21:09:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:09:41 DISPATCHER: Trying to submit another job.
21:09:41 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:09:41 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:09:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:09:41 WORKER: start processing job (8, 0, 19)
21:09:41 WORKER: args: ()
21:09:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002297419564256637, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.054383513609982004, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 16, 'num_filters_4': 34, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:09:48 DISPATCHER: Starting worker discovery
21:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:48 DISPATCHER: Finished worker discovery
21:10:29 WORKER: done with job (8, 0, 19), trying to register it.
21:10:29 WORKER: registered result for job (8, 0, 19) with dispatcher
21:10:29 DISPATCHER: job (8, 0, 19) finished
21:10:29 DISPATCHER: register_result: lock acquired
21:10:29 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:10:29 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002297419564256637, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.054383513609982004, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 16, 'num_filters_4': 34, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47241681447453365, 'info': {'data02': 0.47241681447453365, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002297419564256637, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.054383513609982004, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 16, 'num_filters_4': 34, 'num_filters_5': 45}"}}
exception: None

21:10:29 job_callback for (8, 0, 19) started
21:10:29 DISPATCHER: Trying to submit another job.
21:10:29 job_callback for (8, 0, 19) got condition
21:10:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:10:29 HBMASTER: Trying to run another job!
21:10:29 job_callback for (8, 0, 19) finished
21:10:29 start sampling a new configuration.
21:10:29 best_vector: [2, 0, 0.02820025728058012, 0.9041414486713972, 0.739154745251356, 1, 0.9928937583633297, 0.11831889280385158, 2, 1, 2, 0, 0.8782393955601538, 0.2938964918267509, 0.2378906278617342, 0.504261196799064], 4.7745042263268e-33, 2.0944582989076888, 0.0
21:10:29 done sampling a new configuration.
21:10:29 HBMASTER: schedule new run for iteration 8
21:10:29 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
21:10:29 HBMASTER: submitting job (8, 0, 20) to dispatcher
21:10:29 DISPATCHER: trying to submit job (8, 0, 20)
21:10:29 DISPATCHER: trying to notify the job_runner thread.
21:10:29 HBMASTER: job (8, 0, 20) submitted to dispatcher
21:10:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:10:29 DISPATCHER: Trying to submit another job.
21:10:29 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:10:29 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:10:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:10:29 WORKER: start processing job (8, 0, 20)
21:10:29 WORKER: args: ()
21:10:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011386769110775655, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.01425398930462972, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 99, 'num_filters_3': 29, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:10:48 DISPATCHER: Starting worker discovery
21:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:48 DISPATCHER: Finished worker discovery
21:11:19 WORKER: done with job (8, 0, 20), trying to register it.
21:11:19 WORKER: registered result for job (8, 0, 20) with dispatcher
21:11:19 DISPATCHER: job (8, 0, 20) finished
21:11:19 DISPATCHER: register_result: lock acquired
21:11:19 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:11:19 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011386769110775655, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.01425398930462972, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 99, 'num_filters_3': 29, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5925625220944963, 'info': {'data02': 0.5925625220944963, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011386769110775655, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.01425398930462972, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 99, 'num_filters_3': 29, 'num_filters_4': 26}"}}
exception: None

21:11:19 job_callback for (8, 0, 20) started
21:11:19 DISPATCHER: Trying to submit another job.
21:11:19 job_callback for (8, 0, 20) got condition
21:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:11:19 HBMASTER: Trying to run another job!
21:11:19 job_callback for (8, 0, 20) finished
21:11:19 start sampling a new configuration.
21:11:19 best_vector: [3, 1, 0.16751340425034683, 0.6875283670325083, 0.6245018966320887, 1, 0.7417870978971176, 0.20825591586361974, 1, 1, 2, 0, 0.33331607527783, 0.5493629877748331, 0.9443992572749766, 0.503721023069976], 2.3096806635289153e-33, 4.3296028571851135, 0.0
21:11:19 done sampling a new configuration.
21:11:19 HBMASTER: schedule new run for iteration 8
21:11:19 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
21:11:19 HBMASTER: submitting job (8, 0, 21) to dispatcher
21:11:19 DISPATCHER: trying to submit job (8, 0, 21)
21:11:19 DISPATCHER: trying to notify the job_runner thread.
21:11:19 HBMASTER: job (8, 0, 21) submitted to dispatcher
21:11:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:11:19 DISPATCHER: Trying to submit another job.
21:11:19 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:11:19 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:11:19 WORKER: start processing job (8, 0, 21)
21:11:19 WORKER: args: ()
21:11:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002162852029983702, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.018661527679965064, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 31, 'num_filters_3': 50, 'num_filters_4': 114}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:11:48 DISPATCHER: Starting worker discovery
21:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:48 DISPATCHER: Finished worker discovery
21:12:08 WORKER: done with job (8, 0, 21), trying to register it.
21:12:08 WORKER: registered result for job (8, 0, 21) with dispatcher
21:12:08 DISPATCHER: job (8, 0, 21) finished
21:12:08 DISPATCHER: register_result: lock acquired
21:12:08 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:12:08 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002162852029983702, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.018661527679965064, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 31, 'num_filters_3': 50, 'num_filters_4': 114}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5503640505583134, 'info': {'data02': 0.5503640505583134, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002162852029983702, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.018661527679965064, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 31, 'num_filters_3': 50, 'num_filters_4': 114}"}}
exception: None

21:12:08 job_callback for (8, 0, 21) started
21:12:08 job_callback for (8, 0, 21) got condition
21:12:08 DISPATCHER: Trying to submit another job.
21:12:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:12:08 HBMASTER: Trying to run another job!
21:12:08 job_callback for (8, 0, 21) finished
21:12:08 start sampling a new configuration.
21:12:08 best_vector: [0, 2, 0.04150500257722761, 0.6444733340584832, 0.6631606538078165, 1, 0.9689164531873271, 0.0318198792459489, 0, 0, 1, 0, 0.9492302849048966, 0.6528213798843236, 0.8881626093495741, 0.5031319187685424], 6.102864892191433e-33, 1.6385746983838558, 0.0
21:12:08 done sampling a new configuration.
21:12:08 HBMASTER: schedule new run for iteration 8
21:12:08 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
21:12:08 HBMASTER: submitting job (8, 0, 22) to dispatcher
21:12:08 DISPATCHER: trying to submit job (8, 0, 22)
21:12:08 DISPATCHER: trying to notify the job_runner thread.
21:12:08 HBMASTER: job (8, 0, 22) submitted to dispatcher
21:12:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:12:08 DISPATCHER: Trying to submit another job.
21:12:08 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:12:08 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:12:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:12:08 WORKER: start processing job (8, 0, 22)
21:12:08 WORKER: args: ()
21:12:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001210626023291969, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.0110001502543531, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 62, 'num_filters_4': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:12:48 DISPATCHER: Starting worker discovery
21:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:48 DISPATCHER: Finished worker discovery
21:12:57 WORKER: done with job (8, 0, 22), trying to register it.
21:12:57 WORKER: registered result for job (8, 0, 22) with dispatcher
21:12:57 DISPATCHER: job (8, 0, 22) finished
21:12:57 DISPATCHER: register_result: lock acquired
21:12:57 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:12:57 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001210626023291969, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.0110001502543531, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 62, 'num_filters_4': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6143392256329456, 'info': {'data02': 0.6143392256329456, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001210626023291969, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.0110001502543531, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 62, 'num_filters_4': 101}"}}
exception: None

21:12:57 job_callback for (8, 0, 22) started
21:12:57 job_callback for (8, 0, 22) got condition
21:12:57 DISPATCHER: Trying to submit another job.
21:12:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:12:57 HBMASTER: Trying to run another job!
21:12:57 job_callback for (8, 0, 22) finished
21:12:57 start sampling a new configuration.
21:12:57 done sampling a new configuration.
21:12:57 HBMASTER: schedule new run for iteration 8
21:12:57 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
21:12:57 HBMASTER: submitting job (8, 0, 23) to dispatcher
21:12:57 DISPATCHER: trying to submit job (8, 0, 23)
21:12:57 DISPATCHER: trying to notify the job_runner thread.
21:12:57 HBMASTER: job (8, 0, 23) submitted to dispatcher
21:12:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:12:57 DISPATCHER: Trying to submit another job.
21:12:57 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:12:57 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:12:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:12:57 WORKER: start processing job (8, 0, 23)
21:12:57 WORKER: args: ()
21:12:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0029527753787671356, 'num_filters_1': 63, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.18049541126961186, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 44, 'num_filters_3': 67, 'num_filters_4': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:13:47 WORKER: done with job (8, 0, 23), trying to register it.
21:13:47 WORKER: registered result for job (8, 0, 23) with dispatcher
21:13:47 DISPATCHER: job (8, 0, 23) finished
21:13:47 DISPATCHER: register_result: lock acquired
21:13:47 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:13:47 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0029527753787671356, 'num_filters_1': 63, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.18049541126961186, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 44, 'num_filters_3': 67, 'num_filters_4': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4889276301761157, 'info': {'data02': 0.4889276301761157, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0029527753787671356, 'num_filters_1': 63, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.18049541126961186, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 44, 'num_filters_3': 67, 'num_filters_4': 53}"}}
exception: None

21:13:47 job_callback for (8, 0, 23) started
21:13:47 job_callback for (8, 0, 23) got condition
21:13:47 DISPATCHER: Trying to submit another job.
21:13:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:13:47 HBMASTER: Trying to run another job!
21:13:47 job_callback for (8, 0, 23) finished
21:13:47 start sampling a new configuration.
21:13:47 best_vector: [0, 1, 0.2546037526747092, 0.10322512831464549, 0.6180381997712173, 0, 0.26918333100183994, 0.5218045431115026, 2, 2, 2, 0, 0.5639387951972914, 0.3340974411107284, 0.7523704735469992, 0.5030777617508279], 8.916331090428448e-33, 1.1215375358520339, 0.0
21:13:47 done sampling a new configuration.
21:13:47 HBMASTER: schedule new run for iteration 8
21:13:47 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
21:13:47 HBMASTER: submitting job (8, 0, 24) to dispatcher
21:13:47 DISPATCHER: trying to submit job (8, 0, 24)
21:13:47 DISPATCHER: trying to notify the job_runner thread.
21:13:47 HBMASTER: job (8, 0, 24) submitted to dispatcher
21:13:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:13:47 DISPATCHER: Trying to submit another job.
21:13:47 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:13:47 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:13:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:13:47 WORKER: start processing job (8, 0, 24)
21:13:47 WORKER: args: ()
21:13:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0032300370606631375, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04774010418643766, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 51, 'num_filters_3': 31, 'num_filters_4': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:13:48 DISPATCHER: Starting worker discovery
21:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:48 DISPATCHER: Finished worker discovery
21:14:36 WORKER: done with job (8, 0, 24), trying to register it.
21:14:36 WORKER: registered result for job (8, 0, 24) with dispatcher
21:14:36 DISPATCHER: job (8, 0, 24) finished
21:14:36 DISPATCHER: register_result: lock acquired
21:14:36 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:14:36 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0032300370606631375, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04774010418643766, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 51, 'num_filters_3': 31, 'num_filters_4': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5150346651520161, 'info': {'data02': 0.5150346651520161, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0032300370606631375, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04774010418643766, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 51, 'num_filters_3': 31, 'num_filters_4': 76}"}}
exception: None

21:14:36 job_callback for (8, 0, 24) started
21:14:36 DISPATCHER: Trying to submit another job.
21:14:36 job_callback for (8, 0, 24) got condition
21:14:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:14:36 HBMASTER: Trying to run another job!
21:14:36 job_callback for (8, 0, 24) finished
21:14:36 start sampling a new configuration.
21:14:36 done sampling a new configuration.
21:14:36 HBMASTER: schedule new run for iteration 8
21:14:36 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
21:14:36 HBMASTER: submitting job (8, 0, 25) to dispatcher
21:14:36 DISPATCHER: trying to submit job (8, 0, 25)
21:14:36 DISPATCHER: trying to notify the job_runner thread.
21:14:36 HBMASTER: job (8, 0, 25) submitted to dispatcher
21:14:36 DISPATCHER: Trying to submit another job.
21:14:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:14:36 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:14:36 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:14:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:14:36 WORKER: start processing job (8, 0, 25)
21:14:36 WORKER: args: ()
21:14:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012601591447098414, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.08609544808675419, 'kernel_size_2': 3, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:14:48 DISPATCHER: Starting worker discovery
21:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:48 DISPATCHER: Finished worker discovery
21:15:24 WORKER: done with job (8, 0, 25), trying to register it.
21:15:24 WORKER: registered result for job (8, 0, 25) with dispatcher
21:15:24 DISPATCHER: job (8, 0, 25) finished
21:15:24 DISPATCHER: register_result: lock acquired
21:15:24 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:15:24 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012601591447098414, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.08609544808675419, 'kernel_size_2': 3, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41508895174994126, 'info': {'data02': 0.41508895174994126, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012601591447098414, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.08609544808675419, 'kernel_size_2': 3, 'num_filters_2': 35}"}}
exception: None

21:15:24 job_callback for (8, 0, 25) started
21:15:24 DISPATCHER: Trying to submit another job.
21:15:24 job_callback for (8, 0, 25) got condition
21:15:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:15:24 HBMASTER: Trying to run another job!
21:15:24 job_callback for (8, 0, 25) finished
21:15:24 start sampling a new configuration.
21:15:24 best_vector: [0, 2, 0.27229430161825474, 0.4131257435618179, 0.39277869570778573, 0, 0.9829602243208255, 0.3322352965680339, 0, 2, 1, 0, 0.8906288219743517, 0.5942223587568582, 0.9363829851983481, 0.5030374213473956], 1.655958120945337e-32, 0.6038800059926214, 0.0
21:15:24 done sampling a new configuration.
21:15:24 HBMASTER: schedule new run for iteration 8
21:15:24 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
21:15:24 HBMASTER: submitting job (8, 0, 26) to dispatcher
21:15:24 DISPATCHER: trying to submit job (8, 0, 26)
21:15:24 DISPATCHER: trying to notify the job_runner thread.
21:15:24 HBMASTER: job (8, 0, 26) submitted to dispatcher
21:15:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:15:24 DISPATCHER: Trying to submit another job.
21:15:24 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:15:24 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:15:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:15:24 WORKER: start processing job (8, 0, 26)
21:15:24 WORKER: args: ()
21:15:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0035041977242190243, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02705503414997854, 'kernel_size_2': 3, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:15:48 DISPATCHER: Starting worker discovery
21:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:48 DISPATCHER: Finished worker discovery
21:16:13 WORKER: done with job (8, 0, 26), trying to register it.
21:16:13 WORKER: registered result for job (8, 0, 26) with dispatcher
21:16:13 DISPATCHER: job (8, 0, 26) finished
21:16:13 DISPATCHER: register_result: lock acquired
21:16:13 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:16:13 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0035041977242190243, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02705503414997854, 'kernel_size_2': 3, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6958670629204771, 'info': {'data02': 0.6958670629204771, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0035041977242190243, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02705503414997854, 'kernel_size_2': 3, 'num_filters_2': 102}"}}
exception: None

21:16:13 job_callback for (8, 0, 26) started
21:16:13 job_callback for (8, 0, 26) got condition
21:16:13 DISPATCHER: Trying to submit another job.
21:16:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:16:13 HBMASTER: Trying to run another job!
21:16:13 job_callback for (8, 0, 26) finished
21:16:13 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
21:16:13 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
21:16:13 HBMASTER: schedule new run for iteration 8
21:16:13 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
21:16:13 HBMASTER: submitting job (8, 0, 4) to dispatcher
21:16:13 DISPATCHER: trying to submit job (8, 0, 4)
21:16:13 DISPATCHER: trying to notify the job_runner thread.
21:16:13 HBMASTER: job (8, 0, 4) submitted to dispatcher
21:16:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:16:13 DISPATCHER: Trying to submit another job.
21:16:13 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:16:13 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:16:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:16:13 WORKER: start processing job (8, 0, 4)
21:16:13 WORKER: args: ()
21:16:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004167925920782361, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.019189741541746668, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 101, 'num_filters_4': 94, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:16:48 DISPATCHER: Starting worker discovery
21:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:48 DISPATCHER: Finished worker discovery
21:17:48 DISPATCHER: Starting worker discovery
21:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:48 DISPATCHER: Finished worker discovery
21:18:31 WORKER: done with job (8, 0, 4), trying to register it.
21:18:31 WORKER: registered result for job (8, 0, 4) with dispatcher
21:18:31 DISPATCHER: job (8, 0, 4) finished
21:18:31 DISPATCHER: register_result: lock acquired
21:18:31 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:18:31 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004167925920782361, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.019189741541746668, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 101, 'num_filters_4': 94, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6299776242485324, 'info': {'data02': 0.6299776242485324, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004167925920782361, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.019189741541746668, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 101, 'num_filters_4': 94, 'num_filters_5': 45}"}}
exception: None

21:18:31 job_callback for (8, 0, 4) started
21:18:31 DISPATCHER: Trying to submit another job.
21:18:31 job_callback for (8, 0, 4) got condition
21:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:18:31 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.715210





21:18:31 HBMASTER: Trying to run another job!
21:18:31 job_callback for (8, 0, 4) finished
21:18:31 HBMASTER: schedule new run for iteration 8
21:18:31 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
21:18:31 HBMASTER: submitting job (8, 0, 6) to dispatcher
21:18:31 DISPATCHER: trying to submit job (8, 0, 6)
21:18:31 DISPATCHER: trying to notify the job_runner thread.
21:18:31 HBMASTER: job (8, 0, 6) submitted to dispatcher
21:18:31 DISPATCHER: Trying to submit another job.
21:18:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:18:31 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:18:31 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:18:31 WORKER: start processing job (8, 0, 6)
21:18:31 WORKER: args: ()
21:18:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:18:48 DISPATCHER: Starting worker discovery
21:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:48 DISPATCHER: Finished worker discovery
21:19:48 DISPATCHER: Starting worker discovery
21:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:48 DISPATCHER: Finished worker discovery
21:20:48 DISPATCHER: Starting worker discovery
21:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:48 DISPATCHER: Finished worker discovery
21:20:53 WORKER: done with job (8, 0, 6), trying to register it.
21:20:53 WORKER: registered result for job (8, 0, 6) with dispatcher
21:20:53 DISPATCHER: job (8, 0, 6) finished
21:20:53 DISPATCHER: register_result: lock acquired
21:20:53 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:20:53 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7269499669939681, 'info': {'data02': 0.7269499669939681, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}"}}
exception: None

21:20:53 job_callback for (8, 0, 6) started
21:20:53 DISPATCHER: Trying to submit another job.
21:20:53 job_callback for (8, 0, 6) got condition
21:20:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:20:53 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.726950





21:20:53 HBMASTER: Trying to run another job!
21:20:53 job_callback for (8, 0, 6) finished
21:20:53 HBMASTER: schedule new run for iteration 8
21:20:53 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
21:20:53 HBMASTER: submitting job (8, 0, 9) to dispatcher
21:20:53 DISPATCHER: trying to submit job (8, 0, 9)
21:20:53 DISPATCHER: trying to notify the job_runner thread.
21:20:53 HBMASTER: job (8, 0, 9) submitted to dispatcher
21:20:53 DISPATCHER: Trying to submit another job.
21:20:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:20:53 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:20:53 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:20:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:20:53 WORKER: start processing job (8, 0, 9)
21:20:53 WORKER: args: ()
21:20:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:21:48 DISPATCHER: Starting worker discovery
21:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:48 DISPATCHER: Finished worker discovery
21:22:48 DISPATCHER: Starting worker discovery
21:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:48 DISPATCHER: Finished worker discovery
21:23:12 WORKER: done with job (8, 0, 9), trying to register it.
21:23:12 WORKER: registered result for job (8, 0, 9) with dispatcher
21:23:12 DISPATCHER: job (8, 0, 9) finished
21:23:12 DISPATCHER: register_result: lock acquired
21:23:12 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:23:12 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7395679961215107, 'info': {'data02': 0.7395679961215107, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}"}}
exception: None

21:23:12 job_callback for (8, 0, 9) started
21:23:12 DISPATCHER: Trying to submit another job.
21:23:12 job_callback for (8, 0, 9) got condition
21:23:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:23:12 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.739568





21:23:12 HBMASTER: Trying to run another job!
21:23:12 job_callback for (8, 0, 9) finished
21:23:12 HBMASTER: schedule new run for iteration 8
21:23:12 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
21:23:12 HBMASTER: submitting job (8, 0, 12) to dispatcher
21:23:12 DISPATCHER: trying to submit job (8, 0, 12)
21:23:12 DISPATCHER: trying to notify the job_runner thread.
21:23:12 HBMASTER: job (8, 0, 12) submitted to dispatcher
21:23:12 DISPATCHER: Trying to submit another job.
21:23:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:23:12 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:23:12 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:23:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:23:12 WORKER: start processing job (8, 0, 12)
21:23:12 WORKER: args: ()
21:23:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00411962731945111, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.06377931124919853, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:23:48 DISPATCHER: Starting worker discovery
21:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:48 DISPATCHER: Finished worker discovery
21:24:48 DISPATCHER: Starting worker discovery
21:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:48 DISPATCHER: Finished worker discovery
21:25:30 WORKER: done with job (8, 0, 12), trying to register it.
21:25:30 WORKER: registered result for job (8, 0, 12) with dispatcher
21:25:30 DISPATCHER: job (8, 0, 12) finished
21:25:30 DISPATCHER: register_result: lock acquired
21:25:30 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:25:30 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00411962731945111, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.06377931124919853, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47896797945873787, 'info': {'data02': 0.47896797945873787, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00411962731945111, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.06377931124919853, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 25}"}}
exception: None

21:25:30 job_callback for (8, 0, 12) started
21:25:30 DISPATCHER: Trying to submit another job.
21:25:30 job_callback for (8, 0, 12) got condition
21:25:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:25:30 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.739568





21:25:30 HBMASTER: Trying to run another job!
21:25:30 job_callback for (8, 0, 12) finished
21:25:30 HBMASTER: schedule new run for iteration 8
21:25:30 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
21:25:30 HBMASTER: submitting job (8, 0, 13) to dispatcher
21:25:30 DISPATCHER: trying to submit job (8, 0, 13)
21:25:30 DISPATCHER: trying to notify the job_runner thread.
21:25:30 HBMASTER: job (8, 0, 13) submitted to dispatcher
21:25:30 DISPATCHER: Trying to submit another job.
21:25:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:25:30 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:25:30 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:25:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:25:30 WORKER: start processing job (8, 0, 13)
21:25:30 WORKER: args: ()
21:25:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:25:48 DISPATCHER: Starting worker discovery
21:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:48 DISPATCHER: Finished worker discovery
21:26:48 DISPATCHER: Starting worker discovery
21:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:48 DISPATCHER: Finished worker discovery
21:27:48 DISPATCHER: Starting worker discovery
21:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:48 DISPATCHER: Finished worker discovery
21:27:48 WORKER: done with job (8, 0, 13), trying to register it.
21:27:48 WORKER: registered result for job (8, 0, 13) with dispatcher
21:27:48 DISPATCHER: job (8, 0, 13) finished
21:27:48 DISPATCHER: register_result: lock acquired
21:27:48 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:27:48 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6617331458049838, 'info': {'data02': 0.6617331458049838, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}"}}
exception: None

21:27:48 job_callback for (8, 0, 13) started
21:27:48 DISPATCHER: Trying to submit another job.
21:27:48 job_callback for (8, 0, 13) got condition
21:27:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:27:48 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.739568





21:27:48 HBMASTER: Trying to run another job!
21:27:48 job_callback for (8, 0, 13) finished
21:27:48 HBMASTER: schedule new run for iteration 8
21:27:48 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
21:27:48 HBMASTER: submitting job (8, 0, 16) to dispatcher
21:27:48 DISPATCHER: trying to submit job (8, 0, 16)
21:27:48 DISPATCHER: trying to notify the job_runner thread.
21:27:48 HBMASTER: job (8, 0, 16) submitted to dispatcher
21:27:48 DISPATCHER: Trying to submit another job.
21:27:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:27:48 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:27:48 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:27:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:27:48 WORKER: start processing job (8, 0, 16)
21:27:48 WORKER: args: ()
21:27:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003818993693304715, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.010907613119345747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 67, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:28:48 DISPATCHER: Starting worker discovery
21:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:48 DISPATCHER: Finished worker discovery
21:29:48 DISPATCHER: Starting worker discovery
21:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:48 DISPATCHER: Finished worker discovery
21:30:07 WORKER: done with job (8, 0, 16), trying to register it.
21:30:07 WORKER: registered result for job (8, 0, 16) with dispatcher
21:30:07 DISPATCHER: job (8, 0, 16) finished
21:30:07 DISPATCHER: register_result: lock acquired
21:30:07 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:30:07 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003818993693304715, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.010907613119345747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 67, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6394346536033644, 'info': {'data02': 0.6394346536033644, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003818993693304715, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.010907613119345747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 67, 'num_filters_4': 101}"}}
exception: None

21:30:07 job_callback for (8, 0, 16) started
21:30:07 job_callback for (8, 0, 16) got condition
21:30:07 DISPATCHER: Trying to submit another job.
21:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:30:07 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.739568





21:30:07 HBMASTER: Trying to run another job!
21:30:07 job_callback for (8, 0, 16) finished
21:30:07 HBMASTER: schedule new run for iteration 8
21:30:07 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
21:30:07 HBMASTER: submitting job (8, 0, 20) to dispatcher
21:30:07 DISPATCHER: trying to submit job (8, 0, 20)
21:30:07 DISPATCHER: trying to notify the job_runner thread.
21:30:07 HBMASTER: job (8, 0, 20) submitted to dispatcher
21:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:30:07 DISPATCHER: Trying to submit another job.
21:30:07 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:30:07 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:30:07 WORKER: start processing job (8, 0, 20)
21:30:07 WORKER: args: ()
21:30:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011386769110775655, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.01425398930462972, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 99, 'num_filters_3': 29, 'num_filters_4': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:30:48 DISPATCHER: Starting worker discovery
21:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:48 DISPATCHER: Finished worker discovery
21:31:48 DISPATCHER: Starting worker discovery
21:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:48 DISPATCHER: Finished worker discovery
21:32:25 WORKER: done with job (8, 0, 20), trying to register it.
21:32:25 WORKER: registered result for job (8, 0, 20) with dispatcher
21:32:25 DISPATCHER: job (8, 0, 20) finished
21:32:25 DISPATCHER: register_result: lock acquired
21:32:25 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:32:25 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011386769110775655, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.01425398930462972, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 99, 'num_filters_3': 29, 'num_filters_4': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5550218045734047, 'info': {'data02': 0.5550218045734047, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011386769110775655, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.01425398930462972, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 99, 'num_filters_3': 29, 'num_filters_4': 26}"}}
exception: None

21:32:25 job_callback for (8, 0, 20) started
21:32:25 job_callback for (8, 0, 20) got condition
21:32:25 DISPATCHER: Trying to submit another job.
21:32:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:32:25 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.739568





21:32:25 HBMASTER: Trying to run another job!
21:32:25 job_callback for (8, 0, 20) finished
21:32:25 HBMASTER: schedule new run for iteration 8
21:32:25 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
21:32:25 HBMASTER: submitting job (8, 0, 22) to dispatcher
21:32:25 DISPATCHER: trying to submit job (8, 0, 22)
21:32:25 DISPATCHER: trying to notify the job_runner thread.
21:32:25 HBMASTER: job (8, 0, 22) submitted to dispatcher
21:32:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:32:25 DISPATCHER: Trying to submit another job.
21:32:25 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:32:25 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:32:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:32:25 WORKER: start processing job (8, 0, 22)
21:32:25 WORKER: args: ()
21:32:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001210626023291969, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.0110001502543531, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 62, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:32:48 DISPATCHER: Starting worker discovery
21:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:48 DISPATCHER: Finished worker discovery
21:33:48 DISPATCHER: Starting worker discovery
21:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:48 DISPATCHER: Finished worker discovery
21:34:44 WORKER: done with job (8, 0, 22), trying to register it.
21:34:44 WORKER: registered result for job (8, 0, 22) with dispatcher
21:34:44 DISPATCHER: job (8, 0, 22) finished
21:34:44 DISPATCHER: register_result: lock acquired
21:34:44 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:34:44 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001210626023291969, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.0110001502543531, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 62, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6332023549163054, 'info': {'data02': 0.6332023549163054, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001210626023291969, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.0110001502543531, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 62, 'num_filters_4': 101}"}}
exception: None

21:34:44 job_callback for (8, 0, 22) started
21:34:44 job_callback for (8, 0, 22) got condition
21:34:44 DISPATCHER: Trying to submit another job.
21:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:34:44 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.739568





21:34:44 HBMASTER: Trying to run another job!
21:34:44 job_callback for (8, 0, 22) finished
21:34:44 HBMASTER: schedule new run for iteration 8
21:34:44 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
21:34:44 HBMASTER: submitting job (8, 0, 26) to dispatcher
21:34:44 DISPATCHER: trying to submit job (8, 0, 26)
21:34:44 DISPATCHER: trying to notify the job_runner thread.
21:34:44 HBMASTER: job (8, 0, 26) submitted to dispatcher
21:34:44 DISPATCHER: Trying to submit another job.
21:34:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:34:44 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:34:44 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:34:44 WORKER: start processing job (8, 0, 26)
21:34:44 WORKER: args: ()
21:34:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0035041977242190243, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02705503414997854, 'kernel_size_2': 3, 'num_filters_2': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:34:48 DISPATCHER: Starting worker discovery
21:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:48 DISPATCHER: Finished worker discovery
21:35:48 DISPATCHER: Starting worker discovery
21:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:48 DISPATCHER: Finished worker discovery
21:36:48 DISPATCHER: Starting worker discovery
21:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:48 DISPATCHER: Finished worker discovery
21:37:02 WORKER: done with job (8, 0, 26), trying to register it.
21:37:02 WORKER: registered result for job (8, 0, 26) with dispatcher
21:37:02 DISPATCHER: job (8, 0, 26) finished
21:37:02 DISPATCHER: register_result: lock acquired
21:37:02 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:37:02 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0035041977242190243, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02705503414997854, 'kernel_size_2': 3, 'num_filters_2': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5484300263646176, 'info': {'data02': 0.5484300263646176, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0035041977242190243, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02705503414997854, 'kernel_size_2': 3, 'num_filters_2': 102}"}}
exception: None

21:37:02 job_callback for (8, 0, 26) started
21:37:02 job_callback for (8, 0, 26) got condition
21:37:02 DISPATCHER: Trying to submit another job.
21:37:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:37:02 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.739568





21:37:02 HBMASTER: Trying to run another job!
21:37:02 job_callback for (8, 0, 26) finished
21:37:02 ITERATION: Advancing config (8, 0, 6) to next budget 400.000000
21:37:02 ITERATION: Advancing config (8, 0, 9) to next budget 400.000000
21:37:02 ITERATION: Advancing config (8, 0, 13) to next budget 400.000000
21:37:02 HBMASTER: schedule new run for iteration 8
21:37:02 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
21:37:02 HBMASTER: submitting job (8, 0, 6) to dispatcher
21:37:02 DISPATCHER: trying to submit job (8, 0, 6)
21:37:02 DISPATCHER: trying to notify the job_runner thread.
21:37:02 HBMASTER: job (8, 0, 6) submitted to dispatcher
21:37:02 DISPATCHER: Trying to submit another job.
21:37:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:37:02 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:37:02 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:37:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:37:02 WORKER: start processing job (8, 0, 6)
21:37:02 WORKER: args: ()
21:37:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}, 'budget': 400.0, 'working_directory': '.'}
21:37:48 DISPATCHER: Starting worker discovery
21:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:48 DISPATCHER: Finished worker discovery
21:38:48 DISPATCHER: Starting worker discovery
21:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:48 DISPATCHER: Finished worker discovery
21:39:48 DISPATCHER: Starting worker discovery
21:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:48 DISPATCHER: Finished worker discovery
21:40:48 DISPATCHER: Starting worker discovery
21:40:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:48 DISPATCHER: Finished worker discovery
21:41:48 DISPATCHER: Starting worker discovery
21:41:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:48 DISPATCHER: Finished worker discovery
21:42:48 DISPATCHER: Starting worker discovery
21:42:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:48 DISPATCHER: Finished worker discovery
21:43:48 WORKER: done with job (8, 0, 6), trying to register it.
21:43:48 WORKER: registered result for job (8, 0, 6) with dispatcher
21:43:48 DISPATCHER: job (8, 0, 6) finished
21:43:48 DISPATCHER: register_result: lock acquired
21:43:48 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:43:48 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.627028258025939, 'info': {'data02': 0.627028258025939, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002286829801350905, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01712461920813554, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 46, 'num_filters_4': 105}"}}
exception: None

21:43:48 job_callback for (8, 0, 6) started
21:43:48 DISPATCHER: Trying to submit another job.
21:43:48 job_callback for (8, 0, 6) got condition
21:43:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:43:48 HBMASTER: Trying to run another job!
21:43:48 job_callback for (8, 0, 6) finished
21:43:48 HBMASTER: schedule new run for iteration 8
21:43:48 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
21:43:48 HBMASTER: submitting job (8, 0, 9) to dispatcher
21:43:48 DISPATCHER: trying to submit job (8, 0, 9)
21:43:48 DISPATCHER: trying to notify the job_runner thread.
21:43:48 HBMASTER: job (8, 0, 9) submitted to dispatcher
21:43:48 DISPATCHER: Trying to submit another job.
21:43:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:43:48 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:43:48 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:43:48 WORKER: start processing job (8, 0, 9)
21:43:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:43:48 WORKER: args: ()
21:43:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 400.0, 'working_directory': '.'}
21:43:48 DISPATCHER: Starting worker discovery
21:43:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:48 DISPATCHER: Finished worker discovery
21:44:48 DISPATCHER: Starting worker discovery
21:44:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:48 DISPATCHER: Finished worker discovery
21:45:48 DISPATCHER: Starting worker discovery
21:45:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:48 DISPATCHER: Finished worker discovery
21:46:48 DISPATCHER: Starting worker discovery
21:46:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:48 DISPATCHER: Finished worker discovery
21:47:48 DISPATCHER: Starting worker discovery
21:47:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:48 DISPATCHER: Finished worker discovery
21:48:48 DISPATCHER: Starting worker discovery
21:48:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:48 DISPATCHER: Finished worker discovery
21:49:48 DISPATCHER: Starting worker discovery
21:49:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:48 DISPATCHER: Finished worker discovery
21:50:34 WORKER: done with job (8, 0, 9), trying to register it.
21:50:34 WORKER: registered result for job (8, 0, 9) with dispatcher
21:50:34 DISPATCHER: job (8, 0, 9) finished
21:50:34 DISPATCHER: register_result: lock acquired
21:50:34 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:50:34 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6394170908621122, 'info': {'data02': 0.6394170908621122, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}"}}
exception: None

21:50:34 job_callback for (8, 0, 9) started
21:50:34 job_callback for (8, 0, 9) got condition
21:50:34 DISPATCHER: Trying to submit another job.
21:50:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:50:34 HBMASTER: Trying to run another job!
21:50:34 job_callback for (8, 0, 9) finished
21:50:34 HBMASTER: schedule new run for iteration 8
21:50:34 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
21:50:34 HBMASTER: submitting job (8, 0, 13) to dispatcher
21:50:34 DISPATCHER: trying to submit job (8, 0, 13)
21:50:34 DISPATCHER: trying to notify the job_runner thread.
21:50:34 HBMASTER: job (8, 0, 13) submitted to dispatcher
21:50:34 DISPATCHER: Trying to submit another job.
21:50:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:50:34 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:50:34 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:50:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:50:34 WORKER: start processing job (8, 0, 13)
21:50:34 WORKER: args: ()
21:50:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}, 'budget': 400.0, 'working_directory': '.'}
21:50:48 DISPATCHER: Starting worker discovery
21:50:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:48 DISPATCHER: Finished worker discovery
21:51:48 DISPATCHER: Starting worker discovery
21:51:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:48 DISPATCHER: Finished worker discovery
21:52:48 DISPATCHER: Starting worker discovery
21:52:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:48 DISPATCHER: Finished worker discovery
21:53:48 DISPATCHER: Starting worker discovery
21:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:48 DISPATCHER: Finished worker discovery
21:54:48 DISPATCHER: Starting worker discovery
21:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:48 DISPATCHER: Finished worker discovery
21:55:48 DISPATCHER: Starting worker discovery
21:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:48 DISPATCHER: Finished worker discovery
21:56:48 DISPATCHER: Starting worker discovery
21:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:48 DISPATCHER: Finished worker discovery
21:57:20 WORKER: done with job (8, 0, 13), trying to register it.
21:57:20 WORKER: registered result for job (8, 0, 13) with dispatcher
21:57:20 DISPATCHER: job (8, 0, 13) finished
21:57:20 DISPATCHER: register_result: lock acquired
21:57:20 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:57:20 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6303218284946455, 'info': {'data02': 0.6303218284946455, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00211547135819063, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011248219564713271, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 89, 'num_filters_3': 25, 'num_filters_4': 19}"}}
exception: None

21:57:20 job_callback for (8, 0, 13) started
21:57:20 job_callback for (8, 0, 13) got condition
21:57:20 DISPATCHER: Trying to submit another job.
21:57:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:20 HBMASTER: Trying to run another job!
21:57:20 job_callback for (8, 0, 13) finished
21:57:20 ITERATION: Advancing config (8, 0, 9) to next budget 1200.000000
21:57:20 HBMASTER: schedule new run for iteration 8
21:57:20 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
21:57:20 HBMASTER: submitting job (8, 0, 9) to dispatcher
21:57:20 DISPATCHER: trying to submit job (8, 0, 9)
21:57:20 DISPATCHER: trying to notify the job_runner thread.
21:57:20 HBMASTER: job (8, 0, 9) submitted to dispatcher
21:57:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:20 DISPATCHER: Trying to submit another job.
21:57:20 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:57:20 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:57:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:20 WORKER: start processing job (8, 0, 9)
21:57:20 WORKER: args: ()
21:57:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 1200.0, 'working_directory': '.'}
21:57:48 DISPATCHER: Starting worker discovery
21:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:48 DISPATCHER: Finished worker discovery
21:58:48 DISPATCHER: Starting worker discovery
21:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:48 DISPATCHER: Finished worker discovery
21:59:48 DISPATCHER: Starting worker discovery
21:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:48 DISPATCHER: Finished worker discovery
22:00:48 DISPATCHER: Starting worker discovery
22:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:48 DISPATCHER: Finished worker discovery
22:01:48 DISPATCHER: Starting worker discovery
22:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:48 DISPATCHER: Finished worker discovery
22:02:48 DISPATCHER: Starting worker discovery
22:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:48 DISPATCHER: Finished worker discovery
22:03:48 DISPATCHER: Starting worker discovery
22:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:48 DISPATCHER: Finished worker discovery
22:04:48 DISPATCHER: Starting worker discovery
22:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:48 DISPATCHER: Finished worker discovery
22:05:48 DISPATCHER: Starting worker discovery
22:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:48 DISPATCHER: Finished worker discovery
22:06:48 DISPATCHER: Starting worker discovery
22:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:48 DISPATCHER: Finished worker discovery
22:07:48 DISPATCHER: Starting worker discovery
22:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:48 DISPATCHER: Finished worker discovery
22:08:48 DISPATCHER: Starting worker discovery
22:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:48 DISPATCHER: Finished worker discovery
22:09:48 DISPATCHER: Starting worker discovery
22:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:48 DISPATCHER: Finished worker discovery
22:10:48 DISPATCHER: Starting worker discovery
22:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:48 DISPATCHER: Finished worker discovery
22:11:48 DISPATCHER: Starting worker discovery
22:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:48 DISPATCHER: Finished worker discovery
22:12:48 DISPATCHER: Starting worker discovery
22:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:48 DISPATCHER: Finished worker discovery
22:13:48 DISPATCHER: Starting worker discovery
22:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:48 DISPATCHER: Finished worker discovery
22:14:48 DISPATCHER: Starting worker discovery
22:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:48 DISPATCHER: Finished worker discovery
22:15:48 DISPATCHER: Starting worker discovery
22:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:48 DISPATCHER: Finished worker discovery
22:16:48 DISPATCHER: Starting worker discovery
22:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:48 DISPATCHER: Finished worker discovery
22:17:28 WORKER: done with job (8, 0, 9), trying to register it.
22:17:28 WORKER: registered result for job (8, 0, 9) with dispatcher
22:17:28 DISPATCHER: job (8, 0, 9) finished
22:17:28 DISPATCHER: register_result: lock acquired
22:17:28 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:17:28 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5502228091584679, 'info': {'data02': 0.5502228091584679, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006462525569224085, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.014008485592660437, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 54, 'num_filters_4': 123}"}}
exception: None

22:17:28 job_callback for (8, 0, 9) started
22:17:28 job_callback for (8, 0, 9) got condition
22:17:28 DISPATCHER: Trying to submit another job.
22:17:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:17:28 HBMASTER: Trying to run another job!
22:17:28 job_callback for (8, 0, 9) finished
22:17:28 start sampling a new configuration.
22:17:28 done sampling a new configuration.
22:17:28 HBMASTER: schedule new run for iteration 9
22:17:28 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
22:17:28 HBMASTER: submitting job (9, 0, 0) to dispatcher
22:17:28 DISPATCHER: trying to submit job (9, 0, 0)
22:17:28 DISPATCHER: trying to notify the job_runner thread.
22:17:28 HBMASTER: job (9, 0, 0) submitted to dispatcher
22:17:28 DISPATCHER: Trying to submit another job.
22:17:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:17:28 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:17:28 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:17:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:17:28 WORKER: start processing job (9, 0, 0)
22:17:28 WORKER: args: ()
22:17:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0779296401941669, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.031133867967018277}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:17:48 DISPATCHER: Starting worker discovery
22:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:48 DISPATCHER: Finished worker discovery
22:18:48 DISPATCHER: Starting worker discovery
22:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:48 DISPATCHER: Finished worker discovery
22:19:48 DISPATCHER: Starting worker discovery
22:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:49 DISPATCHER: Finished worker discovery
22:19:49 WORKER: done with job (9, 0, 0), trying to register it.
22:19:49 WORKER: registered result for job (9, 0, 0) with dispatcher
22:19:49 DISPATCHER: job (9, 0, 0) finished
22:19:49 DISPATCHER: register_result: lock acquired
22:19:49 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:19:49 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0779296401941669, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.031133867967018277}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42781430638534923, 'info': {'data02': 0.42781430638534923, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0779296401941669, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.031133867967018277}"}}
exception: None

22:19:49 job_callback for (9, 0, 0) started
22:19:49 job_callback for (9, 0, 0) got condition
22:19:49 DISPATCHER: Trying to submit another job.
22:19:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:19:50 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.739568





22:19:50 HBMASTER: Trying to run another job!
22:19:50 job_callback for (9, 0, 0) finished
22:19:50 start sampling a new configuration.
22:19:50 best_vector: [1, 1, 0.02833207505557661, 0.5481575026258827, 0.5061210663239134, 1, 0.2812110224973199, 0.5512335324012047, 0, 1, 2, 0, 0.03541191247680686, 0.02026284456687534, 0.8419811297316281, 0.5043082349582089], 0.0007319828530693255, 0.01782035617145121, 1.304419515309042e-05
22:19:50 done sampling a new configuration.
22:19:50 HBMASTER: schedule new run for iteration 9
22:19:50 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
22:19:50 HBMASTER: submitting job (9, 0, 1) to dispatcher
22:19:50 DISPATCHER: trying to submit job (9, 0, 1)
22:19:50 DISPATCHER: trying to notify the job_runner thread.
22:19:50 HBMASTER: job (9, 0, 1) submitted to dispatcher
22:19:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:19:50 DISPATCHER: Trying to submit another job.
22:19:50 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:19:50 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:19:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:19:50 WORKER: start processing job (9, 0, 1)
22:19:50 WORKER: args: ()
22:19:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011393683470975137, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.05214004003144663, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:20:49 DISPATCHER: Starting worker discovery
22:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:49 DISPATCHER: Finished worker discovery
22:21:49 DISPATCHER: Starting worker discovery
22:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:49 DISPATCHER: Finished worker discovery
22:22:09 WORKER: done with job (9, 0, 1), trying to register it.
22:22:09 WORKER: registered result for job (9, 0, 1) with dispatcher
22:22:09 DISPATCHER: job (9, 0, 1) finished
22:22:09 DISPATCHER: register_result: lock acquired
22:22:09 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:22:09 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011393683470975137, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.05214004003144663, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5241743585442029, 'info': {'data02': 0.5241743585442029, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011393683470975137, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.05214004003144663, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 16}"}}
exception: None

22:22:09 job_callback for (9, 0, 1) started
22:22:09 DISPATCHER: Trying to submit another job.
22:22:09 job_callback for (9, 0, 1) got condition
22:22:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:22:09 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.739568





22:22:09 HBMASTER: Trying to run another job!
22:22:09 job_callback for (9, 0, 1) finished
22:22:09 start sampling a new configuration.
22:22:10 best_vector: [2, 0, 0.001467269650819926, 0.53200019626037, 0.6862555475069291, 1, 0.9862705941229315, 0.2105284665209545, 0, 2, 1, 0, 0.8761239372226329, 0.9701369151021615, 0.9071917393523536, 0.506065428767338], 1.9451526155603184e-05, 0.5423446305370191, 1.0549430766241772e-05
22:22:10 done sampling a new configuration.
22:22:10 HBMASTER: schedule new run for iteration 9
22:22:10 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
22:22:10 HBMASTER: submitting job (9, 0, 2) to dispatcher
22:22:10 DISPATCHER: trying to submit job (9, 0, 2)
22:22:10 DISPATCHER: trying to notify the job_runner thread.
22:22:10 HBMASTER: job (9, 0, 2) submitted to dispatcher
22:22:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:22:10 DISPATCHER: Trying to submit another job.
22:22:10 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:22:10 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:22:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:22:10 WORKER: start processing job (9, 0, 2)
22:22:10 WORKER: args: ()
22:22:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:22:49 DISPATCHER: Starting worker discovery
22:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:49 DISPATCHER: Finished worker discovery
22:23:49 DISPATCHER: Starting worker discovery
22:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:49 DISPATCHER: Finished worker discovery
22:24:28 WORKER: done with job (9, 0, 2), trying to register it.
22:24:28 WORKER: registered result for job (9, 0, 2) with dispatcher
22:24:28 DISPATCHER: job (9, 0, 2) finished
22:24:28 DISPATCHER: register_result: lock acquired
22:24:28 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:24:28 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6467661383518177, 'info': {'data02': 0.6467661383518177, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}"}}
exception: None

22:24:28 job_callback for (9, 0, 2) started
22:24:28 job_callback for (9, 0, 2) got condition
22:24:28 DISPATCHER: Trying to submit another job.
22:24:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:28 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.739568





22:24:28 HBMASTER: Trying to run another job!
22:24:28 job_callback for (9, 0, 2) finished
22:24:28 start sampling a new configuration.
22:24:28 done sampling a new configuration.
22:24:28 HBMASTER: schedule new run for iteration 9
22:24:28 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
22:24:28 HBMASTER: submitting job (9, 0, 3) to dispatcher
22:24:28 DISPATCHER: trying to submit job (9, 0, 3)
22:24:28 DISPATCHER: trying to notify the job_runner thread.
22:24:28 HBMASTER: job (9, 0, 3) submitted to dispatcher
22:24:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:24:28 DISPATCHER: Trying to submit another job.
22:24:28 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:24:28 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:24:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:24:28 WORKER: start processing job (9, 0, 3)
22:24:28 WORKER: args: ()
22:24:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06479366302907447, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.010925710085125176, 'kernel_size_2': 7, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:24:49 DISPATCHER: Starting worker discovery
22:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:49 DISPATCHER: Finished worker discovery
22:25:49 DISPATCHER: Starting worker discovery
22:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:49 DISPATCHER: Finished worker discovery
22:26:47 WORKER: done with job (9, 0, 3), trying to register it.
22:26:47 WORKER: registered result for job (9, 0, 3) with dispatcher
22:26:47 DISPATCHER: job (9, 0, 3) finished
22:26:47 DISPATCHER: register_result: lock acquired
22:26:47 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:26:47 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06479366302907447, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.010925710085125176, 'kernel_size_2': 7, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.370795829031637, 'info': {'data02': 0.370795829031637, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06479366302907447, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.010925710085125176, 'kernel_size_2': 7, 'num_filters_2': 25}"}}
exception: None

22:26:47 job_callback for (9, 0, 3) started
22:26:47 DISPATCHER: Trying to submit another job.
22:26:47 job_callback for (9, 0, 3) got condition
22:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:26:47 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.739568





22:26:47 HBMASTER: Trying to run another job!
22:26:47 job_callback for (9, 0, 3) finished
22:26:47 start sampling a new configuration.
22:26:47 best_vector: [1, 1, 0.11009601821948917, 0.46569980595502725, 0.425998807098872, 1, 0.9855659750089403, 0.5601921786589111, 2, 1, 2, 0, 0.4839553148811322, 0.712610839757776, 0.8521905582639602, 0.502953725398566], 0.00031579469213396005, 1.2004040964269043, 0.0003790812420674787
22:26:47 done sampling a new configuration.
22:26:47 HBMASTER: schedule new run for iteration 9
22:26:47 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
22:26:47 HBMASTER: submitting job (9, 0, 4) to dispatcher
22:26:47 DISPATCHER: trying to submit job (9, 0, 4)
22:26:47 DISPATCHER: trying to notify the job_runner thread.
22:26:47 HBMASTER: job (9, 0, 4) submitted to dispatcher
22:26:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:26:47 DISPATCHER: Trying to submit another job.
22:26:47 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:26:47 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:26:47 WORKER: start processing job (9, 0, 4)
22:26:47 WORKER: args: ()
22:26:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016603209062453453, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.05355830545118444, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:26:49 DISPATCHER: Starting worker discovery
22:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:49 DISPATCHER: Finished worker discovery
22:27:49 DISPATCHER: Starting worker discovery
22:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:49 DISPATCHER: Finished worker discovery
22:28:49 DISPATCHER: Starting worker discovery
22:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:49 DISPATCHER: Finished worker discovery
22:29:05 WORKER: done with job (9, 0, 4), trying to register it.
22:29:05 WORKER: registered result for job (9, 0, 4) with dispatcher
22:29:05 DISPATCHER: job (9, 0, 4) finished
22:29:05 DISPATCHER: register_result: lock acquired
22:29:05 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:29:05 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016603209062453453, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.05355830545118444, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6701511682528698, 'info': {'data02': 0.6701511682528698, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016603209062453453, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.05355830545118444, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 70}"}}
exception: None

22:29:05 job_callback for (9, 0, 4) started
22:29:05 DISPATCHER: Trying to submit another job.
22:29:05 job_callback for (9, 0, 4) got condition
22:29:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:29:05 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.739568





22:29:05 HBMASTER: Trying to run another job!
22:29:05 job_callback for (9, 0, 4) finished
22:29:05 start sampling a new configuration.
22:29:05 sampled vector: [1, 0, 0.35935230037032007, 0.3666242143858952, 0.3460622368695562, 0, 0.47683496822480165, 0.5848273153904721, 2, 1, 1, 1, 0.05222830123903066, 0.30882433346057664, 0.26473843514557827, 0.7464121630053473] has EI value inf
22:29:05 data in the KDEs:
[[2.00000000e+00 1.00000000e+00 4.05201137e-01 9.94448581e-01
  7.00000800e-01 1.00000000e+00 6.20879147e-01 1.12519456e-01
  1.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  3.57274419e-01 5.90114116e-01 9.79317897e-01 7.37810259e-01]
 [2.00000000e+00 1.00000000e+00 1.79616922e-01 9.67643389e-01
  7.00000800e-01 1.00000000e+00 6.09890134e-01 1.79566131e-01
  2.00000000e+00 0.00000000e+00 2.00000000e+00 0.00000000e+00
  1.43578776e-01 5.14305148e-01 9.04510611e-01 7.02536324e-01]
 [1.00000000e+00 2.00000000e+00 1.50986326e-01 7.63972013e-01
  5.00000000e-01 1.00000000e+00 7.19780268e-01 2.91144463e-01
  1.00000000e+00 2.00000000e+00 2.00000000e+00 1.00000000e+00
  4.36256510e-01 8.47131983e-01 2.44555229e-01 5.48540927e-01]
 [0.00000000e+00 0.00000000e+00 1.86733218e-01 3.27715199e-01
  5.00000000e-01 1.00000000e+00 8.07692375e-01 6.52127395e-02
  0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  3.71388707e-01 6.07308503e-01 8.86147389e-01 1.91951467e-01]
 [3.00000000e+00 0.00000000e+00 6.53368409e-02 5.81276596e-01
  5.00000000e-01 0.00000000e+00 9.61538563e-01 7.30298306e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  8.42020651e-01 5.24473143e-01 8.86147389e-01 8.06995593e-01]
 [1.00000000e+00 0.00000000e+00 2.24633595e-02 9.30783677e-01
  5.00000000e-01 1.00000000e+00 9.83516590e-01 1.03041645e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  9.71567010e-01 9.22187194e-01 9.79317897e-01 3.50957763e-01]
 [1.00000000e+00 0.00000000e+00 3.43126127e-01 8.90805491e-01
  7.00000800e-01 1.00000000e+00 5.32967040e-01 6.82023438e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00
  4.36256510e-01 9.90711064e-01 8.26346502e-01 4.70138466e-01]
 [1.00000000e+00 1.00000000e+00 1.10096018e-01 4.71294279e-01
  5.00000000e-01 1.00000000e+00 9.83516590e-01 5.60192179e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  4.82419346e-01 7.12809330e-01 9.26504973e-01 4.77764046e-01]
 [0.00000000e+00 1.00000000e+00 3.25368876e-02 5.14305148e-01
  7.00000800e-01 1.00000000e+00 9.28571523e-01 1.94496029e-02
  2.00000000e+00 1.00000000e+00 2.00000000e+00 0.00000000e+00
  9.39226643e-01 4.23975468e-01 2.44555229e-01 7.83317510e-01]
 [0.00000000e+00 1.00000000e+00 1.62703575e-01 5.44175724e-01
  7.00000800e-01 1.00000000e+00 4.67032960e-01 3.92641102e-02
  0.00000000e+00 2.00000000e+00 1.00000000e+00 2.00000000e+00
  8.26346502e-01 2.26011930e-01 9.62599641e-02 7.35167373e-01]
 [2.00000000e+00 1.00000000e+00 1.85674351e-01 4.93288642e-01
  5.00000000e-01 1.00000000e+00 6.31868161e-01 8.23256049e-03
  1.00000000e+00 1.00000000e+00 2.00000000e+00 0.00000000e+00
  6.55430702e-01 7.06973316e-02 2.44555229e-01 6.32417591e-01]
 [2.00000000e+00 0.00000000e+00 1.46726965e-03 5.34427058e-01
  7.00000800e-01 1.00000000e+00 9.83516590e-01 2.10528467e-01
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  8.76691203e-01 9.71567010e-01 9.08992100e-01 7.13737731e-01]
 [3.00000000e+00 1.00000000e+00 2.54862755e-01 5.03913663e-01
  7.00000800e-01 1.00000000e+00 2.69230719e-01 5.05089767e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  6.23899452e-01 3.57274419e-01 9.26504973e-01 9.92652108e-01]
 [2.00000000e+00 0.00000000e+00 1.58546313e-01 2.44555229e-01
  2.99999200e-01 1.00000000e+00 6.53846188e-01 3.35513666e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  6.92099734e-01 5.90114116e-01 9.79317897e-01 5.88435008e-01]
 [0.00000000e+00 0.00000000e+00 2.90974471e-01 8.90805491e-01
  7.00000800e-01 0.00000000e+00 4.12087893e-01 2.89998891e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00
  3.27715199e-01 6.92099734e-01 8.86147389e-01 5.92798382e-01]
 [2.00000000e+00 0.00000000e+00 3.86604853e-01 1.65573138e-01
  5.00000000e-01 0.00000000e+00 6.31868161e-01 2.69356944e-02
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  8.26346502e-01 2.62398612e-01 9.08992100e-01 9.95959922e-01]
 [0.00000000e+00 2.00000000e+00 4.15050026e-02 6.47742833e-01
  7.00000800e-01 1.00000000e+00 9.72527576e-01 3.18198792e-02
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  9.47521479e-01 6.55430702e-01 8.86147389e-01 3.93991381e-01]]
[[2.         0.         0.30996    0.84202065 0.9000016  1.
  0.76373632 0.2175731  0.         1.         1.         0.
  0.29618395 0.88614739 0.85218865 0.50391366]
 [3.         0.         0.18336048 0.29618395 0.5        1.
  0.47802197 0.05867882 1.         1.         1.         0.
  0.84202065 0.0436732  0.85218865 0.50391366]
 [1.         1.         0.26279185 0.26239861 0.5        0.
  0.67582421 0.01379875 2.         2.         0.         0.
  0.55372743 0.39841284 0.0436732  0.50391366]
 [2.         2.         0.43770547 0.24455523 0.7000008  1.
  0.15934058 0.07762602 0.         2.         2.         0.
  0.75787137 0.31221238 0.8263465  0.50391366]
 [2.         2.         0.02812941 0.16557314 0.7000008  1.
  0.58791211 0.02095818 0.         0.         0.         0.
  0.88614739 0.18658964 0.0436732  0.59878947]
 [1.         1.         0.23803873 0.72612834 0.7000008  0.
  0.43406592 0.15711763 2.         1.         1.         0.
  0.16557314 0.91782962 0.86704202 0.50391366]
 [2.         1.         0.46729085 0.98694376 0.2999992  0.
  0.56593408 0.29026317 1.         2.         2.         0.
  0.47129428 0.31221238 0.8263465  0.50391366]
 [0.         2.         0.06649942 0.09625996 0.9000016  0.
  0.68681323 0.40008914 2.         2.         2.         0.
  0.83685346 0.09625996 0.39841284 0.50391366]
 [2.         0.         0.36359918 0.0436732  0.5        0.
  0.9065935  0.51683133 0.         2.         1.         0.
  0.26239861 0.24455523 0.74542871 0.59878947]
 [0.         2.         0.56439753 0.52447314 0.2999992  1.
  0.26923072 0.32679467 1.         1.         1.         0.
  0.90451061 0.14357878 0.74542871 0.59878947]
 [2.         0.         0.02820026 0.90451061 0.7000008  1.
  0.9945056  0.11831889 2.         1.         2.         0.
  0.8766912  0.29618395 0.24455523 0.50391366]
 [0.         2.         0.2722943  0.41136689 0.2999992  0.
  0.98351659 0.3322353  0.         1.         1.         0.
  0.89080549 0.22601193 0.74542871 0.59878947]
 [2.         2.         0.05889315 0.99444858 0.5        0.
  0.63186816 0.26059526 0.         1.         2.         0.
  0.82100415 0.14357878 0.8263465  0.59878947]
 [1.         1.         0.02833208 0.54417572 0.5        1.
  0.28021973 0.55123353 0.         1.         1.         0.
  0.0436732  0.01501027 0.85218865 0.50391366]
 [3.         0.         0.31931082 0.59878947 0.9000016  0.
  0.07142848 0.11154826 1.         0.         1.         0.
  0.29618395 0.279593   0.74542871 0.59878947]
 [0.         2.         0.99515975 0.279593   0.0999984  1.
  0.75274731 0.50074335 2.         2.         2.         0.
  0.83685346 0.09625996 0.39841284 0.50391366]
 [3.         1.         0.87325029 0.57227073 0.5        1.
  0.9065935  0.50993883 2.         2.         0.         0.
  0.42397547 0.3277152  0.0436732  0.50391366]
 [1.         2.         0.05955607 0.84713198 0.5        1.
  0.55494507 0.7343961  2.         1.         2.         0.
  0.94339225 0.63198159 0.1205111  0.59878947]
 [1.         1.         0.30742896 0.18658964 0.5        0.
  0.52197803 0.61849444 0.         1.         1.         0.
  0.5812766  0.22601193 0.74542871 0.59878947]
 [2.         1.         0.43207419 0.85218865 0.0999984  1.
  0.65384619 0.14718903 0.         2.         1.         0.
  0.26239861 0.24455523 0.74542871 0.59878947]
 [1.         2.         0.55400003 0.99815678 0.2999992  1.
  0.59890112 0.71342079 2.         2.         1.         0.
  0.35727442 0.24455523 0.74542871 0.59878947]
 [3.         0.         0.79205126 0.68498992 0.5        1.
  0.84065942 0.70574187 1.         1.         0.         0.
  0.1205111  0.66299556 0.22601193 0.59878947]
 [3.         2.         0.59384812 0.16557314 0.5        1.
  0.86263744 0.7615702  1.         1.         2.         0.
  0.18658964 0.63198159 0.8263465  0.59878947]
 [0.         1.         0.58488517 0.43625651 0.7000008  1.
  0.5        0.50726063 1.         2.         0.         0.
  0.7390824  0.09625996 0.22601193 0.50391366]
 [0.         2.         0.75390367 0.1205111  0.5        1.
  0.67582421 0.29910639 2.         2.         1.         0.
  0.79334752 0.63992789 0.85218865 0.50391366]
 [0.         0.         0.03753347 0.86214256 0.0999984  0.
  0.91758251 0.83629983 1.         2.         0.         0.
  0.7390824  0.09625996 0.22601193 0.59878947]
 [3.         1.         0.94585134 0.0436732  0.0999984  0.
  0.43406592 0.37910969 1.         1.         0.         0.
  0.1205111  0.66299556 0.0436732  0.59878947]
 [1.         0.         0.90688586 0.75787137 0.0999984  1.
  0.67582421 0.6059201  1.         2.         0.         0.
  0.7390824  0.09625996 0.22601193 0.50391366]
 [2.         0.         0.84071128 0.01501027 0.0999984  0.
  0.97252758 0.51111759 2.         2.         2.         0.
  0.83685346 0.09625996 0.39841284 0.50391366]
 [1.         2.         0.90576627 0.85218865 0.2999992  1.
  0.14835157 0.02955326 2.         2.         0.         0.
  0.22601193 0.09625996 0.22601193 0.50391366]
 [3.         1.         0.06729967 0.09625996 0.5        1.
  0.68681323 0.93976475 2.         0.         2.         0.
  0.26239861 0.71280933 0.24455523 0.59878947]
 [3.         0.         0.5182687  0.41136689 0.2999992  0.
  0.3351648  0.87772715 2.         0.         0.         0.
  0.81013485 0.18658964 0.0436732  0.50391366]
 [3.         0.         0.5736865  0.61567675 0.7000008  1.
  0.18131861 0.83545085 2.         1.         2.         0.
  0.39841284 0.61567675 0.1205111  0.50391366]]
22:29:05 bandwidth of the KDEs:
[0.93420595 0.6264507  0.11264682 0.22708814 0.11143437 0.35071888
 0.20207507 0.1952994  0.78795684 0.66720039 0.63110839 0.64032214
 0.23043362 0.23546872 0.27942108 0.19183616]
[0.97834983 0.74250748 0.27396665 0.28431924 0.2122186  0.43486345
 0.22808297 0.24544903 0.73065819 0.60665459 0.70944589 0.001
 0.25780073 0.22504289 0.28309457 0.04204396]
22:29:05 l(x) = 7.307162009434154e-07
22:29:05 g(x) = inf
22:29:05 best_vector: [1, 0, 0.35935230037032007, 0.3666242143858952, 0.3460622368695562, 0, 0.47683496822480165, 0.5848273153904721, 2, 1, 1, 1, 0.05222830123903066, 0.30882433346057664, 0.26473843514557827, 0.7464121630053473], 16943696.13383573, 7.307162009434154e-07, inf
22:29:05 done sampling a new configuration.
22:29:05 HBMASTER: schedule new run for iteration 9
22:29:05 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
22:29:05 HBMASTER: submitting job (9, 0, 5) to dispatcher
22:29:05 DISPATCHER: trying to submit job (9, 0, 5)
22:29:05 DISPATCHER: trying to notify the job_runner thread.
22:29:05 HBMASTER: job (9, 0, 5) submitted to dispatcher
22:29:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:29:05 DISPATCHER: Trying to submit another job.
22:29:05 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:29:06 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:29:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:29:06 WORKER: start processing job (9, 0, 5)
22:29:06 WORKER: args: ()
22:29:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005232444141234265, 'num_filters_1': 34, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.05766043037324945, 'kernel_size_2': 7, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:29:49 DISPATCHER: Starting worker discovery
22:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:49 DISPATCHER: Finished worker discovery
22:30:49 DISPATCHER: Starting worker discovery
22:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:49 DISPATCHER: Finished worker discovery
22:31:24 WORKER: done with job (9, 0, 5), trying to register it.
22:31:24 WORKER: registered result for job (9, 0, 5) with dispatcher
22:31:24 DISPATCHER: job (9, 0, 5) finished
22:31:24 DISPATCHER: register_result: lock acquired
22:31:24 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:31:24 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005232444141234265, 'num_filters_1': 34, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.05766043037324945, 'kernel_size_2': 7, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5813087699616728, 'info': {'data02': 0.5813087699616728, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005232444141234265, 'num_filters_1': 34, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.05766043037324945, 'kernel_size_2': 7, 'num_filters_2': 17}"}}
exception: None

22:31:24 job_callback for (9, 0, 5) started
22:31:24 job_callback for (9, 0, 5) got condition
22:31:24 DISPATCHER: Trying to submit another job.
22:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:31:24 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.739568





22:31:24 HBMASTER: Trying to run another job!
22:31:24 job_callback for (9, 0, 5) finished
22:31:24 start sampling a new configuration.
22:31:24 sampled vector: [1, 0, 0.18571487413055468, 0.09995155350019713, 0.5709420437173701, 1, 0.9889847786543239, 0.19393815540853368, 2, 1, 1, 2, 0.26392010480615846, 0.6095895062126522, 0.5830799924024834, 0.11933659131386966] has EI value inf
22:31:24 data in the KDEs:
[[2.00000000e+00 1.00000000e+00 4.05201137e-01 9.94448581e-01
  7.00000800e-01 1.00000000e+00 6.20879147e-01 1.12519456e-01
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  3.57274419e-01 5.90114116e-01 9.79317897e-01 5.09728387e-02]
 [2.00000000e+00 1.00000000e+00 1.79616922e-01 9.67643389e-01
  7.00000800e-01 1.00000000e+00 6.09890134e-01 1.79566131e-01
  2.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  1.43578776e-01 5.14305148e-01 9.04510611e-01 3.41738413e-01]
 [1.00000000e+00 2.00000000e+00 1.50986326e-01 7.63972013e-01
  5.00000000e-01 1.00000000e+00 7.19780268e-01 2.91144463e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  4.36256510e-01 8.47131983e-01 8.86147389e-01 4.18937895e-01]
 [0.00000000e+00 0.00000000e+00 1.86733218e-01 3.27715199e-01
  5.00000000e-01 1.00000000e+00 8.07692375e-01 6.52127395e-02
  0.00000000e+00 1.00000000e+00 0.00000000e+00 2.00000000e+00
  3.71388707e-01 6.07308503e-01 8.86147389e-01 9.88809143e-01]
 [3.00000000e+00 0.00000000e+00 6.53368409e-02 5.81276596e-01
  5.00000000e-01 0.00000000e+00 9.61538563e-01 7.30298306e-01
  1.00000000e+00 1.00000000e+00 2.00000000e+00 0.00000000e+00
  8.42020651e-01 5.24473143e-01 9.04510611e-01 2.72878317e-01]
 [1.00000000e+00 0.00000000e+00 2.24633595e-02 9.30783677e-01
  5.00000000e-01 1.00000000e+00 9.83516590e-01 1.03041645e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  9.71567010e-01 9.22187194e-01 9.79317897e-01 2.06759274e-01]
 [1.00000000e+00 0.00000000e+00 3.43126127e-01 8.90805491e-01
  7.00000800e-01 1.00000000e+00 5.32967040e-01 6.82023438e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00
  4.36256510e-01 9.90711064e-01 8.26346502e-01 2.97665287e-01]
 [1.00000000e+00 1.00000000e+00 1.10096018e-01 4.71294279e-01
  5.00000000e-01 1.00000000e+00 9.83516590e-01 5.60192179e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  4.82419346e-01 7.12809330e-01 9.08992100e-01 8.81001207e-01]
 [0.00000000e+00 1.00000000e+00 3.25368876e-02 5.14305148e-01
  7.00000800e-01 1.00000000e+00 9.28571523e-01 1.94496029e-02
  2.00000000e+00 1.00000000e+00 2.00000000e+00 2.00000000e+00
  9.39226643e-01 4.23975468e-01 2.44555229e-01 7.14643755e-01]
 [0.00000000e+00 1.00000000e+00 1.62703575e-01 5.44175724e-01
  7.00000800e-01 1.00000000e+00 4.67032960e-01 3.92641102e-02
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  8.26346502e-01 2.26011930e-01 9.62599641e-02 5.54350673e-01]
 [2.00000000e+00 1.00000000e+00 1.85674351e-01 4.93288642e-01
  5.00000000e-01 1.00000000e+00 6.31868161e-01 8.23256049e-03
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  6.55430702e-01 7.06973316e-02 8.86147389e-01 6.29067600e-01]
 [2.00000000e+00 0.00000000e+00 1.46726965e-03 5.34427058e-01
  7.00000800e-01 1.00000000e+00 9.83516590e-01 2.10528467e-01
  0.00000000e+00 2.00000000e+00 1.00000000e+00 1.00000000e+00
  8.76691203e-01 9.71567010e-01 9.08992100e-01 2.19522399e-01]
 [3.00000000e+00 1.00000000e+00 2.54862755e-01 5.03913663e-01
  7.00000800e-01 1.00000000e+00 2.69230719e-01 5.05089767e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  6.23899452e-01 3.57274419e-01 9.26504973e-01 1.24210619e-01]
 [2.00000000e+00 0.00000000e+00 1.58546313e-01 2.44555229e-01
  2.99999200e-01 1.00000000e+00 6.53846188e-01 3.35513666e-01
  2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  6.92099734e-01 5.24473143e-01 8.26346502e-01 8.76794884e-01]
 [0.00000000e+00 0.00000000e+00 2.90974471e-01 8.90805491e-01
  7.00000800e-01 0.00000000e+00 4.12087893e-01 2.89998891e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.27715199e-01 6.92099734e-01 8.86147389e-01 4.99592937e-01]
 [2.00000000e+00 0.00000000e+00 3.86604853e-01 1.65573138e-01
  5.00000000e-01 0.00000000e+00 6.31868161e-01 2.69356944e-02
  0.00000000e+00 2.00000000e+00 2.00000000e+00 1.00000000e+00
  8.26346502e-01 2.62398612e-01 9.04510611e-01 8.68042669e-01]
 [0.00000000e+00 2.00000000e+00 4.15050026e-02 6.47742833e-01
  7.00000800e-01 1.00000000e+00 9.72527576e-01 3.18198792e-02
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  9.47521479e-01 6.55430702e-01 8.86147389e-01 7.49339635e-01]]
[[2.         0.         0.30996    0.84202065 0.9000016  1.
  0.76373632 0.2175731  0.         1.         1.         0.
  0.29618395 0.88614739 0.85218865 0.50391366]
 [3.         0.         0.18336048 0.29618395 0.5        1.
  0.47802197 0.05867882 1.         1.         2.         0.
  0.84202065 0.0436732  0.8263465  0.59878947]
 [1.         1.         0.26279185 0.26239861 0.5        0.
  0.67582421 0.01379875 2.         2.         0.         0.
  0.55372743 0.39841284 0.22601193 0.59878947]
 [1.         0.         0.3593523  0.37138871 0.2999992  0.
  0.47802197 0.58482732 2.         1.         1.         0.
  0.0436732  0.88614739 0.85218865 0.50391366]
 [2.         2.         0.43770547 0.24455523 0.7000008  1.
  0.15934058 0.07762602 0.         2.         2.         0.
  0.75787137 0.31221238 0.8263465  0.50391366]
 [2.         2.         0.02812941 0.16557314 0.7000008  1.
  0.58791211 0.02095818 0.         0.         0.         0.
  0.88614739 0.18658964 0.0436732  0.50391366]
 [1.         1.         0.23803873 0.72612834 0.7000008  0.
  0.43406592 0.15711763 2.         1.         1.         0.
  0.16557314 0.91782962 0.86704202 0.50391366]
 [2.         1.         0.46729085 0.98694376 0.2999992  0.
  0.56593408 0.29026317 1.         1.         2.         0.
  0.47129428 0.0436732  0.8263465  0.50391366]
 [0.         2.         0.06649942 0.09625996 0.9000016  0.
  0.68681323 0.40008914 2.         2.         2.         0.
  0.83685346 0.09625996 0.39841284 0.50391366]
 [2.         0.         0.36359918 0.0436732  0.5        0.
  0.9065935  0.51683133 0.         2.         2.         0.
  0.26239861 0.24455523 0.8263465  0.59878947]
 [0.         2.         0.56439753 0.52447314 0.2999992  1.
  0.26923072 0.32679467 1.         1.         2.         0.
  0.90451061 0.22601193 0.39841284 0.50391366]
 [2.         0.         0.02820026 0.90451061 0.7000008  1.
  0.9945056  0.11831889 2.         1.         2.         0.
  0.8766912  0.29618395 0.24455523 0.50391366]
 [0.         2.         0.2722943  0.41136689 0.2999992  0.
  0.98351659 0.3322353  0.         1.         1.         0.
  0.89080549 0.01501027 0.74542871 0.59878947]
 [2.         2.         0.05889315 0.99444858 0.5        0.
  0.63186816 0.26059526 0.         1.         0.         0.
  0.82100415 0.14357878 0.22601193 0.50391366]
 [1.         1.         0.02833208 0.54417572 0.5        1.
  0.28021973 0.55123353 0.         1.         0.         0.
  0.0436732  0.01501027 0.0436732  0.59878947]
 [3.         0.         0.31931082 0.59878947 0.9000016  0.
  0.07142848 0.11154826 1.         0.         1.         0.
  0.29618395 0.279593   0.74542871 0.59878947]
 [0.         2.         0.99515975 0.279593   0.0999984  1.
  0.75274731 0.50074335 2.         2.         2.         0.
  0.79334752 0.63992789 0.24455523 0.59878947]
 [3.         1.         0.87325029 0.57227073 0.5        1.
  0.9065935  0.50993883 2.         2.         0.         0.
  0.42397547 0.3277152  0.22601193 0.50391366]
 [1.         2.         0.05955607 0.84713198 0.5        1.
  0.55494507 0.7343961  2.         1.         1.         0.
  0.94339225 0.63198159 0.86704202 0.59878947]
 [1.         1.         0.30742896 0.18658964 0.5        0.
  0.52197803 0.61849444 0.         1.         2.         0.
  0.5812766  0.22601193 0.39841284 0.50391366]
 [2.         1.         0.43207419 0.85218865 0.0999984  1.
  0.65384619 0.14718903 0.         2.         2.         0.
  0.26239861 0.24455523 0.39841284 0.50391366]
 [1.         2.         0.55400003 0.99815678 0.2999992  1.
  0.59890112 0.71342079 2.         1.         1.         0.
  0.35727442 0.91782962 0.86704202 0.50391366]
 [3.         0.         0.79205126 0.68498992 0.5        1.
  0.84065942 0.70574187 1.         1.         1.         0.
  0.1205111  0.66299556 0.85218865 0.50391366]
 [3.         2.         0.59384812 0.16557314 0.5        1.
  0.86263744 0.7615702  1.         1.         2.         0.
  0.18658964 0.63198159 0.8263465  0.59878947]
 [0.         1.         0.58488517 0.43625651 0.7000008  1.
  0.5        0.50726063 1.         2.         0.         0.
  0.7390824  0.09625996 0.22601193 0.59878947]
 [0.         2.         0.75390367 0.1205111  0.5        1.
  0.67582421 0.29910639 2.         2.         2.         0.
  0.79334752 0.63992789 0.1205111  0.59878947]
 [0.         0.         0.03753347 0.86214256 0.0999984  0.
  0.91758251 0.83629983 0.         1.         1.         0.
  0.89080549 0.66299556 0.74542871 0.59878947]
 [3.         1.         0.94585134 0.0436732  0.0999984  0.
  0.43406592 0.37910969 1.         1.         2.         0.
  0.84202065 0.0436732  0.24455523 0.50391366]
 [1.         0.         0.90688586 0.75787137 0.0999984  1.
  0.67582421 0.6059201  0.         1.         2.         0.
  0.5812766  0.22601193 0.24455523 0.50391366]
 [2.         0.         0.84071128 0.01501027 0.0999984  0.
  0.97252758 0.51111759 1.         0.         1.         0.
  0.47129428 0.279593   0.74542871 0.59878947]
 [1.         2.         0.90576627 0.85218865 0.2999992  1.
  0.14835157 0.02955326 2.         2.         0.         0.
  0.22601193 0.09625996 0.22601193 0.59878947]
 [3.         1.         0.06729967 0.09625996 0.5        1.
  0.68681323 0.93976475 2.         0.         2.         0.
  0.26239861 0.71280933 0.24455523 0.50391366]
 [3.         0.         0.5182687  0.41136689 0.2999992  0.
  0.3351648  0.87772715 2.         0.         1.         0.
  0.81013485 0.279593   0.74542871 0.59878947]
 [3.         0.         0.5736865  0.61567675 0.7000008  1.
  0.18131861 0.83545085 2.         1.         2.         0.
  0.39841284 0.61567675 0.1205111  0.50391366]]
22:31:24 bandwidth of the KDEs:
[0.93420595 0.6264507  0.11264682 0.22708814 0.11143437 0.35071888
 0.20207507 0.1952994  0.78795684 0.66720039 0.66720039 0.80268628
 0.23043362 0.23583728 0.22040163 0.26577848]
[0.96670964 0.74661736 0.26974738 0.28033591 0.2102034  0.43735291
 0.22508147 0.24266794 0.75796823 0.57560409 0.69200943 0.001
 0.25832287 0.25377938 0.26637076 0.04186305]
22:31:24 l(x) = 1.9988509824337812e-05
22:31:24 g(x) = inf
22:31:24 best_vector: [1, 0, 0.18571487413055468, 0.09995155350019713, 0.5709420437173701, 1, 0.9889847786543239, 0.19393815540853368, 2, 1, 1, 2, 0.26392010480615846, 0.6095895062126522, 0.5830799924024834, 0.11933659131386966], inf, 1.9988509824337812e-05, inf
22:31:24 done sampling a new configuration.
22:31:24 HBMASTER: schedule new run for iteration 9
22:31:24 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
22:31:24 HBMASTER: submitting job (9, 0, 6) to dispatcher
22:31:24 DISPATCHER: trying to submit job (9, 0, 6)
22:31:24 DISPATCHER: trying to notify the job_runner thread.
22:31:24 HBMASTER: job (9, 0, 6) submitted to dispatcher
22:31:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:31:24 DISPATCHER: Trying to submit another job.
22:31:24 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:31:24 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:31:24 WORKER: start processing job (9, 0, 6)
22:31:24 WORKER: args: ()
22:31:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023519590082998498, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.017878017476812978, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:31:49 DISPATCHER: Starting worker discovery
22:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:49 DISPATCHER: Finished worker discovery
22:32:49 DISPATCHER: Starting worker discovery
22:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:49 DISPATCHER: Finished worker discovery
22:33:42 WORKER: done with job (9, 0, 6), trying to register it.
22:33:42 WORKER: registered result for job (9, 0, 6) with dispatcher
22:33:42 DISPATCHER: job (9, 0, 6) finished
22:33:42 DISPATCHER: register_result: lock acquired
22:33:42 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:33:42 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023519590082998498, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.017878017476812978, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6652895418779328, 'info': {'data02': 0.6652895418779328, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023519590082998498, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.017878017476812978, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 56}"}}
exception: None

22:33:42 job_callback for (9, 0, 6) started
22:33:42 job_callback for (9, 0, 6) got condition
22:33:42 DISPATCHER: Trying to submit another job.
22:33:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:33:42 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.739568





22:33:42 HBMASTER: Trying to run another job!
22:33:42 job_callback for (9, 0, 6) finished
22:33:42 start sampling a new configuration.
22:33:42 sampled vector: [3, 2, 0.054763018803672264, 0.7135916779463756, 0.18321293427384594, 0, 0.03436261419533504, 0.5439674977303791, 1, 2, 1, 2, 0.5091191192694912, 0.832348490886967, 0.6792814541339189, 0.3387275725921214] has EI value inf
22:33:42 data in the KDEs:
[[2.00000000e+00 1.00000000e+00 4.05201137e-01 9.94448581e-01
  7.00000800e-01 1.00000000e+00 6.20879147e-01 1.12519456e-01
  1.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  3.57274419e-01 5.90114116e-01 9.79317897e-01 7.03196579e-01]
 [2.00000000e+00 1.00000000e+00 1.79616922e-01 9.67643389e-01
  7.00000800e-01 1.00000000e+00 6.09890134e-01 1.79566131e-01
  2.00000000e+00 0.00000000e+00 2.00000000e+00 1.00000000e+00
  1.43578776e-01 5.14305148e-01 9.04510611e-01 5.69351648e-01]
 [1.00000000e+00 2.00000000e+00 1.50986326e-01 7.63972013e-01
  5.00000000e-01 1.00000000e+00 7.19780268e-01 2.91144463e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  4.36256510e-01 8.47131983e-01 8.26346502e-01 5.61924382e-01]
 [0.00000000e+00 0.00000000e+00 1.86733218e-01 3.27715199e-01
  5.00000000e-01 1.00000000e+00 8.07692375e-01 6.52127395e-02
  0.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  3.71388707e-01 6.07308503e-01 9.79317897e-01 6.98084743e-01]
 [3.00000000e+00 0.00000000e+00 6.53368409e-02 5.81276596e-01
  5.00000000e-01 0.00000000e+00 9.61538563e-01 7.30298306e-01
  1.00000000e+00 1.00000000e+00 2.00000000e+00 2.00000000e+00
  8.42020651e-01 5.24473143e-01 2.44555229e-01 4.85219430e-01]
 [1.00000000e+00 0.00000000e+00 2.24633595e-02 9.30783677e-01
  5.00000000e-01 1.00000000e+00 9.83516590e-01 1.03041645e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  9.71567010e-01 9.22187194e-01 9.26504973e-01 5.73031253e-01]
 [1.00000000e+00 0.00000000e+00 3.43126127e-01 8.90805491e-01
  7.00000800e-01 1.00000000e+00 5.32967040e-01 6.82023438e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  4.36256510e-01 9.90711064e-01 8.26346502e-01 2.49180351e-01]
 [1.00000000e+00 1.00000000e+00 1.10096018e-01 4.71294279e-01
  5.00000000e-01 1.00000000e+00 9.83516590e-01 5.60192179e-01
  2.00000000e+00 1.00000000e+00 2.00000000e+00 2.00000000e+00
  4.82419346e-01 7.12809330e-01 9.04510611e-01 3.47270357e-01]
 [1.00000000e+00 0.00000000e+00 1.85714874e-01 9.62599641e-02
  5.00000000e-01 1.00000000e+00 9.83516590e-01 1.93938155e-01
  2.00000000e+00 1.00000000e+00 2.00000000e+00 2.00000000e+00
  2.62398612e-01 6.07308503e-01 2.44555229e-01 9.57252188e-01]
 [0.00000000e+00 1.00000000e+00 3.25368876e-02 5.14305148e-01
  7.00000800e-01 1.00000000e+00 9.28571523e-01 1.94496029e-02
  2.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  9.39226643e-01 4.23975468e-01 2.44555229e-01 4.72641787e-01]
 [0.00000000e+00 1.00000000e+00 1.62703575e-01 5.44175724e-01
  7.00000800e-01 1.00000000e+00 4.67032960e-01 3.92641102e-02
  0.00000000e+00 2.00000000e+00 1.00000000e+00 2.00000000e+00
  8.26346502e-01 2.26011930e-01 9.62599641e-02 2.90543327e-02]
 [2.00000000e+00 1.00000000e+00 1.85674351e-01 4.93288642e-01
  5.00000000e-01 1.00000000e+00 6.31868161e-01 8.23256049e-03
  1.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  6.55430702e-01 7.06973316e-02 9.62599641e-02 3.26295002e-01]
 [2.00000000e+00 0.00000000e+00 1.46726965e-03 5.34427058e-01
  7.00000800e-01 1.00000000e+00 9.83516590e-01 2.10528467e-01
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  8.76691203e-01 9.71567010e-01 9.08992100e-01 8.84741424e-01]
 [3.00000000e+00 1.00000000e+00 2.54862755e-01 5.03913663e-01
  7.00000800e-01 1.00000000e+00 2.69230719e-01 5.05089767e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 1.00000000e+00
  6.23899452e-01 3.57274419e-01 9.26504973e-01 1.83528237e-01]
 [2.00000000e+00 0.00000000e+00 1.58546313e-01 2.44555229e-01
  2.99999200e-01 1.00000000e+00 6.53846188e-01 3.35513666e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 2.00000000e+00
  6.92099734e-01 3.57274419e-01 9.26504973e-01 9.74193976e-01]
 [0.00000000e+00 0.00000000e+00 2.90974471e-01 8.90805491e-01
  7.00000800e-01 0.00000000e+00 4.12087893e-01 2.89998891e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 2.00000000e+00
  3.27715199e-01 6.92099734e-01 8.86147389e-01 3.04167803e-01]
 [2.00000000e+00 0.00000000e+00 3.86604853e-01 1.65573138e-01
  5.00000000e-01 0.00000000e+00 6.31868161e-01 2.69356944e-02
  0.00000000e+00 2.00000000e+00 1.00000000e+00 2.00000000e+00
  8.26346502e-01 2.62398612e-01 9.79317897e-01 7.58906345e-01]]
[[0.         2.         0.041505   0.64774283 0.7000008  1.
  0.97252758 0.03181988 0.         0.         1.         0.
  0.94752148 0.6554307  0.88614739 0.50391366]
 [2.         0.         0.30996    0.84202065 0.9000016  1.
  0.76373632 0.2175731  0.         1.         1.         0.
  0.29618395 0.88614739 0.85218865 0.50391366]
 [3.         0.         0.18336048 0.29618395 0.5        1.
  0.47802197 0.05867882 1.         1.         2.         0.
  0.84202065 0.0436732  0.24455523 0.50391366]
 [1.         1.         0.26279185 0.26239861 0.5        0.
  0.67582421 0.01379875 2.         2.         0.         0.
  0.55372743 0.39841284 0.0436732  0.50391366]
 [1.         0.         0.3593523  0.37138871 0.2999992  0.
  0.47802197 0.58482732 2.         1.         2.         0.
  0.0436732  0.01501027 0.8263465  0.59878947]
 [2.         2.         0.43770547 0.24455523 0.7000008  1.
  0.15934058 0.07762602 0.         2.         2.         0.
  0.75787137 0.31221238 0.8263465  0.50391366]
 [2.         2.         0.02812941 0.16557314 0.7000008  1.
  0.58791211 0.02095818 0.         0.         0.         0.
  0.88614739 0.18658964 0.0436732  0.50391366]
 [1.         1.         0.23803873 0.72612834 0.7000008  0.
  0.43406592 0.15711763 2.         1.         1.         0.
  0.16557314 0.91782962 0.86704202 0.59878947]
 [2.         1.         0.46729085 0.98694376 0.2999992  0.
  0.56593408 0.29026317 1.         0.         1.         0.
  0.47129428 0.6554307  0.88614739 0.50391366]
 [0.         2.         0.06649942 0.09625996 0.9000016  0.
  0.68681323 0.40008914 2.         2.         2.         0.
  0.83685346 0.09625996 0.39841284 0.50391366]
 [2.         0.         0.36359918 0.0436732  0.5        0.
  0.9065935  0.51683133 0.         2.         2.         0.
  0.26239861 0.24455523 0.8263465  0.50391366]
 [0.         2.         0.56439753 0.52447314 0.2999992  1.
  0.26923072 0.32679467 1.         1.         1.         0.
  0.90451061 0.01501027 0.85218865 0.50391366]
 [2.         0.         0.02820026 0.90451061 0.7000008  1.
  0.9945056  0.11831889 2.         1.         2.         0.
  0.8766912  0.29618395 0.24455523 0.50391366]
 [0.         2.         0.2722943  0.41136689 0.2999992  0.
  0.98351659 0.3322353  0.         0.         0.         0.
  0.89080549 0.18658964 0.0436732  0.50391366]
 [2.         2.         0.05889315 0.99444858 0.5        0.
  0.63186816 0.26059526 0.         1.         0.         0.
  0.82100415 0.14357878 0.0436732  0.50391366]
 [1.         1.         0.02833208 0.54417572 0.5        1.
  0.28021973 0.55123353 0.         1.         2.         0.
  0.0436732  0.01501027 0.24455523 0.59878947]
 [3.         0.         0.31931082 0.59878947 0.9000016  0.
  0.07142848 0.11154826 1.         0.         1.         0.
  0.29618395 0.279593   0.74542871 0.59878947]
 [0.         2.         0.99515975 0.279593   0.0999984  1.
  0.75274731 0.50074335 0.         1.         2.         0.
  0.82100415 0.14357878 0.39841284 0.50391366]
 [3.         1.         0.87325029 0.57227073 0.5        1.
  0.9065935  0.50993883 2.         2.         1.         0.
  0.42397547 0.3277152  0.88614739 0.50391366]
 [1.         2.         0.05955607 0.84713198 0.5        1.
  0.55494507 0.7343961  2.         1.         2.         0.
  0.94339225 0.63198159 0.39841284 0.50391366]
 [1.         1.         0.30742896 0.18658964 0.5        0.
  0.52197803 0.61849444 0.         1.         2.         0.
  0.5812766  0.22601193 0.8263465  0.50391366]
 [2.         1.         0.43207419 0.85218865 0.0999984  1.
  0.65384619 0.14718903 0.         0.         0.         0.
  0.89080549 0.18658964 0.0436732  0.50391366]
 [1.         2.         0.55400003 0.99815678 0.2999992  1.
  0.59890112 0.71342079 2.         1.         2.         0.
  0.35727442 0.63198159 0.24455523 0.50391366]
 [3.         0.         0.79205126 0.68498992 0.5        1.
  0.84065942 0.70574187 1.         1.         2.         0.
  0.1205111  0.66299556 0.24455523 0.50391366]
 [3.         2.         0.59384812 0.16557314 0.5        1.
  0.86263744 0.7615702  1.         1.         1.         0.
  0.18658964 0.63198159 0.88614739 0.50391366]
 [0.         1.         0.58488517 0.43625651 0.7000008  1.
  0.5        0.50726063 1.         2.         0.         0.
  0.7390824  0.09625996 0.22601193 0.59878947]
 [0.         2.         0.75390367 0.1205111  0.5        1.
  0.67582421 0.29910639 2.         2.         1.         0.
  0.79334752 0.63992789 0.88614739 0.50391366]
 [0.         0.         0.03753347 0.86214256 0.0999984  0.
  0.91758251 0.83629983 1.         1.         2.         0.
  0.47129428 0.61567675 0.1205111  0.59878947]
 [3.         1.         0.94585134 0.0436732  0.0999984  0.
  0.43406592 0.37910969 2.         2.         2.         0.
  0.79334752 0.63992789 0.8263465  0.50391366]
 [1.         0.         0.90688586 0.75787137 0.0999984  1.
  0.67582421 0.6059201  0.         1.         1.         0.
  0.89080549 0.91782962 0.86704202 0.59878947]
 [2.         0.         0.84071128 0.01501027 0.0999984  0.
  0.97252758 0.51111759 1.         2.         0.         0.
  0.7390824  0.09625996 0.22601193 0.59878947]
 [1.         2.         0.90576627 0.85218865 0.2999992  1.
  0.14835157 0.02955326 2.         2.         0.         0.
  0.22601193 0.09625996 0.22601193 0.50391366]
 [3.         1.         0.06729967 0.09625996 0.5        1.
  0.68681323 0.93976475 2.         0.         2.         0.
  0.26239861 0.71280933 0.39841284 0.50391366]
 [3.         0.         0.5182687  0.41136689 0.2999992  0.
  0.3351648  0.87772715 2.         2.         1.         0.
  0.81013485 0.24455523 0.85218865 0.50391366]
 [3.         0.         0.5736865  0.61567675 0.7000008  1.
  0.18131861 0.83545085 2.         1.         2.         0.
  0.39841284 0.61567675 0.1205111  0.59878947]]
22:33:42 bandwidth of the KDEs:
[0.88923466 0.55716962 0.10836956 0.25310102 0.1103781  0.35071888
 0.20278264 0.19167227 0.75763937 0.64940517 0.62175812 0.71385355
 0.23155552 0.23998989 0.31023707 0.2445819 ]
[0.97996309 0.74953192 0.271724   0.27683138 0.20992858 0.43471846
 0.22848991 0.24590564 0.76312998 0.6282299  0.70626109 0.001
 0.26209239 0.2490585  0.29627559 0.03679576]
22:33:42 l(x) = 1.007577806969994e-07
22:33:42 g(x) = inf
22:33:42 best_vector: [3, 2, 0.054763018803672264, 0.7135916779463756, 0.18321293427384594, 0, 0.03436261419533504, 0.5439674977303791, 1, 2, 1, 2, 0.5091191192694912, 0.832348490886967, 0.6792814541339189, 0.3387275725921214], inf, 1.007577806969994e-07, inf
22:33:42 done sampling a new configuration.
22:33:42 HBMASTER: schedule new run for iteration 9
22:33:42 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
22:33:42 HBMASTER: submitting job (9, 0, 7) to dispatcher
22:33:42 DISPATCHER: trying to submit job (9, 0, 7)
22:33:42 DISPATCHER: trying to notify the job_runner thread.
22:33:42 HBMASTER: job (9, 0, 7) submitted to dispatcher
22:33:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:33:42 DISPATCHER: Trying to submit another job.
22:33:42 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:33:42 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:33:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:33:42 WORKER: start processing job (9, 0, 7)
22:33:42 WORKER: args: ()
22:33:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00128684440193727, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0510173658541622}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:33:49 DISPATCHER: Starting worker discovery
22:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:49 DISPATCHER: Finished worker discovery
22:34:49 DISPATCHER: Starting worker discovery
22:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:49 DISPATCHER: Finished worker discovery
22:35:49 DISPATCHER: Starting worker discovery
22:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:49 DISPATCHER: Finished worker discovery
22:36:01 WORKER: done with job (9, 0, 7), trying to register it.
22:36:01 WORKER: registered result for job (9, 0, 7) with dispatcher
22:36:01 DISPATCHER: job (9, 0, 7) finished
22:36:01 DISPATCHER: register_result: lock acquired
22:36:01 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:36:01 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00128684440193727, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0510173658541622}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43863081246118574, 'info': {'data02': 0.43863081246118574, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00128684440193727, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0510173658541622}"}}
exception: None

22:36:01 job_callback for (9, 0, 7) started
22:36:01 DISPATCHER: Trying to submit another job.
22:36:01 job_callback for (9, 0, 7) got condition
22:36:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:36:01 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.739568





22:36:01 HBMASTER: Trying to run another job!
22:36:01 job_callback for (9, 0, 7) finished
22:36:01 start sampling a new configuration.
22:36:01 done sampling a new configuration.
22:36:01 HBMASTER: schedule new run for iteration 9
22:36:01 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
22:36:01 HBMASTER: submitting job (9, 0, 8) to dispatcher
22:36:01 DISPATCHER: trying to submit job (9, 0, 8)
22:36:01 DISPATCHER: trying to notify the job_runner thread.
22:36:01 HBMASTER: job (9, 0, 8) submitted to dispatcher
22:36:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:36:01 DISPATCHER: Trying to submit another job.
22:36:01 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:36:01 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:36:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:36:01 WORKER: start processing job (9, 0, 8)
22:36:01 WORKER: args: ()
22:36:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0037478194410494018, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.011554690996451818, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 109, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:36:49 DISPATCHER: Starting worker discovery
22:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:49 DISPATCHER: Finished worker discovery
22:37:49 DISPATCHER: Starting worker discovery
22:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:49 DISPATCHER: Finished worker discovery
22:38:18 WORKER: done with job (9, 0, 8), trying to register it.
22:38:18 WORKER: registered result for job (9, 0, 8) with dispatcher
22:38:18 DISPATCHER: job (9, 0, 8) finished
22:38:18 DISPATCHER: register_result: lock acquired
22:38:18 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:38:18 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0037478194410494018, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.011554690996451818, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 109, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.552973250740247, 'info': {'data02': 0.552973250740247, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0037478194410494018, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.011554690996451818, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 109, 'num_filters_3': 63}"}}
exception: None

22:38:18 job_callback for (9, 0, 8) started
22:38:18 DISPATCHER: Trying to submit another job.
22:38:18 job_callback for (9, 0, 8) got condition
22:38:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:38:18 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.739568





22:38:18 HBMASTER: Trying to run another job!
22:38:18 job_callback for (9, 0, 8) finished
22:38:18 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
22:38:18 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
22:38:18 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
22:38:18 HBMASTER: schedule new run for iteration 9
22:38:18 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
22:38:18 HBMASTER: submitting job (9, 0, 2) to dispatcher
22:38:18 DISPATCHER: trying to submit job (9, 0, 2)
22:38:18 DISPATCHER: trying to notify the job_runner thread.
22:38:18 HBMASTER: job (9, 0, 2) submitted to dispatcher
22:38:18 DISPATCHER: Trying to submit another job.
22:38:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:38:18 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:38:18 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:38:18 WORKER: start processing job (9, 0, 2)
22:38:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:38:18 WORKER: args: ()
22:38:18 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}, 'budget': 400.0, 'working_directory': '.'}
22:38:49 DISPATCHER: Starting worker discovery
22:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:49 DISPATCHER: Finished worker discovery
22:39:49 DISPATCHER: Starting worker discovery
22:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:49 DISPATCHER: Finished worker discovery
22:40:49 DISPATCHER: Starting worker discovery
22:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:49 DISPATCHER: Finished worker discovery
22:41:49 DISPATCHER: Starting worker discovery
22:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:49 DISPATCHER: Finished worker discovery
22:42:49 DISPATCHER: Starting worker discovery
22:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:49 DISPATCHER: Finished worker discovery
22:43:49 DISPATCHER: Starting worker discovery
22:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:49 DISPATCHER: Finished worker discovery
22:44:49 DISPATCHER: Starting worker discovery
22:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:49 DISPATCHER: Finished worker discovery
22:45:04 WORKER: done with job (9, 0, 2), trying to register it.
22:45:04 WORKER: registered result for job (9, 0, 2) with dispatcher
22:45:04 DISPATCHER: job (9, 0, 2) finished
22:45:04 DISPATCHER: register_result: lock acquired
22:45:04 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:45:04 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.64395387773928, 'info': {'data02': 0.64395387773928, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}"}}
exception: None

22:45:04 job_callback for (9, 0, 2) started
22:45:04 DISPATCHER: Trying to submit another job.
22:45:04 job_callback for (9, 0, 2) got condition
22:45:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:04 HBMASTER: Trying to run another job!
22:45:04 job_callback for (9, 0, 2) finished
22:45:04 HBMASTER: schedule new run for iteration 9
22:45:04 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
22:45:04 HBMASTER: submitting job (9, 0, 4) to dispatcher
22:45:04 DISPATCHER: trying to submit job (9, 0, 4)
22:45:04 DISPATCHER: trying to notify the job_runner thread.
22:45:04 HBMASTER: job (9, 0, 4) submitted to dispatcher
22:45:04 DISPATCHER: Trying to submit another job.
22:45:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:04 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:45:04 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:45:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:04 WORKER: start processing job (9, 0, 4)
22:45:04 WORKER: args: ()
22:45:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016603209062453453, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.05355830545118444, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 70}, 'budget': 400.0, 'working_directory': '.'}
22:45:49 DISPATCHER: Starting worker discovery
22:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:49 DISPATCHER: Finished worker discovery
22:46:49 DISPATCHER: Starting worker discovery
22:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:49 DISPATCHER: Finished worker discovery
22:47:49 DISPATCHER: Starting worker discovery
22:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:49 DISPATCHER: Finished worker discovery
22:48:49 DISPATCHER: Starting worker discovery
22:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:49 DISPATCHER: Finished worker discovery
22:49:49 DISPATCHER: Starting worker discovery
22:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:49 DISPATCHER: Finished worker discovery
22:50:49 DISPATCHER: Starting worker discovery
22:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:49 DISPATCHER: Finished worker discovery
22:51:49 DISPATCHER: Starting worker discovery
22:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:49 DISPATCHER: Finished worker discovery
22:51:51 WORKER: done with job (9, 0, 4), trying to register it.
22:51:51 WORKER: registered result for job (9, 0, 4) with dispatcher
22:51:51 DISPATCHER: job (9, 0, 4) finished
22:51:51 DISPATCHER: register_result: lock acquired
22:51:51 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:51:51 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016603209062453453, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.05355830545118444, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 70}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5960453929530227, 'info': {'data02': 0.5960453929530227, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016603209062453453, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.05355830545118444, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 70}"}}
exception: None

22:51:51 job_callback for (9, 0, 4) started
22:51:51 job_callback for (9, 0, 4) got condition
22:51:51 DISPATCHER: Trying to submit another job.
22:51:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:51 HBMASTER: Trying to run another job!
22:51:51 job_callback for (9, 0, 4) finished
22:51:51 HBMASTER: schedule new run for iteration 9
22:51:51 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
22:51:51 HBMASTER: submitting job (9, 0, 6) to dispatcher
22:51:51 DISPATCHER: trying to submit job (9, 0, 6)
22:51:51 DISPATCHER: trying to notify the job_runner thread.
22:51:51 HBMASTER: job (9, 0, 6) submitted to dispatcher
22:51:51 DISPATCHER: Trying to submit another job.
22:51:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:51 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:51:51 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:51:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:51 WORKER: start processing job (9, 0, 6)
22:51:51 WORKER: args: ()
22:51:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023519590082998498, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.017878017476812978, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 56}, 'budget': 400.0, 'working_directory': '.'}
22:52:49 DISPATCHER: Starting worker discovery
22:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:49 DISPATCHER: Finished worker discovery
22:53:49 DISPATCHER: Starting worker discovery
22:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:49 DISPATCHER: Finished worker discovery
22:54:49 DISPATCHER: Starting worker discovery
22:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:49 DISPATCHER: Finished worker discovery
22:55:49 DISPATCHER: Starting worker discovery
22:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:49 DISPATCHER: Finished worker discovery
22:56:49 DISPATCHER: Starting worker discovery
22:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:49 DISPATCHER: Finished worker discovery
22:57:49 DISPATCHER: Starting worker discovery
22:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:49 DISPATCHER: Finished worker discovery
22:58:37 WORKER: done with job (9, 0, 6), trying to register it.
22:58:37 WORKER: registered result for job (9, 0, 6) with dispatcher
22:58:37 DISPATCHER: job (9, 0, 6) finished
22:58:37 DISPATCHER: register_result: lock acquired
22:58:37 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:58:37 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023519590082998498, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.017878017476812978, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 56}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5387888464988265, 'info': {'data02': 0.5387888464988265, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023519590082998498, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.017878017476812978, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 56}"}}
exception: None

22:58:37 job_callback for (9, 0, 6) started
22:58:37 job_callback for (9, 0, 6) got condition
22:58:37 DISPATCHER: Trying to submit another job.
22:58:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:37 HBMASTER: Trying to run another job!
22:58:37 job_callback for (9, 0, 6) finished
22:58:37 ITERATION: Advancing config (9, 0, 2) to next budget 1200.000000
22:58:37 HBMASTER: schedule new run for iteration 9
22:58:37 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
22:58:37 HBMASTER: submitting job (9, 0, 2) to dispatcher
22:58:37 DISPATCHER: trying to submit job (9, 0, 2)
22:58:37 DISPATCHER: trying to notify the job_runner thread.
22:58:37 HBMASTER: job (9, 0, 2) submitted to dispatcher
22:58:37 DISPATCHER: Trying to submit another job.
22:58:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:37 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:58:37 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:58:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:37 WORKER: start processing job (9, 0, 2)
22:58:37 WORKER: args: ()
22:58:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}, 'budget': 1200.0, 'working_directory': '.'}
22:58:49 DISPATCHER: Starting worker discovery
22:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:49 DISPATCHER: Finished worker discovery
22:59:49 DISPATCHER: Starting worker discovery
22:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:49 DISPATCHER: Finished worker discovery
23:00:49 DISPATCHER: Starting worker discovery
23:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:49 DISPATCHER: Finished worker discovery
23:01:49 DISPATCHER: Starting worker discovery
23:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:49 DISPATCHER: Finished worker discovery
23:02:49 DISPATCHER: Starting worker discovery
23:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:49 DISPATCHER: Finished worker discovery
23:03:49 DISPATCHER: Starting worker discovery
23:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:49 DISPATCHER: Finished worker discovery
23:04:49 DISPATCHER: Starting worker discovery
23:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:49 DISPATCHER: Finished worker discovery
23:05:49 DISPATCHER: Starting worker discovery
23:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:49 DISPATCHER: Finished worker discovery
23:06:49 DISPATCHER: Starting worker discovery
23:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:49 DISPATCHER: Finished worker discovery
23:07:49 DISPATCHER: Starting worker discovery
23:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:49 DISPATCHER: Finished worker discovery
23:08:49 DISPATCHER: Starting worker discovery
23:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:49 DISPATCHER: Finished worker discovery
23:09:49 DISPATCHER: Starting worker discovery
23:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:49 DISPATCHER: Finished worker discovery
23:10:49 DISPATCHER: Starting worker discovery
23:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:49 DISPATCHER: Finished worker discovery
23:11:49 DISPATCHER: Starting worker discovery
23:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:49 DISPATCHER: Finished worker discovery
23:12:49 DISPATCHER: Starting worker discovery
23:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:49 DISPATCHER: Finished worker discovery
23:13:49 DISPATCHER: Starting worker discovery
23:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:49 DISPATCHER: Finished worker discovery
23:14:49 DISPATCHER: Starting worker discovery
23:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:49 DISPATCHER: Finished worker discovery
23:15:49 DISPATCHER: Starting worker discovery
23:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:49 DISPATCHER: Finished worker discovery
23:16:49 DISPATCHER: Starting worker discovery
23:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:49 DISPATCHER: Finished worker discovery
23:17:49 DISPATCHER: Starting worker discovery
23:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:49 DISPATCHER: Finished worker discovery
23:18:44 WORKER: done with job (9, 0, 2), trying to register it.
23:18:44 WORKER: registered result for job (9, 0, 2) with dispatcher
23:18:44 DISPATCHER: job (9, 0, 2) finished
23:18:44 DISPATCHER: register_result: lock acquired
23:18:44 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:18:44 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6820671828240157, 'info': {'data02': 0.6820671828240157, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010067799066590156, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01878900793725154, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 121, 'num_filters_4': 106}"}}
exception: None

23:18:44 job_callback for (9, 0, 2) started
23:18:44 DISPATCHER: Trying to submit another job.
23:18:44 job_callback for (9, 0, 2) got condition
23:18:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:44 HBMASTER: Trying to run another job!
23:18:44 job_callback for (9, 0, 2) finished
23:18:44 HBMASTER: shutdown initiated, shutdown_workers = True
23:18:44 WORKER: shutting down now!
23:18:45 DISPATCHER: Dispatcher shutting down
23:18:45 DISPATCHER: discover_workers shutting down
23:18:45 DISPATCHER: Trying to submit another job.
23:18:45 DISPATCHER: 'discover_worker' thread exited
23:18:45 DISPATCHER: job_runner shutting down
23:18:45 DISPATCHER: 'job_runner' thread exited
23:18:45 DISPATCHER: shut down complete
23:18:45 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f5c4c3aba20; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31514>
23:18:45 WORKER: No dispatcher found. Waiting for one to initiate contact.
23:18:45 WORKER: start listening for jobs
23:18:45 wait_for_workers trying to get the condition
23:18:45 DISPATCHER: started the 'discover_worker' thread
23:18:45 DISPATCHER: started the 'job_runner' thread
23:18:45 DISPATCHER: Pyro daemon running on localhost:33397
23:18:45 HBMASTER: only 0 worker(s) available, waiting for at least 1.
23:18:45 DISPATCHER: Starting worker discovery
23:18:45 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
23:18:45 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1575140037953214272
23:18:45 HBMASTER: number of workers changed to 1
23:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:45 adjust_queue_size: lock accquired
23:18:45 HBMASTER: adjusted queue size to (0, 1)
23:18:45 DISPATCHER: Finished worker discovery
23:18:45 DISPATCHER: A new worker triggered discover_worker
23:18:45 DISPATCHER: Trying to submit another job.
23:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:45 Enough workers to start this run!
23:18:45 DISPATCHER: Starting worker discovery
23:18:45 HBMASTER: starting run at 1583878725.2323427
23:18:45 start sampling a new configuration.
23:18:45 done sampling a new configuration.
23:18:45 HBMASTER: schedule new run for iteration 0
23:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:45 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
23:18:45 HBMASTER: submitting job (0, 0, 0) to dispatcher
23:18:45 DISPATCHER: trying to submit job (0, 0, 0)
23:18:45 DISPATCHER: Finished worker discovery
23:18:45 DISPATCHER: trying to notify the job_runner thread.
23:18:45 HBMASTER: job (0, 0, 0) submitted to dispatcher
23:18:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:18:45 DISPATCHER: Trying to submit another job.
23:18:45 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:18:45 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:18:45 WORKER: start processing job (0, 0, 0)
23:18:45 WORKER: args: ()
23:18:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 22, 'lr': 0.03790961724388365, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.013852572621018936}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:19:33 WORKER: done with job (0, 0, 0), trying to register it.
23:19:33 WORKER: registered result for job (0, 0, 0) with dispatcher
23:19:33 DISPATCHER: job (0, 0, 0) finished
23:19:33 DISPATCHER: register_result: lock acquired
23:19:33 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:19:33 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 22, 'lr': 0.03790961724388365, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.013852572621018936}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 22, 'lr': 0.03790961724388365, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.013852572621018936}"}}
exception: None

23:19:33 job_callback for (0, 0, 0) started
23:19:33 DISPATCHER: Trying to submit another job.
23:19:33 job_callback for (0, 0, 0) got condition
23:19:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:19:33 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:19:33 HBMASTER: Trying to run another job!
23:19:33 job_callback for (0, 0, 0) finished
23:19:33 start sampling a new configuration.
23:19:33 done sampling a new configuration.
23:19:33 HBMASTER: schedule new run for iteration 0
23:19:33 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
23:19:33 HBMASTER: submitting job (0, 0, 1) to dispatcher
23:19:33 DISPATCHER: trying to submit job (0, 0, 1)
23:19:33 DISPATCHER: trying to notify the job_runner thread.
23:19:33 HBMASTER: job (0, 0, 1) submitted to dispatcher
23:19:33 DISPATCHER: Trying to submit another job.
23:19:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:19:33 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:19:33 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:19:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:19:33 WORKER: start processing job (0, 0, 1)
23:19:33 WORKER: args: ()
23:19:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 65, 'last_n_outputs': 9, 'lr': 0.02060069299307863, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.12536451014156688}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:19:45 DISPATCHER: Starting worker discovery
23:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:45 DISPATCHER: Finished worker discovery
23:20:21 WORKER: done with job (0, 0, 1), trying to register it.
23:20:21 WORKER: registered result for job (0, 0, 1) with dispatcher
23:20:21 DISPATCHER: job (0, 0, 1) finished
23:20:21 DISPATCHER: register_result: lock acquired
23:20:21 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:20:21 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 65, 'last_n_outputs': 9, 'lr': 0.02060069299307863, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.12536451014156688}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 65, 'last_n_outputs': 9, 'lr': 0.02060069299307863, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.12536451014156688}"}}
exception: None

23:20:21 job_callback for (0, 0, 1) started
23:20:21 DISPATCHER: Trying to submit another job.
23:20:21 job_callback for (0, 0, 1) got condition
23:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:21 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:20:21 HBMASTER: Trying to run another job!
23:20:21 job_callback for (0, 0, 1) finished
23:20:21 start sampling a new configuration.
23:20:21 done sampling a new configuration.
23:20:21 HBMASTER: schedule new run for iteration 0
23:20:21 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
23:20:21 HBMASTER: submitting job (0, 0, 2) to dispatcher
23:20:21 DISPATCHER: trying to submit job (0, 0, 2)
23:20:21 DISPATCHER: trying to notify the job_runner thread.
23:20:21 HBMASTER: job (0, 0, 2) submitted to dispatcher
23:20:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:21 DISPATCHER: Trying to submit another job.
23:20:21 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:20:21 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:21 WORKER: start processing job (0, 0, 2)
23:20:21 WORKER: args: ()
23:20:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 23, 'lr': 0.0070422116242460754, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.027648646874075148}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:20:45 DISPATCHER: Starting worker discovery
23:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:45 DISPATCHER: Finished worker discovery
23:21:09 WORKER: done with job (0, 0, 2), trying to register it.
23:21:09 WORKER: registered result for job (0, 0, 2) with dispatcher
23:21:09 DISPATCHER: job (0, 0, 2) finished
23:21:09 DISPATCHER: register_result: lock acquired
23:21:09 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:21:09 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 23, 'lr': 0.0070422116242460754, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.027648646874075148}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12260982550267277, 'info': {'data02': 0.12260982550267277, 'config': "{'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 23, 'lr': 0.0070422116242460754, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.027648646874075148}"}}
exception: None

23:21:09 job_callback for (0, 0, 2) started
23:21:09 job_callback for (0, 0, 2) got condition
23:21:09 DISPATCHER: Trying to submit another job.
23:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:21:09 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:21:09 HBMASTER: Trying to run another job!
23:21:09 job_callback for (0, 0, 2) finished
23:21:09 start sampling a new configuration.
23:21:09 done sampling a new configuration.
23:21:09 HBMASTER: schedule new run for iteration 0
23:21:09 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
23:21:09 HBMASTER: submitting job (0, 0, 3) to dispatcher
23:21:09 DISPATCHER: trying to submit job (0, 0, 3)
23:21:09 DISPATCHER: trying to notify the job_runner thread.
23:21:09 HBMASTER: job (0, 0, 3) submitted to dispatcher
23:21:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:21:09 DISPATCHER: Trying to submit another job.
23:21:09 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:21:09 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:21:09 WORKER: start processing job (0, 0, 3)
23:21:09 WORKER: args: ()
23:21:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 40, 'last_n_outputs': 21, 'lr': 0.09075767429260319, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.027042963916606266}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:21:45 DISPATCHER: Starting worker discovery
23:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:45 DISPATCHER: Finished worker discovery
23:21:57 WORKER: done with job (0, 0, 3), trying to register it.
23:21:57 WORKER: registered result for job (0, 0, 3) with dispatcher
23:21:57 DISPATCHER: job (0, 0, 3) finished
23:21:57 DISPATCHER: register_result: lock acquired
23:21:57 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:21:57 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 40, 'last_n_outputs': 21, 'lr': 0.09075767429260319, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.027042963916606266}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 40, 'last_n_outputs': 21, 'lr': 0.09075767429260319, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.027042963916606266}"}}
exception: None

23:21:57 job_callback for (0, 0, 3) started
23:21:57 job_callback for (0, 0, 3) got condition
23:21:57 DISPATCHER: Trying to submit another job.
23:21:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:21:57 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:21:57 HBMASTER: Trying to run another job!
23:21:57 job_callback for (0, 0, 3) finished
23:21:57 start sampling a new configuration.
23:21:57 done sampling a new configuration.
23:21:57 HBMASTER: schedule new run for iteration 0
23:21:57 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
23:21:57 HBMASTER: submitting job (0, 0, 4) to dispatcher
23:21:57 DISPATCHER: trying to submit job (0, 0, 4)
23:21:57 DISPATCHER: trying to notify the job_runner thread.
23:21:57 HBMASTER: job (0, 0, 4) submitted to dispatcher
23:21:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:21:57 DISPATCHER: Trying to submit another job.
23:21:57 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:21:57 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:21:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:21:57 WORKER: start processing job (0, 0, 4)
23:21:57 WORKER: args: ()
23:21:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 34, 'lr': 0.007838146906362168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.11187966984767499}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:22:45 DISPATCHER: Starting worker discovery
23:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:45 DISPATCHER: Finished worker discovery
23:22:46 WORKER: done with job (0, 0, 4), trying to register it.
23:22:46 WORKER: registered result for job (0, 0, 4) with dispatcher
23:22:46 DISPATCHER: job (0, 0, 4) finished
23:22:46 DISPATCHER: register_result: lock acquired
23:22:46 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:22:46 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 34, 'lr': 0.007838146906362168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.11187966984767499}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5796449164175196, 'info': {'data02': 0.5796449164175196, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 34, 'lr': 0.007838146906362168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.11187966984767499}"}}
exception: None

23:22:46 job_callback for (0, 0, 4) started
23:22:46 job_callback for (0, 0, 4) got condition
23:22:46 DISPATCHER: Trying to submit another job.
23:22:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:46 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:22:46 HBMASTER: Trying to run another job!
23:22:46 job_callback for (0, 0, 4) finished
23:22:46 start sampling a new configuration.
23:22:46 done sampling a new configuration.
23:22:46 HBMASTER: schedule new run for iteration 0
23:22:46 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
23:22:46 HBMASTER: submitting job (0, 0, 5) to dispatcher
23:22:46 DISPATCHER: trying to submit job (0, 0, 5)
23:22:46 DISPATCHER: trying to notify the job_runner thread.
23:22:46 HBMASTER: job (0, 0, 5) submitted to dispatcher
23:22:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:46 DISPATCHER: Trying to submit another job.
23:22:46 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:22:46 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:22:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:46 WORKER: start processing job (0, 0, 5)
23:22:46 WORKER: args: ()
23:22:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 39, 'lr': 0.029432508086195526, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.0321237856154045}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:23:34 WORKER: done with job (0, 0, 5), trying to register it.
23:23:34 WORKER: registered result for job (0, 0, 5) with dispatcher
23:23:34 DISPATCHER: job (0, 0, 5) finished
23:23:34 DISPATCHER: register_result: lock acquired
23:23:34 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:23:34 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 39, 'lr': 0.029432508086195526, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.0321237856154045}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 39, 'lr': 0.029432508086195526, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.0321237856154045}"}}
exception: None

23:23:34 job_callback for (0, 0, 5) started
23:23:34 DISPATCHER: Trying to submit another job.
23:23:34 job_callback for (0, 0, 5) got condition
23:23:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:23:34 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:23:34 HBMASTER: Trying to run another job!
23:23:34 job_callback for (0, 0, 5) finished
23:23:34 start sampling a new configuration.
23:23:34 done sampling a new configuration.
23:23:34 HBMASTER: schedule new run for iteration 0
23:23:34 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
23:23:34 HBMASTER: submitting job (0, 0, 6) to dispatcher
23:23:34 DISPATCHER: trying to submit job (0, 0, 6)
23:23:34 DISPATCHER: trying to notify the job_runner thread.
23:23:34 HBMASTER: job (0, 0, 6) submitted to dispatcher
23:23:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:23:34 DISPATCHER: Trying to submit another job.
23:23:34 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:23:34 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:23:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:23:34 WORKER: start processing job (0, 0, 6)
23:23:34 WORKER: args: ()
23:23:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 41, 'lr': 0.04768335813855811, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.1810548667387807}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:23:45 DISPATCHER: Starting worker discovery
23:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:45 DISPATCHER: Finished worker discovery
23:24:22 WORKER: done with job (0, 0, 6), trying to register it.
23:24:22 WORKER: registered result for job (0, 0, 6) with dispatcher
23:24:22 DISPATCHER: job (0, 0, 6) finished
23:24:22 DISPATCHER: register_result: lock acquired
23:24:22 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:24:22 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 41, 'lr': 0.04768335813855811, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.1810548667387807}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 41, 'lr': 0.04768335813855811, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.1810548667387807}"}}
exception: None

23:24:22 job_callback for (0, 0, 6) started
23:24:22 DISPATCHER: Trying to submit another job.
23:24:22 job_callback for (0, 0, 6) got condition
23:24:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:22 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:24:22 HBMASTER: Trying to run another job!
23:24:22 job_callback for (0, 0, 6) finished
23:24:22 start sampling a new configuration.
23:24:22 done sampling a new configuration.
23:24:22 HBMASTER: schedule new run for iteration 0
23:24:22 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
23:24:22 HBMASTER: submitting job (0, 0, 7) to dispatcher
23:24:22 DISPATCHER: trying to submit job (0, 0, 7)
23:24:22 DISPATCHER: trying to notify the job_runner thread.
23:24:22 HBMASTER: job (0, 0, 7) submitted to dispatcher
23:24:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:22 DISPATCHER: Trying to submit another job.
23:24:22 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:24:22 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:24:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:22 WORKER: start processing job (0, 0, 7)
23:24:22 WORKER: args: ()
23:24:22 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 27, 'lr': 0.0026087547106101575, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.017356824861553998}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:24:45 DISPATCHER: Starting worker discovery
23:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:45 DISPATCHER: Finished worker discovery
23:25:11 WORKER: done with job (0, 0, 7), trying to register it.
23:25:11 WORKER: registered result for job (0, 0, 7) with dispatcher
23:25:11 DISPATCHER: job (0, 0, 7) finished
23:25:11 DISPATCHER: register_result: lock acquired
23:25:11 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:25:11 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 27, 'lr': 0.0026087547106101575, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.017356824861553998}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.011085471514973008, 'info': {'data02': 0.011085471514973008, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 27, 'lr': 0.0026087547106101575, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.017356824861553998}"}}
exception: None

23:25:11 job_callback for (0, 0, 7) started
23:25:11 DISPATCHER: Trying to submit another job.
23:25:11 job_callback for (0, 0, 7) got condition
23:25:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:11 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:25:11 HBMASTER: Trying to run another job!
23:25:11 job_callback for (0, 0, 7) finished
23:25:11 start sampling a new configuration.
23:25:11 done sampling a new configuration.
23:25:11 HBMASTER: schedule new run for iteration 0
23:25:11 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
23:25:11 HBMASTER: submitting job (0, 0, 8) to dispatcher
23:25:11 DISPATCHER: trying to submit job (0, 0, 8)
23:25:11 DISPATCHER: trying to notify the job_runner thread.
23:25:11 HBMASTER: job (0, 0, 8) submitted to dispatcher
23:25:11 DISPATCHER: Trying to submit another job.
23:25:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:11 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:25:11 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:25:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:11 WORKER: start processing job (0, 0, 8)
23:25:11 WORKER: args: ()
23:25:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.043882513076569464, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.08065227158073987}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:25:45 DISPATCHER: Starting worker discovery
23:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:45 DISPATCHER: Finished worker discovery
23:25:59 WORKER: done with job (0, 0, 8), trying to register it.
23:25:59 WORKER: registered result for job (0, 0, 8) with dispatcher
23:25:59 DISPATCHER: job (0, 0, 8) finished
23:25:59 DISPATCHER: register_result: lock acquired
23:25:59 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:25:59 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.043882513076569464, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.08065227158073987}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.043882513076569464, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.08065227158073987}"}}
exception: None

23:25:59 job_callback for (0, 0, 8) started
23:25:59 job_callback for (0, 0, 8) got condition
23:25:59 DISPATCHER: Trying to submit another job.
23:25:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:59 HBMASTER: Trying to run another job!
23:25:59 job_callback for (0, 0, 8) finished
23:25:59 start sampling a new configuration.
23:25:59 done sampling a new configuration.
23:25:59 HBMASTER: schedule new run for iteration 0
23:25:59 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
23:25:59 HBMASTER: submitting job (0, 0, 9) to dispatcher
23:25:59 DISPATCHER: trying to submit job (0, 0, 9)
23:25:59 DISPATCHER: trying to notify the job_runner thread.
23:25:59 HBMASTER: job (0, 0, 9) submitted to dispatcher
23:25:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:59 DISPATCHER: Trying to submit another job.
23:25:59 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:25:59 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:25:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:59 WORKER: start processing job (0, 0, 9)
23:25:59 WORKER: args: ()
23:25:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:26:45 DISPATCHER: Starting worker discovery
23:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:45 DISPATCHER: Finished worker discovery
23:26:47 WORKER: done with job (0, 0, 9), trying to register it.
23:26:47 WORKER: registered result for job (0, 0, 9) with dispatcher
23:26:47 DISPATCHER: job (0, 0, 9) finished
23:26:47 DISPATCHER: register_result: lock acquired
23:26:47 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:26:47 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49123811969030584, 'info': {'data02': 0.49123811969030584, 'config': "{'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}"}}
exception: None

23:26:47 job_callback for (0, 0, 9) started
23:26:47 DISPATCHER: Trying to submit another job.
23:26:47 job_callback for (0, 0, 9) got condition
23:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:26:47 HBMASTER: Trying to run another job!
23:26:47 job_callback for (0, 0, 9) finished
23:26:47 start sampling a new configuration.
23:26:47 done sampling a new configuration.
23:26:47 HBMASTER: schedule new run for iteration 0
23:26:47 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
23:26:47 HBMASTER: submitting job (0, 0, 10) to dispatcher
23:26:47 DISPATCHER: trying to submit job (0, 0, 10)
23:26:47 DISPATCHER: trying to notify the job_runner thread.
23:26:47 HBMASTER: job (0, 0, 10) submitted to dispatcher
23:26:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:26:47 DISPATCHER: Trying to submit another job.
23:26:47 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:26:47 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:26:47 WORKER: start processing job (0, 0, 10)
23:26:47 WORKER: args: ()
23:26:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 49, 'lr': 0.011847879085839763, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.05576192363087311}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:27:35 WORKER: done with job (0, 0, 10), trying to register it.
23:27:35 WORKER: registered result for job (0, 0, 10) with dispatcher
23:27:35 DISPATCHER: job (0, 0, 10) finished
23:27:35 DISPATCHER: register_result: lock acquired
23:27:35 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:27:35 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 49, 'lr': 0.011847879085839763, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.05576192363087311}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 49, 'lr': 0.011847879085839763, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.05576192363087311}"}}
exception: None

23:27:35 job_callback for (0, 0, 10) started
23:27:35 DISPATCHER: Trying to submit another job.
23:27:35 job_callback for (0, 0, 10) got condition
23:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:35 HBMASTER: Trying to run another job!
23:27:35 job_callback for (0, 0, 10) finished
23:27:35 start sampling a new configuration.
23:27:35 done sampling a new configuration.
23:27:35 HBMASTER: schedule new run for iteration 0
23:27:35 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:27:35 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:27:35 DISPATCHER: trying to submit job (0, 0, 11)
23:27:35 DISPATCHER: trying to notify the job_runner thread.
23:27:35 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:27:35 DISPATCHER: Trying to submit another job.
23:27:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:35 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:27:35 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:35 WORKER: start processing job (0, 0, 11)
23:27:35 WORKER: args: ()
23:27:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 1, 'lr': 0.0013409276262503268, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.085775527453203}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:27:45 DISPATCHER: Starting worker discovery
23:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:45 DISPATCHER: Finished worker discovery
23:28:23 WORKER: done with job (0, 0, 11), trying to register it.
23:28:23 WORKER: registered result for job (0, 0, 11) with dispatcher
23:28:23 DISPATCHER: job (0, 0, 11) finished
23:28:23 DISPATCHER: register_result: lock acquired
23:28:23 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:28:23 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 1, 'lr': 0.0013409276262503268, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.085775527453203}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 1, 'lr': 0.0013409276262503268, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.085775527453203}"}}
exception: None

23:28:23 job_callback for (0, 0, 11) started
23:28:23 job_callback for (0, 0, 11) got condition
23:28:23 DISPATCHER: Trying to submit another job.
23:28:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:28:23 HBMASTER: Trying to run another job!
23:28:23 job_callback for (0, 0, 11) finished
23:28:23 start sampling a new configuration.
23:28:23 done sampling a new configuration.
23:28:23 HBMASTER: schedule new run for iteration 0
23:28:23 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
23:28:23 HBMASTER: submitting job (0, 0, 12) to dispatcher
23:28:23 DISPATCHER: trying to submit job (0, 0, 12)
23:28:23 DISPATCHER: trying to notify the job_runner thread.
23:28:23 HBMASTER: job (0, 0, 12) submitted to dispatcher
23:28:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:28:23 DISPATCHER: Trying to submit another job.
23:28:23 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:28:23 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:28:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:28:23 WORKER: start processing job (0, 0, 12)
23:28:23 WORKER: args: ()
23:28:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 9, 'lr': 0.007780931892780437, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01673449627553254}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:28:45 DISPATCHER: Starting worker discovery
23:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:45 DISPATCHER: Finished worker discovery
23:29:11 WORKER: done with job (0, 0, 12), trying to register it.
23:29:11 WORKER: registered result for job (0, 0, 12) with dispatcher
23:29:11 DISPATCHER: job (0, 0, 12) finished
23:29:11 DISPATCHER: register_result: lock acquired
23:29:11 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:29:11 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 9, 'lr': 0.007780931892780437, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01673449627553254}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03469356559870631, 'info': {'data02': 0.03469356559870631, 'config': "{'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 9, 'lr': 0.007780931892780437, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01673449627553254}"}}
exception: None

23:29:11 job_callback for (0, 0, 12) started
23:29:11 job_callback for (0, 0, 12) got condition
23:29:11 DISPATCHER: Trying to submit another job.
23:29:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:29:11 HBMASTER: Trying to run another job!
23:29:11 job_callback for (0, 0, 12) finished
23:29:11 start sampling a new configuration.
23:29:11 done sampling a new configuration.
23:29:11 HBMASTER: schedule new run for iteration 0
23:29:11 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
23:29:11 HBMASTER: submitting job (0, 0, 13) to dispatcher
23:29:11 DISPATCHER: trying to submit job (0, 0, 13)
23:29:11 DISPATCHER: trying to notify the job_runner thread.
23:29:11 HBMASTER: job (0, 0, 13) submitted to dispatcher
23:29:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:29:11 DISPATCHER: Trying to submit another job.
23:29:11 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:29:11 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:29:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:29:11 WORKER: start processing job (0, 0, 13)
23:29:11 WORKER: args: ()
23:29:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 27, 'lr': 0.030497289939106907, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.16944002820982487}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:29:45 DISPATCHER: Starting worker discovery
23:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:45 DISPATCHER: Finished worker discovery
23:29:59 WORKER: done with job (0, 0, 13), trying to register it.
23:29:59 WORKER: registered result for job (0, 0, 13) with dispatcher
23:29:59 DISPATCHER: job (0, 0, 13) finished
23:29:59 DISPATCHER: register_result: lock acquired
23:29:59 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:29:59 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 27, 'lr': 0.030497289939106907, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.16944002820982487}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 27, 'lr': 0.030497289939106907, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.16944002820982487}"}}
exception: None

23:29:59 job_callback for (0, 0, 13) started
23:29:59 job_callback for (0, 0, 13) got condition
23:29:59 DISPATCHER: Trying to submit another job.
23:29:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:29:59 HBMASTER: Trying to run another job!
23:29:59 job_callback for (0, 0, 13) finished
23:29:59 start sampling a new configuration.
23:29:59 done sampling a new configuration.
23:29:59 HBMASTER: schedule new run for iteration 0
23:29:59 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
23:29:59 HBMASTER: submitting job (0, 0, 14) to dispatcher
23:29:59 DISPATCHER: trying to submit job (0, 0, 14)
23:29:59 DISPATCHER: trying to notify the job_runner thread.
23:29:59 HBMASTER: job (0, 0, 14) submitted to dispatcher
23:29:59 DISPATCHER: Trying to submit another job.
23:29:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:29:59 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:29:59 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:29:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:29:59 WORKER: start processing job (0, 0, 14)
23:29:59 WORKER: args: ()
23:29:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 55, 'last_n_outputs': 15, 'lr': 0.004354123940089546, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.12574607270333332}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:30:45 DISPATCHER: Starting worker discovery
23:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:45 DISPATCHER: Finished worker discovery
23:30:47 WORKER: done with job (0, 0, 14), trying to register it.
23:30:47 WORKER: registered result for job (0, 0, 14) with dispatcher
23:30:47 DISPATCHER: job (0, 0, 14) finished
23:30:47 DISPATCHER: register_result: lock acquired
23:30:47 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:30:47 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 55, 'last_n_outputs': 15, 'lr': 0.004354123940089546, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.12574607270333332}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.01953412371316096, 'info': {'data02': -0.01953412371316096, 'config': "{'batch_size': 32, 'hidden_dim': 55, 'last_n_outputs': 15, 'lr': 0.004354123940089546, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.12574607270333332}"}}
exception: None

23:30:47 job_callback for (0, 0, 14) started
23:30:47 DISPATCHER: Trying to submit another job.
23:30:47 job_callback for (0, 0, 14) got condition
23:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:30:47 HBMASTER: Trying to run another job!
23:30:47 job_callback for (0, 0, 14) finished
23:30:47 start sampling a new configuration.
23:30:47 done sampling a new configuration.
23:30:47 HBMASTER: schedule new run for iteration 0
23:30:47 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
23:30:47 HBMASTER: submitting job (0, 0, 15) to dispatcher
23:30:47 DISPATCHER: trying to submit job (0, 0, 15)
23:30:47 DISPATCHER: trying to notify the job_runner thread.
23:30:47 HBMASTER: job (0, 0, 15) submitted to dispatcher
23:30:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:30:47 DISPATCHER: Trying to submit another job.
23:30:47 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:30:47 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:30:47 WORKER: start processing job (0, 0, 15)
23:30:47 WORKER: args: ()
23:30:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 33, 'lr': 0.03903320445488386, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.04188413173302885}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:31:36 WORKER: done with job (0, 0, 15), trying to register it.
23:31:36 WORKER: registered result for job (0, 0, 15) with dispatcher
23:31:36 DISPATCHER: job (0, 0, 15) finished
23:31:36 DISPATCHER: register_result: lock acquired
23:31:36 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:31:36 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 33, 'lr': 0.03903320445488386, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.04188413173302885}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 33, 'lr': 0.03903320445488386, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.04188413173302885}"}}
exception: None

23:31:36 job_callback for (0, 0, 15) started
23:31:36 DISPATCHER: Trying to submit another job.
23:31:36 job_callback for (0, 0, 15) got condition
23:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:36 HBMASTER: Trying to run another job!
23:31:36 job_callback for (0, 0, 15) finished
23:31:36 start sampling a new configuration.
23:31:36 done sampling a new configuration.
23:31:36 HBMASTER: schedule new run for iteration 0
23:31:36 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
23:31:36 HBMASTER: submitting job (0, 0, 16) to dispatcher
23:31:36 DISPATCHER: trying to submit job (0, 0, 16)
23:31:36 DISPATCHER: trying to notify the job_runner thread.
23:31:36 HBMASTER: job (0, 0, 16) submitted to dispatcher
23:31:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:36 DISPATCHER: Trying to submit another job.
23:31:36 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:31:36 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:36 WORKER: start processing job (0, 0, 16)
23:31:36 WORKER: args: ()
23:31:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 24, 'lr': 0.08379691052831315, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.011269428553018981}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:31:45 DISPATCHER: Starting worker discovery
23:31:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:45 DISPATCHER: Finished worker discovery
23:32:24 WORKER: done with job (0, 0, 16), trying to register it.
23:32:24 WORKER: registered result for job (0, 0, 16) with dispatcher
23:32:24 DISPATCHER: job (0, 0, 16) finished
23:32:24 DISPATCHER: register_result: lock acquired
23:32:24 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:32:24 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 24, 'lr': 0.08379691052831315, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.011269428553018981}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 24, 'lr': 0.08379691052831315, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.011269428553018981}"}}
exception: None

23:32:24 job_callback for (0, 0, 16) started
23:32:24 job_callback for (0, 0, 16) got condition
23:32:24 DISPATCHER: Trying to submit another job.
23:32:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:32:24 HBMASTER: Trying to run another job!
23:32:24 job_callback for (0, 0, 16) finished
23:32:24 start sampling a new configuration.
23:32:24 done sampling a new configuration.
23:32:24 HBMASTER: schedule new run for iteration 0
23:32:24 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
23:32:24 HBMASTER: submitting job (0, 0, 17) to dispatcher
23:32:24 DISPATCHER: trying to submit job (0, 0, 17)
23:32:24 DISPATCHER: trying to notify the job_runner thread.
23:32:24 HBMASTER: job (0, 0, 17) submitted to dispatcher
23:32:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:32:24 DISPATCHER: Trying to submit another job.
23:32:24 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:32:24 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:32:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:32:24 WORKER: start processing job (0, 0, 17)
23:32:24 WORKER: args: ()
23:32:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.003383914437913822, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.07127394053543366}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:32:45 DISPATCHER: Starting worker discovery
23:32:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:45 DISPATCHER: Finished worker discovery
23:33:13 WORKER: done with job (0, 0, 17), trying to register it.
23:33:13 WORKER: registered result for job (0, 0, 17) with dispatcher
23:33:13 DISPATCHER: job (0, 0, 17) finished
23:33:13 DISPATCHER: register_result: lock acquired
23:33:13 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:33:13 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.003383914437913822, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.07127394053543366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19411355368296976, 'info': {'data02': 0.19411355368296976, 'config': "{'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.003383914437913822, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.07127394053543366}"}}
exception: None

23:33:13 job_callback for (0, 0, 17) started
23:33:13 job_callback for (0, 0, 17) got condition
23:33:13 DISPATCHER: Trying to submit another job.
23:33:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:13 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.579645





23:33:13 HBMASTER: Trying to run another job!
23:33:13 job_callback for (0, 0, 17) finished
23:33:13 start sampling a new configuration.
23:33:13 done sampling a new configuration.
23:33:13 HBMASTER: schedule new run for iteration 0
23:33:13 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
23:33:13 HBMASTER: submitting job (0, 0, 18) to dispatcher
23:33:13 DISPATCHER: trying to submit job (0, 0, 18)
23:33:13 DISPATCHER: trying to notify the job_runner thread.
23:33:13 HBMASTER: job (0, 0, 18) submitted to dispatcher
23:33:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:13 DISPATCHER: Trying to submit another job.
23:33:13 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:33:13 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:33:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:13 WORKER: start processing job (0, 0, 18)
23:33:13 WORKER: args: ()
23:33:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 70, 'last_n_outputs': 31, 'lr': 0.09794186790782998, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.08982234150505113}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:33:45 DISPATCHER: Starting worker discovery
23:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:45 DISPATCHER: Finished worker discovery
23:34:01 WORKER: done with job (0, 0, 18), trying to register it.
23:34:01 WORKER: registered result for job (0, 0, 18) with dispatcher
23:34:01 DISPATCHER: job (0, 0, 18) finished
23:34:01 DISPATCHER: register_result: lock acquired
23:34:01 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:34:01 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 70, 'last_n_outputs': 31, 'lr': 0.09794186790782998, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.08982234150505113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 70, 'last_n_outputs': 31, 'lr': 0.09794186790782998, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.08982234150505113}"}}
exception: None

23:34:01 job_callback for (0, 0, 18) started
23:34:01 job_callback for (0, 0, 18) got condition
23:34:01 DISPATCHER: Trying to submit another job.
23:34:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:34:01 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.579645





23:34:01 HBMASTER: Trying to run another job!
23:34:01 job_callback for (0, 0, 18) finished
23:34:01 start sampling a new configuration.
23:34:01 best_vector: [2, 0.025782917259096177, 0.20424509788521725, 0.7619068946892213, 0.08476022670453305, 0, 0.36023497004187205, 0.20962148448250753], 1.2731725954358834e-31, 0.0785439463262748, -0.006754036799713465
23:34:01 done sampling a new configuration.
23:34:01 HBMASTER: schedule new run for iteration 0
23:34:01 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:34:01 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:34:01 DISPATCHER: trying to submit job (0, 0, 19)
23:34:01 DISPATCHER: trying to notify the job_runner thread.
23:34:01 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:34:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:34:01 DISPATCHER: Trying to submit another job.
23:34:01 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:34:01 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:34:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:34:01 WORKER: start processing job (0, 0, 19)
23:34:01 WORKER: args: ()
23:34:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 11, 'lr': 0.033405177933680565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.01873802607880943}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:34:45 DISPATCHER: Starting worker discovery
23:34:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:45 DISPATCHER: Finished worker discovery
23:34:49 WORKER: done with job (0, 0, 19), trying to register it.
23:34:49 WORKER: registered result for job (0, 0, 19) with dispatcher
23:34:49 DISPATCHER: job (0, 0, 19) finished
23:34:49 DISPATCHER: register_result: lock acquired
23:34:49 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:34:49 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 11, 'lr': 0.033405177933680565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.01873802607880943}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.358765605864545, 'info': {'data02': 0.358765605864545, 'config': "{'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 11, 'lr': 0.033405177933680565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.01873802607880943}"}}
exception: None

23:34:49 job_callback for (0, 0, 19) started
23:34:49 DISPATCHER: Trying to submit another job.
23:34:49 job_callback for (0, 0, 19) got condition
23:34:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:34:49 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.579645





23:34:49 HBMASTER: Trying to run another job!
23:34:49 job_callback for (0, 0, 19) finished
23:34:49 start sampling a new configuration.
23:34:50 best_vector: [3, 0.16056135800584326, 0.6577256741114684, 0.3367981148225293, 0.5345774303893174, 1, 0.7228779869560478, 0.5931298299003857], 8.708867740264756e-32, 0.11482548935455522, -0.002417832354095296
23:34:50 done sampling a new configuration.
23:34:50 HBMASTER: schedule new run for iteration 0
23:34:50 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:34:50 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:34:50 DISPATCHER: trying to submit job (0, 0, 20)
23:34:50 DISPATCHER: trying to notify the job_runner thread.
23:34:50 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:34:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:34:50 DISPATCHER: Trying to submit another job.
23:34:50 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:34:50 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:34:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:34:50 WORKER: start processing job (0, 0, 20)
23:34:50 WORKER: args: ()
23:34:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 33, 'last_n_outputs': 33, 'lr': 0.004716243608454247, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.059112550769633364}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:35:38 WORKER: done with job (0, 0, 20), trying to register it.
23:35:38 WORKER: registered result for job (0, 0, 20) with dispatcher
23:35:38 DISPATCHER: job (0, 0, 20) finished
23:35:38 DISPATCHER: register_result: lock acquired
23:35:38 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:35:38 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 33, 'last_n_outputs': 33, 'lr': 0.004716243608454247, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.059112550769633364}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 33, 'last_n_outputs': 33, 'lr': 0.004716243608454247, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.059112550769633364}"}}
exception: None

23:35:38 job_callback for (0, 0, 20) started
23:35:38 DISPATCHER: Trying to submit another job.
23:35:38 job_callback for (0, 0, 20) got condition
23:35:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:35:38 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.579645





23:35:38 HBMASTER: Trying to run another job!
23:35:38 job_callback for (0, 0, 20) finished
23:35:38 start sampling a new configuration.
23:35:38 best_vector: [2, 0.061092260706527485, 0.15390058059558984, 0.0792005248566881, 0.02254623654045075, 0, 0.06924602021981874, 0.25793262457415944], 0.0008784921081658394, 0.07894819171695965, 6.935536337731274e-05
23:35:38 done sampling a new configuration.
23:35:38 HBMASTER: schedule new run for iteration 0
23:35:38 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
23:35:38 HBMASTER: submitting job (0, 0, 21) to dispatcher
23:35:38 DISPATCHER: trying to submit job (0, 0, 21)
23:35:38 DISPATCHER: trying to notify the job_runner thread.
23:35:38 HBMASTER: job (0, 0, 21) submitted to dispatcher
23:35:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:35:38 DISPATCHER: Trying to submit another job.
23:35:38 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:35:38 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:35:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:35:38 WORKER: start processing job (0, 0, 21)
23:35:38 WORKER: args: ()
23:35:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 8, 'lr': 0.0014401278520386846, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.021655991955259645}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:35:45 DISPATCHER: Starting worker discovery
23:35:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:45 DISPATCHER: Finished worker discovery
23:36:26 WORKER: done with job (0, 0, 21), trying to register it.
23:36:26 WORKER: registered result for job (0, 0, 21) with dispatcher
23:36:26 DISPATCHER: job (0, 0, 21) finished
23:36:26 DISPATCHER: register_result: lock acquired
23:36:26 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:36:26 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 8, 'lr': 0.0014401278520386846, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.021655991955259645}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.012625581736948282, 'info': {'data02': 0.012625581736948282, 'config': "{'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 8, 'lr': 0.0014401278520386846, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.021655991955259645}"}}
exception: None

23:36:26 job_callback for (0, 0, 21) started
23:36:26 DISPATCHER: Trying to submit another job.
23:36:26 job_callback for (0, 0, 21) got condition
23:36:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:36:26 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.579645





23:36:26 HBMASTER: Trying to run another job!
23:36:26 job_callback for (0, 0, 21) finished
23:36:26 start sampling a new configuration.
23:36:26 best_vector: [3, 0.6373182996499231, 0.9125663578565091, 0.08932424783577239, 0.4392580082390148, 1, 0.6163158676563281, 0.7594992474883714], 5.78880295715363e-32, 0.17274728599359732, -0.0004218505554068576
23:36:26 done sampling a new configuration.
23:36:26 HBMASTER: schedule new run for iteration 0
23:36:26 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:36:26 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:36:26 DISPATCHER: trying to submit job (0, 0, 22)
23:36:26 DISPATCHER: trying to notify the job_runner thread.
23:36:26 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:36:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:36:26 DISPATCHER: Trying to submit another job.
23:36:26 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:36:26 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:36:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:36:26 WORKER: start processing job (0, 0, 22)
23:36:26 WORKER: args: ()
23:36:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.001508858437139787, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.09730413643186285}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:36:45 DISPATCHER: Starting worker discovery
23:36:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:45 DISPATCHER: Finished worker discovery
23:37:14 WORKER: done with job (0, 0, 22), trying to register it.
23:37:14 WORKER: registered result for job (0, 0, 22) with dispatcher
23:37:14 DISPATCHER: job (0, 0, 22) finished
23:37:14 DISPATCHER: register_result: lock acquired
23:37:14 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:37:14 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.001508858437139787, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.09730413643186285}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.07661986572112263, 'info': {'data02': -0.07661986572112263, 'config': "{'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.001508858437139787, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.09730413643186285}"}}
exception: None

23:37:14 job_callback for (0, 0, 22) started
23:37:14 DISPATCHER: Trying to submit another job.
23:37:14 job_callback for (0, 0, 22) got condition
23:37:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:37:14 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.579645





23:37:14 HBMASTER: Trying to run another job!
23:37:14 job_callback for (0, 0, 22) finished
23:37:14 start sampling a new configuration.
23:37:14 done sampling a new configuration.
23:37:14 HBMASTER: schedule new run for iteration 0
23:37:14 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
23:37:14 HBMASTER: submitting job (0, 0, 23) to dispatcher
23:37:14 DISPATCHER: trying to submit job (0, 0, 23)
23:37:14 DISPATCHER: trying to notify the job_runner thread.
23:37:14 HBMASTER: job (0, 0, 23) submitted to dispatcher
23:37:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:37:14 DISPATCHER: Trying to submit another job.
23:37:14 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:37:14 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:37:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:37:14 WORKER: start processing job (0, 0, 23)
23:37:14 WORKER: args: ()
23:37:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 9, 'lr': 0.002939338310565261, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.15003567181937932}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:37:45 DISPATCHER: Starting worker discovery
23:37:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:45 DISPATCHER: Finished worker discovery
23:38:02 WORKER: done with job (0, 0, 23), trying to register it.
23:38:02 WORKER: registered result for job (0, 0, 23) with dispatcher
23:38:02 DISPATCHER: job (0, 0, 23) finished
23:38:02 DISPATCHER: register_result: lock acquired
23:38:02 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:38:02 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 9, 'lr': 0.002939338310565261, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.15003567181937932}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 9, 'lr': 0.002939338310565261, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.15003567181937932}"}}
exception: None

23:38:02 job_callback for (0, 0, 23) started
23:38:02 job_callback for (0, 0, 23) got condition
23:38:02 DISPATCHER: Trying to submit another job.
23:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:02 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.579645





23:38:02 HBMASTER: Trying to run another job!
23:38:02 job_callback for (0, 0, 23) finished
23:38:02 start sampling a new configuration.
23:38:02 best_vector: [2, 0.8755266991931133, 0.7287418637926042, 0.2773545545837254, 0.0162757480480578, 0, 0.5113216189210079, 0.011997363909498349], 0.0006518298898698412, 0.06344426256025588, 4.135486667752488e-05
23:38:02 done sampling a new configuration.
23:38:02 HBMASTER: schedule new run for iteration 0
23:38:02 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:38:02 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:38:02 DISPATCHER: trying to submit job (0, 0, 24)
23:38:02 DISPATCHER: trying to notify the job_runner thread.
23:38:02 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:38:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:02 DISPATCHER: Trying to submit another job.
23:38:02 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:02 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:02 WORKER: start processing job (0, 0, 24)
23:38:02 WORKER: args: ()
23:38:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:38:45 DISPATCHER: Starting worker discovery
23:38:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:45 DISPATCHER: Finished worker discovery
23:38:50 WORKER: done with job (0, 0, 24), trying to register it.
23:38:50 WORKER: registered result for job (0, 0, 24) with dispatcher
23:38:50 DISPATCHER: job (0, 0, 24) finished
23:38:50 DISPATCHER: register_result: lock acquired
23:38:50 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:38:50 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6884246290741397, 'info': {'data02': 0.6884246290741397, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}"}}
exception: None

23:38:50 job_callback for (0, 0, 24) started
23:38:50 DISPATCHER: Trying to submit another job.
23:38:50 job_callback for (0, 0, 24) got condition
23:38:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:50 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.688425





23:38:50 HBMASTER: Trying to run another job!
23:38:50 job_callback for (0, 0, 24) finished
23:38:50 start sampling a new configuration.
23:38:50 done sampling a new configuration.
23:38:50 HBMASTER: schedule new run for iteration 0
23:38:50 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:38:50 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:38:50 DISPATCHER: trying to submit job (0, 0, 25)
23:38:50 DISPATCHER: trying to notify the job_runner thread.
23:38:50 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:38:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:50 DISPATCHER: Trying to submit another job.
23:38:50 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:50 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:50 WORKER: start processing job (0, 0, 25)
23:38:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:50 WORKER: args: ()
23:38:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 20, 'lr': 0.001842999166900282, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03367505418386012}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:39:38 WORKER: done with job (0, 0, 25), trying to register it.
23:39:38 WORKER: registered result for job (0, 0, 25) with dispatcher
23:39:38 DISPATCHER: job (0, 0, 25) finished
23:39:38 DISPATCHER: register_result: lock acquired
23:39:38 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:39:38 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 20, 'lr': 0.001842999166900282, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03367505418386012}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15982577043653998, 'info': {'data02': 0.15982577043653998, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 20, 'lr': 0.001842999166900282, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03367505418386012}"}}
exception: None

23:39:38 job_callback for (0, 0, 25) started
23:39:38 job_callback for (0, 0, 25) got condition
23:39:38 DISPATCHER: Trying to submit another job.
23:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:39:38 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.688425





23:39:38 HBMASTER: Trying to run another job!
23:39:38 job_callback for (0, 0, 25) finished
23:39:38 start sampling a new configuration.
23:39:38 best_vector: [2, 0.7558210762753285, 0.4201173096683595, 0.5006360800051233, 0.17049226639871126, 0, 0.2703061735843728, 0.05821705993954296], 0.0036366425177356567, 0.421760798448539, 0.0015337932519520956
23:39:38 done sampling a new configuration.
23:39:38 HBMASTER: schedule new run for iteration 0
23:39:38 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
23:39:38 HBMASTER: submitting job (0, 0, 26) to dispatcher
23:39:38 DISPATCHER: trying to submit job (0, 0, 26)
23:39:38 DISPATCHER: trying to notify the job_runner thread.
23:39:38 HBMASTER: job (0, 0, 26) submitted to dispatcher
23:39:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:39:38 DISPATCHER: Trying to submit another job.
23:39:38 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:39:38 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:39:38 WORKER: start processing job (0, 0, 26)
23:39:38 WORKER: args: ()
23:39:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:39:45 DISPATCHER: Starting worker discovery
23:39:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:45 DISPATCHER: Finished worker discovery
23:40:26 WORKER: done with job (0, 0, 26), trying to register it.
23:40:26 WORKER: registered result for job (0, 0, 26) with dispatcher
23:40:26 DISPATCHER: job (0, 0, 26) finished
23:40:26 DISPATCHER: register_result: lock acquired
23:40:26 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:40:26 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43196616773138047, 'info': {'data02': 0.43196616773138047, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}"}}
exception: None

23:40:26 job_callback for (0, 0, 26) started
23:40:26 DISPATCHER: Trying to submit another job.
23:40:26 job_callback for (0, 0, 26) got condition
23:40:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:26 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.688425





23:40:26 HBMASTER: Trying to run another job!
23:40:26 job_callback for (0, 0, 26) finished
23:40:26 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
23:40:26 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
23:40:26 HBMASTER: schedule new run for iteration 0
23:40:26 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
23:40:26 HBMASTER: submitting job (0, 0, 2) to dispatcher
23:40:26 DISPATCHER: trying to submit job (0, 0, 2)
23:40:26 DISPATCHER: trying to notify the job_runner thread.
23:40:26 HBMASTER: job (0, 0, 2) submitted to dispatcher
23:40:26 DISPATCHER: Trying to submit another job.
23:40:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:26 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:40:27 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:40:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:27 WORKER: start processing job (0, 0, 2)
23:40:27 WORKER: args: ()
23:40:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 23, 'lr': 0.0070422116242460754, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.027648646874075148}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:40:45 DISPATCHER: Starting worker discovery
23:40:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:45 DISPATCHER: Finished worker discovery
23:41:45 DISPATCHER: Starting worker discovery
23:41:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:45 DISPATCHER: Finished worker discovery
23:42:44 WORKER: done with job (0, 0, 2), trying to register it.
23:42:44 WORKER: registered result for job (0, 0, 2) with dispatcher
23:42:44 DISPATCHER: job (0, 0, 2) finished
23:42:44 DISPATCHER: register_result: lock acquired
23:42:44 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:42:44 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 23, 'lr': 0.0070422116242460754, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.027648646874075148}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19882750677151548, 'info': {'data02': 0.19882750677151548, 'config': "{'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 23, 'lr': 0.0070422116242460754, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.027648646874075148}"}}
exception: None

23:42:44 job_callback for (0, 0, 2) started
23:42:44 job_callback for (0, 0, 2) got condition
23:42:44 DISPATCHER: Trying to submit another job.
23:42:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:42:44 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:42:44 HBMASTER: Trying to run another job!
23:42:44 job_callback for (0, 0, 2) finished
23:42:44 HBMASTER: schedule new run for iteration 0
23:42:44 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
23:42:44 HBMASTER: submitting job (0, 0, 4) to dispatcher
23:42:44 DISPATCHER: trying to submit job (0, 0, 4)
23:42:44 DISPATCHER: trying to notify the job_runner thread.
23:42:44 HBMASTER: job (0, 0, 4) submitted to dispatcher
23:42:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:42:44 DISPATCHER: Trying to submit another job.
23:42:44 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:42:44 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:42:44 WORKER: start processing job (0, 0, 4)
23:42:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:42:44 WORKER: args: ()
23:42:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 34, 'lr': 0.007838146906362168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.11187966984767499}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:42:45 DISPATCHER: Starting worker discovery
23:42:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:43:45 DISPATCHER: Starting worker discovery
23:43:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:45 DISPATCHER: Finished worker discovery
23:44:45 DISPATCHER: Starting worker discovery
23:44:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:45 DISPATCHER: Finished worker discovery
23:45:01 WORKER: done with job (0, 0, 4), trying to register it.
23:45:01 WORKER: registered result for job (0, 0, 4) with dispatcher
23:45:01 DISPATCHER: job (0, 0, 4) finished
23:45:01 DISPATCHER: register_result: lock acquired
23:45:01 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:45:01 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 34, 'lr': 0.007838146906362168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.11187966984767499}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4155936392542806, 'info': {'data02': 0.4155936392542806, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 34, 'lr': 0.007838146906362168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.11187966984767499}"}}
exception: None

23:45:01 job_callback for (0, 0, 4) started
23:45:01 job_callback for (0, 0, 4) got condition
23:45:01 DISPATCHER: Trying to submit another job.
23:45:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:45:01 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:45:01 HBMASTER: Trying to run another job!
23:45:01 job_callback for (0, 0, 4) finished
23:45:01 HBMASTER: schedule new run for iteration 0
23:45:01 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
23:45:01 HBMASTER: submitting job (0, 0, 9) to dispatcher
23:45:01 DISPATCHER: trying to submit job (0, 0, 9)
23:45:01 DISPATCHER: trying to notify the job_runner thread.
23:45:01 HBMASTER: job (0, 0, 9) submitted to dispatcher
23:45:01 DISPATCHER: Trying to submit another job.
23:45:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:45:01 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:45:01 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:45:01 WORKER: start processing job (0, 0, 9)
23:45:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:45:01 WORKER: args: ()
23:45:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:45:45 DISPATCHER: Starting worker discovery
23:45:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:45 DISPATCHER: Finished worker discovery
23:46:45 DISPATCHER: Starting worker discovery
23:46:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:45 DISPATCHER: Finished worker discovery
23:47:18 WORKER: done with job (0, 0, 9), trying to register it.
23:47:18 WORKER: registered result for job (0, 0, 9) with dispatcher
23:47:18 DISPATCHER: job (0, 0, 9) finished
23:47:18 DISPATCHER: register_result: lock acquired
23:47:18 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:47:18 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5082442059832544, 'info': {'data02': 0.5082442059832544, 'config': "{'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}"}}
exception: None

23:47:18 job_callback for (0, 0, 9) started
23:47:18 DISPATCHER: Trying to submit another job.
23:47:18 job_callback for (0, 0, 9) got condition
23:47:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:47:18 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:47:18 HBMASTER: Trying to run another job!
23:47:18 job_callback for (0, 0, 9) finished
23:47:18 HBMASTER: schedule new run for iteration 0
23:47:18 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
23:47:18 HBMASTER: submitting job (0, 0, 12) to dispatcher
23:47:18 DISPATCHER: trying to submit job (0, 0, 12)
23:47:18 DISPATCHER: trying to notify the job_runner thread.
23:47:18 HBMASTER: job (0, 0, 12) submitted to dispatcher
23:47:18 DISPATCHER: Trying to submit another job.
23:47:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:47:18 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:47:18 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:47:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:47:18 WORKER: start processing job (0, 0, 12)
23:47:18 WORKER: args: ()
23:47:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 9, 'lr': 0.007780931892780437, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01673449627553254}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:47:45 DISPATCHER: Starting worker discovery
23:47:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:45 DISPATCHER: Finished worker discovery
23:48:45 DISPATCHER: Starting worker discovery
23:48:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:45 DISPATCHER: Finished worker discovery
23:49:35 WORKER: done with job (0, 0, 12), trying to register it.
23:49:35 WORKER: registered result for job (0, 0, 12) with dispatcher
23:49:35 DISPATCHER: job (0, 0, 12) finished
23:49:35 DISPATCHER: register_result: lock acquired
23:49:35 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:49:35 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 9, 'lr': 0.007780931892780437, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01673449627553254}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.013848776572079023, 'info': {'data02': -0.013848776572079023, 'config': "{'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 9, 'lr': 0.007780931892780437, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01673449627553254}"}}
exception: None

23:49:35 job_callback for (0, 0, 12) started
23:49:35 job_callback for (0, 0, 12) got condition
23:49:35 DISPATCHER: Trying to submit another job.
23:49:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:49:35 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:49:35 HBMASTER: Trying to run another job!
23:49:35 job_callback for (0, 0, 12) finished
23:49:35 HBMASTER: schedule new run for iteration 0
23:49:35 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
23:49:35 HBMASTER: submitting job (0, 0, 17) to dispatcher
23:49:35 DISPATCHER: trying to submit job (0, 0, 17)
23:49:35 DISPATCHER: trying to notify the job_runner thread.
23:49:35 HBMASTER: job (0, 0, 17) submitted to dispatcher
23:49:35 DISPATCHER: Trying to submit another job.
23:49:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:49:35 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:49:35 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:49:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:49:35 WORKER: start processing job (0, 0, 17)
23:49:35 WORKER: args: ()
23:49:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.003383914437913822, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.07127394053543366}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:49:45 DISPATCHER: Starting worker discovery
23:49:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:45 DISPATCHER: Finished worker discovery
23:50:45 DISPATCHER: Starting worker discovery
23:50:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:45 DISPATCHER: Finished worker discovery
23:51:45 DISPATCHER: Starting worker discovery
23:51:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:45 DISPATCHER: Finished worker discovery
23:51:52 WORKER: done with job (0, 0, 17), trying to register it.
23:51:52 WORKER: registered result for job (0, 0, 17) with dispatcher
23:51:52 DISPATCHER: job (0, 0, 17) finished
23:51:52 DISPATCHER: register_result: lock acquired
23:51:52 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:51:52 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.003383914437913822, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.07127394053543366}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17944555323061026, 'info': {'data02': 0.17944555323061026, 'config': "{'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.003383914437913822, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.07127394053543366}"}}
exception: None

23:51:52 job_callback for (0, 0, 17) started
23:51:52 DISPATCHER: Trying to submit another job.
23:51:52 job_callback for (0, 0, 17) got condition
23:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:51:52 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:51:52 HBMASTER: Trying to run another job!
23:51:52 job_callback for (0, 0, 17) finished
23:51:52 HBMASTER: schedule new run for iteration 0
23:51:52 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:51:52 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:51:52 DISPATCHER: trying to submit job (0, 0, 19)
23:51:52 DISPATCHER: trying to notify the job_runner thread.
23:51:52 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:51:52 DISPATCHER: Trying to submit another job.
23:51:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:51:52 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:51:52 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:51:52 WORKER: start processing job (0, 0, 19)
23:51:52 WORKER: args: ()
23:51:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 11, 'lr': 0.033405177933680565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.01873802607880943}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:52:45 DISPATCHER: Starting worker discovery
23:52:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:45 DISPATCHER: Finished worker discovery
23:53:45 DISPATCHER: Starting worker discovery
23:53:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:45 DISPATCHER: Finished worker discovery
23:54:09 WORKER: done with job (0, 0, 19), trying to register it.
23:54:09 WORKER: registered result for job (0, 0, 19) with dispatcher
23:54:09 DISPATCHER: job (0, 0, 19) finished
23:54:09 DISPATCHER: register_result: lock acquired
23:54:09 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:54:09 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 11, 'lr': 0.033405177933680565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.01873802607880943}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.366493746924656, 'info': {'data02': 0.366493746924656, 'config': "{'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 11, 'lr': 0.033405177933680565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.01873802607880943}"}}
exception: None

23:54:09 job_callback for (0, 0, 19) started
23:54:09 DISPATCHER: Trying to submit another job.
23:54:09 job_callback for (0, 0, 19) got condition
23:54:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:09 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:54:09 HBMASTER: Trying to run another job!
23:54:09 job_callback for (0, 0, 19) finished
23:54:09 HBMASTER: schedule new run for iteration 0
23:54:09 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:54:09 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:54:09 DISPATCHER: trying to submit job (0, 0, 24)
23:54:09 DISPATCHER: trying to notify the job_runner thread.
23:54:09 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:54:09 DISPATCHER: Trying to submit another job.
23:54:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:09 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:54:09 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:54:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:09 WORKER: start processing job (0, 0, 24)
23:54:09 WORKER: args: ()
23:54:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:54:45 DISPATCHER: Starting worker discovery
23:54:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:45 DISPATCHER: Finished worker discovery
23:55:45 DISPATCHER: Starting worker discovery
23:55:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:45 DISPATCHER: Finished worker discovery
23:56:26 WORKER: done with job (0, 0, 24), trying to register it.
23:56:26 WORKER: registered result for job (0, 0, 24) with dispatcher
23:56:26 DISPATCHER: job (0, 0, 24) finished
23:56:26 DISPATCHER: register_result: lock acquired
23:56:26 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:56:26 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.60867506213061, 'info': {'data02': 0.60867506213061, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}"}}
exception: None

23:56:26 job_callback for (0, 0, 24) started
23:56:26 DISPATCHER: Trying to submit another job.
23:56:26 job_callback for (0, 0, 24) got condition
23:56:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:56:26 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:56:26 HBMASTER: Trying to run another job!
23:56:26 job_callback for (0, 0, 24) finished
23:56:26 HBMASTER: schedule new run for iteration 0
23:56:26 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:56:26 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:56:26 DISPATCHER: trying to submit job (0, 0, 25)
23:56:26 DISPATCHER: trying to notify the job_runner thread.
23:56:26 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:56:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:56:26 DISPATCHER: Trying to submit another job.
23:56:26 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:56:26 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:56:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:56:26 WORKER: start processing job (0, 0, 25)
23:56:26 WORKER: args: ()
23:56:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 20, 'lr': 0.001842999166900282, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03367505418386012}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:56:45 DISPATCHER: Starting worker discovery
23:56:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:45 DISPATCHER: Finished worker discovery
23:57:45 DISPATCHER: Starting worker discovery
23:57:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:45 DISPATCHER: Finished worker discovery
23:58:43 WORKER: done with job (0, 0, 25), trying to register it.
23:58:43 WORKER: registered result for job (0, 0, 25) with dispatcher
23:58:43 DISPATCHER: job (0, 0, 25) finished
23:58:43 DISPATCHER: register_result: lock acquired
23:58:43 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:58:43 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 20, 'lr': 0.001842999166900282, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03367505418386012}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19546531946457538, 'info': {'data02': 0.19546531946457538, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 20, 'lr': 0.001842999166900282, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03367505418386012}"}}
exception: None

23:58:43 job_callback for (0, 0, 25) started
23:58:43 DISPATCHER: Trying to submit another job.
23:58:43 job_callback for (0, 0, 25) got condition
23:58:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:58:43 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:58:43 HBMASTER: Trying to run another job!
23:58:43 job_callback for (0, 0, 25) finished
23:58:43 HBMASTER: schedule new run for iteration 0
23:58:43 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
23:58:43 HBMASTER: submitting job (0, 0, 26) to dispatcher
23:58:43 DISPATCHER: trying to submit job (0, 0, 26)
23:58:43 DISPATCHER: trying to notify the job_runner thread.
23:58:43 HBMASTER: job (0, 0, 26) submitted to dispatcher
23:58:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:58:43 DISPATCHER: Trying to submit another job.
23:58:43 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:58:43 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:58:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:58:43 WORKER: start processing job (0, 0, 26)
23:58:43 WORKER: args: ()
23:58:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:58:45 DISPATCHER: Starting worker discovery
23:58:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:59:45 DISPATCHER: Starting worker discovery
23:59:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:45 DISPATCHER: Finished worker discovery
00:00:45 DISPATCHER: Starting worker discovery
00:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:45 DISPATCHER: Finished worker discovery
00:01:00 WORKER: done with job (0, 0, 26), trying to register it.
00:01:00 WORKER: registered result for job (0, 0, 26) with dispatcher
00:01:00 DISPATCHER: job (0, 0, 26) finished
00:01:00 DISPATCHER: register_result: lock acquired
00:01:00 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:01:00 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.455364993071143, 'info': {'data02': 0.455364993071143, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}"}}
exception: None

00:01:00 job_callback for (0, 0, 26) started
00:01:00 DISPATCHER: Trying to submit another job.
00:01:00 job_callback for (0, 0, 26) got condition
00:01:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:00 HBMASTER: Trying to run another job!
00:01:00 job_callback for (0, 0, 26) finished
00:01:00 ITERATION: Advancing config (0, 0, 9) to next budget 400.000000
00:01:00 ITERATION: Advancing config (0, 0, 24) to next budget 400.000000
00:01:00 ITERATION: Advancing config (0, 0, 26) to next budget 400.000000
00:01:00 HBMASTER: schedule new run for iteration 0
00:01:00 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
00:01:00 HBMASTER: submitting job (0, 0, 9) to dispatcher
00:01:00 DISPATCHER: trying to submit job (0, 0, 9)
00:01:00 DISPATCHER: trying to notify the job_runner thread.
00:01:00 HBMASTER: job (0, 0, 9) submitted to dispatcher
00:01:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:00 DISPATCHER: Trying to submit another job.
00:01:00 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:01:00 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:01:00 WORKER: start processing job (0, 0, 9)
00:01:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:00 WORKER: args: ()
00:01:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:01:45 DISPATCHER: Starting worker discovery
00:01:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:45 DISPATCHER: Finished worker discovery
00:02:45 DISPATCHER: Starting worker discovery
00:02:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:45 DISPATCHER: Finished worker discovery
00:03:45 DISPATCHER: Starting worker discovery
00:03:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:45 DISPATCHER: Finished worker discovery
00:04:45 DISPATCHER: Starting worker discovery
00:04:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:45 DISPATCHER: Finished worker discovery
00:05:45 DISPATCHER: Starting worker discovery
00:05:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:45 DISPATCHER: Finished worker discovery
00:06:45 DISPATCHER: Starting worker discovery
00:06:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:45 DISPATCHER: Finished worker discovery
00:07:44 WORKER: done with job (0, 0, 9), trying to register it.
00:07:44 WORKER: registered result for job (0, 0, 9) with dispatcher
00:07:44 DISPATCHER: job (0, 0, 9) finished
00:07:44 DISPATCHER: register_result: lock acquired
00:07:44 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:07:44 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.47787526710230743, 'info': {'data02': 0.47787526710230743, 'config': "{'batch_size': 64, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.005549017602029068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014900143610160331}"}}
exception: None

00:07:44 job_callback for (0, 0, 9) started
00:07:44 DISPATCHER: Trying to submit another job.
00:07:44 job_callback for (0, 0, 9) got condition
00:07:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:44 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
00:07:44 HBMASTER: Trying to run another job!
00:07:44 job_callback for (0, 0, 9) finished
00:07:44 HBMASTER: schedule new run for iteration 0
00:07:44 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
00:07:44 HBMASTER: submitting job (0, 0, 24) to dispatcher
00:07:44 DISPATCHER: trying to submit job (0, 0, 24)
00:07:44 DISPATCHER: trying to notify the job_runner thread.
00:07:44 HBMASTER: job (0, 0, 24) submitted to dispatcher
00:07:44 DISPATCHER: Trying to submit another job.
00:07:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:44 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:07:44 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:07:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:44 WORKER: start processing job (0, 0, 24)
00:07:44 WORKER: args: ()
00:07:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 400.0, 'working_directory': '.'}
00:07:45 DISPATCHER: Starting worker discovery
00:07:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:08:45 DISPATCHER: Starting worker discovery
00:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:45 DISPATCHER: Finished worker discovery
00:09:45 DISPATCHER: Starting worker discovery
00:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:45 DISPATCHER: Finished worker discovery
00:10:45 DISPATCHER: Starting worker discovery
00:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:45 DISPATCHER: Finished worker discovery
00:11:45 DISPATCHER: Starting worker discovery
00:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:45 DISPATCHER: Finished worker discovery
00:12:45 DISPATCHER: Starting worker discovery
00:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:45 DISPATCHER: Finished worker discovery
00:13:45 DISPATCHER: Starting worker discovery
00:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:45 DISPATCHER: Finished worker discovery
00:14:28 WORKER: done with job (0, 0, 24), trying to register it.
00:14:28 WORKER: registered result for job (0, 0, 24) with dispatcher
00:14:28 DISPATCHER: job (0, 0, 24) finished
00:14:28 DISPATCHER: register_result: lock acquired
00:14:28 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:14:28 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.619517257298182, 'info': {'data02': 0.619517257298182, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}"}}
exception: None

00:14:28 job_callback for (0, 0, 24) started
00:14:28 DISPATCHER: Trying to submit another job.
00:14:28 job_callback for (0, 0, 24) got condition
00:14:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:28 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
00:14:28 HBMASTER: Trying to run another job!
00:14:28 job_callback for (0, 0, 24) finished
00:14:28 HBMASTER: schedule new run for iteration 0
00:14:28 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
00:14:28 HBMASTER: submitting job (0, 0, 26) to dispatcher
00:14:28 DISPATCHER: trying to submit job (0, 0, 26)
00:14:28 DISPATCHER: trying to notify the job_runner thread.
00:14:28 HBMASTER: job (0, 0, 26) submitted to dispatcher
00:14:28 DISPATCHER: Trying to submit another job.
00:14:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:28 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:14:28 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:14:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:28 WORKER: start processing job (0, 0, 26)
00:14:28 WORKER: args: ()
00:14:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:14:45 DISPATCHER: Starting worker discovery
00:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:45 DISPATCHER: Finished worker discovery
00:15:45 DISPATCHER: Starting worker discovery
00:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:45 DISPATCHER: Finished worker discovery
00:16:45 DISPATCHER: Starting worker discovery
00:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:45 DISPATCHER: Finished worker discovery
00:17:45 DISPATCHER: Starting worker discovery
00:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:45 DISPATCHER: Finished worker discovery
00:18:45 DISPATCHER: Starting worker discovery
00:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:45 DISPATCHER: Finished worker discovery
00:19:45 DISPATCHER: Starting worker discovery
00:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:45 DISPATCHER: Finished worker discovery
00:20:45 DISPATCHER: Starting worker discovery
00:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:45 DISPATCHER: Finished worker discovery
00:21:12 WORKER: done with job (0, 0, 26), trying to register it.
00:21:12 WORKER: registered result for job (0, 0, 26) with dispatcher
00:21:12 DISPATCHER: job (0, 0, 26) finished
00:21:12 DISPATCHER: register_result: lock acquired
00:21:12 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:21:12 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.47773878134089853, 'info': {'data02': 0.47773878134089853, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 22, 'lr': 0.010029335511400053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011905349278627225}"}}
exception: None

00:21:12 job_callback for (0, 0, 26) started
00:21:12 DISPATCHER: Trying to submit another job.
00:21:12 job_callback for (0, 0, 26) got condition
00:21:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:21:12 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
00:21:12 HBMASTER: Trying to run another job!
00:21:12 job_callback for (0, 0, 26) finished
00:21:12 ITERATION: Advancing config (0, 0, 24) to next budget 1200.000000
00:21:12 HBMASTER: schedule new run for iteration 0
00:21:12 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
00:21:12 HBMASTER: submitting job (0, 0, 24) to dispatcher
00:21:12 DISPATCHER: trying to submit job (0, 0, 24)
00:21:12 DISPATCHER: trying to notify the job_runner thread.
00:21:12 HBMASTER: job (0, 0, 24) submitted to dispatcher
00:21:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:21:12 DISPATCHER: Trying to submit another job.
00:21:12 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:21:12 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:21:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:21:12 WORKER: start processing job (0, 0, 24)
00:21:12 WORKER: args: ()
00:21:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:21:45 DISPATCHER: Starting worker discovery
00:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:45 DISPATCHER: Finished worker discovery
00:22:45 DISPATCHER: Starting worker discovery
00:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:45 DISPATCHER: Finished worker discovery
00:23:45 DISPATCHER: Starting worker discovery
00:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:45 DISPATCHER: Finished worker discovery
00:24:45 DISPATCHER: Starting worker discovery
00:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:45 DISPATCHER: Finished worker discovery
00:25:45 DISPATCHER: Starting worker discovery
00:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:45 DISPATCHER: Finished worker discovery
00:26:45 DISPATCHER: Starting worker discovery
00:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:45 DISPATCHER: Finished worker discovery
00:27:45 DISPATCHER: Starting worker discovery
00:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:45 DISPATCHER: Finished worker discovery
00:28:45 DISPATCHER: Starting worker discovery
00:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:45 DISPATCHER: Finished worker discovery
00:29:45 DISPATCHER: Starting worker discovery
00:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:45 DISPATCHER: Finished worker discovery
00:30:45 DISPATCHER: Starting worker discovery
00:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:45 DISPATCHER: Finished worker discovery
00:31:45 DISPATCHER: Starting worker discovery
00:31:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:45 DISPATCHER: Finished worker discovery
00:32:45 DISPATCHER: Starting worker discovery
00:32:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:45 DISPATCHER: Finished worker discovery
00:33:45 DISPATCHER: Starting worker discovery
00:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:45 DISPATCHER: Finished worker discovery
00:34:45 DISPATCHER: Starting worker discovery
00:34:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:45 DISPATCHER: Finished worker discovery
00:35:45 DISPATCHER: Starting worker discovery
00:35:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:45 DISPATCHER: Finished worker discovery
00:36:45 DISPATCHER: Starting worker discovery
00:36:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:45 DISPATCHER: Finished worker discovery
00:37:45 DISPATCHER: Starting worker discovery
00:37:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:45 DISPATCHER: Finished worker discovery
00:38:45 DISPATCHER: Starting worker discovery
00:38:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:45 DISPATCHER: Finished worker discovery
00:39:45 DISPATCHER: Starting worker discovery
00:39:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:45 DISPATCHER: Finished worker discovery
00:40:45 DISPATCHER: Starting worker discovery
00:40:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:45 DISPATCHER: Finished worker discovery
00:41:15 WORKER: done with job (0, 0, 24), trying to register it.
00:41:15 WORKER: registered result for job (0, 0, 24) with dispatcher
00:41:15 DISPATCHER: job (0, 0, 24) finished
00:41:15 DISPATCHER: register_result: lock acquired
00:41:15 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:41:15 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5601185547541694, 'info': {'data02': 0.5601185547541694, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 37, 'lr': 0.003586816089062291, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.010365945718456525}"}}
exception: None

00:41:15 job_callback for (0, 0, 24) started
00:41:15 DISPATCHER: Trying to submit another job.
00:41:15 job_callback for (0, 0, 24) got condition
00:41:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:41:15 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
00:41:15 HBMASTER: Trying to run another job!
00:41:15 job_callback for (0, 0, 24) finished
00:41:15 start sampling a new configuration.
00:41:15 best_vector: [2, 0.4353726163643361, 0.7455174906313391, 0.46812844852306723, 0.06319895560833066, 0, 0.7752318599013709, 0.08597505136958189], 0.003408734477302227, 0.5893006038534213, 0.0020087692858501787
00:41:15 done sampling a new configuration.
00:41:15 HBMASTER: schedule new run for iteration 1
00:41:15 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:41:15 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:41:15 DISPATCHER: trying to submit job (1, 0, 0)
00:41:15 DISPATCHER: trying to notify the job_runner thread.
00:41:15 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:41:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:41:15 DISPATCHER: Trying to submit another job.
00:41:15 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:41:15 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:41:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:41:15 WORKER: start processing job (1, 0, 0)
00:41:15 WORKER: args: ()
00:41:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 38, 'lr': 0.008634891741547756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.012937671527505367}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:41:45 DISPATCHER: Starting worker discovery
00:41:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:45 DISPATCHER: Finished worker discovery
00:42:45 DISPATCHER: Starting worker discovery
00:42:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:45 DISPATCHER: Finished worker discovery
00:43:33 WORKER: done with job (1, 0, 0), trying to register it.
00:43:33 WORKER: registered result for job (1, 0, 0) with dispatcher
00:43:33 DISPATCHER: job (1, 0, 0) finished
00:43:33 DISPATCHER: register_result: lock acquired
00:43:33 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:43:33 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 38, 'lr': 0.008634891741547756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.012937671527505367}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5534906912038954, 'info': {'data02': 0.5534906912038954, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 38, 'lr': 0.008634891741547756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.012937671527505367}"}}
exception: None

00:43:33 job_callback for (1, 0, 0) started
00:43:33 job_callback for (1, 0, 0) got condition
00:43:33 DISPATCHER: Trying to submit another job.
00:43:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:43:33 HBMASTER: Trying to run another job!
00:43:33 job_callback for (1, 0, 0) finished
00:43:33 start sampling a new configuration.
00:43:33 best_vector: [2, 0.014476148003710922, 0.26374631124742454, 0.4497534978859113, 0.10162664196323383, 0, 0.850007236000057, 0.09318991213746251], 0.0003799586026210502, 2.5646956910905105, 0.000974478190934979
00:43:33 done sampling a new configuration.
00:43:33 HBMASTER: schedule new run for iteration 1
00:43:33 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
00:43:33 HBMASTER: submitting job (1, 0, 1) to dispatcher
00:43:33 DISPATCHER: trying to submit job (1, 0, 1)
00:43:33 DISPATCHER: trying to notify the job_runner thread.
00:43:33 HBMASTER: job (1, 0, 1) submitted to dispatcher
00:43:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:43:33 DISPATCHER: Trying to submit another job.
00:43:33 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:43:33 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:43:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:43:33 WORKER: start processing job (1, 0, 1)
00:43:33 WORKER: args: ()
00:43:33 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 14, 'lr': 0.007934270374824717, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013220347504566625}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:43:45 DISPATCHER: Starting worker discovery
00:43:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:45 DISPATCHER: Finished worker discovery
00:44:45 DISPATCHER: Starting worker discovery
00:44:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:45 DISPATCHER: Finished worker discovery
00:45:45 DISPATCHER: Starting worker discovery
00:45:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:45 DISPATCHER: Finished worker discovery
00:45:50 WORKER: done with job (1, 0, 1), trying to register it.
00:45:50 WORKER: registered result for job (1, 0, 1) with dispatcher
00:45:50 DISPATCHER: job (1, 0, 1) finished
00:45:50 DISPATCHER: register_result: lock acquired
00:45:50 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:45:50 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 14, 'lr': 0.007934270374824717, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013220347504566625}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5314855905818379, 'info': {'data02': 0.5314855905818379, 'config': "{'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 14, 'lr': 0.007934270374824717, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013220347504566625}"}}
exception: None

00:45:50 job_callback for (1, 0, 1) started
00:45:50 DISPATCHER: Trying to submit another job.
00:45:50 job_callback for (1, 0, 1) got condition
00:45:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:45:50 HBMASTER: Trying to run another job!
00:45:50 job_callback for (1, 0, 1) finished
00:45:50 start sampling a new configuration.
00:45:50 done sampling a new configuration.
00:45:50 HBMASTER: schedule new run for iteration 1
00:45:50 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:45:50 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:45:50 DISPATCHER: trying to submit job (1, 0, 2)
00:45:50 DISPATCHER: trying to notify the job_runner thread.
00:45:50 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:45:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:45:50 DISPATCHER: Trying to submit another job.
00:45:50 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:45:50 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:45:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:45:50 WORKER: start processing job (1, 0, 2)
00:45:50 WORKER: args: ()
00:45:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0036968791410790405, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.11326514708691535}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:46:45 DISPATCHER: Starting worker discovery
00:46:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:45 DISPATCHER: Finished worker discovery
00:47:45 DISPATCHER: Starting worker discovery
00:47:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:45 DISPATCHER: Finished worker discovery
00:48:07 WORKER: done with job (1, 0, 2), trying to register it.
00:48:07 WORKER: registered result for job (1, 0, 2) with dispatcher
00:48:07 DISPATCHER: job (1, 0, 2) finished
00:48:07 DISPATCHER: register_result: lock acquired
00:48:07 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:48:07 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0036968791410790405, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.11326514708691535}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0036968791410790405, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.11326514708691535}"}}
exception: None

00:48:07 job_callback for (1, 0, 2) started
00:48:07 DISPATCHER: Trying to submit another job.
00:48:07 job_callback for (1, 0, 2) got condition
00:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:48:07 HBMASTER: Trying to run another job!
00:48:07 job_callback for (1, 0, 2) finished
00:48:07 start sampling a new configuration.
00:48:07 best_vector: [2, 0.7042499339309455, 0.9597719085360185, 0.344891153542263, 0.13983111270709475, 0, 0.5585379582410768, 0.025466144264004217], 0.0011824492022980899, 1.5614820275326862, 0.0018463731778588287
00:48:07 done sampling a new configuration.
00:48:07 HBMASTER: schedule new run for iteration 1
00:48:07 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:48:07 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:48:07 DISPATCHER: trying to submit job (1, 0, 3)
00:48:07 DISPATCHER: trying to notify the job_runner thread.
00:48:07 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:48:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:48:07 DISPATCHER: Trying to submit another job.
00:48:07 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:48:07 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:48:07 WORKER: start processing job (1, 0, 3)
00:48:07 WORKER: args: ()
00:48:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:48:45 DISPATCHER: Starting worker discovery
00:48:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:45 DISPATCHER: Finished worker discovery
00:49:45 DISPATCHER: Starting worker discovery
00:49:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:45 DISPATCHER: Finished worker discovery
00:50:25 WORKER: done with job (1, 0, 3), trying to register it.
00:50:25 WORKER: registered result for job (1, 0, 3) with dispatcher
00:50:25 DISPATCHER: job (1, 0, 3) finished
00:50:25 DISPATCHER: register_result: lock acquired
00:50:25 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:50:25 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6251197925318059, 'info': {'data02': 0.6251197925318059, 'config': "{'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}"}}
exception: None

00:50:25 job_callback for (1, 0, 3) started
00:50:25 job_callback for (1, 0, 3) got condition
00:50:25 DISPATCHER: Trying to submit another job.
00:50:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:50:25 HBMASTER: Trying to run another job!
00:50:25 job_callback for (1, 0, 3) finished
00:50:25 start sampling a new configuration.
00:50:25 best_vector: [3, 0.590643979393214, 0.5701523590450548, 0.49353075398466467, 0.02691475092309789, 0, 0.2645123404121593, 0.10767101408618238], 0.0049252091823199454, 1.5104406693908248, 0.0074392362542331746
00:50:25 done sampling a new configuration.
00:50:25 HBMASTER: schedule new run for iteration 1
00:50:25 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:50:25 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:50:25 DISPATCHER: trying to submit job (1, 0, 4)
00:50:25 DISPATCHER: trying to notify the job_runner thread.
00:50:25 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:50:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:50:25 DISPATCHER: Trying to submit another job.
00:50:25 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:50:25 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:50:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:50:25 WORKER: start processing job (1, 0, 4)
00:50:25 WORKER: args: ()
00:50:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 67, 'last_n_outputs': 29, 'lr': 0.009706474277179217, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01380648797530175}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:50:45 DISPATCHER: Starting worker discovery
00:50:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:45 DISPATCHER: Finished worker discovery
00:51:45 DISPATCHER: Starting worker discovery
00:51:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:45 DISPATCHER: Finished worker discovery
00:52:42 WORKER: done with job (1, 0, 4), trying to register it.
00:52:42 WORKER: registered result for job (1, 0, 4) with dispatcher
00:52:42 DISPATCHER: job (1, 0, 4) finished
00:52:42 DISPATCHER: register_result: lock acquired
00:52:42 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:52:42 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 67, 'last_n_outputs': 29, 'lr': 0.009706474277179217, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01380648797530175}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5652422863978414, 'info': {'data02': 0.5652422863978414, 'config': "{'batch_size': 128, 'hidden_dim': 67, 'last_n_outputs': 29, 'lr': 0.009706474277179217, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01380648797530175}"}}
exception: None

00:52:42 job_callback for (1, 0, 4) started
00:52:42 DISPATCHER: Trying to submit another job.
00:52:42 job_callback for (1, 0, 4) got condition
00:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:52:42 HBMASTER: Trying to run another job!
00:52:42 job_callback for (1, 0, 4) finished
00:52:42 start sampling a new configuration.
00:52:42 done sampling a new configuration.
00:52:42 HBMASTER: schedule new run for iteration 1
00:52:42 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
00:52:42 HBMASTER: submitting job (1, 0, 5) to dispatcher
00:52:42 DISPATCHER: trying to submit job (1, 0, 5)
00:52:42 DISPATCHER: trying to notify the job_runner thread.
00:52:42 HBMASTER: job (1, 0, 5) submitted to dispatcher
00:52:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:52:42 DISPATCHER: Trying to submit another job.
00:52:42 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:52:42 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:52:42 WORKER: start processing job (1, 0, 5)
00:52:42 WORKER: args: ()
00:52:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 26, 'lr': 0.0415633304130563, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02104411733091757}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:52:45 DISPATCHER: Starting worker discovery
00:52:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:53:45 DISPATCHER: Starting worker discovery
00:53:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:45 DISPATCHER: Finished worker discovery
00:54:45 DISPATCHER: Starting worker discovery
00:54:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:45 DISPATCHER: Finished worker discovery
00:54:59 WORKER: done with job (1, 0, 5), trying to register it.
00:54:59 WORKER: registered result for job (1, 0, 5) with dispatcher
00:54:59 DISPATCHER: job (1, 0, 5) finished
00:54:59 DISPATCHER: register_result: lock acquired
00:54:59 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:54:59 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 26, 'lr': 0.0415633304130563, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02104411733091757}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 26, 'lr': 0.0415633304130563, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02104411733091757}"}}
exception: None

00:54:59 job_callback for (1, 0, 5) started
00:54:59 DISPATCHER: Trying to submit another job.
00:54:59 job_callback for (1, 0, 5) got condition
00:54:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:54:59 HBMASTER: Trying to run another job!
00:54:59 job_callback for (1, 0, 5) finished
00:54:59 start sampling a new configuration.
00:54:59 done sampling a new configuration.
00:54:59 HBMASTER: schedule new run for iteration 1
00:54:59 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
00:54:59 HBMASTER: submitting job (1, 0, 6) to dispatcher
00:54:59 DISPATCHER: trying to submit job (1, 0, 6)
00:54:59 DISPATCHER: trying to notify the job_runner thread.
00:54:59 HBMASTER: job (1, 0, 6) submitted to dispatcher
00:54:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:54:59 DISPATCHER: Trying to submit another job.
00:54:59 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:54:59 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:54:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:54:59 WORKER: start processing job (1, 0, 6)
00:54:59 WORKER: args: ()
00:54:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 2, 'lr': 0.08564797251880563, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.19620517724481665}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:55:45 DISPATCHER: Starting worker discovery
00:55:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:45 DISPATCHER: Finished worker discovery
00:56:45 DISPATCHER: Starting worker discovery
00:56:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:45 DISPATCHER: Finished worker discovery
00:57:17 WORKER: done with job (1, 0, 6), trying to register it.
00:57:17 WORKER: registered result for job (1, 0, 6) with dispatcher
00:57:17 DISPATCHER: job (1, 0, 6) finished
00:57:17 DISPATCHER: register_result: lock acquired
00:57:17 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:57:17 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 2, 'lr': 0.08564797251880563, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.19620517724481665}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 2, 'lr': 0.08564797251880563, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.19620517724481665}"}}
exception: None

00:57:17 job_callback for (1, 0, 6) started
00:57:17 DISPATCHER: Trying to submit another job.
00:57:17 job_callback for (1, 0, 6) got condition
00:57:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:57:17 HBMASTER: Trying to run another job!
00:57:17 job_callback for (1, 0, 6) finished
00:57:17 start sampling a new configuration.
00:57:17 done sampling a new configuration.
00:57:17 HBMASTER: schedule new run for iteration 1
00:57:17 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
00:57:17 HBMASTER: submitting job (1, 0, 7) to dispatcher
00:57:17 DISPATCHER: trying to submit job (1, 0, 7)
00:57:17 DISPATCHER: trying to notify the job_runner thread.
00:57:17 HBMASTER: job (1, 0, 7) submitted to dispatcher
00:57:17 DISPATCHER: Trying to submit another job.
00:57:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:57:17 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:57:17 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:57:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:57:17 WORKER: start processing job (1, 0, 7)
00:57:17 WORKER: args: ()
00:57:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.015157116177097535, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.028647451179356024}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:57:45 DISPATCHER: Starting worker discovery
00:57:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:45 DISPATCHER: Finished worker discovery
00:58:45 DISPATCHER: Starting worker discovery
00:58:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:45 DISPATCHER: Finished worker discovery
00:59:34 WORKER: done with job (1, 0, 7), trying to register it.
00:59:34 WORKER: registered result for job (1, 0, 7) with dispatcher
00:59:34 DISPATCHER: job (1, 0, 7) finished
00:59:34 DISPATCHER: register_result: lock acquired
00:59:34 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:59:34 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.015157116177097535, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.028647451179356024}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45580151996514706, 'info': {'data02': 0.45580151996514706, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.015157116177097535, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.028647451179356024}"}}
exception: None

00:59:34 job_callback for (1, 0, 7) started
00:59:34 DISPATCHER: Trying to submit another job.
00:59:34 job_callback for (1, 0, 7) got condition
00:59:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:34 HBMASTER: Trying to run another job!
00:59:34 job_callback for (1, 0, 7) finished
00:59:34 start sampling a new configuration.
00:59:34 best_vector: [2, 0.5489632439603047, 0.748264450621875, 0.5481716167638409, 0.164999505492938, 0, 0.4455173411449058, 0.07902406684532567], 0.004458171130739164, 0.8258324061486749, 0.003681702191920882
00:59:34 done sampling a new configuration.
00:59:34 HBMASTER: schedule new run for iteration 1
00:59:34 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:59:34 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:59:34 DISPATCHER: trying to submit job (1, 0, 8)
00:59:34 DISPATCHER: trying to notify the job_runner thread.
00:59:34 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:59:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:34 DISPATCHER: Trying to submit another job.
00:59:34 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:59:34 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:59:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:34 WORKER: start processing job (1, 0, 8)
00:59:34 WORKER: args: ()
00:59:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.012483697415441338, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012671052237740869}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:59:45 DISPATCHER: Starting worker discovery
00:59:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:45 DISPATCHER: Finished worker discovery
01:00:45 DISPATCHER: Starting worker discovery
01:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:45 DISPATCHER: Finished worker discovery
01:01:45 DISPATCHER: Starting worker discovery
01:01:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:45 DISPATCHER: Finished worker discovery
01:01:51 WORKER: done with job (1, 0, 8), trying to register it.
01:01:51 WORKER: registered result for job (1, 0, 8) with dispatcher
01:01:51 DISPATCHER: job (1, 0, 8) finished
01:01:51 DISPATCHER: register_result: lock acquired
01:01:51 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:01:51 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.012483697415441338, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012671052237740869}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4955727128185779, 'info': {'data02': 0.4955727128185779, 'config': "{'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.012483697415441338, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012671052237740869}"}}
exception: None

01:01:51 job_callback for (1, 0, 8) started
01:01:51 job_callback for (1, 0, 8) got condition
01:01:51 DISPATCHER: Trying to submit another job.
01:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:01:51 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.625120





01:01:51 HBMASTER: Trying to run another job!
01:01:51 job_callback for (1, 0, 8) finished
01:01:51 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
01:01:51 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
01:01:51 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
01:01:51 HBMASTER: schedule new run for iteration 1
01:01:51 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
01:01:51 HBMASTER: submitting job (1, 0, 0) to dispatcher
01:01:51 DISPATCHER: trying to submit job (1, 0, 0)
01:01:51 DISPATCHER: trying to notify the job_runner thread.
01:01:51 HBMASTER: job (1, 0, 0) submitted to dispatcher
01:01:51 DISPATCHER: Trying to submit another job.
01:01:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:01:51 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:01:51 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:01:51 WORKER: start processing job (1, 0, 0)
01:01:51 WORKER: args: ()
01:01:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 38, 'lr': 0.008634891741547756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.012937671527505367}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:02:45 DISPATCHER: Starting worker discovery
01:02:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:45 DISPATCHER: Finished worker discovery
01:03:45 DISPATCHER: Starting worker discovery
01:03:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:45 DISPATCHER: Finished worker discovery
01:04:45 DISPATCHER: Starting worker discovery
01:04:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:45 DISPATCHER: Finished worker discovery
01:05:45 DISPATCHER: Starting worker discovery
01:05:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:45 DISPATCHER: Finished worker discovery
01:06:45 DISPATCHER: Starting worker discovery
01:06:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:45 DISPATCHER: Finished worker discovery
01:07:45 DISPATCHER: Starting worker discovery
01:07:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:45 DISPATCHER: Finished worker discovery
01:08:35 WORKER: done with job (1, 0, 0), trying to register it.
01:08:35 WORKER: registered result for job (1, 0, 0) with dispatcher
01:08:35 DISPATCHER: job (1, 0, 0) finished
01:08:35 DISPATCHER: register_result: lock acquired
01:08:35 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:08:35 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 38, 'lr': 0.008634891741547756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.012937671527505367}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5293461087100415, 'info': {'data02': 0.5293461087100415, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 38, 'lr': 0.008634891741547756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.012937671527505367}"}}
exception: None

01:08:35 job_callback for (1, 0, 0) started
01:08:35 job_callback for (1, 0, 0) got condition
01:08:35 DISPATCHER: Trying to submit another job.
01:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:08:35 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:08:35 HBMASTER: Trying to run another job!
01:08:35 job_callback for (1, 0, 0) finished
01:08:35 HBMASTER: schedule new run for iteration 1
01:08:35 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
01:08:35 HBMASTER: submitting job (1, 0, 3) to dispatcher
01:08:35 DISPATCHER: trying to submit job (1, 0, 3)
01:08:35 DISPATCHER: trying to notify the job_runner thread.
01:08:35 HBMASTER: job (1, 0, 3) submitted to dispatcher
01:08:35 DISPATCHER: Trying to submit another job.
01:08:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:08:35 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:08:35 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:08:35 WORKER: start processing job (1, 0, 3)
01:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:08:35 WORKER: args: ()
01:08:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:08:45 DISPATCHER: Starting worker discovery
01:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:45 DISPATCHER: Finished worker discovery
01:09:45 DISPATCHER: Starting worker discovery
01:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:45 DISPATCHER: Finished worker discovery
01:10:45 DISPATCHER: Starting worker discovery
01:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:45 DISPATCHER: Finished worker discovery
01:11:45 DISPATCHER: Starting worker discovery
01:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:45 DISPATCHER: Finished worker discovery
01:12:45 DISPATCHER: Starting worker discovery
01:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:45 DISPATCHER: Finished worker discovery
01:13:45 DISPATCHER: Starting worker discovery
01:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:45 DISPATCHER: Finished worker discovery
01:14:45 DISPATCHER: Starting worker discovery
01:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:45 DISPATCHER: Finished worker discovery
01:15:19 WORKER: done with job (1, 0, 3), trying to register it.
01:15:19 WORKER: registered result for job (1, 0, 3) with dispatcher
01:15:19 DISPATCHER: job (1, 0, 3) finished
01:15:19 DISPATCHER: register_result: lock acquired
01:15:19 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:15:19 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.623684973838144, 'info': {'data02': 0.623684973838144, 'config': "{'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}"}}
exception: None

01:15:19 job_callback for (1, 0, 3) started
01:15:19 job_callback for (1, 0, 3) got condition
01:15:19 DISPATCHER: Trying to submit another job.
01:15:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:15:19 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:15:19 HBMASTER: Trying to run another job!
01:15:19 job_callback for (1, 0, 3) finished
01:15:19 HBMASTER: schedule new run for iteration 1
01:15:19 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
01:15:19 HBMASTER: submitting job (1, 0, 4) to dispatcher
01:15:19 DISPATCHER: trying to submit job (1, 0, 4)
01:15:19 DISPATCHER: trying to notify the job_runner thread.
01:15:19 HBMASTER: job (1, 0, 4) submitted to dispatcher
01:15:19 DISPATCHER: Trying to submit another job.
01:15:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:15:19 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:15:19 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:15:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:15:19 WORKER: start processing job (1, 0, 4)
01:15:19 WORKER: args: ()
01:15:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 67, 'last_n_outputs': 29, 'lr': 0.009706474277179217, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01380648797530175}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:15:45 DISPATCHER: Starting worker discovery
01:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:45 DISPATCHER: Finished worker discovery
01:16:45 DISPATCHER: Starting worker discovery
01:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:45 DISPATCHER: Finished worker discovery
01:17:45 DISPATCHER: Starting worker discovery
01:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:45 DISPATCHER: Finished worker discovery
01:18:45 DISPATCHER: Starting worker discovery
01:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:45 DISPATCHER: Finished worker discovery
01:19:45 DISPATCHER: Starting worker discovery
01:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:45 DISPATCHER: Finished worker discovery
01:20:45 DISPATCHER: Starting worker discovery
01:20:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:46 DISPATCHER: Finished worker discovery
01:21:46 DISPATCHER: Starting worker discovery
01:21:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:46 DISPATCHER: Finished worker discovery
01:22:02 WORKER: done with job (1, 0, 4), trying to register it.
01:22:02 WORKER: registered result for job (1, 0, 4) with dispatcher
01:22:02 DISPATCHER: job (1, 0, 4) finished
01:22:02 DISPATCHER: register_result: lock acquired
01:22:02 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:22:02 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 67, 'last_n_outputs': 29, 'lr': 0.009706474277179217, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01380648797530175}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6117630199265249, 'info': {'data02': 0.6117630199265249, 'config': "{'batch_size': 128, 'hidden_dim': 67, 'last_n_outputs': 29, 'lr': 0.009706474277179217, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01380648797530175}"}}
exception: None

01:22:02 job_callback for (1, 0, 4) started
01:22:02 DISPATCHER: Trying to submit another job.
01:22:02 job_callback for (1, 0, 4) got condition
01:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:02 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:22:02 HBMASTER: Trying to run another job!
01:22:02 job_callback for (1, 0, 4) finished
01:22:02 ITERATION: Advancing config (1, 0, 3) to next budget 1200.000000
01:22:02 HBMASTER: schedule new run for iteration 1
01:22:02 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
01:22:02 HBMASTER: submitting job (1, 0, 3) to dispatcher
01:22:02 DISPATCHER: trying to submit job (1, 0, 3)
01:22:02 DISPATCHER: trying to notify the job_runner thread.
01:22:02 HBMASTER: job (1, 0, 3) submitted to dispatcher
01:22:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:02 DISPATCHER: Trying to submit another job.
01:22:02 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:22:02 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:02 WORKER: start processing job (1, 0, 3)
01:22:02 WORKER: args: ()
01:22:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:22:46 DISPATCHER: Starting worker discovery
01:22:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:46 DISPATCHER: Finished worker discovery
01:23:46 DISPATCHER: Starting worker discovery
01:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:46 DISPATCHER: Finished worker discovery
01:24:46 DISPATCHER: Starting worker discovery
01:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:46 DISPATCHER: Finished worker discovery
01:25:46 DISPATCHER: Starting worker discovery
01:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:46 DISPATCHER: Finished worker discovery
01:26:46 DISPATCHER: Starting worker discovery
01:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:46 DISPATCHER: Finished worker discovery
01:27:46 DISPATCHER: Starting worker discovery
01:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:46 DISPATCHER: Finished worker discovery
01:28:46 DISPATCHER: Starting worker discovery
01:28:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:46 DISPATCHER: Finished worker discovery
01:29:46 DISPATCHER: Starting worker discovery
01:29:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:46 DISPATCHER: Finished worker discovery
01:30:46 DISPATCHER: Starting worker discovery
01:30:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:46 DISPATCHER: Finished worker discovery
01:31:46 DISPATCHER: Starting worker discovery
01:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:46 DISPATCHER: Finished worker discovery
01:32:46 DISPATCHER: Starting worker discovery
01:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:46 DISPATCHER: Finished worker discovery
01:33:46 DISPATCHER: Starting worker discovery
01:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:46 DISPATCHER: Finished worker discovery
01:34:46 DISPATCHER: Starting worker discovery
01:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:46 DISPATCHER: Finished worker discovery
01:35:46 DISPATCHER: Starting worker discovery
01:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:46 DISPATCHER: Finished worker discovery
01:36:46 DISPATCHER: Starting worker discovery
01:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:46 DISPATCHER: Finished worker discovery
01:37:46 DISPATCHER: Starting worker discovery
01:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:46 DISPATCHER: Finished worker discovery
01:38:46 DISPATCHER: Starting worker discovery
01:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:46 DISPATCHER: Finished worker discovery
01:39:46 DISPATCHER: Starting worker discovery
01:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:46 DISPATCHER: Finished worker discovery
01:40:46 DISPATCHER: Starting worker discovery
01:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:46 DISPATCHER: Finished worker discovery
01:41:46 DISPATCHER: Starting worker discovery
01:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:46 DISPATCHER: Finished worker discovery
01:42:06 WORKER: done with job (1, 0, 3), trying to register it.
01:42:06 WORKER: registered result for job (1, 0, 3) with dispatcher
01:42:06 DISPATCHER: job (1, 0, 3) finished
01:42:06 DISPATCHER: register_result: lock acquired
01:42:06 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:42:06 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5265289421536443, 'info': {'data02': 0.5265289421536443, 'config': "{'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 48, 'lr': 0.004895333760904307, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.01079275249134554}"}}
exception: None

01:42:06 job_callback for (1, 0, 3) started
01:42:06 job_callback for (1, 0, 3) got condition
01:42:06 DISPATCHER: Trying to submit another job.
01:42:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:06 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
01:42:06 HBMASTER: Trying to run another job!
01:42:06 job_callback for (1, 0, 3) finished
01:42:06 start sampling a new configuration.
01:42:06 done sampling a new configuration.
01:42:06 HBMASTER: schedule new run for iteration 2
01:42:06 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
01:42:06 HBMASTER: submitting job (2, 0, 0) to dispatcher
01:42:06 DISPATCHER: trying to submit job (2, 0, 0)
01:42:06 DISPATCHER: trying to notify the job_runner thread.
01:42:06 HBMASTER: job (2, 0, 0) submitted to dispatcher
01:42:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:06 DISPATCHER: Trying to submit another job.
01:42:06 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:42:06 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:42:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:06 WORKER: start processing job (2, 0, 0)
01:42:06 WORKER: args: ()
01:42:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 21, 'last_n_outputs': 49, 'lr': 0.031905281104822505, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.15258134088787353}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:42:46 DISPATCHER: Starting worker discovery
01:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:46 DISPATCHER: Finished worker discovery
01:43:46 DISPATCHER: Starting worker discovery
01:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:46 DISPATCHER: Finished worker discovery
01:44:46 DISPATCHER: Starting worker discovery
01:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:46 DISPATCHER: Finished worker discovery
01:45:46 DISPATCHER: Starting worker discovery
01:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:46 DISPATCHER: Finished worker discovery
01:46:46 DISPATCHER: Starting worker discovery
01:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:46 DISPATCHER: Finished worker discovery
01:47:46 DISPATCHER: Starting worker discovery
01:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:46 DISPATCHER: Finished worker discovery
01:48:46 DISPATCHER: Starting worker discovery
01:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:46 DISPATCHER: Finished worker discovery
01:48:50 WORKER: done with job (2, 0, 0), trying to register it.
01:48:50 WORKER: registered result for job (2, 0, 0) with dispatcher
01:48:50 DISPATCHER: job (2, 0, 0) finished
01:48:50 DISPATCHER: register_result: lock acquired
01:48:50 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:48:50 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 21, 'last_n_outputs': 49, 'lr': 0.031905281104822505, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.15258134088787353}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 21, 'last_n_outputs': 49, 'lr': 0.031905281104822505, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.15258134088787353}"}}
exception: None

01:48:50 job_callback for (2, 0, 0) started
01:48:50 DISPATCHER: Trying to submit another job.
01:48:50 job_callback for (2, 0, 0) got condition
01:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:48:50 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:48:50 HBMASTER: Trying to run another job!
01:48:50 job_callback for (2, 0, 0) finished
01:48:50 start sampling a new configuration.
01:48:50 done sampling a new configuration.
01:48:50 HBMASTER: schedule new run for iteration 2
01:48:50 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
01:48:50 HBMASTER: submitting job (2, 0, 1) to dispatcher
01:48:50 DISPATCHER: trying to submit job (2, 0, 1)
01:48:50 DISPATCHER: trying to notify the job_runner thread.
01:48:50 HBMASTER: job (2, 0, 1) submitted to dispatcher
01:48:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:48:50 DISPATCHER: Trying to submit another job.
01:48:50 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:48:50 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:48:50 WORKER: start processing job (2, 0, 1)
01:48:50 WORKER: args: ()
01:48:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.0038883524482918384, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.018113748295584497}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:49:46 DISPATCHER: Starting worker discovery
01:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:46 DISPATCHER: Finished worker discovery
01:50:46 DISPATCHER: Starting worker discovery
01:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:46 DISPATCHER: Finished worker discovery
01:51:46 DISPATCHER: Starting worker discovery
01:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:46 DISPATCHER: Finished worker discovery
01:52:46 DISPATCHER: Starting worker discovery
01:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:46 DISPATCHER: Finished worker discovery
01:53:46 DISPATCHER: Starting worker discovery
01:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:46 DISPATCHER: Finished worker discovery
01:54:46 DISPATCHER: Starting worker discovery
01:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:46 DISPATCHER: Finished worker discovery
01:55:34 WORKER: done with job (2, 0, 1), trying to register it.
01:55:34 WORKER: registered result for job (2, 0, 1) with dispatcher
01:55:34 DISPATCHER: job (2, 0, 1) finished
01:55:34 DISPATCHER: register_result: lock acquired
01:55:34 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
01:55:34 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.0038883524482918384, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.018113748295584497}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.018014855041315236, 'info': {'data02': -0.018014855041315236, 'config': "{'batch_size': 32, 'hidden_dim': 36, 'last_n_outputs': 18, 'lr': 0.0038883524482918384, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.018113748295584497}"}}
exception: None

01:55:34 job_callback for (2, 0, 1) started
01:55:34 DISPATCHER: Trying to submit another job.
01:55:34 job_callback for (2, 0, 1) got condition
01:55:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:34 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:55:34 HBMASTER: Trying to run another job!
01:55:34 job_callback for (2, 0, 1) finished
01:55:34 start sampling a new configuration.
01:55:34 done sampling a new configuration.
01:55:34 HBMASTER: schedule new run for iteration 2
01:55:34 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
01:55:34 HBMASTER: submitting job (2, 0, 2) to dispatcher
01:55:34 DISPATCHER: trying to submit job (2, 0, 2)
01:55:34 DISPATCHER: trying to notify the job_runner thread.
01:55:34 HBMASTER: job (2, 0, 2) submitted to dispatcher
01:55:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:34 DISPATCHER: Trying to submit another job.
01:55:34 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
01:55:34 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
01:55:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:34 WORKER: start processing job (2, 0, 2)
01:55:34 WORKER: args: ()
01:55:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 3, 'lr': 0.04739000300840745, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.014726574373752863}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:55:46 DISPATCHER: Starting worker discovery
01:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:46 DISPATCHER: Finished worker discovery
01:56:46 DISPATCHER: Starting worker discovery
01:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:46 DISPATCHER: Finished worker discovery
01:57:46 DISPATCHER: Starting worker discovery
01:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:46 DISPATCHER: Finished worker discovery
01:58:46 DISPATCHER: Starting worker discovery
01:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:46 DISPATCHER: Finished worker discovery
01:59:46 DISPATCHER: Starting worker discovery
01:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:46 DISPATCHER: Finished worker discovery
02:00:46 DISPATCHER: Starting worker discovery
02:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:46 DISPATCHER: Finished worker discovery
02:01:46 DISPATCHER: Starting worker discovery
02:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:46 DISPATCHER: Finished worker discovery
02:02:17 WORKER: done with job (2, 0, 2), trying to register it.
02:02:17 WORKER: registered result for job (2, 0, 2) with dispatcher
02:02:17 DISPATCHER: job (2, 0, 2) finished
02:02:17 DISPATCHER: register_result: lock acquired
02:02:17 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:02:17 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 3, 'lr': 0.04739000300840745, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.014726574373752863}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 3, 'lr': 0.04739000300840745, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.014726574373752863}"}}
exception: None

02:02:17 job_callback for (2, 0, 2) started
02:02:17 DISPATCHER: Trying to submit another job.
02:02:17 job_callback for (2, 0, 2) got condition
02:02:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:02:17 HBMASTER: Trying to run another job!
02:02:17 job_callback for (2, 0, 2) finished
02:02:17 start sampling a new configuration.
02:02:17 done sampling a new configuration.
02:02:17 HBMASTER: schedule new run for iteration 2
02:02:17 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
02:02:17 HBMASTER: submitting job (2, 0, 3) to dispatcher
02:02:17 DISPATCHER: trying to submit job (2, 0, 3)
02:02:17 DISPATCHER: trying to notify the job_runner thread.
02:02:17 HBMASTER: job (2, 0, 3) submitted to dispatcher
02:02:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:02:17 DISPATCHER: Trying to submit another job.
02:02:17 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:02:17 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:02:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:02:17 WORKER: start processing job (2, 0, 3)
02:02:17 WORKER: args: ()
02:02:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.00470970654721429, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04186145433093325}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:02:46 DISPATCHER: Starting worker discovery
02:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:46 DISPATCHER: Finished worker discovery
02:03:46 DISPATCHER: Starting worker discovery
02:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:46 DISPATCHER: Finished worker discovery
02:04:46 DISPATCHER: Starting worker discovery
02:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:46 DISPATCHER: Finished worker discovery
02:05:46 DISPATCHER: Starting worker discovery
02:05:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:46 DISPATCHER: Finished worker discovery
02:06:46 DISPATCHER: Starting worker discovery
02:06:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:46 DISPATCHER: Finished worker discovery
02:07:46 DISPATCHER: Starting worker discovery
02:07:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:46 DISPATCHER: Finished worker discovery
02:08:46 DISPATCHER: Starting worker discovery
02:08:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:46 DISPATCHER: Finished worker discovery
02:09:01 WORKER: done with job (2, 0, 3), trying to register it.
02:09:01 WORKER: registered result for job (2, 0, 3) with dispatcher
02:09:01 DISPATCHER: job (2, 0, 3) finished
02:09:01 DISPATCHER: register_result: lock acquired
02:09:01 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:09:01 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.00470970654721429, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04186145433093325}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07878613745046692, 'info': {'data02': 0.07878613745046692, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.00470970654721429, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04186145433093325}"}}
exception: None

02:09:01 job_callback for (2, 0, 3) started
02:09:01 job_callback for (2, 0, 3) got condition
02:09:01 DISPATCHER: Trying to submit another job.
02:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:09:01 HBMASTER: Trying to run another job!
02:09:01 job_callback for (2, 0, 3) finished
02:09:01 start sampling a new configuration.
02:09:01 done sampling a new configuration.
02:09:01 HBMASTER: schedule new run for iteration 2
02:09:01 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
02:09:01 HBMASTER: submitting job (2, 0, 4) to dispatcher
02:09:01 DISPATCHER: trying to submit job (2, 0, 4)
02:09:01 DISPATCHER: trying to notify the job_runner thread.
02:09:01 HBMASTER: job (2, 0, 4) submitted to dispatcher
02:09:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:09:01 DISPATCHER: Trying to submit another job.
02:09:01 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:09:01 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:09:01 WORKER: start processing job (2, 0, 4)
02:09:01 WORKER: args: ()
02:09:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 33, 'last_n_outputs': 5, 'lr': 0.01010556474447793, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.01183236125062396}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:09:46 DISPATCHER: Starting worker discovery
02:09:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:46 DISPATCHER: Finished worker discovery
02:10:46 DISPATCHER: Starting worker discovery
02:10:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:46 DISPATCHER: Finished worker discovery
02:11:46 DISPATCHER: Starting worker discovery
02:11:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:46 DISPATCHER: Finished worker discovery
02:12:46 DISPATCHER: Starting worker discovery
02:12:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:46 DISPATCHER: Finished worker discovery
02:13:46 DISPATCHER: Starting worker discovery
02:13:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:46 DISPATCHER: Finished worker discovery
02:14:46 DISPATCHER: Starting worker discovery
02:14:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:46 DISPATCHER: Finished worker discovery
02:15:45 WORKER: done with job (2, 0, 4), trying to register it.
02:15:45 WORKER: registered result for job (2, 0, 4) with dispatcher
02:15:45 DISPATCHER: job (2, 0, 4) finished
02:15:45 DISPATCHER: register_result: lock acquired
02:15:45 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:15:45 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 33, 'last_n_outputs': 5, 'lr': 0.01010556474447793, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.01183236125062396}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04757187583010578, 'info': {'data02': 0.04757187583010578, 'config': "{'batch_size': 64, 'hidden_dim': 33, 'last_n_outputs': 5, 'lr': 0.01010556474447793, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.01183236125062396}"}}
exception: None

02:15:45 job_callback for (2, 0, 4) started
02:15:45 job_callback for (2, 0, 4) got condition
02:15:45 DISPATCHER: Trying to submit another job.
02:15:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:15:45 HBMASTER: Trying to run another job!
02:15:45 job_callback for (2, 0, 4) finished
02:15:45 start sampling a new configuration.
02:15:45 best_vector: [2, 0.5713155429642572, 0.816797714555447, 0.37313414519853505, 0.09921336453792026, 0, 0.3614177254438753, 0.07972555486800029], 2.59247574572067e-05, 2112.9901477713033, 0.05477875709043838
02:15:45 done sampling a new configuration.
02:15:45 HBMASTER: schedule new run for iteration 2
02:15:45 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
02:15:45 HBMASTER: submitting job (2, 0, 5) to dispatcher
02:15:45 DISPATCHER: trying to submit job (2, 0, 5)
02:15:45 DISPATCHER: trying to notify the job_runner thread.
02:15:45 HBMASTER: job (2, 0, 5) submitted to dispatcher
02:15:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:15:45 DISPATCHER: Trying to submit another job.
02:15:45 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:15:45 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:15:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:15:45 WORKER: start processing job (2, 0, 5)
02:15:45 WORKER: args: ()
02:15:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 41, 'lr': 0.005575300631597145, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012697708076219566}, 'budget': 400.0, 'working_directory': '.'}
02:15:46 DISPATCHER: Starting worker discovery
02:15:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:46 DISPATCHER: Finished worker discovery
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:16:46 DISPATCHER: Starting worker discovery
02:16:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:46 DISPATCHER: Finished worker discovery
02:17:46 DISPATCHER: Starting worker discovery
02:17:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:46 DISPATCHER: Finished worker discovery
02:18:46 DISPATCHER: Starting worker discovery
02:18:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:46 DISPATCHER: Finished worker discovery
02:19:46 DISPATCHER: Starting worker discovery
02:19:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:46 DISPATCHER: Finished worker discovery
02:20:46 DISPATCHER: Starting worker discovery
02:20:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:46 DISPATCHER: Finished worker discovery
02:21:46 DISPATCHER: Starting worker discovery
02:21:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:46 DISPATCHER: Finished worker discovery
02:22:29 WORKER: done with job (2, 0, 5), trying to register it.
02:22:29 WORKER: registered result for job (2, 0, 5) with dispatcher
02:22:29 DISPATCHER: job (2, 0, 5) finished
02:22:29 DISPATCHER: register_result: lock acquired
02:22:29 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:22:29 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 41, 'lr': 0.005575300631597145, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012697708076219566}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5941238898889231, 'info': {'data02': 0.5941238898889231, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 41, 'lr': 0.005575300631597145, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012697708076219566}"}}
exception: None

02:22:29 job_callback for (2, 0, 5) started
02:22:29 job_callback for (2, 0, 5) got condition
02:22:29 DISPATCHER: Trying to submit another job.
02:22:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:22:29 HBMASTER: Trying to run another job!
02:22:29 job_callback for (2, 0, 5) finished
02:22:29 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
02:22:29 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
02:22:29 HBMASTER: schedule new run for iteration 2
02:22:29 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
02:22:29 HBMASTER: submitting job (2, 0, 3) to dispatcher
02:22:29 DISPATCHER: trying to submit job (2, 0, 3)
02:22:29 DISPATCHER: trying to notify the job_runner thread.
02:22:29 HBMASTER: job (2, 0, 3) submitted to dispatcher
02:22:29 DISPATCHER: Trying to submit another job.
02:22:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:22:29 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:22:29 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:22:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:22:29 WORKER: start processing job (2, 0, 3)
02:22:29 WORKER: args: ()
02:22:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.00470970654721429, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04186145433093325}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:22:46 DISPATCHER: Starting worker discovery
02:22:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:46 DISPATCHER: Finished worker discovery
02:23:46 DISPATCHER: Starting worker discovery
02:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:46 DISPATCHER: Finished worker discovery
02:24:46 DISPATCHER: Starting worker discovery
02:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:46 DISPATCHER: Finished worker discovery
02:25:46 DISPATCHER: Starting worker discovery
02:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:46 DISPATCHER: Finished worker discovery
02:26:46 DISPATCHER: Starting worker discovery
02:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:46 DISPATCHER: Finished worker discovery
02:27:46 DISPATCHER: Starting worker discovery
02:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:46 DISPATCHER: Finished worker discovery
02:28:46 DISPATCHER: Starting worker discovery
02:28:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:46 DISPATCHER: Finished worker discovery
02:29:46 DISPATCHER: Starting worker discovery
02:29:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:46 DISPATCHER: Finished worker discovery
02:30:46 DISPATCHER: Starting worker discovery
02:30:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:46 DISPATCHER: Finished worker discovery
02:31:46 DISPATCHER: Starting worker discovery
02:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:46 DISPATCHER: Finished worker discovery
02:32:46 DISPATCHER: Starting worker discovery
02:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:46 DISPATCHER: Finished worker discovery
02:33:46 DISPATCHER: Starting worker discovery
02:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:46 DISPATCHER: Finished worker discovery
02:34:46 DISPATCHER: Starting worker discovery
02:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:46 DISPATCHER: Finished worker discovery
02:35:46 DISPATCHER: Starting worker discovery
02:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:46 DISPATCHER: Finished worker discovery
02:36:46 DISPATCHER: Starting worker discovery
02:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:46 DISPATCHER: Finished worker discovery
02:37:46 DISPATCHER: Starting worker discovery
02:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:46 DISPATCHER: Finished worker discovery
02:38:46 DISPATCHER: Starting worker discovery
02:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:46 DISPATCHER: Finished worker discovery
02:39:46 DISPATCHER: Starting worker discovery
02:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:46 DISPATCHER: Finished worker discovery
02:40:46 DISPATCHER: Starting worker discovery
02:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:46 DISPATCHER: Finished worker discovery
02:41:46 DISPATCHER: Starting worker discovery
02:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:46 DISPATCHER: Finished worker discovery
02:42:33 WORKER: done with job (2, 0, 3), trying to register it.
02:42:33 WORKER: registered result for job (2, 0, 3) with dispatcher
02:42:33 DISPATCHER: job (2, 0, 3) finished
02:42:33 DISPATCHER: register_result: lock acquired
02:42:33 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
02:42:33 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.00470970654721429, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04186145433093325}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.116176443794695, 'info': {'data02': 0.116176443794695, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.00470970654721429, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04186145433093325}"}}
exception: None

02:42:33 job_callback for (2, 0, 3) started
02:42:33 job_callback for (2, 0, 3) got condition
02:42:33 DISPATCHER: Trying to submit another job.
02:42:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:42:33 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
02:42:33 HBMASTER: Trying to run another job!
02:42:33 job_callback for (2, 0, 3) finished
02:42:33 HBMASTER: schedule new run for iteration 2
02:42:33 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
02:42:33 HBMASTER: submitting job (2, 0, 5) to dispatcher
02:42:33 DISPATCHER: trying to submit job (2, 0, 5)
02:42:33 DISPATCHER: trying to notify the job_runner thread.
02:42:33 HBMASTER: job (2, 0, 5) submitted to dispatcher
02:42:33 DISPATCHER: Trying to submit another job.
02:42:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:42:33 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
02:42:33 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
02:42:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:42:33 WORKER: start processing job (2, 0, 5)
02:42:33 WORKER: args: ()
02:42:33 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 41, 'lr': 0.005575300631597145, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012697708076219566}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:42:46 DISPATCHER: Starting worker discovery
02:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:46 DISPATCHER: Finished worker discovery
02:43:46 DISPATCHER: Starting worker discovery
02:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:46 DISPATCHER: Finished worker discovery
02:44:46 DISPATCHER: Starting worker discovery
02:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:46 DISPATCHER: Finished worker discovery
02:45:46 DISPATCHER: Starting worker discovery
02:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:46 DISPATCHER: Finished worker discovery
02:46:46 DISPATCHER: Starting worker discovery
02:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:46 DISPATCHER: Finished worker discovery
02:47:46 DISPATCHER: Starting worker discovery
02:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:46 DISPATCHER: Finished worker discovery
02:48:46 DISPATCHER: Starting worker discovery
02:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:46 DISPATCHER: Finished worker discovery
02:49:46 DISPATCHER: Starting worker discovery
02:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:46 DISPATCHER: Finished worker discovery
02:50:46 DISPATCHER: Starting worker discovery
02:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:46 DISPATCHER: Finished worker discovery
02:51:46 DISPATCHER: Starting worker discovery
02:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:46 DISPATCHER: Finished worker discovery
02:52:46 DISPATCHER: Starting worker discovery
02:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:46 DISPATCHER: Finished worker discovery
02:53:46 DISPATCHER: Starting worker discovery
02:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:46 DISPATCHER: Finished worker discovery
02:54:46 DISPATCHER: Starting worker discovery
02:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:46 DISPATCHER: Finished worker discovery
02:55:46 DISPATCHER: Starting worker discovery
02:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:46 DISPATCHER: Finished worker discovery
02:56:46 DISPATCHER: Starting worker discovery
02:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:46 DISPATCHER: Finished worker discovery
02:57:46 DISPATCHER: Starting worker discovery
02:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:46 DISPATCHER: Finished worker discovery
02:58:46 DISPATCHER: Starting worker discovery
02:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:46 DISPATCHER: Finished worker discovery
02:59:46 DISPATCHER: Starting worker discovery
02:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:46 DISPATCHER: Finished worker discovery
03:00:46 DISPATCHER: Starting worker discovery
03:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:46 DISPATCHER: Finished worker discovery
03:01:46 DISPATCHER: Starting worker discovery
03:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:46 DISPATCHER: Finished worker discovery
03:02:37 WORKER: done with job (2, 0, 5), trying to register it.
03:02:37 WORKER: registered result for job (2, 0, 5) with dispatcher
03:02:37 DISPATCHER: job (2, 0, 5) finished
03:02:37 DISPATCHER: register_result: lock acquired
03:02:37 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:02:37 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 41, 'lr': 0.005575300631597145, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012697708076219566}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6071841332219232, 'info': {'data02': 0.6071841332219232, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 41, 'lr': 0.005575300631597145, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012697708076219566}"}}
exception: None

03:02:37 job_callback for (2, 0, 5) started
03:02:37 DISPATCHER: Trying to submit another job.
03:02:37 job_callback for (2, 0, 5) got condition
03:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:37 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:02:37 HBMASTER: Trying to run another job!
03:02:37 job_callback for (2, 0, 5) finished
03:02:37 start sampling a new configuration.
03:02:37 best_vector: [3, 0.4350946609933003, 0.6153577973766954, 0.48776666535797547, 0.10062857929535404, 0, 0.9159158106850553, 0.046162205718826066], 1.30637196606947e-05, 1268.699445915225, 0.016573933895115196
03:02:37 done sampling a new configuration.
03:02:37 HBMASTER: schedule new run for iteration 3
03:02:37 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
03:02:37 HBMASTER: submitting job (3, 0, 0) to dispatcher
03:02:37 DISPATCHER: trying to submit job (3, 0, 0)
03:02:37 DISPATCHER: trying to notify the job_runner thread.
03:02:37 HBMASTER: job (3, 0, 0) submitted to dispatcher
03:02:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:37 DISPATCHER: Trying to submit another job.
03:02:37 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:02:37 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:37 WORKER: start processing job (3, 0, 0)
03:02:37 WORKER: args: ()
03:02:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 31, 'lr': 0.009452209323480986, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.011483080630353025}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:02:46 DISPATCHER: Starting worker discovery
03:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:46 DISPATCHER: Finished worker discovery
03:03:46 DISPATCHER: Starting worker discovery
03:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:46 DISPATCHER: Finished worker discovery
03:04:46 DISPATCHER: Starting worker discovery
03:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:46 DISPATCHER: Finished worker discovery
03:05:46 DISPATCHER: Starting worker discovery
03:05:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:46 DISPATCHER: Finished worker discovery
03:06:46 DISPATCHER: Starting worker discovery
03:06:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:46 DISPATCHER: Finished worker discovery
03:07:46 DISPATCHER: Starting worker discovery
03:07:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:46 DISPATCHER: Finished worker discovery
03:08:46 DISPATCHER: Starting worker discovery
03:08:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:46 DISPATCHER: Finished worker discovery
03:09:46 DISPATCHER: Starting worker discovery
03:09:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:46 DISPATCHER: Finished worker discovery
03:10:46 DISPATCHER: Starting worker discovery
03:10:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:46 DISPATCHER: Finished worker discovery
03:11:46 DISPATCHER: Starting worker discovery
03:11:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:46 DISPATCHER: Finished worker discovery
03:12:46 DISPATCHER: Starting worker discovery
03:12:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:46 DISPATCHER: Finished worker discovery
03:13:46 DISPATCHER: Starting worker discovery
03:13:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:46 DISPATCHER: Finished worker discovery
03:14:46 DISPATCHER: Starting worker discovery
03:14:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:46 DISPATCHER: Finished worker discovery
03:15:46 DISPATCHER: Starting worker discovery
03:15:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:46 DISPATCHER: Finished worker discovery
03:16:46 DISPATCHER: Starting worker discovery
03:16:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:46 DISPATCHER: Finished worker discovery
03:17:46 DISPATCHER: Starting worker discovery
03:17:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:46 DISPATCHER: Finished worker discovery
03:18:46 DISPATCHER: Starting worker discovery
03:18:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:46 DISPATCHER: Finished worker discovery
03:19:46 DISPATCHER: Starting worker discovery
03:19:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:46 DISPATCHER: Finished worker discovery
03:20:46 DISPATCHER: Starting worker discovery
03:20:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:46 DISPATCHER: Finished worker discovery
03:21:46 DISPATCHER: Starting worker discovery
03:21:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:46 DISPATCHER: Finished worker discovery
03:22:41 WORKER: done with job (3, 0, 0), trying to register it.
03:22:41 WORKER: registered result for job (3, 0, 0) with dispatcher
03:22:41 DISPATCHER: job (3, 0, 0) finished
03:22:41 DISPATCHER: register_result: lock acquired
03:22:41 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:22:41 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 31, 'lr': 0.009452209323480986, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.011483080630353025}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5905221151249093, 'info': {'data02': 0.5905221151249093, 'config': "{'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 31, 'lr': 0.009452209323480986, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.011483080630353025}"}}
exception: None

03:22:41 job_callback for (3, 0, 0) started
03:22:41 DISPATCHER: Trying to submit another job.
03:22:41 job_callback for (3, 0, 0) got condition
03:22:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:41 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:22:41 HBMASTER: Trying to run another job!
03:22:41 job_callback for (3, 0, 0) finished
03:22:41 start sampling a new configuration.
03:22:41 best_vector: [2, 0.03425755108412616, 0.15254360751859053, 0.34688727764247906, 0.10071575530608567, 0, 0.815277555504302, 0.10745267686356548], 6.259330472375459e-06, 2394.15560910604, 0.014985811159686065
03:22:41 done sampling a new configuration.
03:22:41 HBMASTER: schedule new run for iteration 3
03:22:41 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
03:22:41 HBMASTER: submitting job (3, 0, 1) to dispatcher
03:22:41 DISPATCHER: trying to submit job (3, 0, 1)
03:22:41 DISPATCHER: trying to notify the job_runner thread.
03:22:41 HBMASTER: job (3, 0, 1) submitted to dispatcher
03:22:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:41 DISPATCHER: Trying to submit another job.
03:22:41 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:22:41 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:22:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:41 WORKER: start processing job (3, 0, 1)
03:22:41 WORKER: args: ()
03:22:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 8, 'lr': 0.004940541541108264, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.013797460382225523}, 'budget': 1200.0, 'working_directory': '.'}
03:22:46 DISPATCHER: Starting worker discovery
03:22:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:46 DISPATCHER: Finished worker discovery
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:23:46 DISPATCHER: Starting worker discovery
03:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:46 DISPATCHER: Finished worker discovery
03:24:46 DISPATCHER: Starting worker discovery
03:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:46 DISPATCHER: Finished worker discovery
03:25:46 DISPATCHER: Starting worker discovery
03:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:46 DISPATCHER: Finished worker discovery
03:26:46 DISPATCHER: Starting worker discovery
03:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:46 DISPATCHER: Finished worker discovery
03:27:46 DISPATCHER: Starting worker discovery
03:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:46 DISPATCHER: Finished worker discovery
03:28:46 DISPATCHER: Starting worker discovery
03:28:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:46 DISPATCHER: Finished worker discovery
03:29:46 DISPATCHER: Starting worker discovery
03:29:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:46 DISPATCHER: Finished worker discovery
03:30:46 DISPATCHER: Starting worker discovery
03:30:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:46 DISPATCHER: Finished worker discovery
03:31:46 DISPATCHER: Starting worker discovery
03:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:46 DISPATCHER: Finished worker discovery
03:32:46 DISPATCHER: Starting worker discovery
03:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:46 DISPATCHER: Finished worker discovery
03:33:46 DISPATCHER: Starting worker discovery
03:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:46 DISPATCHER: Finished worker discovery
03:34:46 DISPATCHER: Starting worker discovery
03:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:46 DISPATCHER: Finished worker discovery
03:35:46 DISPATCHER: Starting worker discovery
03:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:46 DISPATCHER: Finished worker discovery
03:36:46 DISPATCHER: Starting worker discovery
03:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:46 DISPATCHER: Finished worker discovery
03:37:46 DISPATCHER: Starting worker discovery
03:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:46 DISPATCHER: Finished worker discovery
03:38:46 DISPATCHER: Starting worker discovery
03:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:46 DISPATCHER: Finished worker discovery
03:39:46 DISPATCHER: Starting worker discovery
03:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:46 DISPATCHER: Finished worker discovery
03:40:46 DISPATCHER: Starting worker discovery
03:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:46 DISPATCHER: Finished worker discovery
03:41:46 DISPATCHER: Starting worker discovery
03:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:46 DISPATCHER: Finished worker discovery
03:42:45 WORKER: done with job (3, 0, 1), trying to register it.
03:42:45 WORKER: registered result for job (3, 0, 1) with dispatcher
03:42:45 DISPATCHER: job (3, 0, 1) finished
03:42:45 DISPATCHER: register_result: lock acquired
03:42:45 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
03:42:45 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 8, 'lr': 0.004940541541108264, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.013797460382225523}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.35145924234513165, 'info': {'data02': 0.35145924234513165, 'config': "{'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 8, 'lr': 0.004940541541108264, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.013797460382225523}"}}
exception: None

03:42:45 job_callback for (3, 0, 1) started
03:42:45 job_callback for (3, 0, 1) got condition
03:42:45 DISPATCHER: Trying to submit another job.
03:42:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:45 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:42:45 HBMASTER: Trying to run another job!
03:42:45 job_callback for (3, 0, 1) finished
03:42:45 start sampling a new configuration.
03:42:45 best_vector: [2, 0.4204634364983383, 0.5849270379349013, 0.5758397279919114, 0.09943305412131355, 0, 0.4332258513848088, 0.019480040259304693], 4.304695127311237e-05, 2533.3838309746634, 0.10905445032805708
03:42:45 done sampling a new configuration.
03:42:45 HBMASTER: schedule new run for iteration 3
03:42:45 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
03:42:45 HBMASTER: submitting job (3, 0, 2) to dispatcher
03:42:45 DISPATCHER: trying to submit job (3, 0, 2)
03:42:45 DISPATCHER: trying to notify the job_runner thread.
03:42:45 HBMASTER: job (3, 0, 2) submitted to dispatcher
03:42:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:45 DISPATCHER: Trying to submit another job.
03:42:45 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
03:42:45 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
03:42:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:45 WORKER: start processing job (3, 0, 2)
03:42:45 WORKER: args: ()
03:42:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 30, 'lr': 0.014180105303224392, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.010600933659128543}, 'budget': 1200.0, 'working_directory': '.'}
03:42:46 DISPATCHER: Starting worker discovery
03:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:46 DISPATCHER: Finished worker discovery
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:43:46 DISPATCHER: Starting worker discovery
03:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:46 DISPATCHER: Finished worker discovery
03:44:46 DISPATCHER: Starting worker discovery
03:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:46 DISPATCHER: Finished worker discovery
03:45:46 DISPATCHER: Starting worker discovery
03:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:46 DISPATCHER: Finished worker discovery
03:46:46 DISPATCHER: Starting worker discovery
03:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:46 DISPATCHER: Finished worker discovery
03:47:46 DISPATCHER: Starting worker discovery
03:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:46 DISPATCHER: Finished worker discovery
03:48:46 DISPATCHER: Starting worker discovery
03:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:46 DISPATCHER: Finished worker discovery
03:49:46 DISPATCHER: Starting worker discovery
03:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:46 DISPATCHER: Finished worker discovery
03:50:46 DISPATCHER: Starting worker discovery
03:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:46 DISPATCHER: Finished worker discovery
03:51:46 DISPATCHER: Starting worker discovery
03:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:46 DISPATCHER: Finished worker discovery
03:52:46 DISPATCHER: Starting worker discovery
03:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:46 DISPATCHER: Finished worker discovery
03:53:46 DISPATCHER: Starting worker discovery
03:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:46 DISPATCHER: Finished worker discovery
03:54:46 DISPATCHER: Starting worker discovery
03:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:46 DISPATCHER: Finished worker discovery
03:55:46 DISPATCHER: Starting worker discovery
03:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:46 DISPATCHER: Finished worker discovery
03:56:46 DISPATCHER: Starting worker discovery
03:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:46 DISPATCHER: Finished worker discovery
03:57:46 DISPATCHER: Starting worker discovery
03:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:46 DISPATCHER: Finished worker discovery
03:58:46 DISPATCHER: Starting worker discovery
03:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:46 DISPATCHER: Finished worker discovery
03:59:46 DISPATCHER: Starting worker discovery
03:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:46 DISPATCHER: Finished worker discovery
04:00:46 DISPATCHER: Starting worker discovery
04:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:46 DISPATCHER: Finished worker discovery
04:01:46 DISPATCHER: Starting worker discovery
04:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:46 DISPATCHER: Finished worker discovery
04:02:46 DISPATCHER: Starting worker discovery
04:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:46 DISPATCHER: Finished worker discovery
04:02:49 WORKER: done with job (3, 0, 2), trying to register it.
04:02:49 WORKER: registered result for job (3, 0, 2) with dispatcher
04:02:49 DISPATCHER: job (3, 0, 2) finished
04:02:49 DISPATCHER: register_result: lock acquired
04:02:49 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:02:49 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 30, 'lr': 0.014180105303224392, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.010600933659128543}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5928230061424771, 'info': {'data02': 0.5928230061424771, 'config': "{'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 30, 'lr': 0.014180105303224392, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.010600933659128543}"}}
exception: None

04:02:49 job_callback for (3, 0, 2) started
04:02:49 DISPATCHER: Trying to submit another job.
04:02:49 job_callback for (3, 0, 2) got condition
04:02:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:02:49 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:02:49 HBMASTER: Trying to run another job!
04:02:49 job_callback for (3, 0, 2) finished
04:02:49 start sampling a new configuration.
04:02:49 best_vector: [2, 0.3193198691368971, 0.9895182500275794, 0.5659034946874377, 0.0995100847287169, 0, 0.2113851759363621, 0.041621068818243116], 1.0051617799048477e-05, 617.4364707839426, 0.006206235419513552
04:02:49 done sampling a new configuration.
04:02:49 HBMASTER: schedule new run for iteration 3
04:02:49 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
04:02:49 HBMASTER: submitting job (3, 0, 3) to dispatcher
04:02:49 DISPATCHER: trying to submit job (3, 0, 3)
04:02:49 DISPATCHER: trying to notify the job_runner thread.
04:02:49 HBMASTER: job (3, 0, 3) submitted to dispatcher
04:02:49 DISPATCHER: Trying to submit another job.
04:02:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:02:49 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:02:49 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:02:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:02:49 WORKER: start processing job (3, 0, 3)
04:02:49 WORKER: args: ()
04:02:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 45, 'last_n_outputs': 50, 'lr': 0.013545872682941067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011327922235374184}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:03:46 DISPATCHER: Starting worker discovery
04:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:47 DISPATCHER: Finished worker discovery
04:04:47 DISPATCHER: Starting worker discovery
04:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:47 DISPATCHER: Finished worker discovery
04:05:47 DISPATCHER: Starting worker discovery
04:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:47 DISPATCHER: Finished worker discovery
04:06:47 DISPATCHER: Starting worker discovery
04:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:47 DISPATCHER: Finished worker discovery
04:07:47 DISPATCHER: Starting worker discovery
04:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:47 DISPATCHER: Finished worker discovery
04:08:47 DISPATCHER: Starting worker discovery
04:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:47 DISPATCHER: Finished worker discovery
04:09:47 DISPATCHER: Starting worker discovery
04:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:47 DISPATCHER: Finished worker discovery
04:10:47 DISPATCHER: Starting worker discovery
04:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:47 DISPATCHER: Finished worker discovery
04:11:47 DISPATCHER: Starting worker discovery
04:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:47 DISPATCHER: Finished worker discovery
04:12:47 DISPATCHER: Starting worker discovery
04:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:47 DISPATCHER: Finished worker discovery
04:13:47 DISPATCHER: Starting worker discovery
04:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:47 DISPATCHER: Finished worker discovery
04:14:47 DISPATCHER: Starting worker discovery
04:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:47 DISPATCHER: Finished worker discovery
04:15:47 DISPATCHER: Starting worker discovery
04:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:47 DISPATCHER: Finished worker discovery
04:16:47 DISPATCHER: Starting worker discovery
04:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:47 DISPATCHER: Finished worker discovery
04:17:47 DISPATCHER: Starting worker discovery
04:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:47 DISPATCHER: Finished worker discovery
04:18:47 DISPATCHER: Starting worker discovery
04:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:47 DISPATCHER: Finished worker discovery
04:19:47 DISPATCHER: Starting worker discovery
04:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:47 DISPATCHER: Finished worker discovery
04:20:47 DISPATCHER: Starting worker discovery
04:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:47 DISPATCHER: Finished worker discovery
04:21:47 DISPATCHER: Starting worker discovery
04:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:47 DISPATCHER: Finished worker discovery
04:22:47 DISPATCHER: Starting worker discovery
04:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:47 DISPATCHER: Finished worker discovery
04:22:54 WORKER: done with job (3, 0, 3), trying to register it.
04:22:54 WORKER: registered result for job (3, 0, 3) with dispatcher
04:22:54 DISPATCHER: job (3, 0, 3) finished
04:22:54 DISPATCHER: register_result: lock acquired
04:22:54 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:22:54 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 45, 'last_n_outputs': 50, 'lr': 0.013545872682941067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011327922235374184}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.531905987065175, 'info': {'data02': 0.531905987065175, 'config': "{'batch_size': 64, 'hidden_dim': 45, 'last_n_outputs': 50, 'lr': 0.013545872682941067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011327922235374184}"}}
exception: None

04:22:54 job_callback for (3, 0, 3) started
04:22:54 DISPATCHER: Trying to submit another job.
04:22:54 job_callback for (3, 0, 3) got condition
04:22:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:54 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:22:54 HBMASTER: Trying to run another job!
04:22:54 job_callback for (3, 0, 3) finished
04:22:54 start sampling a new configuration.
04:22:54 best_vector: [2, 0.38209023420337507, 0.9312791169597162, 0.6105524824609571, 0.10068057473184433, 0, 0.4552760336244072, 0.1304295709329732], 2.137865829890554e-05, 1205.1145268443483, 0.025763731680452553
04:22:54 done sampling a new configuration.
04:22:54 HBMASTER: schedule new run for iteration 4
04:22:54 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
04:22:54 HBMASTER: submitting job (4, 0, 0) to dispatcher
04:22:54 DISPATCHER: trying to submit job (4, 0, 0)
04:22:54 DISPATCHER: trying to notify the job_runner thread.
04:22:54 HBMASTER: job (4, 0, 0) submitted to dispatcher
04:22:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:54 DISPATCHER: Trying to submit another job.
04:22:54 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:22:54 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:22:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:54 WORKER: start processing job (4, 0, 0)
04:22:54 WORKER: args: ()
04:22:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 47, 'lr': 0.016638147302664753, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.014780624505789243}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:23:43 WORKER: done with job (4, 0, 0), trying to register it.
04:23:43 WORKER: registered result for job (4, 0, 0) with dispatcher
04:23:43 DISPATCHER: job (4, 0, 0) finished
04:23:43 DISPATCHER: register_result: lock acquired
04:23:43 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:23:43 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 47, 'lr': 0.016638147302664753, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.014780624505789243}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33814421249028953, 'info': {'data02': 0.33814421249028953, 'config': "{'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 47, 'lr': 0.016638147302664753, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.014780624505789243}"}}
exception: None

04:23:43 job_callback for (4, 0, 0) started
04:23:43 DISPATCHER: Trying to submit another job.
04:23:43 job_callback for (4, 0, 0) got condition
04:23:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:23:43 HBMASTER: Trying to run another job!
04:23:43 job_callback for (4, 0, 0) finished
04:23:43 start sampling a new configuration.
04:23:43 best_vector: [2, 0.35412841718636207, 0.06099705650546072, 0.4081438269102388, 0.10036631123384647, 0, 0.7688729534989627, 0.15156124064998017], 2.5781143934543906e-05, 1493.6194273820158, 0.0385072174407668
04:23:43 done sampling a new configuration.
04:23:43 HBMASTER: schedule new run for iteration 4
04:23:43 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:23:43 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:23:43 DISPATCHER: trying to submit job (4, 0, 1)
04:23:43 DISPATCHER: trying to notify the job_runner thread.
04:23:43 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:23:43 DISPATCHER: Trying to submit another job.
04:23:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:23:43 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:23:43 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:23:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:23:43 WORKER: start processing job (4, 0, 1)
04:23:43 WORKER: args: ()
04:23:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 4, 'lr': 0.006550699142619312, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01574656101268291}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:23:47 DISPATCHER: Starting worker discovery
04:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:24:31 WORKER: done with job (4, 0, 1), trying to register it.
04:24:31 WORKER: registered result for job (4, 0, 1) with dispatcher
04:24:31 DISPATCHER: job (4, 0, 1) finished
04:24:31 DISPATCHER: register_result: lock acquired
04:24:31 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:24:31 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 4, 'lr': 0.006550699142619312, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01574656101268291}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2822144580373502, 'info': {'data02': 0.2822144580373502, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 4, 'lr': 0.006550699142619312, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01574656101268291}"}}
exception: None

04:24:31 job_callback for (4, 0, 1) started
04:24:31 DISPATCHER: Trying to submit another job.
04:24:31 job_callback for (4, 0, 1) got condition
04:24:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:31 HBMASTER: Trying to run another job!
04:24:31 job_callback for (4, 0, 1) finished
04:24:31 start sampling a new configuration.
04:24:31 best_vector: [2, 0.0914954875535347, 0.8225175610425488, 0.5871691063387607, 0.09855754201638574, 0, 0.5959400879409955, 0.09051527128155655], 6.162415316838075e-05, 314.9885596655882, 0.019410903247119846
04:24:31 done sampling a new configuration.
04:24:31 HBMASTER: schedule new run for iteration 4
04:24:31 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:24:31 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:24:31 DISPATCHER: trying to submit job (4, 0, 2)
04:24:31 DISPATCHER: trying to notify the job_runner thread.
04:24:31 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:24:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:31 DISPATCHER: Trying to submit another job.
04:24:31 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:24:31 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:24:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:31 WORKER: start processing job (4, 0, 2)
04:24:31 WORKER: args: ()
04:24:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 27, 'last_n_outputs': 42, 'lr': 0.01493957396119625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.013114842609178464}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:24:47 DISPATCHER: Starting worker discovery
04:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:47 DISPATCHER: Finished worker discovery
04:25:19 WORKER: done with job (4, 0, 2), trying to register it.
04:25:19 WORKER: registered result for job (4, 0, 2) with dispatcher
04:25:19 DISPATCHER: job (4, 0, 2) finished
04:25:19 DISPATCHER: register_result: lock acquired
04:25:19 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:25:19 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 27, 'last_n_outputs': 42, 'lr': 0.01493957396119625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.013114842609178464}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47018969522954474, 'info': {'data02': 0.47018969522954474, 'config': "{'batch_size': 64, 'hidden_dim': 27, 'last_n_outputs': 42, 'lr': 0.01493957396119625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.013114842609178464}"}}
exception: None

04:25:19 job_callback for (4, 0, 2) started
04:25:19 DISPATCHER: Trying to submit another job.
04:25:19 job_callback for (4, 0, 2) got condition
04:25:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:19 HBMASTER: Trying to run another job!
04:25:19 job_callback for (4, 0, 2) finished
04:25:19 start sampling a new configuration.
04:25:19 done sampling a new configuration.
04:25:19 HBMASTER: schedule new run for iteration 4
04:25:19 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
04:25:19 HBMASTER: submitting job (4, 0, 3) to dispatcher
04:25:19 DISPATCHER: trying to submit job (4, 0, 3)
04:25:19 DISPATCHER: trying to notify the job_runner thread.
04:25:19 HBMASTER: job (4, 0, 3) submitted to dispatcher
04:25:19 DISPATCHER: Trying to submit another job.
04:25:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:19 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:25:19 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:25:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:19 WORKER: start processing job (4, 0, 3)
04:25:19 WORKER: args: ()
04:25:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 47, 'lr': 0.08473576785578797, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.011128703314506393}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:25:47 DISPATCHER: Starting worker discovery
04:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:47 DISPATCHER: Finished worker discovery
04:26:07 WORKER: done with job (4, 0, 3), trying to register it.
04:26:07 WORKER: registered result for job (4, 0, 3) with dispatcher
04:26:07 DISPATCHER: job (4, 0, 3) finished
04:26:07 DISPATCHER: register_result: lock acquired
04:26:07 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:26:07 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 47, 'lr': 0.08473576785578797, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.011128703314506393}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 47, 'lr': 0.08473576785578797, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.011128703314506393}"}}
exception: None

04:26:07 job_callback for (4, 0, 3) started
04:26:07 job_callback for (4, 0, 3) got condition
04:26:07 DISPATCHER: Trying to submit another job.
04:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:07 HBMASTER: Trying to run another job!
04:26:07 job_callback for (4, 0, 3) finished
04:26:07 start sampling a new configuration.
04:26:07 best_vector: [2, 0.34374899692076966, 0.7311341924934266, 0.6759440210968881, 0.09948832097549663, 0, 0.3241861023723033, 0.04315656946668019], 8.989038665258517e-05, 682.2121544544414, 0.061324314343002895
04:26:07 done sampling a new configuration.
04:26:07 HBMASTER: schedule new run for iteration 4
04:26:07 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:26:07 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:26:07 DISPATCHER: trying to submit job (4, 0, 4)
04:26:07 DISPATCHER: trying to notify the job_runner thread.
04:26:07 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:26:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:07 DISPATCHER: Trying to submit another job.
04:26:07 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:26:07 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:07 WORKER: start processing job (4, 0, 4)
04:26:07 WORKER: args: ()
04:26:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 37, 'lr': 0.02248474891432153, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.011380150128944007}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:26:47 DISPATCHER: Starting worker discovery
04:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:47 DISPATCHER: Finished worker discovery
04:26:56 WORKER: done with job (4, 0, 4), trying to register it.
04:26:56 WORKER: registered result for job (4, 0, 4) with dispatcher
04:26:56 DISPATCHER: job (4, 0, 4) finished
04:26:56 DISPATCHER: register_result: lock acquired
04:26:56 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:26:56 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 37, 'lr': 0.02248474891432153, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.011380150128944007}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4831789963999612, 'info': {'data02': 0.4831789963999612, 'config': "{'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 37, 'lr': 0.02248474891432153, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.011380150128944007}"}}
exception: None

04:26:56 job_callback for (4, 0, 4) started
04:26:56 job_callback for (4, 0, 4) got condition
04:26:56 DISPATCHER: Trying to submit another job.
04:26:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:56 HBMASTER: Trying to run another job!
04:26:56 job_callback for (4, 0, 4) finished
04:26:56 start sampling a new configuration.
04:26:56 best_vector: [2, 0.6600878897308273, 0.9089366380825087, 0.5006595831262477, 0.09959763620300592, 0, 0.7967784722332598, 0.08653155043550192], 7.045175877098593e-06, 2381.088942968252, 0.016775190382226118
04:26:56 done sampling a new configuration.
04:26:56 HBMASTER: schedule new run for iteration 4
04:26:56 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:26:56 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:26:56 DISPATCHER: trying to submit job (4, 0, 5)
04:26:56 DISPATCHER: trying to notify the job_runner thread.
04:26:56 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:26:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:56 DISPATCHER: Trying to submit another job.
04:26:56 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:26:56 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:26:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:56 WORKER: start processing job (4, 0, 5)
04:26:56 WORKER: args: ()
04:26:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.010030421104030499, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01295925819588768}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:27:44 WORKER: done with job (4, 0, 5), trying to register it.
04:27:44 WORKER: registered result for job (4, 0, 5) with dispatcher
04:27:44 DISPATCHER: job (4, 0, 5) finished
04:27:44 DISPATCHER: register_result: lock acquired
04:27:44 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:27:44 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.010030421104030499, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01295925819588768}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5121468072539291, 'info': {'data02': 0.5121468072539291, 'config': "{'batch_size': 64, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.010030421104030499, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01295925819588768}"}}
exception: None

04:27:44 job_callback for (4, 0, 5) started
04:27:44 job_callback for (4, 0, 5) got condition
04:27:44 DISPATCHER: Trying to submit another job.
04:27:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:27:44 HBMASTER: Trying to run another job!
04:27:44 job_callback for (4, 0, 5) finished
04:27:44 start sampling a new configuration.
04:27:44 done sampling a new configuration.
04:27:44 HBMASTER: schedule new run for iteration 4
04:27:44 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
04:27:44 HBMASTER: submitting job (4, 0, 6) to dispatcher
04:27:44 DISPATCHER: trying to submit job (4, 0, 6)
04:27:44 DISPATCHER: trying to notify the job_runner thread.
04:27:44 HBMASTER: job (4, 0, 6) submitted to dispatcher
04:27:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:27:44 DISPATCHER: Trying to submit another job.
04:27:44 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:27:44 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:27:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:27:44 WORKER: start processing job (4, 0, 6)
04:27:44 WORKER: args: ()
04:27:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 25, 'lr': 0.06218417113821119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.015683108205095456}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:27:47 DISPATCHER: Starting worker discovery
04:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:28:33 WORKER: done with job (4, 0, 6), trying to register it.
04:28:33 WORKER: registered result for job (4, 0, 6) with dispatcher
04:28:33 DISPATCHER: job (4, 0, 6) finished
04:28:33 DISPATCHER: register_result: lock acquired
04:28:33 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:28:33 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 25, 'lr': 0.06218417113821119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.015683108205095456}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 25, 'lr': 0.06218417113821119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.015683108205095456}"}}
exception: None

04:28:33 job_callback for (4, 0, 6) started
04:28:33 job_callback for (4, 0, 6) got condition
04:28:33 DISPATCHER: Trying to submit another job.
04:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:28:33 HBMASTER: Trying to run another job!
04:28:33 job_callback for (4, 0, 6) finished
04:28:33 start sampling a new configuration.
04:28:33 done sampling a new configuration.
04:28:33 HBMASTER: schedule new run for iteration 4
04:28:33 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:28:33 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:28:33 DISPATCHER: trying to submit job (4, 0, 7)
04:28:33 DISPATCHER: trying to notify the job_runner thread.
04:28:33 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:28:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:28:33 DISPATCHER: Trying to submit another job.
04:28:33 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:28:33 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:28:33 WORKER: start processing job (4, 0, 7)
04:28:33 WORKER: args: ()
04:28:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.006465609784661624, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.03334079882839866}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:28:47 DISPATCHER: Starting worker discovery
04:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:47 DISPATCHER: Finished worker discovery
04:29:21 WORKER: done with job (4, 0, 7), trying to register it.
04:29:21 WORKER: registered result for job (4, 0, 7) with dispatcher
04:29:21 DISPATCHER: job (4, 0, 7) finished
04:29:21 DISPATCHER: register_result: lock acquired
04:29:21 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:29:21 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.006465609784661624, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.03334079882839866}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00965109550391772, 'info': {'data02': 0.00965109550391772, 'config': "{'batch_size': 128, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.006465609784661624, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.03334079882839866}"}}
exception: None

04:29:21 job_callback for (4, 0, 7) started
04:29:21 job_callback for (4, 0, 7) got condition
04:29:21 DISPATCHER: Trying to submit another job.
04:29:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:21 HBMASTER: Trying to run another job!
04:29:21 job_callback for (4, 0, 7) finished
04:29:21 start sampling a new configuration.
04:29:21 done sampling a new configuration.
04:29:21 HBMASTER: schedule new run for iteration 4
04:29:21 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
04:29:21 HBMASTER: submitting job (4, 0, 8) to dispatcher
04:29:21 DISPATCHER: trying to submit job (4, 0, 8)
04:29:21 DISPATCHER: trying to notify the job_runner thread.
04:29:21 HBMASTER: job (4, 0, 8) submitted to dispatcher
04:29:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:21 DISPATCHER: Trying to submit another job.
04:29:21 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:29:21 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:29:21 WORKER: start processing job (4, 0, 8)
04:29:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:21 WORKER: args: ()
04:29:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 46, 'lr': 0.003931646258035757, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01946645345817235}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:29:47 DISPATCHER: Starting worker discovery
04:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:47 DISPATCHER: Finished worker discovery
04:30:09 WORKER: done with job (4, 0, 8), trying to register it.
04:30:09 WORKER: registered result for job (4, 0, 8) with dispatcher
04:30:09 DISPATCHER: job (4, 0, 8) finished
04:30:09 DISPATCHER: register_result: lock acquired
04:30:09 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:30:09 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 46, 'lr': 0.003931646258035757, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01946645345817235}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43842503841534664, 'info': {'data02': 0.43842503841534664, 'config': "{'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 46, 'lr': 0.003931646258035757, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01946645345817235}"}}
exception: None

04:30:09 job_callback for (4, 0, 8) started
04:30:09 DISPATCHER: Trying to submit another job.
04:30:09 job_callback for (4, 0, 8) got condition
04:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:30:09 HBMASTER: Trying to run another job!
04:30:09 job_callback for (4, 0, 8) finished
04:30:09 start sampling a new configuration.
04:30:09 best_vector: [2, 0.6331363165384057, 0.8660643324994116, 0.5470379121601069, 0.10087996598404521, 0, 0.6670911881417373, 0.13729733801683866], 2.1884315767872586e-05, 1809.453925478027, 0.039598661072577736
04:30:09 done sampling a new configuration.
04:30:09 HBMASTER: schedule new run for iteration 4
04:30:09 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:30:09 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:30:09 DISPATCHER: trying to submit job (4, 0, 9)
04:30:09 DISPATCHER: trying to notify the job_runner thread.
04:30:09 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:30:09 DISPATCHER: Trying to submit another job.
04:30:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:30:09 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:30:09 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:30:09 WORKER: start processing job (4, 0, 9)
04:30:09 WORKER: args: ()
04:30:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 44, 'lr': 0.012418691090146254, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01508787075181241}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:30:47 DISPATCHER: Starting worker discovery
04:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:47 DISPATCHER: Finished worker discovery
04:30:58 WORKER: done with job (4, 0, 9), trying to register it.
04:30:58 WORKER: registered result for job (4, 0, 9) with dispatcher
04:30:58 DISPATCHER: job (4, 0, 9) finished
04:30:58 DISPATCHER: register_result: lock acquired
04:30:58 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:30:58 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 44, 'lr': 0.012418691090146254, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01508787075181241}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5634808074769952, 'info': {'data02': 0.5634808074769952, 'config': "{'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 44, 'lr': 0.012418691090146254, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01508787075181241}"}}
exception: None

04:30:58 job_callback for (4, 0, 9) started
04:30:58 DISPATCHER: Trying to submit another job.
04:30:58 job_callback for (4, 0, 9) got condition
04:30:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:30:58 HBMASTER: Trying to run another job!
04:30:58 job_callback for (4, 0, 9) finished
04:30:58 start sampling a new configuration.
04:30:58 best_vector: [3, 0.7404571561916651, 0.7721530986883246, 0.3996913539995597, 0.09926668663022635, 0, 0.10385828974436415, 0.09269430075884764], 2.5052525772812322e-05, 871.7105035065501, 0.021838549855529053
04:30:58 done sampling a new configuration.
04:30:58 HBMASTER: schedule new run for iteration 4
04:30:58 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:30:58 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:30:58 DISPATCHER: trying to submit job (4, 0, 10)
04:30:58 DISPATCHER: trying to notify the job_runner thread.
04:30:58 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:30:58 DISPATCHER: Trying to submit another job.
04:30:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:30:58 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:30:58 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:30:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:30:58 WORKER: start processing job (4, 0, 10)
04:30:58 WORKER: args: ()
04:30:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.006300611593606866, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013200733567608309}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:31:46 WORKER: done with job (4, 0, 10), trying to register it.
04:31:46 WORKER: registered result for job (4, 0, 10) with dispatcher
04:31:46 DISPATCHER: job (4, 0, 10) finished
04:31:46 DISPATCHER: register_result: lock acquired
04:31:46 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:31:46 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.006300611593606866, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013200733567608309}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5083573247060246, 'info': {'data02': 0.5083573247060246, 'config': "{'batch_size': 128, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.006300611593606866, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013200733567608309}"}}
exception: None

04:31:46 job_callback for (4, 0, 10) started
04:31:46 DISPATCHER: Trying to submit another job.
04:31:46 job_callback for (4, 0, 10) got condition
04:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:46 HBMASTER: Trying to run another job!
04:31:46 job_callback for (4, 0, 10) finished
04:31:46 start sampling a new configuration.
04:31:46 best_vector: [2, 0.6127319964344728, 0.6489707090109146, 0.43255072443833753, 0.1008006179167097, 0, 0.3293244352679971, 0.05691892225601982], 3.310121375465739e-05, 3140.1446883797526, 0.10394260055061019
04:31:46 done sampling a new configuration.
04:31:46 HBMASTER: schedule new run for iteration 4
04:31:46 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:31:46 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:31:46 DISPATCHER: trying to submit job (4, 0, 11)
04:31:46 DISPATCHER: trying to notify the job_runner thread.
04:31:46 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:31:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:46 DISPATCHER: Trying to submit another job.
04:31:46 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:31:46 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:46 WORKER: start processing job (4, 0, 11)
04:31:46 WORKER: args: ()
04:31:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:31:47 DISPATCHER: Starting worker discovery
04:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:32:34 WORKER: done with job (4, 0, 11), trying to register it.
04:32:34 WORKER: registered result for job (4, 0, 11) with dispatcher
04:32:34 DISPATCHER: job (4, 0, 11) finished
04:32:34 DISPATCHER: register_result: lock acquired
04:32:34 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:32:34 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6355343735542893, 'info': {'data02': 0.6355343735542893, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}"}}
exception: None

04:32:34 job_callback for (4, 0, 11) started
04:32:34 job_callback for (4, 0, 11) got condition
04:32:34 DISPATCHER: Trying to submit another job.
04:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:32:34 HBMASTER: Trying to run another job!
04:32:34 job_callback for (4, 0, 11) finished
04:32:34 start sampling a new configuration.
04:32:34 done sampling a new configuration.
04:32:34 HBMASTER: schedule new run for iteration 4
04:32:34 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:32:34 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:32:34 DISPATCHER: trying to submit job (4, 0, 12)
04:32:34 DISPATCHER: trying to notify the job_runner thread.
04:32:34 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:32:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:32:34 DISPATCHER: Trying to submit another job.
04:32:34 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:32:34 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:32:34 WORKER: start processing job (4, 0, 12)
04:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:32:34 WORKER: args: ()
04:32:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 4, 'lr': 0.0077226039771051665, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.09245591753713728}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:32:47 DISPATCHER: Starting worker discovery
04:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:47 DISPATCHER: Finished worker discovery
04:33:22 WORKER: done with job (4, 0, 12), trying to register it.
04:33:22 WORKER: registered result for job (4, 0, 12) with dispatcher
04:33:22 DISPATCHER: job (4, 0, 12) finished
04:33:22 DISPATCHER: register_result: lock acquired
04:33:22 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:33:22 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 4, 'lr': 0.0077226039771051665, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.09245591753713728}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.008714450522817078, 'info': {'data02': -0.008714450522817078, 'config': "{'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 4, 'lr': 0.0077226039771051665, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.09245591753713728}"}}
exception: None

04:33:22 job_callback for (4, 0, 12) started
04:33:22 job_callback for (4, 0, 12) got condition
04:33:22 DISPATCHER: Trying to submit another job.
04:33:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:33:22 HBMASTER: Trying to run another job!
04:33:22 job_callback for (4, 0, 12) finished
04:33:22 start sampling a new configuration.
04:33:22 done sampling a new configuration.
04:33:22 HBMASTER: schedule new run for iteration 4
04:33:22 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
04:33:22 HBMASTER: submitting job (4, 0, 13) to dispatcher
04:33:22 DISPATCHER: trying to submit job (4, 0, 13)
04:33:22 DISPATCHER: trying to notify the job_runner thread.
04:33:22 HBMASTER: job (4, 0, 13) submitted to dispatcher
04:33:22 DISPATCHER: Trying to submit another job.
04:33:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:33:22 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:33:22 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:33:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:33:22 WORKER: start processing job (4, 0, 13)
04:33:22 WORKER: args: ()
04:33:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 39, 'lr': 0.07474995626467326, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.019528282456695637}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:33:47 DISPATCHER: Starting worker discovery
04:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:47 DISPATCHER: Finished worker discovery
04:34:10 WORKER: done with job (4, 0, 13), trying to register it.
04:34:10 WORKER: registered result for job (4, 0, 13) with dispatcher
04:34:10 DISPATCHER: job (4, 0, 13) finished
04:34:10 DISPATCHER: register_result: lock acquired
04:34:10 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:34:10 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 39, 'lr': 0.07474995626467326, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.019528282456695637}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16375843571607332, 'info': {'data02': 0.16375843571607332, 'config': "{'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 39, 'lr': 0.07474995626467326, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.019528282456695637}"}}
exception: None

04:34:10 job_callback for (4, 0, 13) started
04:34:10 job_callback for (4, 0, 13) got condition
04:34:10 DISPATCHER: Trying to submit another job.
04:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:34:10 HBMASTER: Trying to run another job!
04:34:10 job_callback for (4, 0, 13) finished
04:34:10 start sampling a new configuration.
04:34:10 best_vector: [2, 0.5438869848330679, 0.7535681548921334, 0.3929414020793956, 0.09996682162398104, 0, 0.35349653134766723, 0.0428332876255692], 1.9838481638881564e-05, 3058.35504639393, 0.06067312043306675
04:34:10 done sampling a new configuration.
04:34:10 HBMASTER: schedule new run for iteration 4
04:34:10 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:34:10 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:34:10 DISPATCHER: trying to submit job (4, 0, 14)
04:34:10 DISPATCHER: trying to notify the job_runner thread.
04:34:10 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:34:10 DISPATCHER: Trying to submit another job.
04:34:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:34:10 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:34:10 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:34:10 WORKER: start processing job (4, 0, 14)
04:34:10 WORKER: args: ()
04:34:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.006107771823674849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011369134177382056}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:34:47 DISPATCHER: Starting worker discovery
04:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:47 DISPATCHER: Finished worker discovery
04:34:58 WORKER: done with job (4, 0, 14), trying to register it.
04:34:58 WORKER: registered result for job (4, 0, 14) with dispatcher
04:34:58 DISPATCHER: job (4, 0, 14) finished
04:34:58 DISPATCHER: register_result: lock acquired
04:34:58 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:34:58 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.006107771823674849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011369134177382056}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5937080607674642, 'info': {'data02': 0.5937080607674642, 'config': "{'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.006107771823674849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011369134177382056}"}}
exception: None

04:34:58 job_callback for (4, 0, 14) started
04:34:58 DISPATCHER: Trying to submit another job.
04:34:58 job_callback for (4, 0, 14) got condition
04:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:34:58 HBMASTER: Trying to run another job!
04:34:58 job_callback for (4, 0, 14) finished
04:34:58 start sampling a new configuration.
04:34:58 best_vector: [2, 0.6055636010016197, 0.9949648783635417, 0.45107667272449836, 0.1006959192230704, 0, 0.9843568973897054, 0.02334279864704074], 4.3584025257901956e-06, 683.9333248363762, 0.0029808567304389485
04:34:58 done sampling a new configuration.
04:34:58 HBMASTER: schedule new run for iteration 4
04:34:58 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
04:34:58 HBMASTER: submitting job (4, 0, 15) to dispatcher
04:34:58 DISPATCHER: trying to submit job (4, 0, 15)
04:34:58 DISPATCHER: trying to notify the job_runner thread.
04:34:58 HBMASTER: job (4, 0, 15) submitted to dispatcher
04:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:34:58 DISPATCHER: Trying to submit another job.
04:34:58 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:34:58 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:34:58 WORKER: start processing job (4, 0, 15)
04:34:58 WORKER: args: ()
04:34:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:35:46 WORKER: done with job (4, 0, 15), trying to register it.
04:35:47 WORKER: registered result for job (4, 0, 15) with dispatcher
04:35:47 DISPATCHER: job (4, 0, 15) finished
04:35:47 DISPATCHER: register_result: lock acquired
04:35:47 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:35:47 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5821751346850328, 'info': {'data02': 0.5821751346850328, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}"}}
exception: None

04:35:47 job_callback for (4, 0, 15) started
04:35:47 job_callback for (4, 0, 15) got condition
04:35:47 DISPATCHER: Trying to submit another job.
04:35:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:35:47 DISPATCHER: Starting worker discovery
04:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:47 DISPATCHER: Finished worker discovery
04:35:47 HBMASTER: Trying to run another job!
04:35:47 job_callback for (4, 0, 15) finished
04:35:47 start sampling a new configuration.
04:35:47 best_vector: [0, 0.9264275732445933, 0.8388500160440303, 0.6280270199913452, 0.09745537100071089, 1, 0.8066154361568096, 0.39892216414657794], 0.0, inf, 0.020839520714000755
04:35:47 done sampling a new configuration.
04:35:47 HBMASTER: schedule new run for iteration 4
04:35:47 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:35:47 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:35:47 DISPATCHER: trying to submit job (4, 0, 16)
04:35:47 DISPATCHER: trying to notify the job_runner thread.
04:35:47 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:35:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:35:47 DISPATCHER: Trying to submit another job.
04:35:47 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:35:47 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:35:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:35:47 WORKER: start processing job (4, 0, 16)
04:35:47 WORKER: args: ()
04:35:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 42, 'lr': 0.018032421073063493, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.033037692108121776}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:36:36 WORKER: done with job (4, 0, 16), trying to register it.
04:36:36 WORKER: registered result for job (4, 0, 16) with dispatcher
04:36:36 DISPATCHER: job (4, 0, 16) finished
04:36:36 DISPATCHER: register_result: lock acquired
04:36:36 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:36:36 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 42, 'lr': 0.018032421073063493, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.033037692108121776}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21372034258461098, 'info': {'data02': 0.21372034258461098, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 42, 'lr': 0.018032421073063493, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.033037692108121776}"}}
exception: None

04:36:36 job_callback for (4, 0, 16) started
04:36:36 job_callback for (4, 0, 16) got condition
04:36:36 DISPATCHER: Trying to submit another job.
04:36:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:36:36 HBMASTER: Trying to run another job!
04:36:36 job_callback for (4, 0, 16) finished
04:36:36 start sampling a new configuration.
04:36:36 best_vector: [3, 0.3329022573512441, 0.5725949470464808, 0.6062514541844425, 0.10037563575007748, 0, 0.90935205960448, 0.024548085480122106], 2.1189286465684703e-05, 304.8821396011593, 0.006460234994279839
04:36:36 done sampling a new configuration.
04:36:36 HBMASTER: schedule new run for iteration 4
04:36:36 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:36:36 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:36:36 DISPATCHER: trying to submit job (4, 0, 17)
04:36:36 DISPATCHER: trying to notify the job_runner thread.
04:36:36 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:36:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:36:36 DISPATCHER: Trying to submit another job.
04:36:36 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:36:36 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:36:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:36:36 WORKER: start processing job (4, 0, 17)
04:36:36 WORKER: args: ()
04:36:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.016311838328490636, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010763110414294123}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:36:47 DISPATCHER: Starting worker discovery
04:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:47 DISPATCHER: Finished worker discovery
04:37:24 WORKER: done with job (4, 0, 17), trying to register it.
04:37:24 WORKER: registered result for job (4, 0, 17) with dispatcher
04:37:24 DISPATCHER: job (4, 0, 17) finished
04:37:24 DISPATCHER: register_result: lock acquired
04:37:24 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:37:24 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.016311838328490636, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010763110414294123}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5958408684706289, 'info': {'data02': 0.5958408684706289, 'config': "{'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.016311838328490636, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010763110414294123}"}}
exception: None

04:37:24 job_callback for (4, 0, 17) started
04:37:24 job_callback for (4, 0, 17) got condition
04:37:24 DISPATCHER: Trying to submit another job.
04:37:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:37:24 HBMASTER: Trying to run another job!
04:37:24 job_callback for (4, 0, 17) finished
04:37:24 start sampling a new configuration.
04:37:24 done sampling a new configuration.
04:37:24 HBMASTER: schedule new run for iteration 4
04:37:24 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
04:37:24 HBMASTER: submitting job (4, 0, 18) to dispatcher
04:37:24 DISPATCHER: trying to submit job (4, 0, 18)
04:37:24 DISPATCHER: trying to notify the job_runner thread.
04:37:24 HBMASTER: job (4, 0, 18) submitted to dispatcher
04:37:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:37:24 DISPATCHER: Trying to submit another job.
04:37:24 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:37:24 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:37:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:37:24 WORKER: start processing job (4, 0, 18)
04:37:24 WORKER: args: ()
04:37:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 39, 'lr': 0.030100616046794405, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.05934737906867479}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:37:47 DISPATCHER: Starting worker discovery
04:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:47 DISPATCHER: Finished worker discovery
04:38:13 WORKER: done with job (4, 0, 18), trying to register it.
04:38:13 WORKER: registered result for job (4, 0, 18) with dispatcher
04:38:13 DISPATCHER: job (4, 0, 18) finished
04:38:13 DISPATCHER: register_result: lock acquired
04:38:13 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:38:13 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 39, 'lr': 0.030100616046794405, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.05934737906867479}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 39, 'lr': 0.030100616046794405, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.05934737906867479}"}}
exception: None

04:38:13 job_callback for (4, 0, 18) started
04:38:13 job_callback for (4, 0, 18) got condition
04:38:13 DISPATCHER: Trying to submit another job.
04:38:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:38:13 HBMASTER: Trying to run another job!
04:38:13 job_callback for (4, 0, 18) finished
04:38:13 start sampling a new configuration.
04:38:13 done sampling a new configuration.
04:38:13 HBMASTER: schedule new run for iteration 4
04:38:13 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
04:38:13 HBMASTER: submitting job (4, 0, 19) to dispatcher
04:38:13 DISPATCHER: trying to submit job (4, 0, 19)
04:38:13 DISPATCHER: trying to notify the job_runner thread.
04:38:13 HBMASTER: job (4, 0, 19) submitted to dispatcher
04:38:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:38:13 DISPATCHER: Trying to submit another job.
04:38:13 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:38:13 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:38:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:38:13 WORKER: start processing job (4, 0, 19)
04:38:13 WORKER: args: ()
04:38:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 7, 'lr': 0.0048560950788825346, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.03772182831441673}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:38:47 DISPATCHER: Starting worker discovery
04:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:47 DISPATCHER: Finished worker discovery
04:39:01 WORKER: done with job (4, 0, 19), trying to register it.
04:39:01 WORKER: registered result for job (4, 0, 19) with dispatcher
04:39:01 DISPATCHER: job (4, 0, 19) finished
04:39:01 DISPATCHER: register_result: lock acquired
04:39:01 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:39:01 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 7, 'lr': 0.0048560950788825346, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.03772182831441673}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 7, 'lr': 0.0048560950788825346, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.03772182831441673}"}}
exception: None

04:39:01 job_callback for (4, 0, 19) started
04:39:01 job_callback for (4, 0, 19) got condition
04:39:01 DISPATCHER: Trying to submit another job.
04:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:39:01 HBMASTER: Trying to run another job!
04:39:01 job_callback for (4, 0, 19) finished
04:39:01 start sampling a new configuration.
04:39:01 done sampling a new configuration.
04:39:01 HBMASTER: schedule new run for iteration 4
04:39:01 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:39:01 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:39:01 DISPATCHER: trying to submit job (4, 0, 20)
04:39:01 DISPATCHER: trying to notify the job_runner thread.
04:39:01 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:39:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:39:01 DISPATCHER: Trying to submit another job.
04:39:01 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:39:01 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:39:01 WORKER: start processing job (4, 0, 20)
04:39:01 WORKER: args: ()
04:39:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 44, 'last_n_outputs': 16, 'lr': 0.03390106389835731, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.020742743721268584}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:39:47 DISPATCHER: Starting worker discovery
04:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:47 DISPATCHER: Finished worker discovery
04:39:49 WORKER: done with job (4, 0, 20), trying to register it.
04:39:49 WORKER: registered result for job (4, 0, 20) with dispatcher
04:39:49 DISPATCHER: job (4, 0, 20) finished
04:39:49 DISPATCHER: register_result: lock acquired
04:39:49 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:39:49 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 44, 'last_n_outputs': 16, 'lr': 0.03390106389835731, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.020742743721268584}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.025884682654577832, 'info': {'data02': -0.025884682654577832, 'config': "{'batch_size': 64, 'hidden_dim': 44, 'last_n_outputs': 16, 'lr': 0.03390106389835731, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.020742743721268584}"}}
exception: None

04:39:49 job_callback for (4, 0, 20) started
04:39:49 job_callback for (4, 0, 20) got condition
04:39:49 DISPATCHER: Trying to submit another job.
04:39:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:39:49 HBMASTER: Trying to run another job!
04:39:49 job_callback for (4, 0, 20) finished
04:39:49 start sampling a new configuration.
04:39:49 best_vector: [2, 0.061206834139747895, 0.04516817472320078, 0.428113673032343, 0.0989580193647615, 0, 0.7613461476790294, 0.11003657866850217], 1.1356472627961037e-05, 1457.6000987225375, 0.016553195623655804
04:39:49 done sampling a new configuration.
04:39:49 HBMASTER: schedule new run for iteration 4
04:39:49 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
04:39:49 HBMASTER: submitting job (4, 0, 21) to dispatcher
04:39:49 DISPATCHER: trying to submit job (4, 0, 21)
04:39:49 DISPATCHER: trying to notify the job_runner thread.
04:39:49 HBMASTER: job (4, 0, 21) submitted to dispatcher
04:39:49 DISPATCHER: Trying to submit another job.
04:39:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:39:49 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:39:49 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:39:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:39:49 WORKER: start processing job (4, 0, 21)
04:39:49 WORKER: args: ()
04:39:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 3, 'lr': 0.007181701432213169, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01390467650806517}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:40:37 WORKER: done with job (4, 0, 21), trying to register it.
04:40:37 WORKER: registered result for job (4, 0, 21) with dispatcher
04:40:37 DISPATCHER: job (4, 0, 21) finished
04:40:37 DISPATCHER: register_result: lock acquired
04:40:37 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:40:37 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 3, 'lr': 0.007181701432213169, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01390467650806517}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21674258990069376, 'info': {'data02': 0.21674258990069376, 'config': "{'batch_size': 64, 'hidden_dim': 24, 'last_n_outputs': 3, 'lr': 0.007181701432213169, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01390467650806517}"}}
exception: None

04:40:37 job_callback for (4, 0, 21) started
04:40:37 job_callback for (4, 0, 21) got condition
04:40:37 DISPATCHER: Trying to submit another job.
04:40:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:40:37 HBMASTER: Trying to run another job!
04:40:37 job_callback for (4, 0, 21) finished
04:40:37 start sampling a new configuration.
04:40:37 done sampling a new configuration.
04:40:37 HBMASTER: schedule new run for iteration 4
04:40:37 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
04:40:37 HBMASTER: submitting job (4, 0, 22) to dispatcher
04:40:37 DISPATCHER: trying to submit job (4, 0, 22)
04:40:37 DISPATCHER: trying to notify the job_runner thread.
04:40:37 HBMASTER: job (4, 0, 22) submitted to dispatcher
04:40:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:40:37 DISPATCHER: Trying to submit another job.
04:40:37 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:40:37 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:40:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:40:37 WORKER: start processing job (4, 0, 22)
04:40:37 WORKER: args: ()
04:40:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 25, 'lr': 0.03334468779115512, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.014124954125584375}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:40:47 DISPATCHER: Starting worker discovery
04:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:47 DISPATCHER: Finished worker discovery
04:41:26 WORKER: done with job (4, 0, 22), trying to register it.
04:41:26 WORKER: registered result for job (4, 0, 22) with dispatcher
04:41:26 DISPATCHER: job (4, 0, 22) finished
04:41:26 DISPATCHER: register_result: lock acquired
04:41:26 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:41:26 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 25, 'lr': 0.03334468779115512, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.014124954125584375}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17721639867996034, 'info': {'data02': 0.17721639867996034, 'config': "{'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 25, 'lr': 0.03334468779115512, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.014124954125584375}"}}
exception: None

04:41:26 job_callback for (4, 0, 22) started
04:41:26 job_callback for (4, 0, 22) got condition
04:41:26 DISPATCHER: Trying to submit another job.
04:41:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:41:26 HBMASTER: Trying to run another job!
04:41:26 job_callback for (4, 0, 22) finished
04:41:26 start sampling a new configuration.
04:41:26 done sampling a new configuration.
04:41:26 HBMASTER: schedule new run for iteration 4
04:41:26 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
04:41:26 HBMASTER: submitting job (4, 0, 23) to dispatcher
04:41:26 DISPATCHER: trying to submit job (4, 0, 23)
04:41:26 DISPATCHER: trying to notify the job_runner thread.
04:41:26 HBMASTER: job (4, 0, 23) submitted to dispatcher
04:41:26 DISPATCHER: Trying to submit another job.
04:41:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:41:26 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:41:26 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:41:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:41:26 WORKER: start processing job (4, 0, 23)
04:41:26 WORKER: args: ()
04:41:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 19, 'lr': 0.002267238240792297, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03128108382659565}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:41:47 DISPATCHER: Starting worker discovery
04:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:47 DISPATCHER: Finished worker discovery
04:42:13 WORKER: done with job (4, 0, 23), trying to register it.
04:42:13 WORKER: registered result for job (4, 0, 23) with dispatcher
04:42:13 DISPATCHER: job (4, 0, 23) finished
04:42:13 DISPATCHER: register_result: lock acquired
04:42:13 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:42:13 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 19, 'lr': 0.002267238240792297, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03128108382659565}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 19, 'lr': 0.002267238240792297, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03128108382659565}"}}
exception: None

04:42:13 job_callback for (4, 0, 23) started
04:42:13 job_callback for (4, 0, 23) got condition
04:42:13 DISPATCHER: Trying to submit another job.
04:42:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:42:13 HBMASTER: Trying to run another job!
04:42:13 job_callback for (4, 0, 23) finished
04:42:13 start sampling a new configuration.
04:42:14 best_vector: [2, 0.5355903703439031, 0.8976688155579273, 0.4600438225833445, 0.09867990299396064, 0, 0.6463880005806714, 0.1002564991325787], 2.073040200595675e-05, 1715.4214058939467, 0.03556137535380502
04:42:14 done sampling a new configuration.
04:42:14 HBMASTER: schedule new run for iteration 4
04:42:14 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
04:42:14 HBMASTER: submitting job (4, 0, 24) to dispatcher
04:42:14 DISPATCHER: trying to submit job (4, 0, 24)
04:42:14 DISPATCHER: trying to notify the job_runner thread.
04:42:14 HBMASTER: job (4, 0, 24) submitted to dispatcher
04:42:14 DISPATCHER: Trying to submit another job.
04:42:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:42:14 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:42:14 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:42:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:42:14 WORKER: start processing job (4, 0, 24)
04:42:14 WORKER: args: ()
04:42:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:42:47 DISPATCHER: Starting worker discovery
04:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:47 DISPATCHER: Finished worker discovery
04:43:01 WORKER: done with job (4, 0, 24), trying to register it.
04:43:02 WORKER: registered result for job (4, 0, 24) with dispatcher
04:43:02 DISPATCHER: job (4, 0, 24) finished
04:43:02 DISPATCHER: register_result: lock acquired
04:43:02 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:43:02 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5653128308451028, 'info': {'data02': 0.5653128308451028, 'config': "{'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}"}}
exception: None

04:43:02 job_callback for (4, 0, 24) started
04:43:02 job_callback for (4, 0, 24) got condition
04:43:02 DISPATCHER: Trying to submit another job.
04:43:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:43:02 HBMASTER: Trying to run another job!
04:43:02 job_callback for (4, 0, 24) finished
04:43:02 start sampling a new configuration.
04:43:02 done sampling a new configuration.
04:43:02 HBMASTER: schedule new run for iteration 4
04:43:02 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:43:02 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:43:02 DISPATCHER: trying to submit job (4, 0, 25)
04:43:02 DISPATCHER: trying to notify the job_runner thread.
04:43:02 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:43:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:43:02 DISPATCHER: Trying to submit another job.
04:43:02 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:43:02 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:43:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:43:02 WORKER: start processing job (4, 0, 25)
04:43:02 WORKER: args: ()
04:43:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 19, 'lr': 0.008888958800090782, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.014766658527258574}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:43:47 DISPATCHER: Starting worker discovery
04:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:47 DISPATCHER: Finished worker discovery
04:43:49 WORKER: done with job (4, 0, 25), trying to register it.
04:43:49 WORKER: registered result for job (4, 0, 25) with dispatcher
04:43:49 DISPATCHER: job (4, 0, 25) finished
04:43:49 DISPATCHER: register_result: lock acquired
04:43:49 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:43:49 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 19, 'lr': 0.008888958800090782, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.014766658527258574}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.010673995194942592, 'info': {'data02': -0.010673995194942592, 'config': "{'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 19, 'lr': 0.008888958800090782, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.014766658527258574}"}}
exception: None

04:43:49 job_callback for (4, 0, 25) started
04:43:49 DISPATCHER: Trying to submit another job.
04:43:49 job_callback for (4, 0, 25) got condition
04:43:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:43:49 HBMASTER: Trying to run another job!
04:43:49 job_callback for (4, 0, 25) finished
04:43:49 start sampling a new configuration.
04:43:50 best_vector: [2, 0.11554970163044592, 0.18692353048082985, 0.6120010860393981, 0.10020785903480042, 0, 0.9960245670370852, 0.03963240858231009], 5.498807895979267e-06, 327.39959760927655, 0.0018003074924743247
04:43:50 done sampling a new configuration.
04:43:50 HBMASTER: schedule new run for iteration 4
04:43:50 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:43:50 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:43:50 DISPATCHER: trying to submit job (4, 0, 26)
04:43:50 DISPATCHER: trying to notify the job_runner thread.
04:43:50 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:43:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:43:50 DISPATCHER: Trying to submit another job.
04:43:50 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:43:50 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:43:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:43:50 WORKER: start processing job (4, 0, 26)
04:43:50 WORKER: args: ()
04:43:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 29, 'last_n_outputs': 10, 'lr': 0.016749512531004176, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.011260636835766771}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:44:37 WORKER: done with job (4, 0, 26), trying to register it.
04:44:38 WORKER: registered result for job (4, 0, 26) with dispatcher
04:44:38 DISPATCHER: job (4, 0, 26) finished
04:44:38 DISPATCHER: register_result: lock acquired
04:44:38 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:44:38 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 29, 'last_n_outputs': 10, 'lr': 0.016749512531004176, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.011260636835766771}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34500400964833866, 'info': {'data02': 0.34500400964833866, 'config': "{'batch_size': 64, 'hidden_dim': 29, 'last_n_outputs': 10, 'lr': 0.016749512531004176, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.011260636835766771}"}}
exception: None

04:44:38 job_callback for (4, 0, 26) started
04:44:38 job_callback for (4, 0, 26) got condition
04:44:38 DISPATCHER: Trying to submit another job.
04:44:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:44:38 HBMASTER: Trying to run another job!
04:44:38 job_callback for (4, 0, 26) finished
04:44:38 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 9) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
04:44:38 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
04:44:38 HBMASTER: schedule new run for iteration 4
04:44:38 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:44:38 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:44:38 DISPATCHER: trying to submit job (4, 0, 4)
04:44:38 DISPATCHER: trying to notify the job_runner thread.
04:44:38 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:44:38 DISPATCHER: Trying to submit another job.
04:44:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:44:38 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:44:38 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:44:38 WORKER: start processing job (4, 0, 4)
04:44:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:44:38 WORKER: args: ()
04:44:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 37, 'lr': 0.02248474891432153, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.011380150128944007}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:44:47 DISPATCHER: Starting worker discovery
04:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:47 DISPATCHER: Finished worker discovery
04:45:47 DISPATCHER: Starting worker discovery
04:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:47 DISPATCHER: Finished worker discovery
04:46:47 DISPATCHER: Starting worker discovery
04:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:47 DISPATCHER: Finished worker discovery
04:46:54 WORKER: done with job (4, 0, 4), trying to register it.
04:46:54 WORKER: registered result for job (4, 0, 4) with dispatcher
04:46:54 DISPATCHER: job (4, 0, 4) finished
04:46:54 DISPATCHER: register_result: lock acquired
04:46:54 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:46:54 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 37, 'lr': 0.02248474891432153, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.011380150128944007}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4968267348400509, 'info': {'data02': 0.4968267348400509, 'config': "{'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 37, 'lr': 0.02248474891432153, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.011380150128944007}"}}
exception: None

04:46:54 job_callback for (4, 0, 4) started
04:46:54 DISPATCHER: Trying to submit another job.
04:46:54 job_callback for (4, 0, 4) got condition
04:46:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:46:54 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.625120





04:46:54 HBMASTER: Trying to run another job!
04:46:54 job_callback for (4, 0, 4) finished
04:46:54 HBMASTER: schedule new run for iteration 4
04:46:54 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:46:54 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:46:54 DISPATCHER: trying to submit job (4, 0, 5)
04:46:54 DISPATCHER: trying to notify the job_runner thread.
04:46:54 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:46:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:46:54 DISPATCHER: Trying to submit another job.
04:46:54 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:46:54 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:46:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:46:54 WORKER: start processing job (4, 0, 5)
04:46:54 WORKER: args: ()
04:46:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.010030421104030499, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01295925819588768}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:47:47 DISPATCHER: Starting worker discovery
04:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:47 DISPATCHER: Finished worker discovery
04:48:47 DISPATCHER: Starting worker discovery
04:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:47 DISPATCHER: Finished worker discovery
04:49:12 WORKER: done with job (4, 0, 5), trying to register it.
04:49:12 WORKER: registered result for job (4, 0, 5) with dispatcher
04:49:12 DISPATCHER: job (4, 0, 5) finished
04:49:12 DISPATCHER: register_result: lock acquired
04:49:12 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:49:12 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.010030421104030499, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01295925819588768}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4965133127629899, 'info': {'data02': 0.4965133127629899, 'config': "{'batch_size': 64, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.010030421104030499, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01295925819588768}"}}
exception: None

04:49:12 job_callback for (4, 0, 5) started
04:49:12 job_callback for (4, 0, 5) got condition
04:49:12 DISPATCHER: Trying to submit another job.
04:49:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:49:12 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.625120





04:49:12 HBMASTER: Trying to run another job!
04:49:12 job_callback for (4, 0, 5) finished
04:49:12 HBMASTER: schedule new run for iteration 4
04:49:12 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:49:12 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:49:12 DISPATCHER: trying to submit job (4, 0, 9)
04:49:12 DISPATCHER: trying to notify the job_runner thread.
04:49:12 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:49:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:49:12 DISPATCHER: Trying to submit another job.
04:49:12 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:49:12 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:49:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:49:12 WORKER: start processing job (4, 0, 9)
04:49:12 WORKER: args: ()
04:49:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 44, 'lr': 0.012418691090146254, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01508787075181241}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:49:47 DISPATCHER: Starting worker discovery
04:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:47 DISPATCHER: Finished worker discovery
04:50:47 DISPATCHER: Starting worker discovery
04:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:47 DISPATCHER: Finished worker discovery
04:51:29 WORKER: done with job (4, 0, 9), trying to register it.
04:51:29 WORKER: registered result for job (4, 0, 9) with dispatcher
04:51:29 DISPATCHER: job (4, 0, 9) finished
04:51:29 DISPATCHER: register_result: lock acquired
04:51:29 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:51:29 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 44, 'lr': 0.012418691090146254, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01508787075181241}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5212215704365027, 'info': {'data02': 0.5212215704365027, 'config': "{'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 44, 'lr': 0.012418691090146254, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01508787075181241}"}}
exception: None

04:51:29 job_callback for (4, 0, 9) started
04:51:29 job_callback for (4, 0, 9) got condition
04:51:29 DISPATCHER: Trying to submit another job.
04:51:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:51:29 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.625120





04:51:29 HBMASTER: Trying to run another job!
04:51:29 job_callback for (4, 0, 9) finished
04:51:29 HBMASTER: schedule new run for iteration 4
04:51:29 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:51:29 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:51:29 DISPATCHER: trying to submit job (4, 0, 10)
04:51:29 DISPATCHER: trying to notify the job_runner thread.
04:51:29 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:51:29 DISPATCHER: Trying to submit another job.
04:51:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:51:29 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:51:29 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:51:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:51:29 WORKER: start processing job (4, 0, 10)
04:51:29 WORKER: args: ()
04:51:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.006300611593606866, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013200733567608309}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:51:47 DISPATCHER: Starting worker discovery
04:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:47 DISPATCHER: Finished worker discovery
04:52:47 DISPATCHER: Starting worker discovery
04:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:47 DISPATCHER: Finished worker discovery
04:53:46 WORKER: done with job (4, 0, 10), trying to register it.
04:53:46 WORKER: registered result for job (4, 0, 10) with dispatcher
04:53:46 DISPATCHER: job (4, 0, 10) finished
04:53:46 DISPATCHER: register_result: lock acquired
04:53:46 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:53:46 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.006300611593606866, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013200733567608309}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4980430823017507, 'info': {'data02': 0.4980430823017507, 'config': "{'batch_size': 128, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.006300611593606866, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013200733567608309}"}}
exception: None

04:53:46 job_callback for (4, 0, 10) started
04:53:46 DISPATCHER: Trying to submit another job.
04:53:46 job_callback for (4, 0, 10) got condition
04:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:53:46 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.625120





04:53:46 HBMASTER: Trying to run another job!
04:53:46 job_callback for (4, 0, 10) finished
04:53:46 HBMASTER: schedule new run for iteration 4
04:53:46 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:53:46 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:53:46 DISPATCHER: trying to submit job (4, 0, 11)
04:53:46 DISPATCHER: trying to notify the job_runner thread.
04:53:46 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:53:46 DISPATCHER: Trying to submit another job.
04:53:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:53:46 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:53:46 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:53:46 WORKER: start processing job (4, 0, 11)
04:53:46 WORKER: args: ()
04:53:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:53:47 DISPATCHER: Starting worker discovery
04:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:54:47 DISPATCHER: Starting worker discovery
04:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:47 DISPATCHER: Finished worker discovery
04:55:47 DISPATCHER: Starting worker discovery
04:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:47 DISPATCHER: Finished worker discovery
04:56:03 WORKER: done with job (4, 0, 11), trying to register it.
04:56:03 WORKER: registered result for job (4, 0, 11) with dispatcher
04:56:03 DISPATCHER: job (4, 0, 11) finished
04:56:03 DISPATCHER: register_result: lock acquired
04:56:03 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:56:03 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6912386313956935, 'info': {'data02': 0.6912386313956935, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}"}}
exception: None

04:56:03 job_callback for (4, 0, 11) started
04:56:03 DISPATCHER: Trying to submit another job.
04:56:03 job_callback for (4, 0, 11) got condition
04:56:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:56:03 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.691239





04:56:03 HBMASTER: Trying to run another job!
04:56:03 job_callback for (4, 0, 11) finished
04:56:03 HBMASTER: schedule new run for iteration 4
04:56:03 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:56:03 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:56:03 DISPATCHER: trying to submit job (4, 0, 14)
04:56:03 DISPATCHER: trying to notify the job_runner thread.
04:56:03 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:56:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:56:03 DISPATCHER: Trying to submit another job.
04:56:03 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:56:03 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:56:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:56:03 WORKER: start processing job (4, 0, 14)
04:56:03 WORKER: args: ()
04:56:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.006107771823674849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011369134177382056}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:56:47 DISPATCHER: Starting worker discovery
04:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:47 DISPATCHER: Finished worker discovery
04:57:47 DISPATCHER: Starting worker discovery
04:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:47 DISPATCHER: Finished worker discovery
04:58:20 WORKER: done with job (4, 0, 14), trying to register it.
04:58:20 WORKER: registered result for job (4, 0, 14) with dispatcher
04:58:20 DISPATCHER: job (4, 0, 14) finished
04:58:20 DISPATCHER: register_result: lock acquired
04:58:20 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
04:58:20 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.006107771823674849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011369134177382056}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49178642726804456, 'info': {'data02': 0.49178642726804456, 'config': "{'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 38, 'lr': 0.006107771823674849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011369134177382056}"}}
exception: None

04:58:20 job_callback for (4, 0, 14) started
04:58:20 DISPATCHER: Trying to submit another job.
04:58:20 job_callback for (4, 0, 14) got condition
04:58:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:58:20 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.691239





04:58:20 HBMASTER: Trying to run another job!
04:58:20 job_callback for (4, 0, 14) finished
04:58:20 HBMASTER: schedule new run for iteration 4
04:58:20 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
04:58:20 HBMASTER: submitting job (4, 0, 15) to dispatcher
04:58:20 DISPATCHER: trying to submit job (4, 0, 15)
04:58:20 DISPATCHER: trying to notify the job_runner thread.
04:58:20 HBMASTER: job (4, 0, 15) submitted to dispatcher
04:58:20 DISPATCHER: Trying to submit another job.
04:58:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:58:20 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
04:58:20 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
04:58:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:58:20 WORKER: start processing job (4, 0, 15)
04:58:20 WORKER: args: ()
04:58:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:58:47 DISPATCHER: Starting worker discovery
04:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:47 DISPATCHER: Finished worker discovery
04:59:47 DISPATCHER: Starting worker discovery
04:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:47 DISPATCHER: Finished worker discovery
05:00:36 WORKER: done with job (4, 0, 15), trying to register it.
05:00:36 WORKER: registered result for job (4, 0, 15) with dispatcher
05:00:36 DISPATCHER: job (4, 0, 15) finished
05:00:36 DISPATCHER: register_result: lock acquired
05:00:36 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:00:36 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5836016491968659, 'info': {'data02': 0.5836016491968659, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}"}}
exception: None

05:00:36 job_callback for (4, 0, 15) started
05:00:36 DISPATCHER: Trying to submit another job.
05:00:36 job_callback for (4, 0, 15) got condition
05:00:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:00:36 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.691239





05:00:36 HBMASTER: Trying to run another job!
05:00:36 job_callback for (4, 0, 15) finished
05:00:36 HBMASTER: schedule new run for iteration 4
05:00:36 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
05:00:36 HBMASTER: submitting job (4, 0, 17) to dispatcher
05:00:36 DISPATCHER: trying to submit job (4, 0, 17)
05:00:36 DISPATCHER: trying to notify the job_runner thread.
05:00:36 HBMASTER: job (4, 0, 17) submitted to dispatcher
05:00:36 DISPATCHER: Trying to submit another job.
05:00:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:00:36 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:00:36 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:00:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:00:36 WORKER: start processing job (4, 0, 17)
05:00:36 WORKER: args: ()
05:00:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.016311838328490636, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010763110414294123}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:00:47 DISPATCHER: Starting worker discovery
05:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:47 DISPATCHER: Finished worker discovery
05:01:47 DISPATCHER: Starting worker discovery
05:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:47 DISPATCHER: Finished worker discovery
05:02:47 DISPATCHER: Starting worker discovery
05:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:47 DISPATCHER: Finished worker discovery
05:02:53 WORKER: done with job (4, 0, 17), trying to register it.
05:02:53 WORKER: registered result for job (4, 0, 17) with dispatcher
05:02:53 DISPATCHER: job (4, 0, 17) finished
05:02:53 DISPATCHER: register_result: lock acquired
05:02:53 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:02:53 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.016311838328490636, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010763110414294123}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4369298942221863, 'info': {'data02': 0.4369298942221863, 'config': "{'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.016311838328490636, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010763110414294123}"}}
exception: None

05:02:53 job_callback for (4, 0, 17) started
05:02:53 DISPATCHER: Trying to submit another job.
05:02:53 job_callback for (4, 0, 17) got condition
05:02:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:02:53 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.691239





05:02:53 HBMASTER: Trying to run another job!
05:02:53 job_callback for (4, 0, 17) finished
05:02:53 HBMASTER: schedule new run for iteration 4
05:02:53 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
05:02:53 HBMASTER: submitting job (4, 0, 24) to dispatcher
05:02:53 DISPATCHER: trying to submit job (4, 0, 24)
05:02:53 DISPATCHER: trying to notify the job_runner thread.
05:02:53 HBMASTER: job (4, 0, 24) submitted to dispatcher
05:02:53 DISPATCHER: Trying to submit another job.
05:02:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:02:53 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:02:53 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:02:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:02:53 WORKER: start processing job (4, 0, 24)
05:02:53 WORKER: args: ()
05:02:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:03:47 DISPATCHER: Starting worker discovery
05:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:47 DISPATCHER: Finished worker discovery
05:04:47 DISPATCHER: Starting worker discovery
05:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:47 DISPATCHER: Finished worker discovery
05:05:10 WORKER: done with job (4, 0, 24), trying to register it.
05:05:10 WORKER: registered result for job (4, 0, 24) with dispatcher
05:05:10 DISPATCHER: job (4, 0, 24) finished
05:05:10 DISPATCHER: register_result: lock acquired
05:05:10 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:05:10 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5708914137877291, 'info': {'data02': 0.5708914137877291, 'config': "{'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}"}}
exception: None

05:05:10 job_callback for (4, 0, 24) started
05:05:10 job_callback for (4, 0, 24) got condition
05:05:10 DISPATCHER: Trying to submit another job.
05:05:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:05:10 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.691239





05:05:10 HBMASTER: Trying to run another job!
05:05:10 job_callback for (4, 0, 24) finished
05:05:10 ITERATION: Advancing config (4, 0, 11) to next budget 400.000000
05:05:10 ITERATION: Advancing config (4, 0, 15) to next budget 400.000000
05:05:10 ITERATION: Advancing config (4, 0, 24) to next budget 400.000000
05:05:10 HBMASTER: schedule new run for iteration 4
05:05:10 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
05:05:10 HBMASTER: submitting job (4, 0, 11) to dispatcher
05:05:10 DISPATCHER: trying to submit job (4, 0, 11)
05:05:10 DISPATCHER: trying to notify the job_runner thread.
05:05:10 HBMASTER: job (4, 0, 11) submitted to dispatcher
05:05:10 DISPATCHER: Trying to submit another job.
05:05:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:05:10 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:05:10 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:05:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:05:10 WORKER: start processing job (4, 0, 11)
05:05:10 WORKER: args: ()
05:05:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:05:47 DISPATCHER: Starting worker discovery
05:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:47 DISPATCHER: Finished worker discovery
05:06:47 DISPATCHER: Starting worker discovery
05:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:47 DISPATCHER: Finished worker discovery
05:07:47 DISPATCHER: Starting worker discovery
05:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:47 DISPATCHER: Finished worker discovery
05:08:47 DISPATCHER: Starting worker discovery
05:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:47 DISPATCHER: Finished worker discovery
05:09:47 DISPATCHER: Starting worker discovery
05:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:47 DISPATCHER: Finished worker discovery
05:10:47 DISPATCHER: Starting worker discovery
05:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:47 DISPATCHER: Finished worker discovery
05:11:47 DISPATCHER: Starting worker discovery
05:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:47 DISPATCHER: Finished worker discovery
05:11:54 WORKER: done with job (4, 0, 11), trying to register it.
05:11:54 WORKER: registered result for job (4, 0, 11) with dispatcher
05:11:54 DISPATCHER: job (4, 0, 11) finished
05:11:54 DISPATCHER: register_result: lock acquired
05:11:54 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:11:54 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.359343521382049, 'info': {'data02': 0.359343521382049, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 33, 'lr': 0.007329957370401021, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01185914079550473}"}}
exception: None

05:11:54 job_callback for (4, 0, 11) started
05:11:54 DISPATCHER: Trying to submit another job.
05:11:54 job_callback for (4, 0, 11) got condition
05:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:11:54 HBMASTER: Trying to run another job!
05:11:54 job_callback for (4, 0, 11) finished
05:11:54 HBMASTER: schedule new run for iteration 4
05:11:54 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
05:11:54 HBMASTER: submitting job (4, 0, 15) to dispatcher
05:11:54 DISPATCHER: trying to submit job (4, 0, 15)
05:11:54 DISPATCHER: trying to notify the job_runner thread.
05:11:54 HBMASTER: job (4, 0, 15) submitted to dispatcher
05:11:54 DISPATCHER: Trying to submit another job.
05:11:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:11:54 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:11:54 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:11:54 WORKER: start processing job (4, 0, 15)
05:11:54 WORKER: args: ()
05:11:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:12:47 DISPATCHER: Starting worker discovery
05:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:47 DISPATCHER: Finished worker discovery
05:13:47 DISPATCHER: Starting worker discovery
05:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:47 DISPATCHER: Finished worker discovery
05:14:47 DISPATCHER: Starting worker discovery
05:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:47 DISPATCHER: Finished worker discovery
05:15:47 DISPATCHER: Starting worker discovery
05:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:47 DISPATCHER: Finished worker discovery
05:16:47 DISPATCHER: Starting worker discovery
05:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:47 DISPATCHER: Finished worker discovery
05:17:47 DISPATCHER: Starting worker discovery
05:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:47 DISPATCHER: Finished worker discovery
05:18:37 WORKER: done with job (4, 0, 15), trying to register it.
05:18:37 WORKER: registered result for job (4, 0, 15) with dispatcher
05:18:37 DISPATCHER: job (4, 0, 15) finished
05:18:37 DISPATCHER: register_result: lock acquired
05:18:37 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:18:37 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5478839012110382, 'info': {'data02': 0.5478839012110382, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 50, 'lr': 0.007982765017162977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010724317948603507}"}}
exception: None

05:18:37 job_callback for (4, 0, 15) started
05:18:37 job_callback for (4, 0, 15) got condition
05:18:37 DISPATCHER: Trying to submit another job.
05:18:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:18:37 HBMASTER: Trying to run another job!
05:18:37 job_callback for (4, 0, 15) finished
05:18:37 HBMASTER: schedule new run for iteration 4
05:18:37 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
05:18:37 HBMASTER: submitting job (4, 0, 24) to dispatcher
05:18:37 DISPATCHER: trying to submit job (4, 0, 24)
05:18:37 DISPATCHER: trying to notify the job_runner thread.
05:18:37 HBMASTER: job (4, 0, 24) submitted to dispatcher
05:18:37 DISPATCHER: Trying to submit another job.
05:18:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:18:37 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:18:37 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:18:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:18:37 WORKER: start processing job (4, 0, 24)
05:18:37 WORKER: args: ()
05:18:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:18:47 DISPATCHER: Starting worker discovery
05:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:47 DISPATCHER: Finished worker discovery
05:19:47 DISPATCHER: Starting worker discovery
05:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:47 DISPATCHER: Finished worker discovery
05:20:47 DISPATCHER: Starting worker discovery
05:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:47 DISPATCHER: Finished worker discovery
05:21:47 DISPATCHER: Starting worker discovery
05:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:47 DISPATCHER: Finished worker discovery
05:22:47 DISPATCHER: Starting worker discovery
05:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:47 DISPATCHER: Finished worker discovery
05:23:47 DISPATCHER: Starting worker discovery
05:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:47 DISPATCHER: Finished worker discovery
05:24:47 DISPATCHER: Starting worker discovery
05:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:47 DISPATCHER: Finished worker discovery
05:25:21 WORKER: done with job (4, 0, 24), trying to register it.
05:25:21 WORKER: registered result for job (4, 0, 24) with dispatcher
05:25:21 DISPATCHER: job (4, 0, 24) finished
05:25:21 DISPATCHER: register_result: lock acquired
05:25:21 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:25:21 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6551778859096227, 'info': {'data02': 0.6551778859096227, 'config': "{'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}"}}
exception: None

05:25:21 job_callback for (4, 0, 24) started
05:25:21 job_callback for (4, 0, 24) got condition
05:25:21 DISPATCHER: Trying to submit another job.
05:25:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:25:21 HBMASTER: Trying to run another job!
05:25:21 job_callback for (4, 0, 24) finished
05:25:21 ITERATION: Advancing config (4, 0, 24) to next budget 1200.000000
05:25:21 HBMASTER: schedule new run for iteration 4
05:25:21 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
05:25:21 HBMASTER: submitting job (4, 0, 24) to dispatcher
05:25:21 DISPATCHER: trying to submit job (4, 0, 24)
05:25:21 DISPATCHER: trying to notify the job_runner thread.
05:25:21 HBMASTER: job (4, 0, 24) submitted to dispatcher
05:25:21 DISPATCHER: Trying to submit another job.
05:25:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:25:21 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:25:21 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:25:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:25:21 WORKER: start processing job (4, 0, 24)
05:25:21 WORKER: args: ()
05:25:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:25:47 DISPATCHER: Starting worker discovery
05:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:47 DISPATCHER: Finished worker discovery
05:26:47 DISPATCHER: Starting worker discovery
05:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:47 DISPATCHER: Finished worker discovery
05:27:47 DISPATCHER: Starting worker discovery
05:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:47 DISPATCHER: Finished worker discovery
05:28:47 DISPATCHER: Starting worker discovery
05:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:47 DISPATCHER: Finished worker discovery
05:29:47 DISPATCHER: Starting worker discovery
05:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:47 DISPATCHER: Finished worker discovery
05:30:47 DISPATCHER: Starting worker discovery
05:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:47 DISPATCHER: Finished worker discovery
05:31:47 DISPATCHER: Starting worker discovery
05:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:47 DISPATCHER: Finished worker discovery
05:32:47 DISPATCHER: Starting worker discovery
05:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:47 DISPATCHER: Finished worker discovery
05:33:47 DISPATCHER: Starting worker discovery
05:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:47 DISPATCHER: Finished worker discovery
05:34:47 DISPATCHER: Starting worker discovery
05:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:47 DISPATCHER: Finished worker discovery
05:35:47 DISPATCHER: Starting worker discovery
05:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:47 DISPATCHER: Finished worker discovery
05:36:47 DISPATCHER: Starting worker discovery
05:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:47 DISPATCHER: Finished worker discovery
05:37:47 DISPATCHER: Starting worker discovery
05:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:47 DISPATCHER: Finished worker discovery
05:38:47 DISPATCHER: Starting worker discovery
05:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:47 DISPATCHER: Finished worker discovery
05:39:47 DISPATCHER: Starting worker discovery
05:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:47 DISPATCHER: Finished worker discovery
05:40:47 DISPATCHER: Starting worker discovery
05:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:47 DISPATCHER: Finished worker discovery
05:41:47 DISPATCHER: Starting worker discovery
05:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:47 DISPATCHER: Finished worker discovery
05:42:47 DISPATCHER: Starting worker discovery
05:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:47 DISPATCHER: Finished worker discovery
05:43:47 DISPATCHER: Starting worker discovery
05:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:47 DISPATCHER: Finished worker discovery
05:44:47 DISPATCHER: Starting worker discovery
05:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:47 DISPATCHER: Finished worker discovery
05:45:26 WORKER: done with job (4, 0, 24), trying to register it.
05:45:26 WORKER: registered result for job (4, 0, 24) with dispatcher
05:45:26 DISPATCHER: job (4, 0, 24) finished
05:45:26 DISPATCHER: register_result: lock acquired
05:45:26 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:45:26 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4820642298963787, 'info': {'data02': 0.4820642298963787, 'config': "{'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 45, 'lr': 0.008319316466661323, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.013503200387359126}"}}
exception: None

05:45:26 job_callback for (4, 0, 24) started
05:45:26 DISPATCHER: Trying to submit another job.
05:45:26 job_callback for (4, 0, 24) got condition
05:45:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:45:26 HBMASTER: Trying to run another job!
05:45:26 job_callback for (4, 0, 24) finished
05:45:26 start sampling a new configuration.
05:45:26 done sampling a new configuration.
05:45:26 HBMASTER: schedule new run for iteration 5
05:45:26 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
05:45:26 HBMASTER: submitting job (5, 0, 0) to dispatcher
05:45:26 DISPATCHER: trying to submit job (5, 0, 0)
05:45:26 DISPATCHER: trying to notify the job_runner thread.
05:45:26 HBMASTER: job (5, 0, 0) submitted to dispatcher
05:45:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:45:26 DISPATCHER: Trying to submit another job.
05:45:26 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:45:26 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:45:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:45:26 WORKER: start processing job (5, 0, 0)
05:45:26 WORKER: args: ()
05:45:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 10, 'lr': 0.09261310803706607, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.07167328269324934}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:45:47 DISPATCHER: Starting worker discovery
05:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:47 DISPATCHER: Finished worker discovery
05:46:47 DISPATCHER: Starting worker discovery
05:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:47 DISPATCHER: Finished worker discovery
05:47:43 WORKER: done with job (5, 0, 0), trying to register it.
05:47:43 WORKER: registered result for job (5, 0, 0) with dispatcher
05:47:43 DISPATCHER: job (5, 0, 0) finished
05:47:43 DISPATCHER: register_result: lock acquired
05:47:43 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:47:43 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 10, 'lr': 0.09261310803706607, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.07167328269324934}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 10, 'lr': 0.09261310803706607, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.07167328269324934}"}}
exception: None

05:47:43 job_callback for (5, 0, 0) started
05:47:43 DISPATCHER: Trying to submit another job.
05:47:43 job_callback for (5, 0, 0) got condition
05:47:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:47:43 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.691239





05:47:43 HBMASTER: Trying to run another job!
05:47:43 job_callback for (5, 0, 0) finished
05:47:43 start sampling a new configuration.
05:47:43 done sampling a new configuration.
05:47:43 HBMASTER: schedule new run for iteration 5
05:47:43 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
05:47:43 HBMASTER: submitting job (5, 0, 1) to dispatcher
05:47:43 DISPATCHER: trying to submit job (5, 0, 1)
05:47:43 DISPATCHER: trying to notify the job_runner thread.
05:47:43 HBMASTER: job (5, 0, 1) submitted to dispatcher
05:47:43 DISPATCHER: Trying to submit another job.
05:47:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:47:43 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:47:43 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:47:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:47:43 WORKER: start processing job (5, 0, 1)
05:47:43 WORKER: args: ()
05:47:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 29, 'lr': 0.023036885099987053, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.05595976817546459}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:47:47 DISPATCHER: Starting worker discovery
05:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:48:47 DISPATCHER: Starting worker discovery
05:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:47 DISPATCHER: Finished worker discovery
05:49:47 DISPATCHER: Starting worker discovery
05:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:47 DISPATCHER: Finished worker discovery
05:50:01 WORKER: done with job (5, 0, 1), trying to register it.
05:50:01 WORKER: registered result for job (5, 0, 1) with dispatcher
05:50:01 DISPATCHER: job (5, 0, 1) finished
05:50:01 DISPATCHER: register_result: lock acquired
05:50:01 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:50:01 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 29, 'lr': 0.023036885099987053, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.05595976817546459}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 29, 'lr': 0.023036885099987053, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.05595976817546459}"}}
exception: None

05:50:01 job_callback for (5, 0, 1) started
05:50:01 DISPATCHER: Trying to submit another job.
05:50:01 job_callback for (5, 0, 1) got condition
05:50:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:50:01 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.691239





05:50:01 HBMASTER: Trying to run another job!
05:50:01 job_callback for (5, 0, 1) finished
05:50:01 start sampling a new configuration.
05:50:01 done sampling a new configuration.
05:50:01 HBMASTER: schedule new run for iteration 5
05:50:01 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
05:50:01 HBMASTER: submitting job (5, 0, 2) to dispatcher
05:50:01 DISPATCHER: trying to submit job (5, 0, 2)
05:50:01 DISPATCHER: trying to notify the job_runner thread.
05:50:01 HBMASTER: job (5, 0, 2) submitted to dispatcher
05:50:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:50:01 DISPATCHER: Trying to submit another job.
05:50:01 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:50:01 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:50:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:50:01 WORKER: start processing job (5, 0, 2)
05:50:01 WORKER: args: ()
05:50:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 52, 'last_n_outputs': 20, 'lr': 0.08716922805310579, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.03585197632734716}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:50:47 DISPATCHER: Starting worker discovery
05:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:47 DISPATCHER: Finished worker discovery
05:51:47 DISPATCHER: Starting worker discovery
05:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:47 DISPATCHER: Finished worker discovery
05:52:18 WORKER: done with job (5, 0, 2), trying to register it.
05:52:18 WORKER: registered result for job (5, 0, 2) with dispatcher
05:52:18 DISPATCHER: job (5, 0, 2) finished
05:52:18 DISPATCHER: register_result: lock acquired
05:52:18 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:52:18 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 52, 'last_n_outputs': 20, 'lr': 0.08716922805310579, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.03585197632734716}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 52, 'last_n_outputs': 20, 'lr': 0.08716922805310579, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.03585197632734716}"}}
exception: None

05:52:18 job_callback for (5, 0, 2) started
05:52:18 DISPATCHER: Trying to submit another job.
05:52:18 job_callback for (5, 0, 2) got condition
05:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:52:18 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.691239





05:52:18 HBMASTER: Trying to run another job!
05:52:18 job_callback for (5, 0, 2) finished
05:52:18 start sampling a new configuration.
05:52:18 done sampling a new configuration.
05:52:18 HBMASTER: schedule new run for iteration 5
05:52:18 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
05:52:18 HBMASTER: submitting job (5, 0, 3) to dispatcher
05:52:18 DISPATCHER: trying to submit job (5, 0, 3)
05:52:18 DISPATCHER: trying to notify the job_runner thread.
05:52:18 HBMASTER: job (5, 0, 3) submitted to dispatcher
05:52:18 DISPATCHER: Trying to submit another job.
05:52:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:52:18 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:52:18 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:52:18 WORKER: start processing job (5, 0, 3)
05:52:18 WORKER: args: ()
05:52:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 7, 'lr': 0.0016303582856817544, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.1519086029246186}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:52:47 DISPATCHER: Starting worker discovery
05:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:47 DISPATCHER: Finished worker discovery
05:53:47 DISPATCHER: Starting worker discovery
05:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:47 DISPATCHER: Finished worker discovery
05:54:35 WORKER: done with job (5, 0, 3), trying to register it.
05:54:35 WORKER: registered result for job (5, 0, 3) with dispatcher
05:54:35 DISPATCHER: job (5, 0, 3) finished
05:54:35 DISPATCHER: register_result: lock acquired
05:54:35 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:54:35 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 7, 'lr': 0.0016303582856817544, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.1519086029246186}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.014168968027474221, 'info': {'data02': -0.014168968027474221, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 7, 'lr': 0.0016303582856817544, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.1519086029246186}"}}
exception: None

05:54:35 job_callback for (5, 0, 3) started
05:54:35 DISPATCHER: Trying to submit another job.
05:54:35 job_callback for (5, 0, 3) got condition
05:54:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:54:35 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.691239





05:54:35 HBMASTER: Trying to run another job!
05:54:35 job_callback for (5, 0, 3) finished
05:54:35 start sampling a new configuration.
05:54:35 best_vector: [1, 0.2597996847758429, 0.05966028206461982, 0.3752752135606165, 0.10004356765567379, 0, 0.9583283184536804, 0.08974000528525489], 8.811334385031084e-05, 815.6170829123935, 0.07186674847684721
05:54:35 done sampling a new configuration.
05:54:35 HBMASTER: schedule new run for iteration 5
05:54:35 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
05:54:35 HBMASTER: submitting job (5, 0, 4) to dispatcher
05:54:35 DISPATCHER: trying to submit job (5, 0, 4)
05:54:35 DISPATCHER: trying to notify the job_runner thread.
05:54:35 HBMASTER: job (5, 0, 4) submitted to dispatcher
05:54:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:54:35 DISPATCHER: Trying to submit another job.
05:54:35 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:54:35 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:54:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:54:35 WORKER: start processing job (5, 0, 4)
05:54:35 WORKER: args: ()
05:54:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 41, 'last_n_outputs': 3, 'lr': 0.00563054491397226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013084418869766669}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:54:47 DISPATCHER: Starting worker discovery
05:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:47 DISPATCHER: Finished worker discovery
05:55:47 DISPATCHER: Starting worker discovery
05:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:47 DISPATCHER: Finished worker discovery
05:56:47 DISPATCHER: Starting worker discovery
05:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:47 DISPATCHER: Finished worker discovery
05:56:52 WORKER: done with job (5, 0, 4), trying to register it.
05:56:52 WORKER: registered result for job (5, 0, 4) with dispatcher
05:56:52 DISPATCHER: job (5, 0, 4) finished
05:56:52 DISPATCHER: register_result: lock acquired
05:56:52 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:56:52 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 41, 'last_n_outputs': 3, 'lr': 0.00563054491397226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013084418869766669}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3716397744930224, 'info': {'data02': 0.3716397744930224, 'config': "{'batch_size': 32, 'hidden_dim': 41, 'last_n_outputs': 3, 'lr': 0.00563054491397226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013084418869766669}"}}
exception: None

05:56:52 job_callback for (5, 0, 4) started
05:56:52 job_callback for (5, 0, 4) got condition
05:56:52 DISPATCHER: Trying to submit another job.
05:56:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:56:52 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.691239





05:56:52 HBMASTER: Trying to run another job!
05:56:52 job_callback for (5, 0, 4) finished
05:56:52 start sampling a new configuration.
05:56:52 done sampling a new configuration.
05:56:52 HBMASTER: schedule new run for iteration 5
05:56:52 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
05:56:52 HBMASTER: submitting job (5, 0, 5) to dispatcher
05:56:52 DISPATCHER: trying to submit job (5, 0, 5)
05:56:52 DISPATCHER: trying to notify the job_runner thread.
05:56:52 HBMASTER: job (5, 0, 5) submitted to dispatcher
05:56:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:56:52 DISPATCHER: Trying to submit another job.
05:56:52 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:56:52 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:56:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:56:52 WORKER: start processing job (5, 0, 5)
05:56:52 WORKER: args: ()
05:56:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 8, 'lr': 0.001402215611712106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.037087997014175436}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:57:47 DISPATCHER: Starting worker discovery
05:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:47 DISPATCHER: Finished worker discovery
05:58:47 DISPATCHER: Starting worker discovery
05:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:47 DISPATCHER: Finished worker discovery
05:59:09 WORKER: done with job (5, 0, 5), trying to register it.
05:59:09 WORKER: registered result for job (5, 0, 5) with dispatcher
05:59:09 DISPATCHER: job (5, 0, 5) finished
05:59:09 DISPATCHER: register_result: lock acquired
05:59:09 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
05:59:09 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 8, 'lr': 0.001402215611712106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.037087997014175436}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.023158801827881822, 'info': {'data02': 0.023158801827881822, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 8, 'lr': 0.001402215611712106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.037087997014175436}"}}
exception: None

05:59:09 job_callback for (5, 0, 5) started
05:59:09 DISPATCHER: Trying to submit another job.
05:59:09 job_callback for (5, 0, 5) got condition
05:59:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:09 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.691239





05:59:09 HBMASTER: Trying to run another job!
05:59:09 job_callback for (5, 0, 5) finished
05:59:09 start sampling a new configuration.
05:59:09 best_vector: [2, 0.6048391575163805, 0.9842162832965135, 0.4029972286972385, 0.10025421709162279, 0, 0.6550416668075395, 0.07193659423150146], 2.209747384953523e-05, 17050.725128415528, 0.37677795264077535
05:59:09 done sampling a new configuration.
05:59:09 HBMASTER: schedule new run for iteration 5
05:59:09 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:59:09 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:59:09 DISPATCHER: trying to submit job (5, 0, 6)
05:59:09 DISPATCHER: trying to notify the job_runner thread.
05:59:09 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:59:09 DISPATCHER: Trying to submit another job.
05:59:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:09 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
05:59:09 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
05:59:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:09 WORKER: start processing job (5, 0, 6)
05:59:09 WORKER: args: ()
05:59:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:59:47 DISPATCHER: Starting worker discovery
05:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:47 DISPATCHER: Finished worker discovery
06:00:47 DISPATCHER: Starting worker discovery
06:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:47 DISPATCHER: Finished worker discovery
06:01:26 WORKER: done with job (5, 0, 6), trying to register it.
06:01:26 WORKER: registered result for job (5, 0, 6) with dispatcher
06:01:26 DISPATCHER: job (5, 0, 6) finished
06:01:26 DISPATCHER: register_result: lock acquired
06:01:26 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:01:26 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6218932635356049, 'info': {'data02': 0.6218932635356049, 'config': "{'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}"}}
exception: None

06:01:26 job_callback for (5, 0, 6) started
06:01:26 DISPATCHER: Trying to submit another job.
06:01:26 job_callback for (5, 0, 6) got condition
06:01:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:01:26 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.691239





06:01:26 HBMASTER: Trying to run another job!
06:01:26 job_callback for (5, 0, 6) finished
06:01:26 start sampling a new configuration.
06:01:26 best_vector: [2, 0.3758019892531572, 0.9670093831295936, 0.3962358334949798, 0.10005247937845872, 0, 0.5448354804709167, 0.0925322876185761], 2.2238353184198348e-05, 20247.58708176238, 0.4502729926520438
06:01:26 done sampling a new configuration.
06:01:26 HBMASTER: schedule new run for iteration 5
06:01:26 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
06:01:26 HBMASTER: submitting job (5, 0, 7) to dispatcher
06:01:26 DISPATCHER: trying to submit job (5, 0, 7)
06:01:26 DISPATCHER: trying to notify the job_runner thread.
06:01:26 HBMASTER: job (5, 0, 7) submitted to dispatcher
06:01:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:01:26 DISPATCHER: Trying to submit another job.
06:01:26 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:01:26 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:01:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:01:26 WORKER: start processing job (5, 0, 7)
06:01:26 WORKER: args: ()
06:01:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 49, 'lr': 0.006201141866014028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013194328172613004}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:01:47 DISPATCHER: Starting worker discovery
06:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:47 DISPATCHER: Finished worker discovery
06:02:47 DISPATCHER: Starting worker discovery
06:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:47 DISPATCHER: Finished worker discovery
06:03:43 WORKER: done with job (5, 0, 7), trying to register it.
06:03:43 WORKER: registered result for job (5, 0, 7) with dispatcher
06:03:43 DISPATCHER: job (5, 0, 7) finished
06:03:43 DISPATCHER: register_result: lock acquired
06:03:43 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:03:43 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 49, 'lr': 0.006201141866014028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013194328172613004}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5927929842200301, 'info': {'data02': 0.5927929842200301, 'config': "{'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 49, 'lr': 0.006201141866014028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013194328172613004}"}}
exception: None

06:03:43 job_callback for (5, 0, 7) started
06:03:43 job_callback for (5, 0, 7) got condition
06:03:43 DISPATCHER: Trying to submit another job.
06:03:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:03:43 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.691239





06:03:43 HBMASTER: Trying to run another job!
06:03:43 job_callback for (5, 0, 7) finished
06:03:43 start sampling a new configuration.
06:03:43 done sampling a new configuration.
06:03:43 HBMASTER: schedule new run for iteration 5
06:03:43 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:03:43 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:03:43 DISPATCHER: trying to submit job (5, 0, 8)
06:03:43 DISPATCHER: trying to notify the job_runner thread.
06:03:43 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:03:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:03:43 DISPATCHER: Trying to submit another job.
06:03:43 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:03:43 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:03:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:03:43 WORKER: start processing job (5, 0, 8)
06:03:43 WORKER: args: ()
06:03:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 39, 'lr': 0.09152016757946316, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.01719452589082366}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:03:47 DISPATCHER: Starting worker discovery
06:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:04:47 DISPATCHER: Starting worker discovery
06:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:47 DISPATCHER: Finished worker discovery
06:05:47 DISPATCHER: Starting worker discovery
06:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:47 DISPATCHER: Finished worker discovery
06:06:00 WORKER: done with job (5, 0, 8), trying to register it.
06:06:00 WORKER: registered result for job (5, 0, 8) with dispatcher
06:06:00 DISPATCHER: job (5, 0, 8) finished
06:06:00 DISPATCHER: register_result: lock acquired
06:06:00 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:06:00 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 39, 'lr': 0.09152016757946316, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.01719452589082366}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 39, 'lr': 0.09152016757946316, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.01719452589082366}"}}
exception: None

06:06:00 job_callback for (5, 0, 8) started
06:06:00 job_callback for (5, 0, 8) got condition
06:06:00 DISPATCHER: Trying to submit another job.
06:06:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:06:00 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.691239





06:06:00 HBMASTER: Trying to run another job!
06:06:00 job_callback for (5, 0, 8) finished
06:06:00 ITERATION: Advancing config (5, 0, 4) to next budget 400.000000
06:06:00 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
06:06:00 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
06:06:00 HBMASTER: schedule new run for iteration 5
06:06:00 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
06:06:00 HBMASTER: submitting job (5, 0, 4) to dispatcher
06:06:00 DISPATCHER: trying to submit job (5, 0, 4)
06:06:00 DISPATCHER: trying to notify the job_runner thread.
06:06:00 HBMASTER: job (5, 0, 4) submitted to dispatcher
06:06:00 DISPATCHER: Trying to submit another job.
06:06:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:06:00 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:06:00 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:06:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:06:00 WORKER: start processing job (5, 0, 4)
06:06:00 WORKER: args: ()
06:06:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 41, 'last_n_outputs': 3, 'lr': 0.00563054491397226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013084418869766669}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:06:47 DISPATCHER: Starting worker discovery
06:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:47 DISPATCHER: Finished worker discovery
06:07:47 DISPATCHER: Starting worker discovery
06:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:47 DISPATCHER: Finished worker discovery
06:08:47 DISPATCHER: Starting worker discovery
06:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:47 DISPATCHER: Finished worker discovery
06:09:47 DISPATCHER: Starting worker discovery
06:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:47 DISPATCHER: Finished worker discovery
06:10:47 DISPATCHER: Starting worker discovery
06:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:47 DISPATCHER: Finished worker discovery
06:11:47 DISPATCHER: Starting worker discovery
06:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:47 DISPATCHER: Finished worker discovery
06:12:44 WORKER: done with job (5, 0, 4), trying to register it.
06:12:44 WORKER: registered result for job (5, 0, 4) with dispatcher
06:12:44 DISPATCHER: job (5, 0, 4) finished
06:12:44 DISPATCHER: register_result: lock acquired
06:12:44 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:12:44 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 41, 'last_n_outputs': 3, 'lr': 0.00563054491397226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013084418869766669}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2202693198544944, 'info': {'data02': 0.2202693198544944, 'config': "{'batch_size': 32, 'hidden_dim': 41, 'last_n_outputs': 3, 'lr': 0.00563054491397226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013084418869766669}"}}
exception: None

06:12:44 job_callback for (5, 0, 4) started
06:12:44 job_callback for (5, 0, 4) got condition
06:12:44 DISPATCHER: Trying to submit another job.
06:12:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:12:44 HBMASTER: Trying to run another job!
06:12:44 job_callback for (5, 0, 4) finished
06:12:44 HBMASTER: schedule new run for iteration 5
06:12:44 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
06:12:44 HBMASTER: submitting job (5, 0, 6) to dispatcher
06:12:44 DISPATCHER: trying to submit job (5, 0, 6)
06:12:44 DISPATCHER: trying to notify the job_runner thread.
06:12:44 HBMASTER: job (5, 0, 6) submitted to dispatcher
06:12:44 DISPATCHER: Trying to submit another job.
06:12:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:12:44 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:12:44 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:12:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:12:44 WORKER: start processing job (5, 0, 6)
06:12:44 WORKER: args: ()
06:12:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}, 'budget': 400.0, 'working_directory': '.'}
06:12:47 DISPATCHER: Starting worker discovery
06:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:47 DISPATCHER: Finished worker discovery
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:13:47 DISPATCHER: Starting worker discovery
06:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:47 DISPATCHER: Finished worker discovery
06:14:47 DISPATCHER: Starting worker discovery
06:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:47 DISPATCHER: Finished worker discovery
06:15:47 DISPATCHER: Starting worker discovery
06:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:47 DISPATCHER: Finished worker discovery
06:16:47 DISPATCHER: Starting worker discovery
06:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:47 DISPATCHER: Finished worker discovery
06:17:47 DISPATCHER: Starting worker discovery
06:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:47 DISPATCHER: Finished worker discovery
06:18:47 DISPATCHER: Starting worker discovery
06:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:48 DISPATCHER: Finished worker discovery
06:19:28 WORKER: done with job (5, 0, 6), trying to register it.
06:19:28 WORKER: registered result for job (5, 0, 6) with dispatcher
06:19:28 DISPATCHER: job (5, 0, 6) finished
06:19:28 DISPATCHER: register_result: lock acquired
06:19:28 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:19:28 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6514080189481575, 'info': {'data02': 0.6514080189481575, 'config': "{'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}"}}
exception: None

06:19:28 job_callback for (5, 0, 6) started
06:19:28 job_callback for (5, 0, 6) got condition
06:19:28 DISPATCHER: Trying to submit another job.
06:19:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:19:28 HBMASTER: Trying to run another job!
06:19:28 job_callback for (5, 0, 6) finished
06:19:28 HBMASTER: schedule new run for iteration 5
06:19:28 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
06:19:28 HBMASTER: submitting job (5, 0, 7) to dispatcher
06:19:28 DISPATCHER: trying to submit job (5, 0, 7)
06:19:28 DISPATCHER: trying to notify the job_runner thread.
06:19:28 HBMASTER: job (5, 0, 7) submitted to dispatcher
06:19:28 DISPATCHER: Trying to submit another job.
06:19:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:19:28 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:19:28 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:19:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:19:28 WORKER: start processing job (5, 0, 7)
06:19:28 WORKER: args: ()
06:19:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 49, 'lr': 0.006201141866014028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013194328172613004}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:19:48 DISPATCHER: Starting worker discovery
06:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:48 DISPATCHER: Finished worker discovery
06:20:48 DISPATCHER: Starting worker discovery
06:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:48 DISPATCHER: Finished worker discovery
06:21:48 DISPATCHER: Starting worker discovery
06:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:48 DISPATCHER: Finished worker discovery
06:22:48 DISPATCHER: Starting worker discovery
06:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:48 DISPATCHER: Finished worker discovery
06:23:48 DISPATCHER: Starting worker discovery
06:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:48 DISPATCHER: Finished worker discovery
06:24:48 DISPATCHER: Starting worker discovery
06:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:48 DISPATCHER: Finished worker discovery
06:25:48 DISPATCHER: Starting worker discovery
06:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:48 DISPATCHER: Finished worker discovery
06:26:11 WORKER: done with job (5, 0, 7), trying to register it.
06:26:11 WORKER: registered result for job (5, 0, 7) with dispatcher
06:26:11 DISPATCHER: job (5, 0, 7) finished
06:26:11 DISPATCHER: register_result: lock acquired
06:26:11 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:26:11 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 49, 'lr': 0.006201141866014028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013194328172613004}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6296652251694607, 'info': {'data02': 0.6296652251694607, 'config': "{'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 49, 'lr': 0.006201141866014028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013194328172613004}"}}
exception: None

06:26:11 job_callback for (5, 0, 7) started
06:26:11 DISPATCHER: Trying to submit another job.
06:26:11 job_callback for (5, 0, 7) got condition
06:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:26:11 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.655178





06:26:11 HBMASTER: Trying to run another job!
06:26:11 job_callback for (5, 0, 7) finished
06:26:11 ITERATION: Advancing config (5, 0, 6) to next budget 1200.000000
06:26:11 HBMASTER: schedule new run for iteration 5
06:26:11 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
06:26:11 HBMASTER: submitting job (5, 0, 6) to dispatcher
06:26:11 DISPATCHER: trying to submit job (5, 0, 6)
06:26:11 DISPATCHER: trying to notify the job_runner thread.
06:26:11 HBMASTER: job (5, 0, 6) submitted to dispatcher
06:26:11 DISPATCHER: Trying to submit another job.
06:26:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:26:11 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:26:11 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:26:11 WORKER: start processing job (5, 0, 6)
06:26:11 WORKER: args: ()
06:26:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:26:48 DISPATCHER: Starting worker discovery
06:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:48 DISPATCHER: Finished worker discovery
06:27:48 DISPATCHER: Starting worker discovery
06:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:48 DISPATCHER: Finished worker discovery
06:28:48 DISPATCHER: Starting worker discovery
06:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:48 DISPATCHER: Finished worker discovery
06:29:48 DISPATCHER: Starting worker discovery
06:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:48 DISPATCHER: Finished worker discovery
06:30:48 DISPATCHER: Starting worker discovery
06:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:48 DISPATCHER: Finished worker discovery
06:31:48 DISPATCHER: Starting worker discovery
06:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:48 DISPATCHER: Finished worker discovery
06:32:48 DISPATCHER: Starting worker discovery
06:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:48 DISPATCHER: Finished worker discovery
06:33:48 DISPATCHER: Starting worker discovery
06:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:48 DISPATCHER: Finished worker discovery
06:34:48 DISPATCHER: Starting worker discovery
06:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:48 DISPATCHER: Finished worker discovery
06:35:48 DISPATCHER: Starting worker discovery
06:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:48 DISPATCHER: Finished worker discovery
06:36:48 DISPATCHER: Starting worker discovery
06:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:48 DISPATCHER: Finished worker discovery
06:37:48 DISPATCHER: Starting worker discovery
06:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:48 DISPATCHER: Finished worker discovery
06:38:48 DISPATCHER: Starting worker discovery
06:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:48 DISPATCHER: Finished worker discovery
06:39:48 DISPATCHER: Starting worker discovery
06:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:48 DISPATCHER: Finished worker discovery
06:40:48 DISPATCHER: Starting worker discovery
06:40:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:48 DISPATCHER: Finished worker discovery
06:41:48 DISPATCHER: Starting worker discovery
06:41:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:48 DISPATCHER: Finished worker discovery
06:42:48 DISPATCHER: Starting worker discovery
06:42:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:48 DISPATCHER: Finished worker discovery
06:43:48 DISPATCHER: Starting worker discovery
06:43:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:48 DISPATCHER: Finished worker discovery
06:44:48 DISPATCHER: Starting worker discovery
06:44:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:48 DISPATCHER: Finished worker discovery
06:45:48 DISPATCHER: Starting worker discovery
06:45:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:48 DISPATCHER: Finished worker discovery
06:46:15 WORKER: done with job (5, 0, 6), trying to register it.
06:46:15 WORKER: registered result for job (5, 0, 6) with dispatcher
06:46:15 DISPATCHER: job (5, 0, 6) finished
06:46:15 DISPATCHER: register_result: lock acquired
06:46:15 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:46:15 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5866020929369681, 'info': {'data02': 0.5866020929369681, 'config': "{'batch_size': 64, 'hidden_dim': 68, 'last_n_outputs': 50, 'lr': 0.006397266710335156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.012404854277325555}"}}
exception: None

06:46:15 job_callback for (5, 0, 6) started
06:46:15 job_callback for (5, 0, 6) got condition
06:46:15 DISPATCHER: Trying to submit another job.
06:46:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:46:16 HBMASTER: Trying to run another job!
06:46:16 job_callback for (5, 0, 6) finished
06:46:16 start sampling a new configuration.
06:46:16 done sampling a new configuration.
06:46:16 HBMASTER: schedule new run for iteration 6
06:46:16 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
06:46:16 HBMASTER: submitting job (6, 0, 0) to dispatcher
06:46:16 DISPATCHER: trying to submit job (6, 0, 0)
06:46:16 DISPATCHER: trying to notify the job_runner thread.
06:46:16 HBMASTER: job (6, 0, 0) submitted to dispatcher
06:46:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:46:16 DISPATCHER: Trying to submit another job.
06:46:16 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:46:16 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:46:16 WORKER: start processing job (6, 0, 0)
06:46:16 WORKER: args: ()
06:46:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 16, 'lr': 0.05518293596052303, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04782865164331612}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:46:48 DISPATCHER: Starting worker discovery
06:46:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:48 DISPATCHER: Finished worker discovery
06:47:48 DISPATCHER: Starting worker discovery
06:47:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:48 DISPATCHER: Finished worker discovery
06:48:48 DISPATCHER: Starting worker discovery
06:48:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:48 DISPATCHER: Finished worker discovery
06:49:48 DISPATCHER: Starting worker discovery
06:49:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:48 DISPATCHER: Finished worker discovery
06:50:48 DISPATCHER: Starting worker discovery
06:50:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:48 DISPATCHER: Finished worker discovery
06:51:48 DISPATCHER: Starting worker discovery
06:51:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:48 DISPATCHER: Finished worker discovery
06:52:48 DISPATCHER: Starting worker discovery
06:52:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:48 DISPATCHER: Finished worker discovery
06:52:59 WORKER: done with job (6, 0, 0), trying to register it.
06:52:59 WORKER: registered result for job (6, 0, 0) with dispatcher
06:52:59 DISPATCHER: job (6, 0, 0) finished
06:52:59 DISPATCHER: register_result: lock acquired
06:52:59 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:52:59 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 16, 'lr': 0.05518293596052303, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04782865164331612}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 16, 'lr': 0.05518293596052303, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04782865164331612}"}}
exception: None

06:52:59 job_callback for (6, 0, 0) started
06:52:59 DISPATCHER: Trying to submit another job.
06:52:59 job_callback for (6, 0, 0) got condition
06:52:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:52:59 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.655178





06:52:59 HBMASTER: Trying to run another job!
06:52:59 job_callback for (6, 0, 0) finished
06:52:59 start sampling a new configuration.
06:52:59 best_vector: [2, 0.28185099103286476, 0.8388112365350582, 0.4352041878823836, 0.09977555794933693, 0, 0.5725658737047825, 0.08188525046584329], 4.657267222710841e-06, 37559.32307486906, 0.17492380426379464
06:52:59 done sampling a new configuration.
06:52:59 HBMASTER: schedule new run for iteration 6
06:52:59 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
06:52:59 HBMASTER: submitting job (6, 0, 1) to dispatcher
06:52:59 DISPATCHER: trying to submit job (6, 0, 1)
06:52:59 DISPATCHER: trying to notify the job_runner thread.
06:52:59 HBMASTER: job (6, 0, 1) submitted to dispatcher
06:52:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:52:59 DISPATCHER: Trying to submit another job.
06:52:59 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:52:59 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:52:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:52:59 WORKER: start processing job (6, 0, 1)
06:52:59 WORKER: args: ()
06:52:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 42, 'lr': 0.007420076379452887, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01278012692639185}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:53:48 DISPATCHER: Starting worker discovery
06:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:48 DISPATCHER: Finished worker discovery
06:54:48 DISPATCHER: Starting worker discovery
06:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:48 DISPATCHER: Finished worker discovery
06:55:48 DISPATCHER: Starting worker discovery
06:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:48 DISPATCHER: Finished worker discovery
06:56:48 DISPATCHER: Starting worker discovery
06:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:48 DISPATCHER: Finished worker discovery
06:57:48 DISPATCHER: Starting worker discovery
06:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:48 DISPATCHER: Finished worker discovery
06:58:48 DISPATCHER: Starting worker discovery
06:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:48 DISPATCHER: Finished worker discovery
06:59:43 WORKER: done with job (6, 0, 1), trying to register it.
06:59:43 WORKER: registered result for job (6, 0, 1) with dispatcher
06:59:43 DISPATCHER: job (6, 0, 1) finished
06:59:43 DISPATCHER: register_result: lock acquired
06:59:43 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
06:59:43 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 42, 'lr': 0.007420076379452887, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01278012692639185}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.545330551068938, 'info': {'data02': 0.545330551068938, 'config': "{'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 42, 'lr': 0.007420076379452887, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01278012692639185}"}}
exception: None

06:59:43 job_callback for (6, 0, 1) started
06:59:43 job_callback for (6, 0, 1) got condition
06:59:43 DISPATCHER: Trying to submit another job.
06:59:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:59:43 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.655178





06:59:43 HBMASTER: Trying to run another job!
06:59:43 job_callback for (6, 0, 1) finished
06:59:43 start sampling a new configuration.
06:59:43 done sampling a new configuration.
06:59:43 HBMASTER: schedule new run for iteration 6
06:59:43 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
06:59:43 HBMASTER: submitting job (6, 0, 2) to dispatcher
06:59:43 DISPATCHER: trying to submit job (6, 0, 2)
06:59:43 DISPATCHER: trying to notify the job_runner thread.
06:59:43 HBMASTER: job (6, 0, 2) submitted to dispatcher
06:59:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:59:43 DISPATCHER: Trying to submit another job.
06:59:43 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
06:59:43 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
06:59:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:59:43 WORKER: start processing job (6, 0, 2)
06:59:43 WORKER: args: ()
06:59:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 86, 'last_n_outputs': 10, 'lr': 0.0032066011979597175, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.10722276411807294}, 'budget': 400.0, 'working_directory': '.'}
06:59:48 DISPATCHER: Starting worker discovery
06:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:48 DISPATCHER: Finished worker discovery
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:00:48 DISPATCHER: Starting worker discovery
07:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:48 DISPATCHER: Finished worker discovery
07:01:48 DISPATCHER: Starting worker discovery
07:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:48 DISPATCHER: Finished worker discovery
07:02:48 DISPATCHER: Starting worker discovery
07:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:48 DISPATCHER: Finished worker discovery
07:03:48 DISPATCHER: Starting worker discovery
07:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:48 DISPATCHER: Finished worker discovery
07:04:48 DISPATCHER: Starting worker discovery
07:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:48 DISPATCHER: Finished worker discovery
07:05:48 DISPATCHER: Starting worker discovery
07:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:48 DISPATCHER: Finished worker discovery
07:06:27 WORKER: done with job (6, 0, 2), trying to register it.
07:06:27 WORKER: registered result for job (6, 0, 2) with dispatcher
07:06:27 DISPATCHER: job (6, 0, 2) finished
07:06:27 DISPATCHER: register_result: lock acquired
07:06:27 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:06:27 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 86, 'last_n_outputs': 10, 'lr': 0.0032066011979597175, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.10722276411807294}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 86, 'last_n_outputs': 10, 'lr': 0.0032066011979597175, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.10722276411807294}"}}
exception: None

07:06:27 job_callback for (6, 0, 2) started
07:06:27 DISPATCHER: Trying to submit another job.
07:06:27 job_callback for (6, 0, 2) got condition
07:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:06:27 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.655178





07:06:27 HBMASTER: Trying to run another job!
07:06:27 job_callback for (6, 0, 2) finished
07:06:27 start sampling a new configuration.
07:06:27 best_vector: [2, 0.5706321357349848, 0.9519753717664335, 0.3612721137071278, 0.10020843989973052, 0, 0.30943302608978, 0.04473668352336489], 9.216904150536904e-06, 33644.30867117471, 0.3100963682332949
07:06:27 done sampling a new configuration.
07:06:27 HBMASTER: schedule new run for iteration 6
07:06:27 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
07:06:27 HBMASTER: submitting job (6, 0, 3) to dispatcher
07:06:27 DISPATCHER: trying to submit job (6, 0, 3)
07:06:27 DISPATCHER: trying to notify the job_runner thread.
07:06:27 HBMASTER: job (6, 0, 3) submitted to dispatcher
07:06:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:06:27 DISPATCHER: Trying to submit another job.
07:06:27 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:06:27 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:06:27 WORKER: start processing job (6, 0, 3)
07:06:27 WORKER: args: ()
07:06:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 48, 'lr': 0.005278909630794522, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.011434146891197362}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:06:48 DISPATCHER: Starting worker discovery
07:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:48 DISPATCHER: Finished worker discovery
07:07:48 DISPATCHER: Starting worker discovery
07:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:48 DISPATCHER: Finished worker discovery
07:08:48 DISPATCHER: Starting worker discovery
07:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:48 DISPATCHER: Finished worker discovery
07:09:48 DISPATCHER: Starting worker discovery
07:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:48 DISPATCHER: Finished worker discovery
07:10:48 DISPATCHER: Starting worker discovery
07:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:48 DISPATCHER: Finished worker discovery
07:11:48 DISPATCHER: Starting worker discovery
07:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:48 DISPATCHER: Finished worker discovery
07:12:48 DISPATCHER: Starting worker discovery
07:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:48 DISPATCHER: Finished worker discovery
07:13:11 WORKER: done with job (6, 0, 3), trying to register it.
07:13:11 WORKER: registered result for job (6, 0, 3) with dispatcher
07:13:11 DISPATCHER: job (6, 0, 3) finished
07:13:11 DISPATCHER: register_result: lock acquired
07:13:11 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:13:11 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 48, 'lr': 0.005278909630794522, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.011434146891197362}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5919483114082164, 'info': {'data02': 0.5919483114082164, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 48, 'lr': 0.005278909630794522, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.011434146891197362}"}}
exception: None

07:13:11 job_callback for (6, 0, 3) started
07:13:11 job_callback for (6, 0, 3) got condition
07:13:11 DISPATCHER: Trying to submit another job.
07:13:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:13:11 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.655178





07:13:11 HBMASTER: Trying to run another job!
07:13:11 job_callback for (6, 0, 3) finished
07:13:11 start sampling a new configuration.
07:13:11 best_vector: [1, 0.8624499550453872, 0.8259425199295326, 0.25554858762952565, 0.10022949081975467, 0, 0.7275612476411083, 0.016707648564686026], 5.633860273770012e-06, 10953.738840972765, 0.06171183410540803
07:13:11 done sampling a new configuration.
07:13:11 HBMASTER: schedule new run for iteration 6
07:13:11 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
07:13:11 HBMASTER: submitting job (6, 0, 4) to dispatcher
07:13:11 DISPATCHER: trying to submit job (6, 0, 4)
07:13:11 DISPATCHER: trying to notify the job_runner thread.
07:13:11 HBMASTER: job (6, 0, 4) submitted to dispatcher
07:13:11 DISPATCHER: Trying to submit another job.
07:13:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:13:11 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:13:11 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:13:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:13:11 WORKER: start processing job (6, 0, 4)
07:13:11 WORKER: args: ()
07:13:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0032441219785412936, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010513253875412994}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:13:48 DISPATCHER: Starting worker discovery
07:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:48 DISPATCHER: Finished worker discovery
07:14:48 DISPATCHER: Starting worker discovery
07:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:48 DISPATCHER: Finished worker discovery
07:15:48 DISPATCHER: Starting worker discovery
07:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:48 DISPATCHER: Finished worker discovery
07:16:48 DISPATCHER: Starting worker discovery
07:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:48 DISPATCHER: Finished worker discovery
07:17:48 DISPATCHER: Starting worker discovery
07:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:48 DISPATCHER: Finished worker discovery
07:18:48 DISPATCHER: Starting worker discovery
07:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:48 DISPATCHER: Finished worker discovery
07:19:48 DISPATCHER: Starting worker discovery
07:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:48 DISPATCHER: Finished worker discovery
07:19:55 WORKER: done with job (6, 0, 4), trying to register it.
07:19:55 WORKER: registered result for job (6, 0, 4) with dispatcher
07:19:55 DISPATCHER: job (6, 0, 4) finished
07:19:55 DISPATCHER: register_result: lock acquired
07:19:55 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:19:55 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0032441219785412936, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010513253875412994}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6630667093891662, 'info': {'data02': 0.6630667093891662, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0032441219785412936, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010513253875412994}"}}
exception: None

07:19:55 job_callback for (6, 0, 4) started
07:19:55 DISPATCHER: Trying to submit another job.
07:19:55 job_callback for (6, 0, 4) got condition
07:19:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:19:55 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.663067





07:19:55 HBMASTER: Trying to run another job!
07:19:55 job_callback for (6, 0, 4) finished
07:19:55 start sampling a new configuration.
07:19:55 best_vector: [2, 0.9602137989042312, 0.7135348606502844, 0.16239369022621178, 0.09925769875789371, 0, 0.34712380827330325, 0.024682132321511042], 1.654494934040144e-05, 3467.727738138065, 0.05737337975379915
07:19:55 done sampling a new configuration.
07:19:55 HBMASTER: schedule new run for iteration 6
07:19:55 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:19:55 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:19:55 DISPATCHER: trying to submit job (6, 0, 5)
07:19:55 DISPATCHER: trying to notify the job_runner thread.
07:19:55 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:19:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:19:55 DISPATCHER: Trying to submit another job.
07:19:55 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:19:55 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:19:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:19:55 WORKER: start processing job (6, 0, 5)
07:19:55 WORKER: args: ()
07:19:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 36, 'lr': 0.0021124545825265, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010767433407779518}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:20:48 DISPATCHER: Starting worker discovery
07:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:48 DISPATCHER: Finished worker discovery
07:21:48 DISPATCHER: Starting worker discovery
07:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:48 DISPATCHER: Finished worker discovery
07:22:48 DISPATCHER: Starting worker discovery
07:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:48 DISPATCHER: Finished worker discovery
07:23:48 DISPATCHER: Starting worker discovery
07:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:48 DISPATCHER: Finished worker discovery
07:24:48 DISPATCHER: Starting worker discovery
07:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:48 DISPATCHER: Finished worker discovery
07:25:48 DISPATCHER: Starting worker discovery
07:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:48 DISPATCHER: Finished worker discovery
07:26:39 WORKER: done with job (6, 0, 5), trying to register it.
07:26:39 WORKER: registered result for job (6, 0, 5) with dispatcher
07:26:39 DISPATCHER: job (6, 0, 5) finished
07:26:39 DISPATCHER: register_result: lock acquired
07:26:39 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:26:39 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 36, 'lr': 0.0021124545825265, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010767433407779518}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5607384129558567, 'info': {'data02': 0.5607384129558567, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 36, 'lr': 0.0021124545825265, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010767433407779518}"}}
exception: None

07:26:39 job_callback for (6, 0, 5) started
07:26:39 DISPATCHER: Trying to submit another job.
07:26:39 job_callback for (6, 0, 5) got condition
07:26:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:26:39 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.663067





07:26:39 HBMASTER: Trying to run another job!
07:26:39 job_callback for (6, 0, 5) finished
07:26:39 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
07:26:39 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
07:26:39 HBMASTER: schedule new run for iteration 6
07:26:39 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
07:26:39 HBMASTER: submitting job (6, 0, 3) to dispatcher
07:26:39 DISPATCHER: trying to submit job (6, 0, 3)
07:26:39 DISPATCHER: trying to notify the job_runner thread.
07:26:39 HBMASTER: job (6, 0, 3) submitted to dispatcher
07:26:39 DISPATCHER: Trying to submit another job.
07:26:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:26:39 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:26:39 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:26:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:26:39 WORKER: start processing job (6, 0, 3)
07:26:39 WORKER: args: ()
07:26:39 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 48, 'lr': 0.005278909630794522, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.011434146891197362}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:26:48 DISPATCHER: Starting worker discovery
07:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:48 DISPATCHER: Finished worker discovery
07:27:48 DISPATCHER: Starting worker discovery
07:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:48 DISPATCHER: Finished worker discovery
07:28:48 DISPATCHER: Starting worker discovery
07:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:48 DISPATCHER: Finished worker discovery
07:29:48 DISPATCHER: Starting worker discovery
07:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:48 DISPATCHER: Finished worker discovery
07:30:48 DISPATCHER: Starting worker discovery
07:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:48 DISPATCHER: Finished worker discovery
07:31:48 DISPATCHER: Starting worker discovery
07:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:48 DISPATCHER: Finished worker discovery
07:32:48 DISPATCHER: Starting worker discovery
07:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:48 DISPATCHER: Finished worker discovery
07:33:48 DISPATCHER: Starting worker discovery
07:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:48 DISPATCHER: Finished worker discovery
07:34:48 DISPATCHER: Starting worker discovery
07:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:48 DISPATCHER: Finished worker discovery
07:35:48 DISPATCHER: Starting worker discovery
07:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:48 DISPATCHER: Finished worker discovery
07:36:48 DISPATCHER: Starting worker discovery
07:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:48 DISPATCHER: Finished worker discovery
07:37:48 DISPATCHER: Starting worker discovery
07:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:48 DISPATCHER: Finished worker discovery
07:38:48 DISPATCHER: Starting worker discovery
07:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:48 DISPATCHER: Finished worker discovery
07:39:48 DISPATCHER: Starting worker discovery
07:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:48 DISPATCHER: Finished worker discovery
07:40:48 DISPATCHER: Starting worker discovery
07:40:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:48 DISPATCHER: Finished worker discovery
07:41:48 DISPATCHER: Starting worker discovery
07:41:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:48 DISPATCHER: Finished worker discovery
07:42:48 DISPATCHER: Starting worker discovery
07:42:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:48 DISPATCHER: Finished worker discovery
07:43:48 DISPATCHER: Starting worker discovery
07:43:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:48 DISPATCHER: Finished worker discovery
07:44:48 DISPATCHER: Starting worker discovery
07:44:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:48 DISPATCHER: Finished worker discovery
07:45:48 DISPATCHER: Starting worker discovery
07:45:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:48 DISPATCHER: Finished worker discovery
07:46:43 WORKER: done with job (6, 0, 3), trying to register it.
07:46:43 WORKER: registered result for job (6, 0, 3) with dispatcher
07:46:43 DISPATCHER: job (6, 0, 3) finished
07:46:43 DISPATCHER: register_result: lock acquired
07:46:43 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
07:46:43 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 48, 'lr': 0.005278909630794522, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.011434146891197362}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6506728461521757, 'info': {'data02': 0.6506728461521757, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 48, 'lr': 0.005278909630794522, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.011434146891197362}"}}
exception: None

07:46:43 job_callback for (6, 0, 3) started
07:46:43 DISPATCHER: Trying to submit another job.
07:46:43 job_callback for (6, 0, 3) got condition
07:46:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:46:43 HBMASTER: Trying to run another job!
07:46:43 job_callback for (6, 0, 3) finished
07:46:43 HBMASTER: schedule new run for iteration 6
07:46:43 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
07:46:43 HBMASTER: submitting job (6, 0, 4) to dispatcher
07:46:43 DISPATCHER: trying to submit job (6, 0, 4)
07:46:43 DISPATCHER: trying to notify the job_runner thread.
07:46:43 HBMASTER: job (6, 0, 4) submitted to dispatcher
07:46:43 DISPATCHER: Trying to submit another job.
07:46:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:46:43 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
07:46:43 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
07:46:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:46:43 WORKER: start processing job (6, 0, 4)
07:46:43 WORKER: args: ()
07:46:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0032441219785412936, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010513253875412994}, 'budget': 1200.0, 'working_directory': '.'}
07:46:48 DISPATCHER: Starting worker discovery
07:46:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:48 DISPATCHER: Finished worker discovery
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:47:48 DISPATCHER: Starting worker discovery
07:47:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:48 DISPATCHER: Finished worker discovery
07:48:48 DISPATCHER: Starting worker discovery
07:48:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:48 DISPATCHER: Finished worker discovery
07:49:48 DISPATCHER: Starting worker discovery
07:49:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:48 DISPATCHER: Finished worker discovery
07:50:48 DISPATCHER: Starting worker discovery
07:50:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:48 DISPATCHER: Finished worker discovery
07:51:48 DISPATCHER: Starting worker discovery
07:51:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:48 DISPATCHER: Finished worker discovery
07:52:48 DISPATCHER: Starting worker discovery
07:52:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:48 DISPATCHER: Finished worker discovery
07:53:48 DISPATCHER: Starting worker discovery
07:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:48 DISPATCHER: Finished worker discovery
07:54:48 DISPATCHER: Starting worker discovery
07:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:48 DISPATCHER: Finished worker discovery
07:55:48 DISPATCHER: Starting worker discovery
07:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:48 DISPATCHER: Finished worker discovery
07:56:48 DISPATCHER: Starting worker discovery
07:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:48 DISPATCHER: Finished worker discovery
07:57:48 DISPATCHER: Starting worker discovery
07:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:48 DISPATCHER: Finished worker discovery
07:58:48 DISPATCHER: Starting worker discovery
07:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:48 DISPATCHER: Finished worker discovery
07:59:48 DISPATCHER: Starting worker discovery
07:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:48 DISPATCHER: Finished worker discovery
08:00:48 DISPATCHER: Starting worker discovery
08:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:48 DISPATCHER: Finished worker discovery
08:01:48 DISPATCHER: Starting worker discovery
08:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:48 DISPATCHER: Finished worker discovery
08:02:48 DISPATCHER: Starting worker discovery
08:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:48 DISPATCHER: Finished worker discovery
08:03:48 DISPATCHER: Starting worker discovery
08:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:48 DISPATCHER: Finished worker discovery
08:04:48 DISPATCHER: Starting worker discovery
08:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:48 DISPATCHER: Finished worker discovery
08:05:48 DISPATCHER: Starting worker discovery
08:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:48 DISPATCHER: Finished worker discovery
08:06:48 WORKER: done with job (6, 0, 4), trying to register it.
08:06:48 WORKER: registered result for job (6, 0, 4) with dispatcher
08:06:48 DISPATCHER: job (6, 0, 4) finished
08:06:48 DISPATCHER: register_result: lock acquired
08:06:48 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:06:48 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0032441219785412936, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010513253875412994}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6061137572368573, 'info': {'data02': 0.6061137572368573, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0032441219785412936, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010513253875412994}"}}
exception: None

08:06:48 job_callback for (6, 0, 4) started
08:06:48 job_callback for (6, 0, 4) got condition
08:06:48 DISPATCHER: Trying to submit another job.
08:06:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:06:48 HBMASTER: Trying to run another job!
08:06:48 job_callback for (6, 0, 4) finished
08:06:48 start sampling a new configuration.
08:06:48 best_vector: [2, 0.6986061774073127, 0.9843059567143854, 0.4299316952819015, 0.09991876560199485, 0, 0.18066956285186087, 0.08206359490370889], 2.5896022872634038e-05, 10667.184956789491, 0.2762376656276384
08:06:48 done sampling a new configuration.
08:06:48 HBMASTER: schedule new run for iteration 7
08:06:48 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
08:06:48 HBMASTER: submitting job (7, 0, 0) to dispatcher
08:06:48 DISPATCHER: trying to submit job (7, 0, 0)
08:06:48 DISPATCHER: trying to notify the job_runner thread.
08:06:48 HBMASTER: job (7, 0, 0) submitted to dispatcher
08:06:48 DISPATCHER: Trying to submit another job.
08:06:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:06:48 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:06:48 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:06:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:06:48 WORKER: start processing job (7, 0, 0)
08:06:48 WORKER: args: ()
08:06:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 50, 'lr': 0.007242081210650682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.012786956817119723}, 'budget': 1200.0, 'working_directory': '.'}
08:06:48 DISPATCHER: Starting worker discovery
08:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:48 DISPATCHER: Finished worker discovery
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:07:48 DISPATCHER: Starting worker discovery
08:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:48 DISPATCHER: Finished worker discovery
08:08:48 DISPATCHER: Starting worker discovery
08:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:48 DISPATCHER: Finished worker discovery
08:09:48 DISPATCHER: Starting worker discovery
08:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:48 DISPATCHER: Finished worker discovery
08:10:48 DISPATCHER: Starting worker discovery
08:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:48 DISPATCHER: Finished worker discovery
08:11:48 DISPATCHER: Starting worker discovery
08:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:48 DISPATCHER: Finished worker discovery
08:12:48 DISPATCHER: Starting worker discovery
08:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:48 DISPATCHER: Finished worker discovery
08:13:48 DISPATCHER: Starting worker discovery
08:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:48 DISPATCHER: Finished worker discovery
08:14:48 DISPATCHER: Starting worker discovery
08:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:48 DISPATCHER: Finished worker discovery
08:15:48 DISPATCHER: Starting worker discovery
08:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:48 DISPATCHER: Finished worker discovery
08:16:48 DISPATCHER: Starting worker discovery
08:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:48 DISPATCHER: Finished worker discovery
08:17:48 DISPATCHER: Starting worker discovery
08:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:48 DISPATCHER: Finished worker discovery
08:18:48 DISPATCHER: Starting worker discovery
08:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:48 DISPATCHER: Finished worker discovery
08:19:48 DISPATCHER: Starting worker discovery
08:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:48 DISPATCHER: Finished worker discovery
08:20:48 DISPATCHER: Starting worker discovery
08:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:48 DISPATCHER: Finished worker discovery
08:21:48 DISPATCHER: Starting worker discovery
08:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:48 DISPATCHER: Finished worker discovery
08:22:48 DISPATCHER: Starting worker discovery
08:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:48 DISPATCHER: Finished worker discovery
08:23:48 DISPATCHER: Starting worker discovery
08:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:48 DISPATCHER: Finished worker discovery
08:24:48 DISPATCHER: Starting worker discovery
08:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:48 DISPATCHER: Finished worker discovery
08:25:48 DISPATCHER: Starting worker discovery
08:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:48 DISPATCHER: Finished worker discovery
08:26:48 DISPATCHER: Starting worker discovery
08:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:48 DISPATCHER: Finished worker discovery
08:26:52 WORKER: done with job (7, 0, 0), trying to register it.
08:26:52 WORKER: registered result for job (7, 0, 0) with dispatcher
08:26:52 DISPATCHER: job (7, 0, 0) finished
08:26:52 DISPATCHER: register_result: lock acquired
08:26:52 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:26:52 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 50, 'lr': 0.007242081210650682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.012786956817119723}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36119826123097326, 'info': {'data02': 0.36119826123097326, 'config': "{'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 50, 'lr': 0.007242081210650682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.012786956817119723}"}}
exception: None

08:26:52 job_callback for (7, 0, 0) started
08:26:52 DISPATCHER: Trying to submit another job.
08:26:52 job_callback for (7, 0, 0) got condition
08:26:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:26:52 HBMASTER: Trying to run another job!
08:26:52 job_callback for (7, 0, 0) finished
08:26:52 start sampling a new configuration.
08:26:52 best_vector: [1, 0.4909787543727109, 0.8691904091291249, 0.4343898079370614, 0.09931728280080852, 0, 0.10585966356226262, 0.0743430135651779], 7.276096548242949e-05, 2761.886350239648, 0.2009575173961802
08:26:52 done sampling a new configuration.
08:26:52 HBMASTER: schedule new run for iteration 7
08:26:52 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
08:26:52 HBMASTER: submitting job (7, 0, 1) to dispatcher
08:26:52 DISPATCHER: trying to submit job (7, 0, 1)
08:26:52 DISPATCHER: trying to notify the job_runner thread.
08:26:52 HBMASTER: job (7, 0, 1) submitted to dispatcher
08:26:52 DISPATCHER: Trying to submit another job.
08:26:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:26:52 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:26:52 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:26:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:26:52 WORKER: start processing job (7, 0, 1)
08:26:52 WORKER: args: ()
08:26:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.007392300552037811, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.012494603836781623}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:27:48 DISPATCHER: Starting worker discovery
08:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:48 DISPATCHER: Finished worker discovery
08:28:48 DISPATCHER: Starting worker discovery
08:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:48 DISPATCHER: Finished worker discovery
08:29:48 DISPATCHER: Starting worker discovery
08:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:48 DISPATCHER: Finished worker discovery
08:30:48 DISPATCHER: Starting worker discovery
08:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:48 DISPATCHER: Finished worker discovery
08:31:48 DISPATCHER: Starting worker discovery
08:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:48 DISPATCHER: Finished worker discovery
08:32:48 DISPATCHER: Starting worker discovery
08:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:48 DISPATCHER: Finished worker discovery
08:33:48 DISPATCHER: Starting worker discovery
08:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:48 DISPATCHER: Finished worker discovery
08:34:48 DISPATCHER: Starting worker discovery
08:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:48 DISPATCHER: Finished worker discovery
08:35:48 DISPATCHER: Starting worker discovery
08:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:48 DISPATCHER: Finished worker discovery
08:36:48 DISPATCHER: Starting worker discovery
08:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:48 DISPATCHER: Finished worker discovery
08:37:48 DISPATCHER: Starting worker discovery
08:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:48 DISPATCHER: Finished worker discovery
08:38:48 DISPATCHER: Starting worker discovery
08:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:48 DISPATCHER: Finished worker discovery
08:39:48 DISPATCHER: Starting worker discovery
08:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:49 DISPATCHER: Finished worker discovery
08:40:49 DISPATCHER: Starting worker discovery
08:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:49 DISPATCHER: Finished worker discovery
08:41:49 DISPATCHER: Starting worker discovery
08:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:49 DISPATCHER: Finished worker discovery
08:42:49 DISPATCHER: Starting worker discovery
08:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:49 DISPATCHER: Finished worker discovery
08:43:49 DISPATCHER: Starting worker discovery
08:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:49 DISPATCHER: Finished worker discovery
08:44:49 DISPATCHER: Starting worker discovery
08:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:49 DISPATCHER: Finished worker discovery
08:45:49 DISPATCHER: Starting worker discovery
08:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:49 DISPATCHER: Finished worker discovery
08:46:49 DISPATCHER: Starting worker discovery
08:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:49 DISPATCHER: Finished worker discovery
08:46:55 WORKER: done with job (7, 0, 1), trying to register it.
08:46:55 WORKER: registered result for job (7, 0, 1) with dispatcher
08:46:55 DISPATCHER: job (7, 0, 1) finished
08:46:55 DISPATCHER: register_result: lock acquired
08:46:55 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
08:46:55 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.007392300552037811, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.012494603836781623}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.26229722622380236, 'info': {'data02': 0.26229722622380236, 'config': "{'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.007392300552037811, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.012494603836781623}"}}
exception: None

08:46:55 job_callback for (7, 0, 1) started
08:46:55 DISPATCHER: Trying to submit another job.
08:46:55 job_callback for (7, 0, 1) got condition
08:46:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:46:56 HBMASTER: Trying to run another job!
08:46:56 job_callback for (7, 0, 1) finished
08:46:56 start sampling a new configuration.
08:46:56 best_vector: [2, 0.3207413584496087, 0.862427402838768, 0.41359718227648967, 0.10026618259951606, 0, 0.10938897201489559, 0.09045015915156758], 7.912537129648812e-05, 2030.8242160388909, 0.16068972013197663
08:46:56 done sampling a new configuration.
08:46:56 HBMASTER: schedule new run for iteration 7
08:46:56 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
08:46:56 HBMASTER: submitting job (7, 0, 2) to dispatcher
08:46:56 DISPATCHER: trying to submit job (7, 0, 2)
08:46:56 DISPATCHER: trying to notify the job_runner thread.
08:46:56 HBMASTER: job (7, 0, 2) submitted to dispatcher
08:46:56 DISPATCHER: Trying to submit another job.
08:46:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:46:56 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
08:46:56 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
08:46:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:46:56 WORKER: start processing job (7, 0, 2)
08:46:56 WORKER: args: ()
08:46:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 45, 'last_n_outputs': 44, 'lr': 0.006717294120652885, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013112284697009998}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:47:49 DISPATCHER: Starting worker discovery
08:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:49 DISPATCHER: Finished worker discovery
08:48:49 DISPATCHER: Starting worker discovery
08:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:49 DISPATCHER: Finished worker discovery
08:49:49 DISPATCHER: Starting worker discovery
08:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:49 DISPATCHER: Finished worker discovery
08:50:49 DISPATCHER: Starting worker discovery
08:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:49 DISPATCHER: Finished worker discovery
08:51:49 DISPATCHER: Starting worker discovery
08:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:49 DISPATCHER: Finished worker discovery
08:52:49 DISPATCHER: Starting worker discovery
08:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:49 DISPATCHER: Finished worker discovery
08:53:49 DISPATCHER: Starting worker discovery
08:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:49 DISPATCHER: Finished worker discovery
08:54:49 DISPATCHER: Starting worker discovery
08:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:49 DISPATCHER: Finished worker discovery
08:55:49 DISPATCHER: Starting worker discovery
08:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:49 DISPATCHER: Finished worker discovery
08:56:49 DISPATCHER: Starting worker discovery
08:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:49 DISPATCHER: Finished worker discovery
08:57:49 DISPATCHER: Starting worker discovery
08:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:49 DISPATCHER: Finished worker discovery
08:58:49 DISPATCHER: Starting worker discovery
08:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:49 DISPATCHER: Finished worker discovery
08:59:49 DISPATCHER: Starting worker discovery
08:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:49 DISPATCHER: Finished worker discovery
09:00:49 DISPATCHER: Starting worker discovery
09:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:49 DISPATCHER: Finished worker discovery
09:01:49 DISPATCHER: Starting worker discovery
09:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:49 DISPATCHER: Finished worker discovery
09:02:49 DISPATCHER: Starting worker discovery
09:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:49 DISPATCHER: Finished worker discovery
09:03:49 DISPATCHER: Starting worker discovery
09:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:49 DISPATCHER: Finished worker discovery
09:04:49 DISPATCHER: Starting worker discovery
09:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:49 DISPATCHER: Finished worker discovery
09:05:49 DISPATCHER: Starting worker discovery
09:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:49 DISPATCHER: Finished worker discovery
09:06:49 DISPATCHER: Starting worker discovery
09:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:49 DISPATCHER: Finished worker discovery
09:06:59 WORKER: done with job (7, 0, 2), trying to register it.
09:06:59 WORKER: registered result for job (7, 0, 2) with dispatcher
09:06:59 DISPATCHER: job (7, 0, 2) finished
09:06:59 DISPATCHER: register_result: lock acquired
09:06:59 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:06:59 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 45, 'last_n_outputs': 44, 'lr': 0.006717294120652885, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013112284697009998}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.449460732313877, 'info': {'data02': 0.449460732313877, 'config': "{'batch_size': 64, 'hidden_dim': 45, 'last_n_outputs': 44, 'lr': 0.006717294120652885, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.013112284697009998}"}}
exception: None

09:06:59 job_callback for (7, 0, 2) started
09:06:59 job_callback for (7, 0, 2) got condition
09:06:59 DISPATCHER: Trying to submit another job.
09:06:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:06:59 HBMASTER: Trying to run another job!
09:06:59 job_callback for (7, 0, 2) finished
09:06:59 start sampling a new configuration.
09:06:59 best_vector: [2, 0.7872269009043356, 0.7260751745342766, 0.4504823362246358, 0.1007687480230001, 1, 0.06585083977880643, 0.20848916826160685], 0.0, inf, 0.19760072832368017
09:06:59 done sampling a new configuration.
09:06:59 HBMASTER: schedule new run for iteration 7
09:06:59 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
09:06:59 HBMASTER: submitting job (7, 0, 3) to dispatcher
09:06:59 DISPATCHER: trying to submit job (7, 0, 3)
09:06:59 DISPATCHER: trying to notify the job_runner thread.
09:06:59 HBMASTER: job (7, 0, 3) submitted to dispatcher
09:06:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:06:59 DISPATCHER: Trying to submit another job.
09:06:59 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:06:59 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:06:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:06:59 WORKER: start processing job (7, 0, 3)
09:06:59 WORKER: args: ()
09:06:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 37, 'lr': 0.007960945897144377, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.018674572198427507}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:07:49 DISPATCHER: Starting worker discovery
09:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:49 DISPATCHER: Finished worker discovery
09:08:49 DISPATCHER: Starting worker discovery
09:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:49 DISPATCHER: Finished worker discovery
09:09:49 DISPATCHER: Starting worker discovery
09:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:49 DISPATCHER: Finished worker discovery
09:10:49 DISPATCHER: Starting worker discovery
09:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:49 DISPATCHER: Finished worker discovery
09:11:49 DISPATCHER: Starting worker discovery
09:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:49 DISPATCHER: Finished worker discovery
09:12:49 DISPATCHER: Starting worker discovery
09:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:49 DISPATCHER: Finished worker discovery
09:13:49 DISPATCHER: Starting worker discovery
09:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:49 DISPATCHER: Finished worker discovery
09:14:49 DISPATCHER: Starting worker discovery
09:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:49 DISPATCHER: Finished worker discovery
09:15:49 DISPATCHER: Starting worker discovery
09:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:49 DISPATCHER: Finished worker discovery
09:16:49 DISPATCHER: Starting worker discovery
09:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:49 DISPATCHER: Finished worker discovery
09:17:49 DISPATCHER: Starting worker discovery
09:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:49 DISPATCHER: Finished worker discovery
09:18:49 DISPATCHER: Starting worker discovery
09:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:49 DISPATCHER: Finished worker discovery
09:19:49 DISPATCHER: Starting worker discovery
09:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:49 DISPATCHER: Finished worker discovery
09:20:49 DISPATCHER: Starting worker discovery
09:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:49 DISPATCHER: Finished worker discovery
09:21:49 DISPATCHER: Starting worker discovery
09:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:49 DISPATCHER: Finished worker discovery
09:22:49 DISPATCHER: Starting worker discovery
09:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:49 DISPATCHER: Finished worker discovery
09:23:49 DISPATCHER: Starting worker discovery
09:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:49 DISPATCHER: Finished worker discovery
09:24:49 DISPATCHER: Starting worker discovery
09:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:49 DISPATCHER: Finished worker discovery
09:25:49 DISPATCHER: Starting worker discovery
09:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:49 DISPATCHER: Finished worker discovery
09:26:49 DISPATCHER: Starting worker discovery
09:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:49 DISPATCHER: Finished worker discovery
09:27:03 WORKER: done with job (7, 0, 3), trying to register it.
09:27:03 WORKER: registered result for job (7, 0, 3) with dispatcher
09:27:03 DISPATCHER: job (7, 0, 3) finished
09:27:03 DISPATCHER: register_result: lock acquired
09:27:03 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:27:03 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 37, 'lr': 0.007960945897144377, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.018674572198427507}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.011859927044361143, 'info': {'data02': 0.011859927044361143, 'config': "{'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 37, 'lr': 0.007960945897144377, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.018674572198427507}"}}
exception: None

09:27:03 job_callback for (7, 0, 3) started
09:27:03 job_callback for (7, 0, 3) got condition
09:27:03 DISPATCHER: Trying to submit another job.
09:27:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:03 HBMASTER: Trying to run another job!
09:27:03 job_callback for (7, 0, 3) finished
09:27:03 start sampling a new configuration.
09:27:03 done sampling a new configuration.
09:27:03 HBMASTER: schedule new run for iteration 8
09:27:03 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
09:27:03 HBMASTER: submitting job (8, 0, 0) to dispatcher
09:27:03 DISPATCHER: trying to submit job (8, 0, 0)
09:27:03 DISPATCHER: trying to notify the job_runner thread.
09:27:03 HBMASTER: job (8, 0, 0) submitted to dispatcher
09:27:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:03 DISPATCHER: Trying to submit another job.
09:27:03 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:27:03 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:27:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:03 WORKER: start processing job (8, 0, 0)
09:27:03 WORKER: args: ()
09:27:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 15, 'lr': 0.010001572041228876, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.04564127540115916}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:27:49 DISPATCHER: Starting worker discovery
09:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:49 DISPATCHER: Finished worker discovery
09:27:51 WORKER: done with job (8, 0, 0), trying to register it.
09:27:51 WORKER: registered result for job (8, 0, 0) with dispatcher
09:27:51 DISPATCHER: job (8, 0, 0) finished
09:27:51 DISPATCHER: register_result: lock acquired
09:27:51 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:27:51 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 15, 'lr': 0.010001572041228876, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.04564127540115916}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 15, 'lr': 0.010001572041228876, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.04564127540115916}"}}
exception: None

09:27:51 job_callback for (8, 0, 0) started
09:27:51 job_callback for (8, 0, 0) got condition
09:27:51 DISPATCHER: Trying to submit another job.
09:27:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:51 HBMASTER: Trying to run another job!
09:27:51 job_callback for (8, 0, 0) finished
09:27:51 start sampling a new configuration.
09:27:51 best_vector: [2, 0.7592424595663735, 0.9584335204549166, 0.3500169429250419, 0.0989692921480861, 0, 0.8081381380790322, 0.07706653050758652], 4.424432319219723e-05, 8860.74190835731, 0.3920375287160073
09:27:51 done sampling a new configuration.
09:27:51 HBMASTER: schedule new run for iteration 8
09:27:51 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
09:27:51 HBMASTER: submitting job (8, 0, 1) to dispatcher
09:27:51 DISPATCHER: trying to submit job (8, 0, 1)
09:27:51 DISPATCHER: trying to notify the job_runner thread.
09:27:51 HBMASTER: job (8, 0, 1) submitted to dispatcher
09:27:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:51 DISPATCHER: Trying to submit another job.
09:27:51 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:27:51 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:27:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:51 WORKER: start processing job (8, 0, 1)
09:27:51 WORKER: args: ()
09:27:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.005012263403135036, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.012596963409248577}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:28:40 WORKER: done with job (8, 0, 1), trying to register it.
09:28:40 WORKER: registered result for job (8, 0, 1) with dispatcher
09:28:40 DISPATCHER: job (8, 0, 1) finished
09:28:40 DISPATCHER: register_result: lock acquired
09:28:40 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:28:40 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.005012263403135036, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.012596963409248577}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5523496814995055, 'info': {'data02': 0.5523496814995055, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.005012263403135036, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.012596963409248577}"}}
exception: None

09:28:40 job_callback for (8, 0, 1) started
09:28:40 DISPATCHER: Trying to submit another job.
09:28:40 job_callback for (8, 0, 1) got condition
09:28:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:40 HBMASTER: Trying to run another job!
09:28:40 job_callback for (8, 0, 1) finished
09:28:40 start sampling a new configuration.
09:28:40 done sampling a new configuration.
09:28:40 HBMASTER: schedule new run for iteration 8
09:28:40 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
09:28:40 HBMASTER: submitting job (8, 0, 2) to dispatcher
09:28:40 DISPATCHER: trying to submit job (8, 0, 2)
09:28:40 DISPATCHER: trying to notify the job_runner thread.
09:28:40 HBMASTER: job (8, 0, 2) submitted to dispatcher
09:28:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:40 DISPATCHER: Trying to submit another job.
09:28:40 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:28:40 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:28:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:40 WORKER: start processing job (8, 0, 2)
09:28:40 WORKER: args: ()
09:28:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 20, 'lr': 0.04737905478336226, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.015495948461801076}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:28:49 DISPATCHER: Starting worker discovery
09:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:49 DISPATCHER: Finished worker discovery
09:29:28 WORKER: done with job (8, 0, 2), trying to register it.
09:29:28 WORKER: registered result for job (8, 0, 2) with dispatcher
09:29:28 DISPATCHER: job (8, 0, 2) finished
09:29:28 DISPATCHER: register_result: lock acquired
09:29:28 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:29:28 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 20, 'lr': 0.04737905478336226, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.015495948461801076}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0013517840634395641, 'info': {'data02': -0.0013517840634395641, 'config': "{'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 20, 'lr': 0.04737905478336226, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.015495948461801076}"}}
exception: None

09:29:28 job_callback for (8, 0, 2) started
09:29:28 DISPATCHER: Trying to submit another job.
09:29:28 job_callback for (8, 0, 2) got condition
09:29:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:28 HBMASTER: Trying to run another job!
09:29:28 job_callback for (8, 0, 2) finished
09:29:28 start sampling a new configuration.
09:29:28 best_vector: [2, 0.4329273723807049, 0.9297246472956989, 0.42527569725692055, 0.09942954422733052, 0, 0.5200940429692715, 0.05111813581926829], 1.641874292273769e-05, 44936.767263188885, 0.7378052294731933
09:29:28 done sampling a new configuration.
09:29:28 HBMASTER: schedule new run for iteration 8
09:29:28 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
09:29:28 HBMASTER: submitting job (8, 0, 3) to dispatcher
09:29:28 DISPATCHER: trying to submit job (8, 0, 3)
09:29:28 DISPATCHER: trying to notify the job_runner thread.
09:29:28 HBMASTER: job (8, 0, 3) submitted to dispatcher
09:29:28 DISPATCHER: Trying to submit another job.
09:29:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:28 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:29:28 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:29:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:28 WORKER: start processing job (8, 0, 3)
09:29:28 WORKER: args: ()
09:29:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 47, 'lr': 0.007088451863983947, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01165483764399743}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:29:49 DISPATCHER: Starting worker discovery
09:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:49 DISPATCHER: Finished worker discovery
09:30:16 WORKER: done with job (8, 0, 3), trying to register it.
09:30:16 WORKER: registered result for job (8, 0, 3) with dispatcher
09:30:16 DISPATCHER: job (8, 0, 3) finished
09:30:16 DISPATCHER: register_result: lock acquired
09:30:16 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:30:16 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 47, 'lr': 0.007088451863983947, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01165483764399743}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6112855076932878, 'info': {'data02': 0.6112855076932878, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 47, 'lr': 0.007088451863983947, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01165483764399743}"}}
exception: None

09:30:16 job_callback for (8, 0, 3) started
09:30:16 job_callback for (8, 0, 3) got condition
09:30:16 DISPATCHER: Trying to submit another job.
09:30:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:30:16 HBMASTER: Trying to run another job!
09:30:16 job_callback for (8, 0, 3) finished
09:30:16 start sampling a new configuration.
09:30:16 done sampling a new configuration.
09:30:16 HBMASTER: schedule new run for iteration 8
09:30:16 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
09:30:16 HBMASTER: submitting job (8, 0, 4) to dispatcher
09:30:16 DISPATCHER: trying to submit job (8, 0, 4)
09:30:16 DISPATCHER: trying to notify the job_runner thread.
09:30:16 HBMASTER: job (8, 0, 4) submitted to dispatcher
09:30:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:30:16 DISPATCHER: Trying to submit another job.
09:30:16 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:30:16 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:30:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:30:16 WORKER: start processing job (8, 0, 4)
09:30:16 WORKER: args: ()
09:30:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 20, 'lr': 0.0019525361341504752, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02111948953892699}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:30:49 DISPATCHER: Starting worker discovery
09:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:49 DISPATCHER: Finished worker discovery
09:31:04 WORKER: done with job (8, 0, 4), trying to register it.
09:31:04 WORKER: registered result for job (8, 0, 4) with dispatcher
09:31:04 DISPATCHER: job (8, 0, 4) finished
09:31:04 DISPATCHER: register_result: lock acquired
09:31:04 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:31:04 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 20, 'lr': 0.0019525361341504752, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02111948953892699}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 20, 'lr': 0.0019525361341504752, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02111948953892699}"}}
exception: None

09:31:04 job_callback for (8, 0, 4) started
09:31:04 DISPATCHER: Trying to submit another job.
09:31:04 job_callback for (8, 0, 4) got condition
09:31:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:04 HBMASTER: Trying to run another job!
09:31:04 job_callback for (8, 0, 4) finished
09:31:04 start sampling a new configuration.
09:31:05 best_vector: [2, 0.5211093745395947, 0.9947332461020661, 0.5006897761973121, 0.10030512771061009, 0, 0.4997741545007763, 0.06899087023426313], 1.837794933783424e-05, 28988.01458061666, 0.5327402633669732
09:31:05 done sampling a new configuration.
09:31:05 HBMASTER: schedule new run for iteration 8
09:31:05 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
09:31:05 HBMASTER: submitting job (8, 0, 5) to dispatcher
09:31:05 DISPATCHER: trying to submit job (8, 0, 5)
09:31:05 DISPATCHER: trying to notify the job_runner thread.
09:31:05 HBMASTER: job (8, 0, 5) submitted to dispatcher
09:31:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:05 DISPATCHER: Trying to submit another job.
09:31:05 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:31:05 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:31:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:05 WORKER: start processing job (8, 0, 5)
09:31:05 WORKER: args: ()
09:31:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:31:49 DISPATCHER: Starting worker discovery
09:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:49 DISPATCHER: Finished worker discovery
09:31:52 WORKER: done with job (8, 0, 5), trying to register it.
09:31:52 WORKER: registered result for job (8, 0, 5) with dispatcher
09:31:52 DISPATCHER: job (8, 0, 5) finished
09:31:52 DISPATCHER: register_result: lock acquired
09:31:52 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:31:52 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6159438025097059, 'info': {'data02': 0.6159438025097059, 'config': "{'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}"}}
exception: None

09:31:52 job_callback for (8, 0, 5) started
09:31:52 job_callback for (8, 0, 5) got condition
09:31:52 DISPATCHER: Trying to submit another job.
09:31:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:52 HBMASTER: Trying to run another job!
09:31:52 job_callback for (8, 0, 5) finished
09:31:52 start sampling a new configuration.
09:31:53 best_vector: [2, 0.7220392919843345, 0.7562320469816267, 0.32002649460423416, 0.10049118859286585, 0, 0.35425441065512375, 0.03981689559802338], 2.6463856398060486e-05, 26051.48067038203, 0.6894226434178385
09:31:53 done sampling a new configuration.
09:31:53 HBMASTER: schedule new run for iteration 8
09:31:53 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
09:31:53 HBMASTER: submitting job (8, 0, 6) to dispatcher
09:31:53 DISPATCHER: trying to submit job (8, 0, 6)
09:31:53 DISPATCHER: trying to notify the job_runner thread.
09:31:53 HBMASTER: job (8, 0, 6) submitted to dispatcher
09:31:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:53 DISPATCHER: Trying to submit another job.
09:31:53 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:31:53 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:31:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:53 WORKER: start processing job (8, 0, 6)
09:31:53 WORKER: args: ()
09:31:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 38, 'lr': 0.0043656909572972104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011266862013757891}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:32:41 WORKER: done with job (8, 0, 6), trying to register it.
09:32:41 WORKER: registered result for job (8, 0, 6) with dispatcher
09:32:41 DISPATCHER: job (8, 0, 6) finished
09:32:41 DISPATCHER: register_result: lock acquired
09:32:41 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:32:41 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 38, 'lr': 0.0043656909572972104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011266862013757891}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5805678587468173, 'info': {'data02': 0.5805678587468173, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 38, 'lr': 0.0043656909572972104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011266862013757891}"}}
exception: None

09:32:41 job_callback for (8, 0, 6) started
09:32:41 job_callback for (8, 0, 6) got condition
09:32:41 DISPATCHER: Trying to submit another job.
09:32:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:41 HBMASTER: Trying to run another job!
09:32:41 job_callback for (8, 0, 6) finished
09:32:41 start sampling a new configuration.
09:32:41 done sampling a new configuration.
09:32:41 HBMASTER: schedule new run for iteration 8
09:32:41 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
09:32:41 HBMASTER: submitting job (8, 0, 7) to dispatcher
09:32:41 DISPATCHER: trying to submit job (8, 0, 7)
09:32:41 DISPATCHER: trying to notify the job_runner thread.
09:32:41 HBMASTER: job (8, 0, 7) submitted to dispatcher
09:32:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:41 DISPATCHER: Trying to submit another job.
09:32:41 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:32:41 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:32:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:41 WORKER: start processing job (8, 0, 7)
09:32:41 WORKER: args: ()
09:32:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.041308490513851, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.015101857451009731}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:32:49 DISPATCHER: Starting worker discovery
09:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:49 DISPATCHER: Finished worker discovery
09:33:30 WORKER: done with job (8, 0, 7), trying to register it.
09:33:30 WORKER: registered result for job (8, 0, 7) with dispatcher
09:33:30 DISPATCHER: job (8, 0, 7) finished
09:33:30 DISPATCHER: register_result: lock acquired
09:33:30 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:33:30 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.041308490513851, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.015101857451009731}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2011375403243711, 'info': {'data02': 0.2011375403243711, 'config': "{'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.041308490513851, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.015101857451009731}"}}
exception: None

09:33:30 job_callback for (8, 0, 7) started
09:33:30 DISPATCHER: Trying to submit another job.
09:33:30 job_callback for (8, 0, 7) got condition
09:33:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:30 HBMASTER: Trying to run another job!
09:33:30 job_callback for (8, 0, 7) finished
09:33:30 start sampling a new configuration.
09:33:30 best_vector: [2, 0.673409959694951, 0.9237934062438211, 0.3755374529317002, 0.09829170144177518, 0, 0.5372583308755761, 0.04956992128763944], 2.596462940958715e-05, 20385.663096371634, 0.5293061875659864
09:33:30 done sampling a new configuration.
09:33:30 HBMASTER: schedule new run for iteration 8
09:33:30 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
09:33:30 HBMASTER: submitting job (8, 0, 8) to dispatcher
09:33:30 DISPATCHER: trying to submit job (8, 0, 8)
09:33:30 DISPATCHER: trying to notify the job_runner thread.
09:33:30 HBMASTER: job (8, 0, 8) submitted to dispatcher
09:33:30 DISPATCHER: Trying to submit another job.
09:33:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:30 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:33:30 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:33:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:30 WORKER: start processing job (8, 0, 8)
09:33:30 WORKER: args: ()
09:33:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:33:49 DISPATCHER: Starting worker discovery
09:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:49 DISPATCHER: Finished worker discovery
09:34:18 WORKER: done with job (8, 0, 8), trying to register it.
09:34:18 WORKER: registered result for job (8, 0, 8) with dispatcher
09:34:18 DISPATCHER: job (8, 0, 8) finished
09:34:18 DISPATCHER: register_result: lock acquired
09:34:18 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:34:18 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6679055763248184, 'info': {'data02': 0.6679055763248184, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}"}}
exception: None

09:34:18 job_callback for (8, 0, 8) started
09:34:18 DISPATCHER: Trying to submit another job.
09:34:18 job_callback for (8, 0, 8) got condition
09:34:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:34:18 HBMASTER: Trying to run another job!
09:34:18 job_callback for (8, 0, 8) finished
09:34:18 start sampling a new configuration.
09:34:18 done sampling a new configuration.
09:34:18 HBMASTER: schedule new run for iteration 8
09:34:18 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
09:34:18 HBMASTER: submitting job (8, 0, 9) to dispatcher
09:34:18 DISPATCHER: trying to submit job (8, 0, 9)
09:34:18 DISPATCHER: trying to notify the job_runner thread.
09:34:18 HBMASTER: job (8, 0, 9) submitted to dispatcher
09:34:18 DISPATCHER: Trying to submit another job.
09:34:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:34:18 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:34:18 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:34:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:34:18 WORKER: start processing job (8, 0, 9)
09:34:18 WORKER: args: ()
09:34:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 41, 'lr': 0.007020895159216018, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09909350084328788}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:34:49 DISPATCHER: Starting worker discovery
09:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:49 DISPATCHER: Finished worker discovery
09:35:07 WORKER: done with job (8, 0, 9), trying to register it.
09:35:07 WORKER: registered result for job (8, 0, 9) with dispatcher
09:35:07 DISPATCHER: job (8, 0, 9) finished
09:35:07 DISPATCHER: register_result: lock acquired
09:35:07 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:35:07 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 41, 'lr': 0.007020895159216018, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09909350084328788}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2986330542852075, 'info': {'data02': 0.2986330542852075, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 41, 'lr': 0.007020895159216018, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09909350084328788}"}}
exception: None

09:35:07 job_callback for (8, 0, 9) started
09:35:07 DISPATCHER: Trying to submit another job.
09:35:07 job_callback for (8, 0, 9) got condition
09:35:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:07 HBMASTER: Trying to run another job!
09:35:07 job_callback for (8, 0, 9) finished
09:35:07 start sampling a new configuration.
09:35:07 best_vector: [2, 0.6289155975263643, 0.977734577609794, 0.33246208215593354, 0.10039816297174493, 0, 0.03735072084009172, 0.06178494056816797], 2.0419736101477558e-05, 5959.102683274209, 0.12168330419406614
09:35:07 done sampling a new configuration.
09:35:07 HBMASTER: schedule new run for iteration 8
09:35:07 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
09:35:07 HBMASTER: submitting job (8, 0, 10) to dispatcher
09:35:07 DISPATCHER: trying to submit job (8, 0, 10)
09:35:07 DISPATCHER: trying to notify the job_runner thread.
09:35:07 HBMASTER: job (8, 0, 10) submitted to dispatcher
09:35:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:07 DISPATCHER: Trying to submit another job.
09:35:07 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:35:07 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:35:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:07 WORKER: start processing job (8, 0, 10)
09:35:07 WORKER: args: ()
09:35:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 70, 'last_n_outputs': 49, 'lr': 0.004623002883411957, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.012033281070309551}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:35:49 DISPATCHER: Starting worker discovery
09:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:49 DISPATCHER: Finished worker discovery
09:35:55 WORKER: done with job (8, 0, 10), trying to register it.
09:35:55 WORKER: registered result for job (8, 0, 10) with dispatcher
09:35:55 DISPATCHER: job (8, 0, 10) finished
09:35:55 DISPATCHER: register_result: lock acquired
09:35:55 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:35:55 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 70, 'last_n_outputs': 49, 'lr': 0.004623002883411957, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.012033281070309551}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3206328287004658, 'info': {'data02': 0.3206328287004658, 'config': "{'batch_size': 64, 'hidden_dim': 70, 'last_n_outputs': 49, 'lr': 0.004623002883411957, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.012033281070309551}"}}
exception: None

09:35:55 job_callback for (8, 0, 10) started
09:35:55 DISPATCHER: Trying to submit another job.
09:35:55 job_callback for (8, 0, 10) got condition
09:35:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:55 HBMASTER: Trying to run another job!
09:35:55 job_callback for (8, 0, 10) finished
09:35:55 start sampling a new configuration.
09:35:55 best_vector: [2, 0.5647392978989036, 0.8788601706042551, 0.2017957176788302, 0.10116294655352143, 0, 0.40690241595205223, 0.056425327935205945], 0.00017249294705510058, 2036.10146185123, 0.3512131416579171
09:35:55 done sampling a new configuration.
09:35:55 HBMASTER: schedule new run for iteration 8
09:35:55 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
09:35:55 HBMASTER: submitting job (8, 0, 11) to dispatcher
09:35:55 DISPATCHER: trying to submit job (8, 0, 11)
09:35:55 DISPATCHER: trying to notify the job_runner thread.
09:35:55 HBMASTER: job (8, 0, 11) submitted to dispatcher
09:35:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:55 DISPATCHER: Trying to submit another job.
09:35:55 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:35:55 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:35:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:55 WORKER: start processing job (8, 0, 11)
09:35:55 WORKER: args: ()
09:35:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 65, 'last_n_outputs': 44, 'lr': 0.0025327448173984623, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.011841617921971366}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:36:43 WORKER: done with job (8, 0, 11), trying to register it.
09:36:43 WORKER: registered result for job (8, 0, 11) with dispatcher
09:36:43 DISPATCHER: job (8, 0, 11) finished
09:36:43 DISPATCHER: register_result: lock acquired
09:36:43 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:36:43 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 65, 'last_n_outputs': 44, 'lr': 0.0025327448173984623, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.011841617921971366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5746759429163529, 'info': {'data02': 0.5746759429163529, 'config': "{'batch_size': 64, 'hidden_dim': 65, 'last_n_outputs': 44, 'lr': 0.0025327448173984623, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.011841617921971366}"}}
exception: None

09:36:43 job_callback for (8, 0, 11) started
09:36:43 job_callback for (8, 0, 11) got condition
09:36:43 DISPATCHER: Trying to submit another job.
09:36:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:43 HBMASTER: Trying to run another job!
09:36:43 job_callback for (8, 0, 11) finished
09:36:43 start sampling a new configuration.
09:36:43 best_vector: [2, 0.38354751823086525, 0.8675601548211868, 0.4997074455423908, 0.09927603948693875, 0, 0.7447318293129269, 0.1439566463348123], 0.00013189357807783048, 6586.971403432057, 0.8687792270950027
09:36:43 done sampling a new configuration.
09:36:43 HBMASTER: schedule new run for iteration 8
09:36:43 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
09:36:43 HBMASTER: submitting job (8, 0, 12) to dispatcher
09:36:43 DISPATCHER: trying to submit job (8, 0, 12)
09:36:43 DISPATCHER: trying to notify the job_runner thread.
09:36:43 HBMASTER: job (8, 0, 12) submitted to dispatcher
09:36:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:43 DISPATCHER: Trying to submit another job.
09:36:43 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:36:43 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:36:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:43 WORKER: start processing job (8, 0, 12)
09:36:43 WORKER: args: ()
09:36:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 51, 'last_n_outputs': 44, 'lr': 0.009986536440854885, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.015391888723761082}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:36:49 DISPATCHER: Starting worker discovery
09:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:49 DISPATCHER: Finished worker discovery
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:37:32 WORKER: done with job (8, 0, 12), trying to register it.
09:37:32 WORKER: registered result for job (8, 0, 12) with dispatcher
09:37:32 DISPATCHER: job (8, 0, 12) finished
09:37:32 DISPATCHER: register_result: lock acquired
09:37:32 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:37:32 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 51, 'last_n_outputs': 44, 'lr': 0.009986536440854885, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.015391888723761082}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4755967890203165, 'info': {'data02': 0.4755967890203165, 'config': "{'batch_size': 64, 'hidden_dim': 51, 'last_n_outputs': 44, 'lr': 0.009986536440854885, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.015391888723761082}"}}
exception: None

09:37:32 job_callback for (8, 0, 12) started
09:37:32 DISPATCHER: Trying to submit another job.
09:37:32 job_callback for (8, 0, 12) got condition
09:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:37:32 HBMASTER: Trying to run another job!
09:37:32 job_callback for (8, 0, 12) finished
09:37:32 start sampling a new configuration.
09:37:32 best_vector: [2, 0.6081022340458041, 0.9136420918295132, 0.3135727278805713, 0.09837262730071013, 0, 0.11244461634100833, 0.06124331321207499], 4.959607096549167e-05, 4688.022909757031, 0.23250751692016047
09:37:32 done sampling a new configuration.
09:37:32 HBMASTER: schedule new run for iteration 8
09:37:32 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
09:37:32 HBMASTER: submitting job (8, 0, 13) to dispatcher
09:37:32 DISPATCHER: trying to submit job (8, 0, 13)
09:37:32 DISPATCHER: trying to notify the job_runner thread.
09:37:32 HBMASTER: job (8, 0, 13) submitted to dispatcher
09:37:32 DISPATCHER: Trying to submit another job.
09:37:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:37:32 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:37:32 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:37:32 WORKER: start processing job (8, 0, 13)
09:37:32 WORKER: args: ()
09:37:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 46, 'lr': 0.004237848781231129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.012013772054471773}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:37:49 DISPATCHER: Starting worker discovery
09:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:49 DISPATCHER: Finished worker discovery
09:38:20 WORKER: done with job (8, 0, 13), trying to register it.
09:38:20 WORKER: registered result for job (8, 0, 13) with dispatcher
09:38:20 DISPATCHER: job (8, 0, 13) finished
09:38:20 DISPATCHER: register_result: lock acquired
09:38:20 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:38:20 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 46, 'lr': 0.004237848781231129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.012013772054471773}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.533370441088325, 'info': {'data02': 0.533370441088325, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 46, 'lr': 0.004237848781231129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.012013772054471773}"}}
exception: None

09:38:20 job_callback for (8, 0, 13) started
09:38:20 DISPATCHER: Trying to submit another job.
09:38:20 job_callback for (8, 0, 13) got condition
09:38:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:20 HBMASTER: Trying to run another job!
09:38:20 job_callback for (8, 0, 13) finished
09:38:20 start sampling a new configuration.
09:38:20 done sampling a new configuration.
09:38:20 HBMASTER: schedule new run for iteration 8
09:38:20 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
09:38:20 HBMASTER: submitting job (8, 0, 14) to dispatcher
09:38:20 DISPATCHER: trying to submit job (8, 0, 14)
09:38:20 DISPATCHER: trying to notify the job_runner thread.
09:38:20 HBMASTER: job (8, 0, 14) submitted to dispatcher
09:38:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:20 DISPATCHER: Trying to submit another job.
09:38:20 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:38:20 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:38:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:20 WORKER: start processing job (8, 0, 14)
09:38:20 WORKER: args: ()
09:38:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.08025991692134732, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.11619882688958884}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:38:49 DISPATCHER: Starting worker discovery
09:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:49 DISPATCHER: Finished worker discovery
09:39:08 WORKER: done with job (8, 0, 14), trying to register it.
09:39:08 WORKER: registered result for job (8, 0, 14) with dispatcher
09:39:08 DISPATCHER: job (8, 0, 14) finished
09:39:08 DISPATCHER: register_result: lock acquired
09:39:08 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:39:08 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.08025991692134732, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.11619882688958884}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.08025991692134732, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.11619882688958884}"}}
exception: None

09:39:08 job_callback for (8, 0, 14) started
09:39:08 DISPATCHER: Trying to submit another job.
09:39:08 job_callback for (8, 0, 14) got condition
09:39:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:08 HBMASTER: Trying to run another job!
09:39:08 job_callback for (8, 0, 14) finished
09:39:08 start sampling a new configuration.
09:39:08 best_vector: [1, 0.34590072831802743, 0.9475719715369518, 0.42656850781160505, 0.10058358485998725, 0, 0.5041488531960179, 0.1212610676782395], 3.949354053033246e-05, 13638.623692814559, 0.5386375375901243
09:39:08 done sampling a new configuration.
09:39:08 HBMASTER: schedule new run for iteration 8
09:39:08 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
09:39:08 HBMASTER: submitting job (8, 0, 15) to dispatcher
09:39:08 DISPATCHER: trying to submit job (8, 0, 15)
09:39:08 DISPATCHER: trying to notify the job_runner thread.
09:39:08 HBMASTER: job (8, 0, 15) submitted to dispatcher
09:39:08 DISPATCHER: Trying to submit another job.
09:39:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:08 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:39:08 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:39:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:08 WORKER: start processing job (8, 0, 15)
09:39:08 WORKER: args: ()
09:39:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.007130779637030385, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.01438017881167298}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:39:49 DISPATCHER: Starting worker discovery
09:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:49 DISPATCHER: Finished worker discovery
09:39:56 WORKER: done with job (8, 0, 15), trying to register it.
09:39:56 WORKER: registered result for job (8, 0, 15) with dispatcher
09:39:56 DISPATCHER: job (8, 0, 15) finished
09:39:56 DISPATCHER: register_result: lock acquired
09:39:56 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:39:56 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.007130779637030385, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.01438017881167298}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.605166219719297, 'info': {'data02': 0.605166219719297, 'config': "{'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.007130779637030385, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.01438017881167298}"}}
exception: None

09:39:56 job_callback for (8, 0, 15) started
09:39:56 DISPATCHER: Trying to submit another job.
09:39:56 job_callback for (8, 0, 15) got condition
09:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:56 HBMASTER: Trying to run another job!
09:39:56 job_callback for (8, 0, 15) finished
09:39:56 start sampling a new configuration.
09:39:56 done sampling a new configuration.
09:39:56 HBMASTER: schedule new run for iteration 8
09:39:56 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
09:39:57 HBMASTER: submitting job (8, 0, 16) to dispatcher
09:39:57 DISPATCHER: trying to submit job (8, 0, 16)
09:39:57 DISPATCHER: trying to notify the job_runner thread.
09:39:57 HBMASTER: job (8, 0, 16) submitted to dispatcher
09:39:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:57 DISPATCHER: Trying to submit another job.
09:39:57 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:39:57 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:39:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:57 WORKER: start processing job (8, 0, 16)
09:39:57 WORKER: args: ()
09:39:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.0017709189923527213, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.061117621251226203}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:40:45 WORKER: done with job (8, 0, 16), trying to register it.
09:40:45 WORKER: registered result for job (8, 0, 16) with dispatcher
09:40:45 DISPATCHER: job (8, 0, 16) finished
09:40:45 DISPATCHER: register_result: lock acquired
09:40:45 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:40:45 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.0017709189923527213, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.061117621251226203}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2946132963726222, 'info': {'data02': 0.2946132963726222, 'config': "{'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.0017709189923527213, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.061117621251226203}"}}
exception: None

09:40:45 job_callback for (8, 0, 16) started
09:40:45 DISPATCHER: Trying to submit another job.
09:40:45 job_callback for (8, 0, 16) got condition
09:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:45 HBMASTER: Trying to run another job!
09:40:45 job_callback for (8, 0, 16) finished
09:40:45 start sampling a new configuration.
09:40:45 best_vector: [1, 0.8630327432328883, 0.8239034686161176, 0.27153472216978947, 0.10190346062140561, 0, 0.609962097356686, 0.008957186760355975], 2.5125494869873186e-05, 9168.582557576468, 0.23036517401439632
09:40:45 done sampling a new configuration.
09:40:45 HBMASTER: schedule new run for iteration 8
09:40:45 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
09:40:45 HBMASTER: submitting job (8, 0, 17) to dispatcher
09:40:45 DISPATCHER: trying to submit job (8, 0, 17)
09:40:45 DISPATCHER: trying to notify the job_runner thread.
09:40:45 HBMASTER: job (8, 0, 17) submitted to dispatcher
09:40:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:45 DISPATCHER: Trying to submit another job.
09:40:45 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:40:45 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:45 WORKER: start processing job (8, 0, 17)
09:40:45 WORKER: args: ()
09:40:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0034919614800286154, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.010271965891928804}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:40:49 DISPATCHER: Starting worker discovery
09:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:49 DISPATCHER: Finished worker discovery
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:41:33 WORKER: done with job (8, 0, 17), trying to register it.
09:41:33 WORKER: registered result for job (8, 0, 17) with dispatcher
09:41:33 DISPATCHER: job (8, 0, 17) finished
09:41:33 DISPATCHER: register_result: lock acquired
09:41:33 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:41:33 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0034919614800286154, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.010271965891928804}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5241846524104111, 'info': {'data02': 0.5241846524104111, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.0034919614800286154, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.010271965891928804}"}}
exception: None

09:41:33 job_callback for (8, 0, 17) started
09:41:33 job_callback for (8, 0, 17) got condition
09:41:33 DISPATCHER: Trying to submit another job.
09:41:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:33 HBMASTER: Trying to run another job!
09:41:33 job_callback for (8, 0, 17) finished
09:41:33 start sampling a new configuration.
09:41:34 best_vector: [2, 0.4413723603523074, 0.9636067356953713, 0.42471153031802455, 0.10024808534284542, 0, 0.5204326183365882, 0.0674230621795315], 8.86666646147126e-06, 77609.74693539971, 0.6881397402353806
09:41:34 done sampling a new configuration.
09:41:34 HBMASTER: schedule new run for iteration 8
09:41:34 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
09:41:34 HBMASTER: submitting job (8, 0, 18) to dispatcher
09:41:34 DISPATCHER: trying to submit job (8, 0, 18)
09:41:34 DISPATCHER: trying to notify the job_runner thread.
09:41:34 HBMASTER: job (8, 0, 18) submitted to dispatcher
09:41:34 DISPATCHER: Trying to submit another job.
09:41:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:34 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:41:34 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:41:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:34 WORKER: start processing job (8, 0, 18)
09:41:34 WORKER: args: ()
09:41:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 49, 'lr': 0.007070059368152524, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.012238252978066782}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:41:49 DISPATCHER: Starting worker discovery
09:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:49 DISPATCHER: Finished worker discovery
09:42:22 WORKER: done with job (8, 0, 18), trying to register it.
09:42:22 WORKER: registered result for job (8, 0, 18) with dispatcher
09:42:22 DISPATCHER: job (8, 0, 18) finished
09:42:22 DISPATCHER: register_result: lock acquired
09:42:22 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:42:22 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 49, 'lr': 0.007070059368152524, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.012238252978066782}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6561575492031536, 'info': {'data02': 0.6561575492031536, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 49, 'lr': 0.007070059368152524, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.012238252978066782}"}}
exception: None

09:42:22 job_callback for (8, 0, 18) started
09:42:22 job_callback for (8, 0, 18) got condition
09:42:22 DISPATCHER: Trying to submit another job.
09:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:42:22 HBMASTER: Trying to run another job!
09:42:22 job_callback for (8, 0, 18) finished
09:42:22 start sampling a new configuration.
09:42:22 done sampling a new configuration.
09:42:22 HBMASTER: schedule new run for iteration 8
09:42:22 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
09:42:22 HBMASTER: submitting job (8, 0, 19) to dispatcher
09:42:22 DISPATCHER: trying to submit job (8, 0, 19)
09:42:22 DISPATCHER: trying to notify the job_runner thread.
09:42:22 HBMASTER: job (8, 0, 19) submitted to dispatcher
09:42:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:42:22 DISPATCHER: Trying to submit another job.
09:42:22 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:42:22 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:42:22 WORKER: start processing job (8, 0, 19)
09:42:22 WORKER: args: ()
09:42:22 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 21, 'lr': 0.003940421561475285, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.15695597585126841}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:42:49 DISPATCHER: Starting worker discovery
09:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:49 DISPATCHER: Finished worker discovery
09:43:10 WORKER: done with job (8, 0, 19), trying to register it.
09:43:10 WORKER: registered result for job (8, 0, 19) with dispatcher
09:43:10 DISPATCHER: job (8, 0, 19) finished
09:43:10 DISPATCHER: register_result: lock acquired
09:43:10 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:43:10 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 21, 'lr': 0.003940421561475285, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.15695597585126841}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06518850494177891, 'info': {'data02': 0.06518850494177891, 'config': "{'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 21, 'lr': 0.003940421561475285, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.15695597585126841}"}}
exception: None

09:43:10 job_callback for (8, 0, 19) started
09:43:10 DISPATCHER: Trying to submit another job.
09:43:10 job_callback for (8, 0, 19) got condition
09:43:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:10 HBMASTER: Trying to run another job!
09:43:10 job_callback for (8, 0, 19) finished
09:43:10 start sampling a new configuration.
09:43:10 done sampling a new configuration.
09:43:10 HBMASTER: schedule new run for iteration 8
09:43:10 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
09:43:10 HBMASTER: submitting job (8, 0, 20) to dispatcher
09:43:10 DISPATCHER: trying to submit job (8, 0, 20)
09:43:10 DISPATCHER: trying to notify the job_runner thread.
09:43:10 HBMASTER: job (8, 0, 20) submitted to dispatcher
09:43:10 DISPATCHER: Trying to submit another job.
09:43:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:10 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:43:10 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:43:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:10 WORKER: start processing job (8, 0, 20)
09:43:10 WORKER: args: ()
09:43:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 24, 'lr': 0.0013996618855704566, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.16838194876345025}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:43:49 DISPATCHER: Starting worker discovery
09:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:49 DISPATCHER: Finished worker discovery
09:43:58 WORKER: done with job (8, 0, 20), trying to register it.
09:43:58 WORKER: registered result for job (8, 0, 20) with dispatcher
09:43:58 DISPATCHER: job (8, 0, 20) finished
09:43:58 DISPATCHER: register_result: lock acquired
09:43:58 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:43:58 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 24, 'lr': 0.0013996618855704566, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.16838194876345025}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.06247813001701579, 'info': {'data02': -0.06247813001701579, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 24, 'lr': 0.0013996618855704566, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.16838194876345025}"}}
exception: None

09:43:58 job_callback for (8, 0, 20) started
09:43:58 job_callback for (8, 0, 20) got condition
09:43:58 DISPATCHER: Trying to submit another job.
09:43:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:58 HBMASTER: Trying to run another job!
09:43:58 job_callback for (8, 0, 20) finished
09:43:58 start sampling a new configuration.
09:43:58 best_vector: [1, 0.8702100587892415, 0.9963113158878342, 0.3819271837599705, 0.09911411266216948, 0, 0.6996443299670873, 0.04130465781511101], 3.1343783929458086e-05, 5532.122503539327, 0.1733976524222294
09:43:58 done sampling a new configuration.
09:43:58 HBMASTER: schedule new run for iteration 8
09:43:58 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
09:43:58 HBMASTER: submitting job (8, 0, 21) to dispatcher
09:43:58 DISPATCHER: trying to submit job (8, 0, 21)
09:43:58 DISPATCHER: trying to notify the job_runner thread.
09:43:58 HBMASTER: job (8, 0, 21) submitted to dispatcher
09:43:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:58 DISPATCHER: Trying to submit another job.
09:43:58 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:43:58 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:43:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:58 WORKER: start processing job (8, 0, 21)
09:43:58 WORKER: args: ()
09:43:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.005805697017542118, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01131718978174067}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:44:46 WORKER: done with job (8, 0, 21), trying to register it.
09:44:46 WORKER: registered result for job (8, 0, 21) with dispatcher
09:44:46 DISPATCHER: job (8, 0, 21) finished
09:44:46 DISPATCHER: register_result: lock acquired
09:44:46 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:44:46 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.005805697017542118, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01131718978174067}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5760407425189482, 'info': {'data02': 0.5760407425189482, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.005805697017542118, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01131718978174067}"}}
exception: None

09:44:46 job_callback for (8, 0, 21) started
09:44:46 job_callback for (8, 0, 21) got condition
09:44:46 DISPATCHER: Trying to submit another job.
09:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:44:46 HBMASTER: Trying to run another job!
09:44:46 job_callback for (8, 0, 21) finished
09:44:46 start sampling a new configuration.
09:44:46 best_vector: [1, 0.8535723093188023, 0.6942053491312146, 0.30820707371259465, 0.09802324900820297, 0, 0.8335776703777538, 0.05369671956449909], 0.00012134420315475017, 1271.77886590993, 0.1543229930728923
09:44:46 done sampling a new configuration.
09:44:46 HBMASTER: schedule new run for iteration 8
09:44:46 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
09:44:46 HBMASTER: submitting job (8, 0, 22) to dispatcher
09:44:46 DISPATCHER: trying to submit job (8, 0, 22)
09:44:46 DISPATCHER: trying to notify the job_runner thread.
09:44:46 HBMASTER: job (8, 0, 22) submitted to dispatcher
09:44:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:44:46 DISPATCHER: Trying to submit another job.
09:44:46 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:44:46 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:44:46 WORKER: start processing job (8, 0, 22)
09:44:46 WORKER: args: ()
09:44:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 35, 'lr': 0.004134415759559869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.011745216939981758}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:44:49 DISPATCHER: Starting worker discovery
09:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:49 DISPATCHER: Finished worker discovery
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:45:35 WORKER: done with job (8, 0, 22), trying to register it.
09:45:35 WORKER: registered result for job (8, 0, 22) with dispatcher
09:45:35 DISPATCHER: job (8, 0, 22) finished
09:45:35 DISPATCHER: register_result: lock acquired
09:45:35 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:45:35 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 35, 'lr': 0.004134415759559869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.011745216939981758}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38735660484303885, 'info': {'data02': 0.38735660484303885, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 35, 'lr': 0.004134415759559869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.011745216939981758}"}}
exception: None

09:45:35 job_callback for (8, 0, 22) started
09:45:35 job_callback for (8, 0, 22) got condition
09:45:35 DISPATCHER: Trying to submit another job.
09:45:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:35 HBMASTER: Trying to run another job!
09:45:35 job_callback for (8, 0, 22) finished
09:45:35 start sampling a new configuration.
09:45:35 best_vector: [2, 0.7366697040341228, 0.8194870257920519, 0.22027248252241474, 0.10067893834088948, 0, 0.6810443171616766, 0.013144880064857284], 1.4187299988821017e-05, 18853.044477408956, 0.2674737977035862
09:45:35 done sampling a new configuration.
09:45:35 HBMASTER: schedule new run for iteration 8
09:45:35 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
09:45:35 HBMASTER: submitting job (8, 0, 23) to dispatcher
09:45:35 DISPATCHER: trying to submit job (8, 0, 23)
09:45:35 DISPATCHER: trying to notify the job_runner thread.
09:45:35 HBMASTER: job (8, 0, 23) submitted to dispatcher
09:45:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:35 DISPATCHER: Trying to submit another job.
09:45:35 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:45:35 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:45:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:35 WORKER: start processing job (8, 0, 23)
09:45:35 WORKER: args: ()
09:45:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.002757686957006996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010401641543743302}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:45:49 DISPATCHER: Starting worker discovery
09:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:49 DISPATCHER: Finished worker discovery
09:46:23 WORKER: done with job (8, 0, 23), trying to register it.
09:46:23 WORKER: registered result for job (8, 0, 23) with dispatcher
09:46:23 DISPATCHER: job (8, 0, 23) finished
09:46:23 DISPATCHER: register_result: lock acquired
09:46:23 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:46:23 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.002757686957006996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010401641543743302}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6550058525786796, 'info': {'data02': 0.6550058525786796, 'config': "{'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.002757686957006996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010401641543743302}"}}
exception: None

09:46:23 job_callback for (8, 0, 23) started
09:46:23 job_callback for (8, 0, 23) got condition
09:46:23 DISPATCHER: Trying to submit another job.
09:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:46:23 HBMASTER: Trying to run another job!
09:46:23 job_callback for (8, 0, 23) finished
09:46:23 start sampling a new configuration.
09:46:23 best_vector: [2, 0.35687149927256906, 0.9233156016417935, 0.4145814906206893, 0.1013634945037208, 0, 0.5804327970886504, 0.0618490392817445], 3.855277273417184e-05, 20947.309169089214, 0.8075768497883306
09:46:23 done sampling a new configuration.
09:46:23 HBMASTER: schedule new run for iteration 8
09:46:23 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
09:46:23 HBMASTER: submitting job (8, 0, 24) to dispatcher
09:46:23 DISPATCHER: trying to submit job (8, 0, 24)
09:46:23 DISPATCHER: trying to notify the job_runner thread.
09:46:23 HBMASTER: job (8, 0, 24) submitted to dispatcher
09:46:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:46:23 DISPATCHER: Trying to submit another job.
09:46:23 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:46:23 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:46:23 WORKER: start processing job (8, 0, 24)
09:46:23 WORKER: args: ()
09:46:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:46:49 DISPATCHER: Starting worker discovery
09:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:49 DISPATCHER: Finished worker discovery
09:47:11 WORKER: done with job (8, 0, 24), trying to register it.
09:47:11 WORKER: registered result for job (8, 0, 24) with dispatcher
09:47:11 DISPATCHER: job (8, 0, 24) finished
09:47:11 DISPATCHER: register_result: lock acquired
09:47:11 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:47:11 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5854616403804054, 'info': {'data02': 0.5854616403804054, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}"}}
exception: None

09:47:11 job_callback for (8, 0, 24) started
09:47:11 job_callback for (8, 0, 24) got condition
09:47:11 DISPATCHER: Trying to submit another job.
09:47:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:11 HBMASTER: Trying to run another job!
09:47:11 job_callback for (8, 0, 24) finished
09:47:11 start sampling a new configuration.
09:47:11 done sampling a new configuration.
09:47:11 HBMASTER: schedule new run for iteration 8
09:47:11 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
09:47:11 HBMASTER: submitting job (8, 0, 25) to dispatcher
09:47:11 DISPATCHER: trying to submit job (8, 0, 25)
09:47:11 DISPATCHER: trying to notify the job_runner thread.
09:47:11 HBMASTER: job (8, 0, 25) submitted to dispatcher
09:47:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:11 DISPATCHER: Trying to submit another job.
09:47:11 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:47:11 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:47:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:11 WORKER: start processing job (8, 0, 25)
09:47:11 WORKER: args: ()
09:47:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 43, 'lr': 0.001271927670867638, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.06654663905191163}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:47:49 DISPATCHER: Starting worker discovery
09:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:49 DISPATCHER: Finished worker discovery
09:47:59 WORKER: done with job (8, 0, 25), trying to register it.
09:47:59 WORKER: registered result for job (8, 0, 25) with dispatcher
09:47:59 DISPATCHER: job (8, 0, 25) finished
09:47:59 DISPATCHER: register_result: lock acquired
09:47:59 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:47:59 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 43, 'lr': 0.001271927670867638, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.06654663905191163}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.012537129642951412, 'info': {'data02': -0.012537129642951412, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 43, 'lr': 0.001271927670867638, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.06654663905191163}"}}
exception: None

09:47:59 job_callback for (8, 0, 25) started
09:47:59 DISPATCHER: Trying to submit another job.
09:47:59 job_callback for (8, 0, 25) got condition
09:47:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:59 HBMASTER: Trying to run another job!
09:47:59 job_callback for (8, 0, 25) finished
09:47:59 start sampling a new configuration.
09:47:59 done sampling a new configuration.
09:47:59 HBMASTER: schedule new run for iteration 8
09:47:59 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
09:47:59 HBMASTER: submitting job (8, 0, 26) to dispatcher
09:47:59 DISPATCHER: trying to submit job (8, 0, 26)
09:47:59 DISPATCHER: trying to notify the job_runner thread.
09:47:59 HBMASTER: job (8, 0, 26) submitted to dispatcher
09:47:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:59 DISPATCHER: Trying to submit another job.
09:47:59 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:47:59 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:47:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:59 WORKER: start processing job (8, 0, 26)
09:47:59 WORKER: args: ()
09:47:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 35, 'lr': 0.013233883840652503, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.059460001842542035}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:48:47 WORKER: done with job (8, 0, 26), trying to register it.
09:48:47 WORKER: registered result for job (8, 0, 26) with dispatcher
09:48:47 DISPATCHER: job (8, 0, 26) finished
09:48:47 DISPATCHER: register_result: lock acquired
09:48:47 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:48:47 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 35, 'lr': 0.013233883840652503, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.059460001842542035}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17713660315723445, 'info': {'data02': 0.17713660315723445, 'config': "{'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 35, 'lr': 0.013233883840652503, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.059460001842542035}"}}
exception: None

09:48:47 job_callback for (8, 0, 26) started
09:48:47 job_callback for (8, 0, 26) got condition
09:48:47 DISPATCHER: Trying to submit another job.
09:48:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:47 HBMASTER: Trying to run another job!
09:48:47 job_callback for (8, 0, 26) finished
09:48:47 ITERATION: Advancing config (8, 0, 3) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
09:48:47 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
09:48:47 HBMASTER: schedule new run for iteration 8
09:48:47 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
09:48:47 HBMASTER: submitting job (8, 0, 3) to dispatcher
09:48:47 DISPATCHER: trying to submit job (8, 0, 3)
09:48:47 DISPATCHER: trying to notify the job_runner thread.
09:48:47 HBMASTER: job (8, 0, 3) submitted to dispatcher
09:48:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:47 DISPATCHER: Trying to submit another job.
09:48:47 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:48:47 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:48:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:47 WORKER: start processing job (8, 0, 3)
09:48:47 WORKER: args: ()
09:48:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 47, 'lr': 0.007088451863983947, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01165483764399743}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:48:49 DISPATCHER: Starting worker discovery
09:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:49 DISPATCHER: Finished worker discovery
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:49:49 DISPATCHER: Starting worker discovery
09:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:49 DISPATCHER: Finished worker discovery
09:50:49 DISPATCHER: Starting worker discovery
09:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:49 DISPATCHER: Finished worker discovery
09:51:05 WORKER: done with job (8, 0, 3), trying to register it.
09:51:05 WORKER: registered result for job (8, 0, 3) with dispatcher
09:51:05 DISPATCHER: job (8, 0, 3) finished
09:51:05 DISPATCHER: register_result: lock acquired
09:51:05 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:51:05 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 47, 'lr': 0.007088451863983947, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01165483764399743}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.565665244232596, 'info': {'data02': 0.565665244232596, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 47, 'lr': 0.007088451863983947, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01165483764399743}"}}
exception: None

09:51:05 job_callback for (8, 0, 3) started
09:51:05 job_callback for (8, 0, 3) got condition
09:51:05 DISPATCHER: Trying to submit another job.
09:51:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:05 HBMASTER: Trying to run another job!
09:51:05 job_callback for (8, 0, 3) finished
09:51:05 HBMASTER: schedule new run for iteration 8
09:51:05 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
09:51:05 HBMASTER: submitting job (8, 0, 5) to dispatcher
09:51:05 DISPATCHER: trying to submit job (8, 0, 5)
09:51:05 DISPATCHER: trying to notify the job_runner thread.
09:51:05 HBMASTER: job (8, 0, 5) submitted to dispatcher
09:51:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:05 DISPATCHER: Trying to submit another job.
09:51:05 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:51:05 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:51:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:05 WORKER: start processing job (8, 0, 5)
09:51:05 WORKER: args: ()
09:51:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:51:49 DISPATCHER: Starting worker discovery
09:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:49 DISPATCHER: Finished worker discovery
09:52:49 DISPATCHER: Starting worker discovery
09:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:49 DISPATCHER: Finished worker discovery
09:53:22 WORKER: done with job (8, 0, 5), trying to register it.
09:53:22 WORKER: registered result for job (8, 0, 5) with dispatcher
09:53:22 DISPATCHER: job (8, 0, 5) finished
09:53:22 DISPATCHER: register_result: lock acquired
09:53:22 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:53:22 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5782496587663353, 'info': {'data02': 0.5782496587663353, 'config': "{'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}"}}
exception: None

09:53:22 job_callback for (8, 0, 5) started
09:53:22 job_callback for (8, 0, 5) got condition
09:53:22 DISPATCHER: Trying to submit another job.
09:53:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:53:22 HBMASTER: Trying to run another job!
09:53:22 job_callback for (8, 0, 5) finished
09:53:22 HBMASTER: schedule new run for iteration 8
09:53:22 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
09:53:22 HBMASTER: submitting job (8, 0, 6) to dispatcher
09:53:22 DISPATCHER: trying to submit job (8, 0, 6)
09:53:22 DISPATCHER: trying to notify the job_runner thread.
09:53:22 HBMASTER: job (8, 0, 6) submitted to dispatcher
09:53:22 DISPATCHER: Trying to submit another job.
09:53:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:53:22 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:53:22 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:53:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:53:22 WORKER: start processing job (8, 0, 6)
09:53:22 WORKER: args: ()
09:53:22 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 38, 'lr': 0.0043656909572972104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011266862013757891}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:53:49 DISPATCHER: Starting worker discovery
09:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:49 DISPATCHER: Finished worker discovery
09:54:49 DISPATCHER: Starting worker discovery
09:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:49 DISPATCHER: Finished worker discovery
09:55:39 WORKER: done with job (8, 0, 6), trying to register it.
09:55:39 WORKER: registered result for job (8, 0, 6) with dispatcher
09:55:39 DISPATCHER: job (8, 0, 6) finished
09:55:39 DISPATCHER: register_result: lock acquired
09:55:39 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:55:39 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 38, 'lr': 0.0043656909572972104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011266862013757891}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4223160823549625, 'info': {'data02': 0.4223160823549625, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 38, 'lr': 0.0043656909572972104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011266862013757891}"}}
exception: None

09:55:39 job_callback for (8, 0, 6) started
09:55:39 DISPATCHER: Trying to submit another job.
09:55:39 job_callback for (8, 0, 6) got condition
09:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:39 HBMASTER: Trying to run another job!
09:55:39 job_callback for (8, 0, 6) finished
09:55:39 HBMASTER: schedule new run for iteration 8
09:55:39 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
09:55:39 HBMASTER: submitting job (8, 0, 8) to dispatcher
09:55:39 DISPATCHER: trying to submit job (8, 0, 8)
09:55:39 DISPATCHER: trying to notify the job_runner thread.
09:55:39 HBMASTER: job (8, 0, 8) submitted to dispatcher
09:55:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:39 DISPATCHER: Trying to submit another job.
09:55:39 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:55:39 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:39 WORKER: start processing job (8, 0, 8)
09:55:39 WORKER: args: ()
09:55:39 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:55:49 DISPATCHER: Starting worker discovery
09:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:49 DISPATCHER: Finished worker discovery
09:56:49 DISPATCHER: Starting worker discovery
09:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:49 DISPATCHER: Finished worker discovery
09:57:49 DISPATCHER: Starting worker discovery
09:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:49 DISPATCHER: Finished worker discovery
09:57:56 WORKER: done with job (8, 0, 8), trying to register it.
09:57:56 WORKER: registered result for job (8, 0, 8) with dispatcher
09:57:56 DISPATCHER: job (8, 0, 8) finished
09:57:56 DISPATCHER: register_result: lock acquired
09:57:56 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
09:57:56 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6221211221651565, 'info': {'data02': 0.6221211221651565, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}"}}
exception: None

09:57:56 job_callback for (8, 0, 8) started
09:57:56 job_callback for (8, 0, 8) got condition
09:57:56 DISPATCHER: Trying to submit another job.
09:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:57:56 HBMASTER: Trying to run another job!
09:57:56 job_callback for (8, 0, 8) finished
09:57:56 HBMASTER: schedule new run for iteration 8
09:57:56 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
09:57:56 HBMASTER: submitting job (8, 0, 15) to dispatcher
09:57:56 DISPATCHER: trying to submit job (8, 0, 15)
09:57:56 DISPATCHER: trying to notify the job_runner thread.
09:57:56 HBMASTER: job (8, 0, 15) submitted to dispatcher
09:57:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:57:56 DISPATCHER: Trying to submit another job.
09:57:56 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
09:57:56 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
09:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:57:56 WORKER: start processing job (8, 0, 15)
09:57:56 WORKER: args: ()
09:57:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.007130779637030385, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.01438017881167298}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:58:49 DISPATCHER: Starting worker discovery
09:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:49 DISPATCHER: Finished worker discovery
09:59:49 DISPATCHER: Starting worker discovery
09:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:49 DISPATCHER: Finished worker discovery
10:00:13 WORKER: done with job (8, 0, 15), trying to register it.
10:00:13 WORKER: registered result for job (8, 0, 15) with dispatcher
10:00:13 DISPATCHER: job (8, 0, 15) finished
10:00:13 DISPATCHER: register_result: lock acquired
10:00:13 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:00:13 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.007130779637030385, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.01438017881167298}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5751125696954106, 'info': {'data02': 0.5751125696954106, 'config': "{'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.007130779637030385, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.01438017881167298}"}}
exception: None

10:00:13 job_callback for (8, 0, 15) started
10:00:13 DISPATCHER: Trying to submit another job.
10:00:13 job_callback for (8, 0, 15) got condition
10:00:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:00:13 HBMASTER: Trying to run another job!
10:00:13 job_callback for (8, 0, 15) finished
10:00:13 HBMASTER: schedule new run for iteration 8
10:00:13 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
10:00:13 HBMASTER: submitting job (8, 0, 18) to dispatcher
10:00:13 DISPATCHER: trying to submit job (8, 0, 18)
10:00:13 DISPATCHER: trying to notify the job_runner thread.
10:00:13 HBMASTER: job (8, 0, 18) submitted to dispatcher
10:00:13 DISPATCHER: Trying to submit another job.
10:00:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:00:13 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:00:13 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:00:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:00:13 WORKER: start processing job (8, 0, 18)
10:00:13 WORKER: args: ()
10:00:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 49, 'lr': 0.007070059368152524, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.012238252978066782}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:00:49 DISPATCHER: Starting worker discovery
10:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:49 DISPATCHER: Finished worker discovery
10:01:49 DISPATCHER: Starting worker discovery
10:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:49 DISPATCHER: Finished worker discovery
10:02:30 WORKER: done with job (8, 0, 18), trying to register it.
10:02:30 WORKER: registered result for job (8, 0, 18) with dispatcher
10:02:30 DISPATCHER: job (8, 0, 18) finished
10:02:30 DISPATCHER: register_result: lock acquired
10:02:30 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:02:30 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 49, 'lr': 0.007070059368152524, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.012238252978066782}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42342056988796895, 'info': {'data02': 0.42342056988796895, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 49, 'lr': 0.007070059368152524, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.012238252978066782}"}}
exception: None

10:02:30 job_callback for (8, 0, 18) started
10:02:30 DISPATCHER: Trying to submit another job.
10:02:30 job_callback for (8, 0, 18) got condition
10:02:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:30 HBMASTER: Trying to run another job!
10:02:30 job_callback for (8, 0, 18) finished
10:02:30 HBMASTER: schedule new run for iteration 8
10:02:30 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
10:02:30 HBMASTER: submitting job (8, 0, 21) to dispatcher
10:02:30 DISPATCHER: trying to submit job (8, 0, 21)
10:02:30 DISPATCHER: trying to notify the job_runner thread.
10:02:30 HBMASTER: job (8, 0, 21) submitted to dispatcher
10:02:30 DISPATCHER: Trying to submit another job.
10:02:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:30 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:02:30 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:02:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:30 WORKER: start processing job (8, 0, 21)
10:02:30 WORKER: args: ()
10:02:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.005805697017542118, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01131718978174067}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:02:49 DISPATCHER: Starting worker discovery
10:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:49 DISPATCHER: Finished worker discovery
10:03:49 DISPATCHER: Starting worker discovery
10:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:49 DISPATCHER: Finished worker discovery
10:04:47 WORKER: done with job (8, 0, 21), trying to register it.
10:04:47 WORKER: registered result for job (8, 0, 21) with dispatcher
10:04:47 DISPATCHER: job (8, 0, 21) finished
10:04:47 DISPATCHER: register_result: lock acquired
10:04:47 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:04:47 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.005805697017542118, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01131718978174067}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4538357905316926, 'info': {'data02': 0.4538357905316926, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.005805697017542118, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01131718978174067}"}}
exception: None

10:04:47 job_callback for (8, 0, 21) started
10:04:47 DISPATCHER: Trying to submit another job.
10:04:47 job_callback for (8, 0, 21) got condition
10:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:04:47 HBMASTER: Trying to run another job!
10:04:47 job_callback for (8, 0, 21) finished
10:04:47 HBMASTER: schedule new run for iteration 8
10:04:47 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
10:04:47 HBMASTER: submitting job (8, 0, 23) to dispatcher
10:04:47 DISPATCHER: trying to submit job (8, 0, 23)
10:04:47 DISPATCHER: trying to notify the job_runner thread.
10:04:47 HBMASTER: job (8, 0, 23) submitted to dispatcher
10:04:47 DISPATCHER: Trying to submit another job.
10:04:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:04:47 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:04:47 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:04:47 WORKER: start processing job (8, 0, 23)
10:04:47 WORKER: args: ()
10:04:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.002757686957006996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010401641543743302}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:04:49 DISPATCHER: Starting worker discovery
10:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:49 DISPATCHER: Finished worker discovery
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:05:49 DISPATCHER: Starting worker discovery
10:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:49 DISPATCHER: Finished worker discovery
10:06:49 DISPATCHER: Starting worker discovery
10:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:49 DISPATCHER: Finished worker discovery
10:07:04 WORKER: done with job (8, 0, 23), trying to register it.
10:07:04 WORKER: registered result for job (8, 0, 23) with dispatcher
10:07:04 DISPATCHER: job (8, 0, 23) finished
10:07:04 DISPATCHER: register_result: lock acquired
10:07:04 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:07:04 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.002757686957006996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010401641543743302}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5470878846966134, 'info': {'data02': 0.5470878846966134, 'config': "{'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.002757686957006996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.010401641543743302}"}}
exception: None

10:07:04 job_callback for (8, 0, 23) started
10:07:04 DISPATCHER: Trying to submit another job.
10:07:04 job_callback for (8, 0, 23) got condition
10:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:07:04 HBMASTER: Trying to run another job!
10:07:04 job_callback for (8, 0, 23) finished
10:07:04 HBMASTER: schedule new run for iteration 8
10:07:04 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
10:07:04 HBMASTER: submitting job (8, 0, 24) to dispatcher
10:07:04 DISPATCHER: trying to submit job (8, 0, 24)
10:07:04 DISPATCHER: trying to notify the job_runner thread.
10:07:04 HBMASTER: job (8, 0, 24) submitted to dispatcher
10:07:04 DISPATCHER: Trying to submit another job.
10:07:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:07:04 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:07:04 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:07:04 WORKER: start processing job (8, 0, 24)
10:07:04 WORKER: args: ()
10:07:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:07:49 DISPATCHER: Starting worker discovery
10:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:49 DISPATCHER: Finished worker discovery
10:08:49 DISPATCHER: Starting worker discovery
10:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:49 DISPATCHER: Finished worker discovery
10:09:21 WORKER: done with job (8, 0, 24), trying to register it.
10:09:21 WORKER: registered result for job (8, 0, 24) with dispatcher
10:09:21 DISPATCHER: job (8, 0, 24) finished
10:09:21 DISPATCHER: register_result: lock acquired
10:09:21 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:09:21 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5809157435952107, 'info': {'data02': 0.5809157435952107, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}"}}
exception: None

10:09:21 job_callback for (8, 0, 24) started
10:09:21 job_callback for (8, 0, 24) got condition
10:09:21 DISPATCHER: Trying to submit another job.
10:09:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:09:21 HBMASTER: Trying to run another job!
10:09:21 job_callback for (8, 0, 24) finished
10:09:21 ITERATION: Advancing config (8, 0, 5) to next budget 400.000000
10:09:21 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
10:09:21 ITERATION: Advancing config (8, 0, 24) to next budget 400.000000
10:09:21 HBMASTER: schedule new run for iteration 8
10:09:21 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
10:09:21 HBMASTER: submitting job (8, 0, 5) to dispatcher
10:09:21 DISPATCHER: trying to submit job (8, 0, 5)
10:09:21 DISPATCHER: trying to notify the job_runner thread.
10:09:21 HBMASTER: job (8, 0, 5) submitted to dispatcher
10:09:21 DISPATCHER: Trying to submit another job.
10:09:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:09:21 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:09:21 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:09:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:09:21 WORKER: start processing job (8, 0, 5)
10:09:21 WORKER: args: ()
10:09:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:09:49 DISPATCHER: Starting worker discovery
10:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:49 DISPATCHER: Finished worker discovery
10:10:49 DISPATCHER: Starting worker discovery
10:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:49 DISPATCHER: Finished worker discovery
10:11:49 DISPATCHER: Starting worker discovery
10:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:49 DISPATCHER: Finished worker discovery
10:12:49 DISPATCHER: Starting worker discovery
10:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:49 DISPATCHER: Finished worker discovery
10:13:49 DISPATCHER: Starting worker discovery
10:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:49 DISPATCHER: Finished worker discovery
10:14:49 DISPATCHER: Starting worker discovery
10:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:49 DISPATCHER: Finished worker discovery
10:15:49 DISPATCHER: Starting worker discovery
10:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:49 DISPATCHER: Finished worker discovery
10:16:05 WORKER: done with job (8, 0, 5), trying to register it.
10:16:05 WORKER: registered result for job (8, 0, 5) with dispatcher
10:16:05 DISPATCHER: job (8, 0, 5) finished
10:16:05 DISPATCHER: register_result: lock acquired
10:16:05 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:16:05 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5634222350550301, 'info': {'data02': 0.5634222350550301, 'config': "{'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}"}}
exception: None

10:16:05 job_callback for (8, 0, 5) started
10:16:05 DISPATCHER: Trying to submit another job.
10:16:05 job_callback for (8, 0, 5) got condition
10:16:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:16:06 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.663067





10:16:06 HBMASTER: Trying to run another job!
10:16:06 job_callback for (8, 0, 5) finished
10:16:06 HBMASTER: schedule new run for iteration 8
10:16:06 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
10:16:06 HBMASTER: submitting job (8, 0, 8) to dispatcher
10:16:06 DISPATCHER: trying to submit job (8, 0, 8)
10:16:06 DISPATCHER: trying to notify the job_runner thread.
10:16:06 HBMASTER: job (8, 0, 8) submitted to dispatcher
10:16:06 DISPATCHER: Trying to submit another job.
10:16:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:16:06 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:16:06 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:16:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:16:06 WORKER: start processing job (8, 0, 8)
10:16:06 WORKER: args: ()
10:16:06 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:16:49 DISPATCHER: Starting worker discovery
10:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:49 DISPATCHER: Finished worker discovery
10:17:49 DISPATCHER: Starting worker discovery
10:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:49 DISPATCHER: Finished worker discovery
10:18:49 DISPATCHER: Starting worker discovery
10:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:49 DISPATCHER: Finished worker discovery
10:19:49 DISPATCHER: Starting worker discovery
10:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:49 DISPATCHER: Finished worker discovery
10:20:49 DISPATCHER: Starting worker discovery
10:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:49 DISPATCHER: Finished worker discovery
10:21:49 DISPATCHER: Starting worker discovery
10:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:49 DISPATCHER: Finished worker discovery
10:22:49 DISPATCHER: Starting worker discovery
10:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:49 DISPATCHER: Finished worker discovery
10:22:50 WORKER: done with job (8, 0, 8), trying to register it.
10:22:50 WORKER: registered result for job (8, 0, 8) with dispatcher
10:22:50 DISPATCHER: job (8, 0, 8) finished
10:22:50 DISPATCHER: register_result: lock acquired
10:22:50 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:22:50 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5385409052214479, 'info': {'data02': 0.5385409052214479, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.005637348788121892, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.01160090724689189}"}}
exception: None

10:22:50 job_callback for (8, 0, 8) started
10:22:50 job_callback for (8, 0, 8) got condition
10:22:50 DISPATCHER: Trying to submit another job.
10:22:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:50 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.663067





10:22:50 HBMASTER: Trying to run another job!
10:22:50 job_callback for (8, 0, 8) finished
10:22:50 HBMASTER: schedule new run for iteration 8
10:22:50 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
10:22:50 HBMASTER: submitting job (8, 0, 24) to dispatcher
10:22:50 DISPATCHER: trying to submit job (8, 0, 24)
10:22:50 DISPATCHER: trying to notify the job_runner thread.
10:22:50 HBMASTER: job (8, 0, 24) submitted to dispatcher
10:22:50 DISPATCHER: Trying to submit another job.
10:22:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:50 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:22:50 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:22:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:50 WORKER: start processing job (8, 0, 24)
10:22:50 WORKER: args: ()
10:22:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:23:49 DISPATCHER: Starting worker discovery
10:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:49 DISPATCHER: Finished worker discovery
10:24:49 DISPATCHER: Starting worker discovery
10:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:49 DISPATCHER: Finished worker discovery
10:25:49 DISPATCHER: Starting worker discovery
10:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:49 DISPATCHER: Finished worker discovery
10:26:49 DISPATCHER: Starting worker discovery
10:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:49 DISPATCHER: Finished worker discovery
10:27:49 DISPATCHER: Starting worker discovery
10:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:49 DISPATCHER: Finished worker discovery
10:28:49 DISPATCHER: Starting worker discovery
10:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:49 DISPATCHER: Finished worker discovery
10:29:34 WORKER: done with job (8, 0, 24), trying to register it.
10:29:34 WORKER: registered result for job (8, 0, 24) with dispatcher
10:29:34 DISPATCHER: job (8, 0, 24) finished
10:29:34 DISPATCHER: register_result: lock acquired
10:29:34 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:29:34 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.49465068987670696, 'info': {'data02': 0.49465068987670696, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 47, 'lr': 0.0067478121085046625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.012035591953909977}"}}
exception: None

10:29:34 job_callback for (8, 0, 24) started
10:29:34 DISPATCHER: Trying to submit another job.
10:29:34 job_callback for (8, 0, 24) got condition
10:29:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:29:34 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.663067





10:29:34 HBMASTER: Trying to run another job!
10:29:34 job_callback for (8, 0, 24) finished
10:29:34 ITERATION: Advancing config (8, 0, 5) to next budget 1200.000000
10:29:34 HBMASTER: schedule new run for iteration 8
10:29:34 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
10:29:34 HBMASTER: submitting job (8, 0, 5) to dispatcher
10:29:34 DISPATCHER: trying to submit job (8, 0, 5)
10:29:34 DISPATCHER: trying to notify the job_runner thread.
10:29:34 HBMASTER: job (8, 0, 5) submitted to dispatcher
10:29:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:29:34 DISPATCHER: Trying to submit another job.
10:29:34 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:29:34 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:29:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:29:34 WORKER: start processing job (8, 0, 5)
10:29:34 WORKER: args: ()
10:29:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:29:49 DISPATCHER: Starting worker discovery
10:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:49 DISPATCHER: Finished worker discovery
10:30:49 DISPATCHER: Starting worker discovery
10:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:49 DISPATCHER: Finished worker discovery
10:31:49 DISPATCHER: Starting worker discovery
10:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:49 DISPATCHER: Finished worker discovery
10:32:49 DISPATCHER: Starting worker discovery
10:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:49 DISPATCHER: Finished worker discovery
10:33:49 DISPATCHER: Starting worker discovery
10:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:49 DISPATCHER: Finished worker discovery
10:34:49 DISPATCHER: Starting worker discovery
10:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:49 DISPATCHER: Finished worker discovery
10:35:49 DISPATCHER: Starting worker discovery
10:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:49 DISPATCHER: Finished worker discovery
10:36:49 DISPATCHER: Starting worker discovery
10:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:49 DISPATCHER: Finished worker discovery
10:37:49 DISPATCHER: Starting worker discovery
10:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:49 DISPATCHER: Finished worker discovery
10:38:49 DISPATCHER: Starting worker discovery
10:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:49 DISPATCHER: Finished worker discovery
10:39:49 DISPATCHER: Starting worker discovery
10:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:49 DISPATCHER: Finished worker discovery
10:40:49 DISPATCHER: Starting worker discovery
10:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:49 DISPATCHER: Finished worker discovery
10:41:49 DISPATCHER: Starting worker discovery
10:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:49 DISPATCHER: Finished worker discovery
10:42:49 DISPATCHER: Starting worker discovery
10:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:49 DISPATCHER: Finished worker discovery
10:43:49 DISPATCHER: Starting worker discovery
10:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:49 DISPATCHER: Finished worker discovery
10:44:49 DISPATCHER: Starting worker discovery
10:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:49 DISPATCHER: Finished worker discovery
10:45:49 DISPATCHER: Starting worker discovery
10:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:49 DISPATCHER: Finished worker discovery
10:46:49 DISPATCHER: Starting worker discovery
10:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:49 DISPATCHER: Finished worker discovery
10:47:49 DISPATCHER: Starting worker discovery
10:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:49 DISPATCHER: Finished worker discovery
10:48:49 DISPATCHER: Starting worker discovery
10:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:49 DISPATCHER: Finished worker discovery
10:49:38 WORKER: done with job (8, 0, 5), trying to register it.
10:49:38 WORKER: registered result for job (8, 0, 5) with dispatcher
10:49:38 DISPATCHER: job (8, 0, 5) finished
10:49:38 DISPATCHER: register_result: lock acquired
10:49:38 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:49:38 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5284165618548239, 'info': {'data02': 0.5284165618548239, 'config': "{'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 50, 'lr': 0.010031815873181452, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012295867982234565}"}}
exception: None

10:49:38 job_callback for (8, 0, 5) started
10:49:38 DISPATCHER: Trying to submit another job.
10:49:38 job_callback for (8, 0, 5) got condition
10:49:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:49:38 HBMASTER: Trying to run another job!
10:49:38 job_callback for (8, 0, 5) finished
10:49:38 start sampling a new configuration.
10:49:38 best_vector: [0, 0.6572604342851271, 0.9057855271776268, 0.31972501271840204, 0.10004237115307606, 0, 0.5751725294742613, 0.0641560255587394], 5.1045994815390516e-05, 20140.510937729206, 1.028092416906641
10:49:38 done sampling a new configuration.
10:49:38 HBMASTER: schedule new run for iteration 9
10:49:38 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
10:49:38 HBMASTER: submitting job (9, 0, 0) to dispatcher
10:49:38 DISPATCHER: trying to submit job (9, 0, 0)
10:49:38 DISPATCHER: trying to notify the job_runner thread.
10:49:38 HBMASTER: job (9, 0, 0) submitted to dispatcher
10:49:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:49:38 DISPATCHER: Trying to submit another job.
10:49:38 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:49:38 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:49:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:49:38 WORKER: start processing job (9, 0, 0)
10:49:38 WORKER: args: ()
10:49:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.004359633945078243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01211905938708682}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:49:49 DISPATCHER: Starting worker discovery
10:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:49 DISPATCHER: Finished worker discovery
10:50:49 DISPATCHER: Starting worker discovery
10:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:49 DISPATCHER: Finished worker discovery
10:51:49 DISPATCHER: Starting worker discovery
10:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:49 DISPATCHER: Finished worker discovery
10:51:55 WORKER: done with job (9, 0, 0), trying to register it.
10:51:55 WORKER: registered result for job (9, 0, 0) with dispatcher
10:51:55 DISPATCHER: job (9, 0, 0) finished
10:51:55 DISPATCHER: register_result: lock acquired
10:51:55 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:51:55 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.004359633945078243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01211905938708682}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5971555722115238, 'info': {'data02': 0.5971555722115238, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.004359633945078243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01211905938708682}"}}
exception: None

10:51:55 job_callback for (9, 0, 0) started
10:51:55 DISPATCHER: Trying to submit another job.
10:51:55 job_callback for (9, 0, 0) got condition
10:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:51:55 HBMASTER: Trying to run another job!
10:51:55 job_callback for (9, 0, 0) finished
10:51:55 start sampling a new configuration.
10:51:55 best_vector: [2, 0.7990056368952366, 0.7502243482410671, 0.1652687750047501, 0.09944286006477077, 0, 0.6381275712776342, 0.06515786035183059], 0.00014698581320914112, 2803.276266224288, 0.4120418416408618
10:51:55 done sampling a new configuration.
10:51:55 HBMASTER: schedule new run for iteration 9
10:51:55 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
10:51:55 HBMASTER: submitting job (9, 0, 1) to dispatcher
10:51:55 DISPATCHER: trying to submit job (9, 0, 1)
10:51:55 DISPATCHER: trying to notify the job_runner thread.
10:51:55 HBMASTER: job (9, 0, 1) submitted to dispatcher
10:51:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:51:55 DISPATCHER: Trying to submit another job.
10:51:55 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:51:55 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:51:55 WORKER: start processing job (9, 0, 1)
10:51:55 WORKER: args: ()
10:51:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:52:49 DISPATCHER: Starting worker discovery
10:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:49 DISPATCHER: Finished worker discovery
10:53:49 DISPATCHER: Starting worker discovery
10:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:49 DISPATCHER: Finished worker discovery
10:54:12 WORKER: done with job (9, 0, 1), trying to register it.
10:54:12 WORKER: registered result for job (9, 0, 1) with dispatcher
10:54:12 DISPATCHER: job (9, 0, 1) finished
10:54:12 DISPATCHER: register_result: lock acquired
10:54:12 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:54:12 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5772286096603362, 'info': {'data02': 0.5772286096603362, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}"}}
exception: None

10:54:12 job_callback for (9, 0, 1) started
10:54:12 DISPATCHER: Trying to submit another job.
10:54:12 job_callback for (9, 0, 1) got condition
10:54:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:54:12 HBMASTER: Trying to run another job!
10:54:12 job_callback for (9, 0, 1) finished
10:54:12 start sampling a new configuration.
10:54:12 done sampling a new configuration.
10:54:12 HBMASTER: schedule new run for iteration 9
10:54:12 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
10:54:12 HBMASTER: submitting job (9, 0, 2) to dispatcher
10:54:12 DISPATCHER: trying to submit job (9, 0, 2)
10:54:12 DISPATCHER: trying to notify the job_runner thread.
10:54:12 HBMASTER: job (9, 0, 2) submitted to dispatcher
10:54:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:54:12 DISPATCHER: Trying to submit another job.
10:54:12 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:54:12 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:54:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:54:12 WORKER: start processing job (9, 0, 2)
10:54:12 WORKER: args: ()
10:54:12 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 25, 'last_n_outputs': 30, 'lr': 0.008267284095316546, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.024213410103268256}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:54:49 DISPATCHER: Starting worker discovery
10:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:49 DISPATCHER: Finished worker discovery
10:55:49 DISPATCHER: Starting worker discovery
10:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:49 DISPATCHER: Finished worker discovery
10:56:29 WORKER: done with job (9, 0, 2), trying to register it.
10:56:29 WORKER: registered result for job (9, 0, 2) with dispatcher
10:56:29 DISPATCHER: job (9, 0, 2) finished
10:56:29 DISPATCHER: register_result: lock acquired
10:56:29 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:56:29 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 25, 'last_n_outputs': 30, 'lr': 0.008267284095316546, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.024213410103268256}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.023816692793694638, 'info': {'data02': 0.023816692793694638, 'config': "{'batch_size': 32, 'hidden_dim': 25, 'last_n_outputs': 30, 'lr': 0.008267284095316546, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.024213410103268256}"}}
exception: None

10:56:29 job_callback for (9, 0, 2) started
10:56:29 job_callback for (9, 0, 2) got condition
10:56:29 DISPATCHER: Trying to submit another job.
10:56:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:56:29 HBMASTER: Trying to run another job!
10:56:29 job_callback for (9, 0, 2) finished
10:56:29 start sampling a new configuration.
10:56:29 done sampling a new configuration.
10:56:29 HBMASTER: schedule new run for iteration 9
10:56:29 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
10:56:29 HBMASTER: submitting job (9, 0, 3) to dispatcher
10:56:29 DISPATCHER: trying to submit job (9, 0, 3)
10:56:29 DISPATCHER: trying to notify the job_runner thread.
10:56:29 HBMASTER: job (9, 0, 3) submitted to dispatcher
10:56:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:56:29 DISPATCHER: Trying to submit another job.
10:56:30 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:56:30 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:56:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:56:30 WORKER: start processing job (9, 0, 3)
10:56:30 WORKER: args: ()
10:56:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 47, 'lr': 0.05544570554121112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.05887747180869326}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:56:49 DISPATCHER: Starting worker discovery
10:56:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:50 DISPATCHER: Finished worker discovery
10:57:50 DISPATCHER: Starting worker discovery
10:57:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:50 DISPATCHER: Finished worker discovery
10:58:47 WORKER: done with job (9, 0, 3), trying to register it.
10:58:47 WORKER: registered result for job (9, 0, 3) with dispatcher
10:58:47 DISPATCHER: job (9, 0, 3) finished
10:58:47 DISPATCHER: register_result: lock acquired
10:58:47 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
10:58:47 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 47, 'lr': 0.05544570554121112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.05887747180869326}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08652213316553548, 'info': {'data02': 0.08652213316553548, 'config': "{'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 47, 'lr': 0.05544570554121112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.05887747180869326}"}}
exception: None

10:58:47 job_callback for (9, 0, 3) started
10:58:47 DISPATCHER: Trying to submit another job.
10:58:47 job_callback for (9, 0, 3) got condition
10:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:58:47 HBMASTER: Trying to run another job!
10:58:47 job_callback for (9, 0, 3) finished
10:58:47 start sampling a new configuration.
10:58:47 best_vector: [2, 0.35307586422271264, 0.7351379418906852, 0.30581401345973674, 0.10154247599563587, 1, 0.06175007626828055, 0.0531681755581046], 0.0, inf, 0.10048115110145613
10:58:47 done sampling a new configuration.
10:58:47 HBMASTER: schedule new run for iteration 9
10:58:47 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
10:58:47 HBMASTER: submitting job (9, 0, 4) to dispatcher
10:58:47 DISPATCHER: trying to submit job (9, 0, 4)
10:58:47 DISPATCHER: trying to notify the job_runner thread.
10:58:47 HBMASTER: job (9, 0, 4) submitted to dispatcher
10:58:47 DISPATCHER: Trying to submit another job.
10:58:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:58:47 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
10:58:47 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
10:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:58:47 WORKER: start processing job (9, 0, 4)
10:58:47 WORKER: args: ()
10:58:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 37, 'lr': 0.0040891027818218, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.011726634556730176}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:58:50 DISPATCHER: Starting worker discovery
10:58:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:50 DISPATCHER: Finished worker discovery
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:59:50 DISPATCHER: Starting worker discovery
10:59:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:50 DISPATCHER: Finished worker discovery
11:00:50 DISPATCHER: Starting worker discovery
11:00:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:50 DISPATCHER: Finished worker discovery
11:01:04 WORKER: done with job (9, 0, 4), trying to register it.
11:01:04 WORKER: registered result for job (9, 0, 4) with dispatcher
11:01:04 DISPATCHER: job (9, 0, 4) finished
11:01:04 DISPATCHER: register_result: lock acquired
11:01:04 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:01:04 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 37, 'lr': 0.0040891027818218, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.011726634556730176}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.08394252974484091, 'info': {'data02': -0.08394252974484091, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 37, 'lr': 0.0040891027818218, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.011726634556730176}"}}
exception: None

11:01:04 job_callback for (9, 0, 4) started
11:01:04 DISPATCHER: Trying to submit another job.
11:01:04 job_callback for (9, 0, 4) got condition
11:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:01:04 HBMASTER: Trying to run another job!
11:01:04 job_callback for (9, 0, 4) finished
11:01:04 start sampling a new configuration.
11:01:04 done sampling a new configuration.
11:01:04 HBMASTER: schedule new run for iteration 9
11:01:04 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
11:01:04 HBMASTER: submitting job (9, 0, 5) to dispatcher
11:01:04 DISPATCHER: trying to submit job (9, 0, 5)
11:01:04 DISPATCHER: trying to notify the job_runner thread.
11:01:04 HBMASTER: job (9, 0, 5) submitted to dispatcher
11:01:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:01:04 DISPATCHER: Trying to submit another job.
11:01:04 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:01:04 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:01:04 WORKER: start processing job (9, 0, 5)
11:01:04 WORKER: args: ()
11:01:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 4, 'lr': 0.03404396866120569, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.014500247888511656}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:01:50 DISPATCHER: Starting worker discovery
11:01:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:50 DISPATCHER: Finished worker discovery
11:02:50 DISPATCHER: Starting worker discovery
11:02:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:50 DISPATCHER: Finished worker discovery
11:03:21 WORKER: done with job (9, 0, 5), trying to register it.
11:03:21 WORKER: registered result for job (9, 0, 5) with dispatcher
11:03:21 DISPATCHER: job (9, 0, 5) finished
11:03:21 DISPATCHER: register_result: lock acquired
11:03:21 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:03:21 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 4, 'lr': 0.03404396866120569, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.014500247888511656}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16571434761594706, 'info': {'data02': 0.16571434761594706, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 4, 'lr': 0.03404396866120569, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.014500247888511656}"}}
exception: None

11:03:21 job_callback for (9, 0, 5) started
11:03:21 DISPATCHER: Trying to submit another job.
11:03:21 job_callback for (9, 0, 5) got condition
11:03:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:03:21 HBMASTER: Trying to run another job!
11:03:21 job_callback for (9, 0, 5) finished
11:03:21 start sampling a new configuration.
11:03:21 best_vector: [2, 0.9550216521615621, 0.6397163156252894, 0.31681288232269467, 0.0996249503361041, 0, 0.5875097431238973, 0.036830746340411794], 2.405373759636323e-05, 19902.25606739749, 0.4787236450208073
11:03:21 done sampling a new configuration.
11:03:21 HBMASTER: schedule new run for iteration 9
11:03:21 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
11:03:21 HBMASTER: submitting job (9, 0, 6) to dispatcher
11:03:21 DISPATCHER: trying to submit job (9, 0, 6)
11:03:21 DISPATCHER: trying to notify the job_runner thread.
11:03:21 HBMASTER: job (9, 0, 6) submitted to dispatcher
11:03:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:03:21 DISPATCHER: Trying to submit another job.
11:03:21 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:03:21 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:03:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:03:21 WORKER: start processing job (9, 0, 6)
11:03:21 WORKER: args: ()
11:03:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 32, 'lr': 0.004301557817409956, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011166521481984912}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:03:50 DISPATCHER: Starting worker discovery
11:03:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:50 DISPATCHER: Finished worker discovery
11:04:50 DISPATCHER: Starting worker discovery
11:04:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:50 DISPATCHER: Finished worker discovery
11:05:39 WORKER: done with job (9, 0, 6), trying to register it.
11:05:39 WORKER: registered result for job (9, 0, 6) with dispatcher
11:05:39 DISPATCHER: job (9, 0, 6) finished
11:05:39 DISPATCHER: register_result: lock acquired
11:05:39 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:05:39 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 32, 'lr': 0.004301557817409956, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011166521481984912}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5064722727132271, 'info': {'data02': 0.5064722727132271, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 32, 'lr': 0.004301557817409956, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011166521481984912}"}}
exception: None

11:05:39 job_callback for (9, 0, 6) started
11:05:39 job_callback for (9, 0, 6) got condition
11:05:39 DISPATCHER: Trying to submit another job.
11:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:05:39 HBMASTER: Trying to run another job!
11:05:39 job_callback for (9, 0, 6) finished
11:05:39 start sampling a new configuration.
11:05:39 done sampling a new configuration.
11:05:39 HBMASTER: schedule new run for iteration 9
11:05:39 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
11:05:39 HBMASTER: submitting job (9, 0, 7) to dispatcher
11:05:39 DISPATCHER: trying to submit job (9, 0, 7)
11:05:39 DISPATCHER: trying to notify the job_runner thread.
11:05:39 HBMASTER: job (9, 0, 7) submitted to dispatcher
11:05:39 DISPATCHER: Trying to submit another job.
11:05:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:05:39 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:05:39 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:05:39 WORKER: start processing job (9, 0, 7)
11:05:39 WORKER: args: ()
11:05:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 20, 'lr': 0.08591233929311673, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.10059731092294798}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:05:50 DISPATCHER: Starting worker discovery
11:05:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:50 DISPATCHER: Finished worker discovery
11:06:50 DISPATCHER: Starting worker discovery
11:06:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:50 DISPATCHER: Finished worker discovery
11:07:50 DISPATCHER: Starting worker discovery
11:07:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:50 DISPATCHER: Finished worker discovery
11:07:56 WORKER: done with job (9, 0, 7), trying to register it.
11:07:56 WORKER: registered result for job (9, 0, 7) with dispatcher
11:07:56 DISPATCHER: job (9, 0, 7) finished
11:07:56 DISPATCHER: register_result: lock acquired
11:07:56 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:07:56 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 20, 'lr': 0.08591233929311673, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.10059731092294798}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 20, 'lr': 0.08591233929311673, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.10059731092294798}"}}
exception: None

11:07:56 job_callback for (9, 0, 7) started
11:07:56 job_callback for (9, 0, 7) got condition
11:07:56 DISPATCHER: Trying to submit another job.
11:07:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:07:56 HBMASTER: Trying to run another job!
11:07:56 job_callback for (9, 0, 7) finished
11:07:56 start sampling a new configuration.
11:07:56 done sampling a new configuration.
11:07:56 HBMASTER: schedule new run for iteration 9
11:07:56 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
11:07:56 HBMASTER: submitting job (9, 0, 8) to dispatcher
11:07:56 DISPATCHER: trying to submit job (9, 0, 8)
11:07:56 DISPATCHER: trying to notify the job_runner thread.
11:07:56 HBMASTER: job (9, 0, 8) submitted to dispatcher
11:07:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:07:56 DISPATCHER: Trying to submit another job.
11:07:56 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:07:56 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:07:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:07:56 WORKER: start processing job (9, 0, 8)
11:07:56 WORKER: args: ()
11:07:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 28, 'lr': 0.0463200272803355, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.17155112123640825}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:08:50 DISPATCHER: Starting worker discovery
11:08:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:50 DISPATCHER: Finished worker discovery
11:09:50 DISPATCHER: Starting worker discovery
11:09:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:50 DISPATCHER: Finished worker discovery
11:10:13 WORKER: done with job (9, 0, 8), trying to register it.
11:10:13 WORKER: registered result for job (9, 0, 8) with dispatcher
11:10:13 DISPATCHER: job (9, 0, 8) finished
11:10:13 DISPATCHER: register_result: lock acquired
11:10:13 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:10:13 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 28, 'lr': 0.0463200272803355, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.17155112123640825}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 28, 'lr': 0.0463200272803355, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.17155112123640825}"}}
exception: None

11:10:13 job_callback for (9, 0, 8) started
11:10:13 DISPATCHER: Trying to submit another job.
11:10:13 job_callback for (9, 0, 8) got condition
11:10:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:10:13 HBMASTER: Trying to run another job!
11:10:13 job_callback for (9, 0, 8) finished
11:10:13 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
11:10:13 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
11:10:13 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
11:10:13 HBMASTER: schedule new run for iteration 9
11:10:13 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
11:10:13 HBMASTER: submitting job (9, 0, 0) to dispatcher
11:10:13 DISPATCHER: trying to submit job (9, 0, 0)
11:10:13 DISPATCHER: trying to notify the job_runner thread.
11:10:13 HBMASTER: job (9, 0, 0) submitted to dispatcher
11:10:13 DISPATCHER: Trying to submit another job.
11:10:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:10:13 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:10:13 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:10:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:10:13 WORKER: start processing job (9, 0, 0)
11:10:13 WORKER: args: ()
11:10:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.004359633945078243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01211905938708682}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:10:50 DISPATCHER: Starting worker discovery
11:10:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:50 DISPATCHER: Finished worker discovery
11:11:50 DISPATCHER: Starting worker discovery
11:11:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:50 DISPATCHER: Finished worker discovery
11:12:50 DISPATCHER: Starting worker discovery
11:12:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:50 DISPATCHER: Finished worker discovery
11:13:50 DISPATCHER: Starting worker discovery
11:13:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:50 DISPATCHER: Finished worker discovery
11:14:50 DISPATCHER: Starting worker discovery
11:14:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:50 DISPATCHER: Finished worker discovery
11:15:50 DISPATCHER: Starting worker discovery
11:15:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:50 DISPATCHER: Finished worker discovery
11:16:50 DISPATCHER: Starting worker discovery
11:16:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:50 DISPATCHER: Finished worker discovery
11:16:57 WORKER: done with job (9, 0, 0), trying to register it.
11:16:57 WORKER: registered result for job (9, 0, 0) with dispatcher
11:16:57 DISPATCHER: job (9, 0, 0) finished
11:16:57 DISPATCHER: register_result: lock acquired
11:16:57 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:16:57 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.004359633945078243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01211905938708682}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.44078859270494686, 'info': {'data02': 0.44078859270494686, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 46, 'lr': 0.004359633945078243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01211905938708682}"}}
exception: None

11:16:57 job_callback for (9, 0, 0) started
11:16:57 DISPATCHER: Trying to submit another job.
11:16:57 job_callback for (9, 0, 0) got condition
11:16:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:16:57 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.663067





11:16:57 HBMASTER: Trying to run another job!
11:16:57 job_callback for (9, 0, 0) finished
11:16:57 HBMASTER: schedule new run for iteration 9
11:16:57 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
11:16:57 HBMASTER: submitting job (9, 0, 1) to dispatcher
11:16:57 DISPATCHER: trying to submit job (9, 0, 1)
11:16:57 DISPATCHER: trying to notify the job_runner thread.
11:16:57 HBMASTER: job (9, 0, 1) submitted to dispatcher
11:16:57 DISPATCHER: Trying to submit another job.
11:16:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:16:57 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:16:57 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:16:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:16:57 WORKER: start processing job (9, 0, 1)
11:16:57 WORKER: args: ()
11:16:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:17:50 DISPATCHER: Starting worker discovery
11:17:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:50 DISPATCHER: Finished worker discovery
11:18:50 DISPATCHER: Starting worker discovery
11:18:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:50 DISPATCHER: Finished worker discovery
11:19:50 DISPATCHER: Starting worker discovery
11:19:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:50 DISPATCHER: Finished worker discovery
11:20:50 DISPATCHER: Starting worker discovery
11:20:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:50 DISPATCHER: Finished worker discovery
11:21:50 DISPATCHER: Starting worker discovery
11:21:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:50 DISPATCHER: Finished worker discovery
11:22:50 DISPATCHER: Starting worker discovery
11:22:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:50 DISPATCHER: Finished worker discovery
11:23:41 WORKER: done with job (9, 0, 1), trying to register it.
11:23:41 WORKER: registered result for job (9, 0, 1) with dispatcher
11:23:41 DISPATCHER: job (9, 0, 1) finished
11:23:41 DISPATCHER: register_result: lock acquired
11:23:41 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:23:41 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.599967507577929, 'info': {'data02': 0.599967507577929, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}"}}
exception: None

11:23:41 job_callback for (9, 0, 1) started
11:23:41 job_callback for (9, 0, 1) got condition
11:23:41 DISPATCHER: Trying to submit another job.
11:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:23:41 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.663067





11:23:41 HBMASTER: Trying to run another job!
11:23:41 job_callback for (9, 0, 1) finished
11:23:41 HBMASTER: schedule new run for iteration 9
11:23:41 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
11:23:41 HBMASTER: submitting job (9, 0, 6) to dispatcher
11:23:41 DISPATCHER: trying to submit job (9, 0, 6)
11:23:41 DISPATCHER: trying to notify the job_runner thread.
11:23:41 HBMASTER: job (9, 0, 6) submitted to dispatcher
11:23:41 DISPATCHER: Trying to submit another job.
11:23:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:23:41 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:23:41 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:23:41 WORKER: start processing job (9, 0, 6)
11:23:41 WORKER: args: ()
11:23:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 32, 'lr': 0.004301557817409956, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011166521481984912}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:23:50 DISPATCHER: Starting worker discovery
11:23:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:50 DISPATCHER: Finished worker discovery
11:24:50 DISPATCHER: Starting worker discovery
11:24:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:50 DISPATCHER: Finished worker discovery
11:25:50 DISPATCHER: Starting worker discovery
11:25:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:50 DISPATCHER: Finished worker discovery
11:26:50 DISPATCHER: Starting worker discovery
11:26:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:50 DISPATCHER: Finished worker discovery
11:27:50 DISPATCHER: Starting worker discovery
11:27:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:50 DISPATCHER: Finished worker discovery
11:28:50 DISPATCHER: Starting worker discovery
11:28:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:50 DISPATCHER: Finished worker discovery
11:29:50 DISPATCHER: Starting worker discovery
11:29:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:50 DISPATCHER: Finished worker discovery
11:30:25 WORKER: done with job (9, 0, 6), trying to register it.
11:30:25 WORKER: registered result for job (9, 0, 6) with dispatcher
11:30:25 DISPATCHER: job (9, 0, 6) finished
11:30:25 DISPATCHER: register_result: lock acquired
11:30:25 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:30:25 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 32, 'lr': 0.004301557817409956, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011166521481984912}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5421018639313566, 'info': {'data02': 0.5421018639313566, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 32, 'lr': 0.004301557817409956, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011166521481984912}"}}
exception: None

11:30:25 job_callback for (9, 0, 6) started
11:30:25 job_callback for (9, 0, 6) got condition
11:30:25 DISPATCHER: Trying to submit another job.
11:30:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:30:25 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.663067





11:30:25 HBMASTER: Trying to run another job!
11:30:25 job_callback for (9, 0, 6) finished
11:30:25 ITERATION: Advancing config (9, 0, 1) to next budget 1200.000000
11:30:25 HBMASTER: schedule new run for iteration 9
11:30:25 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
11:30:25 HBMASTER: submitting job (9, 0, 1) to dispatcher
11:30:25 DISPATCHER: trying to submit job (9, 0, 1)
11:30:25 DISPATCHER: trying to notify the job_runner thread.
11:30:25 HBMASTER: job (9, 0, 1) submitted to dispatcher
11:30:25 DISPATCHER: Trying to submit another job.
11:30:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:30:25 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:30:25 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:30:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:30:25 WORKER: start processing job (9, 0, 1)
11:30:25 WORKER: args: ()
11:30:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:30:50 DISPATCHER: Starting worker discovery
11:30:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:50 DISPATCHER: Finished worker discovery
11:31:50 DISPATCHER: Starting worker discovery
11:31:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:50 DISPATCHER: Finished worker discovery
11:32:50 DISPATCHER: Starting worker discovery
11:32:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:50 DISPATCHER: Finished worker discovery
11:33:50 DISPATCHER: Starting worker discovery
11:33:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:50 DISPATCHER: Finished worker discovery
11:34:50 DISPATCHER: Starting worker discovery
11:34:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:50 DISPATCHER: Finished worker discovery
11:35:50 DISPATCHER: Starting worker discovery
11:35:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:50 DISPATCHER: Finished worker discovery
11:36:50 DISPATCHER: Starting worker discovery
11:36:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:50 DISPATCHER: Finished worker discovery
11:37:50 DISPATCHER: Starting worker discovery
11:37:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:50 DISPATCHER: Finished worker discovery
11:38:50 DISPATCHER: Starting worker discovery
11:38:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:50 DISPATCHER: Finished worker discovery
11:39:50 DISPATCHER: Starting worker discovery
11:39:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:50 DISPATCHER: Finished worker discovery
11:40:50 DISPATCHER: Starting worker discovery
11:40:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:50 DISPATCHER: Finished worker discovery
11:41:50 DISPATCHER: Starting worker discovery
11:41:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:50 DISPATCHER: Finished worker discovery
11:42:50 DISPATCHER: Starting worker discovery
11:42:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:50 DISPATCHER: Finished worker discovery
11:43:50 DISPATCHER: Starting worker discovery
11:43:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:50 DISPATCHER: Finished worker discovery
11:44:50 DISPATCHER: Starting worker discovery
11:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:50 DISPATCHER: Finished worker discovery
11:45:50 DISPATCHER: Starting worker discovery
11:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:50 DISPATCHER: Finished worker discovery
11:46:50 DISPATCHER: Starting worker discovery
11:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:50 DISPATCHER: Finished worker discovery
11:47:50 DISPATCHER: Starting worker discovery
11:47:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:50 DISPATCHER: Finished worker discovery
11:48:50 DISPATCHER: Starting worker discovery
11:48:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:50 DISPATCHER: Finished worker discovery
11:49:50 DISPATCHER: Starting worker discovery
11:49:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:50 DISPATCHER: Finished worker discovery
11:50:29 WORKER: done with job (9, 0, 1), trying to register it.
11:50:29 WORKER: registered result for job (9, 0, 1) with dispatcher
11:50:29 DISPATCHER: job (9, 0, 1) finished
11:50:29 DISPATCHER: register_result: lock acquired
11:50:29 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:50:29 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6652430497421598, 'info': {'data02': 0.6652430497421598, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 38, 'lr': 0.0021406100003896283, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.012155486092516826}"}}
exception: None

11:50:29 job_callback for (9, 0, 1) started
11:50:29 job_callback for (9, 0, 1) got condition
11:50:29 DISPATCHER: Trying to submit another job.
11:50:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:50:29 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.665243





11:50:29 HBMASTER: Trying to run another job!
11:50:29 job_callback for (9, 0, 1) finished
11:50:30 HBMASTER: shutdown initiated, shutdown_workers = True
11:50:30 WORKER: shutting down now!
11:50:30 DISPATCHER: Dispatcher shutting down
11:50:30 DISPATCHER: discover_workers shutting down
11:50:30 DISPATCHER: Trying to submit another job.
11:50:30 DISPATCHER: 'discover_worker' thread exited
11:50:30 DISPATCHER: job_runner shutting down
11:50:30 DISPATCHER: 'job_runner' thread exited
11:50:30 DISPATCHER: shut down complete
11:50:31 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f5c4c6e5cc0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:30148>
11:50:31 WORKER: No dispatcher found. Waiting for one to initiate contact.
11:50:31 WORKER: start listening for jobs
11:50:31 wait_for_workers trying to get the condition
11:50:31 DISPATCHER: started the 'discover_worker' thread
11:50:31 DISPATCHER: started the 'job_runner' thread
11:50:31 DISPATCHER: Pyro daemon running on localhost:43929
11:50:31 DISPATCHER: Starting worker discovery
11:50:31 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
11:50:31 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1575140037953214272
11:50:31 HBMASTER: number of workers changed to 1
11:50:31 Enough workers to start this run!
11:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:50:31 adjust_queue_size: lock accquired
11:50:31 HBMASTER: starting run at 1583923831.9880068
11:50:31 HBMASTER: adjusted queue size to (0, 1)
11:50:31 DISPATCHER: Finished worker discovery
11:50:31 start sampling a new configuration.
11:50:31 DISPATCHER: Trying to submit another job.
11:50:32 done sampling a new configuration.
11:50:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:50:32 HBMASTER: schedule new run for iteration 0
11:50:32 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
11:50:32 HBMASTER: submitting job (0, 0, 0) to dispatcher
11:50:32 DISPATCHER: trying to submit job (0, 0, 0)
11:50:32 DISPATCHER: trying to notify the job_runner thread.
11:50:32 HBMASTER: job (0, 0, 0) submitted to dispatcher
11:50:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:50:32 DISPATCHER: Trying to submit another job.
11:50:32 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:50:32 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:50:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:50:32 WORKER: start processing job (0, 0, 0)
11:50:32 WORKER: args: ()
11:50:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03104777088566083, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.018936110013804935, 'kernel_size_2': 3, 'num_filters_2': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:51:20 WORKER: done with job (0, 0, 0), trying to register it.
11:51:20 WORKER: registered result for job (0, 0, 0) with dispatcher
11:51:20 DISPATCHER: job (0, 0, 0) finished
11:51:20 DISPATCHER: register_result: lock acquired
11:51:20 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:51:20 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03104777088566083, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.018936110013804935, 'kernel_size_2': 3, 'num_filters_2': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42144468805567203, 'info': {'data02': 0.42144468805567203, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03104777088566083, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.018936110013804935, 'kernel_size_2': 3, 'num_filters_2': 52}"}}
exception: None

11:51:20 job_callback for (0, 0, 0) started
11:51:20 job_callback for (0, 0, 0) got condition
11:51:20 DISPATCHER: Trying to submit another job.
11:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:51:20 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:51:20 HBMASTER: Trying to run another job!
11:51:20 job_callback for (0, 0, 0) finished
11:51:20 start sampling a new configuration.
11:51:20 done sampling a new configuration.
11:51:20 HBMASTER: schedule new run for iteration 0
11:51:20 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
11:51:20 HBMASTER: submitting job (0, 0, 1) to dispatcher
11:51:20 DISPATCHER: trying to submit job (0, 0, 1)
11:51:20 DISPATCHER: trying to notify the job_runner thread.
11:51:20 HBMASTER: job (0, 0, 1) submitted to dispatcher
11:51:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:51:20 DISPATCHER: Trying to submit another job.
11:51:20 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:51:20 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:51:20 WORKER: start processing job (0, 0, 1)
11:51:20 WORKER: args: ()
11:51:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022136011670559593, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.030866354146433232}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:51:31 DISPATCHER: Starting worker discovery
11:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:32 DISPATCHER: Finished worker discovery
11:52:09 WORKER: done with job (0, 0, 1), trying to register it.
11:52:09 WORKER: registered result for job (0, 0, 1) with dispatcher
11:52:09 DISPATCHER: job (0, 0, 1) finished
11:52:09 DISPATCHER: register_result: lock acquired
11:52:09 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:52:09 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022136011670559593, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.030866354146433232}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4724428577860853, 'info': {'data02': 0.4724428577860853, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022136011670559593, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.030866354146433232}"}}
exception: None

11:52:09 job_callback for (0, 0, 1) started
11:52:09 DISPATCHER: Trying to submit another job.
11:52:09 job_callback for (0, 0, 1) got condition
11:52:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:52:09 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:52:09 HBMASTER: Trying to run another job!
11:52:09 job_callback for (0, 0, 1) finished
11:52:09 start sampling a new configuration.
11:52:09 done sampling a new configuration.
11:52:09 HBMASTER: schedule new run for iteration 0
11:52:09 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
11:52:09 HBMASTER: submitting job (0, 0, 2) to dispatcher
11:52:09 DISPATCHER: trying to submit job (0, 0, 2)
11:52:09 DISPATCHER: trying to notify the job_runner thread.
11:52:09 HBMASTER: job (0, 0, 2) submitted to dispatcher
11:52:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:52:09 DISPATCHER: Trying to submit another job.
11:52:09 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:52:09 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:52:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:52:09 WORKER: start processing job (0, 0, 2)
11:52:09 WORKER: args: ()
11:52:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02607885836941576, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.01613357846730101}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:52:32 DISPATCHER: Starting worker discovery
11:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:32 DISPATCHER: Finished worker discovery
11:52:57 WORKER: done with job (0, 0, 2), trying to register it.
11:52:57 WORKER: registered result for job (0, 0, 2) with dispatcher
11:52:57 DISPATCHER: job (0, 0, 2) finished
11:52:57 DISPATCHER: register_result: lock acquired
11:52:57 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:52:57 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02607885836941576, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.01613357846730101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34206768497068174, 'info': {'data02': 0.34206768497068174, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02607885836941576, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.01613357846730101}"}}
exception: None

11:52:57 job_callback for (0, 0, 2) started
11:52:57 job_callback for (0, 0, 2) got condition
11:52:57 DISPATCHER: Trying to submit another job.
11:52:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:52:57 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:52:57 HBMASTER: Trying to run another job!
11:52:57 job_callback for (0, 0, 2) finished
11:52:57 start sampling a new configuration.
11:52:57 done sampling a new configuration.
11:52:57 HBMASTER: schedule new run for iteration 0
11:52:57 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
11:52:57 HBMASTER: submitting job (0, 0, 3) to dispatcher
11:52:57 DISPATCHER: trying to submit job (0, 0, 3)
11:52:57 DISPATCHER: trying to notify the job_runner thread.
11:52:57 HBMASTER: job (0, 0, 3) submitted to dispatcher
11:52:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:52:57 DISPATCHER: Trying to submit another job.
11:52:57 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:52:57 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:52:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:52:57 WORKER: start processing job (0, 0, 3)
11:52:57 WORKER: args: ()
11:52:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06546758669477627, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.17409712624873866, 'kernel_size_2': 3, 'num_filters_2': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:53:32 DISPATCHER: Starting worker discovery
11:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:32 DISPATCHER: Finished worker discovery
11:53:48 WORKER: done with job (0, 0, 3), trying to register it.
11:53:48 WORKER: registered result for job (0, 0, 3) with dispatcher
11:53:48 DISPATCHER: job (0, 0, 3) finished
11:53:48 DISPATCHER: register_result: lock acquired
11:53:48 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:53:48 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06546758669477627, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.17409712624873866, 'kernel_size_2': 3, 'num_filters_2': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3225225944886806, 'info': {'data02': 0.3225225944886806, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06546758669477627, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.17409712624873866, 'kernel_size_2': 3, 'num_filters_2': 125}"}}
exception: None

11:53:48 job_callback for (0, 0, 3) started
11:53:48 DISPATCHER: Trying to submit another job.
11:53:48 job_callback for (0, 0, 3) got condition
11:53:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:53:48 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:53:48 HBMASTER: Trying to run another job!
11:53:48 job_callback for (0, 0, 3) finished
11:53:48 start sampling a new configuration.
11:53:48 done sampling a new configuration.
11:53:48 HBMASTER: schedule new run for iteration 0
11:53:48 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
11:53:48 HBMASTER: submitting job (0, 0, 4) to dispatcher
11:53:48 DISPATCHER: trying to submit job (0, 0, 4)
11:53:48 DISPATCHER: trying to notify the job_runner thread.
11:53:48 HBMASTER: job (0, 0, 4) submitted to dispatcher
11:53:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:53:48 DISPATCHER: Trying to submit another job.
11:53:48 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:53:48 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:53:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:53:48 WORKER: start processing job (0, 0, 4)
11:53:48 WORKER: args: ()
11:53:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0028448042863654655, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.16348900540596492}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:54:32 DISPATCHER: Starting worker discovery
11:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:32 DISPATCHER: Finished worker discovery
11:54:37 WORKER: done with job (0, 0, 4), trying to register it.
11:54:37 WORKER: registered result for job (0, 0, 4) with dispatcher
11:54:37 DISPATCHER: job (0, 0, 4) finished
11:54:37 DISPATCHER: register_result: lock acquired
11:54:37 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:54:37 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0028448042863654655, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.16348900540596492}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49225366533482856, 'info': {'data02': 0.49225366533482856, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0028448042863654655, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.16348900540596492}"}}
exception: None

11:54:37 job_callback for (0, 0, 4) started
11:54:37 DISPATCHER: Trying to submit another job.
11:54:37 job_callback for (0, 0, 4) got condition
11:54:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:54:37 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:54:37 HBMASTER: Trying to run another job!
11:54:37 job_callback for (0, 0, 4) finished
11:54:37 start sampling a new configuration.
11:54:37 done sampling a new configuration.
11:54:37 HBMASTER: schedule new run for iteration 0
11:54:37 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
11:54:37 HBMASTER: submitting job (0, 0, 5) to dispatcher
11:54:37 DISPATCHER: trying to submit job (0, 0, 5)
11:54:37 DISPATCHER: trying to notify the job_runner thread.
11:54:37 HBMASTER: job (0, 0, 5) submitted to dispatcher
11:54:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:54:37 DISPATCHER: Trying to submit another job.
11:54:37 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:54:37 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:54:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:54:37 WORKER: start processing job (0, 0, 5)
11:54:37 WORKER: args: ()
11:54:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012260367645199177, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.016258097311416194, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 26, 'num_filters_4': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:55:26 WORKER: done with job (0, 0, 5), trying to register it.
11:55:26 WORKER: registered result for job (0, 0, 5) with dispatcher
11:55:26 DISPATCHER: job (0, 0, 5) finished
11:55:26 DISPATCHER: register_result: lock acquired
11:55:26 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:55:26 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012260367645199177, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.016258097311416194, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 26, 'num_filters_4': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5233486137869091, 'info': {'data02': 0.5233486137869091, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012260367645199177, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.016258097311416194, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 26, 'num_filters_4': 28}"}}
exception: None

11:55:26 job_callback for (0, 0, 5) started
11:55:26 job_callback for (0, 0, 5) got condition
11:55:26 DISPATCHER: Trying to submit another job.
11:55:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:55:26 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:55:26 HBMASTER: Trying to run another job!
11:55:26 job_callback for (0, 0, 5) finished
11:55:26 start sampling a new configuration.
11:55:26 done sampling a new configuration.
11:55:26 HBMASTER: schedule new run for iteration 0
11:55:26 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
11:55:26 HBMASTER: submitting job (0, 0, 6) to dispatcher
11:55:26 DISPATCHER: trying to submit job (0, 0, 6)
11:55:26 DISPATCHER: trying to notify the job_runner thread.
11:55:26 HBMASTER: job (0, 0, 6) submitted to dispatcher
11:55:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:55:26 DISPATCHER: Trying to submit another job.
11:55:26 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:55:26 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:55:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:55:26 WORKER: start processing job (0, 0, 6)
11:55:26 WORKER: args: ()
11:55:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004515185329496938, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.1267505366288899, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 56, 'num_filters_4': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:55:32 DISPATCHER: Starting worker discovery
11:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:32 DISPATCHER: Finished worker discovery
11:56:14 WORKER: done with job (0, 0, 6), trying to register it.
11:56:14 WORKER: registered result for job (0, 0, 6) with dispatcher
11:56:14 DISPATCHER: job (0, 0, 6) finished
11:56:14 DISPATCHER: register_result: lock acquired
11:56:14 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:56:14 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004515185329496938, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.1267505366288899, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 56, 'num_filters_4': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40186836137019977, 'info': {'data02': 0.40186836137019977, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004515185329496938, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.1267505366288899, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 56, 'num_filters_4': 48}"}}
exception: None

11:56:14 job_callback for (0, 0, 6) started
11:56:14 DISPATCHER: Trying to submit another job.
11:56:14 job_callback for (0, 0, 6) got condition
11:56:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:14 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:56:14 HBMASTER: Trying to run another job!
11:56:14 job_callback for (0, 0, 6) finished
11:56:14 start sampling a new configuration.
11:56:14 done sampling a new configuration.
11:56:14 HBMASTER: schedule new run for iteration 0
11:56:14 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
11:56:14 HBMASTER: submitting job (0, 0, 7) to dispatcher
11:56:14 DISPATCHER: trying to submit job (0, 0, 7)
11:56:14 DISPATCHER: trying to notify the job_runner thread.
11:56:14 HBMASTER: job (0, 0, 7) submitted to dispatcher
11:56:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:14 DISPATCHER: Trying to submit another job.
11:56:14 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:56:14 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:56:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:14 WORKER: start processing job (0, 0, 7)
11:56:14 WORKER: args: ()
11:56:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:56:32 DISPATCHER: Starting worker discovery
11:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:32 DISPATCHER: Finished worker discovery
11:57:03 WORKER: done with job (0, 0, 7), trying to register it.
11:57:03 WORKER: registered result for job (0, 0, 7) with dispatcher
11:57:03 DISPATCHER: job (0, 0, 7) finished
11:57:03 DISPATCHER: register_result: lock acquired
11:57:03 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:57:03 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6052381588619894, 'info': {'data02': 0.6052381588619894, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}"}}
exception: None

11:57:03 job_callback for (0, 0, 7) started
11:57:03 job_callback for (0, 0, 7) got condition
11:57:03 DISPATCHER: Trying to submit another job.
11:57:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:57:03 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:57:03 HBMASTER: Trying to run another job!
11:57:03 job_callback for (0, 0, 7) finished
11:57:03 start sampling a new configuration.
11:57:03 done sampling a new configuration.
11:57:03 HBMASTER: schedule new run for iteration 0
11:57:03 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
11:57:03 HBMASTER: submitting job (0, 0, 8) to dispatcher
11:57:03 DISPATCHER: trying to submit job (0, 0, 8)
11:57:03 DISPATCHER: trying to notify the job_runner thread.
11:57:03 HBMASTER: job (0, 0, 8) submitted to dispatcher
11:57:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:57:03 DISPATCHER: Trying to submit another job.
11:57:03 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:57:03 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:57:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:57:03 WORKER: start processing job (0, 0, 8)
11:57:03 WORKER: args: ()
11:57:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0017429090542032647, 'num_filters_1': 39, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.06174430488966001, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:57:32 DISPATCHER: Starting worker discovery
11:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:32 DISPATCHER: Finished worker discovery
11:57:52 WORKER: done with job (0, 0, 8), trying to register it.
11:57:52 WORKER: registered result for job (0, 0, 8) with dispatcher
11:57:52 DISPATCHER: job (0, 0, 8) finished
11:57:52 DISPATCHER: register_result: lock acquired
11:57:52 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:57:52 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0017429090542032647, 'num_filters_1': 39, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.06174430488966001, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3941837938134899, 'info': {'data02': 0.3941837938134899, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0017429090542032647, 'num_filters_1': 39, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.06174430488966001, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 90}"}}
exception: None

11:57:52 job_callback for (0, 0, 8) started
11:57:52 job_callback for (0, 0, 8) got condition
11:57:52 DISPATCHER: Trying to submit another job.
11:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:57:52 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:57:52 HBMASTER: Trying to run another job!
11:57:52 job_callback for (0, 0, 8) finished
11:57:52 start sampling a new configuration.
11:57:52 done sampling a new configuration.
11:57:52 HBMASTER: schedule new run for iteration 0
11:57:52 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
11:57:52 HBMASTER: submitting job (0, 0, 9) to dispatcher
11:57:52 DISPATCHER: trying to submit job (0, 0, 9)
11:57:52 DISPATCHER: trying to notify the job_runner thread.
11:57:52 HBMASTER: job (0, 0, 9) submitted to dispatcher
11:57:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:57:52 DISPATCHER: Trying to submit another job.
11:57:52 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:57:52 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:57:52 WORKER: start processing job (0, 0, 9)
11:57:52 WORKER: args: ()
11:57:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09522707929537401, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01875661681848209, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 51, 'num_filters_3': 31, 'num_filters_4': 30, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:58:32 DISPATCHER: Starting worker discovery
11:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:32 DISPATCHER: Finished worker discovery
11:58:41 WORKER: done with job (0, 0, 9), trying to register it.
11:58:41 WORKER: registered result for job (0, 0, 9) with dispatcher
11:58:41 DISPATCHER: job (0, 0, 9) finished
11:58:41 DISPATCHER: register_result: lock acquired
11:58:41 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:58:41 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09522707929537401, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01875661681848209, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 51, 'num_filters_3': 31, 'num_filters_4': 30, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27337276252630427, 'info': {'data02': 0.27337276252630427, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09522707929537401, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01875661681848209, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 51, 'num_filters_3': 31, 'num_filters_4': 30, 'num_filters_5': 17}"}}
exception: None

11:58:41 job_callback for (0, 0, 9) started
11:58:41 job_callback for (0, 0, 9) got condition
11:58:41 DISPATCHER: Trying to submit another job.
11:58:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:58:41 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:58:41 HBMASTER: Trying to run another job!
11:58:41 job_callback for (0, 0, 9) finished
11:58:41 start sampling a new configuration.
11:58:41 done sampling a new configuration.
11:58:41 HBMASTER: schedule new run for iteration 0
11:58:41 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
11:58:41 HBMASTER: submitting job (0, 0, 10) to dispatcher
11:58:41 DISPATCHER: trying to submit job (0, 0, 10)
11:58:41 DISPATCHER: trying to notify the job_runner thread.
11:58:41 HBMASTER: job (0, 0, 10) submitted to dispatcher
11:58:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:58:41 DISPATCHER: Trying to submit another job.
11:58:41 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:58:41 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:58:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:58:41 WORKER: start processing job (0, 0, 10)
11:58:41 WORKER: args: ()
11:58:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.011381521697587597, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.11459895922964922}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:59:30 WORKER: done with job (0, 0, 10), trying to register it.
11:59:30 WORKER: registered result for job (0, 0, 10) with dispatcher
11:59:30 DISPATCHER: job (0, 0, 10) finished
11:59:30 DISPATCHER: register_result: lock acquired
11:59:30 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
11:59:30 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.011381521697587597, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.11459895922964922}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3478670934196085, 'info': {'data02': 0.3478670934196085, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.011381521697587597, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.11459895922964922}"}}
exception: None

11:59:30 job_callback for (0, 0, 10) started
11:59:30 job_callback for (0, 0, 10) got condition
11:59:30 DISPATCHER: Trying to submit another job.
11:59:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:59:30 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:59:30 HBMASTER: Trying to run another job!
11:59:30 job_callback for (0, 0, 10) finished
11:59:30 start sampling a new configuration.
11:59:30 done sampling a new configuration.
11:59:30 HBMASTER: schedule new run for iteration 0
11:59:30 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
11:59:30 HBMASTER: submitting job (0, 0, 11) to dispatcher
11:59:30 DISPATCHER: trying to submit job (0, 0, 11)
11:59:30 DISPATCHER: trying to notify the job_runner thread.
11:59:30 HBMASTER: job (0, 0, 11) submitted to dispatcher
11:59:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:59:30 DISPATCHER: Trying to submit another job.
11:59:30 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
11:59:30 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
11:59:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:59:30 WORKER: start processing job (0, 0, 11)
11:59:30 WORKER: args: ()
11:59:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02844085227319865, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09453465857799942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 119, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:59:32 DISPATCHER: Starting worker discovery
11:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:32 DISPATCHER: Finished worker discovery
12:00:18 WORKER: done with job (0, 0, 11), trying to register it.
12:00:18 WORKER: registered result for job (0, 0, 11) with dispatcher
12:00:18 DISPATCHER: job (0, 0, 11) finished
12:00:18 DISPATCHER: register_result: lock acquired
12:00:18 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:00:18 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02844085227319865, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09453465857799942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 119, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02844085227319865, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09453465857799942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 119, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 22}"}}
exception: None

12:00:18 job_callback for (0, 0, 11) started
12:00:18 job_callback for (0, 0, 11) got condition
12:00:18 DISPATCHER: Trying to submit another job.
12:00:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:00:18 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:00:18 HBMASTER: Trying to run another job!
12:00:18 job_callback for (0, 0, 11) finished
12:00:18 start sampling a new configuration.
12:00:18 done sampling a new configuration.
12:00:18 HBMASTER: schedule new run for iteration 0
12:00:18 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
12:00:18 HBMASTER: submitting job (0, 0, 12) to dispatcher
12:00:18 DISPATCHER: trying to submit job (0, 0, 12)
12:00:18 DISPATCHER: trying to notify the job_runner thread.
12:00:18 HBMASTER: job (0, 0, 12) submitted to dispatcher
12:00:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:00:18 DISPATCHER: Trying to submit another job.
12:00:18 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:00:18 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:00:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:00:18 WORKER: start processing job (0, 0, 12)
12:00:18 WORKER: args: ()
12:00:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05512983205690437, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07256018954488896, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:00:32 DISPATCHER: Starting worker discovery
12:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:32 DISPATCHER: Finished worker discovery
12:01:07 WORKER: done with job (0, 0, 12), trying to register it.
12:01:07 WORKER: registered result for job (0, 0, 12) with dispatcher
12:01:07 DISPATCHER: job (0, 0, 12) finished
12:01:07 DISPATCHER: register_result: lock acquired
12:01:07 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:01:07 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05512983205690437, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07256018954488896, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05512983205690437, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07256018954488896, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 18}"}}
exception: None

12:01:07 job_callback for (0, 0, 12) started
12:01:07 job_callback for (0, 0, 12) got condition
12:01:07 DISPATCHER: Trying to submit another job.
12:01:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:07 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:01:07 HBMASTER: Trying to run another job!
12:01:07 job_callback for (0, 0, 12) finished
12:01:07 start sampling a new configuration.
12:01:07 done sampling a new configuration.
12:01:07 HBMASTER: schedule new run for iteration 0
12:01:07 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
12:01:07 HBMASTER: submitting job (0, 0, 13) to dispatcher
12:01:07 DISPATCHER: trying to submit job (0, 0, 13)
12:01:07 DISPATCHER: trying to notify the job_runner thread.
12:01:07 HBMASTER: job (0, 0, 13) submitted to dispatcher
12:01:07 DISPATCHER: Trying to submit another job.
12:01:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:07 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:01:07 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:01:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:07 WORKER: start processing job (0, 0, 13)
12:01:07 WORKER: args: ()
12:01:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.044201795251397606, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.06153091931647188, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 47, 'num_filters_4': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:01:32 DISPATCHER: Starting worker discovery
12:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:32 DISPATCHER: Finished worker discovery
12:01:56 WORKER: done with job (0, 0, 13), trying to register it.
12:01:56 WORKER: registered result for job (0, 0, 13) with dispatcher
12:01:56 DISPATCHER: job (0, 0, 13) finished
12:01:56 DISPATCHER: register_result: lock acquired
12:01:56 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:01:56 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.044201795251397606, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.06153091931647188, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 47, 'num_filters_4': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.044201795251397606, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.06153091931647188, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 47, 'num_filters_4': 75}"}}
exception: None

12:01:56 job_callback for (0, 0, 13) started
12:01:56 DISPATCHER: Trying to submit another job.
12:01:56 job_callback for (0, 0, 13) got condition
12:01:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:56 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:01:56 HBMASTER: Trying to run another job!
12:01:56 job_callback for (0, 0, 13) finished
12:01:56 start sampling a new configuration.
12:01:56 done sampling a new configuration.
12:01:56 HBMASTER: schedule new run for iteration 0
12:01:56 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
12:01:56 HBMASTER: submitting job (0, 0, 14) to dispatcher
12:01:56 DISPATCHER: trying to submit job (0, 0, 14)
12:01:56 DISPATCHER: trying to notify the job_runner thread.
12:01:56 HBMASTER: job (0, 0, 14) submitted to dispatcher
12:01:56 DISPATCHER: Trying to submit another job.
12:01:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:56 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:01:56 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:01:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:56 WORKER: start processing job (0, 0, 14)
12:01:56 WORKER: args: ()
12:01:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00746162952184806, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.059236791077171655}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:02:32 DISPATCHER: Starting worker discovery
12:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:32 DISPATCHER: Finished worker discovery
12:02:44 WORKER: done with job (0, 0, 14), trying to register it.
12:02:44 WORKER: registered result for job (0, 0, 14) with dispatcher
12:02:44 DISPATCHER: job (0, 0, 14) finished
12:02:44 DISPATCHER: register_result: lock acquired
12:02:44 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:02:44 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00746162952184806, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.059236791077171655}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45759982734464605, 'info': {'data02': 0.45759982734464605, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00746162952184806, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.059236791077171655}"}}
exception: None

12:02:44 job_callback for (0, 0, 14) started
12:02:44 job_callback for (0, 0, 14) got condition
12:02:44 DISPATCHER: Trying to submit another job.
12:02:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:02:44 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:02:44 HBMASTER: Trying to run another job!
12:02:44 job_callback for (0, 0, 14) finished
12:02:44 start sampling a new configuration.
12:02:44 done sampling a new configuration.
12:02:44 HBMASTER: schedule new run for iteration 0
12:02:44 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
12:02:44 HBMASTER: submitting job (0, 0, 15) to dispatcher
12:02:44 DISPATCHER: trying to submit job (0, 0, 15)
12:02:44 DISPATCHER: trying to notify the job_runner thread.
12:02:44 HBMASTER: job (0, 0, 15) submitted to dispatcher
12:02:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:02:44 DISPATCHER: Trying to submit another job.
12:02:44 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:02:44 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:02:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:02:44 WORKER: start processing job (0, 0, 15)
12:02:44 WORKER: args: ()
12:02:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002483816288730722, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11162237412771157, 'kernel_size_2': 7, 'num_filters_2': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:03:32 DISPATCHER: Starting worker discovery
12:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:32 DISPATCHER: Finished worker discovery
12:03:34 WORKER: done with job (0, 0, 15), trying to register it.
12:03:34 WORKER: registered result for job (0, 0, 15) with dispatcher
12:03:34 DISPATCHER: job (0, 0, 15) finished
12:03:34 DISPATCHER: register_result: lock acquired
12:03:34 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:03:34 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002483816288730722, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11162237412771157, 'kernel_size_2': 7, 'num_filters_2': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48281880309066344, 'info': {'data02': 0.48281880309066344, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002483816288730722, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11162237412771157, 'kernel_size_2': 7, 'num_filters_2': 105}"}}
exception: None

12:03:34 job_callback for (0, 0, 15) started
12:03:34 DISPATCHER: Trying to submit another job.
12:03:34 job_callback for (0, 0, 15) got condition
12:03:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:03:34 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:03:34 HBMASTER: Trying to run another job!
12:03:34 job_callback for (0, 0, 15) finished
12:03:34 start sampling a new configuration.
12:03:34 done sampling a new configuration.
12:03:34 HBMASTER: schedule new run for iteration 0
12:03:34 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
12:03:34 HBMASTER: submitting job (0, 0, 16) to dispatcher
12:03:34 DISPATCHER: trying to submit job (0, 0, 16)
12:03:34 DISPATCHER: trying to notify the job_runner thread.
12:03:34 HBMASTER: job (0, 0, 16) submitted to dispatcher
12:03:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:03:34 DISPATCHER: Trying to submit another job.
12:03:34 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:03:34 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:03:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:03:34 WORKER: start processing job (0, 0, 16)
12:03:34 WORKER: args: ()
12:03:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.012164144789441875, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.17242316502803465}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:04:23 WORKER: done with job (0, 0, 16), trying to register it.
12:04:23 WORKER: registered result for job (0, 0, 16) with dispatcher
12:04:23 DISPATCHER: job (0, 0, 16) finished
12:04:23 DISPATCHER: register_result: lock acquired
12:04:23 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:04:23 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.012164144789441875, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.17242316502803465}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34561182872199164, 'info': {'data02': 0.34561182872199164, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.012164144789441875, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.17242316502803465}"}}
exception: None

12:04:23 job_callback for (0, 0, 16) started
12:04:23 DISPATCHER: Trying to submit another job.
12:04:23 job_callback for (0, 0, 16) got condition
12:04:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:23 HBMASTER: Trying to run another job!
12:04:23 job_callback for (0, 0, 16) finished
12:04:23 start sampling a new configuration.
12:04:23 done sampling a new configuration.
12:04:23 HBMASTER: schedule new run for iteration 0
12:04:23 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
12:04:23 HBMASTER: submitting job (0, 0, 17) to dispatcher
12:04:23 DISPATCHER: trying to submit job (0, 0, 17)
12:04:23 DISPATCHER: trying to notify the job_runner thread.
12:04:23 HBMASTER: job (0, 0, 17) submitted to dispatcher
12:04:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:23 DISPATCHER: Trying to submit another job.
12:04:23 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:04:23 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:04:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:23 WORKER: start processing job (0, 0, 17)
12:04:23 WORKER: args: ()
12:04:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010074701196545792, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.05037220240813745, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:04:32 DISPATCHER: Starting worker discovery
12:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:32 DISPATCHER: Finished worker discovery
12:05:12 WORKER: done with job (0, 0, 17), trying to register it.
12:05:12 WORKER: registered result for job (0, 0, 17) with dispatcher
12:05:12 DISPATCHER: job (0, 0, 17) finished
12:05:12 DISPATCHER: register_result: lock acquired
12:05:12 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:05:12 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010074701196545792, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.05037220240813745, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5442482986889351, 'info': {'data02': 0.5442482986889351, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010074701196545792, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.05037220240813745, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 106}"}}
exception: None

12:05:12 job_callback for (0, 0, 17) started
12:05:12 job_callback for (0, 0, 17) got condition
12:05:12 DISPATCHER: Trying to submit another job.
12:05:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:05:12 HBMASTER: Trying to run another job!
12:05:12 job_callback for (0, 0, 17) finished
12:05:12 start sampling a new configuration.
12:05:12 done sampling a new configuration.
12:05:12 HBMASTER: schedule new run for iteration 0
12:05:12 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:05:12 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:05:12 DISPATCHER: trying to submit job (0, 0, 18)
12:05:12 DISPATCHER: trying to notify the job_runner thread.
12:05:12 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:05:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:05:12 DISPATCHER: Trying to submit another job.
12:05:12 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:05:12 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:05:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:05:12 WORKER: start processing job (0, 0, 18)
12:05:12 WORKER: args: ()
12:05:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0023829128926230857, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.17678301926078355, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:05:32 DISPATCHER: Starting worker discovery
12:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:32 DISPATCHER: Finished worker discovery
12:06:01 WORKER: done with job (0, 0, 18), trying to register it.
12:06:01 WORKER: registered result for job (0, 0, 18) with dispatcher
12:06:01 DISPATCHER: job (0, 0, 18) finished
12:06:01 DISPATCHER: register_result: lock acquired
12:06:01 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:06:01 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0023829128926230857, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.17678301926078355, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4698605894199742, 'info': {'data02': 0.4698605894199742, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0023829128926230857, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.17678301926078355, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 62}"}}
exception: None

12:06:01 job_callback for (0, 0, 18) started
12:06:01 job_callback for (0, 0, 18) got condition
12:06:01 DISPATCHER: Trying to submit another job.
12:06:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:01 HBMASTER: Trying to run another job!
12:06:01 job_callback for (0, 0, 18) finished
12:06:01 start sampling a new configuration.
12:06:01 done sampling a new configuration.
12:06:01 HBMASTER: schedule new run for iteration 0
12:06:01 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:06:01 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:06:01 DISPATCHER: trying to submit job (0, 0, 19)
12:06:01 DISPATCHER: trying to notify the job_runner thread.
12:06:01 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:06:01 DISPATCHER: Trying to submit another job.
12:06:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:01 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:06:01 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:06:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:01 WORKER: start processing job (0, 0, 19)
12:06:01 WORKER: args: ()
12:06:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.050024444008217116, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.0898463042049314, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:06:32 DISPATCHER: Starting worker discovery
12:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:32 DISPATCHER: Finished worker discovery
12:06:49 WORKER: done with job (0, 0, 19), trying to register it.
12:06:49 WORKER: registered result for job (0, 0, 19) with dispatcher
12:06:49 DISPATCHER: job (0, 0, 19) finished
12:06:49 DISPATCHER: register_result: lock acquired
12:06:49 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:06:49 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.050024444008217116, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.0898463042049314, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3592356630679196, 'info': {'data02': 0.3592356630679196, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.050024444008217116, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.0898463042049314, 'kernel_size_2': 5, 'num_filters_2': 22}"}}
exception: None

12:06:49 job_callback for (0, 0, 19) started
12:06:49 job_callback for (0, 0, 19) got condition
12:06:49 DISPATCHER: Trying to submit another job.
12:06:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:49 HBMASTER: Trying to run another job!
12:06:49 job_callback for (0, 0, 19) finished
12:06:49 start sampling a new configuration.
12:06:49 done sampling a new configuration.
12:06:49 HBMASTER: schedule new run for iteration 0
12:06:49 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
12:06:49 HBMASTER: submitting job (0, 0, 20) to dispatcher
12:06:49 DISPATCHER: trying to submit job (0, 0, 20)
12:06:49 DISPATCHER: trying to notify the job_runner thread.
12:06:49 HBMASTER: job (0, 0, 20) submitted to dispatcher
12:06:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:49 DISPATCHER: Trying to submit another job.
12:06:49 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:06:49 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:06:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:49 WORKER: start processing job (0, 0, 20)
12:06:49 WORKER: args: ()
12:06:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07434795930014369, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02241753586050488, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:07:32 DISPATCHER: Starting worker discovery
12:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:32 DISPATCHER: Finished worker discovery
12:07:38 WORKER: done with job (0, 0, 20), trying to register it.
12:07:38 WORKER: registered result for job (0, 0, 20) with dispatcher
12:07:38 DISPATCHER: job (0, 0, 20) finished
12:07:38 DISPATCHER: register_result: lock acquired
12:07:38 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:07:38 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07434795930014369, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02241753586050488, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3383741286218139, 'info': {'data02': 0.3383741286218139, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07434795930014369, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02241753586050488, 'kernel_size_2': 3, 'num_filters_2': 30}"}}
exception: None

12:07:38 job_callback for (0, 0, 20) started
12:07:38 job_callback for (0, 0, 20) got condition
12:07:38 DISPATCHER: Trying to submit another job.
12:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:38 HBMASTER: Trying to run another job!
12:07:38 job_callback for (0, 0, 20) finished
12:07:38 start sampling a new configuration.
12:07:38 done sampling a new configuration.
12:07:38 HBMASTER: schedule new run for iteration 0
12:07:38 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:07:38 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:07:38 DISPATCHER: trying to submit job (0, 0, 21)
12:07:38 DISPATCHER: trying to notify the job_runner thread.
12:07:38 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:07:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:38 DISPATCHER: Trying to submit another job.
12:07:38 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:07:38 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:38 WORKER: start processing job (0, 0, 21)
12:07:38 WORKER: args: ()
12:07:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.054413871423329443, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.02496627537337585, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 89, 'num_filters_4': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:08:28 WORKER: done with job (0, 0, 21), trying to register it.
12:08:28 WORKER: registered result for job (0, 0, 21) with dispatcher
12:08:28 DISPATCHER: job (0, 0, 21) finished
12:08:28 DISPATCHER: register_result: lock acquired
12:08:28 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:08:28 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.054413871423329443, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.02496627537337585, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 89, 'num_filters_4': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.054413871423329443, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.02496627537337585, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 89, 'num_filters_4': 33}"}}
exception: None

12:08:28 job_callback for (0, 0, 21) started
12:08:28 job_callback for (0, 0, 21) got condition
12:08:28 DISPATCHER: Trying to submit another job.
12:08:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:08:28 HBMASTER: Trying to run another job!
12:08:28 job_callback for (0, 0, 21) finished
12:08:28 start sampling a new configuration.
12:08:28 done sampling a new configuration.
12:08:28 HBMASTER: schedule new run for iteration 0
12:08:28 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
12:08:28 HBMASTER: submitting job (0, 0, 22) to dispatcher
12:08:28 DISPATCHER: trying to submit job (0, 0, 22)
12:08:28 DISPATCHER: trying to notify the job_runner thread.
12:08:28 HBMASTER: job (0, 0, 22) submitted to dispatcher
12:08:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:08:28 DISPATCHER: Trying to submit another job.
12:08:28 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:08:28 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:08:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:08:28 WORKER: start processing job (0, 0, 22)
12:08:28 WORKER: args: ()
12:08:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07386205747529, 'num_filters_1': 74, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.14540772979791725, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 75, 'num_filters_3': 45, 'num_filters_4': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:08:32 DISPATCHER: Starting worker discovery
12:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:32 DISPATCHER: Finished worker discovery
12:09:17 WORKER: done with job (0, 0, 22), trying to register it.
12:09:17 WORKER: registered result for job (0, 0, 22) with dispatcher
12:09:17 DISPATCHER: job (0, 0, 22) finished
12:09:17 DISPATCHER: register_result: lock acquired
12:09:17 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:09:17 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07386205747529, 'num_filters_1': 74, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.14540772979791725, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 75, 'num_filters_3': 45, 'num_filters_4': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0013646803964713094, 'info': {'data02': 0.0013646803964713094, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07386205747529, 'num_filters_1': 74, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.14540772979791725, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 75, 'num_filters_3': 45, 'num_filters_4': 67}"}}
exception: None

12:09:17 job_callback for (0, 0, 22) started
12:09:17 DISPATCHER: Trying to submit another job.
12:09:17 job_callback for (0, 0, 22) got condition
12:09:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:09:17 HBMASTER: Trying to run another job!
12:09:17 job_callback for (0, 0, 22) finished
12:09:17 start sampling a new configuration.
12:09:17 done sampling a new configuration.
12:09:17 HBMASTER: schedule new run for iteration 0
12:09:17 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
12:09:17 HBMASTER: submitting job (0, 0, 23) to dispatcher
12:09:17 DISPATCHER: trying to submit job (0, 0, 23)
12:09:17 DISPATCHER: trying to notify the job_runner thread.
12:09:17 HBMASTER: job (0, 0, 23) submitted to dispatcher
12:09:17 DISPATCHER: Trying to submit another job.
12:09:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:09:17 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:09:17 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:09:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:09:17 WORKER: start processing job (0, 0, 23)
12:09:17 WORKER: args: ()
12:09:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013677848913348318, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.04242399105566995}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:09:32 DISPATCHER: Starting worker discovery
12:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:32 DISPATCHER: Finished worker discovery
12:10:06 WORKER: done with job (0, 0, 23), trying to register it.
12:10:06 WORKER: registered result for job (0, 0, 23) with dispatcher
12:10:06 DISPATCHER: job (0, 0, 23) finished
12:10:06 DISPATCHER: register_result: lock acquired
12:10:06 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:10:06 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013677848913348318, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.04242399105566995}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44866619309799216, 'info': {'data02': 0.44866619309799216, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013677848913348318, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.04242399105566995}"}}
exception: None

12:10:06 job_callback for (0, 0, 23) started
12:10:06 DISPATCHER: Trying to submit another job.
12:10:06 job_callback for (0, 0, 23) got condition
12:10:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:10:06 HBMASTER: Trying to run another job!
12:10:06 job_callback for (0, 0, 23) finished
12:10:06 start sampling a new configuration.
12:10:06 done sampling a new configuration.
12:10:06 HBMASTER: schedule new run for iteration 0
12:10:06 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
12:10:06 HBMASTER: submitting job (0, 0, 24) to dispatcher
12:10:06 DISPATCHER: trying to submit job (0, 0, 24)
12:10:06 DISPATCHER: trying to notify the job_runner thread.
12:10:06 HBMASTER: job (0, 0, 24) submitted to dispatcher
12:10:06 DISPATCHER: Trying to submit another job.
12:10:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:10:06 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:10:06 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:10:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:10:06 WORKER: start processing job (0, 0, 24)
12:10:06 WORKER: args: ()
12:10:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01909323897850004, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.15980583878729585}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:10:32 DISPATCHER: Starting worker discovery
12:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:32 DISPATCHER: Finished worker discovery
12:10:55 WORKER: done with job (0, 0, 24), trying to register it.
12:10:55 WORKER: registered result for job (0, 0, 24) with dispatcher
12:10:55 DISPATCHER: job (0, 0, 24) finished
12:10:55 DISPATCHER: register_result: lock acquired
12:10:55 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:10:55 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01909323897850004, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.15980583878729585}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3990969538365329, 'info': {'data02': 0.3990969538365329, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01909323897850004, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.15980583878729585}"}}
exception: None

12:10:55 job_callback for (0, 0, 24) started
12:10:55 DISPATCHER: Trying to submit another job.
12:10:55 job_callback for (0, 0, 24) got condition
12:10:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:10:55 HBMASTER: Trying to run another job!
12:10:55 job_callback for (0, 0, 24) finished
12:10:55 start sampling a new configuration.
12:10:55 done sampling a new configuration.
12:10:55 HBMASTER: schedule new run for iteration 0
12:10:55 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:10:55 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:10:55 DISPATCHER: trying to submit job (0, 0, 25)
12:10:55 DISPATCHER: trying to notify the job_runner thread.
12:10:55 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:10:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:10:55 DISPATCHER: Trying to submit another job.
12:10:55 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:10:55 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:10:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:10:55 WORKER: start processing job (0, 0, 25)
12:10:55 WORKER: args: ()
12:10:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:11:32 DISPATCHER: Starting worker discovery
12:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:32 DISPATCHER: Finished worker discovery
12:11:43 WORKER: done with job (0, 0, 25), trying to register it.
12:11:43 WORKER: registered result for job (0, 0, 25) with dispatcher
12:11:43 DISPATCHER: job (0, 0, 25) finished
12:11:43 DISPATCHER: register_result: lock acquired
12:11:43 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:11:43 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47224292930228823, 'info': {'data02': 0.47224292930228823, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}"}}
exception: None

12:11:43 job_callback for (0, 0, 25) started
12:11:43 DISPATCHER: Trying to submit another job.
12:11:43 job_callback for (0, 0, 25) got condition
12:11:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:11:43 HBMASTER: Trying to run another job!
12:11:43 job_callback for (0, 0, 25) finished
12:11:43 start sampling a new configuration.
12:11:43 done sampling a new configuration.
12:11:43 HBMASTER: schedule new run for iteration 0
12:11:43 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:11:43 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:11:43 DISPATCHER: trying to submit job (0, 0, 26)
12:11:43 DISPATCHER: trying to notify the job_runner thread.
12:11:43 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:11:43 DISPATCHER: Trying to submit another job.
12:11:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:11:43 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:11:43 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:11:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:11:43 WORKER: start processing job (0, 0, 26)
12:11:43 WORKER: args: ()
12:11:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:12:32 WORKER: done with job (0, 0, 26), trying to register it.
12:12:32 WORKER: registered result for job (0, 0, 26) with dispatcher
12:12:32 DISPATCHER: job (0, 0, 26) finished
12:12:32 DISPATCHER: register_result: lock acquired
12:12:32 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:12:32 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5327438195285621, 'info': {'data02': 0.5327438195285621, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}"}}
exception: None

12:12:32 job_callback for (0, 0, 26) started
12:12:32 DISPATCHER: Trying to submit another job.
12:12:32 job_callback for (0, 0, 26) got condition
12:12:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:12:32 HBMASTER: Trying to run another job!
12:12:32 job_callback for (0, 0, 26) finished
12:12:32 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
12:12:32 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
12:12:32 HBMASTER: schedule new run for iteration 0
12:12:32 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
12:12:32 HBMASTER: submitting job (0, 0, 1) to dispatcher
12:12:32 DISPATCHER: trying to submit job (0, 0, 1)
12:12:32 DISPATCHER: trying to notify the job_runner thread.
12:12:32 HBMASTER: job (0, 0, 1) submitted to dispatcher
12:12:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:12:32 DISPATCHER: Trying to submit another job.
12:12:32 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:12:32 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:12:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:12:32 WORKER: start processing job (0, 0, 1)
12:12:32 WORKER: args: ()
12:12:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022136011670559593, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.030866354146433232}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:12:32 DISPATCHER: Starting worker discovery
12:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:32 DISPATCHER: Finished worker discovery
12:13:32 DISPATCHER: Starting worker discovery
12:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:32 DISPATCHER: Finished worker discovery
12:14:32 DISPATCHER: Starting worker discovery
12:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:32 DISPATCHER: Finished worker discovery
12:14:50 WORKER: done with job (0, 0, 1), trying to register it.
12:14:50 WORKER: registered result for job (0, 0, 1) with dispatcher
12:14:50 DISPATCHER: job (0, 0, 1) finished
12:14:50 DISPATCHER: register_result: lock acquired
12:14:50 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:14:50 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022136011670559593, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.030866354146433232}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.48044792778552037, 'info': {'data02': 0.48044792778552037, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022136011670559593, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.030866354146433232}"}}
exception: None

12:14:50 job_callback for (0, 0, 1) started
12:14:50 DISPATCHER: Trying to submit another job.
12:14:50 job_callback for (0, 0, 1) got condition
12:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:50 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:14:50 HBMASTER: Trying to run another job!
12:14:50 job_callback for (0, 0, 1) finished
12:14:50 HBMASTER: schedule new run for iteration 0
12:14:50 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
12:14:50 HBMASTER: submitting job (0, 0, 4) to dispatcher
12:14:50 DISPATCHER: trying to submit job (0, 0, 4)
12:14:50 DISPATCHER: trying to notify the job_runner thread.
12:14:50 HBMASTER: job (0, 0, 4) submitted to dispatcher
12:14:50 DISPATCHER: Trying to submit another job.
12:14:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:50 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:14:50 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:50 WORKER: start processing job (0, 0, 4)
12:14:50 WORKER: args: ()
12:14:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0028448042863654655, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.16348900540596492}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:15:32 DISPATCHER: Starting worker discovery
12:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:32 DISPATCHER: Finished worker discovery
12:16:32 DISPATCHER: Starting worker discovery
12:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:32 DISPATCHER: Finished worker discovery
12:17:09 WORKER: done with job (0, 0, 4), trying to register it.
12:17:09 WORKER: registered result for job (0, 0, 4) with dispatcher
12:17:09 DISPATCHER: job (0, 0, 4) finished
12:17:09 DISPATCHER: register_result: lock acquired
12:17:09 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:17:09 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0028448042863654655, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.16348900540596492}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3556795365000497, 'info': {'data02': 0.3556795365000497, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0028448042863654655, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.16348900540596492}"}}
exception: None

12:17:09 job_callback for (0, 0, 4) started
12:17:09 DISPATCHER: Trying to submit another job.
12:17:09 job_callback for (0, 0, 4) got condition
12:17:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:17:09 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:17:09 HBMASTER: Trying to run another job!
12:17:09 job_callback for (0, 0, 4) finished
12:17:09 HBMASTER: schedule new run for iteration 0
12:17:09 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
12:17:09 HBMASTER: submitting job (0, 0, 5) to dispatcher
12:17:09 DISPATCHER: trying to submit job (0, 0, 5)
12:17:09 DISPATCHER: trying to notify the job_runner thread.
12:17:09 HBMASTER: job (0, 0, 5) submitted to dispatcher
12:17:09 DISPATCHER: Trying to submit another job.
12:17:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:17:09 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:17:09 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:17:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:17:09 WORKER: start processing job (0, 0, 5)
12:17:09 WORKER: args: ()
12:17:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012260367645199177, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.016258097311416194, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 26, 'num_filters_4': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:17:32 DISPATCHER: Starting worker discovery
12:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:32 DISPATCHER: Finished worker discovery
12:18:32 DISPATCHER: Starting worker discovery
12:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:32 DISPATCHER: Finished worker discovery
12:19:28 WORKER: done with job (0, 0, 5), trying to register it.
12:19:28 WORKER: registered result for job (0, 0, 5) with dispatcher
12:19:28 DISPATCHER: job (0, 0, 5) finished
12:19:28 DISPATCHER: register_result: lock acquired
12:19:28 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:19:28 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012260367645199177, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.016258097311416194, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 26, 'num_filters_4': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35864753956910855, 'info': {'data02': 0.35864753956910855, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012260367645199177, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.016258097311416194, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 26, 'num_filters_4': 28}"}}
exception: None

12:19:28 job_callback for (0, 0, 5) started
12:19:28 DISPATCHER: Trying to submit another job.
12:19:28 job_callback for (0, 0, 5) got condition
12:19:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:19:28 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:19:28 HBMASTER: Trying to run another job!
12:19:28 job_callback for (0, 0, 5) finished
12:19:28 HBMASTER: schedule new run for iteration 0
12:19:28 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
12:19:28 HBMASTER: submitting job (0, 0, 7) to dispatcher
12:19:28 DISPATCHER: trying to submit job (0, 0, 7)
12:19:28 DISPATCHER: trying to notify the job_runner thread.
12:19:28 HBMASTER: job (0, 0, 7) submitted to dispatcher
12:19:28 DISPATCHER: Trying to submit another job.
12:19:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:19:28 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:19:28 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:19:28 WORKER: start processing job (0, 0, 7)
12:19:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:19:28 WORKER: args: ()
12:19:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:19:32 DISPATCHER: Starting worker discovery
12:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:32 DISPATCHER: Finished worker discovery
12:20:32 DISPATCHER: Starting worker discovery
12:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:32 DISPATCHER: Finished worker discovery
12:21:32 DISPATCHER: Starting worker discovery
12:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:32 DISPATCHER: Finished worker discovery
12:21:48 WORKER: done with job (0, 0, 7), trying to register it.
12:21:48 WORKER: registered result for job (0, 0, 7) with dispatcher
12:21:48 DISPATCHER: job (0, 0, 7) finished
12:21:48 DISPATCHER: register_result: lock acquired
12:21:48 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:21:48 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49721558227886503, 'info': {'data02': 0.49721558227886503, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}"}}
exception: None

12:21:48 job_callback for (0, 0, 7) started
12:21:48 DISPATCHER: Trying to submit another job.
12:21:48 job_callback for (0, 0, 7) got condition
12:21:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:21:48 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:21:48 HBMASTER: Trying to run another job!
12:21:48 job_callback for (0, 0, 7) finished
12:21:48 HBMASTER: schedule new run for iteration 0
12:21:48 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
12:21:48 HBMASTER: submitting job (0, 0, 15) to dispatcher
12:21:48 DISPATCHER: trying to submit job (0, 0, 15)
12:21:48 DISPATCHER: trying to notify the job_runner thread.
12:21:48 HBMASTER: job (0, 0, 15) submitted to dispatcher
12:21:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:21:48 DISPATCHER: Trying to submit another job.
12:21:48 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:21:48 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:21:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:21:48 WORKER: start processing job (0, 0, 15)
12:21:48 WORKER: args: ()
12:21:48 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002483816288730722, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11162237412771157, 'kernel_size_2': 7, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:22:32 DISPATCHER: Starting worker discovery
12:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:32 DISPATCHER: Finished worker discovery
12:23:32 DISPATCHER: Starting worker discovery
12:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:32 DISPATCHER: Finished worker discovery
12:24:06 WORKER: done with job (0, 0, 15), trying to register it.
12:24:06 WORKER: registered result for job (0, 0, 15) with dispatcher
12:24:06 DISPATCHER: job (0, 0, 15) finished
12:24:06 DISPATCHER: register_result: lock acquired
12:24:06 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:24:06 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002483816288730722, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11162237412771157, 'kernel_size_2': 7, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.379621451106503, 'info': {'data02': 0.379621451106503, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002483816288730722, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11162237412771157, 'kernel_size_2': 7, 'num_filters_2': 105}"}}
exception: None

12:24:06 job_callback for (0, 0, 15) started
12:24:06 DISPATCHER: Trying to submit another job.
12:24:06 job_callback for (0, 0, 15) got condition
12:24:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:24:06 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:24:06 HBMASTER: Trying to run another job!
12:24:06 job_callback for (0, 0, 15) finished
12:24:06 HBMASTER: schedule new run for iteration 0
12:24:06 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
12:24:06 HBMASTER: submitting job (0, 0, 17) to dispatcher
12:24:06 DISPATCHER: trying to submit job (0, 0, 17)
12:24:06 DISPATCHER: trying to notify the job_runner thread.
12:24:06 HBMASTER: job (0, 0, 17) submitted to dispatcher
12:24:06 DISPATCHER: Trying to submit another job.
12:24:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:24:06 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:24:06 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:24:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:24:06 WORKER: start processing job (0, 0, 17)
12:24:06 WORKER: args: ()
12:24:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010074701196545792, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.05037220240813745, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:24:32 DISPATCHER: Starting worker discovery
12:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:32 DISPATCHER: Finished worker discovery
12:25:32 DISPATCHER: Starting worker discovery
12:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:32 DISPATCHER: Finished worker discovery
12:26:24 WORKER: done with job (0, 0, 17), trying to register it.
12:26:24 WORKER: registered result for job (0, 0, 17) with dispatcher
12:26:24 DISPATCHER: job (0, 0, 17) finished
12:26:24 DISPATCHER: register_result: lock acquired
12:26:24 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:26:24 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010074701196545792, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.05037220240813745, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47884397663140876, 'info': {'data02': 0.47884397663140876, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010074701196545792, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.05037220240813745, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 121, 'num_filters_3': 106}"}}
exception: None

12:26:24 job_callback for (0, 0, 17) started
12:26:24 job_callback for (0, 0, 17) got condition
12:26:24 DISPATCHER: Trying to submit another job.
12:26:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:26:24 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:26:24 HBMASTER: Trying to run another job!
12:26:24 job_callback for (0, 0, 17) finished
12:26:24 HBMASTER: schedule new run for iteration 0
12:26:24 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:26:24 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:26:24 DISPATCHER: trying to submit job (0, 0, 18)
12:26:24 DISPATCHER: trying to notify the job_runner thread.
12:26:24 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:26:24 DISPATCHER: Trying to submit another job.
12:26:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:26:24 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:26:24 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:26:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:26:24 WORKER: start processing job (0, 0, 18)
12:26:24 WORKER: args: ()
12:26:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0023829128926230857, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.17678301926078355, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:26:32 DISPATCHER: Starting worker discovery
12:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:32 DISPATCHER: Finished worker discovery
12:27:32 DISPATCHER: Starting worker discovery
12:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:32 DISPATCHER: Finished worker discovery
12:28:32 DISPATCHER: Starting worker discovery
12:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:32 DISPATCHER: Finished worker discovery
12:28:42 WORKER: done with job (0, 0, 18), trying to register it.
12:28:42 WORKER: registered result for job (0, 0, 18) with dispatcher
12:28:42 DISPATCHER: job (0, 0, 18) finished
12:28:42 DISPATCHER: register_result: lock acquired
12:28:42 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:28:42 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0023829128926230857, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.17678301926078355, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3820159137801406, 'info': {'data02': 0.3820159137801406, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0023829128926230857, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.17678301926078355, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 62}"}}
exception: None

12:28:42 job_callback for (0, 0, 18) started
12:28:42 DISPATCHER: Trying to submit another job.
12:28:42 job_callback for (0, 0, 18) got condition
12:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:28:42 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:28:42 HBMASTER: Trying to run another job!
12:28:42 job_callback for (0, 0, 18) finished
12:28:42 HBMASTER: schedule new run for iteration 0
12:28:42 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:28:42 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:28:42 DISPATCHER: trying to submit job (0, 0, 25)
12:28:42 DISPATCHER: trying to notify the job_runner thread.
12:28:42 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:28:42 DISPATCHER: Trying to submit another job.
12:28:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:28:42 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:28:42 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:28:42 WORKER: start processing job (0, 0, 25)
12:28:42 WORKER: args: ()
12:28:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:29:32 DISPATCHER: Starting worker discovery
12:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:32 DISPATCHER: Finished worker discovery
12:30:32 DISPATCHER: Starting worker discovery
12:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:32 DISPATCHER: Finished worker discovery
12:31:01 WORKER: done with job (0, 0, 25), trying to register it.
12:31:01 WORKER: registered result for job (0, 0, 25) with dispatcher
12:31:01 DISPATCHER: job (0, 0, 25) finished
12:31:01 DISPATCHER: register_result: lock acquired
12:31:01 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:31:01 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5179148193834803, 'info': {'data02': 0.5179148193834803, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}"}}
exception: None

12:31:01 job_callback for (0, 0, 25) started
12:31:01 DISPATCHER: Trying to submit another job.
12:31:01 job_callback for (0, 0, 25) got condition
12:31:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:31:01 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:31:01 HBMASTER: Trying to run another job!
12:31:01 job_callback for (0, 0, 25) finished
12:31:01 HBMASTER: schedule new run for iteration 0
12:31:01 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:31:01 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:31:01 DISPATCHER: trying to submit job (0, 0, 26)
12:31:01 DISPATCHER: trying to notify the job_runner thread.
12:31:01 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:31:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:31:01 DISPATCHER: Trying to submit another job.
12:31:01 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:31:01 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:31:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:31:01 WORKER: start processing job (0, 0, 26)
12:31:01 WORKER: args: ()
12:31:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:31:32 DISPATCHER: Starting worker discovery
12:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:32 DISPATCHER: Finished worker discovery
12:32:32 DISPATCHER: Starting worker discovery
12:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:32 DISPATCHER: Finished worker discovery
12:33:18 WORKER: done with job (0, 0, 26), trying to register it.
12:33:18 WORKER: registered result for job (0, 0, 26) with dispatcher
12:33:18 DISPATCHER: job (0, 0, 26) finished
12:33:18 DISPATCHER: register_result: lock acquired
12:33:18 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:33:18 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6875954273613323, 'info': {'data02': 0.6875954273613323, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}"}}
exception: None

12:33:18 job_callback for (0, 0, 26) started
12:33:18 DISPATCHER: Trying to submit another job.
12:33:18 job_callback for (0, 0, 26) got condition
12:33:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:33:18 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:33:18 HBMASTER: Trying to run another job!
12:33:18 job_callback for (0, 0, 26) finished
12:33:18 ITERATION: Advancing config (0, 0, 7) to next budget 400.000000
12:33:18 ITERATION: Advancing config (0, 0, 25) to next budget 400.000000
12:33:18 ITERATION: Advancing config (0, 0, 26) to next budget 400.000000
12:33:18 HBMASTER: schedule new run for iteration 0
12:33:18 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
12:33:18 HBMASTER: submitting job (0, 0, 7) to dispatcher
12:33:18 DISPATCHER: trying to submit job (0, 0, 7)
12:33:18 DISPATCHER: trying to notify the job_runner thread.
12:33:18 HBMASTER: job (0, 0, 7) submitted to dispatcher
12:33:18 DISPATCHER: Trying to submit another job.
12:33:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:33:18 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:33:18 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:33:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:33:18 WORKER: start processing job (0, 0, 7)
12:33:18 WORKER: args: ()
12:33:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}, 'budget': 400.0, 'working_directory': '.'}
12:33:32 DISPATCHER: Starting worker discovery
12:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:32 DISPATCHER: Finished worker discovery
12:34:32 DISPATCHER: Starting worker discovery
12:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:32 DISPATCHER: Finished worker discovery
12:35:32 DISPATCHER: Starting worker discovery
12:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:32 DISPATCHER: Finished worker discovery
12:36:32 DISPATCHER: Starting worker discovery
12:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:32 DISPATCHER: Finished worker discovery
12:37:32 DISPATCHER: Starting worker discovery
12:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:32 DISPATCHER: Finished worker discovery
12:38:32 DISPATCHER: Starting worker discovery
12:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:32 DISPATCHER: Finished worker discovery
12:39:32 DISPATCHER: Starting worker discovery
12:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:32 DISPATCHER: Finished worker discovery
12:40:10 WORKER: done with job (0, 0, 7), trying to register it.
12:40:10 WORKER: registered result for job (0, 0, 7) with dispatcher
12:40:10 DISPATCHER: job (0, 0, 7) finished
12:40:10 DISPATCHER: register_result: lock acquired
12:40:10 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:40:10 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.436847501584084, 'info': {'data02': 0.436847501584084, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005101783950838028, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.025965015648254087}"}}
exception: None

12:40:10 job_callback for (0, 0, 7) started
12:40:10 DISPATCHER: Trying to submit another job.
12:40:10 job_callback for (0, 0, 7) got condition
12:40:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:40:10 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:40:10 HBMASTER: Trying to run another job!
12:40:10 job_callback for (0, 0, 7) finished
12:40:10 HBMASTER: schedule new run for iteration 0
12:40:10 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:40:10 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:40:10 DISPATCHER: trying to submit job (0, 0, 25)
12:40:10 DISPATCHER: trying to notify the job_runner thread.
12:40:10 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:40:10 DISPATCHER: Trying to submit another job.
12:40:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:40:10 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:40:10 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:40:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:40:10 WORKER: start processing job (0, 0, 25)
12:40:10 WORKER: args: ()
12:40:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}, 'budget': 400.0, 'working_directory': '.'}
12:40:32 DISPATCHER: Starting worker discovery
12:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:32 DISPATCHER: Finished worker discovery
12:41:32 DISPATCHER: Starting worker discovery
12:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:32 DISPATCHER: Finished worker discovery
12:42:32 DISPATCHER: Starting worker discovery
12:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:32 DISPATCHER: Finished worker discovery
12:43:32 DISPATCHER: Starting worker discovery
12:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:32 DISPATCHER: Finished worker discovery
12:44:32 DISPATCHER: Starting worker discovery
12:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:32 DISPATCHER: Finished worker discovery
12:45:32 DISPATCHER: Starting worker discovery
12:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:32 DISPATCHER: Finished worker discovery
12:46:32 DISPATCHER: Starting worker discovery
12:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:32 DISPATCHER: Finished worker discovery
12:46:57 WORKER: done with job (0, 0, 25), trying to register it.
12:46:57 WORKER: registered result for job (0, 0, 25) with dispatcher
12:46:57 DISPATCHER: job (0, 0, 25) finished
12:46:57 DISPATCHER: register_result: lock acquired
12:46:57 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:46:57 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4540694837985302, 'info': {'data02': 0.4540694837985302, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00851997753423406, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.012234688169480963, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 31, 'num_filters_4': 64}"}}
exception: None

12:46:57 job_callback for (0, 0, 25) started
12:46:57 job_callback for (0, 0, 25) got condition
12:46:57 DISPATCHER: Trying to submit another job.
12:46:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:46:57 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:46:57 HBMASTER: Trying to run another job!
12:46:57 job_callback for (0, 0, 25) finished
12:46:57 HBMASTER: schedule new run for iteration 0
12:46:57 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:46:57 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:46:57 DISPATCHER: trying to submit job (0, 0, 26)
12:46:57 DISPATCHER: trying to notify the job_runner thread.
12:46:57 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:46:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:46:57 DISPATCHER: Trying to submit another job.
12:46:57 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:46:57 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:46:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:46:57 WORKER: start processing job (0, 0, 26)
12:46:57 WORKER: args: ()
12:46:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 400.0, 'working_directory': '.'}
12:47:32 DISPATCHER: Starting worker discovery
12:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:32 DISPATCHER: Finished worker discovery
12:48:32 DISPATCHER: Starting worker discovery
12:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:32 DISPATCHER: Finished worker discovery
12:49:32 DISPATCHER: Starting worker discovery
12:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:32 DISPATCHER: Finished worker discovery
12:50:32 DISPATCHER: Starting worker discovery
12:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:32 DISPATCHER: Finished worker discovery
12:51:32 DISPATCHER: Starting worker discovery
12:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:32 DISPATCHER: Finished worker discovery
12:52:32 DISPATCHER: Starting worker discovery
12:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:32 DISPATCHER: Finished worker discovery
12:53:32 DISPATCHER: Starting worker discovery
12:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:32 DISPATCHER: Finished worker discovery
12:53:43 WORKER: done with job (0, 0, 26), trying to register it.
12:53:43 WORKER: registered result for job (0, 0, 26) with dispatcher
12:53:43 DISPATCHER: job (0, 0, 26) finished
12:53:43 DISPATCHER: register_result: lock acquired
12:53:43 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
12:53:43 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6037145269434524, 'info': {'data02': 0.6037145269434524, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}"}}
exception: None

12:53:43 job_callback for (0, 0, 26) started
12:53:43 job_callback for (0, 0, 26) got condition
12:53:43 DISPATCHER: Trying to submit another job.
12:53:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:53:43 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:53:43 HBMASTER: Trying to run another job!
12:53:43 job_callback for (0, 0, 26) finished
12:53:43 ITERATION: Advancing config (0, 0, 26) to next budget 1200.000000
12:53:43 HBMASTER: schedule new run for iteration 0
12:53:43 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:53:43 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:53:43 DISPATCHER: trying to submit job (0, 0, 26)
12:53:43 DISPATCHER: trying to notify the job_runner thread.
12:53:43 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:53:43 DISPATCHER: Trying to submit another job.
12:53:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:53:43 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
12:53:43 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
12:53:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:53:43 WORKER: start processing job (0, 0, 26)
12:53:43 WORKER: args: ()
12:53:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 1200.0, 'working_directory': '.'}
12:54:32 DISPATCHER: Starting worker discovery
12:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:32 DISPATCHER: Finished worker discovery
12:55:32 DISPATCHER: Starting worker discovery
12:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:32 DISPATCHER: Finished worker discovery
12:56:32 DISPATCHER: Starting worker discovery
12:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:32 DISPATCHER: Finished worker discovery
12:57:32 DISPATCHER: Starting worker discovery
12:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:32 DISPATCHER: Finished worker discovery
12:58:32 DISPATCHER: Starting worker discovery
12:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:32 DISPATCHER: Finished worker discovery
12:59:32 DISPATCHER: Starting worker discovery
12:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:32 DISPATCHER: Finished worker discovery
13:00:32 DISPATCHER: Starting worker discovery
13:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:32 DISPATCHER: Finished worker discovery
13:01:32 DISPATCHER: Starting worker discovery
13:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:32 DISPATCHER: Finished worker discovery
13:02:32 DISPATCHER: Starting worker discovery
13:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:32 DISPATCHER: Finished worker discovery
13:03:32 DISPATCHER: Starting worker discovery
13:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:32 DISPATCHER: Finished worker discovery
13:04:32 DISPATCHER: Starting worker discovery
13:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:32 DISPATCHER: Finished worker discovery
13:05:32 DISPATCHER: Starting worker discovery
13:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:32 DISPATCHER: Finished worker discovery
13:06:32 DISPATCHER: Starting worker discovery
13:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:32 DISPATCHER: Finished worker discovery
13:07:32 DISPATCHER: Starting worker discovery
13:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:32 DISPATCHER: Finished worker discovery
13:08:32 DISPATCHER: Starting worker discovery
13:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:32 DISPATCHER: Finished worker discovery
13:09:32 DISPATCHER: Starting worker discovery
13:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:32 DISPATCHER: Finished worker discovery
13:10:32 DISPATCHER: Starting worker discovery
13:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:32 DISPATCHER: Finished worker discovery
13:11:32 DISPATCHER: Starting worker discovery
13:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:32 DISPATCHER: Finished worker discovery
13:12:32 DISPATCHER: Starting worker discovery
13:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:32 DISPATCHER: Finished worker discovery
13:13:32 DISPATCHER: Starting worker discovery
13:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:32 DISPATCHER: Finished worker discovery
13:13:54 WORKER: done with job (0, 0, 26), trying to register it.
13:13:54 WORKER: registered result for job (0, 0, 26) with dispatcher
13:13:54 DISPATCHER: job (0, 0, 26) finished
13:13:54 DISPATCHER: register_result: lock acquired
13:13:54 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:13:54 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5131927787168602, 'info': {'data02': 0.5131927787168602, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002731484985677088, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.030575496842379903, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 110, 'num_filters_4': 66}"}}
exception: None

13:13:54 job_callback for (0, 0, 26) started
13:13:54 DISPATCHER: Trying to submit another job.
13:13:54 job_callback for (0, 0, 26) got condition
13:13:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:13:54 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:13:54 HBMASTER: Trying to run another job!
13:13:54 job_callback for (0, 0, 26) finished
13:13:54 start sampling a new configuration.
13:13:54 done sampling a new configuration.
13:13:54 HBMASTER: schedule new run for iteration 1
13:13:54 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
13:13:54 HBMASTER: submitting job (1, 0, 0) to dispatcher
13:13:54 DISPATCHER: trying to submit job (1, 0, 0)
13:13:54 DISPATCHER: trying to notify the job_runner thread.
13:13:54 HBMASTER: job (1, 0, 0) submitted to dispatcher
13:13:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:13:54 DISPATCHER: Trying to submit another job.
13:13:54 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:13:54 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:13:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:13:54 WORKER: start processing job (1, 0, 0)
13:13:54 WORKER: args: ()
13:13:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003946405817442204, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.0872005979260266}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:14:32 DISPATCHER: Starting worker discovery
13:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:32 DISPATCHER: Finished worker discovery
13:15:32 DISPATCHER: Starting worker discovery
13:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:32 DISPATCHER: Finished worker discovery
13:16:12 WORKER: done with job (1, 0, 0), trying to register it.
13:16:12 WORKER: registered result for job (1, 0, 0) with dispatcher
13:16:12 DISPATCHER: job (1, 0, 0) finished
13:16:12 DISPATCHER: register_result: lock acquired
13:16:12 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:16:12 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003946405817442204, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.0872005979260266}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41846287238927626, 'info': {'data02': 0.41846287238927626, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003946405817442204, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.0872005979260266}"}}
exception: None

13:16:12 job_callback for (1, 0, 0) started
13:16:12 DISPATCHER: Trying to submit another job.
13:16:12 job_callback for (1, 0, 0) got condition
13:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:16:12 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:16:12 HBMASTER: Trying to run another job!
13:16:12 job_callback for (1, 0, 0) finished
13:16:12 start sampling a new configuration.
13:16:12 done sampling a new configuration.
13:16:12 HBMASTER: schedule new run for iteration 1
13:16:12 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
13:16:12 HBMASTER: submitting job (1, 0, 1) to dispatcher
13:16:12 DISPATCHER: trying to submit job (1, 0, 1)
13:16:12 DISPATCHER: trying to notify the job_runner thread.
13:16:12 HBMASTER: job (1, 0, 1) submitted to dispatcher
13:16:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:16:12 DISPATCHER: Trying to submit another job.
13:16:12 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:16:12 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:16:12 WORKER: start processing job (1, 0, 1)
13:16:12 WORKER: args: ()
13:16:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.056043423265721905, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.01906486896034988}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:16:32 DISPATCHER: Starting worker discovery
13:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:32 DISPATCHER: Finished worker discovery
13:17:32 DISPATCHER: Starting worker discovery
13:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:32 DISPATCHER: Finished worker discovery
13:18:32 WORKER: done with job (1, 0, 1), trying to register it.
13:18:32 WORKER: registered result for job (1, 0, 1) with dispatcher
13:18:32 DISPATCHER: job (1, 0, 1) finished
13:18:32 DISPATCHER: register_result: lock acquired
13:18:32 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:18:32 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.056043423265721905, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.01906486896034988}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32108291484615437, 'info': {'data02': 0.32108291484615437, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.056043423265721905, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.01906486896034988}"}}
exception: None

13:18:32 job_callback for (1, 0, 1) started
13:18:32 job_callback for (1, 0, 1) got condition
13:18:32 DISPATCHER: Trying to submit another job.
13:18:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:18:32 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:18:32 HBMASTER: Trying to run another job!
13:18:32 job_callback for (1, 0, 1) finished
13:18:32 start sampling a new configuration.
13:18:32 done sampling a new configuration.
13:18:32 HBMASTER: schedule new run for iteration 1
13:18:32 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
13:18:32 HBMASTER: submitting job (1, 0, 2) to dispatcher
13:18:32 DISPATCHER: trying to submit job (1, 0, 2)
13:18:32 DISPATCHER: trying to notify the job_runner thread.
13:18:32 HBMASTER: job (1, 0, 2) submitted to dispatcher
13:18:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:18:32 DISPATCHER: Trying to submit another job.
13:18:32 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:18:32 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:18:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:18:32 WORKER: start processing job (1, 0, 2)
13:18:32 WORKER: args: ()
13:18:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012678607351736034, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.02289547600396256, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 113, 'num_filters_3': 27, 'num_filters_4': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:18:32 DISPATCHER: Starting worker discovery
13:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:32 DISPATCHER: Finished worker discovery
13:19:32 DISPATCHER: Starting worker discovery
13:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:32 DISPATCHER: Finished worker discovery
13:20:32 DISPATCHER: Starting worker discovery
13:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:32 DISPATCHER: Finished worker discovery
13:20:50 WORKER: done with job (1, 0, 2), trying to register it.
13:20:50 WORKER: registered result for job (1, 0, 2) with dispatcher
13:20:50 DISPATCHER: job (1, 0, 2) finished
13:20:50 DISPATCHER: register_result: lock acquired
13:20:50 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:20:50 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012678607351736034, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.02289547600396256, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 113, 'num_filters_3': 27, 'num_filters_4': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36410858994969064, 'info': {'data02': 0.36410858994969064, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012678607351736034, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.02289547600396256, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 113, 'num_filters_3': 27, 'num_filters_4': 89}"}}
exception: None

13:20:50 job_callback for (1, 0, 2) started
13:20:50 DISPATCHER: Trying to submit another job.
13:20:50 job_callback for (1, 0, 2) got condition
13:20:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:20:50 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:20:50 HBMASTER: Trying to run another job!
13:20:50 job_callback for (1, 0, 2) finished
13:20:50 start sampling a new configuration.
13:20:50 done sampling a new configuration.
13:20:50 HBMASTER: schedule new run for iteration 1
13:20:50 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
13:20:50 HBMASTER: submitting job (1, 0, 3) to dispatcher
13:20:50 DISPATCHER: trying to submit job (1, 0, 3)
13:20:50 DISPATCHER: trying to notify the job_runner thread.
13:20:50 HBMASTER: job (1, 0, 3) submitted to dispatcher
13:20:50 DISPATCHER: Trying to submit another job.
13:20:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:20:50 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:20:50 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:20:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:20:50 WORKER: start processing job (1, 0, 3)
13:20:50 WORKER: args: ()
13:20:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:21:32 DISPATCHER: Starting worker discovery
13:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:32 DISPATCHER: Finished worker discovery
13:22:32 DISPATCHER: Starting worker discovery
13:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:32 DISPATCHER: Finished worker discovery
13:23:09 WORKER: done with job (1, 0, 3), trying to register it.
13:23:09 WORKER: registered result for job (1, 0, 3) with dispatcher
13:23:09 DISPATCHER: job (1, 0, 3) finished
13:23:09 DISPATCHER: register_result: lock acquired
13:23:09 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:23:09 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4976473322707885, 'info': {'data02': 0.4976473322707885, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}"}}
exception: None

13:23:09 job_callback for (1, 0, 3) started
13:23:09 job_callback for (1, 0, 3) got condition
13:23:09 DISPATCHER: Trying to submit another job.
13:23:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:23:09 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:23:09 HBMASTER: Trying to run another job!
13:23:09 job_callback for (1, 0, 3) finished
13:23:09 start sampling a new configuration.
13:23:09 done sampling a new configuration.
13:23:09 HBMASTER: schedule new run for iteration 1
13:23:09 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
13:23:09 HBMASTER: submitting job (1, 0, 4) to dispatcher
13:23:09 DISPATCHER: trying to submit job (1, 0, 4)
13:23:09 DISPATCHER: trying to notify the job_runner thread.
13:23:09 HBMASTER: job (1, 0, 4) submitted to dispatcher
13:23:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:23:09 DISPATCHER: Trying to submit another job.
13:23:09 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:23:09 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:23:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:23:09 WORKER: start processing job (1, 0, 4)
13:23:09 WORKER: args: ()
13:23:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01735814448465516, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0977790645793461}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:23:32 DISPATCHER: Starting worker discovery
13:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:32 DISPATCHER: Finished worker discovery
13:24:32 DISPATCHER: Starting worker discovery
13:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:32 DISPATCHER: Finished worker discovery
13:25:27 WORKER: done with job (1, 0, 4), trying to register it.
13:25:27 WORKER: registered result for job (1, 0, 4) with dispatcher
13:25:27 DISPATCHER: job (1, 0, 4) finished
13:25:27 DISPATCHER: register_result: lock acquired
13:25:27 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:25:27 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01735814448465516, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0977790645793461}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33352408158558916, 'info': {'data02': 0.33352408158558916, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01735814448465516, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0977790645793461}"}}
exception: None

13:25:27 job_callback for (1, 0, 4) started
13:25:27 DISPATCHER: Trying to submit another job.
13:25:27 job_callback for (1, 0, 4) got condition
13:25:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:25:27 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:25:27 HBMASTER: Trying to run another job!
13:25:27 job_callback for (1, 0, 4) finished
13:25:27 start sampling a new configuration.
13:25:27 done sampling a new configuration.
13:25:27 HBMASTER: schedule new run for iteration 1
13:25:27 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
13:25:27 HBMASTER: submitting job (1, 0, 5) to dispatcher
13:25:27 DISPATCHER: trying to submit job (1, 0, 5)
13:25:27 DISPATCHER: trying to notify the job_runner thread.
13:25:27 HBMASTER: job (1, 0, 5) submitted to dispatcher
13:25:27 DISPATCHER: Trying to submit another job.
13:25:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:25:27 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:25:27 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:25:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:25:27 WORKER: start processing job (1, 0, 5)
13:25:27 WORKER: args: ()
13:25:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011957657446529347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.013344471017675996}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:25:32 DISPATCHER: Starting worker discovery
13:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:32 DISPATCHER: Finished worker discovery
13:26:32 DISPATCHER: Starting worker discovery
13:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:32 DISPATCHER: Finished worker discovery
13:27:32 DISPATCHER: Starting worker discovery
13:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:32 DISPATCHER: Finished worker discovery
13:27:45 WORKER: done with job (1, 0, 5), trying to register it.
13:27:45 WORKER: registered result for job (1, 0, 5) with dispatcher
13:27:45 DISPATCHER: job (1, 0, 5) finished
13:27:45 DISPATCHER: register_result: lock acquired
13:27:45 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:27:45 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011957657446529347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.013344471017675996}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4670265183478539, 'info': {'data02': 0.4670265183478539, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011957657446529347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.013344471017675996}"}}
exception: None

13:27:45 job_callback for (1, 0, 5) started
13:27:45 job_callback for (1, 0, 5) got condition
13:27:45 DISPATCHER: Trying to submit another job.
13:27:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:27:45 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:27:45 HBMASTER: Trying to run another job!
13:27:45 job_callback for (1, 0, 5) finished
13:27:45 start sampling a new configuration.
13:27:45 done sampling a new configuration.
13:27:45 HBMASTER: schedule new run for iteration 1
13:27:45 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
13:27:45 HBMASTER: submitting job (1, 0, 6) to dispatcher
13:27:45 DISPATCHER: trying to submit job (1, 0, 6)
13:27:45 DISPATCHER: trying to notify the job_runner thread.
13:27:45 HBMASTER: job (1, 0, 6) submitted to dispatcher
13:27:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:27:45 DISPATCHER: Trying to submit another job.
13:27:45 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:27:45 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:27:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:27:45 WORKER: start processing job (1, 0, 6)
13:27:45 WORKER: args: ()
13:27:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015777987325150886, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.06847995605690929, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 76}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:28:32 DISPATCHER: Starting worker discovery
13:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:32 DISPATCHER: Finished worker discovery
13:29:32 DISPATCHER: Starting worker discovery
13:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:32 DISPATCHER: Finished worker discovery
13:30:03 WORKER: done with job (1, 0, 6), trying to register it.
13:30:03 WORKER: registered result for job (1, 0, 6) with dispatcher
13:30:03 DISPATCHER: job (1, 0, 6) finished
13:30:03 DISPATCHER: register_result: lock acquired
13:30:03 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:30:03 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015777987325150886, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.06847995605690929, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 76}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5132539891502725, 'info': {'data02': 0.5132539891502725, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015777987325150886, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.06847995605690929, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 76}"}}
exception: None

13:30:03 job_callback for (1, 0, 6) started
13:30:03 job_callback for (1, 0, 6) got condition
13:30:03 DISPATCHER: Trying to submit another job.
13:30:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:30:03 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:30:03 HBMASTER: Trying to run another job!
13:30:03 job_callback for (1, 0, 6) finished
13:30:03 start sampling a new configuration.
13:30:04 done sampling a new configuration.
13:30:04 HBMASTER: schedule new run for iteration 1
13:30:04 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
13:30:04 HBMASTER: submitting job (1, 0, 7) to dispatcher
13:30:04 DISPATCHER: trying to submit job (1, 0, 7)
13:30:04 DISPATCHER: trying to notify the job_runner thread.
13:30:04 HBMASTER: job (1, 0, 7) submitted to dispatcher
13:30:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:30:04 DISPATCHER: Trying to submit another job.
13:30:04 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:30:04 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:30:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:30:04 WORKER: start processing job (1, 0, 7)
13:30:04 WORKER: args: ()
13:30:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.013692075134259636, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.034460523614305426, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:30:32 DISPATCHER: Starting worker discovery
13:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:32 DISPATCHER: Finished worker discovery
13:31:32 DISPATCHER: Starting worker discovery
13:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:32 DISPATCHER: Finished worker discovery
13:32:21 WORKER: done with job (1, 0, 7), trying to register it.
13:32:21 WORKER: registered result for job (1, 0, 7) with dispatcher
13:32:21 DISPATCHER: job (1, 0, 7) finished
13:32:21 DISPATCHER: register_result: lock acquired
13:32:21 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:32:21 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.013692075134259636, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.034460523614305426, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.27226865457702604, 'info': {'data02': 0.27226865457702604, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.013692075134259636, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.034460523614305426, 'kernel_size_2': 7, 'num_filters_2': 32}"}}
exception: None

13:32:21 job_callback for (1, 0, 7) started
13:32:21 DISPATCHER: Trying to submit another job.
13:32:21 job_callback for (1, 0, 7) got condition
13:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:32:21 HBMASTER: Trying to run another job!
13:32:21 job_callback for (1, 0, 7) finished
13:32:21 start sampling a new configuration.
13:32:21 done sampling a new configuration.
13:32:21 HBMASTER: schedule new run for iteration 1
13:32:21 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
13:32:21 HBMASTER: submitting job (1, 0, 8) to dispatcher
13:32:21 DISPATCHER: trying to submit job (1, 0, 8)
13:32:21 DISPATCHER: trying to notify the job_runner thread.
13:32:21 HBMASTER: job (1, 0, 8) submitted to dispatcher
13:32:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:32:21 DISPATCHER: Trying to submit another job.
13:32:21 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:32:21 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:32:21 WORKER: start processing job (1, 0, 8)
13:32:21 WORKER: args: ()
13:32:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009431421771167122, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01650323018712943, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 35, 'num_filters_4': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:32:32 DISPATCHER: Starting worker discovery
13:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:32 DISPATCHER: Finished worker discovery
13:33:32 DISPATCHER: Starting worker discovery
13:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:32 DISPATCHER: Finished worker discovery
13:34:32 DISPATCHER: Starting worker discovery
13:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:32 DISPATCHER: Finished worker discovery
13:34:39 WORKER: done with job (1, 0, 8), trying to register it.
13:34:39 WORKER: registered result for job (1, 0, 8) with dispatcher
13:34:39 DISPATCHER: job (1, 0, 8) finished
13:34:39 DISPATCHER: register_result: lock acquired
13:34:39 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:34:39 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009431421771167122, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01650323018712943, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 35, 'num_filters_4': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.27594262503825395, 'info': {'data02': 0.27594262503825395, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009431421771167122, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.01650323018712943, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 35, 'num_filters_4': 87}"}}
exception: None

13:34:39 job_callback for (1, 0, 8) started
13:34:39 job_callback for (1, 0, 8) got condition
13:34:39 DISPATCHER: Trying to submit another job.
13:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:34:39 HBMASTER: Trying to run another job!
13:34:39 job_callback for (1, 0, 8) finished
13:34:39 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
13:34:39 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
13:34:39 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
13:34:39 HBMASTER: schedule new run for iteration 1
13:34:39 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
13:34:39 HBMASTER: submitting job (1, 0, 3) to dispatcher
13:34:39 DISPATCHER: trying to submit job (1, 0, 3)
13:34:39 DISPATCHER: trying to notify the job_runner thread.
13:34:39 HBMASTER: job (1, 0, 3) submitted to dispatcher
13:34:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:34:39 DISPATCHER: Trying to submit another job.
13:34:39 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:34:39 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:34:39 WORKER: start processing job (1, 0, 3)
13:34:39 WORKER: args: ()
13:34:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}, 'budget': 400.0, 'working_directory': '.'}
13:35:32 DISPATCHER: Starting worker discovery
13:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:32 DISPATCHER: Finished worker discovery
13:36:32 DISPATCHER: Starting worker discovery
13:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:32 DISPATCHER: Finished worker discovery
13:37:32 DISPATCHER: Starting worker discovery
13:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:32 DISPATCHER: Finished worker discovery
13:38:32 DISPATCHER: Starting worker discovery
13:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:32 DISPATCHER: Finished worker discovery
13:39:32 DISPATCHER: Starting worker discovery
13:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:32 DISPATCHER: Finished worker discovery
13:40:32 DISPATCHER: Starting worker discovery
13:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:32 DISPATCHER: Finished worker discovery
13:41:25 WORKER: done with job (1, 0, 3), trying to register it.
13:41:25 WORKER: registered result for job (1, 0, 3) with dispatcher
13:41:25 DISPATCHER: job (1, 0, 3) finished
13:41:25 DISPATCHER: register_result: lock acquired
13:41:25 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:41:25 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6534303715665011, 'info': {'data02': 0.6534303715665011, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}"}}
exception: None

13:41:25 job_callback for (1, 0, 3) started
13:41:25 DISPATCHER: Trying to submit another job.
13:41:25 job_callback for (1, 0, 3) got condition
13:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:41:25 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:41:25 HBMASTER: Trying to run another job!
13:41:25 job_callback for (1, 0, 3) finished
13:41:25 HBMASTER: schedule new run for iteration 1
13:41:25 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
13:41:25 HBMASTER: submitting job (1, 0, 5) to dispatcher
13:41:25 DISPATCHER: trying to submit job (1, 0, 5)
13:41:25 DISPATCHER: trying to notify the job_runner thread.
13:41:25 HBMASTER: job (1, 0, 5) submitted to dispatcher
13:41:25 DISPATCHER: Trying to submit another job.
13:41:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:41:25 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:41:25 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:41:25 WORKER: start processing job (1, 0, 5)
13:41:25 WORKER: args: ()
13:41:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011957657446529347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.013344471017675996}, 'budget': 400.0, 'working_directory': '.'}
13:41:32 DISPATCHER: Starting worker discovery
13:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:32 DISPATCHER: Finished worker discovery
13:42:32 DISPATCHER: Starting worker discovery
13:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:32 DISPATCHER: Finished worker discovery
13:43:32 DISPATCHER: Starting worker discovery
13:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:32 DISPATCHER: Finished worker discovery
13:44:32 DISPATCHER: Starting worker discovery
13:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:32 DISPATCHER: Finished worker discovery
13:45:32 DISPATCHER: Starting worker discovery
13:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:32 DISPATCHER: Finished worker discovery
13:46:32 DISPATCHER: Starting worker discovery
13:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:32 DISPATCHER: Finished worker discovery
13:47:32 DISPATCHER: Starting worker discovery
13:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:32 DISPATCHER: Finished worker discovery
13:48:12 WORKER: done with job (1, 0, 5), trying to register it.
13:48:12 WORKER: registered result for job (1, 0, 5) with dispatcher
13:48:12 DISPATCHER: job (1, 0, 5) finished
13:48:12 DISPATCHER: register_result: lock acquired
13:48:12 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:48:12 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011957657446529347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.013344471017675996}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4806633160797054, 'info': {'data02': 0.4806633160797054, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011957657446529347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.013344471017675996}"}}
exception: None

13:48:12 job_callback for (1, 0, 5) started
13:48:12 job_callback for (1, 0, 5) got condition
13:48:12 DISPATCHER: Trying to submit another job.
13:48:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:48:12 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:48:12 HBMASTER: Trying to run another job!
13:48:12 job_callback for (1, 0, 5) finished
13:48:12 HBMASTER: schedule new run for iteration 1
13:48:12 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
13:48:12 HBMASTER: submitting job (1, 0, 6) to dispatcher
13:48:12 DISPATCHER: trying to submit job (1, 0, 6)
13:48:12 DISPATCHER: trying to notify the job_runner thread.
13:48:12 HBMASTER: job (1, 0, 6) submitted to dispatcher
13:48:12 DISPATCHER: Trying to submit another job.
13:48:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:48:12 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:48:12 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:48:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:48:12 WORKER: start processing job (1, 0, 6)
13:48:12 WORKER: args: ()
13:48:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015777987325150886, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.06847995605690929, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 76}, 'budget': 400.0, 'working_directory': '.'}
13:48:32 DISPATCHER: Starting worker discovery
13:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:32 DISPATCHER: Finished worker discovery
13:49:32 DISPATCHER: Starting worker discovery
13:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:32 DISPATCHER: Finished worker discovery
13:50:32 DISPATCHER: Starting worker discovery
13:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:32 DISPATCHER: Finished worker discovery
13:51:32 DISPATCHER: Starting worker discovery
13:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:32 DISPATCHER: Finished worker discovery
13:52:32 DISPATCHER: Starting worker discovery
13:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:32 DISPATCHER: Finished worker discovery
13:53:32 DISPATCHER: Starting worker discovery
13:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:32 DISPATCHER: Finished worker discovery
13:54:32 DISPATCHER: Starting worker discovery
13:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:33 DISPATCHER: Finished worker discovery
13:54:58 WORKER: done with job (1, 0, 6), trying to register it.
13:54:58 WORKER: registered result for job (1, 0, 6) with dispatcher
13:54:58 DISPATCHER: job (1, 0, 6) finished
13:54:58 DISPATCHER: register_result: lock acquired
13:54:58 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
13:54:58 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015777987325150886, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.06847995605690929, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 76}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6070352060783143, 'info': {'data02': 0.6070352060783143, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015777987325150886, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.06847995605690929, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 76}"}}
exception: None

13:54:58 job_callback for (1, 0, 6) started
13:54:58 DISPATCHER: Trying to submit another job.
13:54:58 job_callback for (1, 0, 6) got condition
13:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:54:58 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:54:58 HBMASTER: Trying to run another job!
13:54:58 job_callback for (1, 0, 6) finished
13:54:58 ITERATION: Advancing config (1, 0, 3) to next budget 1200.000000
13:54:58 HBMASTER: schedule new run for iteration 1
13:54:58 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
13:54:58 HBMASTER: submitting job (1, 0, 3) to dispatcher
13:54:58 DISPATCHER: trying to submit job (1, 0, 3)
13:54:58 DISPATCHER: trying to notify the job_runner thread.
13:54:58 HBMASTER: job (1, 0, 3) submitted to dispatcher
13:54:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:54:58 DISPATCHER: Trying to submit another job.
13:54:58 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
13:54:58 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
13:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:54:58 WORKER: start processing job (1, 0, 3)
13:54:58 WORKER: args: ()
13:54:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}, 'budget': 1200.0, 'working_directory': '.'}
13:55:33 DISPATCHER: Starting worker discovery
13:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:33 DISPATCHER: Finished worker discovery
13:56:33 DISPATCHER: Starting worker discovery
13:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:33 DISPATCHER: Finished worker discovery
13:57:33 DISPATCHER: Starting worker discovery
13:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:33 DISPATCHER: Finished worker discovery
13:58:33 DISPATCHER: Starting worker discovery
13:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:33 DISPATCHER: Finished worker discovery
13:59:33 DISPATCHER: Starting worker discovery
13:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:33 DISPATCHER: Finished worker discovery
14:00:33 DISPATCHER: Starting worker discovery
14:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:33 DISPATCHER: Finished worker discovery
14:01:33 DISPATCHER: Starting worker discovery
14:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:33 DISPATCHER: Finished worker discovery
14:02:33 DISPATCHER: Starting worker discovery
14:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:33 DISPATCHER: Finished worker discovery
14:03:33 DISPATCHER: Starting worker discovery
14:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:33 DISPATCHER: Finished worker discovery
14:04:33 DISPATCHER: Starting worker discovery
14:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:33 DISPATCHER: Finished worker discovery
14:05:33 DISPATCHER: Starting worker discovery
14:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:33 DISPATCHER: Finished worker discovery
14:06:33 DISPATCHER: Starting worker discovery
14:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:33 DISPATCHER: Finished worker discovery
14:07:33 DISPATCHER: Starting worker discovery
14:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:33 DISPATCHER: Finished worker discovery
14:08:33 DISPATCHER: Starting worker discovery
14:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:33 DISPATCHER: Finished worker discovery
14:09:33 DISPATCHER: Starting worker discovery
14:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:33 DISPATCHER: Finished worker discovery
14:10:33 DISPATCHER: Starting worker discovery
14:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:33 DISPATCHER: Finished worker discovery
14:11:33 DISPATCHER: Starting worker discovery
14:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:33 DISPATCHER: Finished worker discovery
14:12:33 DISPATCHER: Starting worker discovery
14:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:33 DISPATCHER: Finished worker discovery
14:13:33 DISPATCHER: Starting worker discovery
14:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:33 DISPATCHER: Finished worker discovery
14:14:33 DISPATCHER: Starting worker discovery
14:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:33 DISPATCHER: Finished worker discovery
14:15:07 WORKER: done with job (1, 0, 3), trying to register it.
14:15:07 WORKER: registered result for job (1, 0, 3) with dispatcher
14:15:07 DISPATCHER: job (1, 0, 3) finished
14:15:07 DISPATCHER: register_result: lock acquired
14:15:07 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:15:07 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4678269933150954, 'info': {'data02': 0.4678269933150954, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002125116984896351, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.012083421673899352, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 113, 'num_filters_4': 94}"}}
exception: None

14:15:07 job_callback for (1, 0, 3) started
14:15:07 job_callback for (1, 0, 3) got condition
14:15:07 DISPATCHER: Trying to submit another job.
14:15:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:15:07 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:15:07 HBMASTER: Trying to run another job!
14:15:07 job_callback for (1, 0, 3) finished
14:15:07 start sampling a new configuration.
14:15:07 done sampling a new configuration.
14:15:07 HBMASTER: schedule new run for iteration 2
14:15:07 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
14:15:07 HBMASTER: submitting job (2, 0, 0) to dispatcher
14:15:07 DISPATCHER: trying to submit job (2, 0, 0)
14:15:07 DISPATCHER: trying to notify the job_runner thread.
14:15:07 HBMASTER: job (2, 0, 0) submitted to dispatcher
14:15:07 DISPATCHER: Trying to submit another job.
14:15:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:15:07 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:15:07 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:15:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:15:07 WORKER: start processing job (2, 0, 0)
14:15:07 WORKER: args: ()
14:15:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015723081031061782, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.14587816849130217, 'kernel_size_2': 3, 'num_filters_2': 34}, 'budget': 400.0, 'working_directory': '.'}
14:15:33 DISPATCHER: Starting worker discovery
14:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:33 DISPATCHER: Finished worker discovery
14:16:33 DISPATCHER: Starting worker discovery
14:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:33 DISPATCHER: Finished worker discovery
14:17:33 DISPATCHER: Starting worker discovery
14:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:33 DISPATCHER: Finished worker discovery
14:18:33 DISPATCHER: Starting worker discovery
14:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:33 DISPATCHER: Finished worker discovery
14:19:33 DISPATCHER: Starting worker discovery
14:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:33 DISPATCHER: Finished worker discovery
14:20:33 DISPATCHER: Starting worker discovery
14:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:33 DISPATCHER: Finished worker discovery
14:21:33 DISPATCHER: Starting worker discovery
14:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:33 DISPATCHER: Finished worker discovery
14:21:53 WORKER: done with job (2, 0, 0), trying to register it.
14:21:53 WORKER: registered result for job (2, 0, 0) with dispatcher
14:21:53 DISPATCHER: job (2, 0, 0) finished
14:21:53 DISPATCHER: register_result: lock acquired
14:21:53 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:21:53 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015723081031061782, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.14587816849130217, 'kernel_size_2': 3, 'num_filters_2': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.46695202216670384, 'info': {'data02': 0.46695202216670384, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015723081031061782, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.14587816849130217, 'kernel_size_2': 3, 'num_filters_2': 34}"}}
exception: None

14:21:53 job_callback for (2, 0, 0) started
14:21:53 job_callback for (2, 0, 0) got condition
14:21:53 DISPATCHER: Trying to submit another job.
14:21:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:21:53 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:21:53 HBMASTER: Trying to run another job!
14:21:53 job_callback for (2, 0, 0) finished
14:21:53 start sampling a new configuration.
14:21:53 done sampling a new configuration.
14:21:53 HBMASTER: schedule new run for iteration 2
14:21:53 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
14:21:53 HBMASTER: submitting job (2, 0, 1) to dispatcher
14:21:53 DISPATCHER: trying to submit job (2, 0, 1)
14:21:53 DISPATCHER: trying to notify the job_runner thread.
14:21:53 HBMASTER: job (2, 0, 1) submitted to dispatcher
14:21:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:21:53 DISPATCHER: Trying to submit another job.
14:21:53 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:21:53 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:21:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:21:53 WORKER: start processing job (2, 0, 1)
14:21:53 WORKER: args: ()
14:21:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00267739730040158, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.027824919609906875}, 'budget': 400.0, 'working_directory': '.'}
14:22:33 DISPATCHER: Starting worker discovery
14:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:33 DISPATCHER: Finished worker discovery
14:23:33 DISPATCHER: Starting worker discovery
14:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:33 DISPATCHER: Finished worker discovery
14:24:33 DISPATCHER: Starting worker discovery
14:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:33 DISPATCHER: Finished worker discovery
14:25:33 DISPATCHER: Starting worker discovery
14:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:33 DISPATCHER: Finished worker discovery
14:26:33 DISPATCHER: Starting worker discovery
14:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:33 DISPATCHER: Finished worker discovery
14:27:33 DISPATCHER: Starting worker discovery
14:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:33 DISPATCHER: Finished worker discovery
14:28:33 DISPATCHER: Starting worker discovery
14:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:33 DISPATCHER: Finished worker discovery
14:28:43 WORKER: done with job (2, 0, 1), trying to register it.
14:28:43 WORKER: registered result for job (2, 0, 1) with dispatcher
14:28:43 DISPATCHER: job (2, 0, 1) finished
14:28:43 DISPATCHER: register_result: lock acquired
14:28:43 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:28:43 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00267739730040158, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.027824919609906875}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45449461270153335, 'info': {'data02': 0.45449461270153335, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00267739730040158, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.027824919609906875}"}}
exception: None

14:28:43 job_callback for (2, 0, 1) started
14:28:43 DISPATCHER: Trying to submit another job.
14:28:43 job_callback for (2, 0, 1) got condition
14:28:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:28:43 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:28:43 HBMASTER: Trying to run another job!
14:28:43 job_callback for (2, 0, 1) finished
14:28:43 start sampling a new configuration.
14:28:43 done sampling a new configuration.
14:28:43 HBMASTER: schedule new run for iteration 2
14:28:43 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
14:28:43 HBMASTER: submitting job (2, 0, 2) to dispatcher
14:28:43 DISPATCHER: trying to submit job (2, 0, 2)
14:28:43 DISPATCHER: trying to notify the job_runner thread.
14:28:43 HBMASTER: job (2, 0, 2) submitted to dispatcher
14:28:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:28:43 DISPATCHER: Trying to submit another job.
14:28:43 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:28:43 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:28:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:28:43 WORKER: start processing job (2, 0, 2)
14:28:43 WORKER: args: ()
14:28:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.026076899767901843, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01979223516436406, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 36}, 'budget': 400.0, 'working_directory': '.'}
14:29:33 DISPATCHER: Starting worker discovery
14:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:33 DISPATCHER: Finished worker discovery
14:30:33 DISPATCHER: Starting worker discovery
14:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:33 DISPATCHER: Finished worker discovery
14:31:33 DISPATCHER: Starting worker discovery
14:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:33 DISPATCHER: Finished worker discovery
14:32:33 DISPATCHER: Starting worker discovery
14:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:33 DISPATCHER: Finished worker discovery
14:33:33 DISPATCHER: Starting worker discovery
14:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:33 DISPATCHER: Finished worker discovery
14:34:33 DISPATCHER: Starting worker discovery
14:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:33 DISPATCHER: Finished worker discovery
14:35:28 WORKER: done with job (2, 0, 2), trying to register it.
14:35:28 WORKER: registered result for job (2, 0, 2) with dispatcher
14:35:28 DISPATCHER: job (2, 0, 2) finished
14:35:28 DISPATCHER: register_result: lock acquired
14:35:28 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:35:28 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.026076899767901843, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01979223516436406, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 36}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.026076899767901843, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01979223516436406, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 36}"}}
exception: None

14:35:28 job_callback for (2, 0, 2) started
14:35:28 job_callback for (2, 0, 2) got condition
14:35:28 DISPATCHER: Trying to submit another job.
14:35:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:35:28 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:35:28 HBMASTER: Trying to run another job!
14:35:28 job_callback for (2, 0, 2) finished
14:35:28 start sampling a new configuration.
14:35:28 done sampling a new configuration.
14:35:28 HBMASTER: schedule new run for iteration 2
14:35:28 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
14:35:28 HBMASTER: submitting job (2, 0, 3) to dispatcher
14:35:28 DISPATCHER: trying to submit job (2, 0, 3)
14:35:28 DISPATCHER: trying to notify the job_runner thread.
14:35:28 HBMASTER: job (2, 0, 3) submitted to dispatcher
14:35:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:35:28 DISPATCHER: Trying to submit another job.
14:35:28 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:35:28 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:35:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:35:28 WORKER: start processing job (2, 0, 3)
14:35:28 WORKER: args: ()
14:35:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.015095425014402773, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.01760214801719828}, 'budget': 400.0, 'working_directory': '.'}
14:35:33 DISPATCHER: Starting worker discovery
14:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:33 DISPATCHER: Finished worker discovery
14:36:33 DISPATCHER: Starting worker discovery
14:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:33 DISPATCHER: Finished worker discovery
14:37:33 DISPATCHER: Starting worker discovery
14:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:33 DISPATCHER: Finished worker discovery
14:38:33 DISPATCHER: Starting worker discovery
14:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:33 DISPATCHER: Finished worker discovery
14:39:33 DISPATCHER: Starting worker discovery
14:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:33 DISPATCHER: Finished worker discovery
14:40:33 DISPATCHER: Starting worker discovery
14:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:33 DISPATCHER: Finished worker discovery
14:41:33 DISPATCHER: Starting worker discovery
14:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:33 DISPATCHER: Finished worker discovery
14:42:26 WORKER: done with job (2, 0, 3), trying to register it.
14:42:26 WORKER: registered result for job (2, 0, 3) with dispatcher
14:42:26 DISPATCHER: job (2, 0, 3) finished
14:42:26 DISPATCHER: register_result: lock acquired
14:42:26 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:42:26 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.015095425014402773, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.01760214801719828}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.30525933567120844, 'info': {'data02': 0.30525933567120844, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.015095425014402773, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.01760214801719828}"}}
exception: None

14:42:26 job_callback for (2, 0, 3) started
14:42:26 job_callback for (2, 0, 3) got condition
14:42:26 DISPATCHER: Trying to submit another job.
14:42:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:26 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:42:26 HBMASTER: Trying to run another job!
14:42:26 job_callback for (2, 0, 3) finished
14:42:26 start sampling a new configuration.
14:42:26 done sampling a new configuration.
14:42:26 HBMASTER: schedule new run for iteration 2
14:42:26 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
14:42:26 HBMASTER: submitting job (2, 0, 4) to dispatcher
14:42:26 DISPATCHER: trying to submit job (2, 0, 4)
14:42:26 DISPATCHER: trying to notify the job_runner thread.
14:42:26 HBMASTER: job (2, 0, 4) submitted to dispatcher
14:42:26 DISPATCHER: Trying to submit another job.
14:42:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:26 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:42:26 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:42:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:26 WORKER: start processing job (2, 0, 4)
14:42:26 WORKER: args: ()
14:42:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006798470694584894, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.029091445053365608, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 28, 'num_filters_4': 52, 'num_filters_5': 47}, 'budget': 400.0, 'working_directory': '.'}
14:42:33 DISPATCHER: Starting worker discovery
14:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:33 DISPATCHER: Finished worker discovery
14:43:33 DISPATCHER: Starting worker discovery
14:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:33 DISPATCHER: Finished worker discovery
14:44:33 DISPATCHER: Starting worker discovery
14:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:33 DISPATCHER: Finished worker discovery
14:45:33 DISPATCHER: Starting worker discovery
14:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:33 DISPATCHER: Finished worker discovery
14:46:33 DISPATCHER: Starting worker discovery
14:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:33 DISPATCHER: Finished worker discovery
14:47:33 DISPATCHER: Starting worker discovery
14:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:33 DISPATCHER: Finished worker discovery
14:48:33 DISPATCHER: Starting worker discovery
14:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:33 DISPATCHER: Finished worker discovery
14:49:12 WORKER: done with job (2, 0, 4), trying to register it.
14:49:12 WORKER: registered result for job (2, 0, 4) with dispatcher
14:49:12 DISPATCHER: job (2, 0, 4) finished
14:49:12 DISPATCHER: register_result: lock acquired
14:49:12 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:49:12 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006798470694584894, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.029091445053365608, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 28, 'num_filters_4': 52, 'num_filters_5': 47}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2116867914798531, 'info': {'data02': 0.2116867914798531, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006798470694584894, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.029091445053365608, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 28, 'num_filters_4': 52, 'num_filters_5': 47}"}}
exception: None

14:49:12 job_callback for (2, 0, 4) started
14:49:12 DISPATCHER: Trying to submit another job.
14:49:12 job_callback for (2, 0, 4) got condition
14:49:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:49:12 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:49:12 HBMASTER: Trying to run another job!
14:49:12 job_callback for (2, 0, 4) finished
14:49:12 start sampling a new configuration.
14:49:12 done sampling a new configuration.
14:49:12 HBMASTER: schedule new run for iteration 2
14:49:12 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
14:49:12 HBMASTER: submitting job (2, 0, 5) to dispatcher
14:49:12 DISPATCHER: trying to submit job (2, 0, 5)
14:49:12 DISPATCHER: trying to notify the job_runner thread.
14:49:12 HBMASTER: job (2, 0, 5) submitted to dispatcher
14:49:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:49:12 DISPATCHER: Trying to submit another job.
14:49:12 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:49:12 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:49:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:49:12 WORKER: start processing job (2, 0, 5)
14:49:12 WORKER: args: ()
14:49:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03344568654998946, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.024757802352923207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 40, 'num_filters_4': 51}, 'budget': 400.0, 'working_directory': '.'}
14:49:33 DISPATCHER: Starting worker discovery
14:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:33 DISPATCHER: Finished worker discovery
14:50:33 DISPATCHER: Starting worker discovery
14:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:33 DISPATCHER: Finished worker discovery
14:51:33 DISPATCHER: Starting worker discovery
14:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:33 DISPATCHER: Finished worker discovery
14:52:33 DISPATCHER: Starting worker discovery
14:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:33 DISPATCHER: Finished worker discovery
14:53:33 DISPATCHER: Starting worker discovery
14:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:33 DISPATCHER: Finished worker discovery
14:54:33 DISPATCHER: Starting worker discovery
14:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:33 DISPATCHER: Finished worker discovery
14:55:33 DISPATCHER: Starting worker discovery
14:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:33 DISPATCHER: Finished worker discovery
14:55:59 WORKER: done with job (2, 0, 5), trying to register it.
14:55:59 WORKER: registered result for job (2, 0, 5) with dispatcher
14:55:59 DISPATCHER: job (2, 0, 5) finished
14:55:59 DISPATCHER: register_result: lock acquired
14:55:59 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
14:55:59 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03344568654998946, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.024757802352923207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 40, 'num_filters_4': 51}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03344568654998946, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.024757802352923207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 40, 'num_filters_4': 51}"}}
exception: None

14:55:59 job_callback for (2, 0, 5) started
14:55:59 DISPATCHER: Trying to submit another job.
14:55:59 job_callback for (2, 0, 5) got condition
14:55:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:55:59 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:55:59 HBMASTER: Trying to run another job!
14:55:59 job_callback for (2, 0, 5) finished
14:55:59 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
14:55:59 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
14:55:59 HBMASTER: schedule new run for iteration 2
14:55:59 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
14:55:59 HBMASTER: submitting job (2, 0, 0) to dispatcher
14:55:59 DISPATCHER: trying to submit job (2, 0, 0)
14:55:59 DISPATCHER: trying to notify the job_runner thread.
14:55:59 HBMASTER: job (2, 0, 0) submitted to dispatcher
14:55:59 DISPATCHER: Trying to submit another job.
14:55:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:55:59 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
14:55:59 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
14:55:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:55:59 WORKER: start processing job (2, 0, 0)
14:55:59 WORKER: args: ()
14:55:59 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015723081031061782, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.14587816849130217, 'kernel_size_2': 3, 'num_filters_2': 34}, 'budget': 1200.0, 'working_directory': '.'}
14:56:33 DISPATCHER: Starting worker discovery
14:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:33 DISPATCHER: Finished worker discovery
14:57:33 DISPATCHER: Starting worker discovery
14:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:33 DISPATCHER: Finished worker discovery
14:58:33 DISPATCHER: Starting worker discovery
14:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:33 DISPATCHER: Finished worker discovery
14:59:33 DISPATCHER: Starting worker discovery
14:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:33 DISPATCHER: Finished worker discovery
15:00:33 DISPATCHER: Starting worker discovery
15:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:33 DISPATCHER: Finished worker discovery
15:01:33 DISPATCHER: Starting worker discovery
15:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:33 DISPATCHER: Finished worker discovery
15:02:33 DISPATCHER: Starting worker discovery
15:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:33 DISPATCHER: Finished worker discovery
15:03:33 DISPATCHER: Starting worker discovery
15:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:33 DISPATCHER: Finished worker discovery
15:04:33 DISPATCHER: Starting worker discovery
15:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:33 DISPATCHER: Finished worker discovery
15:05:33 DISPATCHER: Starting worker discovery
15:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:33 DISPATCHER: Finished worker discovery
15:06:33 DISPATCHER: Starting worker discovery
15:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:33 DISPATCHER: Finished worker discovery
15:07:33 DISPATCHER: Starting worker discovery
15:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:33 DISPATCHER: Finished worker discovery
15:08:33 DISPATCHER: Starting worker discovery
15:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:33 DISPATCHER: Finished worker discovery
15:09:33 DISPATCHER: Starting worker discovery
15:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:33 DISPATCHER: Finished worker discovery
15:10:33 DISPATCHER: Starting worker discovery
15:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:33 DISPATCHER: Finished worker discovery
15:11:33 DISPATCHER: Starting worker discovery
15:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:33 DISPATCHER: Finished worker discovery
15:12:33 DISPATCHER: Starting worker discovery
15:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:33 DISPATCHER: Finished worker discovery
15:13:33 DISPATCHER: Starting worker discovery
15:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:33 DISPATCHER: Finished worker discovery
15:14:33 DISPATCHER: Starting worker discovery
15:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:33 DISPATCHER: Finished worker discovery
15:15:33 DISPATCHER: Starting worker discovery
15:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:33 DISPATCHER: Finished worker discovery
15:16:06 WORKER: done with job (2, 0, 0), trying to register it.
15:16:06 WORKER: registered result for job (2, 0, 0) with dispatcher
15:16:06 DISPATCHER: job (2, 0, 0) finished
15:16:06 DISPATCHER: register_result: lock acquired
15:16:06 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:16:06 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015723081031061782, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.14587816849130217, 'kernel_size_2': 3, 'num_filters_2': 34}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.353885219931511, 'info': {'data02': 0.353885219931511, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015723081031061782, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.14587816849130217, 'kernel_size_2': 3, 'num_filters_2': 34}"}}
exception: None

15:16:06 job_callback for (2, 0, 0) started
15:16:06 DISPATCHER: Trying to submit another job.
15:16:06 job_callback for (2, 0, 0) got condition
15:16:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:16:06 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:16:06 HBMASTER: Trying to run another job!
15:16:06 job_callback for (2, 0, 0) finished
15:16:06 HBMASTER: schedule new run for iteration 2
15:16:06 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
15:16:06 HBMASTER: submitting job (2, 0, 1) to dispatcher
15:16:06 DISPATCHER: trying to submit job (2, 0, 1)
15:16:06 DISPATCHER: trying to notify the job_runner thread.
15:16:06 HBMASTER: job (2, 0, 1) submitted to dispatcher
15:16:06 DISPATCHER: Trying to submit another job.
15:16:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:16:06 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:16:06 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:16:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:16:06 WORKER: start processing job (2, 0, 1)
15:16:06 WORKER: args: ()
15:16:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00267739730040158, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.027824919609906875}, 'budget': 1200.0, 'working_directory': '.'}
15:16:33 DISPATCHER: Starting worker discovery
15:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:33 DISPATCHER: Finished worker discovery
15:17:33 DISPATCHER: Starting worker discovery
15:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:33 DISPATCHER: Finished worker discovery
15:18:33 DISPATCHER: Starting worker discovery
15:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:33 DISPATCHER: Finished worker discovery
15:19:33 DISPATCHER: Starting worker discovery
15:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:33 DISPATCHER: Finished worker discovery
15:20:33 DISPATCHER: Starting worker discovery
15:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:33 DISPATCHER: Finished worker discovery
15:21:33 DISPATCHER: Starting worker discovery
15:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:33 DISPATCHER: Finished worker discovery
15:22:33 DISPATCHER: Starting worker discovery
15:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:33 DISPATCHER: Finished worker discovery
15:23:33 DISPATCHER: Starting worker discovery
15:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:33 DISPATCHER: Finished worker discovery
15:24:33 DISPATCHER: Starting worker discovery
15:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:33 DISPATCHER: Finished worker discovery
15:25:33 DISPATCHER: Starting worker discovery
15:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:33 DISPATCHER: Finished worker discovery
15:26:33 DISPATCHER: Starting worker discovery
15:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:33 DISPATCHER: Finished worker discovery
15:27:33 DISPATCHER: Starting worker discovery
15:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:33 DISPATCHER: Finished worker discovery
15:28:33 DISPATCHER: Starting worker discovery
15:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:33 DISPATCHER: Finished worker discovery
15:29:33 DISPATCHER: Starting worker discovery
15:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:33 DISPATCHER: Finished worker discovery
15:30:33 DISPATCHER: Starting worker discovery
15:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:33 DISPATCHER: Finished worker discovery
15:31:33 DISPATCHER: Starting worker discovery
15:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:33 DISPATCHER: Finished worker discovery
15:32:33 DISPATCHER: Starting worker discovery
15:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:33 DISPATCHER: Finished worker discovery
15:33:33 DISPATCHER: Starting worker discovery
15:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:33 DISPATCHER: Finished worker discovery
15:34:33 DISPATCHER: Starting worker discovery
15:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:33 DISPATCHER: Finished worker discovery
15:35:33 DISPATCHER: Starting worker discovery
15:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:33 DISPATCHER: Finished worker discovery
15:36:28 WORKER: done with job (2, 0, 1), trying to register it.
15:36:28 WORKER: registered result for job (2, 0, 1) with dispatcher
15:36:28 DISPATCHER: job (2, 0, 1) finished
15:36:28 DISPATCHER: register_result: lock acquired
15:36:28 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:36:28 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00267739730040158, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.027824919609906875}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.42561818232430515, 'info': {'data02': 0.42561818232430515, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00267739730040158, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.027824919609906875}"}}
exception: None

15:36:28 job_callback for (2, 0, 1) started
15:36:28 DISPATCHER: Trying to submit another job.
15:36:28 job_callback for (2, 0, 1) got condition
15:36:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:36:28 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:36:28 HBMASTER: Trying to run another job!
15:36:28 job_callback for (2, 0, 1) finished
15:36:28 start sampling a new configuration.
15:36:28 done sampling a new configuration.
15:36:28 HBMASTER: schedule new run for iteration 3
15:36:28 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
15:36:28 HBMASTER: submitting job (3, 0, 0) to dispatcher
15:36:28 DISPATCHER: trying to submit job (3, 0, 0)
15:36:28 DISPATCHER: trying to notify the job_runner thread.
15:36:28 HBMASTER: job (3, 0, 0) submitted to dispatcher
15:36:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:36:28 DISPATCHER: Trying to submit another job.
15:36:28 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:36:28 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:36:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:36:28 WORKER: start processing job (3, 0, 0)
15:36:28 WORKER: args: ()
15:36:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0030062903759157512, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.036217493796390374, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 46, 'num_filters_4': 41}, 'budget': 1200.0, 'working_directory': '.'}
15:36:33 DISPATCHER: Starting worker discovery
15:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:33 DISPATCHER: Finished worker discovery
15:37:33 DISPATCHER: Starting worker discovery
15:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:33 DISPATCHER: Finished worker discovery
15:38:33 DISPATCHER: Starting worker discovery
15:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:33 DISPATCHER: Finished worker discovery
15:39:33 DISPATCHER: Starting worker discovery
15:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:33 DISPATCHER: Finished worker discovery
15:40:33 DISPATCHER: Starting worker discovery
15:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:33 DISPATCHER: Finished worker discovery
15:41:33 DISPATCHER: Starting worker discovery
15:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:33 DISPATCHER: Finished worker discovery
15:42:33 DISPATCHER: Starting worker discovery
15:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:33 DISPATCHER: Finished worker discovery
15:43:33 DISPATCHER: Starting worker discovery
15:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:33 DISPATCHER: Finished worker discovery
15:44:33 DISPATCHER: Starting worker discovery
15:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:33 DISPATCHER: Finished worker discovery
15:45:33 DISPATCHER: Starting worker discovery
15:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:33 DISPATCHER: Finished worker discovery
15:46:33 DISPATCHER: Starting worker discovery
15:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:33 DISPATCHER: Finished worker discovery
15:47:33 DISPATCHER: Starting worker discovery
15:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:33 DISPATCHER: Finished worker discovery
15:48:33 DISPATCHER: Starting worker discovery
15:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:33 DISPATCHER: Finished worker discovery
15:49:33 DISPATCHER: Starting worker discovery
15:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:33 DISPATCHER: Finished worker discovery
15:50:33 DISPATCHER: Starting worker discovery
15:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:33 DISPATCHER: Finished worker discovery
15:51:33 DISPATCHER: Starting worker discovery
15:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:33 DISPATCHER: Finished worker discovery
15:52:33 DISPATCHER: Starting worker discovery
15:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:33 DISPATCHER: Finished worker discovery
15:53:33 DISPATCHER: Starting worker discovery
15:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:33 DISPATCHER: Finished worker discovery
15:54:33 DISPATCHER: Starting worker discovery
15:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:33 DISPATCHER: Finished worker discovery
15:55:33 DISPATCHER: Starting worker discovery
15:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:34 DISPATCHER: Finished worker discovery
15:56:34 DISPATCHER: Starting worker discovery
15:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:34 DISPATCHER: Finished worker discovery
15:56:37 WORKER: done with job (3, 0, 0), trying to register it.
15:56:37 WORKER: registered result for job (3, 0, 0) with dispatcher
15:56:37 DISPATCHER: job (3, 0, 0) finished
15:56:37 DISPATCHER: register_result: lock acquired
15:56:37 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
15:56:37 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0030062903759157512, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.036217493796390374, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 46, 'num_filters_4': 41}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4580970953188906, 'info': {'data02': 0.4580970953188906, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0030062903759157512, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.036217493796390374, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 46, 'num_filters_4': 41}"}}
exception: None

15:56:37 job_callback for (3, 0, 0) started
15:56:37 job_callback for (3, 0, 0) got condition
15:56:37 DISPATCHER: Trying to submit another job.
15:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:56:37 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:56:37 HBMASTER: Trying to run another job!
15:56:37 job_callback for (3, 0, 0) finished
15:56:37 start sampling a new configuration.
15:56:37 done sampling a new configuration.
15:56:37 HBMASTER: schedule new run for iteration 3
15:56:37 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
15:56:37 HBMASTER: submitting job (3, 0, 1) to dispatcher
15:56:37 DISPATCHER: trying to submit job (3, 0, 1)
15:56:37 DISPATCHER: trying to notify the job_runner thread.
15:56:37 HBMASTER: job (3, 0, 1) submitted to dispatcher
15:56:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:56:37 DISPATCHER: Trying to submit another job.
15:56:37 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
15:56:37 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
15:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:56:37 WORKER: start processing job (3, 0, 1)
15:56:37 WORKER: args: ()
15:56:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009949519159558233, 'num_filters_1': 108, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.06987479028317463}, 'budget': 1200.0, 'working_directory': '.'}
15:57:34 DISPATCHER: Starting worker discovery
15:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:34 DISPATCHER: Finished worker discovery
15:58:34 DISPATCHER: Starting worker discovery
15:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:34 DISPATCHER: Finished worker discovery
15:59:34 DISPATCHER: Starting worker discovery
15:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:34 DISPATCHER: Finished worker discovery
16:00:34 DISPATCHER: Starting worker discovery
16:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:34 DISPATCHER: Finished worker discovery
16:01:34 DISPATCHER: Starting worker discovery
16:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:34 DISPATCHER: Finished worker discovery
16:02:34 DISPATCHER: Starting worker discovery
16:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:34 DISPATCHER: Finished worker discovery
16:03:34 DISPATCHER: Starting worker discovery
16:03:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:34 DISPATCHER: Finished worker discovery
16:04:34 DISPATCHER: Starting worker discovery
16:04:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:34 DISPATCHER: Finished worker discovery
16:05:34 DISPATCHER: Starting worker discovery
16:05:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:34 DISPATCHER: Finished worker discovery
16:06:34 DISPATCHER: Starting worker discovery
16:06:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:34 DISPATCHER: Finished worker discovery
16:07:34 DISPATCHER: Starting worker discovery
16:07:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:34 DISPATCHER: Finished worker discovery
16:08:34 DISPATCHER: Starting worker discovery
16:08:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:34 DISPATCHER: Finished worker discovery
16:09:34 DISPATCHER: Starting worker discovery
16:09:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:34 DISPATCHER: Finished worker discovery
16:10:34 DISPATCHER: Starting worker discovery
16:10:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:34 DISPATCHER: Finished worker discovery
16:11:34 DISPATCHER: Starting worker discovery
16:11:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:34 DISPATCHER: Finished worker discovery
16:12:34 DISPATCHER: Starting worker discovery
16:12:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:34 DISPATCHER: Finished worker discovery
16:13:34 DISPATCHER: Starting worker discovery
16:13:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:34 DISPATCHER: Finished worker discovery
16:14:34 DISPATCHER: Starting worker discovery
16:14:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:34 DISPATCHER: Finished worker discovery
16:15:34 DISPATCHER: Starting worker discovery
16:15:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:34 DISPATCHER: Finished worker discovery
16:16:34 DISPATCHER: Starting worker discovery
16:16:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:34 DISPATCHER: Finished worker discovery
16:16:48 WORKER: done with job (3, 0, 1), trying to register it.
16:16:48 WORKER: registered result for job (3, 0, 1) with dispatcher
16:16:48 DISPATCHER: job (3, 0, 1) finished
16:16:48 DISPATCHER: register_result: lock acquired
16:16:48 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:16:48 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009949519159558233, 'num_filters_1': 108, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.06987479028317463}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3773371703718794, 'info': {'data02': 0.3773371703718794, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009949519159558233, 'num_filters_1': 108, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.06987479028317463}"}}
exception: None

16:16:48 job_callback for (3, 0, 1) started
16:16:48 DISPATCHER: Trying to submit another job.
16:16:48 job_callback for (3, 0, 1) got condition
16:16:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:16:48 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:16:48 HBMASTER: Trying to run another job!
16:16:48 job_callback for (3, 0, 1) finished
16:16:48 start sampling a new configuration.
16:16:48 done sampling a new configuration.
16:16:48 HBMASTER: schedule new run for iteration 3
16:16:48 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
16:16:48 HBMASTER: submitting job (3, 0, 2) to dispatcher
16:16:48 DISPATCHER: trying to submit job (3, 0, 2)
16:16:48 DISPATCHER: trying to notify the job_runner thread.
16:16:48 HBMASTER: job (3, 0, 2) submitted to dispatcher
16:16:48 DISPATCHER: Trying to submit another job.
16:16:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:16:48 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:16:48 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:16:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:16:48 WORKER: start processing job (3, 0, 2)
16:16:48 WORKER: args: ()
16:16:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006234330738640544, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.040528668414285735}, 'budget': 1200.0, 'working_directory': '.'}
16:17:34 DISPATCHER: Starting worker discovery
16:17:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:34 DISPATCHER: Finished worker discovery
16:18:34 DISPATCHER: Starting worker discovery
16:18:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:34 DISPATCHER: Finished worker discovery
16:19:34 DISPATCHER: Starting worker discovery
16:19:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:34 DISPATCHER: Finished worker discovery
16:20:34 DISPATCHER: Starting worker discovery
16:20:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:34 DISPATCHER: Finished worker discovery
16:21:34 DISPATCHER: Starting worker discovery
16:21:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:34 DISPATCHER: Finished worker discovery
16:22:34 DISPATCHER: Starting worker discovery
16:22:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:34 DISPATCHER: Finished worker discovery
16:23:34 DISPATCHER: Starting worker discovery
16:23:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:34 DISPATCHER: Finished worker discovery
16:24:34 DISPATCHER: Starting worker discovery
16:24:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:34 DISPATCHER: Finished worker discovery
16:25:34 DISPATCHER: Starting worker discovery
16:25:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:34 DISPATCHER: Finished worker discovery
16:26:34 DISPATCHER: Starting worker discovery
16:26:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:34 DISPATCHER: Finished worker discovery
16:27:34 DISPATCHER: Starting worker discovery
16:27:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:34 DISPATCHER: Finished worker discovery
16:28:34 DISPATCHER: Starting worker discovery
16:28:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:34 DISPATCHER: Finished worker discovery
16:29:34 DISPATCHER: Starting worker discovery
16:29:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:34 DISPATCHER: Finished worker discovery
16:30:34 DISPATCHER: Starting worker discovery
16:30:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:34 DISPATCHER: Finished worker discovery
16:31:34 DISPATCHER: Starting worker discovery
16:31:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:34 DISPATCHER: Finished worker discovery
16:32:34 DISPATCHER: Starting worker discovery
16:32:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:34 DISPATCHER: Finished worker discovery
16:33:34 DISPATCHER: Starting worker discovery
16:33:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:34 DISPATCHER: Finished worker discovery
16:34:34 DISPATCHER: Starting worker discovery
16:34:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:34 DISPATCHER: Finished worker discovery
16:35:34 DISPATCHER: Starting worker discovery
16:35:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:34 DISPATCHER: Finished worker discovery
16:36:34 DISPATCHER: Starting worker discovery
16:36:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:34 DISPATCHER: Finished worker discovery
16:37:04 WORKER: done with job (3, 0, 2), trying to register it.
16:37:04 WORKER: registered result for job (3, 0, 2) with dispatcher
16:37:04 DISPATCHER: job (3, 0, 2) finished
16:37:04 DISPATCHER: register_result: lock acquired
16:37:04 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:37:04 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006234330738640544, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.040528668414285735}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.38499364243537587, 'info': {'data02': 0.38499364243537587, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006234330738640544, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.040528668414285735}"}}
exception: None

16:37:04 job_callback for (3, 0, 2) started
16:37:04 DISPATCHER: Trying to submit another job.
16:37:04 job_callback for (3, 0, 2) got condition
16:37:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:37:04 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:37:04 HBMASTER: Trying to run another job!
16:37:04 job_callback for (3, 0, 2) finished
16:37:04 start sampling a new configuration.
16:37:04 done sampling a new configuration.
16:37:04 HBMASTER: schedule new run for iteration 3
16:37:04 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
16:37:04 HBMASTER: submitting job (3, 0, 3) to dispatcher
16:37:04 DISPATCHER: trying to submit job (3, 0, 3)
16:37:04 DISPATCHER: trying to notify the job_runner thread.
16:37:04 HBMASTER: job (3, 0, 3) submitted to dispatcher
16:37:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:37:04 DISPATCHER: Trying to submit another job.
16:37:04 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:37:04 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:37:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:37:04 WORKER: start processing job (3, 0, 3)
16:37:04 WORKER: args: ()
16:37:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009842357973477182, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07797579456306024, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 102, 'num_filters_3': 31, 'num_filters_4': 71, 'num_filters_5': 41}, 'budget': 1200.0, 'working_directory': '.'}
16:37:34 DISPATCHER: Starting worker discovery
16:37:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:34 DISPATCHER: Finished worker discovery
16:38:34 DISPATCHER: Starting worker discovery
16:38:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:34 DISPATCHER: Finished worker discovery
16:39:34 DISPATCHER: Starting worker discovery
16:39:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:34 DISPATCHER: Finished worker discovery
16:40:34 DISPATCHER: Starting worker discovery
16:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:34 DISPATCHER: Finished worker discovery
16:41:34 DISPATCHER: Starting worker discovery
16:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:34 DISPATCHER: Finished worker discovery
16:42:34 DISPATCHER: Starting worker discovery
16:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:34 DISPATCHER: Finished worker discovery
16:43:34 DISPATCHER: Starting worker discovery
16:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:34 DISPATCHER: Finished worker discovery
16:44:34 DISPATCHER: Starting worker discovery
16:44:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:34 DISPATCHER: Finished worker discovery
16:45:34 DISPATCHER: Starting worker discovery
16:45:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:34 DISPATCHER: Finished worker discovery
16:46:34 DISPATCHER: Starting worker discovery
16:46:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:34 DISPATCHER: Finished worker discovery
16:47:34 DISPATCHER: Starting worker discovery
16:47:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:34 DISPATCHER: Finished worker discovery
16:48:34 DISPATCHER: Starting worker discovery
16:48:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:34 DISPATCHER: Finished worker discovery
16:49:34 DISPATCHER: Starting worker discovery
16:49:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:34 DISPATCHER: Finished worker discovery
16:50:34 DISPATCHER: Starting worker discovery
16:50:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:34 DISPATCHER: Finished worker discovery
16:51:34 DISPATCHER: Starting worker discovery
16:51:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:34 DISPATCHER: Finished worker discovery
16:52:34 DISPATCHER: Starting worker discovery
16:52:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:34 DISPATCHER: Finished worker discovery
16:53:34 DISPATCHER: Starting worker discovery
16:53:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:34 DISPATCHER: Finished worker discovery
16:54:34 DISPATCHER: Starting worker discovery
16:54:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:34 DISPATCHER: Finished worker discovery
16:55:34 DISPATCHER: Starting worker discovery
16:55:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:34 DISPATCHER: Finished worker discovery
16:56:34 DISPATCHER: Starting worker discovery
16:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:34 DISPATCHER: Finished worker discovery
16:57:13 WORKER: done with job (3, 0, 3), trying to register it.
16:57:13 WORKER: registered result for job (3, 0, 3) with dispatcher
16:57:13 DISPATCHER: job (3, 0, 3) finished
16:57:13 DISPATCHER: register_result: lock acquired
16:57:13 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:57:13 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009842357973477182, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07797579456306024, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 102, 'num_filters_3': 31, 'num_filters_4': 71, 'num_filters_5': 41}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009842357973477182, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07797579456306024, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 102, 'num_filters_3': 31, 'num_filters_4': 71, 'num_filters_5': 41}"}}
exception: None

16:57:13 job_callback for (3, 0, 3) started
16:57:13 DISPATCHER: Trying to submit another job.
16:57:13 job_callback for (3, 0, 3) got condition
16:57:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:13 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:57:13 HBMASTER: Trying to run another job!
16:57:13 job_callback for (3, 0, 3) finished
16:57:13 start sampling a new configuration.
16:57:13 done sampling a new configuration.
16:57:13 HBMASTER: schedule new run for iteration 4
16:57:13 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
16:57:13 HBMASTER: submitting job (4, 0, 0) to dispatcher
16:57:13 DISPATCHER: trying to submit job (4, 0, 0)
16:57:13 DISPATCHER: trying to notify the job_runner thread.
16:57:13 HBMASTER: job (4, 0, 0) submitted to dispatcher
16:57:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:13 DISPATCHER: Trying to submit another job.
16:57:13 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:57:13 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:57:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:13 WORKER: start processing job (4, 0, 0)
16:57:13 WORKER: args: ()
16:57:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020509711324021213, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.09663907078469193, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:57:34 DISPATCHER: Starting worker discovery
16:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:34 DISPATCHER: Finished worker discovery
16:58:02 WORKER: done with job (4, 0, 0), trying to register it.
16:58:02 WORKER: registered result for job (4, 0, 0) with dispatcher
16:58:02 DISPATCHER: job (4, 0, 0) finished
16:58:02 DISPATCHER: register_result: lock acquired
16:58:02 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:58:02 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020509711324021213, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.09663907078469193, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5295002840466259, 'info': {'data02': 0.5295002840466259, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020509711324021213, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.09663907078469193, 'kernel_size_2': 7, 'num_filters_2': 100}"}}
exception: None

16:58:02 job_callback for (4, 0, 0) started
16:58:02 job_callback for (4, 0, 0) got condition
16:58:02 DISPATCHER: Trying to submit another job.
16:58:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:58:02 HBMASTER: Trying to run another job!
16:58:02 job_callback for (4, 0, 0) finished
16:58:02 start sampling a new configuration.
16:58:02 done sampling a new configuration.
16:58:02 HBMASTER: schedule new run for iteration 4
16:58:02 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
16:58:02 HBMASTER: submitting job (4, 0, 1) to dispatcher
16:58:02 DISPATCHER: trying to submit job (4, 0, 1)
16:58:02 DISPATCHER: trying to notify the job_runner thread.
16:58:02 HBMASTER: job (4, 0, 1) submitted to dispatcher
16:58:02 DISPATCHER: Trying to submit another job.
16:58:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:58:02 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:58:02 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:58:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:58:02 WORKER: start processing job (4, 0, 1)
16:58:02 WORKER: args: ()
16:58:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0018200053096112737, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.03221971002219043, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:58:34 DISPATCHER: Starting worker discovery
16:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:34 DISPATCHER: Finished worker discovery
16:58:51 WORKER: done with job (4, 0, 1), trying to register it.
16:58:51 WORKER: registered result for job (4, 0, 1) with dispatcher
16:58:51 DISPATCHER: job (4, 0, 1) finished
16:58:51 DISPATCHER: register_result: lock acquired
16:58:51 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:58:51 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0018200053096112737, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.03221971002219043, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45353766263574913, 'info': {'data02': 0.45353766263574913, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0018200053096112737, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.03221971002219043, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 36}"}}
exception: None

16:58:51 job_callback for (4, 0, 1) started
16:58:51 DISPATCHER: Trying to submit another job.
16:58:51 job_callback for (4, 0, 1) got condition
16:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:58:51 HBMASTER: Trying to run another job!
16:58:51 job_callback for (4, 0, 1) finished
16:58:51 start sampling a new configuration.
16:58:51 done sampling a new configuration.
16:58:51 HBMASTER: schedule new run for iteration 4
16:58:51 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
16:58:51 HBMASTER: submitting job (4, 0, 2) to dispatcher
16:58:51 DISPATCHER: trying to submit job (4, 0, 2)
16:58:51 DISPATCHER: trying to notify the job_runner thread.
16:58:51 HBMASTER: job (4, 0, 2) submitted to dispatcher
16:58:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:58:51 DISPATCHER: Trying to submit another job.
16:58:51 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:58:51 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:58:51 WORKER: start processing job (4, 0, 2)
16:58:51 WORKER: args: ()
16:58:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04761651832163288, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.0391188676400119}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:59:34 DISPATCHER: Starting worker discovery
16:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:34 DISPATCHER: Finished worker discovery
16:59:40 WORKER: done with job (4, 0, 2), trying to register it.
16:59:40 WORKER: registered result for job (4, 0, 2) with dispatcher
16:59:40 DISPATCHER: job (4, 0, 2) finished
16:59:40 DISPATCHER: register_result: lock acquired
16:59:40 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
16:59:40 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04761651832163288, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.0391188676400119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41460421444110557, 'info': {'data02': 0.41460421444110557, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04761651832163288, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.0391188676400119}"}}
exception: None

16:59:40 job_callback for (4, 0, 2) started
16:59:40 job_callback for (4, 0, 2) got condition
16:59:40 DISPATCHER: Trying to submit another job.
16:59:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:59:40 HBMASTER: Trying to run another job!
16:59:40 job_callback for (4, 0, 2) finished
16:59:40 start sampling a new configuration.
16:59:40 done sampling a new configuration.
16:59:40 HBMASTER: schedule new run for iteration 4
16:59:40 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
16:59:40 HBMASTER: submitting job (4, 0, 3) to dispatcher
16:59:40 DISPATCHER: trying to submit job (4, 0, 3)
16:59:40 DISPATCHER: trying to notify the job_runner thread.
16:59:40 HBMASTER: job (4, 0, 3) submitted to dispatcher
16:59:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:59:40 DISPATCHER: Trying to submit another job.
16:59:40 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
16:59:40 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
16:59:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:59:40 WORKER: start processing job (4, 0, 3)
16:59:40 WORKER: args: ()
16:59:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008328142451838596, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.048958836732934816, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:00:29 WORKER: done with job (4, 0, 3), trying to register it.
17:00:29 WORKER: registered result for job (4, 0, 3) with dispatcher
17:00:29 DISPATCHER: job (4, 0, 3) finished
17:00:29 DISPATCHER: register_result: lock acquired
17:00:29 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:00:29 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008328142451838596, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.048958836732934816, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5539202231195054, 'info': {'data02': 0.5539202231195054, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008328142451838596, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.048958836732934816, 'kernel_size_2': 7, 'num_filters_2': 32}"}}
exception: None

17:00:29 job_callback for (4, 0, 3) started
17:00:29 job_callback for (4, 0, 3) got condition
17:00:29 DISPATCHER: Trying to submit another job.
17:00:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:00:29 HBMASTER: Trying to run another job!
17:00:29 job_callback for (4, 0, 3) finished
17:00:29 start sampling a new configuration.
17:00:29 done sampling a new configuration.
17:00:29 HBMASTER: schedule new run for iteration 4
17:00:29 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
17:00:29 HBMASTER: submitting job (4, 0, 4) to dispatcher
17:00:29 DISPATCHER: trying to submit job (4, 0, 4)
17:00:29 DISPATCHER: trying to notify the job_runner thread.
17:00:29 HBMASTER: job (4, 0, 4) submitted to dispatcher
17:00:29 DISPATCHER: Trying to submit another job.
17:00:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:00:29 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:00:29 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:00:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:00:29 WORKER: start processing job (4, 0, 4)
17:00:29 WORKER: args: ()
17:00:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014985817937961403, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.02962517842038085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:00:34 DISPATCHER: Starting worker discovery
17:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:34 DISPATCHER: Finished worker discovery
17:01:18 WORKER: done with job (4, 0, 4), trying to register it.
17:01:18 WORKER: registered result for job (4, 0, 4) with dispatcher
17:01:18 DISPATCHER: job (4, 0, 4) finished
17:01:18 DISPATCHER: register_result: lock acquired
17:01:18 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:01:18 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014985817937961403, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.02962517842038085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4623507718492557, 'info': {'data02': 0.4623507718492557, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014985817937961403, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.02962517842038085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 39}"}}
exception: None

17:01:18 job_callback for (4, 0, 4) started
17:01:18 DISPATCHER: Trying to submit another job.
17:01:18 job_callback for (4, 0, 4) got condition
17:01:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:01:18 HBMASTER: Trying to run another job!
17:01:18 job_callback for (4, 0, 4) finished
17:01:18 start sampling a new configuration.
17:01:18 done sampling a new configuration.
17:01:18 HBMASTER: schedule new run for iteration 4
17:01:18 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
17:01:18 HBMASTER: submitting job (4, 0, 5) to dispatcher
17:01:18 DISPATCHER: trying to submit job (4, 0, 5)
17:01:18 DISPATCHER: trying to notify the job_runner thread.
17:01:18 HBMASTER: job (4, 0, 5) submitted to dispatcher
17:01:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:01:18 DISPATCHER: Trying to submit another job.
17:01:18 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:01:18 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:01:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:01:18 WORKER: start processing job (4, 0, 5)
17:01:18 WORKER: args: ()
17:01:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:01:34 DISPATCHER: Starting worker discovery
17:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:34 DISPATCHER: Finished worker discovery
17:02:07 WORKER: done with job (4, 0, 5), trying to register it.
17:02:07 WORKER: registered result for job (4, 0, 5) with dispatcher
17:02:07 DISPATCHER: job (4, 0, 5) finished
17:02:07 DISPATCHER: register_result: lock acquired
17:02:07 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:02:07 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6769317372862993, 'info': {'data02': 0.6769317372862993, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}"}}
exception: None

17:02:07 job_callback for (4, 0, 5) started
17:02:07 job_callback for (4, 0, 5) got condition
17:02:07 DISPATCHER: Trying to submit another job.
17:02:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:02:07 HBMASTER: Trying to run another job!
17:02:07 job_callback for (4, 0, 5) finished
17:02:07 start sampling a new configuration.
17:02:07 done sampling a new configuration.
17:02:07 HBMASTER: schedule new run for iteration 4
17:02:07 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
17:02:07 HBMASTER: submitting job (4, 0, 6) to dispatcher
17:02:07 DISPATCHER: trying to submit job (4, 0, 6)
17:02:07 DISPATCHER: trying to notify the job_runner thread.
17:02:07 HBMASTER: job (4, 0, 6) submitted to dispatcher
17:02:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:02:07 DISPATCHER: Trying to submit another job.
17:02:07 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:02:07 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:02:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:02:07 WORKER: start processing job (4, 0, 6)
17:02:07 WORKER: args: ()
17:02:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07709959195161237, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.027164858084320027, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 72, 'num_filters_3': 46, 'num_filters_4': 26, 'num_filters_5': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:02:34 DISPATCHER: Starting worker discovery
17:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:34 DISPATCHER: Finished worker discovery
17:02:55 WORKER: done with job (4, 0, 6), trying to register it.
17:02:55 WORKER: registered result for job (4, 0, 6) with dispatcher
17:02:55 DISPATCHER: job (4, 0, 6) finished
17:02:55 DISPATCHER: register_result: lock acquired
17:02:55 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:02:55 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07709959195161237, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.027164858084320027, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 72, 'num_filters_3': 46, 'num_filters_4': 26, 'num_filters_5': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07709959195161237, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.027164858084320027, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 72, 'num_filters_3': 46, 'num_filters_4': 26, 'num_filters_5': 67}"}}
exception: None

17:02:55 job_callback for (4, 0, 6) started
17:02:55 job_callback for (4, 0, 6) got condition
17:02:55 DISPATCHER: Trying to submit another job.
17:02:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:02:55 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.676932





17:02:55 HBMASTER: Trying to run another job!
17:02:55 job_callback for (4, 0, 6) finished
17:02:55 start sampling a new configuration.
17:02:55 best_vector: [0, 0, 0.2582599655627397, 0.8336502697562518, 0.1430762551944887, 1, 0.18204484467624216, 0.9167028429539188, 0, 0, 2, 1, 0.1500777179979263, 0.12215669848057714, 0.17506968853907875, 0.6178901523867909], 2.6732745788081377e-29, 0.0003740730592836609, -0.00016889826650144332
17:02:55 done sampling a new configuration.
17:02:55 HBMASTER: schedule new run for iteration 4
17:02:55 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
17:02:55 HBMASTER: submitting job (4, 0, 7) to dispatcher
17:02:55 DISPATCHER: trying to submit job (4, 0, 7)
17:02:55 DISPATCHER: trying to notify the job_runner thread.
17:02:55 HBMASTER: job (4, 0, 7) submitted to dispatcher
17:02:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:02:55 DISPATCHER: Trying to submit another job.
17:02:55 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:02:55 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:02:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:02:55 WORKER: start processing job (4, 0, 7)
17:02:55 WORKER: args: ()
17:02:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003284883193085111, 'num_filters_1': 90, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.1558324489550542}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:03:34 DISPATCHER: Starting worker discovery
17:03:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:34 DISPATCHER: Finished worker discovery
17:03:45 WORKER: done with job (4, 0, 7), trying to register it.
17:03:45 WORKER: registered result for job (4, 0, 7) with dispatcher
17:03:45 DISPATCHER: job (4, 0, 7) finished
17:03:45 DISPATCHER: register_result: lock acquired
17:03:45 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:03:45 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003284883193085111, 'num_filters_1': 90, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.1558324489550542}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3906245045081207, 'info': {'data02': 0.3906245045081207, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003284883193085111, 'num_filters_1': 90, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.1558324489550542}"}}
exception: None

17:03:45 job_callback for (4, 0, 7) started
17:03:45 job_callback for (4, 0, 7) got condition
17:03:45 DISPATCHER: Trying to submit another job.
17:03:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:45 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.676932





17:03:45 HBMASTER: Trying to run another job!
17:03:45 job_callback for (4, 0, 7) finished
17:03:45 start sampling a new configuration.
17:03:45 done sampling a new configuration.
17:03:45 HBMASTER: schedule new run for iteration 4
17:03:45 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
17:03:45 HBMASTER: submitting job (4, 0, 8) to dispatcher
17:03:45 DISPATCHER: trying to submit job (4, 0, 8)
17:03:45 DISPATCHER: trying to notify the job_runner thread.
17:03:45 HBMASTER: job (4, 0, 8) submitted to dispatcher
17:03:45 DISPATCHER: Trying to submit another job.
17:03:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:45 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:03:45 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:03:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:45 WORKER: start processing job (4, 0, 8)
17:03:45 WORKER: args: ()
17:03:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04007309754991632, 'num_filters_1': 73, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.023381351364303717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:04:34 WORKER: done with job (4, 0, 8), trying to register it.
17:04:34 WORKER: registered result for job (4, 0, 8) with dispatcher
17:04:34 DISPATCHER: job (4, 0, 8) finished
17:04:34 DISPATCHER: register_result: lock acquired
17:04:34 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:04:34 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04007309754991632, 'num_filters_1': 73, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.023381351364303717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3270775494336018, 'info': {'data02': 0.3270775494336018, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04007309754991632, 'num_filters_1': 73, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.023381351364303717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 17}"}}
exception: None

17:04:34 job_callback for (4, 0, 8) started
17:04:34 DISPATCHER: Trying to submit another job.
17:04:34 job_callback for (4, 0, 8) got condition
17:04:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:04:34 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.676932





17:04:34 HBMASTER: Trying to run another job!
17:04:34 job_callback for (4, 0, 8) finished
17:04:34 start sampling a new configuration.
17:04:34 done sampling a new configuration.
17:04:34 HBMASTER: schedule new run for iteration 4
17:04:34 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
17:04:34 HBMASTER: submitting job (4, 0, 9) to dispatcher
17:04:34 DISPATCHER: trying to submit job (4, 0, 9)
17:04:34 DISPATCHER: trying to notify the job_runner thread.
17:04:34 HBMASTER: job (4, 0, 9) submitted to dispatcher
17:04:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:04:34 DISPATCHER: Trying to submit another job.
17:04:34 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:04:34 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:04:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:04:34 WORKER: start processing job (4, 0, 9)
17:04:34 WORKER: args: ()
17:04:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.009242157152588219, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.04305334360964124}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:04:34 DISPATCHER: Starting worker discovery
17:04:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:34 DISPATCHER: Finished worker discovery
17:05:22 WORKER: done with job (4, 0, 9), trying to register it.
17:05:22 WORKER: registered result for job (4, 0, 9) with dispatcher
17:05:22 DISPATCHER: job (4, 0, 9) finished
17:05:22 DISPATCHER: register_result: lock acquired
17:05:22 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:05:22 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.009242157152588219, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.04305334360964124}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30719426921422266, 'info': {'data02': 0.30719426921422266, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.009242157152588219, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.04305334360964124}"}}
exception: None

17:05:22 job_callback for (4, 0, 9) started
17:05:22 job_callback for (4, 0, 9) got condition
17:05:22 DISPATCHER: Trying to submit another job.
17:05:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:05:22 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.676932





17:05:22 HBMASTER: Trying to run another job!
17:05:22 job_callback for (4, 0, 9) finished
17:05:22 start sampling a new configuration.
17:05:22 done sampling a new configuration.
17:05:22 HBMASTER: schedule new run for iteration 4
17:05:22 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:05:22 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:05:22 DISPATCHER: trying to submit job (4, 0, 10)
17:05:22 DISPATCHER: trying to notify the job_runner thread.
17:05:22 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:05:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:05:22 DISPATCHER: Trying to submit another job.
17:05:22 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:05:22 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:05:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:05:22 WORKER: start processing job (4, 0, 10)
17:05:22 WORKER: args: ()
17:05:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.025061076854999812, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.017598090156324887, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 81, 'num_filters_3': 106, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:05:34 DISPATCHER: Starting worker discovery
17:05:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:34 DISPATCHER: Finished worker discovery
17:06:12 WORKER: done with job (4, 0, 10), trying to register it.
17:06:12 WORKER: registered result for job (4, 0, 10) with dispatcher
17:06:12 DISPATCHER: job (4, 0, 10) finished
17:06:12 DISPATCHER: register_result: lock acquired
17:06:12 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:06:12 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.025061076854999812, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.017598090156324887, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 81, 'num_filters_3': 106, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5168780794497932, 'info': {'data02': 0.5168780794497932, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.025061076854999812, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.017598090156324887, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 81, 'num_filters_3': 106, 'num_filters_4': 20}"}}
exception: None

17:06:12 job_callback for (4, 0, 10) started
17:06:12 DISPATCHER: Trying to submit another job.
17:06:12 job_callback for (4, 0, 10) got condition
17:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:06:12 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.676932





17:06:12 HBMASTER: Trying to run another job!
17:06:12 job_callback for (4, 0, 10) finished
17:06:12 start sampling a new configuration.
17:06:12 best_vector: [1, 2, 0.4159380498525505, 0.6649604933388302, 0.05066467013958017, 1, 0.6623276582899309, 0.7791027231563014, 1, 2, 2, 2, 0.7240465884123969, 0.9547789998847347, 0.9578113976131045, 0.6454630302110775], 4.514222085849149e-29, 0.00022152210967526975, -6.845682077075813e-06
17:06:12 done sampling a new configuration.
17:06:12 HBMASTER: schedule new run for iteration 4
17:06:12 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
17:06:12 HBMASTER: submitting job (4, 0, 11) to dispatcher
17:06:12 DISPATCHER: trying to submit job (4, 0, 11)
17:06:12 DISPATCHER: trying to notify the job_runner thread.
17:06:12 HBMASTER: job (4, 0, 11) submitted to dispatcher
17:06:12 DISPATCHER: Trying to submit another job.
17:06:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:06:12 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:06:12 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:06:12 WORKER: start processing job (4, 0, 11)
17:06:12 WORKER: args: ()
17:06:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006790098895904964, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.10318961985282189}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:06:34 DISPATCHER: Starting worker discovery
17:06:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:34 DISPATCHER: Finished worker discovery
17:07:01 WORKER: done with job (4, 0, 11), trying to register it.
17:07:01 WORKER: registered result for job (4, 0, 11) with dispatcher
17:07:01 DISPATCHER: job (4, 0, 11) finished
17:07:01 DISPATCHER: register_result: lock acquired
17:07:01 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:07:01 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006790098895904964, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.10318961985282189}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4135055309087462, 'info': {'data02': 0.4135055309087462, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006790098895904964, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.10318961985282189}"}}
exception: None

17:07:01 job_callback for (4, 0, 11) started
17:07:01 job_callback for (4, 0, 11) got condition
17:07:01 DISPATCHER: Trying to submit another job.
17:07:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:01 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.676932





17:07:01 HBMASTER: Trying to run another job!
17:07:01 job_callback for (4, 0, 11) finished
17:07:01 start sampling a new configuration.
17:07:01 done sampling a new configuration.
17:07:01 HBMASTER: schedule new run for iteration 4
17:07:01 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
17:07:01 HBMASTER: submitting job (4, 0, 12) to dispatcher
17:07:01 DISPATCHER: trying to submit job (4, 0, 12)
17:07:01 DISPATCHER: trying to notify the job_runner thread.
17:07:01 HBMASTER: job (4, 0, 12) submitted to dispatcher
17:07:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:01 DISPATCHER: Trying to submit another job.
17:07:01 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:07:01 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:07:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:01 WORKER: start processing job (4, 0, 12)
17:07:01 WORKER: args: ()
17:07:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.042202775882890065, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.028216183518115088, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 95, 'num_filters_3': 29, 'num_filters_4': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:07:34 DISPATCHER: Starting worker discovery
17:07:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:34 DISPATCHER: Finished worker discovery
17:07:50 WORKER: done with job (4, 0, 12), trying to register it.
17:07:50 WORKER: registered result for job (4, 0, 12) with dispatcher
17:07:50 DISPATCHER: job (4, 0, 12) finished
17:07:50 DISPATCHER: register_result: lock acquired
17:07:50 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:07:50 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.042202775882890065, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.028216183518115088, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 95, 'num_filters_3': 29, 'num_filters_4': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.042202775882890065, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.028216183518115088, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 95, 'num_filters_3': 29, 'num_filters_4': 58}"}}
exception: None

17:07:50 job_callback for (4, 0, 12) started
17:07:50 DISPATCHER: Trying to submit another job.
17:07:50 job_callback for (4, 0, 12) got condition
17:07:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:50 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.676932





17:07:50 HBMASTER: Trying to run another job!
17:07:50 job_callback for (4, 0, 12) finished
17:07:50 start sampling a new configuration.
17:07:50 done sampling a new configuration.
17:07:50 HBMASTER: schedule new run for iteration 4
17:07:50 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
17:07:50 HBMASTER: submitting job (4, 0, 13) to dispatcher
17:07:50 DISPATCHER: trying to submit job (4, 0, 13)
17:07:50 DISPATCHER: trying to notify the job_runner thread.
17:07:50 HBMASTER: job (4, 0, 13) submitted to dispatcher
17:07:50 DISPATCHER: Trying to submit another job.
17:07:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:50 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:07:50 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:07:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:50 WORKER: start processing job (4, 0, 13)
17:07:50 WORKER: args: ()
17:07:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002940856630364757, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012491572747833945, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 42, 'num_filters_4': 123, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:08:34 DISPATCHER: Starting worker discovery
17:08:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:34 DISPATCHER: Finished worker discovery
17:08:39 WORKER: done with job (4, 0, 13), trying to register it.
17:08:39 WORKER: registered result for job (4, 0, 13) with dispatcher
17:08:39 DISPATCHER: job (4, 0, 13) finished
17:08:39 DISPATCHER: register_result: lock acquired
17:08:39 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:08:39 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002940856630364757, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012491572747833945, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 42, 'num_filters_4': 123, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42356256952217186, 'info': {'data02': 0.42356256952217186, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002940856630364757, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012491572747833945, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 42, 'num_filters_4': 123, 'num_filters_5': 44}"}}
exception: None

17:08:39 job_callback for (4, 0, 13) started
17:08:39 DISPATCHER: Trying to submit another job.
17:08:39 job_callback for (4, 0, 13) got condition
17:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:08:39 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.676932





17:08:39 HBMASTER: Trying to run another job!
17:08:39 job_callback for (4, 0, 13) finished
17:08:39 start sampling a new configuration.
17:08:39 done sampling a new configuration.
17:08:39 HBMASTER: schedule new run for iteration 4
17:08:39 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
17:08:39 HBMASTER: submitting job (4, 0, 14) to dispatcher
17:08:39 DISPATCHER: trying to submit job (4, 0, 14)
17:08:39 DISPATCHER: trying to notify the job_runner thread.
17:08:39 HBMASTER: job (4, 0, 14) submitted to dispatcher
17:08:39 DISPATCHER: Trying to submit another job.
17:08:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:08:39 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:08:39 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:08:39 WORKER: start processing job (4, 0, 14)
17:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:08:39 WORKER: args: ()
17:08:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0017583494294544652, 'num_filters_1': 84, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.06783103974759629, 'kernel_size_2': 3, 'num_filters_2': 110}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:09:27 WORKER: done with job (4, 0, 14), trying to register it.
17:09:27 WORKER: registered result for job (4, 0, 14) with dispatcher
17:09:27 DISPATCHER: job (4, 0, 14) finished
17:09:27 DISPATCHER: register_result: lock acquired
17:09:27 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:09:27 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0017583494294544652, 'num_filters_1': 84, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.06783103974759629, 'kernel_size_2': 3, 'num_filters_2': 110}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4776591620042386, 'info': {'data02': 0.4776591620042386, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0017583494294544652, 'num_filters_1': 84, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.06783103974759629, 'kernel_size_2': 3, 'num_filters_2': 110}"}}
exception: None

17:09:27 job_callback for (4, 0, 14) started
17:09:27 DISPATCHER: Trying to submit another job.
17:09:27 job_callback for (4, 0, 14) got condition
17:09:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:09:27 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.676932





17:09:27 HBMASTER: Trying to run another job!
17:09:27 job_callback for (4, 0, 14) finished
17:09:27 start sampling a new configuration.
17:09:28 best_vector: [3, 2, 0.058635099945283486, 0.4460847973006302, 0.5238892620574953, 1, 0.03540128314664248, 0.26982897438094283, 1, 1, 2, 1, 0.4217749473157629, 0.8830154534187509, 0.16314881056115071, 0.6376057006551207], 8.145318691585106e-29, 0.0001227699047592939, -9.116822228137749e-08
17:09:28 done sampling a new configuration.
17:09:28 HBMASTER: schedule new run for iteration 4
17:09:28 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
17:09:28 HBMASTER: submitting job (4, 0, 15) to dispatcher
17:09:28 DISPATCHER: trying to submit job (4, 0, 15)
17:09:28 DISPATCHER: trying to notify the job_runner thread.
17:09:28 HBMASTER: job (4, 0, 15) submitted to dispatcher
17:09:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:09:28 DISPATCHER: Trying to submit another job.
17:09:28 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:09:28 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:09:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:09:28 WORKER: start processing job (4, 0, 15)
17:09:28 WORKER: args: ()
17:09:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0013099966947528528, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.022441691573731572, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:09:34 DISPATCHER: Starting worker discovery
17:09:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:34 DISPATCHER: Finished worker discovery
17:10:16 WORKER: done with job (4, 0, 15), trying to register it.
17:10:16 WORKER: registered result for job (4, 0, 15) with dispatcher
17:10:16 DISPATCHER: job (4, 0, 15) finished
17:10:16 DISPATCHER: register_result: lock acquired
17:10:16 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:10:16 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0013099966947528528, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.022441691573731572, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46209683697280896, 'info': {'data02': 0.46209683697280896, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0013099966947528528, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.022441691573731572, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 100}"}}
exception: None

17:10:16 job_callback for (4, 0, 15) started
17:10:16 DISPATCHER: Trying to submit another job.
17:10:16 job_callback for (4, 0, 15) got condition
17:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:10:16 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.676932





17:10:16 HBMASTER: Trying to run another job!
17:10:16 job_callback for (4, 0, 15) finished
17:10:16 start sampling a new configuration.
17:10:16 done sampling a new configuration.
17:10:16 HBMASTER: schedule new run for iteration 4
17:10:16 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
17:10:16 HBMASTER: submitting job (4, 0, 16) to dispatcher
17:10:16 DISPATCHER: trying to submit job (4, 0, 16)
17:10:16 DISPATCHER: trying to notify the job_runner thread.
17:10:16 HBMASTER: job (4, 0, 16) submitted to dispatcher
17:10:16 DISPATCHER: Trying to submit another job.
17:10:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:10:16 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:10:16 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:10:16 WORKER: start processing job (4, 0, 16)
17:10:16 WORKER: args: ()
17:10:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012551487285088435, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.016725077153962067, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 25, 'num_filters_3': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:10:34 DISPATCHER: Starting worker discovery
17:10:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:34 DISPATCHER: Finished worker discovery
17:11:05 WORKER: done with job (4, 0, 16), trying to register it.
17:11:05 WORKER: registered result for job (4, 0, 16) with dispatcher
17:11:05 DISPATCHER: job (4, 0, 16) finished
17:11:05 DISPATCHER: register_result: lock acquired
17:11:05 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:11:05 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012551487285088435, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.016725077153962067, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 25, 'num_filters_3': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49567732604843184, 'info': {'data02': 0.49567732604843184, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012551487285088435, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.016725077153962067, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 25, 'num_filters_3': 89}"}}
exception: None

17:11:05 job_callback for (4, 0, 16) started
17:11:05 DISPATCHER: Trying to submit another job.
17:11:05 job_callback for (4, 0, 16) got condition
17:11:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:11:05 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.676932





17:11:05 HBMASTER: Trying to run another job!
17:11:05 job_callback for (4, 0, 16) finished
17:11:05 start sampling a new configuration.
17:11:05 done sampling a new configuration.
17:11:05 HBMASTER: schedule new run for iteration 4
17:11:05 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
17:11:05 HBMASTER: submitting job (4, 0, 17) to dispatcher
17:11:05 DISPATCHER: trying to submit job (4, 0, 17)
17:11:05 DISPATCHER: trying to notify the job_runner thread.
17:11:05 HBMASTER: job (4, 0, 17) submitted to dispatcher
17:11:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:11:05 DISPATCHER: Trying to submit another job.
17:11:05 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:11:05 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:11:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:11:05 WORKER: start processing job (4, 0, 17)
17:11:05 WORKER: args: ()
17:11:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:11:34 DISPATCHER: Starting worker discovery
17:11:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:34 DISPATCHER: Finished worker discovery
17:11:53 WORKER: done with job (4, 0, 17), trying to register it.
17:11:53 WORKER: registered result for job (4, 0, 17) with dispatcher
17:11:53 DISPATCHER: job (4, 0, 17) finished
17:11:53 DISPATCHER: register_result: lock acquired
17:11:53 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:11:53 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5985141385740053, 'info': {'data02': 0.5985141385740053, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}"}}
exception: None

17:11:53 job_callback for (4, 0, 17) started
17:11:53 DISPATCHER: Trying to submit another job.
17:11:53 job_callback for (4, 0, 17) got condition
17:11:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:11:53 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.676932





17:11:53 HBMASTER: Trying to run another job!
17:11:53 job_callback for (4, 0, 17) finished
17:11:53 start sampling a new configuration.
17:11:54 best_vector: [1, 0, 0.21048374431277256, 0.48351533633048416, 0.7228402563591302, 1, 0.57853339751199, 0.19356455761385682, 2, 0, 2, 2, 0.30656653073475815, 0.4774940995705965, 0.07044283158113862, 0.47907433311760306], 8.311571857023181e-29, 0.0001203141857162688, -1.7187922183289763e-06
17:11:54 done sampling a new configuration.
17:11:54 HBMASTER: schedule new run for iteration 4
17:11:54 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:11:54 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:11:54 DISPATCHER: trying to submit job (4, 0, 18)
17:11:54 DISPATCHER: trying to notify the job_runner thread.
17:11:54 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:11:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:11:54 DISPATCHER: Trying to submit another job.
17:11:54 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:11:54 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:11:54 WORKER: start processing job (4, 0, 18)
17:11:54 WORKER: args: ()
17:11:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026361340369011814, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.017858019610935135, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 43, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:12:34 DISPATCHER: Starting worker discovery
17:12:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:34 DISPATCHER: Finished worker discovery
17:12:42 WORKER: done with job (4, 0, 18), trying to register it.
17:12:42 WORKER: registered result for job (4, 0, 18) with dispatcher
17:12:42 DISPATCHER: job (4, 0, 18) finished
17:12:42 DISPATCHER: register_result: lock acquired
17:12:42 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:12:42 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026361340369011814, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.017858019610935135, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 43, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6142174004210222, 'info': {'data02': 0.6142174004210222, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026361340369011814, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.017858019610935135, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 43, 'num_filters_4': 18}"}}
exception: None

17:12:42 job_callback for (4, 0, 18) started
17:12:42 DISPATCHER: Trying to submit another job.
17:12:42 job_callback for (4, 0, 18) got condition
17:12:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:12:42 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.676932





17:12:42 HBMASTER: Trying to run another job!
17:12:42 job_callback for (4, 0, 18) finished
17:12:42 start sampling a new configuration.
17:12:42 best_vector: [1, 2, 0.44066901586408097, 0.20932949075776636, 0.7769594423357352, 1, 0.9142813389732969, 0.1863940415487909, 1, 1, 0, 2, 0.9073155347124299, 0.7964936701018466, 0.02779355323572641, 0.48051945882464603], 1.269067678764648e-30, 0.00787980039782774, -1.1568513079524254e-06
17:12:42 done sampling a new configuration.
17:12:42 HBMASTER: schedule new run for iteration 4
17:12:42 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
17:12:42 HBMASTER: submitting job (4, 0, 19) to dispatcher
17:12:42 DISPATCHER: trying to submit job (4, 0, 19)
17:12:42 DISPATCHER: trying to notify the job_runner thread.
17:12:42 HBMASTER: job (4, 0, 19) submitted to dispatcher
17:12:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:12:42 DISPATCHER: Trying to submit another job.
17:12:42 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:12:42 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:12:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:12:42 WORKER: start processing job (4, 0, 19)
17:12:42 WORKER: args: ()
17:12:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00760918304850283, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01747850322778291, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 106, 'num_filters_3': 84, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:13:31 WORKER: done with job (4, 0, 19), trying to register it.
17:13:31 WORKER: registered result for job (4, 0, 19) with dispatcher
17:13:31 DISPATCHER: job (4, 0, 19) finished
17:13:31 DISPATCHER: register_result: lock acquired
17:13:31 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:13:31 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00760918304850283, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01747850322778291, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 106, 'num_filters_3': 84, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4919057042978643, 'info': {'data02': 0.4919057042978643, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00760918304850283, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01747850322778291, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 106, 'num_filters_3': 84, 'num_filters_4': 16}"}}
exception: None

17:13:31 job_callback for (4, 0, 19) started
17:13:31 DISPATCHER: Trying to submit another job.
17:13:31 job_callback for (4, 0, 19) got condition
17:13:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:32 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.676932





17:13:32 HBMASTER: Trying to run another job!
17:13:32 job_callback for (4, 0, 19) finished
17:13:32 start sampling a new configuration.
17:13:32 done sampling a new configuration.
17:13:32 HBMASTER: schedule new run for iteration 4
17:13:32 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
17:13:32 HBMASTER: submitting job (4, 0, 20) to dispatcher
17:13:32 DISPATCHER: trying to submit job (4, 0, 20)
17:13:32 DISPATCHER: trying to notify the job_runner thread.
17:13:32 HBMASTER: job (4, 0, 20) submitted to dispatcher
17:13:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:32 DISPATCHER: Trying to submit another job.
17:13:32 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:13:32 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:32 WORKER: start processing job (4, 0, 20)
17:13:32 WORKER: args: ()
17:13:32 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010850415904122043, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.014346603404217085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 43, 'num_filters_4': 73}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:13:34 DISPATCHER: Starting worker discovery
17:13:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:34 DISPATCHER: Finished worker discovery
17:14:25 WORKER: done with job (4, 0, 20), trying to register it.
17:14:25 WORKER: registered result for job (4, 0, 20) with dispatcher
17:14:25 DISPATCHER: job (4, 0, 20) finished
17:14:25 DISPATCHER: register_result: lock acquired
17:14:25 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:14:25 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010850415904122043, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.014346603404217085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 43, 'num_filters_4': 73}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5720870539001834, 'info': {'data02': 0.5720870539001834, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010850415904122043, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.014346603404217085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 43, 'num_filters_4': 73}"}}
exception: None

17:14:25 job_callback for (4, 0, 20) started
17:14:25 DISPATCHER: Trying to submit another job.
17:14:25 job_callback for (4, 0, 20) got condition
17:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:14:25 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.676932





17:14:25 HBMASTER: Trying to run another job!
17:14:25 job_callback for (4, 0, 20) finished
17:14:25 start sampling a new configuration.
17:14:25 done sampling a new configuration.
17:14:25 HBMASTER: schedule new run for iteration 4
17:14:25 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
17:14:25 HBMASTER: submitting job (4, 0, 21) to dispatcher
17:14:25 DISPATCHER: trying to submit job (4, 0, 21)
17:14:25 DISPATCHER: trying to notify the job_runner thread.
17:14:25 HBMASTER: job (4, 0, 21) submitted to dispatcher
17:14:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:14:25 DISPATCHER: Trying to submit another job.
17:14:25 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:14:25 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:14:25 WORKER: start processing job (4, 0, 21)
17:14:25 WORKER: args: ()
17:14:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002635485009017105, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.04352421597118562, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:14:34 DISPATCHER: Starting worker discovery
17:14:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:34 DISPATCHER: Finished worker discovery
17:15:14 WORKER: done with job (4, 0, 21), trying to register it.
17:15:14 WORKER: registered result for job (4, 0, 21) with dispatcher
17:15:14 DISPATCHER: job (4, 0, 21) finished
17:15:14 DISPATCHER: register_result: lock acquired
17:15:14 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:15:14 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002635485009017105, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.04352421597118562, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5704708345010541, 'info': {'data02': 0.5704708345010541, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002635485009017105, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.04352421597118562, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 41}"}}
exception: None

17:15:14 job_callback for (4, 0, 21) started
17:15:14 DISPATCHER: Trying to submit another job.
17:15:14 job_callback for (4, 0, 21) got condition
17:15:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:14 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.676932





17:15:14 HBMASTER: Trying to run another job!
17:15:14 job_callback for (4, 0, 21) finished
17:15:14 start sampling a new configuration.
17:15:14 best_vector: [0, 1, 0.3202672474160796, 0.9170614651309572, 0.24097401280429925, 0, 0.41406470593915146, 0.9355120570625879, 2, 0, 2, 2, 0.575190185982241, 0.6812848677695645, 0.9083229493609057, 0.4839143298049448], 3.7066808676980735e-32, 0.2697831390650636, -5.6027046083720604e-06
17:15:14 done sampling a new configuration.
17:15:14 HBMASTER: schedule new run for iteration 4
17:15:14 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
17:15:14 HBMASTER: submitting job (4, 0, 22) to dispatcher
17:15:14 DISPATCHER: trying to submit job (4, 0, 22)
17:15:14 DISPATCHER: trying to notify the job_runner thread.
17:15:14 HBMASTER: job (4, 0, 22) submitted to dispatcher
17:15:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:14 DISPATCHER: Trying to submit another job.
17:15:14 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:15:14 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:15:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:14 WORKER: start processing job (4, 0, 22)
17:15:14 WORKER: args: ()
17:15:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004370533916569064, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.16486529633625877, 'kernel_size_2': 7, 'num_filters_2': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:15:34 DISPATCHER: Starting worker discovery
17:15:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:34 DISPATCHER: Finished worker discovery
17:16:03 WORKER: done with job (4, 0, 22), trying to register it.
17:16:03 WORKER: registered result for job (4, 0, 22) with dispatcher
17:16:03 DISPATCHER: job (4, 0, 22) finished
17:16:03 DISPATCHER: register_result: lock acquired
17:16:03 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:16:03 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004370533916569064, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.16486529633625877, 'kernel_size_2': 7, 'num_filters_2': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32369257267191537, 'info': {'data02': 0.32369257267191537, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004370533916569064, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.16486529633625877, 'kernel_size_2': 7, 'num_filters_2': 52}"}}
exception: None

17:16:03 job_callback for (4, 0, 22) started
17:16:03 job_callback for (4, 0, 22) got condition
17:16:03 DISPATCHER: Trying to submit another job.
17:16:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:16:03 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.676932





17:16:03 HBMASTER: Trying to run another job!
17:16:03 job_callback for (4, 0, 22) finished
17:16:03 start sampling a new configuration.
17:16:03 best_vector: [3, 0, 0.2850566104423708, 0.30039695877317396, 0.6346756427112183, 0, 0.00989168803327406, 0.8213799371621466, 0, 2, 0, 2, 0.28080676833895296, 0.9722644270311309, 0.7556289375299291, 0.4801240277339478], 6.414820457217226e-31, 0.015588900837823353, -2.0065701460585337e-06
17:16:03 done sampling a new configuration.
17:16:03 HBMASTER: schedule new run for iteration 4
17:16:03 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:16:03 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:16:03 DISPATCHER: trying to submit job (4, 0, 23)
17:16:03 DISPATCHER: trying to notify the job_runner thread.
17:16:03 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:16:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:16:03 DISPATCHER: Trying to submit another job.
17:16:03 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:16:03 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:16:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:16:03 WORKER: start processing job (4, 0, 23)
17:16:03 WORKER: args: ()
17:16:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0037163210122620025, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.11712239271429724, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 28, 'num_filters_3': 121, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:16:34 DISPATCHER: Starting worker discovery
17:16:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:34 DISPATCHER: Finished worker discovery
17:16:53 WORKER: done with job (4, 0, 23), trying to register it.
17:16:53 WORKER: registered result for job (4, 0, 23) with dispatcher
17:16:53 DISPATCHER: job (4, 0, 23) finished
17:16:53 DISPATCHER: register_result: lock acquired
17:16:53 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:16:53 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0037163210122620025, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.11712239271429724, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 28, 'num_filters_3': 121, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00013611578316920496, 'info': {'data02': 0.00013611578316920496, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0037163210122620025, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.11712239271429724, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 28, 'num_filters_3': 121, 'num_filters_4': 77}"}}
exception: None

17:16:53 job_callback for (4, 0, 23) started
17:16:53 DISPATCHER: Trying to submit another job.
17:16:53 job_callback for (4, 0, 23) got condition
17:16:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:16:53 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.676932





17:16:53 HBMASTER: Trying to run another job!
17:16:53 job_callback for (4, 0, 23) finished
17:16:53 start sampling a new configuration.
17:16:53 best_vector: [3, 2, 0.22270302753675314, 0.1462852475809686, 0.9010791035067787, 1, 0.11173233149530254, 0.14278647040943007, 0, 0, 2, 2, 0.45885673349936884, 0.7127171114584046, 0.19944431918667693, 0.4830060774231752], 3.5656835069532114e-32, 0.2804511387648298, -2.884534534502359e-06
17:16:53 done sampling a new configuration.
17:16:53 HBMASTER: schedule new run for iteration 4
17:16:53 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:16:53 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:16:53 DISPATCHER: trying to submit job (4, 0, 24)
17:16:53 DISPATCHER: trying to notify the job_runner thread.
17:16:53 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:16:53 DISPATCHER: Trying to submit another job.
17:16:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:16:53 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:16:53 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:16:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:16:53 WORKER: start processing job (4, 0, 24)
17:16:53 WORKER: args: ()
17:16:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002788727344222707, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.015338026401073195, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 70, 'num_filters_4': 24, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:17:34 DISPATCHER: Starting worker discovery
17:17:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:34 DISPATCHER: Finished worker discovery
17:17:42 WORKER: done with job (4, 0, 24), trying to register it.
17:17:42 WORKER: registered result for job (4, 0, 24) with dispatcher
17:17:42 DISPATCHER: job (4, 0, 24) finished
17:17:42 DISPATCHER: register_result: lock acquired
17:17:42 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:17:42 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002788727344222707, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.015338026401073195, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 70, 'num_filters_4': 24, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43658776146738343, 'info': {'data02': 0.43658776146738343, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002788727344222707, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.015338026401073195, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 70, 'num_filters_4': 24, 'num_filters_5': 43}"}}
exception: None

17:17:42 job_callback for (4, 0, 24) started
17:17:42 DISPATCHER: Trying to submit another job.
17:17:42 job_callback for (4, 0, 24) got condition
17:17:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:17:42 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.676932





17:17:42 HBMASTER: Trying to run another job!
17:17:42 job_callback for (4, 0, 24) finished
17:17:42 start sampling a new configuration.
17:17:42 best_vector: [3, 1, 0.4487709480957849, 0.9938418509816886, 0.6749841000183656, 1, 0.2749367054199602, 0.4919915710044923, 1, 2, 1, 2, 0.9681510535665843, 0.9181495084120811, 0.5039313226075838, 0.4831111269517577], 3.236144687171268e-32, 0.3090096694267726, -6.100518782475347e-06
17:17:42 done sampling a new configuration.
17:17:42 HBMASTER: schedule new run for iteration 4
17:17:42 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:17:42 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:17:42 DISPATCHER: trying to submit job (4, 0, 25)
17:17:42 DISPATCHER: trying to notify the job_runner thread.
17:17:42 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:17:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:17:42 DISPATCHER: Trying to submit another job.
17:17:42 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:17:42 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:17:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:17:42 WORKER: start processing job (4, 0, 25)
17:17:42 WORKER: args: ()
17:17:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:18:31 WORKER: done with job (4, 0, 25), trying to register it.
17:18:31 WORKER: registered result for job (4, 0, 25) with dispatcher
17:18:31 DISPATCHER: job (4, 0, 25) finished
17:18:31 DISPATCHER: register_result: lock acquired
17:18:31 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:18:31 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.657742848871944, 'info': {'data02': 0.657742848871944, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}"}}
exception: None

17:18:31 job_callback for (4, 0, 25) started
17:18:31 DISPATCHER: Trying to submit another job.
17:18:31 job_callback for (4, 0, 25) got condition
17:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:18:31 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.676932





17:18:31 HBMASTER: Trying to run another job!
17:18:31 job_callback for (4, 0, 25) finished
17:18:31 start sampling a new configuration.
17:18:31 best_vector: [1, 2, 0.9054825543102201, 0.3380690310761307, 0.8787983312152668, 1, 0.6442199723771689, 0.4536889423562628, 0, 0, 0, 2, 0.5536923229530236, 0.5651802918346456, 0.11933602330791454, 0.4878593724241688], 3.003670881470991e-24, 3.3292595609218976e-09, -4.3117075341169434e-05
17:18:31 done sampling a new configuration.
17:18:31 HBMASTER: schedule new run for iteration 4
17:18:31 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
17:18:31 HBMASTER: submitting job (4, 0, 26) to dispatcher
17:18:31 DISPATCHER: trying to submit job (4, 0, 26)
17:18:31 DISPATCHER: trying to notify the job_runner thread.
17:18:31 HBMASTER: job (4, 0, 26) submitted to dispatcher
17:18:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:18:31 DISPATCHER: Trying to submit another job.
17:18:31 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:18:31 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:18:31 WORKER: start processing job (4, 0, 26)
17:18:31 WORKER: args: ()
17:18:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06470906261595605, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.0389280744975235, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 50, 'num_filters_3': 51, 'num_filters_4': 20, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:18:34 DISPATCHER: Starting worker discovery
17:18:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:34 DISPATCHER: Finished worker discovery
Exception in thread Thread-693:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4575657222616913683 is out of bounds for axis 0 with size 7

17:19:19 WORKER: done with job (4, 0, 26), trying to register it.
17:19:19 WORKER: registered result for job (4, 0, 26) with dispatcher
17:19:19 DISPATCHER: job (4, 0, 26) finished
17:19:19 DISPATCHER: register_result: lock acquired
17:19:19 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:19:19 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06470906261595605, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.0389280744975235, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 50, 'num_filters_3': 51, 'num_filters_4': 20, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49230728145816505, 'info': {'data02': 0.49230728145816505, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06470906261595605, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.0389280744975235, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 50, 'num_filters_3': 51, 'num_filters_4': 20, 'num_filters_5': 43}"}}
exception: None

17:19:19 job_callback for (4, 0, 26) started
17:19:19 DISPATCHER: Trying to submit another job.
17:19:19 job_callback for (4, 0, 26) got condition
17:19:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:19:19 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.676932





17:19:19 HBMASTER: Trying to run another job!
17:19:19 job_callback for (4, 0, 26) finished
17:19:19 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
17:19:19 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
17:19:19 HBMASTER: schedule new run for iteration 4
17:19:19 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
17:19:19 HBMASTER: submitting job (4, 0, 0) to dispatcher
17:19:19 DISPATCHER: trying to submit job (4, 0, 0)
17:19:19 DISPATCHER: trying to notify the job_runner thread.
17:19:19 HBMASTER: job (4, 0, 0) submitted to dispatcher
17:19:19 DISPATCHER: Trying to submit another job.
17:19:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:19:19 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:19:19 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:19:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:19:19 WORKER: start processing job (4, 0, 0)
17:19:19 WORKER: args: ()
17:19:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020509711324021213, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.09663907078469193, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:19:34 DISPATCHER: Starting worker discovery
17:19:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:34 DISPATCHER: Finished worker discovery
17:20:34 DISPATCHER: Starting worker discovery
17:20:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:34 DISPATCHER: Finished worker discovery
17:21:34 DISPATCHER: Starting worker discovery
17:21:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:34 DISPATCHER: Finished worker discovery
17:21:37 WORKER: done with job (4, 0, 0), trying to register it.
17:21:37 WORKER: registered result for job (4, 0, 0) with dispatcher
17:21:37 DISPATCHER: job (4, 0, 0) finished
17:21:37 DISPATCHER: register_result: lock acquired
17:21:37 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:21:37 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020509711324021213, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.09663907078469193, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4817827714317582, 'info': {'data02': 0.4817827714317582, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020509711324021213, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.09663907078469193, 'kernel_size_2': 7, 'num_filters_2': 100}"}}
exception: None

17:21:37 job_callback for (4, 0, 0) started
17:21:37 DISPATCHER: Trying to submit another job.
17:21:37 job_callback for (4, 0, 0) got condition
17:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:21:37 HBMASTER: Trying to run another job!
17:21:37 job_callback for (4, 0, 0) finished
17:21:37 HBMASTER: schedule new run for iteration 4
17:21:37 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
17:21:37 HBMASTER: submitting job (4, 0, 3) to dispatcher
17:21:37 DISPATCHER: trying to submit job (4, 0, 3)
17:21:37 DISPATCHER: trying to notify the job_runner thread.
17:21:37 HBMASTER: job (4, 0, 3) submitted to dispatcher
17:21:37 DISPATCHER: Trying to submit another job.
17:21:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:21:37 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:21:37 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:21:37 WORKER: start processing job (4, 0, 3)
17:21:37 WORKER: args: ()
17:21:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008328142451838596, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.048958836732934816, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:22:34 DISPATCHER: Starting worker discovery
17:22:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:34 DISPATCHER: Finished worker discovery
17:23:34 DISPATCHER: Starting worker discovery
17:23:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:34 DISPATCHER: Finished worker discovery
17:23:56 WORKER: done with job (4, 0, 3), trying to register it.
17:23:56 WORKER: registered result for job (4, 0, 3) with dispatcher
17:23:56 DISPATCHER: job (4, 0, 3) finished
17:23:56 DISPATCHER: register_result: lock acquired
17:23:56 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:23:56 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008328142451838596, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.048958836732934816, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36787465466648805, 'info': {'data02': 0.36787465466648805, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008328142451838596, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.048958836732934816, 'kernel_size_2': 7, 'num_filters_2': 32}"}}
exception: None

17:23:56 job_callback for (4, 0, 3) started
17:23:56 DISPATCHER: Trying to submit another job.
17:23:56 job_callback for (4, 0, 3) got condition
17:23:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:23:56 HBMASTER: Trying to run another job!
17:23:56 job_callback for (4, 0, 3) finished
17:23:56 HBMASTER: schedule new run for iteration 4
17:23:56 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
17:23:56 HBMASTER: submitting job (4, 0, 5) to dispatcher
17:23:56 DISPATCHER: trying to submit job (4, 0, 5)
17:23:56 DISPATCHER: trying to notify the job_runner thread.
17:23:56 HBMASTER: job (4, 0, 5) submitted to dispatcher
17:23:56 DISPATCHER: Trying to submit another job.
17:23:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:23:56 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:23:56 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:23:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:23:56 WORKER: start processing job (4, 0, 5)
17:23:56 WORKER: args: ()
17:23:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:24:34 DISPATCHER: Starting worker discovery
17:24:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:34 DISPATCHER: Finished worker discovery
17:25:34 DISPATCHER: Starting worker discovery
17:25:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:34 DISPATCHER: Finished worker discovery
17:26:15 WORKER: done with job (4, 0, 5), trying to register it.
17:26:15 WORKER: registered result for job (4, 0, 5) with dispatcher
17:26:15 DISPATCHER: job (4, 0, 5) finished
17:26:15 DISPATCHER: register_result: lock acquired
17:26:15 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:26:15 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6683188565581847, 'info': {'data02': 0.6683188565581847, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}"}}
exception: None

17:26:15 job_callback for (4, 0, 5) started
17:26:15 job_callback for (4, 0, 5) got condition
17:26:15 DISPATCHER: Trying to submit another job.
17:26:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:26:15 HBMASTER: Trying to run another job!
17:26:15 job_callback for (4, 0, 5) finished
17:26:15 HBMASTER: schedule new run for iteration 4
17:26:15 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:26:15 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:26:15 DISPATCHER: trying to submit job (4, 0, 10)
17:26:15 DISPATCHER: trying to notify the job_runner thread.
17:26:15 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:26:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:26:15 DISPATCHER: Trying to submit another job.
17:26:15 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:26:15 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:26:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:26:15 WORKER: start processing job (4, 0, 10)
17:26:15 WORKER: args: ()
17:26:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.025061076854999812, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.017598090156324887, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 81, 'num_filters_3': 106, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:26:34 DISPATCHER: Starting worker discovery
17:26:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:34 DISPATCHER: Finished worker discovery
17:27:34 DISPATCHER: Starting worker discovery
17:27:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:34 DISPATCHER: Finished worker discovery
17:28:33 WORKER: done with job (4, 0, 10), trying to register it.
17:28:33 WORKER: registered result for job (4, 0, 10) with dispatcher
17:28:33 DISPATCHER: job (4, 0, 10) finished
17:28:33 DISPATCHER: register_result: lock acquired
17:28:33 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:28:33 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.025061076854999812, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.017598090156324887, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 81, 'num_filters_3': 106, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39969560513603847, 'info': {'data02': 0.39969560513603847, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.025061076854999812, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.017598090156324887, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 81, 'num_filters_3': 106, 'num_filters_4': 20}"}}
exception: None

17:28:33 job_callback for (4, 0, 10) started
17:28:33 DISPATCHER: Trying to submit another job.
17:28:33 job_callback for (4, 0, 10) got condition
17:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:28:33 HBMASTER: Trying to run another job!
17:28:33 job_callback for (4, 0, 10) finished
17:28:33 HBMASTER: schedule new run for iteration 4
17:28:33 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
17:28:33 HBMASTER: submitting job (4, 0, 17) to dispatcher
17:28:33 DISPATCHER: trying to submit job (4, 0, 17)
17:28:33 DISPATCHER: trying to notify the job_runner thread.
17:28:33 HBMASTER: job (4, 0, 17) submitted to dispatcher
17:28:33 DISPATCHER: Trying to submit another job.
17:28:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:28:33 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:28:33 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:28:33 WORKER: start processing job (4, 0, 17)
17:28:33 WORKER: args: ()
17:28:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:28:34 DISPATCHER: Starting worker discovery
17:28:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:34 DISPATCHER: Finished worker discovery
17:29:34 DISPATCHER: Starting worker discovery
17:29:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:34 DISPATCHER: Finished worker discovery
17:30:34 DISPATCHER: Starting worker discovery
17:30:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:34 DISPATCHER: Finished worker discovery
17:30:52 WORKER: done with job (4, 0, 17), trying to register it.
17:30:52 WORKER: registered result for job (4, 0, 17) with dispatcher
17:30:52 DISPATCHER: job (4, 0, 17) finished
17:30:52 DISPATCHER: register_result: lock acquired
17:30:52 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:30:52 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6094618895696692, 'info': {'data02': 0.6094618895696692, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}"}}
exception: None

17:30:52 job_callback for (4, 0, 17) started
17:30:52 DISPATCHER: Trying to submit another job.
17:30:52 job_callback for (4, 0, 17) got condition
17:30:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:30:52 HBMASTER: Trying to run another job!
17:30:52 job_callback for (4, 0, 17) finished
17:30:52 HBMASTER: schedule new run for iteration 4
17:30:52 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:30:52 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:30:52 DISPATCHER: trying to submit job (4, 0, 18)
17:30:52 DISPATCHER: trying to notify the job_runner thread.
17:30:52 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:30:52 DISPATCHER: Trying to submit another job.
17:30:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:30:52 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:30:52 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:30:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:30:52 WORKER: start processing job (4, 0, 18)
17:30:52 WORKER: args: ()
17:30:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026361340369011814, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.017858019610935135, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 43, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:31:34 DISPATCHER: Starting worker discovery
17:31:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:34 DISPATCHER: Finished worker discovery
17:32:34 DISPATCHER: Starting worker discovery
17:32:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:34 DISPATCHER: Finished worker discovery
17:33:10 WORKER: done with job (4, 0, 18), trying to register it.
17:33:10 WORKER: registered result for job (4, 0, 18) with dispatcher
17:33:10 DISPATCHER: job (4, 0, 18) finished
17:33:10 DISPATCHER: register_result: lock acquired
17:33:10 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:33:10 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026361340369011814, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.017858019610935135, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 43, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4828509362125143, 'info': {'data02': 0.4828509362125143, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026361340369011814, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.017858019610935135, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 43, 'num_filters_4': 18}"}}
exception: None

17:33:10 job_callback for (4, 0, 18) started
17:33:10 DISPATCHER: Trying to submit another job.
17:33:10 job_callback for (4, 0, 18) got condition
17:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:33:10 HBMASTER: Trying to run another job!
17:33:10 job_callback for (4, 0, 18) finished
17:33:10 HBMASTER: schedule new run for iteration 4
17:33:10 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
17:33:10 HBMASTER: submitting job (4, 0, 20) to dispatcher
17:33:10 DISPATCHER: trying to submit job (4, 0, 20)
17:33:10 DISPATCHER: trying to notify the job_runner thread.
17:33:10 HBMASTER: job (4, 0, 20) submitted to dispatcher
17:33:10 DISPATCHER: Trying to submit another job.
17:33:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:33:10 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:33:10 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:33:10 WORKER: start processing job (4, 0, 20)
17:33:10 WORKER: args: ()
17:33:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010850415904122043, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.014346603404217085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 43, 'num_filters_4': 73}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:33:34 DISPATCHER: Starting worker discovery
17:33:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:34 DISPATCHER: Finished worker discovery
17:34:34 DISPATCHER: Starting worker discovery
17:34:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:34 DISPATCHER: Finished worker discovery
17:35:28 WORKER: done with job (4, 0, 20), trying to register it.
17:35:28 WORKER: registered result for job (4, 0, 20) with dispatcher
17:35:28 DISPATCHER: job (4, 0, 20) finished
17:35:28 DISPATCHER: register_result: lock acquired
17:35:28 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:35:28 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010850415904122043, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.014346603404217085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 43, 'num_filters_4': 73}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4891282305217666, 'info': {'data02': 0.4891282305217666, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010850415904122043, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.014346603404217085, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 45, 'num_filters_3': 43, 'num_filters_4': 73}"}}
exception: None

17:35:28 job_callback for (4, 0, 20) started
17:35:28 job_callback for (4, 0, 20) got condition
17:35:28 DISPATCHER: Trying to submit another job.
17:35:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:35:28 HBMASTER: Trying to run another job!
17:35:28 job_callback for (4, 0, 20) finished
17:35:28 HBMASTER: schedule new run for iteration 4
17:35:28 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
17:35:28 HBMASTER: submitting job (4, 0, 21) to dispatcher
17:35:28 DISPATCHER: trying to submit job (4, 0, 21)
17:35:28 DISPATCHER: trying to notify the job_runner thread.
17:35:28 HBMASTER: job (4, 0, 21) submitted to dispatcher
17:35:28 DISPATCHER: Trying to submit another job.
17:35:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:35:28 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:35:28 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:35:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:35:28 WORKER: start processing job (4, 0, 21)
17:35:28 WORKER: args: ()
17:35:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002635485009017105, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.04352421597118562, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:35:34 DISPATCHER: Starting worker discovery
17:35:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:34 DISPATCHER: Finished worker discovery
17:36:34 DISPATCHER: Starting worker discovery
17:36:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:34 DISPATCHER: Finished worker discovery
17:37:34 DISPATCHER: Starting worker discovery
17:37:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:34 DISPATCHER: Finished worker discovery
17:37:47 WORKER: done with job (4, 0, 21), trying to register it.
17:37:47 WORKER: registered result for job (4, 0, 21) with dispatcher
17:37:47 DISPATCHER: job (4, 0, 21) finished
17:37:47 DISPATCHER: register_result: lock acquired
17:37:47 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:37:47 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002635485009017105, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.04352421597118562, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.515804989146532, 'info': {'data02': 0.515804989146532, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002635485009017105, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.04352421597118562, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 41}"}}
exception: None

17:37:47 job_callback for (4, 0, 21) started
17:37:47 job_callback for (4, 0, 21) got condition
17:37:47 DISPATCHER: Trying to submit another job.
17:37:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:37:47 HBMASTER: Trying to run another job!
17:37:47 job_callback for (4, 0, 21) finished
17:37:47 HBMASTER: schedule new run for iteration 4
17:37:47 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:37:47 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:37:47 DISPATCHER: trying to submit job (4, 0, 25)
17:37:47 DISPATCHER: trying to notify the job_runner thread.
17:37:47 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:37:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:37:47 DISPATCHER: Trying to submit another job.
17:37:47 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:37:47 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:37:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:37:47 WORKER: start processing job (4, 0, 25)
17:37:47 WORKER: args: ()
17:37:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:38:34 DISPATCHER: Starting worker discovery
17:38:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:34 DISPATCHER: Finished worker discovery
17:39:34 DISPATCHER: Starting worker discovery
17:39:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:34 DISPATCHER: Finished worker discovery
17:40:05 WORKER: done with job (4, 0, 25), trying to register it.
17:40:05 WORKER: registered result for job (4, 0, 25) with dispatcher
17:40:05 DISPATCHER: job (4, 0, 25) finished
17:40:05 DISPATCHER: register_result: lock acquired
17:40:05 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:40:05 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7400360618458129, 'info': {'data02': 0.7400360618458129, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}"}}
exception: None

17:40:05 job_callback for (4, 0, 25) started
17:40:05 job_callback for (4, 0, 25) got condition
17:40:05 DISPATCHER: Trying to submit another job.
17:40:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:40:05 HBMASTER: Trying to run another job!
17:40:05 job_callback for (4, 0, 25) finished
17:40:05 ITERATION: Advancing config (4, 0, 5) to next budget 400.000000
17:40:05 ITERATION: Advancing config (4, 0, 17) to next budget 400.000000
17:40:05 ITERATION: Advancing config (4, 0, 25) to next budget 400.000000
17:40:05 HBMASTER: schedule new run for iteration 4
17:40:05 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
17:40:05 HBMASTER: submitting job (4, 0, 5) to dispatcher
17:40:05 DISPATCHER: trying to submit job (4, 0, 5)
17:40:05 DISPATCHER: trying to notify the job_runner thread.
17:40:05 HBMASTER: job (4, 0, 5) submitted to dispatcher
17:40:05 DISPATCHER: Trying to submit another job.
17:40:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:40:05 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:40:05 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:40:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:40:05 WORKER: start processing job (4, 0, 5)
17:40:05 WORKER: args: ()
17:40:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}, 'budget': 400.0, 'working_directory': '.'}
17:40:34 DISPATCHER: Starting worker discovery
17:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:34 DISPATCHER: Finished worker discovery
17:41:34 DISPATCHER: Starting worker discovery
17:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:34 DISPATCHER: Finished worker discovery
17:42:34 DISPATCHER: Starting worker discovery
17:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:34 DISPATCHER: Finished worker discovery
17:43:34 DISPATCHER: Starting worker discovery
17:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:34 DISPATCHER: Finished worker discovery
17:44:34 DISPATCHER: Starting worker discovery
17:44:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:34 DISPATCHER: Finished worker discovery
17:45:34 DISPATCHER: Starting worker discovery
17:45:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:34 DISPATCHER: Finished worker discovery
17:46:34 DISPATCHER: Starting worker discovery
17:46:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:34 DISPATCHER: Finished worker discovery
17:46:51 WORKER: done with job (4, 0, 5), trying to register it.
17:46:51 WORKER: registered result for job (4, 0, 5) with dispatcher
17:46:51 DISPATCHER: job (4, 0, 5) finished
17:46:51 DISPATCHER: register_result: lock acquired
17:46:51 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:46:51 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6247080033080192, 'info': {'data02': 0.6247080033080192, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011616283329572786, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.10611294166103856, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 78, 'num_filters_4': 88}"}}
exception: None

17:46:51 job_callback for (4, 0, 5) started
17:46:51 DISPATCHER: Trying to submit another job.
17:46:51 job_callback for (4, 0, 5) got condition
17:46:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:46:51 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:46:51 HBMASTER: Trying to run another job!
17:46:51 job_callback for (4, 0, 5) finished
17:46:51 HBMASTER: schedule new run for iteration 4
17:46:51 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
17:46:51 HBMASTER: submitting job (4, 0, 17) to dispatcher
17:46:51 DISPATCHER: trying to submit job (4, 0, 17)
17:46:51 DISPATCHER: trying to notify the job_runner thread.
17:46:51 HBMASTER: job (4, 0, 17) submitted to dispatcher
17:46:51 DISPATCHER: Trying to submit another job.
17:46:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:46:51 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:46:51 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:46:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:46:51 WORKER: start processing job (4, 0, 17)
17:46:51 WORKER: args: ()
17:46:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
17:47:34 DISPATCHER: Starting worker discovery
17:47:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:34 DISPATCHER: Finished worker discovery
17:48:34 DISPATCHER: Starting worker discovery
17:48:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:35 DISPATCHER: Finished worker discovery
17:49:35 DISPATCHER: Starting worker discovery
17:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:35 DISPATCHER: Finished worker discovery
17:50:35 DISPATCHER: Starting worker discovery
17:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:35 DISPATCHER: Finished worker discovery
17:51:35 DISPATCHER: Starting worker discovery
17:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:35 DISPATCHER: Finished worker discovery
17:52:35 DISPATCHER: Starting worker discovery
17:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:35 DISPATCHER: Finished worker discovery
17:53:35 DISPATCHER: Starting worker discovery
17:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:35 DISPATCHER: Finished worker discovery
17:53:39 WORKER: done with job (4, 0, 17), trying to register it.
17:53:39 WORKER: registered result for job (4, 0, 17) with dispatcher
17:53:39 DISPATCHER: job (4, 0, 17) finished
17:53:39 DISPATCHER: register_result: lock acquired
17:53:39 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
17:53:39 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.32119959600859826, 'info': {'data02': 0.32119959600859826, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0068921698785893905, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017320387862350548, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 87, 'num_filters_4': 21, 'num_filters_5': 43}"}}
exception: None

17:53:39 job_callback for (4, 0, 17) started
17:53:39 DISPATCHER: Trying to submit another job.
17:53:39 job_callback for (4, 0, 17) got condition
17:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:53:39 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:53:39 HBMASTER: Trying to run another job!
17:53:39 job_callback for (4, 0, 17) finished
17:53:39 HBMASTER: schedule new run for iteration 4
17:53:39 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:53:39 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:53:39 DISPATCHER: trying to submit job (4, 0, 25)
17:53:39 DISPATCHER: trying to notify the job_runner thread.
17:53:39 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:53:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:53:39 DISPATCHER: Trying to submit another job.
17:53:39 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
17:53:39 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
17:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:53:39 WORKER: start processing job (4, 0, 25)
17:53:39 WORKER: args: ()
17:53:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 400.0, 'working_directory': '.'}
17:54:35 DISPATCHER: Starting worker discovery
17:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:35 DISPATCHER: Finished worker discovery
17:55:35 DISPATCHER: Starting worker discovery
17:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:35 DISPATCHER: Finished worker discovery
17:56:35 DISPATCHER: Starting worker discovery
17:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:35 DISPATCHER: Finished worker discovery
17:57:35 DISPATCHER: Starting worker discovery
17:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:35 DISPATCHER: Finished worker discovery
17:58:35 DISPATCHER: Starting worker discovery
17:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:35 DISPATCHER: Finished worker discovery
17:59:35 DISPATCHER: Starting worker discovery
17:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:35 DISPATCHER: Finished worker discovery
18:00:25 WORKER: done with job (4, 0, 25), trying to register it.
18:00:25 WORKER: registered result for job (4, 0, 25) with dispatcher
18:00:25 DISPATCHER: job (4, 0, 25) finished
18:00:25 DISPATCHER: register_result: lock acquired
18:00:25 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:00:25 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6845991110039806, 'info': {'data02': 0.6845991110039806, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}"}}
exception: None

18:00:25 job_callback for (4, 0, 25) started
18:00:25 job_callback for (4, 0, 25) got condition
18:00:25 DISPATCHER: Trying to submit another job.
18:00:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:00:25 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:00:25 HBMASTER: Trying to run another job!
18:00:25 job_callback for (4, 0, 25) finished
18:00:25 ITERATION: Advancing config (4, 0, 25) to next budget 1200.000000
18:00:25 HBMASTER: schedule new run for iteration 4
18:00:25 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
18:00:25 HBMASTER: submitting job (4, 0, 25) to dispatcher
18:00:25 DISPATCHER: trying to submit job (4, 0, 25)
18:00:25 DISPATCHER: trying to notify the job_runner thread.
18:00:25 HBMASTER: job (4, 0, 25) submitted to dispatcher
18:00:25 DISPATCHER: Trying to submit another job.
18:00:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:00:25 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:00:25 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:00:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:00:25 WORKER: start processing job (4, 0, 25)
18:00:25 WORKER: args: ()
18:00:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 1200.0, 'working_directory': '.'}
18:00:35 DISPATCHER: Starting worker discovery
18:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:35 DISPATCHER: Finished worker discovery
18:01:35 DISPATCHER: Starting worker discovery
18:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:35 DISPATCHER: Finished worker discovery
18:02:35 DISPATCHER: Starting worker discovery
18:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:35 DISPATCHER: Finished worker discovery
18:03:35 DISPATCHER: Starting worker discovery
18:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:35 DISPATCHER: Finished worker discovery
18:04:35 DISPATCHER: Starting worker discovery
18:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:35 DISPATCHER: Finished worker discovery
18:05:35 DISPATCHER: Starting worker discovery
18:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:35 DISPATCHER: Finished worker discovery
18:06:35 DISPATCHER: Starting worker discovery
18:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:35 DISPATCHER: Finished worker discovery
18:07:35 DISPATCHER: Starting worker discovery
18:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:35 DISPATCHER: Finished worker discovery
18:08:35 DISPATCHER: Starting worker discovery
18:08:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:35 DISPATCHER: Finished worker discovery
18:09:35 DISPATCHER: Starting worker discovery
18:09:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:35 DISPATCHER: Finished worker discovery
18:10:35 DISPATCHER: Starting worker discovery
18:10:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:35 DISPATCHER: Finished worker discovery
18:11:35 DISPATCHER: Starting worker discovery
18:11:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:35 DISPATCHER: Finished worker discovery
18:12:35 DISPATCHER: Starting worker discovery
18:12:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:35 DISPATCHER: Finished worker discovery
18:13:35 DISPATCHER: Starting worker discovery
18:13:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:35 DISPATCHER: Finished worker discovery
18:14:35 DISPATCHER: Starting worker discovery
18:14:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:35 DISPATCHER: Finished worker discovery
18:15:35 DISPATCHER: Starting worker discovery
18:15:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:35 DISPATCHER: Finished worker discovery
18:16:35 DISPATCHER: Starting worker discovery
18:16:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:35 DISPATCHER: Finished worker discovery
18:17:35 DISPATCHER: Starting worker discovery
18:17:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:35 DISPATCHER: Finished worker discovery
18:18:35 DISPATCHER: Starting worker discovery
18:18:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:35 DISPATCHER: Finished worker discovery
18:19:35 DISPATCHER: Starting worker discovery
18:19:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:35 DISPATCHER: Finished worker discovery
18:20:35 WORKER: done with job (4, 0, 25), trying to register it.
18:20:35 WORKER: registered result for job (4, 0, 25) with dispatcher
18:20:35 DISPATCHER: job (4, 0, 25) finished
18:20:35 DISPATCHER: register_result: lock acquired
18:20:35 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:20:35 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5470015986805958, 'info': {'data02': 0.5470015986805958, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0078984504171742, 'num_filters_1': 127, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.043661212430887386, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 120, 'num_filters_3': 108, 'num_filters_4': 45}"}}
exception: None

18:20:35 job_callback for (4, 0, 25) started
18:20:35 DISPATCHER: Trying to submit another job.
18:20:35 job_callback for (4, 0, 25) got condition
18:20:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:20:35 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:20:35 HBMASTER: Trying to run another job!
18:20:35 job_callback for (4, 0, 25) finished
18:20:35 start sampling a new configuration.
18:20:35 best_vector: [3, 0, 0.2736924416737655, 0.36474366898320687, 0.5453556872940672, 1, 0.05469981859067127, 0.5577192128189239, 2, 2, 1, 2, 0.53216299144043, 0.6446151073045453, 0.35547675033965204, 0.48292889305399794], 8.614457552285576e-33, 1.1608391984410922, -9.529403723994783e-06
18:20:35 done sampling a new configuration.
18:20:35 HBMASTER: schedule new run for iteration 5
18:20:35 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
18:20:35 HBMASTER: submitting job (5, 0, 0) to dispatcher
18:20:35 DISPATCHER: trying to submit job (5, 0, 0)
18:20:35 DISPATCHER: trying to notify the job_runner thread.
18:20:35 HBMASTER: job (5, 0, 0) submitted to dispatcher
18:20:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:20:35 DISPATCHER: Trying to submit another job.
18:20:35 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:20:35 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:20:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:20:35 WORKER: start processing job (5, 0, 0)
18:20:35 WORKER: args: ()
18:20:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0035268328991862803, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.05316299323530135, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:20:35 DISPATCHER: Starting worker discovery
18:20:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:35 DISPATCHER: Finished worker discovery
18:21:35 DISPATCHER: Starting worker discovery
18:21:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:35 DISPATCHER: Finished worker discovery
18:22:35 DISPATCHER: Starting worker discovery
18:22:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:35 DISPATCHER: Finished worker discovery
18:22:54 WORKER: done with job (5, 0, 0), trying to register it.
18:22:54 WORKER: registered result for job (5, 0, 0) with dispatcher
18:22:54 DISPATCHER: job (5, 0, 0) finished
18:22:54 DISPATCHER: register_result: lock acquired
18:22:54 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:22:54 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0035268328991862803, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.05316299323530135, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6786775671518726, 'info': {'data02': 0.6786775671518726, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0035268328991862803, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.05316299323530135, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 61}"}}
exception: None

18:22:54 job_callback for (5, 0, 0) started
18:22:54 job_callback for (5, 0, 0) got condition
18:22:54 DISPATCHER: Trying to submit another job.
18:22:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:22:54 HBMASTER: Trying to run another job!
18:22:54 job_callback for (5, 0, 0) finished
18:22:54 start sampling a new configuration.
18:22:54 best_vector: [3, 2, 0.35293949134344, 0.15891306136366332, 0.15198460924960477, 1, 0.18748496607772658, 0.10618936973277317, 0, 0, 0, 2, 0.18022856048132097, 0.9958746111870025, 0.7127609363542533, 0.48371114886204736], 1.679375610698455e-30, 0.005954594038579008, -1.325516914734739e-05
18:22:54 done sampling a new configuration.
18:22:54 HBMASTER: schedule new run for iteration 5
18:22:54 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
18:22:54 HBMASTER: submitting job (5, 0, 1) to dispatcher
18:22:54 DISPATCHER: trying to submit job (5, 0, 1)
18:22:54 DISPATCHER: trying to notify the job_runner thread.
18:22:54 HBMASTER: job (5, 0, 1) submitted to dispatcher
18:22:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:22:54 DISPATCHER: Trying to submit another job.
18:22:54 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:22:54 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:22:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:22:54 WORKER: start processing job (5, 0, 1)
18:22:54 WORKER: args: ()
18:22:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005080178623063586, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.013745342163954693}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:23:35 DISPATCHER: Starting worker discovery
18:23:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:35 DISPATCHER: Finished worker discovery
18:24:35 DISPATCHER: Starting worker discovery
18:24:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:35 DISPATCHER: Finished worker discovery
18:25:13 WORKER: done with job (5, 0, 1), trying to register it.
18:25:13 WORKER: registered result for job (5, 0, 1) with dispatcher
18:25:13 DISPATCHER: job (5, 0, 1) finished
18:25:13 DISPATCHER: register_result: lock acquired
18:25:13 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:25:13 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005080178623063586, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.013745342163954693}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4613347562370095, 'info': {'data02': 0.4613347562370095, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005080178623063586, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.013745342163954693}"}}
exception: None

18:25:13 job_callback for (5, 0, 1) started
18:25:13 job_callback for (5, 0, 1) got condition
18:25:13 DISPATCHER: Trying to submit another job.
18:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:25:13 HBMASTER: Trying to run another job!
18:25:13 job_callback for (5, 0, 1) finished
18:25:13 start sampling a new configuration.
18:25:13 best_vector: [2, 2, 0.33646955716696825, 0.9682924398941393, 0.44972538949543506, 1, 0.7831132823171484, 0.5988651017109177, 2, 2, 0, 2, 0.993440531287723, 0.8817836675242207, 0.9524747342151002, 0.4805791915178287], 9.949394165518097e-32, 0.10050863232112453, -1.0713736625708956e-05
18:25:13 done sampling a new configuration.
18:25:13 HBMASTER: schedule new run for iteration 5
18:25:13 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:25:13 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:25:13 DISPATCHER: trying to submit job (5, 0, 2)
18:25:13 DISPATCHER: trying to notify the job_runner thread.
18:25:13 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:25:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:25:13 DISPATCHER: Trying to submit another job.
18:25:13 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:25:13 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:25:13 WORKER: start processing job (5, 0, 2)
18:25:13 WORKER: args: ()
18:25:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:25:35 DISPATCHER: Starting worker discovery
18:25:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:35 DISPATCHER: Finished worker discovery
18:26:35 DISPATCHER: Starting worker discovery
18:26:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:35 DISPATCHER: Finished worker discovery
18:27:33 WORKER: done with job (5, 0, 2), trying to register it.
18:27:33 WORKER: registered result for job (5, 0, 2) with dispatcher
18:27:33 DISPATCHER: job (5, 0, 2) finished
18:27:33 DISPATCHER: register_result: lock acquired
18:27:33 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:27:33 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7061526323648812, 'info': {'data02': 0.7061526323648812, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}"}}
exception: None

18:27:33 job_callback for (5, 0, 2) started
18:27:33 DISPATCHER: Trying to submit another job.
18:27:33 job_callback for (5, 0, 2) got condition
18:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:27:33 HBMASTER: Trying to run another job!
18:27:33 job_callback for (5, 0, 2) finished
18:27:33 start sampling a new configuration.
18:27:33 best_vector: [3, 2, 0.44845727733054624, 0.8521801699990226, 0.8243525919506856, 1, 0.021310812786756284, 0.2249565448546066, 0, 1, 0, 2, 0.5607084289561981, 0.8302598763961423, 0.7225447511656188, 0.48139163242284055], 8.345288479164965e-32, 0.1198280925215015, -3.568964691185192e-06
18:27:33 done sampling a new configuration.
18:27:33 HBMASTER: schedule new run for iteration 5
18:27:33 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
18:27:33 HBMASTER: submitting job (5, 0, 3) to dispatcher
18:27:33 DISPATCHER: trying to submit job (5, 0, 3)
18:27:33 DISPATCHER: trying to notify the job_runner thread.
18:27:33 HBMASTER: job (5, 0, 3) submitted to dispatcher
18:27:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:27:33 DISPATCHER: Trying to submit another job.
18:27:33 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:27:33 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:27:33 WORKER: start processing job (5, 0, 3)
18:27:33 WORKER: args: ()
18:27:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007887049284724864, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.01961892525417524, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 51, 'num_filters_3': 90, 'num_filters_4': 71, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:27:35 DISPATCHER: Starting worker discovery
18:27:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:35 DISPATCHER: Finished worker discovery
18:28:35 DISPATCHER: Starting worker discovery
18:28:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:35 DISPATCHER: Finished worker discovery
18:29:35 DISPATCHER: Starting worker discovery
18:29:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:35 DISPATCHER: Finished worker discovery
18:29:53 WORKER: done with job (5, 0, 3), trying to register it.
18:29:53 WORKER: registered result for job (5, 0, 3) with dispatcher
18:29:53 DISPATCHER: job (5, 0, 3) finished
18:29:53 DISPATCHER: register_result: lock acquired
18:29:53 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:29:53 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007887049284724864, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.01961892525417524, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 51, 'num_filters_3': 90, 'num_filters_4': 71, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5067990243277244, 'info': {'data02': 0.5067990243277244, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007887049284724864, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.01961892525417524, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 51, 'num_filters_3': 90, 'num_filters_4': 71, 'num_filters_5': 43}"}}
exception: None

18:29:53 job_callback for (5, 0, 3) started
18:29:53 DISPATCHER: Trying to submit another job.
18:29:53 job_callback for (5, 0, 3) got condition
18:29:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:29:54 HBMASTER: Trying to run another job!
18:29:54 job_callback for (5, 0, 3) finished
18:29:54 start sampling a new configuration.
18:29:54 done sampling a new configuration.
18:29:54 HBMASTER: schedule new run for iteration 5
18:29:54 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
18:29:54 HBMASTER: submitting job (5, 0, 4) to dispatcher
18:29:54 DISPATCHER: trying to submit job (5, 0, 4)
18:29:54 DISPATCHER: trying to notify the job_runner thread.
18:29:54 HBMASTER: job (5, 0, 4) submitted to dispatcher
18:29:54 DISPATCHER: Trying to submit another job.
18:29:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:29:54 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:29:54 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:29:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:29:54 WORKER: start processing job (5, 0, 4)
18:29:54 WORKER: args: ()
18:29:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.011104135604852749, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.04169545318508789, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:30:35 DISPATCHER: Starting worker discovery
18:30:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:35 DISPATCHER: Finished worker discovery
18:31:35 DISPATCHER: Starting worker discovery
18:31:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:35 DISPATCHER: Finished worker discovery
18:32:13 WORKER: done with job (5, 0, 4), trying to register it.
18:32:13 WORKER: registered result for job (5, 0, 4) with dispatcher
18:32:13 DISPATCHER: job (5, 0, 4) finished
18:32:13 DISPATCHER: register_result: lock acquired
18:32:13 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:32:13 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.011104135604852749, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.04169545318508789, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.011104135604852749, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.04169545318508789, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 22}"}}
exception: None

18:32:13 job_callback for (5, 0, 4) started
18:32:13 DISPATCHER: Trying to submit another job.
18:32:13 job_callback for (5, 0, 4) got condition
18:32:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:32:13 HBMASTER: Trying to run another job!
18:32:13 job_callback for (5, 0, 4) finished
18:32:13 start sampling a new configuration.
18:32:13 done sampling a new configuration.
18:32:13 HBMASTER: schedule new run for iteration 5
18:32:13 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
18:32:13 HBMASTER: submitting job (5, 0, 5) to dispatcher
18:32:13 DISPATCHER: trying to submit job (5, 0, 5)
18:32:13 DISPATCHER: trying to notify the job_runner thread.
18:32:13 HBMASTER: job (5, 0, 5) submitted to dispatcher
18:32:13 DISPATCHER: Trying to submit another job.
18:32:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:32:13 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:32:13 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:32:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:32:13 WORKER: start processing job (5, 0, 5)
18:32:13 WORKER: args: ()
18:32:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001398606960270155, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.042948774830802484}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:32:35 DISPATCHER: Starting worker discovery
18:32:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:35 DISPATCHER: Finished worker discovery
18:33:35 DISPATCHER: Starting worker discovery
18:33:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:35 DISPATCHER: Finished worker discovery
18:34:33 WORKER: done with job (5, 0, 5), trying to register it.
18:34:33 WORKER: registered result for job (5, 0, 5) with dispatcher
18:34:33 DISPATCHER: job (5, 0, 5) finished
18:34:33 DISPATCHER: register_result: lock acquired
18:34:33 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:34:33 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001398606960270155, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.042948774830802484}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5700295033829436, 'info': {'data02': 0.5700295033829436, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001398606960270155, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.042948774830802484}"}}
exception: None

18:34:33 job_callback for (5, 0, 5) started
18:34:33 DISPATCHER: Trying to submit another job.
18:34:33 job_callback for (5, 0, 5) got condition
18:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:34:33 HBMASTER: Trying to run another job!
18:34:33 job_callback for (5, 0, 5) finished
18:34:33 start sampling a new configuration.
18:34:33 best_vector: [3, 1, 0.0461824453672596, 0.23501934981899922, 0.43192845377223743, 1, 0.1911864759613373, 0.32030974826927283, 2, 2, 2, 2, 0.4251851568691099, 0.6333253828278453, 0.042510027549188825, 0.47963589791124694], 3.944792207839365e-31, 0.025349877694767566, -4.313129654621987e-05
18:34:33 done sampling a new configuration.
18:34:33 HBMASTER: schedule new run for iteration 5
18:34:33 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
18:34:33 HBMASTER: submitting job (5, 0, 6) to dispatcher
18:34:33 DISPATCHER: trying to submit job (5, 0, 6)
18:34:33 DISPATCHER: trying to notify the job_runner thread.
18:34:33 HBMASTER: job (5, 0, 6) submitted to dispatcher
18:34:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:34:33 DISPATCHER: Trying to submit another job.
18:34:33 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:34:33 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:34:33 WORKER: start processing job (5, 0, 6)
18:34:33 WORKER: args: ()
18:34:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012369863029121125, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.02610553454596055, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:34:35 DISPATCHER: Starting worker discovery
18:34:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:35 DISPATCHER: Finished worker discovery
18:35:35 DISPATCHER: Starting worker discovery
18:35:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:35 DISPATCHER: Finished worker discovery
18:36:35 DISPATCHER: Starting worker discovery
18:36:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:35 DISPATCHER: Finished worker discovery
18:36:51 WORKER: done with job (5, 0, 6), trying to register it.
18:36:51 WORKER: registered result for job (5, 0, 6) with dispatcher
18:36:51 DISPATCHER: job (5, 0, 6) finished
18:36:51 DISPATCHER: register_result: lock acquired
18:36:51 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:36:51 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012369863029121125, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.02610553454596055, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5288551861919293, 'info': {'data02': 0.5288551861919293, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012369863029121125, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.02610553454596055, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 59}"}}
exception: None

18:36:51 job_callback for (5, 0, 6) started
18:36:51 job_callback for (5, 0, 6) got condition
18:36:51 DISPATCHER: Trying to submit another job.
18:36:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:36:51 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.740036





18:36:51 HBMASTER: Trying to run another job!
18:36:51 job_callback for (5, 0, 6) finished
18:36:51 start sampling a new configuration.
18:36:51 done sampling a new configuration.
18:36:51 HBMASTER: schedule new run for iteration 5
18:36:51 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
18:36:51 HBMASTER: submitting job (5, 0, 7) to dispatcher
18:36:51 DISPATCHER: trying to submit job (5, 0, 7)
18:36:51 DISPATCHER: trying to notify the job_runner thread.
18:36:51 HBMASTER: job (5, 0, 7) submitted to dispatcher
18:36:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:36:51 DISPATCHER: Trying to submit another job.
18:36:51 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:36:51 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:36:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:36:51 WORKER: start processing job (5, 0, 7)
18:36:51 WORKER: args: ()
18:36:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014780369521911, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.0765033795974718, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:37:35 DISPATCHER: Starting worker discovery
18:37:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:36 DISPATCHER: Finished worker discovery
18:38:36 DISPATCHER: Starting worker discovery
18:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:36 DISPATCHER: Finished worker discovery
18:39:10 WORKER: done with job (5, 0, 7), trying to register it.
18:39:10 WORKER: registered result for job (5, 0, 7) with dispatcher
18:39:10 DISPATCHER: job (5, 0, 7) finished
18:39:10 DISPATCHER: register_result: lock acquired
18:39:10 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:39:10 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014780369521911, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.0765033795974718, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4240477132736863, 'info': {'data02': 0.4240477132736863, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014780369521911, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.0765033795974718, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 17}"}}
exception: None

18:39:10 job_callback for (5, 0, 7) started
18:39:10 DISPATCHER: Trying to submit another job.
18:39:10 job_callback for (5, 0, 7) got condition
18:39:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:10 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.740036





18:39:10 HBMASTER: Trying to run another job!
18:39:10 job_callback for (5, 0, 7) finished
18:39:10 start sampling a new configuration.
18:39:10 best_vector: [1, 0, 0.3418279082262725, 0.28990117971757534, 0.942754551735172, 1, 0.26226396191698387, 0.5939774994955754, 2, 2, 1, 2, 0.15753247046166707, 0.11396317255587662, 0.9985747670863105, 0.480751113804408], 2.0271575381271727e-29, 0.0004933015718767811, -2.2080731094448262e-07
18:39:10 done sampling a new configuration.
18:39:10 HBMASTER: schedule new run for iteration 5
18:39:10 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
18:39:10 HBMASTER: submitting job (5, 0, 8) to dispatcher
18:39:10 DISPATCHER: trying to submit job (5, 0, 8)
18:39:10 DISPATCHER: trying to notify the job_runner thread.
18:39:10 HBMASTER: job (5, 0, 8) submitted to dispatcher
18:39:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:10 DISPATCHER: Trying to submit another job.
18:39:10 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:39:10 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:39:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:10 WORKER: start processing job (5, 0, 8)
18:39:10 WORKER: args: ()
18:39:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004826761238465813, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.059262851414013044, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 20, 'num_filters_4': 128, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:39:36 DISPATCHER: Starting worker discovery
18:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:36 DISPATCHER: Finished worker discovery
18:40:36 DISPATCHER: Starting worker discovery
18:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:36 DISPATCHER: Finished worker discovery
18:41:29 WORKER: done with job (5, 0, 8), trying to register it.
18:41:29 WORKER: registered result for job (5, 0, 8) with dispatcher
18:41:29 DISPATCHER: job (5, 0, 8) finished
18:41:29 DISPATCHER: register_result: lock acquired
18:41:29 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:41:29 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004826761238465813, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.059262851414013044, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 20, 'num_filters_4': 128, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6123289316466899, 'info': {'data02': 0.6123289316466899, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004826761238465813, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.059262851414013044, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 20, 'num_filters_4': 128, 'num_filters_5': 43}"}}
exception: None

18:41:29 job_callback for (5, 0, 8) started
18:41:29 DISPATCHER: Trying to submit another job.
18:41:29 job_callback for (5, 0, 8) got condition
18:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:41:29 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.740036





18:41:29 HBMASTER: Trying to run another job!
18:41:29 job_callback for (5, 0, 8) finished
18:41:29 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
18:41:29 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
18:41:29 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
18:41:29 HBMASTER: schedule new run for iteration 5
18:41:29 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
18:41:29 HBMASTER: submitting job (5, 0, 0) to dispatcher
18:41:29 DISPATCHER: trying to submit job (5, 0, 0)
18:41:29 DISPATCHER: trying to notify the job_runner thread.
18:41:29 HBMASTER: job (5, 0, 0) submitted to dispatcher
18:41:29 DISPATCHER: Trying to submit another job.
18:41:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:41:29 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:41:29 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:41:29 WORKER: start processing job (5, 0, 0)
18:41:29 WORKER: args: ()
18:41:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0035268328991862803, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.05316299323530135, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 61}, 'budget': 400.0, 'working_directory': '.'}
18:41:36 DISPATCHER: Starting worker discovery
18:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:36 DISPATCHER: Finished worker discovery
18:42:36 DISPATCHER: Starting worker discovery
18:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:36 DISPATCHER: Finished worker discovery
18:43:36 DISPATCHER: Starting worker discovery
18:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:36 DISPATCHER: Finished worker discovery
18:44:36 DISPATCHER: Starting worker discovery
18:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:36 DISPATCHER: Finished worker discovery
18:45:36 DISPATCHER: Starting worker discovery
18:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:36 DISPATCHER: Finished worker discovery
18:46:36 DISPATCHER: Starting worker discovery
18:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:36 DISPATCHER: Finished worker discovery
18:47:36 DISPATCHER: Starting worker discovery
18:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:36 DISPATCHER: Finished worker discovery
18:48:18 WORKER: done with job (5, 0, 0), trying to register it.
18:48:18 WORKER: registered result for job (5, 0, 0) with dispatcher
18:48:18 DISPATCHER: job (5, 0, 0) finished
18:48:18 DISPATCHER: register_result: lock acquired
18:48:18 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:48:18 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0035268328991862803, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.05316299323530135, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 61}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5116072257212378, 'info': {'data02': 0.5116072257212378, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0035268328991862803, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.05316299323530135, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 61}"}}
exception: None

18:48:18 job_callback for (5, 0, 0) started
18:48:18 DISPATCHER: Trying to submit another job.
18:48:18 job_callback for (5, 0, 0) got condition
18:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:18 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:48:18 HBMASTER: Trying to run another job!
18:48:18 job_callback for (5, 0, 0) finished
18:48:18 HBMASTER: schedule new run for iteration 5
18:48:18 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:48:18 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:48:18 DISPATCHER: trying to submit job (5, 0, 2)
18:48:18 DISPATCHER: trying to notify the job_runner thread.
18:48:18 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:48:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:18 DISPATCHER: Trying to submit another job.
18:48:18 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:48:18 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:18 WORKER: start processing job (5, 0, 2)
18:48:18 WORKER: args: ()
18:48:18 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}, 'budget': 400.0, 'working_directory': '.'}
18:48:36 DISPATCHER: Starting worker discovery
18:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:36 DISPATCHER: Finished worker discovery
18:49:36 DISPATCHER: Starting worker discovery
18:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:36 DISPATCHER: Finished worker discovery
18:50:36 DISPATCHER: Starting worker discovery
18:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:36 DISPATCHER: Finished worker discovery
18:51:36 DISPATCHER: Starting worker discovery
18:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:36 DISPATCHER: Finished worker discovery
18:52:36 DISPATCHER: Starting worker discovery
18:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:36 DISPATCHER: Finished worker discovery
18:53:36 DISPATCHER: Starting worker discovery
18:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:36 DISPATCHER: Finished worker discovery
18:54:36 DISPATCHER: Starting worker discovery
18:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:36 DISPATCHER: Finished worker discovery
18:55:04 WORKER: done with job (5, 0, 2), trying to register it.
18:55:04 WORKER: registered result for job (5, 0, 2) with dispatcher
18:55:04 DISPATCHER: job (5, 0, 2) finished
18:55:04 DISPATCHER: register_result: lock acquired
18:55:04 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
18:55:04 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6197760010872527, 'info': {'data02': 0.6197760010872527, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}"}}
exception: None

18:55:04 job_callback for (5, 0, 2) started
18:55:04 job_callback for (5, 0, 2) got condition
18:55:04 DISPATCHER: Trying to submit another job.
18:55:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:55:04 HBMASTER: Trying to run another job!
18:55:04 job_callback for (5, 0, 2) finished
18:55:04 HBMASTER: schedule new run for iteration 5
18:55:04 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
18:55:04 HBMASTER: submitting job (5, 0, 8) to dispatcher
18:55:04 DISPATCHER: trying to submit job (5, 0, 8)
18:55:04 DISPATCHER: trying to notify the job_runner thread.
18:55:04 HBMASTER: job (5, 0, 8) submitted to dispatcher
18:55:04 DISPATCHER: Trying to submit another job.
18:55:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:55:04 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
18:55:04 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
18:55:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:55:04 WORKER: start processing job (5, 0, 8)
18:55:04 WORKER: args: ()
18:55:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004826761238465813, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.059262851414013044, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 20, 'num_filters_4': 128, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
18:55:36 DISPATCHER: Starting worker discovery
18:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:36 DISPATCHER: Finished worker discovery
18:56:36 DISPATCHER: Starting worker discovery
18:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:36 DISPATCHER: Finished worker discovery
18:57:36 DISPATCHER: Starting worker discovery
18:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:36 DISPATCHER: Finished worker discovery
18:58:36 DISPATCHER: Starting worker discovery
18:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:36 DISPATCHER: Finished worker discovery
18:59:36 DISPATCHER: Starting worker discovery
18:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:36 DISPATCHER: Finished worker discovery
19:00:36 DISPATCHER: Starting worker discovery
19:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:36 DISPATCHER: Finished worker discovery
19:01:36 DISPATCHER: Starting worker discovery
19:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:36 DISPATCHER: Finished worker discovery
19:01:51 WORKER: done with job (5, 0, 8), trying to register it.
19:01:51 WORKER: registered result for job (5, 0, 8) with dispatcher
19:01:51 DISPATCHER: job (5, 0, 8) finished
19:01:51 DISPATCHER: register_result: lock acquired
19:01:51 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:01:51 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004826761238465813, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.059262851414013044, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 20, 'num_filters_4': 128, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5359423835874845, 'info': {'data02': 0.5359423835874845, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004826761238465813, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.059262851414013044, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 20, 'num_filters_4': 128, 'num_filters_5': 43}"}}
exception: None

19:01:51 job_callback for (5, 0, 8) started
19:01:51 DISPATCHER: Trying to submit another job.
19:01:51 job_callback for (5, 0, 8) got condition
19:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:01:51 HBMASTER: Trying to run another job!
19:01:51 job_callback for (5, 0, 8) finished
19:01:51 ITERATION: Advancing config (5, 0, 2) to next budget 1200.000000
19:01:51 HBMASTER: schedule new run for iteration 5
19:01:51 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
19:01:51 HBMASTER: submitting job (5, 0, 2) to dispatcher
19:01:51 DISPATCHER: trying to submit job (5, 0, 2)
19:01:51 DISPATCHER: trying to notify the job_runner thread.
19:01:51 HBMASTER: job (5, 0, 2) submitted to dispatcher
19:01:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:01:51 DISPATCHER: Trying to submit another job.
19:01:51 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:01:51 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:01:51 WORKER: start processing job (5, 0, 2)
19:01:51 WORKER: args: ()
19:01:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}, 'budget': 1200.0, 'working_directory': '.'}
19:02:36 DISPATCHER: Starting worker discovery
19:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:36 DISPATCHER: Finished worker discovery
19:03:36 DISPATCHER: Starting worker discovery
19:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:36 DISPATCHER: Finished worker discovery
19:04:36 DISPATCHER: Starting worker discovery
19:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:36 DISPATCHER: Finished worker discovery
19:05:36 DISPATCHER: Starting worker discovery
19:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:36 DISPATCHER: Finished worker discovery
19:06:36 DISPATCHER: Starting worker discovery
19:06:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:36 DISPATCHER: Finished worker discovery
19:07:36 DISPATCHER: Starting worker discovery
19:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:36 DISPATCHER: Finished worker discovery
19:08:36 DISPATCHER: Starting worker discovery
19:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:36 DISPATCHER: Finished worker discovery
19:09:36 DISPATCHER: Starting worker discovery
19:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:36 DISPATCHER: Finished worker discovery
19:10:36 DISPATCHER: Starting worker discovery
19:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:36 DISPATCHER: Finished worker discovery
19:11:36 DISPATCHER: Starting worker discovery
19:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:36 DISPATCHER: Finished worker discovery
19:12:36 DISPATCHER: Starting worker discovery
19:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:36 DISPATCHER: Finished worker discovery
19:13:36 DISPATCHER: Starting worker discovery
19:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:36 DISPATCHER: Finished worker discovery
19:14:36 DISPATCHER: Starting worker discovery
19:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:36 DISPATCHER: Finished worker discovery
19:15:36 DISPATCHER: Starting worker discovery
19:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:36 DISPATCHER: Finished worker discovery
19:16:36 DISPATCHER: Starting worker discovery
19:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:36 DISPATCHER: Finished worker discovery
19:17:36 DISPATCHER: Starting worker discovery
19:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:36 DISPATCHER: Finished worker discovery
19:18:36 DISPATCHER: Starting worker discovery
19:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:36 DISPATCHER: Finished worker discovery
19:19:36 DISPATCHER: Starting worker discovery
19:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:36 DISPATCHER: Finished worker discovery
19:20:36 DISPATCHER: Starting worker discovery
19:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:36 DISPATCHER: Finished worker discovery
19:21:36 DISPATCHER: Starting worker discovery
19:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:36 DISPATCHER: Finished worker discovery
19:21:59 WORKER: done with job (5, 0, 2), trying to register it.
19:21:59 WORKER: registered result for job (5, 0, 2) with dispatcher
19:21:59 DISPATCHER: job (5, 0, 2) finished
19:21:59 DISPATCHER: register_result: lock acquired
19:21:59 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:21:59 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5247552995401443, 'info': {'data02': 0.5247552995401443, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004709113026287133, 'num_filters_1': 120, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.060136958684897074, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 127, 'num_filters_3': 100}"}}
exception: None

19:21:59 job_callback for (5, 0, 2) started
19:21:59 job_callback for (5, 0, 2) got condition
19:21:59 DISPATCHER: Trying to submit another job.
19:21:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:21:59 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:21:59 HBMASTER: Trying to run another job!
19:21:59 job_callback for (5, 0, 2) finished
19:21:59 start sampling a new configuration.
19:21:59 done sampling a new configuration.
19:21:59 HBMASTER: schedule new run for iteration 6
19:21:59 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
19:21:59 HBMASTER: submitting job (6, 0, 0) to dispatcher
19:21:59 DISPATCHER: trying to submit job (6, 0, 0)
19:21:59 DISPATCHER: trying to notify the job_runner thread.
19:21:59 HBMASTER: job (6, 0, 0) submitted to dispatcher
19:21:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:21:59 DISPATCHER: Trying to submit another job.
19:21:59 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:21:59 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:21:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:21:59 WORKER: start processing job (6, 0, 0)
19:21:59 WORKER: args: ()
19:21:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005216124259951938, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.1738973737990525, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 400.0, 'working_directory': '.'}
19:22:36 DISPATCHER: Starting worker discovery
19:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:36 DISPATCHER: Finished worker discovery
19:23:36 DISPATCHER: Starting worker discovery
19:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:36 DISPATCHER: Finished worker discovery
19:24:36 DISPATCHER: Starting worker discovery
19:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:36 DISPATCHER: Finished worker discovery
19:25:36 DISPATCHER: Starting worker discovery
19:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:36 DISPATCHER: Finished worker discovery
19:26:36 DISPATCHER: Starting worker discovery
19:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:36 DISPATCHER: Finished worker discovery
19:27:36 DISPATCHER: Starting worker discovery
19:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:36 DISPATCHER: Finished worker discovery
19:28:36 DISPATCHER: Starting worker discovery
19:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:36 DISPATCHER: Finished worker discovery
19:28:46 WORKER: done with job (6, 0, 0), trying to register it.
19:28:46 WORKER: registered result for job (6, 0, 0) with dispatcher
19:28:46 DISPATCHER: job (6, 0, 0) finished
19:28:46 DISPATCHER: register_result: lock acquired
19:28:46 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:28:46 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005216124259951938, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.1738973737990525, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4495410300995253, 'info': {'data02': 0.4495410300995253, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005216124259951938, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.1738973737990525, 'kernel_size_2': 7, 'num_filters_2': 63}"}}
exception: None

19:28:46 job_callback for (6, 0, 0) started
19:28:46 job_callback for (6, 0, 0) got condition
19:28:46 DISPATCHER: Trying to submit another job.
19:28:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:28:46 HBMASTER: Trying to run another job!
19:28:46 job_callback for (6, 0, 0) finished
19:28:46 start sampling a new configuration.
19:28:46 best_vector: [1, 0, 0.1074942301507364, 0.1425735883646675, 0.8617721532280167, 0, 0.493979313577673, 0.0944211515609707, 0, 0, 2, 2, 0.38837167442694465, 0.6972562654965822, 0.005847686448759742, 0.4815976708741997], 4.000934959564076e-31, 0.024994157868263762, -5.951996087537348e-07
19:28:46 done sampling a new configuration.
19:28:46 HBMASTER: schedule new run for iteration 6
19:28:46 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
19:28:46 HBMASTER: submitting job (6, 0, 1) to dispatcher
19:28:46 DISPATCHER: trying to submit job (6, 0, 1)
19:28:46 DISPATCHER: trying to notify the job_runner thread.
19:28:46 HBMASTER: job (6, 0, 1) submitted to dispatcher
19:28:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:28:46 DISPATCHER: Trying to submit another job.
19:28:46 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:28:46 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:28:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:28:46 WORKER: start processing job (6, 0, 1)
19:28:46 WORKER: args: ()
19:28:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001640546181441737, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013269200316666403, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
19:29:36 DISPATCHER: Starting worker discovery
19:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:36 DISPATCHER: Finished worker discovery
19:30:36 DISPATCHER: Starting worker discovery
19:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:36 DISPATCHER: Finished worker discovery
19:31:36 DISPATCHER: Starting worker discovery
19:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:36 DISPATCHER: Finished worker discovery
19:32:36 DISPATCHER: Starting worker discovery
19:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:36 DISPATCHER: Finished worker discovery
19:33:36 DISPATCHER: Starting worker discovery
19:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:36 DISPATCHER: Finished worker discovery
19:34:36 DISPATCHER: Starting worker discovery
19:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:36 DISPATCHER: Finished worker discovery
19:35:32 WORKER: done with job (6, 0, 1), trying to register it.
19:35:32 WORKER: registered result for job (6, 0, 1) with dispatcher
19:35:32 DISPATCHER: job (6, 0, 1) finished
19:35:32 DISPATCHER: register_result: lock acquired
19:35:32 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:35:32 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001640546181441737, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013269200316666403, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3656446664079717, 'info': {'data02': 0.3656446664079717, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001640546181441737, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013269200316666403, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 16, 'num_filters_5': 43}"}}
exception: None

19:35:32 job_callback for (6, 0, 1) started
19:35:32 job_callback for (6, 0, 1) got condition
19:35:32 DISPATCHER: Trying to submit another job.
19:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:35:32 HBMASTER: Trying to run another job!
19:35:32 job_callback for (6, 0, 1) finished
19:35:32 start sampling a new configuration.
19:35:32 done sampling a new configuration.
19:35:32 HBMASTER: schedule new run for iteration 6
19:35:32 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
19:35:32 HBMASTER: submitting job (6, 0, 2) to dispatcher
19:35:32 DISPATCHER: trying to submit job (6, 0, 2)
19:35:32 DISPATCHER: trying to notify the job_runner thread.
19:35:32 HBMASTER: job (6, 0, 2) submitted to dispatcher
19:35:32 DISPATCHER: Trying to submit another job.
19:35:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:35:32 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:35:32 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:35:32 WORKER: start processing job (6, 0, 2)
19:35:32 WORKER: args: ()
19:35:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.024383810941435036, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.033558348793955965, 'kernel_size_2': 5, 'num_filters_2': 112}, 'budget': 400.0, 'working_directory': '.'}
19:35:36 DISPATCHER: Starting worker discovery
19:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:36 DISPATCHER: Finished worker discovery
19:36:36 DISPATCHER: Starting worker discovery
19:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:36 DISPATCHER: Finished worker discovery
19:37:36 DISPATCHER: Starting worker discovery
19:37:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:36 DISPATCHER: Finished worker discovery
19:38:36 DISPATCHER: Starting worker discovery
19:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:36 DISPATCHER: Finished worker discovery
19:39:36 DISPATCHER: Starting worker discovery
19:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:36 DISPATCHER: Finished worker discovery
19:40:36 DISPATCHER: Starting worker discovery
19:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:36 DISPATCHER: Finished worker discovery
19:41:36 DISPATCHER: Starting worker discovery
19:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:36 DISPATCHER: Finished worker discovery
19:42:17 WORKER: done with job (6, 0, 2), trying to register it.
19:42:17 WORKER: registered result for job (6, 0, 2) with dispatcher
19:42:17 DISPATCHER: job (6, 0, 2) finished
19:42:17 DISPATCHER: register_result: lock acquired
19:42:17 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:42:17 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.024383810941435036, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.033558348793955965, 'kernel_size_2': 5, 'num_filters_2': 112}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04120632951591103, 'info': {'data02': 0.04120632951591103, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.024383810941435036, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.033558348793955965, 'kernel_size_2': 5, 'num_filters_2': 112}"}}
exception: None

19:42:17 job_callback for (6, 0, 2) started
19:42:17 DISPATCHER: Trying to submit another job.
19:42:17 job_callback for (6, 0, 2) got condition
19:42:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:42:17 HBMASTER: Trying to run another job!
19:42:17 job_callback for (6, 0, 2) finished
19:42:17 start sampling a new configuration.
19:42:17 done sampling a new configuration.
19:42:17 HBMASTER: schedule new run for iteration 6
19:42:17 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
19:42:17 HBMASTER: submitting job (6, 0, 3) to dispatcher
19:42:17 DISPATCHER: trying to submit job (6, 0, 3)
19:42:17 DISPATCHER: trying to notify the job_runner thread.
19:42:17 HBMASTER: job (6, 0, 3) submitted to dispatcher
19:42:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:42:17 DISPATCHER: Trying to submit another job.
19:42:17 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:42:17 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:42:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:42:17 WORKER: start processing job (6, 0, 3)
19:42:17 WORKER: args: ()
19:42:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01867813784688124, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012076360814919621, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 25, 'num_filters_3': 16, 'num_filters_4': 16, 'num_filters_5': 30}, 'budget': 400.0, 'working_directory': '.'}
19:42:36 DISPATCHER: Starting worker discovery
19:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:36 DISPATCHER: Finished worker discovery
19:43:36 DISPATCHER: Starting worker discovery
19:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:36 DISPATCHER: Finished worker discovery
19:44:36 DISPATCHER: Starting worker discovery
19:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:36 DISPATCHER: Finished worker discovery
19:45:36 DISPATCHER: Starting worker discovery
19:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:36 DISPATCHER: Finished worker discovery
19:46:36 DISPATCHER: Starting worker discovery
19:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:36 DISPATCHER: Finished worker discovery
19:47:36 DISPATCHER: Starting worker discovery
19:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:36 DISPATCHER: Finished worker discovery
19:48:36 DISPATCHER: Starting worker discovery
19:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:36 DISPATCHER: Finished worker discovery
19:49:04 WORKER: done with job (6, 0, 3), trying to register it.
19:49:04 WORKER: registered result for job (6, 0, 3) with dispatcher
19:49:04 DISPATCHER: job (6, 0, 3) finished
19:49:04 DISPATCHER: register_result: lock acquired
19:49:04 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:49:04 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01867813784688124, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012076360814919621, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 25, 'num_filters_3': 16, 'num_filters_4': 16, 'num_filters_5': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.29142139312788606, 'info': {'data02': 0.29142139312788606, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01867813784688124, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012076360814919621, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 25, 'num_filters_3': 16, 'num_filters_4': 16, 'num_filters_5': 30}"}}
exception: None

19:49:04 job_callback for (6, 0, 3) started
19:49:04 job_callback for (6, 0, 3) got condition
19:49:04 DISPATCHER: Trying to submit another job.
19:49:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:49:04 HBMASTER: Trying to run another job!
19:49:04 job_callback for (6, 0, 3) finished
19:49:04 start sampling a new configuration.
19:49:04 best_vector: [1, 2, 0.17093826719937877, 0.49138706879287475, 0.9344991917915898, 0, 0.6706441150742749, 0.08845893792360349, 2, 0, 0, 2, 0.4416827519813076, 0.30203201581114214, 0.14473789822730954, 0.4832657977527764], 1.7488564434599748e-31, 0.057180222181163066, -1.7939789422430681e-06
19:49:04 done sampling a new configuration.
19:49:04 HBMASTER: schedule new run for iteration 6
19:49:04 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
19:49:04 HBMASTER: submitting job (6, 0, 4) to dispatcher
19:49:04 DISPATCHER: trying to submit job (6, 0, 4)
19:49:04 DISPATCHER: trying to notify the job_runner thread.
19:49:04 HBMASTER: job (6, 0, 4) submitted to dispatcher
19:49:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:49:04 DISPATCHER: Trying to submit another job.
19:49:04 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:49:04 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:49:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:49:04 WORKER: start processing job (6, 0, 4)
19:49:04 WORKER: args: ()
19:49:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0021972351318933023, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.013034300571492796, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 29, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
19:49:36 DISPATCHER: Starting worker discovery
19:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:36 DISPATCHER: Finished worker discovery
19:50:36 DISPATCHER: Starting worker discovery
19:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:36 DISPATCHER: Finished worker discovery
19:51:36 DISPATCHER: Starting worker discovery
19:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:36 DISPATCHER: Finished worker discovery
19:52:36 DISPATCHER: Starting worker discovery
19:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:36 DISPATCHER: Finished worker discovery
19:53:36 DISPATCHER: Starting worker discovery
19:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:36 DISPATCHER: Finished worker discovery
19:54:36 DISPATCHER: Starting worker discovery
19:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:36 DISPATCHER: Finished worker discovery
19:55:36 DISPATCHER: Starting worker discovery
19:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:36 DISPATCHER: Finished worker discovery
19:55:50 WORKER: done with job (6, 0, 4), trying to register it.
19:55:50 WORKER: registered result for job (6, 0, 4) with dispatcher
19:55:50 DISPATCHER: job (6, 0, 4) finished
19:55:50 DISPATCHER: register_result: lock acquired
19:55:50 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
19:55:50 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0021972351318933023, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.013034300571492796, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 29, 'num_filters_4': 21, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.33486890462808905, 'info': {'data02': 0.33486890462808905, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0021972351318933023, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.013034300571492796, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 29, 'num_filters_4': 21, 'num_filters_5': 43}"}}
exception: None

19:55:50 job_callback for (6, 0, 4) started
19:55:50 job_callback for (6, 0, 4) got condition
19:55:50 DISPATCHER: Trying to submit another job.
19:55:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:50 HBMASTER: Trying to run another job!
19:55:50 job_callback for (6, 0, 4) finished
19:55:50 start sampling a new configuration.
19:55:50 done sampling a new configuration.
19:55:50 HBMASTER: schedule new run for iteration 6
19:55:50 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
19:55:50 HBMASTER: submitting job (6, 0, 5) to dispatcher
19:55:50 DISPATCHER: trying to submit job (6, 0, 5)
19:55:50 DISPATCHER: trying to notify the job_runner thread.
19:55:50 HBMASTER: job (6, 0, 5) submitted to dispatcher
19:55:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:50 DISPATCHER: Trying to submit another job.
19:55:50 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
19:55:50 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
19:55:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:50 WORKER: start processing job (6, 0, 5)
19:55:50 WORKER: args: ()
19:55:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02117127191831083, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.015748799364844496, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 107}, 'budget': 400.0, 'working_directory': '.'}
19:56:36 DISPATCHER: Starting worker discovery
19:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:36 DISPATCHER: Finished worker discovery
19:57:36 DISPATCHER: Starting worker discovery
19:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:36 DISPATCHER: Finished worker discovery
19:58:36 DISPATCHER: Starting worker discovery
19:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:36 DISPATCHER: Finished worker discovery
19:59:36 DISPATCHER: Starting worker discovery
19:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:36 DISPATCHER: Finished worker discovery
20:00:36 DISPATCHER: Starting worker discovery
20:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:36 DISPATCHER: Finished worker discovery
20:01:36 DISPATCHER: Starting worker discovery
20:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:36 DISPATCHER: Finished worker discovery
20:02:36 DISPATCHER: Starting worker discovery
20:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:37 DISPATCHER: Finished worker discovery
20:02:43 WORKER: done with job (6, 0, 5), trying to register it.
20:02:43 WORKER: registered result for job (6, 0, 5) with dispatcher
20:02:43 DISPATCHER: job (6, 0, 5) finished
20:02:43 DISPATCHER: register_result: lock acquired
20:02:43 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:02:43 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02117127191831083, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.015748799364844496, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 107}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3195306027379028, 'info': {'data02': 0.3195306027379028, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02117127191831083, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.015748799364844496, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 107}"}}
exception: None

20:02:43 job_callback for (6, 0, 5) started
20:02:43 job_callback for (6, 0, 5) got condition
20:02:43 DISPATCHER: Trying to submit another job.
20:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:02:43 HBMASTER: Trying to run another job!
20:02:43 job_callback for (6, 0, 5) finished
20:02:43 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
20:02:43 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
20:02:43 HBMASTER: schedule new run for iteration 6
20:02:43 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
20:02:43 HBMASTER: submitting job (6, 0, 0) to dispatcher
20:02:43 DISPATCHER: trying to submit job (6, 0, 0)
20:02:43 DISPATCHER: trying to notify the job_runner thread.
20:02:43 HBMASTER: job (6, 0, 0) submitted to dispatcher
20:02:43 DISPATCHER: Trying to submit another job.
20:02:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:02:43 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:02:43 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:02:43 WORKER: start processing job (6, 0, 0)
20:02:43 WORKER: args: ()
20:02:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005216124259951938, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.1738973737990525, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 1200.0, 'working_directory': '.'}
20:03:37 DISPATCHER: Starting worker discovery
20:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:37 DISPATCHER: Finished worker discovery
20:04:37 DISPATCHER: Starting worker discovery
20:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:37 DISPATCHER: Finished worker discovery
20:05:37 DISPATCHER: Starting worker discovery
20:05:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:37 DISPATCHER: Finished worker discovery
20:06:37 DISPATCHER: Starting worker discovery
20:06:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:37 DISPATCHER: Finished worker discovery
20:07:37 DISPATCHER: Starting worker discovery
20:07:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:37 DISPATCHER: Finished worker discovery
20:08:37 DISPATCHER: Starting worker discovery
20:08:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:37 DISPATCHER: Finished worker discovery
20:09:37 DISPATCHER: Starting worker discovery
20:09:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:37 DISPATCHER: Finished worker discovery
20:10:37 DISPATCHER: Starting worker discovery
20:10:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:37 DISPATCHER: Finished worker discovery
20:11:37 DISPATCHER: Starting worker discovery
20:11:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:37 DISPATCHER: Finished worker discovery
20:12:37 DISPATCHER: Starting worker discovery
20:12:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:37 DISPATCHER: Finished worker discovery
20:13:37 DISPATCHER: Starting worker discovery
20:13:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:37 DISPATCHER: Finished worker discovery
20:14:37 DISPATCHER: Starting worker discovery
20:14:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:37 DISPATCHER: Finished worker discovery
20:15:37 DISPATCHER: Starting worker discovery
20:15:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:37 DISPATCHER: Finished worker discovery
20:16:37 DISPATCHER: Starting worker discovery
20:16:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:37 DISPATCHER: Finished worker discovery
20:17:37 DISPATCHER: Starting worker discovery
20:17:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:37 DISPATCHER: Finished worker discovery
20:18:37 DISPATCHER: Starting worker discovery
20:18:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:37 DISPATCHER: Finished worker discovery
20:19:37 DISPATCHER: Starting worker discovery
20:19:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:37 DISPATCHER: Finished worker discovery
20:20:37 DISPATCHER: Starting worker discovery
20:20:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:37 DISPATCHER: Finished worker discovery
20:21:37 DISPATCHER: Starting worker discovery
20:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:37 DISPATCHER: Finished worker discovery
20:22:37 DISPATCHER: Starting worker discovery
20:22:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:37 DISPATCHER: Finished worker discovery
20:22:57 WORKER: done with job (6, 0, 0), trying to register it.
20:22:57 WORKER: registered result for job (6, 0, 0) with dispatcher
20:22:57 DISPATCHER: job (6, 0, 0) finished
20:22:57 DISPATCHER: register_result: lock acquired
20:22:57 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:22:57 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005216124259951938, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.1738973737990525, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4555516374503701, 'info': {'data02': 0.4555516374503701, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005216124259951938, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.1738973737990525, 'kernel_size_2': 7, 'num_filters_2': 63}"}}
exception: None

20:22:57 job_callback for (6, 0, 0) started
20:22:57 DISPATCHER: Trying to submit another job.
20:22:57 job_callback for (6, 0, 0) got condition
20:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:22:57 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:22:57 HBMASTER: Trying to run another job!
20:22:57 job_callback for (6, 0, 0) finished
20:22:57 HBMASTER: schedule new run for iteration 6
20:22:57 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
20:22:57 HBMASTER: submitting job (6, 0, 1) to dispatcher
20:22:57 DISPATCHER: trying to submit job (6, 0, 1)
20:22:57 DISPATCHER: trying to notify the job_runner thread.
20:22:57 HBMASTER: job (6, 0, 1) submitted to dispatcher
20:22:57 DISPATCHER: Trying to submit another job.
20:22:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:22:57 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:22:57 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:22:57 WORKER: start processing job (6, 0, 1)
20:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:22:57 WORKER: args: ()
20:22:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001640546181441737, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013269200316666403, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 1200.0, 'working_directory': '.'}
20:23:37 DISPATCHER: Starting worker discovery
20:23:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:37 DISPATCHER: Finished worker discovery
20:24:37 DISPATCHER: Starting worker discovery
20:24:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:37 DISPATCHER: Finished worker discovery
20:25:37 DISPATCHER: Starting worker discovery
20:25:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:37 DISPATCHER: Finished worker discovery
20:26:37 DISPATCHER: Starting worker discovery
20:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:37 DISPATCHER: Finished worker discovery
20:27:37 DISPATCHER: Starting worker discovery
20:27:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:37 DISPATCHER: Finished worker discovery
20:28:37 DISPATCHER: Starting worker discovery
20:28:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:37 DISPATCHER: Finished worker discovery
20:29:37 DISPATCHER: Starting worker discovery
20:29:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:37 DISPATCHER: Finished worker discovery
20:30:37 DISPATCHER: Starting worker discovery
20:30:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:37 DISPATCHER: Finished worker discovery
20:31:37 DISPATCHER: Starting worker discovery
20:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:37 DISPATCHER: Finished worker discovery
20:32:37 DISPATCHER: Starting worker discovery
20:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:37 DISPATCHER: Finished worker discovery
20:33:37 DISPATCHER: Starting worker discovery
20:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:37 DISPATCHER: Finished worker discovery
20:34:37 DISPATCHER: Starting worker discovery
20:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:37 DISPATCHER: Finished worker discovery
20:35:37 DISPATCHER: Starting worker discovery
20:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:37 DISPATCHER: Finished worker discovery
20:36:37 DISPATCHER: Starting worker discovery
20:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:37 DISPATCHER: Finished worker discovery
20:37:37 DISPATCHER: Starting worker discovery
20:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:37 DISPATCHER: Finished worker discovery
20:38:37 DISPATCHER: Starting worker discovery
20:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:37 DISPATCHER: Finished worker discovery
20:39:37 DISPATCHER: Starting worker discovery
20:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:37 DISPATCHER: Finished worker discovery
20:40:37 DISPATCHER: Starting worker discovery
20:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:37 DISPATCHER: Finished worker discovery
20:41:37 DISPATCHER: Starting worker discovery
20:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:37 DISPATCHER: Finished worker discovery
20:42:37 DISPATCHER: Starting worker discovery
20:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:37 DISPATCHER: Finished worker discovery
20:43:06 WORKER: done with job (6, 0, 1), trying to register it.
20:43:06 WORKER: registered result for job (6, 0, 1) with dispatcher
20:43:06 DISPATCHER: job (6, 0, 1) finished
20:43:06 DISPATCHER: register_result: lock acquired
20:43:06 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
20:43:06 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001640546181441737, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013269200316666403, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.39229863105661233, 'info': {'data02': 0.39229863105661233, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001640546181441737, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013269200316666403, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 16, 'num_filters_5': 43}"}}
exception: None

20:43:06 job_callback for (6, 0, 1) started
20:43:06 DISPATCHER: Trying to submit another job.
20:43:06 job_callback for (6, 0, 1) got condition
20:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:43:06 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:43:06 HBMASTER: Trying to run another job!
20:43:06 job_callback for (6, 0, 1) finished
20:43:06 start sampling a new configuration.
20:43:06 best_vector: [1, 2, 0.1518414351642007, 0.4877201460151001, 0.5179244670577302, 0, 0.23166965670698303, 0.19739264884655228, 0, 0, 1, 2, 0.15406236461221123, 0.65695057458164, 0.15100370829150145, 0.4831200843513178], 5.094190963567585e-32, 0.19630202462996713, -3.6726426014241415e-05
20:43:06 done sampling a new configuration.
20:43:06 HBMASTER: schedule new run for iteration 7
20:43:06 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
20:43:06 HBMASTER: submitting job (7, 0, 0) to dispatcher
20:43:06 DISPATCHER: trying to submit job (7, 0, 0)
20:43:06 DISPATCHER: trying to notify the job_runner thread.
20:43:06 HBMASTER: job (7, 0, 0) submitted to dispatcher
20:43:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:43:06 DISPATCHER: Trying to submit another job.
20:43:06 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
20:43:06 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
20:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:43:06 WORKER: start processing job (7, 0, 0)
20:43:06 WORKER: args: ()
20:43:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002012254328805381, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.018063993032692457, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 62}, 'budget': 1200.0, 'working_directory': '.'}
20:43:37 DISPATCHER: Starting worker discovery
20:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:37 DISPATCHER: Finished worker discovery
20:44:37 DISPATCHER: Starting worker discovery
20:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:37 DISPATCHER: Finished worker discovery
20:45:37 DISPATCHER: Starting worker discovery
20:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:37 DISPATCHER: Finished worker discovery
20:46:37 DISPATCHER: Starting worker discovery
20:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:37 DISPATCHER: Finished worker discovery
20:47:37 DISPATCHER: Starting worker discovery
20:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:37 DISPATCHER: Finished worker discovery
20:48:37 DISPATCHER: Starting worker discovery
20:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:37 DISPATCHER: Finished worker discovery
20:49:37 DISPATCHER: Starting worker discovery
20:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:37 DISPATCHER: Finished worker discovery
20:50:37 DISPATCHER: Starting worker discovery
20:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:37 DISPATCHER: Finished worker discovery
20:51:37 DISPATCHER: Starting worker discovery
20:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:37 DISPATCHER: Finished worker discovery
20:52:37 DISPATCHER: Starting worker discovery
20:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:37 DISPATCHER: Finished worker discovery
20:53:37 DISPATCHER: Starting worker discovery
20:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:37 DISPATCHER: Finished worker discovery
20:54:37 DISPATCHER: Starting worker discovery
20:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:37 DISPATCHER: Finished worker discovery
20:55:37 DISPATCHER: Starting worker discovery
20:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:37 DISPATCHER: Finished worker discovery
20:56:37 DISPATCHER: Starting worker discovery
20:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:37 DISPATCHER: Finished worker discovery
20:57:37 DISPATCHER: Starting worker discovery
20:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:37 DISPATCHER: Finished worker discovery
20:58:37 DISPATCHER: Starting worker discovery
20:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:37 DISPATCHER: Finished worker discovery
20:59:37 DISPATCHER: Starting worker discovery
20:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:37 DISPATCHER: Finished worker discovery
21:00:37 DISPATCHER: Starting worker discovery
21:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:37 DISPATCHER: Finished worker discovery
21:01:37 DISPATCHER: Starting worker discovery
21:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:37 DISPATCHER: Finished worker discovery
21:02:37 DISPATCHER: Starting worker discovery
21:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:37 DISPATCHER: Finished worker discovery
21:03:20 WORKER: done with job (7, 0, 0), trying to register it.
21:03:20 WORKER: registered result for job (7, 0, 0) with dispatcher
21:03:20 DISPATCHER: job (7, 0, 0) finished
21:03:20 DISPATCHER: register_result: lock acquired
21:03:20 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:03:20 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002012254328805381, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.018063993032692457, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 62}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.47487503337515935, 'info': {'data02': 0.47487503337515935, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002012254328805381, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.018063993032692457, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 62}"}}
exception: None

21:03:20 job_callback for (7, 0, 0) started
21:03:20 DISPATCHER: Trying to submit another job.
21:03:20 job_callback for (7, 0, 0) got condition
21:03:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:20 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:03:20 HBMASTER: Trying to run another job!
21:03:20 job_callback for (7, 0, 0) finished
21:03:20 start sampling a new configuration.
21:03:20 best_vector: [3, 0, 0.02201153071150791, 0.26399426642592805, 0.5226755299765878, 0, 0.3823673932880881, 0.8069154382499211, 0, 2, 1, 2, 0.9268728686613049, 0.7731346892754613, 0.6625085294409514, 0.4812341711060594], 4.3399098664868284e-32, 0.23041953191749195, -9.235059486725553e-05
21:03:20 done sampling a new configuration.
21:03:20 HBMASTER: schedule new run for iteration 7
21:03:20 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
21:03:20 HBMASTER: submitting job (7, 0, 1) to dispatcher
21:03:20 DISPATCHER: trying to submit job (7, 0, 1)
21:03:20 DISPATCHER: trying to notify the job_runner thread.
21:03:20 HBMASTER: job (7, 0, 1) submitted to dispatcher
21:03:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:20 DISPATCHER: Trying to submit another job.
21:03:20 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:03:20 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:03:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:20 WORKER: start processing job (7, 0, 1)
21:03:20 WORKER: args: ()
21:03:20 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001106682548244432, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.11215565838187452, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 80}, 'budget': 1200.0, 'working_directory': '.'}
21:03:37 DISPATCHER: Starting worker discovery
21:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:37 DISPATCHER: Finished worker discovery
21:04:37 DISPATCHER: Starting worker discovery
21:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:37 DISPATCHER: Finished worker discovery
21:05:37 DISPATCHER: Starting worker discovery
21:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:38 DISPATCHER: Finished worker discovery
21:06:38 DISPATCHER: Starting worker discovery
21:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:38 DISPATCHER: Finished worker discovery
21:07:38 DISPATCHER: Starting worker discovery
21:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:38 DISPATCHER: Finished worker discovery
21:08:38 DISPATCHER: Starting worker discovery
21:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:38 DISPATCHER: Finished worker discovery
21:09:38 DISPATCHER: Starting worker discovery
21:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:38 DISPATCHER: Finished worker discovery
21:10:38 DISPATCHER: Starting worker discovery
21:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:38 DISPATCHER: Finished worker discovery
21:11:38 DISPATCHER: Starting worker discovery
21:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:38 DISPATCHER: Finished worker discovery
21:12:38 DISPATCHER: Starting worker discovery
21:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:38 DISPATCHER: Finished worker discovery
21:13:38 DISPATCHER: Starting worker discovery
21:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:38 DISPATCHER: Finished worker discovery
21:14:38 DISPATCHER: Starting worker discovery
21:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:38 DISPATCHER: Finished worker discovery
21:15:38 DISPATCHER: Starting worker discovery
21:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:38 DISPATCHER: Finished worker discovery
21:16:38 DISPATCHER: Starting worker discovery
21:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:38 DISPATCHER: Finished worker discovery
21:17:38 DISPATCHER: Starting worker discovery
21:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:38 DISPATCHER: Finished worker discovery
21:18:38 DISPATCHER: Starting worker discovery
21:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:38 DISPATCHER: Finished worker discovery
21:19:38 DISPATCHER: Starting worker discovery
21:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:38 DISPATCHER: Finished worker discovery
21:20:38 DISPATCHER: Starting worker discovery
21:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:38 DISPATCHER: Finished worker discovery
21:21:38 DISPATCHER: Starting worker discovery
21:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:38 DISPATCHER: Finished worker discovery
21:22:38 DISPATCHER: Starting worker discovery
21:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:38 DISPATCHER: Finished worker discovery
21:23:29 WORKER: done with job (7, 0, 1), trying to register it.
21:23:29 WORKER: registered result for job (7, 0, 1) with dispatcher
21:23:29 DISPATCHER: job (7, 0, 1) finished
21:23:29 DISPATCHER: register_result: lock acquired
21:23:29 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:23:29 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001106682548244432, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.11215565838187452, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 80}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4769535308296887, 'info': {'data02': 0.4769535308296887, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001106682548244432, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.11215565838187452, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 80}"}}
exception: None

21:23:29 job_callback for (7, 0, 1) started
21:23:29 job_callback for (7, 0, 1) got condition
21:23:29 DISPATCHER: Trying to submit another job.
21:23:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:23:29 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:23:29 HBMASTER: Trying to run another job!
21:23:29 job_callback for (7, 0, 1) finished
21:23:29 start sampling a new configuration.
21:23:29 done sampling a new configuration.
21:23:29 HBMASTER: schedule new run for iteration 7
21:23:29 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
21:23:29 HBMASTER: submitting job (7, 0, 2) to dispatcher
21:23:29 DISPATCHER: trying to submit job (7, 0, 2)
21:23:29 DISPATCHER: trying to notify the job_runner thread.
21:23:29 HBMASTER: job (7, 0, 2) submitted to dispatcher
21:23:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:23:29 DISPATCHER: Trying to submit another job.
21:23:29 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:23:29 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:23:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:23:29 WORKER: start processing job (7, 0, 2)
21:23:29 WORKER: args: ()
21:23:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07618549060142443, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.09434828286447534, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 104}, 'budget': 1200.0, 'working_directory': '.'}
21:23:38 DISPATCHER: Starting worker discovery
21:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:38 DISPATCHER: Finished worker discovery
21:24:38 DISPATCHER: Starting worker discovery
21:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:38 DISPATCHER: Finished worker discovery
21:25:38 DISPATCHER: Starting worker discovery
21:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:38 DISPATCHER: Finished worker discovery
21:26:38 DISPATCHER: Starting worker discovery
21:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:38 DISPATCHER: Finished worker discovery
21:27:38 DISPATCHER: Starting worker discovery
21:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:38 DISPATCHER: Finished worker discovery
21:28:38 DISPATCHER: Starting worker discovery
21:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:38 DISPATCHER: Finished worker discovery
21:29:38 DISPATCHER: Starting worker discovery
21:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:38 DISPATCHER: Finished worker discovery
21:30:38 DISPATCHER: Starting worker discovery
21:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:38 DISPATCHER: Finished worker discovery
21:31:38 DISPATCHER: Starting worker discovery
21:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:38 DISPATCHER: Finished worker discovery
21:32:38 DISPATCHER: Starting worker discovery
21:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:38 DISPATCHER: Finished worker discovery
21:33:38 DISPATCHER: Starting worker discovery
21:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:38 DISPATCHER: Finished worker discovery
21:34:38 DISPATCHER: Starting worker discovery
21:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:38 DISPATCHER: Finished worker discovery
21:35:38 DISPATCHER: Starting worker discovery
21:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:38 DISPATCHER: Finished worker discovery
21:36:38 DISPATCHER: Starting worker discovery
21:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:38 DISPATCHER: Finished worker discovery
21:37:38 DISPATCHER: Starting worker discovery
21:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:38 DISPATCHER: Finished worker discovery
21:38:38 DISPATCHER: Starting worker discovery
21:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:38 DISPATCHER: Finished worker discovery
21:39:38 DISPATCHER: Starting worker discovery
21:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:38 DISPATCHER: Finished worker discovery
21:40:38 DISPATCHER: Starting worker discovery
21:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:38 DISPATCHER: Finished worker discovery
21:41:38 DISPATCHER: Starting worker discovery
21:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:38 DISPATCHER: Finished worker discovery
21:42:38 DISPATCHER: Starting worker discovery
21:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:38 DISPATCHER: Finished worker discovery
21:43:37 WORKER: done with job (7, 0, 2), trying to register it.
21:43:37 WORKER: registered result for job (7, 0, 2) with dispatcher
21:43:37 DISPATCHER: job (7, 0, 2) finished
21:43:37 DISPATCHER: register_result: lock acquired
21:43:37 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
21:43:37 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07618549060142443, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.09434828286447534, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 104}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08308619790850252, 'info': {'data02': 0.08308619790850252, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07618549060142443, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.09434828286447534, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 112, 'num_filters_3': 104}"}}
exception: None

21:43:37 job_callback for (7, 0, 2) started
21:43:37 DISPATCHER: Trying to submit another job.
21:43:37 job_callback for (7, 0, 2) got condition
21:43:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:43:37 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:43:37 HBMASTER: Trying to run another job!
21:43:37 job_callback for (7, 0, 2) finished
21:43:37 start sampling a new configuration.
21:43:37 done sampling a new configuration.
21:43:37 HBMASTER: schedule new run for iteration 7
21:43:37 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
21:43:37 HBMASTER: submitting job (7, 0, 3) to dispatcher
21:43:37 DISPATCHER: trying to submit job (7, 0, 3)
21:43:37 DISPATCHER: trying to notify the job_runner thread.
21:43:37 HBMASTER: job (7, 0, 3) submitted to dispatcher
21:43:37 DISPATCHER: Trying to submit another job.
21:43:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:43:37 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
21:43:37 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
21:43:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:43:37 WORKER: start processing job (7, 0, 3)
21:43:37 WORKER: args: ()
21:43:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012926444444016027, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.11000954965002468, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 70, 'num_filters_3': 80, 'num_filters_4': 82, 'num_filters_5': 79}, 'budget': 1200.0, 'working_directory': '.'}
21:43:38 DISPATCHER: Starting worker discovery
21:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:38 DISPATCHER: Finished worker discovery
21:44:38 DISPATCHER: Starting worker discovery
21:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:38 DISPATCHER: Finished worker discovery
21:45:38 DISPATCHER: Starting worker discovery
21:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:38 DISPATCHER: Finished worker discovery
21:46:38 DISPATCHER: Starting worker discovery
21:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:38 DISPATCHER: Finished worker discovery
21:47:38 DISPATCHER: Starting worker discovery
21:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:38 DISPATCHER: Finished worker discovery
21:48:38 DISPATCHER: Starting worker discovery
21:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:38 DISPATCHER: Finished worker discovery
21:49:38 DISPATCHER: Starting worker discovery
21:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:38 DISPATCHER: Finished worker discovery
21:50:38 DISPATCHER: Starting worker discovery
21:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:38 DISPATCHER: Finished worker discovery
21:51:38 DISPATCHER: Starting worker discovery
21:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:38 DISPATCHER: Finished worker discovery
21:52:38 DISPATCHER: Starting worker discovery
21:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:38 DISPATCHER: Finished worker discovery
21:53:38 DISPATCHER: Starting worker discovery
21:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:38 DISPATCHER: Finished worker discovery
21:54:38 DISPATCHER: Starting worker discovery
21:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:38 DISPATCHER: Finished worker discovery
21:55:38 DISPATCHER: Starting worker discovery
21:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:38 DISPATCHER: Finished worker discovery
21:56:38 DISPATCHER: Starting worker discovery
21:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:38 DISPATCHER: Finished worker discovery
21:57:38 DISPATCHER: Starting worker discovery
21:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:38 DISPATCHER: Finished worker discovery
21:58:38 DISPATCHER: Starting worker discovery
21:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:38 DISPATCHER: Finished worker discovery
21:59:38 DISPATCHER: Starting worker discovery
21:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:38 DISPATCHER: Finished worker discovery
22:00:38 DISPATCHER: Starting worker discovery
22:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:38 DISPATCHER: Finished worker discovery
22:01:38 DISPATCHER: Starting worker discovery
22:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:38 DISPATCHER: Finished worker discovery
22:02:38 DISPATCHER: Starting worker discovery
22:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:38 DISPATCHER: Finished worker discovery
22:03:38 DISPATCHER: Starting worker discovery
22:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:38 DISPATCHER: Finished worker discovery
22:03:44 WORKER: done with job (7, 0, 3), trying to register it.
22:03:44 WORKER: registered result for job (7, 0, 3) with dispatcher
22:03:44 DISPATCHER: job (7, 0, 3) finished
22:03:44 DISPATCHER: register_result: lock acquired
22:03:44 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:03:44 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012926444444016027, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.11000954965002468, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 70, 'num_filters_3': 80, 'num_filters_4': 82, 'num_filters_5': 79}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6061307709991168, 'info': {'data02': 0.6061307709991168, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012926444444016027, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.11000954965002468, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 70, 'num_filters_3': 80, 'num_filters_4': 82, 'num_filters_5': 79}"}}
exception: None

22:03:44 job_callback for (7, 0, 3) started
22:03:44 DISPATCHER: Trying to submit another job.
22:03:44 job_callback for (7, 0, 3) got condition
22:03:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:03:44 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:03:44 HBMASTER: Trying to run another job!
22:03:44 job_callback for (7, 0, 3) finished
22:03:44 start sampling a new configuration.
22:03:44 done sampling a new configuration.
22:03:44 HBMASTER: schedule new run for iteration 8
22:03:44 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
22:03:44 HBMASTER: submitting job (8, 0, 0) to dispatcher
22:03:44 DISPATCHER: trying to submit job (8, 0, 0)
22:03:44 DISPATCHER: trying to notify the job_runner thread.
22:03:44 HBMASTER: job (8, 0, 0) submitted to dispatcher
22:03:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:03:44 DISPATCHER: Trying to submit another job.
22:03:44 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:03:44 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:03:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:03:44 WORKER: start processing job (8, 0, 0)
22:03:44 WORKER: args: ()
22:03:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03489290522714871, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.10442531912080924, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 108, 'num_filters_3': 64, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:04:34 WORKER: done with job (8, 0, 0), trying to register it.
22:04:34 WORKER: registered result for job (8, 0, 0) with dispatcher
22:04:34 DISPATCHER: job (8, 0, 0) finished
22:04:34 DISPATCHER: register_result: lock acquired
22:04:34 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:04:34 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03489290522714871, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.10442531912080924, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 108, 'num_filters_3': 64, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0025939197689156435, 'info': {'data02': 0.0025939197689156435, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03489290522714871, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.10442531912080924, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 108, 'num_filters_3': 64, 'num_filters_4': 23}"}}
exception: None

22:04:34 job_callback for (8, 0, 0) started
22:04:34 DISPATCHER: Trying to submit another job.
22:04:34 job_callback for (8, 0, 0) got condition
22:04:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:34 HBMASTER: Trying to run another job!
22:04:34 job_callback for (8, 0, 0) finished
22:04:34 start sampling a new configuration.
22:04:34 best_vector: [2, 2, 0.6308033068674007, 0.9263491140644546, 0.38554415241276485, 1, 0.1509595420933333, 0.7759824498109866, 0, 2, 0, 1, 0.09681884764409854, 0.25330033858203793, 0.5414525664456885, 0.48099766150871764], 0.0, inf, 7.68139896692992e-05
22:04:34 done sampling a new configuration.
22:04:34 HBMASTER: schedule new run for iteration 8
22:04:34 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
22:04:34 HBMASTER: submitting job (8, 0, 1) to dispatcher
22:04:34 DISPATCHER: trying to submit job (8, 0, 1)
22:04:34 DISPATCHER: trying to notify the job_runner thread.
22:04:34 HBMASTER: job (8, 0, 1) submitted to dispatcher
22:04:34 DISPATCHER: Trying to submit another job.
22:04:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:34 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:04:34 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:04:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:34 WORKER: start processing job (8, 0, 1)
22:04:34 WORKER: args: ()
22:04:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018264450629230503, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.10222954863871787, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:04:38 DISPATCHER: Starting worker discovery
22:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:38 DISPATCHER: Finished worker discovery
22:05:23 WORKER: done with job (8, 0, 1), trying to register it.
22:05:23 WORKER: registered result for job (8, 0, 1) with dispatcher
22:05:23 DISPATCHER: job (8, 0, 1) finished
22:05:23 DISPATCHER: register_result: lock acquired
22:05:23 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:05:23 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018264450629230503, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.10222954863871787, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40306262274537796, 'info': {'data02': 0.40306262274537796, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018264450629230503, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.10222954863871787, 'kernel_size_2': 3, 'num_filters_2': 19}"}}
exception: None

22:05:23 job_callback for (8, 0, 1) started
22:05:23 DISPATCHER: Trying to submit another job.
22:05:23 job_callback for (8, 0, 1) got condition
22:05:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:05:23 HBMASTER: Trying to run another job!
22:05:23 job_callback for (8, 0, 1) finished
22:05:23 start sampling a new configuration.
22:05:23 best_vector: [1, 0, 0.3201142458761025, 0.8346376445134361, 0.0803968726147054, 1, 0.2949881768545522, 0.4844789053827814, 2, 0, 2, 2, 0.5756548293934953, 0.22822619450959047, 0.16686829020460398, 0.48210338133090713], 7.684499736215012e-31, 0.013013208853235623, -3.192544519002929e-05
22:05:23 done sampling a new configuration.
22:05:23 HBMASTER: schedule new run for iteration 8
22:05:23 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
22:05:23 HBMASTER: submitting job (8, 0, 2) to dispatcher
22:05:23 DISPATCHER: trying to submit job (8, 0, 2)
22:05:23 DISPATCHER: trying to notify the job_runner thread.
22:05:23 HBMASTER: job (8, 0, 2) submitted to dispatcher
22:05:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:05:23 DISPATCHER: Trying to submit another job.
22:05:23 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:05:23 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:05:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:05:23 WORKER: start processing job (8, 0, 2)
22:05:23 WORKER: args: ()
22:05:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00436745553118263, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.04268955111425585}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:05:38 DISPATCHER: Starting worker discovery
22:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:38 DISPATCHER: Finished worker discovery
22:06:11 WORKER: done with job (8, 0, 2), trying to register it.
22:06:11 WORKER: registered result for job (8, 0, 2) with dispatcher
22:06:11 DISPATCHER: job (8, 0, 2) finished
22:06:11 DISPATCHER: register_result: lock acquired
22:06:11 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:06:11 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00436745553118263, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.04268955111425585}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4670262257077051, 'info': {'data02': 0.4670262257077051, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00436745553118263, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.04268955111425585}"}}
exception: None

22:06:11 job_callback for (8, 0, 2) started
22:06:11 DISPATCHER: Trying to submit another job.
22:06:11 job_callback for (8, 0, 2) got condition
22:06:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:06:11 HBMASTER: Trying to run another job!
22:06:11 job_callback for (8, 0, 2) finished
22:06:11 start sampling a new configuration.
22:06:11 best_vector: [1, 2, 0.007119845519959422, 0.6343152646667422, 0.3387563571775689, 0, 0.23445518028035706, 0.8209958313394482, 1, 0, 0, 2, 0.537985043584462, 0.6367743911750515, 0.1251455384688358, 0.4829611832686079], 1.7549762837107834e-31, 0.056980826993602726, -1.5649668477243837e-05
22:06:11 done sampling a new configuration.
22:06:11 HBMASTER: schedule new run for iteration 8
22:06:11 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
22:06:11 HBMASTER: submitting job (8, 0, 3) to dispatcher
22:06:11 DISPATCHER: trying to submit job (8, 0, 3)
22:06:11 DISPATCHER: trying to notify the job_runner thread.
22:06:11 HBMASTER: job (8, 0, 3) submitted to dispatcher
22:06:11 DISPATCHER: Trying to submit another job.
22:06:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:06:11 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:06:11 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:06:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:06:11 WORKER: start processing job (8, 0, 3)
22:06:11 WORKER: args: ()
22:06:11 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010333315534123793, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11698770003797994, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:06:38 DISPATCHER: Starting worker discovery
22:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:38 DISPATCHER: Finished worker discovery
22:07:00 WORKER: done with job (8, 0, 3), trying to register it.
22:07:00 WORKER: registered result for job (8, 0, 3) with dispatcher
22:07:00 DISPATCHER: job (8, 0, 3) finished
22:07:00 DISPATCHER: register_result: lock acquired
22:07:00 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:07:00 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010333315534123793, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11698770003797994, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49215881698436387, 'info': {'data02': 0.49215881698436387, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010333315534123793, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.11698770003797994, 'kernel_size_2': 5, 'num_filters_2': 48}"}}
exception: None

22:07:00 job_callback for (8, 0, 3) started
22:07:00 DISPATCHER: Trying to submit another job.
22:07:00 job_callback for (8, 0, 3) got condition
22:07:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:07:00 HBMASTER: Trying to run another job!
22:07:00 job_callback for (8, 0, 3) finished
22:07:00 start sampling a new configuration.
22:07:00 best_vector: [3, 1, 0.02884257835567011, 0.21185494392555923, 0.7475214445247629, 0, 0.45960669358153633, 0.5802946469458227, 2, 1, 1, 2, 0.7558353674401502, 0.8697275696087272, 0.4553983250081551, 0.4821797462016591], 1.001444872981145e-32, 0.9985572116647381, -1.516083460158635e-06
22:07:00 done sampling a new configuration.
22:07:00 HBMASTER: schedule new run for iteration 8
22:07:00 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
22:07:00 HBMASTER: submitting job (8, 0, 4) to dispatcher
22:07:00 DISPATCHER: trying to submit job (8, 0, 4)
22:07:00 DISPATCHER: trying to notify the job_runner thread.
22:07:00 HBMASTER: job (8, 0, 4) submitted to dispatcher
22:07:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:07:00 DISPATCHER: Trying to submit another job.
22:07:00 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:07:00 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:07:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:07:00 WORKER: start processing job (8, 0, 4)
22:07:00 WORKER: args: ()
22:07:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011420501014346607, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.056882770665276285, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 98, 'num_filters_4': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:07:38 DISPATCHER: Starting worker discovery
22:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:38 DISPATCHER: Finished worker discovery
22:07:48 WORKER: done with job (8, 0, 4), trying to register it.
22:07:48 WORKER: registered result for job (8, 0, 4) with dispatcher
22:07:48 DISPATCHER: job (8, 0, 4) finished
22:07:48 DISPATCHER: register_result: lock acquired
22:07:48 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:07:48 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011420501014346607, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.056882770665276285, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 98, 'num_filters_4': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5668706266414705, 'info': {'data02': 0.5668706266414705, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011420501014346607, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.056882770665276285, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 98, 'num_filters_4': 41}"}}
exception: None

22:07:48 job_callback for (8, 0, 4) started
22:07:48 job_callback for (8, 0, 4) got condition
22:07:48 DISPATCHER: Trying to submit another job.
22:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:07:48 HBMASTER: Trying to run another job!
22:07:48 job_callback for (8, 0, 4) finished
22:07:48 start sampling a new configuration.
22:07:48 best_vector: [1, 2, 0.5608382949678508, 0.7747642321840217, 0.33235043715482115, 1, 0.8146680022612123, 0.9030150396147729, 0, 0, 0, 2, 0.9290292615226782, 0.26630746027603835, 0.3584969445311533, 0.4824258207813171], 3.6030759136905985e-30, 0.0027754064137264015, -7.629248049995496e-05
22:07:48 done sampling a new configuration.
22:07:48 HBMASTER: schedule new run for iteration 8
22:07:48 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
22:07:48 HBMASTER: submitting job (8, 0, 5) to dispatcher
22:07:48 DISPATCHER: trying to submit job (8, 0, 5)
22:07:48 DISPATCHER: trying to notify the job_runner thread.
22:07:48 HBMASTER: job (8, 0, 5) submitted to dispatcher
22:07:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:07:48 DISPATCHER: Trying to submit another job.
22:07:48 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:07:48 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:07:48 WORKER: start processing job (8, 0, 5)
22:07:48 WORKER: args: ()
22:07:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013233556927227552, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.14957177690236736, 'kernel_size_2': 3, 'num_filters_2': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:08:37 WORKER: done with job (8, 0, 5), trying to register it.
22:08:37 WORKER: registered result for job (8, 0, 5) with dispatcher
22:08:37 DISPATCHER: job (8, 0, 5) finished
22:08:37 DISPATCHER: register_result: lock acquired
22:08:37 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:08:37 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013233556927227552, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.14957177690236736, 'kernel_size_2': 3, 'num_filters_2': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32624933787247656, 'info': {'data02': 0.32624933787247656, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013233556927227552, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.14957177690236736, 'kernel_size_2': 3, 'num_filters_2': 111}"}}
exception: None

22:08:37 job_callback for (8, 0, 5) started
22:08:37 DISPATCHER: Trying to submit another job.
22:08:37 job_callback for (8, 0, 5) got condition
22:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:08:37 HBMASTER: Trying to run another job!
22:08:37 job_callback for (8, 0, 5) finished
22:08:37 start sampling a new configuration.
22:08:37 done sampling a new configuration.
22:08:37 HBMASTER: schedule new run for iteration 8
22:08:37 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
22:08:37 HBMASTER: submitting job (8, 0, 6) to dispatcher
22:08:37 DISPATCHER: trying to submit job (8, 0, 6)
22:08:37 DISPATCHER: trying to notify the job_runner thread.
22:08:37 HBMASTER: job (8, 0, 6) submitted to dispatcher
22:08:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:08:37 DISPATCHER: Trying to submit another job.
22:08:37 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:08:37 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:08:37 WORKER: start processing job (8, 0, 6)
22:08:37 WORKER: args: ()
22:08:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02969475027205534, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01816560056315508, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 24, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:08:38 DISPATCHER: Starting worker discovery
22:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:38 DISPATCHER: Finished worker discovery
22:09:26 WORKER: done with job (8, 0, 6), trying to register it.
22:09:26 WORKER: registered result for job (8, 0, 6) with dispatcher
22:09:26 DISPATCHER: job (8, 0, 6) finished
22:09:26 DISPATCHER: register_result: lock acquired
22:09:26 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:09:26 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02969475027205534, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01816560056315508, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 24, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5899581781582357, 'info': {'data02': 0.5899581781582357, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02969475027205534, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01816560056315508, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 24, 'num_filters_4': 43}"}}
exception: None

22:09:26 job_callback for (8, 0, 6) started
22:09:26 DISPATCHER: Trying to submit another job.
22:09:26 job_callback for (8, 0, 6) got condition
22:09:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:09:26 HBMASTER: Trying to run another job!
22:09:26 job_callback for (8, 0, 6) finished
22:09:26 start sampling a new configuration.
22:09:26 best_vector: [1, 1, 0.14141424592765195, 0.416795298287373, 0.6694272361020056, 1, 0.4655804852883636, 0.6018777219626863, 2, 1, 1, 2, 0.6884524406614616, 0.3054092661114114, 0.2082723970522804, 0.4826493283668208], 1.2551255848552663e-32, 0.7967330218316873, -7.771377081320859e-06
22:09:26 done sampling a new configuration.
22:09:26 HBMASTER: schedule new run for iteration 8
22:09:26 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
22:09:26 HBMASTER: submitting job (8, 0, 7) to dispatcher
22:09:26 DISPATCHER: trying to submit job (8, 0, 7)
22:09:26 DISPATCHER: trying to notify the job_runner thread.
22:09:26 HBMASTER: job (8, 0, 7) submitted to dispatcher
22:09:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:09:26 DISPATCHER: Trying to submit another job.
22:09:26 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:09:26 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:09:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:09:26 WORKER: start processing job (8, 0, 7)
22:09:26 WORKER: args: ()
22:09:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0019179111847677207, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.0606821514433215, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 66, 'num_filters_3': 30, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:09:38 DISPATCHER: Starting worker discovery
22:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:38 DISPATCHER: Finished worker discovery
22:10:16 WORKER: done with job (8, 0, 7), trying to register it.
22:10:16 WORKER: registered result for job (8, 0, 7) with dispatcher
22:10:16 DISPATCHER: job (8, 0, 7) finished
22:10:16 DISPATCHER: register_result: lock acquired
22:10:16 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:10:16 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0019179111847677207, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.0606821514433215, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 66, 'num_filters_3': 30, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45740019109234187, 'info': {'data02': 0.45740019109234187, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0019179111847677207, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.0606821514433215, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 66, 'num_filters_3': 30, 'num_filters_4': 24}"}}
exception: None

22:10:16 job_callback for (8, 0, 7) started
22:10:16 DISPATCHER: Trying to submit another job.
22:10:16 job_callback for (8, 0, 7) got condition
22:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:10:16 HBMASTER: Trying to run another job!
22:10:16 job_callback for (8, 0, 7) finished
22:10:16 start sampling a new configuration.
22:10:16 done sampling a new configuration.
22:10:16 HBMASTER: schedule new run for iteration 8
22:10:16 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
22:10:16 HBMASTER: submitting job (8, 0, 8) to dispatcher
22:10:16 DISPATCHER: trying to submit job (8, 0, 8)
22:10:16 DISPATCHER: trying to notify the job_runner thread.
22:10:16 HBMASTER: job (8, 0, 8) submitted to dispatcher
22:10:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:10:16 DISPATCHER: Trying to submit another job.
22:10:16 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:10:16 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:10:16 WORKER: start processing job (8, 0, 8)
22:10:16 WORKER: args: ()
22:10:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013373335696690142, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.13275219750810718, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 58, 'num_filters_3': 74, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:10:38 DISPATCHER: Starting worker discovery
22:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:38 DISPATCHER: Finished worker discovery
22:11:05 WORKER: done with job (8, 0, 8), trying to register it.
22:11:05 WORKER: registered result for job (8, 0, 8) with dispatcher
22:11:05 DISPATCHER: job (8, 0, 8) finished
22:11:05 DISPATCHER: register_result: lock acquired
22:11:05 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:11:05 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013373335696690142, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.13275219750810718, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 58, 'num_filters_3': 74, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48885305123142114, 'info': {'data02': 0.48885305123142114, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013373335696690142, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.13275219750810718, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 58, 'num_filters_3': 74, 'num_filters_4': 25}"}}
exception: None

22:11:05 job_callback for (8, 0, 8) started
22:11:05 job_callback for (8, 0, 8) got condition
22:11:05 DISPATCHER: Trying to submit another job.
22:11:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:05 HBMASTER: Trying to run another job!
22:11:05 job_callback for (8, 0, 8) finished
22:11:05 start sampling a new configuration.
22:11:05 best_vector: [0, 2, 0.24694891781058093, 0.21060330875221644, 0.15936594718279984, 0, 0.9680435149561593, 0.2577047349174122, 2, 2, 0, 2, 0.8467862534569021, 0.7148415897463736, 0.010987460256433823, 0.47872792792774227], 9.413682413975232e-29, 0.00010622835528373403, -1.52902382524216e-06
22:11:05 done sampling a new configuration.
22:11:05 HBMASTER: schedule new run for iteration 8
22:11:05 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
22:11:05 HBMASTER: submitting job (8, 0, 9) to dispatcher
22:11:05 DISPATCHER: trying to submit job (8, 0, 9)
22:11:05 DISPATCHER: trying to notify the job_runner thread.
22:11:05 HBMASTER: job (8, 0, 9) submitted to dispatcher
22:11:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:05 DISPATCHER: Trying to submit another job.
22:11:05 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:11:05 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:11:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:05 WORKER: start processing job (8, 0, 9)
22:11:05 WORKER: args: ()
22:11:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003118155976013421, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021641212533026807}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:11:38 DISPATCHER: Starting worker discovery
22:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:38 DISPATCHER: Finished worker discovery
22:11:54 WORKER: done with job (8, 0, 9), trying to register it.
22:11:54 WORKER: registered result for job (8, 0, 9) with dispatcher
22:11:54 DISPATCHER: job (8, 0, 9) finished
22:11:54 DISPATCHER: register_result: lock acquired
22:11:54 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:11:54 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003118155976013421, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021641212533026807}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3969523202244109, 'info': {'data02': 0.3969523202244109, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003118155976013421, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021641212533026807}"}}
exception: None

22:11:54 job_callback for (8, 0, 9) started
22:11:54 DISPATCHER: Trying to submit another job.
22:11:54 job_callback for (8, 0, 9) got condition
22:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:54 HBMASTER: Trying to run another job!
22:11:54 job_callback for (8, 0, 9) finished
22:11:54 start sampling a new configuration.
22:11:54 done sampling a new configuration.
22:11:54 HBMASTER: schedule new run for iteration 8
22:11:54 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
22:11:54 HBMASTER: submitting job (8, 0, 10) to dispatcher
22:11:54 DISPATCHER: trying to submit job (8, 0, 10)
22:11:54 DISPATCHER: trying to notify the job_runner thread.
22:11:54 HBMASTER: job (8, 0, 10) submitted to dispatcher
22:11:54 DISPATCHER: Trying to submit another job.
22:11:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:54 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:11:54 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:54 WORKER: start processing job (8, 0, 10)
22:11:54 WORKER: args: ()
22:11:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01607971686889038, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.01628136323301029}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:12:38 DISPATCHER: Starting worker discovery
22:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:38 DISPATCHER: Finished worker discovery
22:12:44 WORKER: done with job (8, 0, 10), trying to register it.
22:12:44 WORKER: registered result for job (8, 0, 10) with dispatcher
22:12:44 DISPATCHER: job (8, 0, 10) finished
22:12:44 DISPATCHER: register_result: lock acquired
22:12:44 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:12:44 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01607971686889038, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.01628136323301029}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3646826510857175, 'info': {'data02': 0.3646826510857175, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01607971686889038, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.01628136323301029}"}}
exception: None

22:12:44 job_callback for (8, 0, 10) started
22:12:44 job_callback for (8, 0, 10) got condition
22:12:44 DISPATCHER: Trying to submit another job.
22:12:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:12:44 HBMASTER: Trying to run another job!
22:12:44 job_callback for (8, 0, 10) finished
22:12:44 start sampling a new configuration.
22:12:44 best_vector: [3, 0, 0.45811118964911524, 0.1445957273854313, 0.698494134503787, 1, 0.5438633061405942, 0.28788648958540075, 0, 2, 0, 2, 0.6557200465517854, 0.4474686513719256, 0.8303650422235618, 0.4828771921606721], 2.3022751820955997e-32, 0.43435294259210583, -2.5625748952829902e-05
22:12:44 done sampling a new configuration.
22:12:44 HBMASTER: schedule new run for iteration 8
22:12:44 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
22:12:44 HBMASTER: submitting job (8, 0, 11) to dispatcher
22:12:44 DISPATCHER: trying to submit job (8, 0, 11)
22:12:44 DISPATCHER: trying to notify the job_runner thread.
22:12:44 HBMASTER: job (8, 0, 11) submitted to dispatcher
22:12:44 DISPATCHER: Trying to submit another job.
22:12:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:12:44 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:12:44 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:12:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:12:44 WORKER: start processing job (8, 0, 11)
22:12:44 WORKER: args: ()
22:12:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008245602207340785, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.023689121657285102, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 40, 'num_filters_4': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:13:34 WORKER: done with job (8, 0, 11), trying to register it.
22:13:34 WORKER: registered result for job (8, 0, 11) with dispatcher
22:13:34 DISPATCHER: job (8, 0, 11) finished
22:13:34 DISPATCHER: register_result: lock acquired
22:13:34 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:13:34 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008245602207340785, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.023689121657285102, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 40, 'num_filters_4': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5256893030798878, 'info': {'data02': 0.5256893030798878, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008245602207340785, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.023689121657285102, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 40, 'num_filters_4': 90}"}}
exception: None

22:13:34 job_callback for (8, 0, 11) started
22:13:34 DISPATCHER: Trying to submit another job.
22:13:34 job_callback for (8, 0, 11) got condition
22:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:13:34 HBMASTER: Trying to run another job!
22:13:34 job_callback for (8, 0, 11) finished
22:13:34 start sampling a new configuration.
22:13:34 best_vector: [1, 2, 0.04299810419414149, 0.7493909655073213, 0.8230476073620879, 1, 0.10260245084753616, 0.3517852126401547, 2, 1, 2, 2, 0.30819963910360915, 0.6345815434504809, 0.7478206767455662, 0.48349722382254773], 2.041934848814839e-31, 0.048973158990866475, -2.5309572446161266e-06
22:13:34 done sampling a new configuration.
22:13:34 HBMASTER: schedule new run for iteration 8
22:13:34 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
22:13:34 HBMASTER: submitting job (8, 0, 12) to dispatcher
22:13:34 DISPATCHER: trying to submit job (8, 0, 12)
22:13:34 DISPATCHER: trying to notify the job_runner thread.
22:13:34 HBMASTER: job (8, 0, 12) submitted to dispatcher
22:13:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:13:34 DISPATCHER: Trying to submit another job.
22:13:34 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:13:34 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:13:34 WORKER: start processing job (8, 0, 12)
22:13:34 WORKER: args: ()
22:13:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:13:38 DISPATCHER: Starting worker discovery
22:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:38 DISPATCHER: Finished worker discovery
22:14:23 WORKER: done with job (8, 0, 12), trying to register it.
22:14:23 WORKER: registered result for job (8, 0, 12) with dispatcher
22:14:23 DISPATCHER: job (8, 0, 12) finished
22:14:23 DISPATCHER: register_result: lock acquired
22:14:23 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:14:23 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6721299055773738, 'info': {'data02': 0.6721299055773738, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}"}}
exception: None

22:14:23 job_callback for (8, 0, 12) started
22:14:23 DISPATCHER: Trying to submit another job.
22:14:23 job_callback for (8, 0, 12) got condition
22:14:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:14:23 HBMASTER: Trying to run another job!
22:14:23 job_callback for (8, 0, 12) finished
22:14:23 start sampling a new configuration.
22:14:23 best_vector: [3, 0, 0.18130265397376977, 0.42014439854728314, 0.8654426326735463, 0, 0.44378918559951824, 0.5677774246829508, 2, 2, 0, 2, 0.8517454826995545, 0.9622148135814421, 0.018076344726085602, 0.4815802951829135], 9.674987978719555e-32, 0.10335930155154012, -6.927122847427355e-08
22:14:23 done sampling a new configuration.
22:14:23 HBMASTER: schedule new run for iteration 8
22:14:23 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
22:14:23 HBMASTER: submitting job (8, 0, 13) to dispatcher
22:14:23 DISPATCHER: trying to submit job (8, 0, 13)
22:14:23 DISPATCHER: trying to notify the job_runner thread.
22:14:23 HBMASTER: job (8, 0, 13) submitted to dispatcher
22:14:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:14:23 DISPATCHER: Trying to submit another job.
22:14:23 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:14:23 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:14:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:14:23 WORKER: start processing job (8, 0, 13)
22:14:23 WORKER: args: ()
22:14:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023046517414382984, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.0547892632307732, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 119, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:14:38 DISPATCHER: Starting worker discovery
22:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:38 DISPATCHER: Finished worker discovery
22:15:12 WORKER: done with job (8, 0, 13), trying to register it.
22:15:12 WORKER: registered result for job (8, 0, 13) with dispatcher
22:15:12 DISPATCHER: job (8, 0, 13) finished
22:15:12 DISPATCHER: register_result: lock acquired
22:15:12 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:15:12 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023046517414382984, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.0547892632307732, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 119, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6137981527880617, 'info': {'data02': 0.6137981527880617, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023046517414382984, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.0547892632307732, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 119, 'num_filters_4': 16, 'num_filters_5': 43}"}}
exception: None

22:15:12 job_callback for (8, 0, 13) started
22:15:12 job_callback for (8, 0, 13) got condition
22:15:12 DISPATCHER: Trying to submit another job.
22:15:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:15:12 HBMASTER: Trying to run another job!
22:15:12 job_callback for (8, 0, 13) finished
22:15:12 start sampling a new configuration.
22:15:12 best_vector: [1, 1, 0.2129069702525788, 0.5043448175993407, 0.7998939684238663, 1, 0.5025696562327265, 0.6227548994662071, 0, 2, 0, 2, 0.34333635537697527, 0.28531044825838475, 0.2546621244827957, 0.48383243908726536], 1.437020786355098e-31, 0.06958841580409074, -3.1670433401355664e-06
22:15:12 done sampling a new configuration.
22:15:12 HBMASTER: schedule new run for iteration 8
22:15:12 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:15:12 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:15:12 DISPATCHER: trying to submit job (8, 0, 14)
22:15:12 DISPATCHER: trying to notify the job_runner thread.
22:15:12 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:15:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:15:12 DISPATCHER: Trying to submit another job.
22:15:12 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:15:12 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:15:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:15:12 WORKER: start processing job (8, 0, 14)
22:15:12 WORKER: args: ()
22:15:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:15:38 DISPATCHER: Starting worker discovery
22:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:38 DISPATCHER: Finished worker discovery
22:16:01 WORKER: done with job (8, 0, 14), trying to register it.
22:16:01 WORKER: registered result for job (8, 0, 14) with dispatcher
22:16:01 DISPATCHER: job (8, 0, 14) finished
22:16:01 DISPATCHER: register_result: lock acquired
22:16:01 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:16:01 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6787428349053267, 'info': {'data02': 0.6787428349053267, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}"}}
exception: None

22:16:01 job_callback for (8, 0, 14) started
22:16:01 job_callback for (8, 0, 14) got condition
22:16:01 DISPATCHER: Trying to submit another job.
22:16:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:01 HBMASTER: Trying to run another job!
22:16:01 job_callback for (8, 0, 14) finished
22:16:01 start sampling a new configuration.
22:16:01 done sampling a new configuration.
22:16:01 HBMASTER: schedule new run for iteration 8
22:16:01 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
22:16:01 HBMASTER: submitting job (8, 0, 15) to dispatcher
22:16:01 DISPATCHER: trying to submit job (8, 0, 15)
22:16:01 DISPATCHER: trying to notify the job_runner thread.
22:16:01 HBMASTER: job (8, 0, 15) submitted to dispatcher
22:16:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:01 DISPATCHER: Trying to submit another job.
22:16:01 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:16:01 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:16:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:01 WORKER: start processing job (8, 0, 15)
22:16:01 WORKER: args: ()
22:16:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07931316708938832, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03092037313113314, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 57, 'num_filters_3': 41, 'num_filters_4': 98, 'num_filters_5': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:16:38 DISPATCHER: Starting worker discovery
22:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:38 DISPATCHER: Finished worker discovery
22:16:50 WORKER: done with job (8, 0, 15), trying to register it.
22:16:50 WORKER: registered result for job (8, 0, 15) with dispatcher
22:16:50 DISPATCHER: job (8, 0, 15) finished
22:16:50 DISPATCHER: register_result: lock acquired
22:16:50 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:16:50 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07931316708938832, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03092037313113314, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 57, 'num_filters_3': 41, 'num_filters_4': 98, 'num_filters_5': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4662652899975137, 'info': {'data02': 0.4662652899975137, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07931316708938832, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03092037313113314, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 57, 'num_filters_3': 41, 'num_filters_4': 98, 'num_filters_5': 38}"}}
exception: None

22:16:50 job_callback for (8, 0, 15) started
22:16:50 DISPATCHER: Trying to submit another job.
22:16:50 job_callback for (8, 0, 15) got condition
22:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:50 HBMASTER: Trying to run another job!
22:16:50 job_callback for (8, 0, 15) finished
22:16:50 start sampling a new configuration.
22:16:50 best_vector: [1, 2, 0.36407419193223556, 0.22641328764051757, 0.40055841034379086, 1, 0.18574618384479435, 0.34068491979932997, 0, 1, 0, 2, 0.16373560535862475, 0.6302207187484186, 0.2259048234536296, 0.4820668574638897], 3.1031213154484534e-32, 0.322256173170427, -4.234354853661974e-06
22:16:50 done sampling a new configuration.
22:16:50 HBMASTER: schedule new run for iteration 8
22:16:50 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
22:16:50 HBMASTER: submitting job (8, 0, 16) to dispatcher
22:16:50 DISPATCHER: trying to submit job (8, 0, 16)
22:16:50 DISPATCHER: trying to notify the job_runner thread.
22:16:50 HBMASTER: job (8, 0, 16) submitted to dispatcher
22:16:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:50 DISPATCHER: Trying to submit another job.
22:16:50 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:16:50 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:50 WORKER: start processing job (8, 0, 16)
22:16:50 WORKER: args: ()
22:16:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005347470333219727, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.027748614259474367, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:17:38 DISPATCHER: Starting worker discovery
22:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:38 WORKER: done with job (8, 0, 16), trying to register it.
22:17:38 DISPATCHER: Finished worker discovery
22:17:38 WORKER: registered result for job (8, 0, 16) with dispatcher
22:17:38 DISPATCHER: job (8, 0, 16) finished
22:17:38 DISPATCHER: register_result: lock acquired
22:17:38 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:17:38 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005347470333219727, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.027748614259474367, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47829837190372704, 'info': {'data02': 0.47829837190372704, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005347470333219727, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.027748614259474367, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 59}"}}
exception: None

22:17:38 job_callback for (8, 0, 16) started
22:17:38 job_callback for (8, 0, 16) got condition
22:17:38 DISPATCHER: Trying to submit another job.
22:17:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:17:38 HBMASTER: Trying to run another job!
22:17:38 job_callback for (8, 0, 16) finished
22:17:38 start sampling a new configuration.
22:17:38 done sampling a new configuration.
22:17:38 HBMASTER: schedule new run for iteration 8
22:17:38 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
22:17:38 HBMASTER: submitting job (8, 0, 17) to dispatcher
22:17:38 DISPATCHER: trying to submit job (8, 0, 17)
22:17:38 DISPATCHER: trying to notify the job_runner thread.
22:17:38 HBMASTER: job (8, 0, 17) submitted to dispatcher
22:17:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:17:38 DISPATCHER: Trying to submit another job.
22:17:38 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:17:38 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:17:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:17:38 WORKER: start processing job (8, 0, 17)
22:17:38 WORKER: args: ()
22:17:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022156803434454455, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.016767729659469825, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:18:27 WORKER: done with job (8, 0, 17), trying to register it.
22:18:27 WORKER: registered result for job (8, 0, 17) with dispatcher
22:18:27 DISPATCHER: job (8, 0, 17) finished
22:18:27 DISPATCHER: register_result: lock acquired
22:18:27 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:18:27 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022156803434454455, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.016767729659469825, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5401017210088015, 'info': {'data02': 0.5401017210088015, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022156803434454455, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.016767729659469825, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 26}"}}
exception: None

22:18:27 job_callback for (8, 0, 17) started
22:18:27 DISPATCHER: Trying to submit another job.
22:18:27 job_callback for (8, 0, 17) got condition
22:18:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:27 HBMASTER: Trying to run another job!
22:18:27 job_callback for (8, 0, 17) finished
22:18:27 start sampling a new configuration.
22:18:27 best_vector: [1, 0, 0.05831032538268496, 0.6867910849316574, 0.3318669365435581, 0, 0.5382270442803376, 0.3794614872537299, 2, 2, 1, 2, 0.08725351083527788, 0.03167682678020256, 0.3346812909387788, 0.48322002598902386], 1.9218954642811946e-30, 0.0052031966284597515, -1.5177595211878223e-06
22:18:27 done sampling a new configuration.
22:18:27 HBMASTER: schedule new run for iteration 8
22:18:27 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
22:18:27 HBMASTER: submitting job (8, 0, 18) to dispatcher
22:18:27 DISPATCHER: trying to submit job (8, 0, 18)
22:18:27 DISPATCHER: trying to notify the job_runner thread.
22:18:27 HBMASTER: job (8, 0, 18) submitted to dispatcher
22:18:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:27 DISPATCHER: Trying to submit another job.
22:18:27 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:18:27 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:18:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:27 WORKER: start processing job (8, 0, 18)
22:18:27 WORKER: args: ()
22:18:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0013080388729676288, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.031166696876665616, 'kernel_size_2': 7, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:18:38 DISPATCHER: Starting worker discovery
22:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:38 DISPATCHER: Finished worker discovery
22:19:16 WORKER: done with job (8, 0, 18), trying to register it.
22:19:16 WORKER: registered result for job (8, 0, 18) with dispatcher
22:19:16 DISPATCHER: job (8, 0, 18) finished
22:19:16 DISPATCHER: register_result: lock acquired
22:19:16 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:19:16 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0013080388729676288, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.031166696876665616, 'kernel_size_2': 7, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5087326822982894, 'info': {'data02': 0.5087326822982894, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0013080388729676288, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.031166696876665616, 'kernel_size_2': 7, 'num_filters_2': 19}"}}
exception: None

22:19:16 job_callback for (8, 0, 18) started
22:19:16 job_callback for (8, 0, 18) got condition
22:19:16 DISPATCHER: Trying to submit another job.
22:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:19:16 HBMASTER: Trying to run another job!
22:19:16 job_callback for (8, 0, 18) finished
22:19:16 start sampling a new configuration.
22:19:16 done sampling a new configuration.
22:19:16 HBMASTER: schedule new run for iteration 8
22:19:16 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
22:19:16 HBMASTER: submitting job (8, 0, 19) to dispatcher
22:19:16 DISPATCHER: trying to submit job (8, 0, 19)
22:19:16 DISPATCHER: trying to notify the job_runner thread.
22:19:16 HBMASTER: job (8, 0, 19) submitted to dispatcher
22:19:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:19:16 DISPATCHER: Trying to submit another job.
22:19:16 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:19:16 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:19:16 WORKER: start processing job (8, 0, 19)
22:19:16 WORKER: args: ()
22:19:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006874032790017159, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.01843211460301945, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 67, 'num_filters_3': 27, 'num_filters_4': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:19:38 DISPATCHER: Starting worker discovery
22:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:38 DISPATCHER: Finished worker discovery
22:20:05 WORKER: done with job (8, 0, 19), trying to register it.
22:20:05 WORKER: registered result for job (8, 0, 19) with dispatcher
22:20:05 DISPATCHER: job (8, 0, 19) finished
22:20:05 DISPATCHER: register_result: lock acquired
22:20:05 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:20:05 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006874032790017159, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.01843211460301945, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 67, 'num_filters_3': 27, 'num_filters_4': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5234884435392941, 'info': {'data02': 0.5234884435392941, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006874032790017159, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.01843211460301945, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 67, 'num_filters_3': 27, 'num_filters_4': 64}"}}
exception: None

22:20:05 job_callback for (8, 0, 19) started
22:20:05 job_callback for (8, 0, 19) got condition
22:20:05 DISPATCHER: Trying to submit another job.
22:20:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:20:05 HBMASTER: Trying to run another job!
22:20:05 job_callback for (8, 0, 19) finished
22:20:05 start sampling a new configuration.
22:20:05 best_vector: [1, 1, 0.3094494956664471, 0.9116376832050985, 0.5503334150403433, 1, 0.2515941848431069, 0.3529446288527284, 2, 2, 0, 2, 0.012898611083145273, 0.07276479402239255, 0.6882356259239455, 0.4855886368603462], 6.058745460572173e-28, 1.6505067039168245e-05, -3.448214505412429e-06
22:20:05 done sampling a new configuration.
22:20:05 HBMASTER: schedule new run for iteration 8
22:20:05 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
22:20:05 HBMASTER: submitting job (8, 0, 20) to dispatcher
22:20:05 DISPATCHER: trying to submit job (8, 0, 20)
22:20:05 DISPATCHER: trying to notify the job_runner thread.
22:20:05 HBMASTER: job (8, 0, 20) submitted to dispatcher
22:20:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:20:05 DISPATCHER: Trying to submit another job.
22:20:05 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:05 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:20:05 WORKER: start processing job (8, 0, 20)
22:20:05 WORKER: args: ()
22:20:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:20:38 DISPATCHER: Starting worker discovery
22:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:38 DISPATCHER: Finished worker discovery
22:20:54 WORKER: done with job (8, 0, 20), trying to register it.
22:20:54 WORKER: registered result for job (8, 0, 20) with dispatcher
22:20:54 DISPATCHER: job (8, 0, 20) finished
22:20:54 DISPATCHER: register_result: lock acquired
22:20:54 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:20:54 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6348963715070947, 'info': {'data02': 0.6348963715070947, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}"}}
exception: None

22:20:54 job_callback for (8, 0, 20) started
22:20:54 DISPATCHER: Trying to submit another job.
22:20:54 job_callback for (8, 0, 20) got condition
22:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:20:54 HBMASTER: Trying to run another job!
22:20:54 job_callback for (8, 0, 20) finished
22:20:54 start sampling a new configuration.
22:20:54 best_vector: [1, 1, 0.0767674096757754, 0.6884492771326687, 0.8588250594729414, 0, 0.4855974037151125, 0.7005321944187758, 0, 1, 0, 2, 0.1638620846470049, 0.9626710432248204, 0.3952173299497105, 0.4837308573303374], 8.654849195057205e-31, 0.01155421634118248, -3.7682239648800986e-08
22:20:54 done sampling a new configuration.
22:20:54 HBMASTER: schedule new run for iteration 8
22:20:54 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
22:20:54 HBMASTER: submitting job (8, 0, 21) to dispatcher
22:20:54 DISPATCHER: trying to submit job (8, 0, 21)
22:20:54 DISPATCHER: trying to notify the job_runner thread.
22:20:54 HBMASTER: job (8, 0, 21) submitted to dispatcher
22:20:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:20:54 DISPATCHER: Trying to submit another job.
22:20:54 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:54 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:20:54 WORKER: start processing job (8, 0, 21)
22:20:54 WORKER: args: ()
22:20:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014240814171132148, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08154801570150451, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 119, 'num_filters_4': 36, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:21:38 DISPATCHER: Starting worker discovery
22:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:39 DISPATCHER: Finished worker discovery
22:21:44 WORKER: done with job (8, 0, 21), trying to register it.
22:21:44 WORKER: registered result for job (8, 0, 21) with dispatcher
22:21:44 DISPATCHER: job (8, 0, 21) finished
22:21:44 DISPATCHER: register_result: lock acquired
22:21:44 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:21:44 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014240814171132148, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08154801570150451, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 119, 'num_filters_4': 36, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6102916712052104, 'info': {'data02': 0.6102916712052104, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014240814171132148, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08154801570150451, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 119, 'num_filters_4': 36, 'num_filters_5': 43}"}}
exception: None

22:21:44 job_callback for (8, 0, 21) started
22:21:44 DISPATCHER: Trying to submit another job.
22:21:44 job_callback for (8, 0, 21) got condition
22:21:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:21:44 HBMASTER: Trying to run another job!
22:21:44 job_callback for (8, 0, 21) finished
22:21:44 start sampling a new configuration.
22:21:44 best_vector: [3, 0, 0.32503526746912237, 0.13139313232743285, 0.8830338326550264, 0, 0.02358508068892798, 0.6148372156174713, 0, 2, 0, 2, 0.6172224881268458, 0.1413230197335141, 0.9821421528407548, 0.48302587073920217], 6.850443972291177e-32, 0.1459759402521678, -2.4753190519475804e-07
22:21:44 done sampling a new configuration.
22:21:44 HBMASTER: schedule new run for iteration 8
22:21:44 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
22:21:44 HBMASTER: submitting job (8, 0, 22) to dispatcher
22:21:44 DISPATCHER: trying to submit job (8, 0, 22)
22:21:44 DISPATCHER: trying to notify the job_runner thread.
22:21:44 HBMASTER: job (8, 0, 22) submitted to dispatcher
22:21:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:21:44 DISPATCHER: Trying to submit another job.
22:21:44 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:21:44 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:21:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:21:44 WORKER: start processing job (8, 0, 22)
22:21:44 WORKER: args: ()
22:21:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004467561451296241, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.0630843539764241, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 21, 'num_filters_4': 124, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:22:32 WORKER: done with job (8, 0, 22), trying to register it.
22:22:32 WORKER: registered result for job (8, 0, 22) with dispatcher
22:22:32 DISPATCHER: job (8, 0, 22) finished
22:22:32 DISPATCHER: register_result: lock acquired
22:22:32 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:22:32 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004467561451296241, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.0630843539764241, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 21, 'num_filters_4': 124, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004467561451296241, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.0630843539764241, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 21, 'num_filters_4': 124, 'num_filters_5': 43}"}}
exception: None

22:22:32 job_callback for (8, 0, 22) started
22:22:32 DISPATCHER: Trying to submit another job.
22:22:32 job_callback for (8, 0, 22) got condition
22:22:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:22:32 HBMASTER: Trying to run another job!
22:22:32 job_callback for (8, 0, 22) finished
22:22:32 start sampling a new configuration.
22:22:33 best_vector: [1, 2, 0.37215364630178893, 0.505485285383164, 0.2830974072738997, 0, 0.08030939350904509, 0.023215931705738317, 0, 1, 1, 2, 0.3830505045812687, 0.3357968399180806, 0.058227792664246714, 0.4826458188374164], 3.6437447308738886e-31, 0.027444293545782157, -7.608537434105773e-06
22:22:33 done sampling a new configuration.
22:22:33 HBMASTER: schedule new run for iteration 8
22:22:33 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
22:22:33 HBMASTER: submitting job (8, 0, 23) to dispatcher
22:22:33 DISPATCHER: trying to submit job (8, 0, 23)
22:22:33 DISPATCHER: trying to notify the job_runner thread.
22:22:33 HBMASTER: job (8, 0, 23) submitted to dispatcher
22:22:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:22:33 DISPATCHER: Trying to submit another job.
22:22:33 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:22:33 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:22:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:22:33 WORKER: start processing job (8, 0, 23)
22:22:33 WORKER: args: ()
22:22:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005550182868838279, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.010720242845300045, 'kernel_size_2': 3, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:22:39 DISPATCHER: Starting worker discovery
22:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:39 DISPATCHER: Finished worker discovery
22:23:21 WORKER: done with job (8, 0, 23), trying to register it.
22:23:21 WORKER: registered result for job (8, 0, 23) with dispatcher
22:23:21 DISPATCHER: job (8, 0, 23) finished
22:23:21 DISPATCHER: register_result: lock acquired
22:23:21 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:23:21 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005550182868838279, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.010720242845300045, 'kernel_size_2': 3, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4163847504793601, 'info': {'data02': 0.4163847504793601, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005550182868838279, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.010720242845300045, 'kernel_size_2': 3, 'num_filters_2': 35}"}}
exception: None

22:23:21 job_callback for (8, 0, 23) started
22:23:21 job_callback for (8, 0, 23) got condition
22:23:21 DISPATCHER: Trying to submit another job.
22:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:21 HBMASTER: Trying to run another job!
22:23:21 job_callback for (8, 0, 23) finished
22:23:21 start sampling a new configuration.
22:23:21 best_vector: [3, 0, 0.49519981288127307, 0.411376627807409, 0.4934475855709476, 0, 0.4444866893472619, 0.011652929464039508, 2, 2, 2, 2, 0.8504908502577764, 0.6096498230227017, 0.5827530233163025, 0.48336377772222267], 1.282129031065921e-32, 0.7799527003679435, -9.696326978779738e-08
22:23:21 done sampling a new configuration.
22:23:21 HBMASTER: schedule new run for iteration 8
22:23:21 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
22:23:21 HBMASTER: submitting job (8, 0, 24) to dispatcher
22:23:21 DISPATCHER: trying to submit job (8, 0, 24)
22:23:21 DISPATCHER: trying to notify the job_runner thread.
22:23:21 HBMASTER: job (8, 0, 24) submitted to dispatcher
22:23:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:21 DISPATCHER: Trying to submit another job.
22:23:21 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:23:21 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:21 WORKER: start processing job (8, 0, 24)
22:23:21 WORKER: args: ()
22:23:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009781368614488039, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010355255305914267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:23:39 DISPATCHER: Starting worker discovery
22:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:39 DISPATCHER: Finished worker discovery
22:24:11 WORKER: done with job (8, 0, 24), trying to register it.
22:24:11 WORKER: registered result for job (8, 0, 24) with dispatcher
22:24:11 DISPATCHER: job (8, 0, 24) finished
22:24:11 DISPATCHER: register_result: lock acquired
22:24:11 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:24:11 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009781368614488039, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010355255305914267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40813319932930375, 'info': {'data02': 0.40813319932930375, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009781368614488039, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010355255305914267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 56}"}}
exception: None

22:24:11 job_callback for (8, 0, 24) started
22:24:11 DISPATCHER: Trying to submit another job.
22:24:11 job_callback for (8, 0, 24) got condition
22:24:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:11 HBMASTER: Trying to run another job!
22:24:11 job_callback for (8, 0, 24) finished
22:24:11 start sampling a new configuration.
22:24:11 done sampling a new configuration.
22:24:11 HBMASTER: schedule new run for iteration 8
22:24:11 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
22:24:11 HBMASTER: submitting job (8, 0, 25) to dispatcher
22:24:11 DISPATCHER: trying to submit job (8, 0, 25)
22:24:11 DISPATCHER: trying to notify the job_runner thread.
22:24:11 HBMASTER: job (8, 0, 25) submitted to dispatcher
22:24:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:24:11 DISPATCHER: Trying to submit another job.
22:24:11 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:24:11 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:24:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:24:11 WORKER: start processing job (8, 0, 25)
22:24:11 WORKER: args: ()
22:24:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04063575081625766, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.0233365271955665, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 48, 'num_filters_4': 51, 'num_filters_5': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:24:39 DISPATCHER: Starting worker discovery
22:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:39 DISPATCHER: Finished worker discovery
22:24:59 WORKER: done with job (8, 0, 25), trying to register it.
22:24:59 WORKER: registered result for job (8, 0, 25) with dispatcher
22:24:59 DISPATCHER: job (8, 0, 25) finished
22:24:59 DISPATCHER: register_result: lock acquired
22:24:59 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:24:59 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04063575081625766, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.0233365271955665, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 48, 'num_filters_4': 51, 'num_filters_5': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38288253126878574, 'info': {'data02': 0.38288253126878574, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04063575081625766, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.0233365271955665, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 48, 'num_filters_4': 51, 'num_filters_5': 24}"}}
exception: None

22:24:59 job_callback for (8, 0, 25) started
22:24:59 DISPATCHER: Trying to submit another job.
22:24:59 job_callback for (8, 0, 25) got condition
22:24:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:59 HBMASTER: Trying to run another job!
22:24:59 job_callback for (8, 0, 25) finished
22:24:59 start sampling a new configuration.
22:25:00 best_vector: [3, 0, 0.44547601247698215, 0.5337356645162034, 0.5546161572661733, 1, 0.7597399792264309, 0.4631796745399024, 0, 2, 1, 2, 0.36445566930073525, 0.6170001170369026, 0.9893991958206199, 0.4839678633815776], 2.9274499783864002e-31, 0.03415942227478115, -5.042208533504868e-06
22:25:00 done sampling a new configuration.
22:25:00 HBMASTER: schedule new run for iteration 8
22:25:00 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
22:25:00 HBMASTER: submitting job (8, 0, 26) to dispatcher
22:25:00 DISPATCHER: trying to submit job (8, 0, 26)
22:25:00 DISPATCHER: trying to notify the job_runner thread.
22:25:00 HBMASTER: job (8, 0, 26) submitted to dispatcher
22:25:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:00 DISPATCHER: Trying to submit another job.
22:25:00 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:25:00 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:25:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:00 WORKER: start processing job (8, 0, 26)
22:25:00 WORKER: args: ()
22:25:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007779506087142, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.04005074970108834, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:25:39 DISPATCHER: Starting worker discovery
22:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:39 DISPATCHER: Finished worker discovery
22:25:49 WORKER: done with job (8, 0, 26), trying to register it.
22:25:49 WORKER: registered result for job (8, 0, 26) with dispatcher
22:25:49 DISPATCHER: job (8, 0, 26) finished
22:25:49 DISPATCHER: register_result: lock acquired
22:25:49 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:25:49 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007779506087142, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.04005074970108834, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6119576200374213, 'info': {'data02': 0.6119576200374213, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007779506087142, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.04005074970108834, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 57}"}}
exception: None

22:25:49 job_callback for (8, 0, 26) started
22:25:49 job_callback for (8, 0, 26) got condition
22:25:49 DISPATCHER: Trying to submit another job.
22:25:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:25:49 HBMASTER: Trying to run another job!
22:25:49 job_callback for (8, 0, 26) finished
22:25:49 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
22:25:49 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
22:25:49 HBMASTER: schedule new run for iteration 8
22:25:49 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
22:25:49 HBMASTER: submitting job (8, 0, 4) to dispatcher
22:25:49 DISPATCHER: trying to submit job (8, 0, 4)
22:25:49 DISPATCHER: trying to notify the job_runner thread.
22:25:49 HBMASTER: job (8, 0, 4) submitted to dispatcher
22:25:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:49 DISPATCHER: Trying to submit another job.
22:25:49 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:25:49 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:25:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:49 WORKER: start processing job (8, 0, 4)
22:25:49 WORKER: args: ()
22:25:49 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011420501014346607, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.056882770665276285, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 98, 'num_filters_4': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:26:39 DISPATCHER: Starting worker discovery
22:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:39 DISPATCHER: Finished worker discovery
22:27:39 DISPATCHER: Starting worker discovery
22:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:39 DISPATCHER: Finished worker discovery
22:28:08 WORKER: done with job (8, 0, 4), trying to register it.
22:28:08 WORKER: registered result for job (8, 0, 4) with dispatcher
22:28:08 DISPATCHER: job (8, 0, 4) finished
22:28:08 DISPATCHER: register_result: lock acquired
22:28:08 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:28:08 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011420501014346607, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.056882770665276285, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 98, 'num_filters_4': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5246680609633311, 'info': {'data02': 0.5246680609633311, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011420501014346607, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.056882770665276285, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 98, 'num_filters_4': 41}"}}
exception: None

22:28:08 job_callback for (8, 0, 4) started
22:28:08 DISPATCHER: Trying to submit another job.
22:28:08 job_callback for (8, 0, 4) got condition
22:28:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:28:08 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.740036





22:28:08 HBMASTER: Trying to run another job!
22:28:08 job_callback for (8, 0, 4) finished
22:28:08 HBMASTER: schedule new run for iteration 8
22:28:08 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
22:28:08 HBMASTER: submitting job (8, 0, 6) to dispatcher
22:28:08 DISPATCHER: trying to submit job (8, 0, 6)
22:28:08 DISPATCHER: trying to notify the job_runner thread.
22:28:08 HBMASTER: job (8, 0, 6) submitted to dispatcher
22:28:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:28:08 DISPATCHER: Trying to submit another job.
22:28:08 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:28:08 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:28:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:28:08 WORKER: start processing job (8, 0, 6)
22:28:08 WORKER: args: ()
22:28:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02969475027205534, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01816560056315508, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 24, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:28:39 DISPATCHER: Starting worker discovery
22:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:39 DISPATCHER: Finished worker discovery
22:29:39 DISPATCHER: Starting worker discovery
22:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:39 DISPATCHER: Finished worker discovery
22:30:26 WORKER: done with job (8, 0, 6), trying to register it.
22:30:26 WORKER: registered result for job (8, 0, 6) with dispatcher
22:30:26 DISPATCHER: job (8, 0, 6) finished
22:30:26 DISPATCHER: register_result: lock acquired
22:30:26 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:30:26 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02969475027205534, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01816560056315508, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 24, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35686155496380767, 'info': {'data02': 0.35686155496380767, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02969475027205534, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01816560056315508, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 24, 'num_filters_4': 43}"}}
exception: None

22:30:26 job_callback for (8, 0, 6) started
22:30:26 DISPATCHER: Trying to submit another job.
22:30:26 job_callback for (8, 0, 6) got condition
22:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:30:26 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.740036





22:30:26 HBMASTER: Trying to run another job!
22:30:26 job_callback for (8, 0, 6) finished
22:30:26 HBMASTER: schedule new run for iteration 8
22:30:26 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
22:30:26 HBMASTER: submitting job (8, 0, 12) to dispatcher
22:30:26 DISPATCHER: trying to submit job (8, 0, 12)
22:30:26 DISPATCHER: trying to notify the job_runner thread.
22:30:26 HBMASTER: job (8, 0, 12) submitted to dispatcher
22:30:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:30:26 DISPATCHER: Trying to submit another job.
22:30:26 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:30:26 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:30:26 WORKER: start processing job (8, 0, 12)
22:30:26 WORKER: args: ()
22:30:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:30:39 DISPATCHER: Starting worker discovery
22:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:39 DISPATCHER: Finished worker discovery
22:31:39 DISPATCHER: Starting worker discovery
22:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:39 DISPATCHER: Finished worker discovery
22:32:39 DISPATCHER: Starting worker discovery
22:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:39 DISPATCHER: Finished worker discovery
22:32:45 WORKER: done with job (8, 0, 12), trying to register it.
22:32:45 WORKER: registered result for job (8, 0, 12) with dispatcher
22:32:45 DISPATCHER: job (8, 0, 12) finished
22:32:45 DISPATCHER: register_result: lock acquired
22:32:45 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:32:45 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6854796090695753, 'info': {'data02': 0.6854796090695753, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}"}}
exception: None

22:32:45 job_callback for (8, 0, 12) started
22:32:45 DISPATCHER: Trying to submit another job.
22:32:45 job_callback for (8, 0, 12) got condition
22:32:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:32:45 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.740036





22:32:45 HBMASTER: Trying to run another job!
22:32:45 job_callback for (8, 0, 12) finished
22:32:45 HBMASTER: schedule new run for iteration 8
22:32:45 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
22:32:45 HBMASTER: submitting job (8, 0, 13) to dispatcher
22:32:45 DISPATCHER: trying to submit job (8, 0, 13)
22:32:45 DISPATCHER: trying to notify the job_runner thread.
22:32:45 HBMASTER: job (8, 0, 13) submitted to dispatcher
22:32:45 DISPATCHER: Trying to submit another job.
22:32:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:32:45 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:32:45 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:32:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:32:45 WORKER: start processing job (8, 0, 13)
22:32:45 WORKER: args: ()
22:32:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023046517414382984, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.0547892632307732, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 119, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:33:39 DISPATCHER: Starting worker discovery
22:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:39 DISPATCHER: Finished worker discovery
22:34:39 DISPATCHER: Starting worker discovery
22:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:39 DISPATCHER: Finished worker discovery
22:35:03 WORKER: done with job (8, 0, 13), trying to register it.
22:35:03 WORKER: registered result for job (8, 0, 13) with dispatcher
22:35:03 DISPATCHER: job (8, 0, 13) finished
22:35:03 DISPATCHER: register_result: lock acquired
22:35:03 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:35:03 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023046517414382984, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.0547892632307732, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 119, 'num_filters_4': 16, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.40854494234969696, 'info': {'data02': 0.40854494234969696, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0023046517414382984, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.0547892632307732, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 119, 'num_filters_4': 16, 'num_filters_5': 43}"}}
exception: None

22:35:03 job_callback for (8, 0, 13) started
22:35:03 DISPATCHER: Trying to submit another job.
22:35:03 job_callback for (8, 0, 13) got condition
22:35:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:03 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.740036





22:35:03 HBMASTER: Trying to run another job!
22:35:03 job_callback for (8, 0, 13) finished
22:35:03 HBMASTER: schedule new run for iteration 8
22:35:03 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:35:03 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:35:03 DISPATCHER: trying to submit job (8, 0, 14)
22:35:03 DISPATCHER: trying to notify the job_runner thread.
22:35:03 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:35:03 DISPATCHER: Trying to submit another job.
22:35:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:03 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:35:03 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:35:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:03 WORKER: start processing job (8, 0, 14)
22:35:03 WORKER: args: ()
22:35:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:35:39 DISPATCHER: Starting worker discovery
22:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:39 DISPATCHER: Finished worker discovery
22:36:39 DISPATCHER: Starting worker discovery
22:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:39 DISPATCHER: Finished worker discovery
22:37:21 WORKER: done with job (8, 0, 14), trying to register it.
22:37:21 WORKER: registered result for job (8, 0, 14) with dispatcher
22:37:21 DISPATCHER: job (8, 0, 14) finished
22:37:21 DISPATCHER: register_result: lock acquired
22:37:21 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:37:21 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6005497181666468, 'info': {'data02': 0.6005497181666468, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}"}}
exception: None

22:37:21 job_callback for (8, 0, 14) started
22:37:21 DISPATCHER: Trying to submit another job.
22:37:21 job_callback for (8, 0, 14) got condition
22:37:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:37:21 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.740036





22:37:21 HBMASTER: Trying to run another job!
22:37:21 job_callback for (8, 0, 14) finished
22:37:21 HBMASTER: schedule new run for iteration 8
22:37:21 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
22:37:21 HBMASTER: submitting job (8, 0, 17) to dispatcher
22:37:21 DISPATCHER: trying to submit job (8, 0, 17)
22:37:21 DISPATCHER: trying to notify the job_runner thread.
22:37:21 HBMASTER: job (8, 0, 17) submitted to dispatcher
22:37:21 DISPATCHER: Trying to submit another job.
22:37:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:37:21 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:37:21 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:37:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:37:21 WORKER: start processing job (8, 0, 17)
22:37:21 WORKER: args: ()
22:37:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022156803434454455, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.016767729659469825, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:37:39 DISPATCHER: Starting worker discovery
22:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:39 DISPATCHER: Finished worker discovery
22:38:39 DISPATCHER: Starting worker discovery
22:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:39 DISPATCHER: Finished worker discovery
22:39:39 DISPATCHER: Starting worker discovery
22:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:39 DISPATCHER: Finished worker discovery
22:39:39 WORKER: done with job (8, 0, 17), trying to register it.
22:39:39 WORKER: registered result for job (8, 0, 17) with dispatcher
22:39:39 DISPATCHER: job (8, 0, 17) finished
22:39:39 DISPATCHER: register_result: lock acquired
22:39:39 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:39:39 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022156803434454455, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.016767729659469825, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.381998036700502, 'info': {'data02': 0.381998036700502, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022156803434454455, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.016767729659469825, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 26}"}}
exception: None

22:39:39 job_callback for (8, 0, 17) started
22:39:39 DISPATCHER: Trying to submit another job.
22:39:39 job_callback for (8, 0, 17) got condition
22:39:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:39 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.740036





22:39:39 HBMASTER: Trying to run another job!
22:39:39 job_callback for (8, 0, 17) finished
22:39:39 HBMASTER: schedule new run for iteration 8
22:39:39 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
22:39:39 HBMASTER: submitting job (8, 0, 20) to dispatcher
22:39:39 DISPATCHER: trying to submit job (8, 0, 20)
22:39:39 DISPATCHER: trying to notify the job_runner thread.
22:39:39 HBMASTER: job (8, 0, 20) submitted to dispatcher
22:39:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:39 DISPATCHER: Trying to submit another job.
22:39:39 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:39:39 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:39:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:39 WORKER: start processing job (8, 0, 20)
22:39:39 WORKER: args: ()
22:39:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:40:39 DISPATCHER: Starting worker discovery
22:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:39 DISPATCHER: Finished worker discovery
22:41:39 DISPATCHER: Starting worker discovery
22:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:39 DISPATCHER: Finished worker discovery
22:41:57 WORKER: done with job (8, 0, 20), trying to register it.
22:41:57 WORKER: registered result for job (8, 0, 20) with dispatcher
22:41:57 DISPATCHER: job (8, 0, 20) finished
22:41:57 DISPATCHER: register_result: lock acquired
22:41:57 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:41:57 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6297952687662681, 'info': {'data02': 0.6297952687662681, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}"}}
exception: None

22:41:57 job_callback for (8, 0, 20) started
22:41:57 job_callback for (8, 0, 20) got condition
22:41:57 DISPATCHER: Trying to submit another job.
22:41:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:41:57 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.740036





22:41:57 HBMASTER: Trying to run another job!
22:41:57 job_callback for (8, 0, 20) finished
22:41:57 HBMASTER: schedule new run for iteration 8
22:41:57 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
22:41:57 HBMASTER: submitting job (8, 0, 21) to dispatcher
22:41:57 DISPATCHER: trying to submit job (8, 0, 21)
22:41:57 DISPATCHER: trying to notify the job_runner thread.
22:41:57 HBMASTER: job (8, 0, 21) submitted to dispatcher
22:41:57 DISPATCHER: Trying to submit another job.
22:41:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:41:57 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:41:57 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:41:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:41:57 WORKER: start processing job (8, 0, 21)
22:41:57 WORKER: args: ()
22:41:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014240814171132148, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08154801570150451, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 119, 'num_filters_4': 36, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:42:39 DISPATCHER: Starting worker discovery
22:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:39 DISPATCHER: Finished worker discovery
22:43:39 DISPATCHER: Starting worker discovery
22:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:39 DISPATCHER: Finished worker discovery
22:44:15 WORKER: done with job (8, 0, 21), trying to register it.
22:44:15 WORKER: registered result for job (8, 0, 21) with dispatcher
22:44:15 DISPATCHER: job (8, 0, 21) finished
22:44:15 DISPATCHER: register_result: lock acquired
22:44:15 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:44:15 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014240814171132148, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08154801570150451, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 119, 'num_filters_4': 36, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4126120547387482, 'info': {'data02': 0.4126120547387482, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014240814171132148, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08154801570150451, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 119, 'num_filters_4': 36, 'num_filters_5': 43}"}}
exception: None

22:44:15 job_callback for (8, 0, 21) started
22:44:15 DISPATCHER: Trying to submit another job.
22:44:15 job_callback for (8, 0, 21) got condition
22:44:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:15 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.740036





22:44:15 HBMASTER: Trying to run another job!
22:44:15 job_callback for (8, 0, 21) finished
22:44:15 HBMASTER: schedule new run for iteration 8
22:44:15 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
22:44:15 HBMASTER: submitting job (8, 0, 26) to dispatcher
22:44:15 DISPATCHER: trying to submit job (8, 0, 26)
22:44:15 DISPATCHER: trying to notify the job_runner thread.
22:44:15 HBMASTER: job (8, 0, 26) submitted to dispatcher
22:44:15 DISPATCHER: Trying to submit another job.
22:44:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:15 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:44:15 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:44:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:15 WORKER: start processing job (8, 0, 26)
22:44:15 WORKER: args: ()
22:44:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007779506087142, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.04005074970108834, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:44:39 DISPATCHER: Starting worker discovery
22:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:39 DISPATCHER: Finished worker discovery
22:45:39 DISPATCHER: Starting worker discovery
22:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:39 DISPATCHER: Finished worker discovery
22:46:33 WORKER: done with job (8, 0, 26), trying to register it.
22:46:33 WORKER: registered result for job (8, 0, 26) with dispatcher
22:46:33 DISPATCHER: job (8, 0, 26) finished
22:46:33 DISPATCHER: register_result: lock acquired
22:46:33 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:46:33 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007779506087142, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.04005074970108834, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5024379110006054, 'info': {'data02': 0.5024379110006054, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007779506087142, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.04005074970108834, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 57}"}}
exception: None

22:46:33 job_callback for (8, 0, 26) started
22:46:33 DISPATCHER: Trying to submit another job.
22:46:33 job_callback for (8, 0, 26) got condition
22:46:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:33 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.740036





22:46:33 HBMASTER: Trying to run another job!
22:46:33 job_callback for (8, 0, 26) finished
22:46:33 ITERATION: Advancing config (8, 0, 12) to next budget 400.000000
22:46:33 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
22:46:33 ITERATION: Advancing config (8, 0, 20) to next budget 400.000000
22:46:33 HBMASTER: schedule new run for iteration 8
22:46:33 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
22:46:33 HBMASTER: submitting job (8, 0, 12) to dispatcher
22:46:33 DISPATCHER: trying to submit job (8, 0, 12)
22:46:33 DISPATCHER: trying to notify the job_runner thread.
22:46:33 HBMASTER: job (8, 0, 12) submitted to dispatcher
22:46:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:33 DISPATCHER: Trying to submit another job.
22:46:33 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:46:33 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:46:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:33 WORKER: start processing job (8, 0, 12)
22:46:33 WORKER: args: ()
22:46:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
22:46:39 DISPATCHER: Starting worker discovery
22:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:39 DISPATCHER: Finished worker discovery
22:47:39 DISPATCHER: Starting worker discovery
22:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:39 DISPATCHER: Finished worker discovery
22:48:39 DISPATCHER: Starting worker discovery
22:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:39 DISPATCHER: Finished worker discovery
22:49:39 DISPATCHER: Starting worker discovery
22:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:39 DISPATCHER: Finished worker discovery
22:50:39 DISPATCHER: Starting worker discovery
22:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:39 DISPATCHER: Finished worker discovery
22:51:39 DISPATCHER: Starting worker discovery
22:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:39 DISPATCHER: Finished worker discovery
22:52:39 DISPATCHER: Starting worker discovery
22:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:39 DISPATCHER: Finished worker discovery
22:53:21 WORKER: done with job (8, 0, 12), trying to register it.
22:53:21 WORKER: registered result for job (8, 0, 12) with dispatcher
22:53:21 DISPATCHER: job (8, 0, 12) finished
22:53:21 DISPATCHER: register_result: lock acquired
22:53:21 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
22:53:21 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6248735320144683, 'info': {'data02': 0.6248735320144683, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}"}}
exception: None

22:53:21 job_callback for (8, 0, 12) started
22:53:21 DISPATCHER: Trying to submit another job.
22:53:21 job_callback for (8, 0, 12) got condition
22:53:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:21 HBMASTER: Trying to run another job!
22:53:21 job_callback for (8, 0, 12) finished
22:53:21 HBMASTER: schedule new run for iteration 8
22:53:21 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:53:21 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:53:21 DISPATCHER: trying to submit job (8, 0, 14)
22:53:21 DISPATCHER: trying to notify the job_runner thread.
22:53:21 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:53:21 DISPATCHER: Trying to submit another job.
22:53:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:21 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272
22:53:21 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
22:53:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:21 WORKER: start processing job (8, 0, 14)
22:53:21 WORKER: args: ()
22:53:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
22:53:39 DISPATCHER: Starting worker discovery
22:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:39 DISPATCHER: Finished worker discovery
22:54:39 DISPATCHER: Starting worker discovery
22:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:39 DISPATCHER: Finished worker discovery
22:55:39 DISPATCHER: Starting worker discovery
22:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:39 DISPATCHER: Finished worker discovery
22:56:39 DISPATCHER: Starting worker discovery
22:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:39 DISPATCHER: Finished worker discovery
22:57:39 DISPATCHER: Starting worker discovery
22:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:39 DISPATCHER: Finished worker discovery
22:58:39 DISPATCHER: Starting worker discovery
22:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:39 DISPATCHER: Finished worker discovery
22:59:39 DISPATCHER: Starting worker discovery
22:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:39 DISPATCHER: Finished worker discovery
23:00:07 WORKER: done with job (8, 0, 14), trying to register it.
23:00:07 WORKER: registered result for job (8, 0, 14) with dispatcher
23:00:07 DISPATCHER: job (8, 0, 14) finished
23:00:07 DISPATCHER: register_result: lock acquired
23:00:07 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:00:07 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5151063626945768, 'info': {'data02': 0.5151063626945768, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00266571637945333, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.06459855511120687, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 32, 'num_filters_3': 28, 'num_filters_4': 27}"}}
exception: None

23:00:07 job_callback for (8, 0, 14) started
23:00:07 DISPATCHER: Trying to submit another job.
23:00:07 job_callback for (8, 0, 14) got condition
23:00:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:07 HBMASTER: Trying to run another job!
23:00:07 job_callback for (8, 0, 14) finished
23:00:07 HBMASTER: schedule new run for iteration 8
23:00:07 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:00:07 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:00:07 DISPATCHER: trying to submit job (8, 0, 20)
23:00:07 DISPATCHER: trying to notify the job_runner thread.
23:00:07 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:00:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:07 DISPATCHER: Trying to submit another job.
23:00:07 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:00:07 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:00:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:07 WORKER: start processing job (8, 0, 20)
23:00:07 WORKER: args: ()
23:00:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
23:00:39 DISPATCHER: Starting worker discovery
23:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:39 DISPATCHER: Finished worker discovery
23:01:39 DISPATCHER: Starting worker discovery
23:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:39 DISPATCHER: Finished worker discovery
23:02:39 DISPATCHER: Starting worker discovery
23:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:39 DISPATCHER: Finished worker discovery
23:03:39 DISPATCHER: Starting worker discovery
23:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:39 DISPATCHER: Finished worker discovery
23:04:39 DISPATCHER: Starting worker discovery
23:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:39 DISPATCHER: Finished worker discovery
23:05:39 DISPATCHER: Starting worker discovery
23:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:39 DISPATCHER: Finished worker discovery
23:06:39 DISPATCHER: Starting worker discovery
23:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:39 DISPATCHER: Finished worker discovery
23:06:54 WORKER: done with job (8, 0, 20), trying to register it.
23:06:54 WORKER: registered result for job (8, 0, 20) with dispatcher
23:06:54 DISPATCHER: job (8, 0, 20) finished
23:06:54 DISPATCHER: register_result: lock acquired
23:06:54 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:06:54 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4779148859357789, 'info': {'data02': 0.4779148859357789, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004158138888153035, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.028786677935129016, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 18}"}}
exception: None

23:06:54 job_callback for (8, 0, 20) started
23:06:54 job_callback for (8, 0, 20) got condition
23:06:54 DISPATCHER: Trying to submit another job.
23:06:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:54 HBMASTER: Trying to run another job!
23:06:54 job_callback for (8, 0, 20) finished
23:06:54 ITERATION: Advancing config (8, 0, 12) to next budget 1200.000000
23:06:54 HBMASTER: schedule new run for iteration 8
23:06:54 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
23:06:54 HBMASTER: submitting job (8, 0, 12) to dispatcher
23:06:54 DISPATCHER: trying to submit job (8, 0, 12)
23:06:54 DISPATCHER: trying to notify the job_runner thread.
23:06:54 HBMASTER: job (8, 0, 12) submitted to dispatcher
23:06:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:54 DISPATCHER: Trying to submit another job.
23:06:54 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:06:54 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:06:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:54 WORKER: start processing job (8, 0, 12)
23:06:54 WORKER: args: ()
23:06:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 1200.0, 'working_directory': '.'}
23:07:39 DISPATCHER: Starting worker discovery
23:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:39 DISPATCHER: Finished worker discovery
23:08:39 DISPATCHER: Starting worker discovery
23:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:39 DISPATCHER: Finished worker discovery
23:09:39 DISPATCHER: Starting worker discovery
23:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:39 DISPATCHER: Finished worker discovery
23:10:39 DISPATCHER: Starting worker discovery
23:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:39 DISPATCHER: Finished worker discovery
23:11:39 DISPATCHER: Starting worker discovery
23:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:39 DISPATCHER: Finished worker discovery
23:12:39 DISPATCHER: Starting worker discovery
23:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:39 DISPATCHER: Finished worker discovery
23:13:39 DISPATCHER: Starting worker discovery
23:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:39 DISPATCHER: Finished worker discovery
23:14:39 DISPATCHER: Starting worker discovery
23:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:39 DISPATCHER: Finished worker discovery
23:15:39 DISPATCHER: Starting worker discovery
23:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:39 DISPATCHER: Finished worker discovery
23:16:39 DISPATCHER: Starting worker discovery
23:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:39 DISPATCHER: Finished worker discovery
23:17:39 DISPATCHER: Starting worker discovery
23:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:39 DISPATCHER: Finished worker discovery
23:18:39 DISPATCHER: Starting worker discovery
23:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:39 DISPATCHER: Finished worker discovery
23:19:39 DISPATCHER: Starting worker discovery
23:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:39 DISPATCHER: Finished worker discovery
23:20:39 DISPATCHER: Starting worker discovery
23:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:39 DISPATCHER: Finished worker discovery
23:21:39 DISPATCHER: Starting worker discovery
23:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:39 DISPATCHER: Finished worker discovery
23:22:39 DISPATCHER: Starting worker discovery
23:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:39 DISPATCHER: Finished worker discovery
23:23:39 DISPATCHER: Starting worker discovery
23:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:40 DISPATCHER: Finished worker discovery
23:24:40 DISPATCHER: Starting worker discovery
23:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:40 DISPATCHER: Finished worker discovery
23:25:40 DISPATCHER: Starting worker discovery
23:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:40 DISPATCHER: Finished worker discovery
23:26:40 DISPATCHER: Starting worker discovery
23:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:40 DISPATCHER: Finished worker discovery
23:27:11 WORKER: done with job (8, 0, 12), trying to register it.
23:27:11 WORKER: registered result for job (8, 0, 12) with dispatcher
23:27:11 DISPATCHER: job (8, 0, 12) finished
23:27:11 DISPATCHER: register_result: lock acquired
23:27:11 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:27:11 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6465554040545799, 'info': {'data02': 0.6465554040545799, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012189789565721244, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02868686658809582, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 59, 'num_filters_4': 75, 'num_filters_5': 43}"}}
exception: None

23:27:11 job_callback for (8, 0, 12) started
23:27:11 DISPATCHER: Trying to submit another job.
23:27:11 job_callback for (8, 0, 12) got condition
23:27:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:11 HBMASTER: Trying to run another job!
23:27:11 job_callback for (8, 0, 12) finished
23:27:11 start sampling a new configuration.
23:27:11 best_vector: [0, 1, 0.030765868097304895, 0.3230188709390191, 0.576903399046351, 0, 0.6119708024011693, 0.6404746499961111, 0, 2, 1, 2, 0.5001786450279609, 0.8027364647704867, 0.6252599816147192, 0.48593228651219], 0.02188470118909405, 0.009551731601684384, 0.00020903679194128944
23:27:11 done sampling a new configuration.
23:27:11 HBMASTER: schedule new run for iteration 9
23:27:11 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
23:27:11 HBMASTER: submitting job (9, 0, 0) to dispatcher
23:27:11 DISPATCHER: trying to submit job (9, 0, 0)
23:27:11 DISPATCHER: trying to notify the job_runner thread.
23:27:11 HBMASTER: job (9, 0, 0) submitted to dispatcher
23:27:11 DISPATCHER: Trying to submit another job.
23:27:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:11 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:27:11 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:27:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:11 WORKER: start processing job (9, 0, 0)
23:27:11 WORKER: args: ()
23:27:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011522102548464027, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.06812032810663565, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 45, 'num_filters_3': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:27:40 DISPATCHER: Starting worker discovery
23:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:40 DISPATCHER: Finished worker discovery
23:28:40 DISPATCHER: Starting worker discovery
23:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:40 DISPATCHER: Finished worker discovery
23:29:30 WORKER: done with job (9, 0, 0), trying to register it.
23:29:30 WORKER: registered result for job (9, 0, 0) with dispatcher
23:29:30 DISPATCHER: job (9, 0, 0) finished
23:29:30 DISPATCHER: register_result: lock acquired
23:29:30 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:29:30 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011522102548464027, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.06812032810663565, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 45, 'num_filters_3': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.412516900774672, 'info': {'data02': 0.412516900774672, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011522102548464027, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.06812032810663565, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 45, 'num_filters_3': 85}"}}
exception: None

23:29:30 job_callback for (9, 0, 0) started
23:29:30 job_callback for (9, 0, 0) got condition
23:29:30 DISPATCHER: Trying to submit another job.
23:29:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:29:30 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.740036





23:29:30 HBMASTER: Trying to run another job!
23:29:30 job_callback for (9, 0, 0) finished
23:29:30 start sampling a new configuration.
23:29:30 best_vector: [3, 1, 0.2847343824305433, 0.028908430482838532, 0.9123328036440812, 1, 0.3550901460165101, 0.5244992918058076, 1, 0, 1, 2, 0.48029798031001053, 0.07120850788810357, 0.9601707720393184, 0.4842100228839156], 0.00437412191729888, 0.27550610377760526, 0.0012050972868832429
23:29:30 done sampling a new configuration.
23:29:30 HBMASTER: schedule new run for iteration 9
23:29:30 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
23:29:30 HBMASTER: submitting job (9, 0, 1) to dispatcher
23:29:30 DISPATCHER: trying to submit job (9, 0, 1)
23:29:30 DISPATCHER: trying to notify the job_runner thread.
23:29:30 HBMASTER: job (9, 0, 1) submitted to dispatcher
23:29:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:29:30 DISPATCHER: Trying to submit another job.
23:29:30 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:29:30 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:29:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:29:30 WORKER: start processing job (9, 0, 1)
23:29:30 WORKER: args: ()
23:29:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:29:40 DISPATCHER: Starting worker discovery
23:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:40 DISPATCHER: Finished worker discovery
23:30:40 DISPATCHER: Starting worker discovery
23:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:40 DISPATCHER: Finished worker discovery
23:31:40 DISPATCHER: Starting worker discovery
23:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:40 DISPATCHER: Finished worker discovery
23:31:48 WORKER: done with job (9, 0, 1), trying to register it.
23:31:48 WORKER: registered result for job (9, 0, 1) with dispatcher
23:31:48 DISPATCHER: job (9, 0, 1) finished
23:31:48 DISPATCHER: register_result: lock acquired
23:31:48 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:31:48 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6292122684647308, 'info': {'data02': 0.6292122684647308, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}"}}
exception: None

23:31:48 job_callback for (9, 0, 1) started
23:31:48 DISPATCHER: Trying to submit another job.
23:31:48 job_callback for (9, 0, 1) got condition
23:31:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:48 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.740036





23:31:48 HBMASTER: Trying to run another job!
23:31:48 job_callback for (9, 0, 1) finished
23:31:48 start sampling a new configuration.
23:31:48 best_vector: [1, 0, 0.1439248686859098, 0.746055438752808, 0.42767968365941883, 0, 0.25147446829521203, 0.5841394821909478, 0, 1, 1, 2, 0.5936578792193514, 0.04940440582268757, 0.12404854860039383, 0.48481994678183776], 4.09423078280606e-30, 0.0024424612413143716, -4.886023391530738e-05
23:31:48 done sampling a new configuration.
23:31:48 HBMASTER: schedule new run for iteration 9
23:31:48 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
23:31:48 HBMASTER: submitting job (9, 0, 2) to dispatcher
23:31:48 DISPATCHER: trying to submit job (9, 0, 2)
23:31:48 DISPATCHER: trying to notify the job_runner thread.
23:31:48 HBMASTER: job (9, 0, 2) submitted to dispatcher
23:31:48 DISPATCHER: Trying to submit another job.
23:31:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:48 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:31:48 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:31:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:48 WORKER: start processing job (9, 0, 2)
23:31:48 WORKER: args: ()
23:31:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019402144618187879, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.057541739686468744, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:32:40 DISPATCHER: Starting worker discovery
23:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:40 DISPATCHER: Finished worker discovery
23:33:40 DISPATCHER: Starting worker discovery
23:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:40 DISPATCHER: Finished worker discovery
23:34:07 WORKER: done with job (9, 0, 2), trying to register it.
23:34:07 WORKER: registered result for job (9, 0, 2) with dispatcher
23:34:07 DISPATCHER: job (9, 0, 2) finished
23:34:07 DISPATCHER: register_result: lock acquired
23:34:07 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:34:07 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019402144618187879, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.057541739686468744, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5960893558690058, 'info': {'data02': 0.5960893558690058, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019402144618187879, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.057541739686468744, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 17}"}}
exception: None

23:34:07 job_callback for (9, 0, 2) started
23:34:07 DISPATCHER: Trying to submit another job.
23:34:07 job_callback for (9, 0, 2) got condition
23:34:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:34:07 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.740036





23:34:07 HBMASTER: Trying to run another job!
23:34:07 job_callback for (9, 0, 2) finished
23:34:07 start sampling a new configuration.
23:34:07 done sampling a new configuration.
23:34:07 HBMASTER: schedule new run for iteration 9
23:34:07 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
23:34:07 HBMASTER: submitting job (9, 0, 3) to dispatcher
23:34:07 DISPATCHER: trying to submit job (9, 0, 3)
23:34:07 DISPATCHER: trying to notify the job_runner thread.
23:34:07 HBMASTER: job (9, 0, 3) submitted to dispatcher
23:34:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:34:07 DISPATCHER: Trying to submit another job.
23:34:07 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:34:07 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:34:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:34:07 WORKER: start processing job (9, 0, 3)
23:34:07 WORKER: args: ()
23:34:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.033902631755330634, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.03536300067688619, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 115, 'num_filters_4': 86, 'num_filters_5': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:34:40 DISPATCHER: Starting worker discovery
23:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:40 DISPATCHER: Finished worker discovery
23:35:40 DISPATCHER: Starting worker discovery
23:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:40 DISPATCHER: Finished worker discovery
23:36:25 WORKER: done with job (9, 0, 3), trying to register it.
23:36:25 WORKER: registered result for job (9, 0, 3) with dispatcher
23:36:25 DISPATCHER: job (9, 0, 3) finished
23:36:25 DISPATCHER: register_result: lock acquired
23:36:25 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:36:25 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.033902631755330634, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.03536300067688619, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 115, 'num_filters_4': 86, 'num_filters_5': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data02': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.033902631755330634, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.03536300067688619, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 115, 'num_filters_4': 86, 'num_filters_5': 97}"}}
exception: None

23:36:25 job_callback for (9, 0, 3) started
23:36:25 job_callback for (9, 0, 3) got condition
23:36:25 DISPATCHER: Trying to submit another job.
23:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:36:25 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.740036





23:36:25 HBMASTER: Trying to run another job!
23:36:25 job_callback for (9, 0, 3) finished
23:36:25 start sampling a new configuration.
23:36:25 done sampling a new configuration.
23:36:25 HBMASTER: schedule new run for iteration 9
23:36:25 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
23:36:25 HBMASTER: submitting job (9, 0, 4) to dispatcher
23:36:25 DISPATCHER: trying to submit job (9, 0, 4)
23:36:25 DISPATCHER: trying to notify the job_runner thread.
23:36:25 HBMASTER: job (9, 0, 4) submitted to dispatcher
23:36:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:36:25 DISPATCHER: Trying to submit another job.
23:36:25 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:36:25 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:36:25 WORKER: start processing job (9, 0, 4)
23:36:25 WORKER: args: ()
23:36:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001894970705451231, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.010987631468323465}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:36:40 DISPATCHER: Starting worker discovery
23:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:40 DISPATCHER: Finished worker discovery
23:37:40 DISPATCHER: Starting worker discovery
23:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:40 DISPATCHER: Finished worker discovery
23:38:40 DISPATCHER: Starting worker discovery
23:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:40 DISPATCHER: Finished worker discovery
23:38:43 WORKER: done with job (9, 0, 4), trying to register it.
23:38:43 WORKER: registered result for job (9, 0, 4) with dispatcher
23:38:43 DISPATCHER: job (9, 0, 4) finished
23:38:43 DISPATCHER: register_result: lock acquired
23:38:43 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:38:43 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001894970705451231, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.010987631468323465}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45587940578201946, 'info': {'data02': 0.45587940578201946, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001894970705451231, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.010987631468323465}"}}
exception: None

23:38:43 job_callback for (9, 0, 4) started
23:38:43 DISPATCHER: Trying to submit another job.
23:38:43 job_callback for (9, 0, 4) got condition
23:38:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:43 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.740036





23:38:43 HBMASTER: Trying to run another job!
23:38:43 job_callback for (9, 0, 4) finished
23:38:43 start sampling a new configuration.
23:38:44 best_vector: [0, 1, 0.1598670011925506, 0.6576311303223801, 0.6275799994369817, 0, 0.25991812749301013, 0.6581397329782803, 0, 0, 0, 2, 0.6489869782783424, 0.3330826375777931, 0.22376549335436224, 0.4825685582716238], 0.0001050933984031482, 2.4732548941287757, 0.00025992276194121156
23:38:44 done sampling a new configuration.
23:38:44 HBMASTER: schedule new run for iteration 9
23:38:44 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
23:38:44 HBMASTER: submitting job (9, 0, 5) to dispatcher
23:38:44 DISPATCHER: trying to submit job (9, 0, 5)
23:38:44 DISPATCHER: trying to notify the job_runner thread.
23:38:44 HBMASTER: job (9, 0, 5) submitted to dispatcher
23:38:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:44 DISPATCHER: Trying to submit another job.
23:38:44 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:44 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:38:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:44 WORKER: start processing job (9, 0, 5)
23:38:44 WORKER: args: ()
23:38:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002088016866086197, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.07182233726101771, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 61, 'num_filters_3': 31, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:39:40 DISPATCHER: Starting worker discovery
23:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:40 DISPATCHER: Finished worker discovery
23:40:40 DISPATCHER: Starting worker discovery
23:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:40 DISPATCHER: Finished worker discovery
23:41:02 WORKER: done with job (9, 0, 5), trying to register it.
23:41:02 WORKER: registered result for job (9, 0, 5) with dispatcher
23:41:02 DISPATCHER: job (9, 0, 5) finished
23:41:02 DISPATCHER: register_result: lock acquired
23:41:02 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:41:02 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002088016866086197, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.07182233726101771, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 61, 'num_filters_3': 31, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4454116851521064, 'info': {'data02': 0.4454116851521064, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002088016866086197, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.07182233726101771, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 61, 'num_filters_3': 31, 'num_filters_4': 25}"}}
exception: None

23:41:02 job_callback for (9, 0, 5) started
23:41:02 job_callback for (9, 0, 5) got condition
23:41:02 DISPATCHER: Trying to submit another job.
23:41:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:41:02 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.740036





23:41:02 HBMASTER: Trying to run another job!
23:41:02 job_callback for (9, 0, 5) finished
23:41:02 start sampling a new configuration.
23:41:02 best_vector: [3, 1, 0.17509135573940637, 0.647134444703741, 0.11031089220035561, 1, 0.29650212091201644, 0.2121893228714032, 1, 2, 1, 2, 0.23066457885877595, 0.04420211707246073, 0.14003448795194673, 0.48206864813594413], 0.0004912179091250843, 0.12245189910946973, 6.015056584894949e-05
23:41:02 done sampling a new configuration.
23:41:02 HBMASTER: schedule new run for iteration 9
23:41:02 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
23:41:02 HBMASTER: submitting job (9, 0, 6) to dispatcher
23:41:02 DISPATCHER: trying to submit job (9, 0, 6)
23:41:02 DISPATCHER: trying to notify the job_runner thread.
23:41:02 HBMASTER: job (9, 0, 6) submitted to dispatcher
23:41:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:41:02 DISPATCHER: Trying to submit another job.
23:41:02 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:41:02 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:41:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:41:02 WORKER: start processing job (9, 0, 6)
23:41:02 WORKER: args: ()
23:41:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002239663186239569, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.018882725239696464}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:41:40 DISPATCHER: Starting worker discovery
23:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:40 DISPATCHER: Finished worker discovery
23:42:40 DISPATCHER: Starting worker discovery
23:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:40 DISPATCHER: Finished worker discovery
23:43:26 WORKER: done with job (9, 0, 6), trying to register it.
23:43:26 WORKER: registered result for job (9, 0, 6) with dispatcher
23:43:26 DISPATCHER: job (9, 0, 6) finished
23:43:26 DISPATCHER: register_result: lock acquired
23:43:26 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:43:26 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002239663186239569, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.018882725239696464}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47108230824798136, 'info': {'data02': 0.47108230824798136, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002239663186239569, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.018882725239696464}"}}
exception: None

23:43:26 job_callback for (9, 0, 6) started
23:43:26 DISPATCHER: Trying to submit another job.
23:43:26 job_callback for (9, 0, 6) got condition
23:43:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:43:26 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.740036





23:43:26 HBMASTER: Trying to run another job!
23:43:26 job_callback for (9, 0, 6) finished
23:43:26 start sampling a new configuration.
23:43:26 best_vector: [1, 1, 0.2831571834786957, 0.17273787564132792, 0.3672900491727495, 1, 0.1993053474888699, 0.3369958216827218, 0, 0, 0, 2, 0.8438628016773189, 0.3621723082252587, 0.8193747271940046, 0.4829782391786817], 8.204213053589787e-05, 0.7080137236106003, 5.8086954333667985e-05
23:43:26 done sampling a new configuration.
23:43:26 HBMASTER: schedule new run for iteration 9
23:43:26 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
23:43:26 HBMASTER: submitting job (9, 0, 7) to dispatcher
23:43:26 DISPATCHER: trying to submit job (9, 0, 7)
23:43:26 DISPATCHER: trying to notify the job_runner thread.
23:43:26 HBMASTER: job (9, 0, 7) submitted to dispatcher
23:43:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:43:26 DISPATCHER: Trying to submit another job.
23:43:26 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:43:26 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:43:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:43:26 WORKER: start processing job (9, 0, 7)
23:43:26 WORKER: args: ()
23:43:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0036839554272272016, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.027443637391222842, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:43:40 DISPATCHER: Starting worker discovery
23:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:40 DISPATCHER: Finished worker discovery
23:44:40 DISPATCHER: Starting worker discovery
23:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:40 DISPATCHER: Finished worker discovery
23:45:40 DISPATCHER: Starting worker discovery
23:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:40 DISPATCHER: Finished worker discovery
23:45:46 WORKER: done with job (9, 0, 7), trying to register it.
23:45:46 WORKER: registered result for job (9, 0, 7) with dispatcher
23:45:46 DISPATCHER: job (9, 0, 7) finished
23:45:46 DISPATCHER: register_result: lock acquired
23:45:46 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:45:46 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0036839554272272016, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.027443637391222842, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47424316281514645, 'info': {'data02': 0.47424316281514645, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0036839554272272016, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.027443637391222842, 'kernel_size_2': 3, 'num_filters_2': 92}"}}
exception: None

23:45:46 job_callback for (9, 0, 7) started
23:45:46 DISPATCHER: Trying to submit another job.
23:45:46 job_callback for (9, 0, 7) got condition
23:45:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:45:46 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.740036





23:45:46 HBMASTER: Trying to run another job!
23:45:46 job_callback for (9, 0, 7) finished
23:45:46 start sampling a new configuration.
23:45:46 best_vector: [2, 2, 0.7619978361670209, 0.3669001053049608, 0.31114678614546254, 0, 0.9868624499451994, 0.6323527044421925, 1, 0, 0, 0, 0.13595416232245705, 0.48670615382114113, 0.747090562184137, 0.47814798671050684], 0.0, inf, 0.00019313041937135713
23:45:46 done sampling a new configuration.
23:45:46 HBMASTER: schedule new run for iteration 9
23:45:46 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
23:45:46 HBMASTER: submitting job (9, 0, 8) to dispatcher
23:45:46 DISPATCHER: trying to submit job (9, 0, 8)
23:45:46 DISPATCHER: trying to notify the job_runner thread.
23:45:46 HBMASTER: job (9, 0, 8) submitted to dispatcher
23:45:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:45:46 DISPATCHER: Trying to submit another job.
23:45:46 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:45:46 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:45:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:45:46 WORKER: start processing job (9, 0, 8)
23:45:46 WORKER: args: ()
23:45:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03341917098495812, 'num_filters_1': 34, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.06648288179850678, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:46:40 DISPATCHER: Starting worker discovery
23:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:40 DISPATCHER: Finished worker discovery
23:47:40 DISPATCHER: Starting worker discovery
23:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:40 DISPATCHER: Finished worker discovery
23:48:04 WORKER: done with job (9, 0, 8), trying to register it.
23:48:04 WORKER: registered result for job (9, 0, 8) with dispatcher
23:48:04 DISPATCHER: job (9, 0, 8) finished
23:48:04 DISPATCHER: register_result: lock acquired
23:48:04 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:48:04 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03341917098495812, 'num_filters_1': 34, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.06648288179850678, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31637445281944687, 'info': {'data02': 0.31637445281944687, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03341917098495812, 'num_filters_1': 34, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.06648288179850678, 'kernel_size_2': 5, 'num_filters_2': 21}"}}
exception: None

23:48:04 job_callback for (9, 0, 8) started
23:48:04 DISPATCHER: Trying to submit another job.
23:48:04 job_callback for (9, 0, 8) got condition
23:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:48:04 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.740036





23:48:04 HBMASTER: Trying to run another job!
23:48:04 job_callback for (9, 0, 8) finished
23:48:04 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
23:48:04 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
23:48:04 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
23:48:04 HBMASTER: schedule new run for iteration 9
23:48:04 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
23:48:04 HBMASTER: submitting job (9, 0, 1) to dispatcher
23:48:04 DISPATCHER: trying to submit job (9, 0, 1)
23:48:04 DISPATCHER: trying to notify the job_runner thread.
23:48:04 HBMASTER: job (9, 0, 1) submitted to dispatcher
23:48:04 DISPATCHER: Trying to submit another job.
23:48:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:48:04 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:48:04 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:48:04 WORKER: start processing job (9, 0, 1)
23:48:04 WORKER: args: ()
23:48:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
23:48:40 DISPATCHER: Starting worker discovery
23:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:40 DISPATCHER: Finished worker discovery
23:49:40 DISPATCHER: Starting worker discovery
23:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:40 DISPATCHER: Finished worker discovery
23:50:40 DISPATCHER: Starting worker discovery
23:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:40 DISPATCHER: Finished worker discovery
23:51:40 DISPATCHER: Starting worker discovery
23:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:40 DISPATCHER: Finished worker discovery
23:52:40 DISPATCHER: Starting worker discovery
23:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:40 DISPATCHER: Finished worker discovery
23:53:40 DISPATCHER: Starting worker discovery
23:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:40 DISPATCHER: Finished worker discovery
23:54:40 DISPATCHER: Starting worker discovery
23:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:40 DISPATCHER: Finished worker discovery
23:54:50 WORKER: done with job (9, 0, 1), trying to register it.
23:54:50 WORKER: registered result for job (9, 0, 1) with dispatcher
23:54:50 DISPATCHER: job (9, 0, 1) finished
23:54:50 DISPATCHER: register_result: lock acquired
23:54:50 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
23:54:50 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5698024446946841, 'info': {'data02': 0.5698024446946841, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}"}}
exception: None

23:54:50 job_callback for (9, 0, 1) started
23:54:50 DISPATCHER: Trying to submit another job.
23:54:50 job_callback for (9, 0, 1) got condition
23:54:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:50 HBMASTER: Trying to run another job!
23:54:50 job_callback for (9, 0, 1) finished
23:54:50 HBMASTER: schedule new run for iteration 9
23:54:50 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
23:54:50 HBMASTER: submitting job (9, 0, 2) to dispatcher
23:54:50 DISPATCHER: trying to submit job (9, 0, 2)
23:54:50 DISPATCHER: trying to notify the job_runner thread.
23:54:50 HBMASTER: job (9, 0, 2) submitted to dispatcher
23:54:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:50 DISPATCHER: Trying to submit another job.
23:54:50 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272
23:54:50 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
23:54:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:50 WORKER: start processing job (9, 0, 2)
23:54:50 WORKER: args: ()
23:54:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019402144618187879, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.057541739686468744, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 17}, 'budget': 400.0, 'working_directory': '.'}
23:55:40 DISPATCHER: Starting worker discovery
23:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:40 DISPATCHER: Finished worker discovery
23:56:40 DISPATCHER: Starting worker discovery
23:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:40 DISPATCHER: Finished worker discovery
23:57:40 DISPATCHER: Starting worker discovery
23:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:40 DISPATCHER: Finished worker discovery
23:58:40 DISPATCHER: Starting worker discovery
23:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:40 DISPATCHER: Finished worker discovery
23:59:40 DISPATCHER: Starting worker discovery
23:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:40 DISPATCHER: Finished worker discovery
00:00:40 DISPATCHER: Starting worker discovery
00:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:40 DISPATCHER: Finished worker discovery
00:01:38 WORKER: done with job (9, 0, 2), trying to register it.
00:01:38 WORKER: registered result for job (9, 0, 2) with dispatcher
00:01:38 DISPATCHER: job (9, 0, 2) finished
00:01:38 DISPATCHER: register_result: lock acquired
00:01:38 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:01:38 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019402144618187879, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.057541739686468744, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.46691618102704896, 'info': {'data02': 0.46691618102704896, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019402144618187879, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.057541739686468744, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 17}"}}
exception: None

00:01:38 job_callback for (9, 0, 2) started
00:01:38 job_callback for (9, 0, 2) got condition
00:01:38 DISPATCHER: Trying to submit another job.
00:01:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:38 HBMASTER: Trying to run another job!
00:01:38 job_callback for (9, 0, 2) finished
00:01:38 HBMASTER: schedule new run for iteration 9
00:01:38 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:01:38 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:01:38 DISPATCHER: trying to submit job (9, 0, 7)
00:01:38 DISPATCHER: trying to notify the job_runner thread.
00:01:38 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:01:38 DISPATCHER: Trying to submit another job.
00:01:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:38 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:01:38 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:01:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:38 WORKER: start processing job (9, 0, 7)
00:01:38 WORKER: args: ()
00:01:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0036839554272272016, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.027443637391222842, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 400.0, 'working_directory': '.'}
00:01:40 DISPATCHER: Starting worker discovery
00:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:40 DISPATCHER: Finished worker discovery
00:02:40 DISPATCHER: Starting worker discovery
00:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:41 DISPATCHER: Finished worker discovery
00:03:41 DISPATCHER: Starting worker discovery
00:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:41 DISPATCHER: Finished worker discovery
00:04:41 DISPATCHER: Starting worker discovery
00:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:41 DISPATCHER: Finished worker discovery
00:05:41 DISPATCHER: Starting worker discovery
00:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:41 DISPATCHER: Finished worker discovery
00:06:41 DISPATCHER: Starting worker discovery
00:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:41 DISPATCHER: Finished worker discovery
00:07:41 DISPATCHER: Starting worker discovery
00:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:41 DISPATCHER: Finished worker discovery
00:08:27 WORKER: done with job (9, 0, 7), trying to register it.
00:08:27 WORKER: registered result for job (9, 0, 7) with dispatcher
00:08:27 DISPATCHER: job (9, 0, 7) finished
00:08:27 DISPATCHER: register_result: lock acquired
00:08:27 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:08:27 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0036839554272272016, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.027443637391222842, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4948328577185275, 'info': {'data02': 0.4948328577185275, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0036839554272272016, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.027443637391222842, 'kernel_size_2': 3, 'num_filters_2': 92}"}}
exception: None

00:08:27 job_callback for (9, 0, 7) started
00:08:27 job_callback for (9, 0, 7) got condition
00:08:27 DISPATCHER: Trying to submit another job.
00:08:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:08:27 HBMASTER: Trying to run another job!
00:08:27 job_callback for (9, 0, 7) finished
00:08:27 ITERATION: Advancing config (9, 0, 1) to next budget 1200.000000
00:08:27 HBMASTER: schedule new run for iteration 9
00:08:27 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
00:08:27 HBMASTER: submitting job (9, 0, 1) to dispatcher
00:08:27 DISPATCHER: trying to submit job (9, 0, 1)
00:08:27 DISPATCHER: trying to notify the job_runner thread.
00:08:27 HBMASTER: job (9, 0, 1) submitted to dispatcher
00:08:27 DISPATCHER: Trying to submit another job.
00:08:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:08:27 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272
00:08:27 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1575140037953214272
00:08:27 WORKER: start processing job (9, 0, 1)
00:08:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:08:27 WORKER: args: ()
00:08:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}, 'budget': 1200.0, 'working_directory': '.'}
00:08:41 DISPATCHER: Starting worker discovery
00:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:41 DISPATCHER: Finished worker discovery
00:09:41 DISPATCHER: Starting worker discovery
00:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:41 DISPATCHER: Finished worker discovery
00:10:41 DISPATCHER: Starting worker discovery
00:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:41 DISPATCHER: Finished worker discovery
00:11:41 DISPATCHER: Starting worker discovery
00:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:41 DISPATCHER: Finished worker discovery
00:12:41 DISPATCHER: Starting worker discovery
00:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:41 DISPATCHER: Finished worker discovery
00:13:41 DISPATCHER: Starting worker discovery
00:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:41 DISPATCHER: Finished worker discovery
00:14:41 DISPATCHER: Starting worker discovery
00:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:41 DISPATCHER: Finished worker discovery
00:15:41 DISPATCHER: Starting worker discovery
00:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:41 DISPATCHER: Finished worker discovery
00:16:41 DISPATCHER: Starting worker discovery
00:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:41 DISPATCHER: Finished worker discovery
00:17:41 DISPATCHER: Starting worker discovery
00:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:41 DISPATCHER: Finished worker discovery
00:18:41 DISPATCHER: Starting worker discovery
00:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:41 DISPATCHER: Finished worker discovery
00:19:41 DISPATCHER: Starting worker discovery
00:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:41 DISPATCHER: Finished worker discovery
00:20:41 DISPATCHER: Starting worker discovery
00:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:41 DISPATCHER: Finished worker discovery
00:21:41 DISPATCHER: Starting worker discovery
00:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:41 DISPATCHER: Finished worker discovery
00:22:41 DISPATCHER: Starting worker discovery
00:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:41 DISPATCHER: Finished worker discovery
00:23:41 DISPATCHER: Starting worker discovery
00:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:41 DISPATCHER: Finished worker discovery
00:24:41 DISPATCHER: Starting worker discovery
00:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:41 DISPATCHER: Finished worker discovery
00:25:41 DISPATCHER: Starting worker discovery
00:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:41 DISPATCHER: Finished worker discovery
00:26:41 DISPATCHER: Starting worker discovery
00:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:41 DISPATCHER: Finished worker discovery
00:27:41 DISPATCHER: Starting worker discovery
00:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:41 DISPATCHER: Finished worker discovery
00:28:37 WORKER: done with job (9, 0, 1), trying to register it.
00:28:37 WORKER: registered result for job (9, 0, 1) with dispatcher
00:28:37 DISPATCHER: job (9, 0, 1) finished
00:28:37 DISPATCHER: register_result: lock acquired
00:28:37 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1575140037953214272 finished
00:28:37 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5276411508946961, 'info': {'data02': 0.5276411508946961, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0037108103980394184, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04812705769116589, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 18, 'num_filters_4': 118, 'num_filters_5': 43}"}}
exception: None

00:28:37 job_callback for (9, 0, 1) started
00:28:37 DISPATCHER: Trying to submit another job.
00:28:37 job_callback for (9, 0, 1) got condition
00:28:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:37 HBMASTER: Trying to run another job!
00:28:37 job_callback for (9, 0, 1) finished
00:28:37 HBMASTER: shutdown initiated, shutdown_workers = True
00:28:37 WORKER: shutting down now!
00:28:38 DISPATCHER: Dispatcher shutting down
00:28:38 DISPATCHER: discover_workers shutting down
00:28:38 DISPATCHER: Trying to submit another job.
00:28:38 DISPATCHER: 'discover_worker' thread exited
00:28:38 DISPATCHER: job_runner shutting down
00:28:38 DISPATCHER: 'job_runner' thread exited
00:28:38 DISPATCHER: shut down complete
