/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 20:48:37.594487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 20:48:37.598053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299865000 Hz
2020-03-09 20:48:37.598535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cf89452e10 executing computations on platform Host. Devices:
2020-03-09 20:48:37.598576: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 20:48:37.599409: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

20:48:37 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f7d4bf89630; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:34276>
20:48:37 WORKER: No dispatcher found. Waiting for one to initiate contact.
20:48:37 WORKER: start listening for jobs
20:48:37 wait_for_workers trying to get the condition
20:48:37 DISPATCHER: started the 'discover_worker' thread
20:48:37 DISPATCHER: started the 'job_runner' thread
20:48:37 DISPATCHER: Pyro daemon running on localhost:46593
20:48:37 HBMASTER: only 0 worker(s) available, waiting for at least 1.
20:48:37 DISPATCHER: Starting worker discovery
20:48:37 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
20:48:37 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.29881140179544557376
20:48:37 HBMASTER: number of workers changed to 1
20:48:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:37 adjust_queue_size: lock accquired
20:48:37 HBMASTER: adjusted queue size to (0, 1)
20:48:37 DISPATCHER: Finished worker discovery
20:48:37 DISPATCHER: Trying to submit another job.
20:48:37 DISPATCHER: A new worker triggered discover_worker
20:48:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:37 Enough workers to start this run!
20:48:37 DISPATCHER: Starting worker discovery
20:48:37 HBMASTER: starting run at 1583783317.6958728
20:48:37 start sampling a new configuration.
20:48:37 done sampling a new configuration.
20:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:37 HBMASTER: schedule new run for iteration 0
20:48:37 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
20:48:37 HBMASTER: submitting job (0, 0, 0) to dispatcher
20:48:37 DISPATCHER: trying to submit job (0, 0, 0)
20:48:37 DISPATCHER: Finished worker discovery
20:48:37 DISPATCHER: trying to notify the job_runner thread.
20:48:37 HBMASTER: job (0, 0, 0) submitted to dispatcher
20:48:37 DISPATCHER: Trying to submit another job.
20:48:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:48:37 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:48:37 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:48:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:48:37 WORKER: start processing job (0, 0, 0)
20:48:37 WORKER: args: ()
20:48:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 577, 'last_n_outputs': 14, 'leak_rate': 0.7804913922751098, 'lr': 0.08306456339055034, 'optimizer': 'Adam', 'sparsity': 0.8675618143466441, 'steps_to_train': 35, 'weight_decay': 0.015936518932421997}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:49:37 DISPATCHER: Starting worker discovery
20:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:37 DISPATCHER: Finished worker discovery
20:49:55 WORKER: done with job (0, 0, 0), trying to register it.
20:49:55 WORKER: registered result for job (0, 0, 0) with dispatcher
20:49:55 DISPATCHER: job (0, 0, 0) finished
20:49:55 DISPATCHER: register_result: lock acquired
20:49:55 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:49:55 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 577, 'last_n_outputs': 14, 'leak_rate': 0.7804913922751098, 'lr': 0.08306456339055034, 'optimizer': 'Adam', 'sparsity': 0.8675618143466441, 'steps_to_train': 35, 'weight_decay': 0.015936518932421997}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.343001619166502, 'info': {'number_mnist': 0.343001619166502, 'config': "{'batch_size': 64, 'hidden_dim': 577, 'last_n_outputs': 14, 'leak_rate': 0.7804913922751098, 'lr': 0.08306456339055034, 'optimizer': 'Adam', 'sparsity': 0.8675618143466441, 'steps_to_train': 35, 'weight_decay': 0.015936518932421997}"}}
exception: None

20:49:55 job_callback for (0, 0, 0) started
20:49:55 DISPATCHER: Trying to submit another job.
20:49:55 job_callback for (0, 0, 0) got condition
20:49:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:49:56 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:49:56 HBMASTER: Trying to run another job!
20:49:56 job_callback for (0, 0, 0) finished
20:49:56 start sampling a new configuration.
20:49:56 done sampling a new configuration.
20:49:57 HBMASTER: schedule new run for iteration 0
20:49:57 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
20:49:57 HBMASTER: submitting job (0, 0, 1) to dispatcher
20:49:57 DISPATCHER: trying to submit job (0, 0, 1)
20:49:57 DISPATCHER: trying to notify the job_runner thread.
20:49:57 HBMASTER: job (0, 0, 1) submitted to dispatcher
20:49:57 DISPATCHER: Trying to submit another job.
20:49:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:49:57 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:49:57 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:49:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:49:57 WORKER: start processing job (0, 0, 1)
20:49:57 WORKER: args: ()
20:49:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:50:37 DISPATCHER: Starting worker discovery
20:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:37 DISPATCHER: Finished worker discovery
20:50:53 WORKER: done with job (0, 0, 1), trying to register it.
20:50:53 WORKER: registered result for job (0, 0, 1) with dispatcher
20:50:53 DISPATCHER: job (0, 0, 1) finished
20:50:53 DISPATCHER: register_result: lock acquired
20:50:53 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:50:53 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9125890594882793, 'info': {'number_mnist': 0.9125890594882793, 'config': "{'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}"}}
exception: None

20:50:53 job_callback for (0, 0, 1) started
20:50:53 DISPATCHER: Trying to submit another job.
20:50:53 job_callback for (0, 0, 1) got condition
20:50:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:50:53 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:50:53 HBMASTER: Trying to run another job!
20:50:53 job_callback for (0, 0, 1) finished
20:50:53 start sampling a new configuration.
20:50:53 done sampling a new configuration.
20:50:53 HBMASTER: schedule new run for iteration 0
20:50:53 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
20:50:53 HBMASTER: submitting job (0, 0, 2) to dispatcher
20:50:53 DISPATCHER: trying to submit job (0, 0, 2)
20:50:53 DISPATCHER: trying to notify the job_runner thread.
20:50:53 HBMASTER: job (0, 0, 2) submitted to dispatcher
20:50:53 DISPATCHER: Trying to submit another job.
20:50:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:50:53 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:50:53 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:50:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:50:53 WORKER: start processing job (0, 0, 2)
20:50:53 WORKER: args: ()
20:50:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 715, 'last_n_outputs': 34, 'leak_rate': 0.8790252577224074, 'lr': 0.08458222442414558, 'optimizer': 'Adam', 'sparsity': 0.7790681082435935, 'steps_to_train': 12, 'weight_decay': 0.025302916990375433}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:51:37 DISPATCHER: Starting worker discovery
20:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:37 DISPATCHER: Finished worker discovery
20:51:48 WORKER: done with job (0, 0, 2), trying to register it.
20:51:48 WORKER: registered result for job (0, 0, 2) with dispatcher
20:51:48 DISPATCHER: job (0, 0, 2) finished
20:51:48 DISPATCHER: register_result: lock acquired
20:51:48 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:51:48 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 715, 'last_n_outputs': 34, 'leak_rate': 0.8790252577224074, 'lr': 0.08458222442414558, 'optimizer': 'Adam', 'sparsity': 0.7790681082435935, 'steps_to_train': 12, 'weight_decay': 0.025302916990375433}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11335082508042417, 'info': {'number_mnist': 0.11335082508042417, 'config': "{'batch_size': 128, 'hidden_dim': 715, 'last_n_outputs': 34, 'leak_rate': 0.8790252577224074, 'lr': 0.08458222442414558, 'optimizer': 'Adam', 'sparsity': 0.7790681082435935, 'steps_to_train': 12, 'weight_decay': 0.025302916990375433}"}}
exception: None

20:51:48 job_callback for (0, 0, 2) started
20:51:48 job_callback for (0, 0, 2) got condition
20:51:48 DISPATCHER: Trying to submit another job.
20:51:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:51:48 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:51:48 HBMASTER: Trying to run another job!
20:51:48 job_callback for (0, 0, 2) finished
20:51:48 start sampling a new configuration.
20:51:48 done sampling a new configuration.
20:51:48 HBMASTER: schedule new run for iteration 0
20:51:48 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
20:51:48 HBMASTER: submitting job (0, 0, 3) to dispatcher
20:51:48 DISPATCHER: trying to submit job (0, 0, 3)
20:51:48 DISPATCHER: trying to notify the job_runner thread.
20:51:48 HBMASTER: job (0, 0, 3) submitted to dispatcher
20:51:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:51:48 DISPATCHER: Trying to submit another job.
20:51:48 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:51:48 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:51:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:51:48 WORKER: start processing job (0, 0, 3)
20:51:48 WORKER: args: ()
20:51:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 671, 'last_n_outputs': 49, 'leak_rate': 0.8977503808197919, 'lr': 0.06590583996487392, 'optimizer': 'Adam', 'sparsity': 0.8922657804778666, 'steps_to_train': 93, 'weight_decay': 0.03072891754052366}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:52:37 DISPATCHER: Starting worker discovery
20:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:37 DISPATCHER: Finished worker discovery
20:52:42 WORKER: done with job (0, 0, 3), trying to register it.
20:52:42 WORKER: registered result for job (0, 0, 3) with dispatcher
20:52:42 DISPATCHER: job (0, 0, 3) finished
20:52:42 DISPATCHER: register_result: lock acquired
20:52:42 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:52:42 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 671, 'last_n_outputs': 49, 'leak_rate': 0.8977503808197919, 'lr': 0.06590583996487392, 'optimizer': 'Adam', 'sparsity': 0.8922657804778666, 'steps_to_train': 93, 'weight_decay': 0.03072891754052366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31185988504713297, 'info': {'number_mnist': 0.31185988504713297, 'config': "{'batch_size': 128, 'hidden_dim': 671, 'last_n_outputs': 49, 'leak_rate': 0.8977503808197919, 'lr': 0.06590583996487392, 'optimizer': 'Adam', 'sparsity': 0.8922657804778666, 'steps_to_train': 93, 'weight_decay': 0.03072891754052366}"}}
exception: None

20:52:42 job_callback for (0, 0, 3) started
20:52:42 job_callback for (0, 0, 3) got condition
20:52:42 DISPATCHER: Trying to submit another job.
20:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:52:42 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:52:42 HBMASTER: Trying to run another job!
20:52:42 job_callback for (0, 0, 3) finished
20:52:42 start sampling a new configuration.
20:52:42 done sampling a new configuration.
20:52:42 HBMASTER: schedule new run for iteration 0
20:52:42 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
20:52:42 HBMASTER: submitting job (0, 0, 4) to dispatcher
20:52:42 DISPATCHER: trying to submit job (0, 0, 4)
20:52:42 DISPATCHER: trying to notify the job_runner thread.
20:52:42 HBMASTER: job (0, 0, 4) submitted to dispatcher
20:52:42 DISPATCHER: Trying to submit another job.
20:52:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:52:42 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:52:42 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:52:42 WORKER: start processing job (0, 0, 4)
20:52:42 WORKER: args: ()
20:52:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 350, 'last_n_outputs': 47, 'leak_rate': 0.8072517072235376, 'lr': 0.018201574983051437, 'optimizer': 'Adam', 'sparsity': 0.7783470713489001, 'steps_to_train': 90, 'weight_decay': 0.02815439505341807}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:53:37 WORKER: done with job (0, 0, 4), trying to register it.
20:53:37 WORKER: registered result for job (0, 0, 4) with dispatcher
20:53:37 DISPATCHER: job (0, 0, 4) finished
20:53:37 DISPATCHER: register_result: lock acquired
20:53:37 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:53:37 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 350, 'last_n_outputs': 47, 'leak_rate': 0.8072517072235376, 'lr': 0.018201574983051437, 'optimizer': 'Adam', 'sparsity': 0.7783470713489001, 'steps_to_train': 90, 'weight_decay': 0.02815439505341807}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4643873441892903, 'info': {'number_mnist': 0.4643873441892903, 'config': "{'batch_size': 64, 'hidden_dim': 350, 'last_n_outputs': 47, 'leak_rate': 0.8072517072235376, 'lr': 0.018201574983051437, 'optimizer': 'Adam', 'sparsity': 0.7783470713489001, 'steps_to_train': 90, 'weight_decay': 0.02815439505341807}"}}
exception: None

20:53:37 job_callback for (0, 0, 4) started
20:53:37 job_callback for (0, 0, 4) got condition
20:53:37 DISPATCHER: Trying to submit another job.
20:53:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:53:37 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:53:37 HBMASTER: Trying to run another job!
20:53:37 job_callback for (0, 0, 4) finished
20:53:37 start sampling a new configuration.
20:53:37 done sampling a new configuration.
20:53:37 HBMASTER: schedule new run for iteration 0
20:53:37 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
20:53:37 HBMASTER: submitting job (0, 0, 5) to dispatcher
20:53:37 DISPATCHER: trying to submit job (0, 0, 5)
20:53:37 DISPATCHER: trying to notify the job_runner thread.
20:53:37 HBMASTER: job (0, 0, 5) submitted to dispatcher
20:53:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:53:37 DISPATCHER: Trying to submit another job.
20:53:37 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:53:37 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:53:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:53:37 WORKER: start processing job (0, 0, 5)
20:53:37 WORKER: args: ()
20:53:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 374, 'last_n_outputs': 35, 'leak_rate': 0.7966197654549849, 'lr': 0.025135809416683596, 'optimizer': 'SGD', 'sparsity': 0.8756642178952916, 'steps_to_train': 40, 'weight_decay': 0.18023387258406645}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:53:37 DISPATCHER: Starting worker discovery
20:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:37 DISPATCHER: Finished worker discovery
20:54:30 WORKER: done with job (0, 0, 5), trying to register it.
20:54:30 WORKER: registered result for job (0, 0, 5) with dispatcher
20:54:30 DISPATCHER: job (0, 0, 5) finished
20:54:30 DISPATCHER: register_result: lock acquired
20:54:30 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:54:30 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 374, 'last_n_outputs': 35, 'leak_rate': 0.7966197654549849, 'lr': 0.025135809416683596, 'optimizer': 'SGD', 'sparsity': 0.8756642178952916, 'steps_to_train': 40, 'weight_decay': 0.18023387258406645}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8435415573674944, 'info': {'number_mnist': 0.8435415573674944, 'config': "{'batch_size': 64, 'hidden_dim': 374, 'last_n_outputs': 35, 'leak_rate': 0.7966197654549849, 'lr': 0.025135809416683596, 'optimizer': 'SGD', 'sparsity': 0.8756642178952916, 'steps_to_train': 40, 'weight_decay': 0.18023387258406645}"}}
exception: None

20:54:30 job_callback for (0, 0, 5) started
20:54:30 job_callback for (0, 0, 5) got condition
20:54:30 DISPATCHER: Trying to submit another job.
20:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:54:30 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:54:30 HBMASTER: Trying to run another job!
20:54:30 job_callback for (0, 0, 5) finished
20:54:30 start sampling a new configuration.
20:54:30 done sampling a new configuration.
20:54:30 HBMASTER: schedule new run for iteration 0
20:54:30 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
20:54:30 HBMASTER: submitting job (0, 0, 6) to dispatcher
20:54:30 DISPATCHER: trying to submit job (0, 0, 6)
20:54:30 DISPATCHER: trying to notify the job_runner thread.
20:54:30 HBMASTER: job (0, 0, 6) submitted to dispatcher
20:54:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:54:30 DISPATCHER: Trying to submit another job.
20:54:30 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:54:30 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:54:30 WORKER: start processing job (0, 0, 6)
20:54:30 WORKER: args: ()
20:54:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 284, 'last_n_outputs': 10, 'leak_rate': 0.7562712002614024, 'lr': 0.0018107491065908036, 'optimizer': 'SGD', 'sparsity': 0.975489620421363, 'steps_to_train': 72, 'weight_decay': 0.14209676741365374}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:54:37 DISPATCHER: Starting worker discovery
20:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:37 DISPATCHER: Finished worker discovery
20:55:24 WORKER: done with job (0, 0, 6), trying to register it.
20:55:24 WORKER: registered result for job (0, 0, 6) with dispatcher
20:55:24 DISPATCHER: job (0, 0, 6) finished
20:55:24 DISPATCHER: register_result: lock acquired
20:55:24 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:55:24 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 284, 'last_n_outputs': 10, 'leak_rate': 0.7562712002614024, 'lr': 0.0018107491065908036, 'optimizer': 'SGD', 'sparsity': 0.975489620421363, 'steps_to_train': 72, 'weight_decay': 0.14209676741365374}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5443487372836653, 'info': {'number_mnist': 0.5443487372836653, 'config': "{'batch_size': 64, 'hidden_dim': 284, 'last_n_outputs': 10, 'leak_rate': 0.7562712002614024, 'lr': 0.0018107491065908036, 'optimizer': 'SGD', 'sparsity': 0.975489620421363, 'steps_to_train': 72, 'weight_decay': 0.14209676741365374}"}}
exception: None

20:55:24 job_callback for (0, 0, 6) started
20:55:24 job_callback for (0, 0, 6) got condition
20:55:24 DISPATCHER: Trying to submit another job.
20:55:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:24 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:55:24 HBMASTER: Trying to run another job!
20:55:24 job_callback for (0, 0, 6) finished
20:55:24 start sampling a new configuration.
20:55:24 done sampling a new configuration.
20:55:24 HBMASTER: schedule new run for iteration 0
20:55:24 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
20:55:24 HBMASTER: submitting job (0, 0, 7) to dispatcher
20:55:24 DISPATCHER: trying to submit job (0, 0, 7)
20:55:24 DISPATCHER: trying to notify the job_runner thread.
20:55:24 HBMASTER: job (0, 0, 7) submitted to dispatcher
20:55:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:24 DISPATCHER: Trying to submit another job.
20:55:24 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:55:24 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:55:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:24 WORKER: start processing job (0, 0, 7)
20:55:24 WORKER: args: ()
20:55:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 848, 'last_n_outputs': 32, 'leak_rate': 0.7553226383871563, 'lr': 0.05818672147939375, 'optimizer': 'Adam', 'sparsity': 0.8300019728898974, 'steps_to_train': 96, 'weight_decay': 0.04864104192374895}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:55:37 DISPATCHER: Starting worker discovery
20:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:37 DISPATCHER: Finished worker discovery
20:56:17 WORKER: done with job (0, 0, 7), trying to register it.
20:56:17 WORKER: registered result for job (0, 0, 7) with dispatcher
20:56:17 DISPATCHER: job (0, 0, 7) finished
20:56:17 DISPATCHER: register_result: lock acquired
20:56:17 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:56:17 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 848, 'last_n_outputs': 32, 'leak_rate': 0.7553226383871563, 'lr': 0.05818672147939375, 'optimizer': 'Adam', 'sparsity': 0.8300019728898974, 'steps_to_train': 96, 'weight_decay': 0.04864104192374895}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23884392683244676, 'info': {'number_mnist': 0.23884392683244676, 'config': "{'batch_size': 64, 'hidden_dim': 848, 'last_n_outputs': 32, 'leak_rate': 0.7553226383871563, 'lr': 0.05818672147939375, 'optimizer': 'Adam', 'sparsity': 0.8300019728898974, 'steps_to_train': 96, 'weight_decay': 0.04864104192374895}"}}
exception: None

20:56:17 job_callback for (0, 0, 7) started
20:56:17 DISPATCHER: Trying to submit another job.
20:56:17 job_callback for (0, 0, 7) got condition
20:56:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:56:17 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:56:17 HBMASTER: Trying to run another job!
20:56:17 job_callback for (0, 0, 7) finished
20:56:17 start sampling a new configuration.
20:56:17 done sampling a new configuration.
20:56:17 HBMASTER: schedule new run for iteration 0
20:56:17 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
20:56:17 HBMASTER: submitting job (0, 0, 8) to dispatcher
20:56:17 DISPATCHER: trying to submit job (0, 0, 8)
20:56:17 DISPATCHER: trying to notify the job_runner thread.
20:56:17 HBMASTER: job (0, 0, 8) submitted to dispatcher
20:56:17 DISPATCHER: Trying to submit another job.
20:56:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:56:17 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:56:17 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:56:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:56:17 WORKER: start processing job (0, 0, 8)
20:56:17 WORKER: args: ()
20:56:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 732, 'last_n_outputs': 13, 'leak_rate': 0.9403700638641588, 'lr': 0.004153137600636875, 'optimizer': 'SGD', 'sparsity': 0.9201881340288672, 'steps_to_train': 67, 'weight_decay': 0.11491393642004158}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:56:37 DISPATCHER: Starting worker discovery
20:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:37 DISPATCHER: Finished worker discovery
20:57:11 WORKER: done with job (0, 0, 8), trying to register it.
20:57:11 WORKER: registered result for job (0, 0, 8) with dispatcher
20:57:11 DISPATCHER: job (0, 0, 8) finished
20:57:11 DISPATCHER: register_result: lock acquired
20:57:11 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:57:11 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 732, 'last_n_outputs': 13, 'leak_rate': 0.9403700638641588, 'lr': 0.004153137600636875, 'optimizer': 'SGD', 'sparsity': 0.9201881340288672, 'steps_to_train': 67, 'weight_decay': 0.11491393642004158}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8668149560740354, 'info': {'number_mnist': 0.8668149560740354, 'config': "{'batch_size': 32, 'hidden_dim': 732, 'last_n_outputs': 13, 'leak_rate': 0.9403700638641588, 'lr': 0.004153137600636875, 'optimizer': 'SGD', 'sparsity': 0.9201881340288672, 'steps_to_train': 67, 'weight_decay': 0.11491393642004158}"}}
exception: None

20:57:11 job_callback for (0, 0, 8) started
20:57:11 DISPATCHER: Trying to submit another job.
20:57:11 job_callback for (0, 0, 8) got condition
20:57:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:57:11 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
20:57:11 HBMASTER: Trying to run another job!
20:57:11 job_callback for (0, 0, 8) finished
20:57:11 start sampling a new configuration.
20:57:11 done sampling a new configuration.
20:57:11 HBMASTER: schedule new run for iteration 0
20:57:11 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
20:57:11 HBMASTER: submitting job (0, 0, 9) to dispatcher
20:57:11 DISPATCHER: trying to submit job (0, 0, 9)
20:57:11 DISPATCHER: trying to notify the job_runner thread.
20:57:11 HBMASTER: job (0, 0, 9) submitted to dispatcher
20:57:11 DISPATCHER: Trying to submit another job.
20:57:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:57:11 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:57:11 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:57:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:57:11 WORKER: start processing job (0, 0, 9)
20:57:11 WORKER: args: ()
20:57:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 690, 'last_n_outputs': 45, 'leak_rate': 0.7948707052175613, 'lr': 0.004592511679241032, 'optimizer': 'Adam', 'sparsity': 0.7796630217377735, 'steps_to_train': 62, 'weight_decay': 0.036293216096305064}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:57:37 DISPATCHER: Starting worker discovery
20:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:37 DISPATCHER: Finished worker discovery
20:58:06 WORKER: done with job (0, 0, 9), trying to register it.
20:58:06 WORKER: registered result for job (0, 0, 9) with dispatcher
20:58:06 DISPATCHER: job (0, 0, 9) finished
20:58:06 DISPATCHER: register_result: lock acquired
20:58:06 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:58:06 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 690, 'last_n_outputs': 45, 'leak_rate': 0.7948707052175613, 'lr': 0.004592511679241032, 'optimizer': 'Adam', 'sparsity': 0.7796630217377735, 'steps_to_train': 62, 'weight_decay': 0.036293216096305064}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5897458354508403, 'info': {'number_mnist': 0.5897458354508403, 'config': "{'batch_size': 64, 'hidden_dim': 690, 'last_n_outputs': 45, 'leak_rate': 0.7948707052175613, 'lr': 0.004592511679241032, 'optimizer': 'Adam', 'sparsity': 0.7796630217377735, 'steps_to_train': 62, 'weight_decay': 0.036293216096305064}"}}
exception: None

20:58:06 job_callback for (0, 0, 9) started
20:58:06 DISPATCHER: Trying to submit another job.
20:58:06 job_callback for (0, 0, 9) got condition
20:58:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:06 HBMASTER: Trying to run another job!
20:58:06 job_callback for (0, 0, 9) finished
20:58:06 start sampling a new configuration.
20:58:06 done sampling a new configuration.
20:58:06 HBMASTER: schedule new run for iteration 0
20:58:06 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
20:58:06 HBMASTER: submitting job (0, 0, 10) to dispatcher
20:58:06 DISPATCHER: trying to submit job (0, 0, 10)
20:58:06 DISPATCHER: trying to notify the job_runner thread.
20:58:06 HBMASTER: job (0, 0, 10) submitted to dispatcher
20:58:06 DISPATCHER: Trying to submit another job.
20:58:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:06 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:58:06 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:58:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:06 WORKER: start processing job (0, 0, 10)
20:58:06 WORKER: args: ()
20:58:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 602, 'last_n_outputs': 10, 'leak_rate': 0.9298669756405626, 'lr': 0.0105642547951847, 'optimizer': 'Adam', 'sparsity': 0.9681791749485669, 'steps_to_train': 61, 'weight_decay': 0.050163302057484635}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:58:37 DISPATCHER: Starting worker discovery
20:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:37 DISPATCHER: Finished worker discovery
20:59:00 WORKER: done with job (0, 0, 10), trying to register it.
20:59:00 WORKER: registered result for job (0, 0, 10) with dispatcher
20:59:00 DISPATCHER: job (0, 0, 10) finished
20:59:00 DISPATCHER: register_result: lock acquired
20:59:00 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:59:00 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 602, 'last_n_outputs': 10, 'leak_rate': 0.9298669756405626, 'lr': 0.0105642547951847, 'optimizer': 'Adam', 'sparsity': 0.9681791749485669, 'steps_to_train': 61, 'weight_decay': 0.050163302057484635}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46232927703295634, 'info': {'number_mnist': 0.46232927703295634, 'config': "{'batch_size': 128, 'hidden_dim': 602, 'last_n_outputs': 10, 'leak_rate': 0.9298669756405626, 'lr': 0.0105642547951847, 'optimizer': 'Adam', 'sparsity': 0.9681791749485669, 'steps_to_train': 61, 'weight_decay': 0.050163302057484635}"}}
exception: None

20:59:00 job_callback for (0, 0, 10) started
20:59:00 DISPATCHER: Trying to submit another job.
20:59:00 job_callback for (0, 0, 10) got condition
20:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:59:00 HBMASTER: Trying to run another job!
20:59:00 job_callback for (0, 0, 10) finished
20:59:00 start sampling a new configuration.
20:59:00 done sampling a new configuration.
20:59:00 HBMASTER: schedule new run for iteration 0
20:59:00 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
20:59:00 HBMASTER: submitting job (0, 0, 11) to dispatcher
20:59:00 DISPATCHER: trying to submit job (0, 0, 11)
20:59:00 DISPATCHER: trying to notify the job_runner thread.
20:59:00 HBMASTER: job (0, 0, 11) submitted to dispatcher
20:59:00 DISPATCHER: Trying to submit another job.
20:59:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:59:00 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:59:00 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:59:00 WORKER: start processing job (0, 0, 11)
20:59:00 WORKER: args: ()
20:59:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 877, 'last_n_outputs': 31, 'leak_rate': 0.8688718785005763, 'lr': 0.03521498245448867, 'optimizer': 'Adam', 'sparsity': 0.9852970600047973, 'steps_to_train': 28, 'weight_decay': 0.010415466598024494}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:59:37 DISPATCHER: Starting worker discovery
20:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:37 DISPATCHER: Finished worker discovery
20:59:54 WORKER: done with job (0, 0, 11), trying to register it.
20:59:54 WORKER: registered result for job (0, 0, 11) with dispatcher
20:59:54 DISPATCHER: job (0, 0, 11) finished
20:59:54 DISPATCHER: register_result: lock acquired
20:59:54 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:59:54 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 877, 'last_n_outputs': 31, 'leak_rate': 0.8688718785005763, 'lr': 0.03521498245448867, 'optimizer': 'Adam', 'sparsity': 0.9852970600047973, 'steps_to_train': 28, 'weight_decay': 0.010415466598024494}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4183470289833265, 'info': {'number_mnist': 0.4183470289833265, 'config': "{'batch_size': 128, 'hidden_dim': 877, 'last_n_outputs': 31, 'leak_rate': 0.8688718785005763, 'lr': 0.03521498245448867, 'optimizer': 'Adam', 'sparsity': 0.9852970600047973, 'steps_to_train': 28, 'weight_decay': 0.010415466598024494}"}}
exception: None

20:59:54 job_callback for (0, 0, 11) started
20:59:54 job_callback for (0, 0, 11) got condition
20:59:54 DISPATCHER: Trying to submit another job.
20:59:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:59:54 HBMASTER: Trying to run another job!
20:59:54 job_callback for (0, 0, 11) finished
20:59:54 start sampling a new configuration.
20:59:54 done sampling a new configuration.
20:59:54 HBMASTER: schedule new run for iteration 0
20:59:54 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
20:59:54 HBMASTER: submitting job (0, 0, 12) to dispatcher
20:59:54 DISPATCHER: trying to submit job (0, 0, 12)
20:59:54 DISPATCHER: trying to notify the job_runner thread.
20:59:54 HBMASTER: job (0, 0, 12) submitted to dispatcher
20:59:54 DISPATCHER: Trying to submit another job.
20:59:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:59:54 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:59:54 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:59:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:59:54 WORKER: start processing job (0, 0, 12)
20:59:54 WORKER: args: ()
20:59:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 1000, 'last_n_outputs': 22, 'leak_rate': 0.7829813609015187, 'lr': 0.0015351580287575955, 'optimizer': 'SGD', 'sparsity': 0.8471153323848389, 'steps_to_train': 81, 'weight_decay': 0.07212697636435808}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:00:37 DISPATCHER: Starting worker discovery
21:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:37 DISPATCHER: Finished worker discovery
21:00:49 WORKER: done with job (0, 0, 12), trying to register it.
21:00:49 WORKER: registered result for job (0, 0, 12) with dispatcher
21:00:49 DISPATCHER: job (0, 0, 12) finished
21:00:49 DISPATCHER: register_result: lock acquired
21:00:49 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:00:49 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 1000, 'last_n_outputs': 22, 'leak_rate': 0.7829813609015187, 'lr': 0.0015351580287575955, 'optimizer': 'SGD', 'sparsity': 0.8471153323848389, 'steps_to_train': 81, 'weight_decay': 0.07212697636435808}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.849414931988323, 'info': {'number_mnist': 0.849414931988323, 'config': "{'batch_size': 128, 'hidden_dim': 1000, 'last_n_outputs': 22, 'leak_rate': 0.7829813609015187, 'lr': 0.0015351580287575955, 'optimizer': 'SGD', 'sparsity': 0.8471153323848389, 'steps_to_train': 81, 'weight_decay': 0.07212697636435808}"}}
exception: None

21:00:49 job_callback for (0, 0, 12) started
21:00:49 DISPATCHER: Trying to submit another job.
21:00:49 job_callback for (0, 0, 12) got condition
21:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:00:49 HBMASTER: Trying to run another job!
21:00:49 job_callback for (0, 0, 12) finished
21:00:49 start sampling a new configuration.
21:00:49 done sampling a new configuration.
21:00:49 HBMASTER: schedule new run for iteration 0
21:00:49 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
21:00:49 HBMASTER: submitting job (0, 0, 13) to dispatcher
21:00:49 DISPATCHER: trying to submit job (0, 0, 13)
21:00:49 DISPATCHER: trying to notify the job_runner thread.
21:00:49 HBMASTER: job (0, 0, 13) submitted to dispatcher
21:00:49 DISPATCHER: Trying to submit another job.
21:00:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:00:49 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:00:49 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:00:49 WORKER: start processing job (0, 0, 13)
21:00:49 WORKER: args: ()
21:00:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 224, 'last_n_outputs': 27, 'leak_rate': 0.8282075944802861, 'lr': 0.006425464192403476, 'optimizer': 'Adam', 'sparsity': 0.7600401085842539, 'steps_to_train': 40, 'weight_decay': 0.025994061431607346}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:01:37 DISPATCHER: Starting worker discovery
21:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:37 DISPATCHER: Finished worker discovery
21:01:44 WORKER: done with job (0, 0, 13), trying to register it.
21:01:44 WORKER: registered result for job (0, 0, 13) with dispatcher
21:01:44 DISPATCHER: job (0, 0, 13) finished
21:01:44 DISPATCHER: register_result: lock acquired
21:01:44 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:01:44 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 224, 'last_n_outputs': 27, 'leak_rate': 0.8282075944802861, 'lr': 0.006425464192403476, 'optimizer': 'Adam', 'sparsity': 0.7600401085842539, 'steps_to_train': 40, 'weight_decay': 0.025994061431607346}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7222184463717687, 'info': {'number_mnist': 0.7222184463717687, 'config': "{'batch_size': 128, 'hidden_dim': 224, 'last_n_outputs': 27, 'leak_rate': 0.8282075944802861, 'lr': 0.006425464192403476, 'optimizer': 'Adam', 'sparsity': 0.7600401085842539, 'steps_to_train': 40, 'weight_decay': 0.025994061431607346}"}}
exception: None

21:01:44 job_callback for (0, 0, 13) started
21:01:44 DISPATCHER: Trying to submit another job.
21:01:44 job_callback for (0, 0, 13) got condition
21:01:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:01:44 HBMASTER: Trying to run another job!
21:01:44 job_callback for (0, 0, 13) finished
21:01:44 start sampling a new configuration.
21:01:44 done sampling a new configuration.
21:01:44 HBMASTER: schedule new run for iteration 0
21:01:44 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
21:01:44 HBMASTER: submitting job (0, 0, 14) to dispatcher
21:01:44 DISPATCHER: trying to submit job (0, 0, 14)
21:01:44 DISPATCHER: trying to notify the job_runner thread.
21:01:44 HBMASTER: job (0, 0, 14) submitted to dispatcher
21:01:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:01:44 DISPATCHER: Trying to submit another job.
21:01:44 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:01:44 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:01:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:01:44 WORKER: start processing job (0, 0, 14)
21:01:44 WORKER: args: ()
21:01:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 506, 'last_n_outputs': 27, 'leak_rate': 0.7661690570335462, 'lr': 0.003984279977231828, 'optimizer': 'Adam', 'sparsity': 0.8233981424011613, 'steps_to_train': 30, 'weight_decay': 0.0879637458270061}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:02:37 DISPATCHER: Starting worker discovery
21:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:38 DISPATCHER: Finished worker discovery
21:02:38 WORKER: done with job (0, 0, 14), trying to register it.
21:02:38 WORKER: registered result for job (0, 0, 14) with dispatcher
21:02:38 DISPATCHER: job (0, 0, 14) finished
21:02:38 DISPATCHER: register_result: lock acquired
21:02:38 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:02:38 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 506, 'last_n_outputs': 27, 'leak_rate': 0.7661690570335462, 'lr': 0.003984279977231828, 'optimizer': 'Adam', 'sparsity': 0.8233981424011613, 'steps_to_train': 30, 'weight_decay': 0.0879637458270061}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.336210219418322, 'info': {'number_mnist': 0.336210219418322, 'config': "{'batch_size': 16, 'hidden_dim': 506, 'last_n_outputs': 27, 'leak_rate': 0.7661690570335462, 'lr': 0.003984279977231828, 'optimizer': 'Adam', 'sparsity': 0.8233981424011613, 'steps_to_train': 30, 'weight_decay': 0.0879637458270061}"}}
exception: None

21:02:38 job_callback for (0, 0, 14) started
21:02:38 DISPATCHER: Trying to submit another job.
21:02:38 job_callback for (0, 0, 14) got condition
21:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:02:38 HBMASTER: Trying to run another job!
21:02:38 job_callback for (0, 0, 14) finished
21:02:38 start sampling a new configuration.
21:02:38 done sampling a new configuration.
21:02:38 HBMASTER: schedule new run for iteration 0
21:02:38 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
21:02:38 HBMASTER: submitting job (0, 0, 15) to dispatcher
21:02:38 DISPATCHER: trying to submit job (0, 0, 15)
21:02:38 DISPATCHER: trying to notify the job_runner thread.
21:02:38 HBMASTER: job (0, 0, 15) submitted to dispatcher
21:02:38 DISPATCHER: Trying to submit another job.
21:02:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:02:38 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:02:38 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:02:38 WORKER: start processing job (0, 0, 15)
21:02:38 WORKER: args: ()
21:02:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:03:32 WORKER: done with job (0, 0, 15), trying to register it.
21:03:32 WORKER: registered result for job (0, 0, 15) with dispatcher
21:03:32 DISPATCHER: job (0, 0, 15) finished
21:03:32 DISPATCHER: register_result: lock acquired
21:03:32 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:03:32 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9014327873112791, 'info': {'number_mnist': 0.9014327873112791, 'config': "{'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}"}}
exception: None

21:03:32 job_callback for (0, 0, 15) started
21:03:32 DISPATCHER: Trying to submit another job.
21:03:32 job_callback for (0, 0, 15) got condition
21:03:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:32 HBMASTER: Trying to run another job!
21:03:32 job_callback for (0, 0, 15) finished
21:03:32 start sampling a new configuration.
21:03:32 done sampling a new configuration.
21:03:32 HBMASTER: schedule new run for iteration 0
21:03:32 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
21:03:32 HBMASTER: submitting job (0, 0, 16) to dispatcher
21:03:32 DISPATCHER: trying to submit job (0, 0, 16)
21:03:32 DISPATCHER: trying to notify the job_runner thread.
21:03:32 HBMASTER: job (0, 0, 16) submitted to dispatcher
21:03:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:32 DISPATCHER: Trying to submit another job.
21:03:32 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:03:32 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:03:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:32 WORKER: start processing job (0, 0, 16)
21:03:32 WORKER: args: ()
21:03:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 573, 'last_n_outputs': 16, 'leak_rate': 0.9082177932259644, 'lr': 0.09776160331422967, 'optimizer': 'SGD', 'sparsity': 0.7984209966712336, 'steps_to_train': 70, 'weight_decay': 0.06586061786378021}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:03:38 DISPATCHER: Starting worker discovery
21:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:38 DISPATCHER: Finished worker discovery
21:04:25 WORKER: done with job (0, 0, 16), trying to register it.
21:04:25 WORKER: registered result for job (0, 0, 16) with dispatcher
21:04:25 DISPATCHER: job (0, 0, 16) finished
21:04:25 DISPATCHER: register_result: lock acquired
21:04:25 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:04:25 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 573, 'last_n_outputs': 16, 'leak_rate': 0.9082177932259644, 'lr': 0.09776160331422967, 'optimizer': 'SGD', 'sparsity': 0.7984209966712336, 'steps_to_train': 70, 'weight_decay': 0.06586061786378021}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4847186431127803, 'info': {'number_mnist': 0.4847186431127803, 'config': "{'batch_size': 16, 'hidden_dim': 573, 'last_n_outputs': 16, 'leak_rate': 0.9082177932259644, 'lr': 0.09776160331422967, 'optimizer': 'SGD', 'sparsity': 0.7984209966712336, 'steps_to_train': 70, 'weight_decay': 0.06586061786378021}"}}
exception: None

21:04:25 job_callback for (0, 0, 16) started
21:04:25 DISPATCHER: Trying to submit another job.
21:04:25 job_callback for (0, 0, 16) got condition
21:04:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:04:25 HBMASTER: Trying to run another job!
21:04:25 job_callback for (0, 0, 16) finished
21:04:25 start sampling a new configuration.
21:04:25 done sampling a new configuration.
21:04:25 HBMASTER: schedule new run for iteration 0
21:04:25 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
21:04:25 HBMASTER: submitting job (0, 0, 17) to dispatcher
21:04:25 DISPATCHER: trying to submit job (0, 0, 17)
21:04:25 DISPATCHER: trying to notify the job_runner thread.
21:04:25 HBMASTER: job (0, 0, 17) submitted to dispatcher
21:04:25 DISPATCHER: Trying to submit another job.
21:04:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:04:25 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:04:25 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:04:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:04:25 WORKER: start processing job (0, 0, 17)
21:04:25 WORKER: args: ()
21:04:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 390, 'last_n_outputs': 15, 'leak_rate': 0.7671508842359258, 'lr': 0.002080106702784618, 'optimizer': 'SGD', 'sparsity': 0.8480354552951481, 'steps_to_train': 45, 'weight_decay': 0.1066294929207693}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:04:38 DISPATCHER: Starting worker discovery
21:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:38 DISPATCHER: Finished worker discovery
21:05:20 WORKER: done with job (0, 0, 17), trying to register it.
21:05:20 WORKER: registered result for job (0, 0, 17) with dispatcher
21:05:20 DISPATCHER: job (0, 0, 17) finished
21:05:20 DISPATCHER: register_result: lock acquired
21:05:20 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:05:20 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 390, 'last_n_outputs': 15, 'leak_rate': 0.7671508842359258, 'lr': 0.002080106702784618, 'optimizer': 'SGD', 'sparsity': 0.8480354552951481, 'steps_to_train': 45, 'weight_decay': 0.1066294929207693}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7795497034907395, 'info': {'number_mnist': 0.7795497034907395, 'config': "{'batch_size': 64, 'hidden_dim': 390, 'last_n_outputs': 15, 'leak_rate': 0.7671508842359258, 'lr': 0.002080106702784618, 'optimizer': 'SGD', 'sparsity': 0.8480354552951481, 'steps_to_train': 45, 'weight_decay': 0.1066294929207693}"}}
exception: None

21:05:20 job_callback for (0, 0, 17) started
21:05:20 DISPATCHER: Trying to submit another job.
21:05:20 job_callback for (0, 0, 17) got condition
21:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:05:20 HBMASTER: Trying to run another job!
21:05:20 job_callback for (0, 0, 17) finished
21:05:20 start sampling a new configuration.
21:05:20 done sampling a new configuration.
21:05:20 HBMASTER: schedule new run for iteration 0
21:05:20 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
21:05:20 HBMASTER: submitting job (0, 0, 18) to dispatcher
21:05:20 DISPATCHER: trying to submit job (0, 0, 18)
21:05:20 DISPATCHER: trying to notify the job_runner thread.
21:05:20 HBMASTER: job (0, 0, 18) submitted to dispatcher
21:05:20 DISPATCHER: Trying to submit another job.
21:05:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:05:20 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:05:20 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:05:20 WORKER: start processing job (0, 0, 18)
21:05:20 WORKER: args: ()
21:05:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 321, 'last_n_outputs': 47, 'leak_rate': 0.9983015533240569, 'lr': 0.004463032231753831, 'optimizer': 'Adam', 'sparsity': 0.9021565992624315, 'steps_to_train': 16, 'weight_decay': 0.08024323266395601}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:05:38 DISPATCHER: Starting worker discovery
21:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:38 DISPATCHER: Finished worker discovery
21:06:14 WORKER: done with job (0, 0, 18), trying to register it.
21:06:14 WORKER: registered result for job (0, 0, 18) with dispatcher
21:06:14 DISPATCHER: job (0, 0, 18) finished
21:06:14 DISPATCHER: register_result: lock acquired
21:06:14 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:06:14 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 321, 'last_n_outputs': 47, 'leak_rate': 0.9983015533240569, 'lr': 0.004463032231753831, 'optimizer': 'Adam', 'sparsity': 0.9021565992624315, 'steps_to_train': 16, 'weight_decay': 0.08024323266395601}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3973755500977482, 'info': {'number_mnist': 0.3973755500977482, 'config': "{'batch_size': 32, 'hidden_dim': 321, 'last_n_outputs': 47, 'leak_rate': 0.9983015533240569, 'lr': 0.004463032231753831, 'optimizer': 'Adam', 'sparsity': 0.9021565992624315, 'steps_to_train': 16, 'weight_decay': 0.08024323266395601}"}}
exception: None

21:06:14 job_callback for (0, 0, 18) started
21:06:14 job_callback for (0, 0, 18) got condition
21:06:14 DISPATCHER: Trying to submit another job.
21:06:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:06:14 HBMASTER: Trying to run another job!
21:06:14 job_callback for (0, 0, 18) finished
21:06:14 start sampling a new configuration.
21:06:14 done sampling a new configuration.
21:06:14 HBMASTER: schedule new run for iteration 0
21:06:14 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
21:06:14 HBMASTER: submitting job (0, 0, 19) to dispatcher
21:06:14 DISPATCHER: trying to submit job (0, 0, 19)
21:06:14 DISPATCHER: trying to notify the job_runner thread.
21:06:14 HBMASTER: job (0, 0, 19) submitted to dispatcher
21:06:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:06:14 DISPATCHER: Trying to submit another job.
21:06:14 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:06:14 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:06:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:06:14 WORKER: start processing job (0, 0, 19)
21:06:14 WORKER: args: ()
21:06:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 992, 'last_n_outputs': 30, 'leak_rate': 0.9675332615743659, 'lr': 0.0014532623418905492, 'optimizer': 'Adam', 'sparsity': 0.9445046945211504, 'steps_to_train': 10, 'weight_decay': 0.020791633210290462}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:06:38 DISPATCHER: Starting worker discovery
21:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:38 DISPATCHER: Finished worker discovery
21:07:09 WORKER: done with job (0, 0, 19), trying to register it.
21:07:09 WORKER: registered result for job (0, 0, 19) with dispatcher
21:07:09 DISPATCHER: job (0, 0, 19) finished
21:07:09 DISPATCHER: register_result: lock acquired
21:07:09 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:07:09 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 992, 'last_n_outputs': 30, 'leak_rate': 0.9675332615743659, 'lr': 0.0014532623418905492, 'optimizer': 'Adam', 'sparsity': 0.9445046945211504, 'steps_to_train': 10, 'weight_decay': 0.020791633210290462}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6423695819087878, 'info': {'number_mnist': 0.6423695819087878, 'config': "{'batch_size': 64, 'hidden_dim': 992, 'last_n_outputs': 30, 'leak_rate': 0.9675332615743659, 'lr': 0.0014532623418905492, 'optimizer': 'Adam', 'sparsity': 0.9445046945211504, 'steps_to_train': 10, 'weight_decay': 0.020791633210290462}"}}
exception: None

21:07:09 job_callback for (0, 0, 19) started
21:07:09 DISPATCHER: Trying to submit another job.
21:07:09 job_callback for (0, 0, 19) got condition
21:07:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:07:09 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.912589





21:07:09 HBMASTER: Trying to run another job!
21:07:09 job_callback for (0, 0, 19) finished
21:07:09 start sampling a new configuration.
21:07:09 best_vector: [0, 0.3474795896724108, 0.4088223789503974, 0.28961237742709145, 0.9056390251187629, 1, 0.16006874185795733, 0.5276821794623476, 0.8987655703698427], 2.7048664448398476e-31, 0.03697040206579253, -0.0007398161066192995
21:07:09 done sampling a new configuration.
21:07:09 HBMASTER: schedule new run for iteration 0
21:07:09 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
21:07:09 HBMASTER: submitting job (0, 0, 20) to dispatcher
21:07:09 DISPATCHER: trying to submit job (0, 0, 20)
21:07:09 DISPATCHER: trying to notify the job_runner thread.
21:07:09 HBMASTER: job (0, 0, 20) submitted to dispatcher
21:07:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:07:09 DISPATCHER: Trying to submit another job.
21:07:09 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:07:09 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:07:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:07:09 WORKER: start processing job (0, 0, 20)
21:07:09 WORKER: args: ()
21:07:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 478, 'last_n_outputs': 26, 'leak_rate': 0.8224030943567728, 'lr': 0.06475570713290947, 'optimizer': 'SGD', 'sparsity': 0.7884164980459097, 'steps_to_train': 58, 'weight_decay': 0.14767975599674887}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:07:38 DISPATCHER: Starting worker discovery
21:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:38 DISPATCHER: Finished worker discovery
21:08:04 WORKER: done with job (0, 0, 20), trying to register it.
21:08:04 WORKER: registered result for job (0, 0, 20) with dispatcher
21:08:04 DISPATCHER: job (0, 0, 20) finished
21:08:04 DISPATCHER: register_result: lock acquired
21:08:04 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:08:04 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 478, 'last_n_outputs': 26, 'leak_rate': 0.8224030943567728, 'lr': 0.06475570713290947, 'optimizer': 'SGD', 'sparsity': 0.7884164980459097, 'steps_to_train': 58, 'weight_decay': 0.14767975599674887}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4230696426274829, 'info': {'number_mnist': 0.4230696426274829, 'config': "{'batch_size': 16, 'hidden_dim': 478, 'last_n_outputs': 26, 'leak_rate': 0.8224030943567728, 'lr': 0.06475570713290947, 'optimizer': 'SGD', 'sparsity': 0.7884164980459097, 'steps_to_train': 58, 'weight_decay': 0.14767975599674887}"}}
exception: None

21:08:04 job_callback for (0, 0, 20) started
21:08:04 job_callback for (0, 0, 20) got condition
21:08:04 DISPATCHER: Trying to submit another job.
21:08:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:08:04 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.912589





21:08:04 HBMASTER: Trying to run another job!
21:08:04 job_callback for (0, 0, 20) finished
21:08:04 start sampling a new configuration.
21:08:04 done sampling a new configuration.
21:08:04 HBMASTER: schedule new run for iteration 0
21:08:04 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
21:08:04 HBMASTER: submitting job (0, 0, 21) to dispatcher
21:08:04 DISPATCHER: trying to submit job (0, 0, 21)
21:08:04 DISPATCHER: trying to notify the job_runner thread.
21:08:04 HBMASTER: job (0, 0, 21) submitted to dispatcher
21:08:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:08:04 DISPATCHER: Trying to submit another job.
21:08:04 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:08:04 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:08:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:08:04 WORKER: start processing job (0, 0, 21)
21:08:04 WORKER: args: ()
21:08:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 223, 'last_n_outputs': 21, 'leak_rate': 0.9521255423050887, 'lr': 0.05979011279962865, 'optimizer': 'Adam', 'sparsity': 0.9640801836034064, 'steps_to_train': 26, 'weight_decay': 0.03919352183624779}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:08:38 DISPATCHER: Starting worker discovery
21:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:38 DISPATCHER: Finished worker discovery
21:08:58 WORKER: done with job (0, 0, 21), trying to register it.
21:08:58 WORKER: registered result for job (0, 0, 21) with dispatcher
21:08:58 DISPATCHER: job (0, 0, 21) finished
21:08:58 DISPATCHER: register_result: lock acquired
21:08:58 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:08:58 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 223, 'last_n_outputs': 21, 'leak_rate': 0.9521255423050887, 'lr': 0.05979011279962865, 'optimizer': 'Adam', 'sparsity': 0.9640801836034064, 'steps_to_train': 26, 'weight_decay': 0.03919352183624779}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0648638390961808, 'info': {'number_mnist': 0.0648638390961808, 'config': "{'batch_size': 128, 'hidden_dim': 223, 'last_n_outputs': 21, 'leak_rate': 0.9521255423050887, 'lr': 0.05979011279962865, 'optimizer': 'Adam', 'sparsity': 0.9640801836034064, 'steps_to_train': 26, 'weight_decay': 0.03919352183624779}"}}
exception: None

21:08:58 job_callback for (0, 0, 21) started
21:08:58 DISPATCHER: Trying to submit another job.
21:08:58 job_callback for (0, 0, 21) got condition
21:08:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:08:58 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.912589





21:08:58 HBMASTER: Trying to run another job!
21:08:58 job_callback for (0, 0, 21) finished
21:08:58 start sampling a new configuration.
21:08:58 done sampling a new configuration.
21:08:58 HBMASTER: schedule new run for iteration 0
21:08:58 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
21:08:58 HBMASTER: submitting job (0, 0, 22) to dispatcher
21:08:58 DISPATCHER: trying to submit job (0, 0, 22)
21:08:58 DISPATCHER: trying to notify the job_runner thread.
21:08:58 HBMASTER: job (0, 0, 22) submitted to dispatcher
21:08:58 DISPATCHER: Trying to submit another job.
21:08:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:08:58 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:08:58 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:08:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:08:58 WORKER: start processing job (0, 0, 22)
21:08:58 WORKER: args: ()
21:08:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 537, 'last_n_outputs': 18, 'leak_rate': 0.9145625166275464, 'lr': 0.004012863564213359, 'optimizer': 'Adam', 'sparsity': 0.8749910182223402, 'steps_to_train': 83, 'weight_decay': 0.07707331488126659}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:09:38 DISPATCHER: Starting worker discovery
21:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:38 DISPATCHER: Finished worker discovery
21:09:53 WORKER: done with job (0, 0, 22), trying to register it.
21:09:53 WORKER: registered result for job (0, 0, 22) with dispatcher
21:09:53 DISPATCHER: job (0, 0, 22) finished
21:09:53 DISPATCHER: register_result: lock acquired
21:09:53 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:09:53 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 537, 'last_n_outputs': 18, 'leak_rate': 0.9145625166275464, 'lr': 0.004012863564213359, 'optimizer': 'Adam', 'sparsity': 0.8749910182223402, 'steps_to_train': 83, 'weight_decay': 0.07707331488126659}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7735615375997743, 'info': {'number_mnist': 0.7735615375997743, 'config': "{'batch_size': 64, 'hidden_dim': 537, 'last_n_outputs': 18, 'leak_rate': 0.9145625166275464, 'lr': 0.004012863564213359, 'optimizer': 'Adam', 'sparsity': 0.8749910182223402, 'steps_to_train': 83, 'weight_decay': 0.07707331488126659}"}}
exception: None

21:09:53 job_callback for (0, 0, 22) started
21:09:53 job_callback for (0, 0, 22) got condition
21:09:53 DISPATCHER: Trying to submit another job.
21:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:09:53 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.912589





21:09:53 HBMASTER: Trying to run another job!
21:09:53 job_callback for (0, 0, 22) finished
21:09:53 start sampling a new configuration.
21:09:53 best_vector: [3, 0.9241250398292882, 0.9922064870908172, 0.7383005089858121, 0.7579341893958376, 0, 0.3641071959552269, 0.1387529585361752, 0.5196956334664395], 9.900935517968551e-29, 0.00010100055678427219, -0.0005003338083050927
21:09:53 done sampling a new configuration.
21:09:53 HBMASTER: schedule new run for iteration 0
21:09:53 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
21:09:53 HBMASTER: submitting job (0, 0, 23) to dispatcher
21:09:53 DISPATCHER: trying to submit job (0, 0, 23)
21:09:53 DISPATCHER: trying to notify the job_runner thread.
21:09:53 HBMASTER: job (0, 0, 23) submitted to dispatcher
21:09:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:09:53 DISPATCHER: Trying to submit another job.
21:09:53 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:09:53 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:09:53 WORKER: start processing job (0, 0, 23)
21:09:53 WORKER: args: ()
21:09:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 940, 'last_n_outputs': 50, 'leak_rate': 0.9345751272464531, 'lr': 0.03279958726565543, 'optimizer': 'Adam', 'sparsity': 0.8373857270292544, 'steps_to_train': 22, 'weight_decay': 0.047439445899532716}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:10:38 DISPATCHER: Starting worker discovery
21:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:38 DISPATCHER: Finished worker discovery
21:10:48 WORKER: done with job (0, 0, 23), trying to register it.
21:10:48 WORKER: registered result for job (0, 0, 23) with dispatcher
21:10:48 DISPATCHER: job (0, 0, 23) finished
21:10:48 DISPATCHER: register_result: lock acquired
21:10:48 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:10:48 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 940, 'last_n_outputs': 50, 'leak_rate': 0.9345751272464531, 'lr': 0.03279958726565543, 'optimizer': 'Adam', 'sparsity': 0.8373857270292544, 'steps_to_train': 22, 'weight_decay': 0.047439445899532716}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30159262456502384, 'info': {'number_mnist': 0.30159262456502384, 'config': "{'batch_size': 128, 'hidden_dim': 940, 'last_n_outputs': 50, 'leak_rate': 0.9345751272464531, 'lr': 0.03279958726565543, 'optimizer': 'Adam', 'sparsity': 0.8373857270292544, 'steps_to_train': 22, 'weight_decay': 0.047439445899532716}"}}
exception: None

21:10:48 job_callback for (0, 0, 23) started
21:10:48 DISPATCHER: Trying to submit another job.
21:10:48 job_callback for (0, 0, 23) got condition
21:10:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:10:48 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.912589





21:10:48 HBMASTER: Trying to run another job!
21:10:48 job_callback for (0, 0, 23) finished
21:10:48 start sampling a new configuration.
21:10:48 done sampling a new configuration.
21:10:48 HBMASTER: schedule new run for iteration 0
21:10:48 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
21:10:48 HBMASTER: submitting job (0, 0, 24) to dispatcher
21:10:48 DISPATCHER: trying to submit job (0, 0, 24)
21:10:48 DISPATCHER: trying to notify the job_runner thread.
21:10:48 HBMASTER: job (0, 0, 24) submitted to dispatcher
21:10:48 DISPATCHER: Trying to submit another job.
21:10:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:10:48 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:10:48 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:10:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:10:48 WORKER: start processing job (0, 0, 24)
21:10:48 WORKER: args: ()
21:10:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 629, 'last_n_outputs': 42, 'leak_rate': 0.8979654428534103, 'lr': 0.004226475550415295, 'optimizer': 'Adam', 'sparsity': 0.7523411390681075, 'steps_to_train': 44, 'weight_decay': 0.025763236544710657}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:11:38 DISPATCHER: Starting worker discovery
21:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:38 DISPATCHER: Finished worker discovery
21:11:43 WORKER: done with job (0, 0, 24), trying to register it.
21:11:43 WORKER: registered result for job (0, 0, 24) with dispatcher
21:11:43 DISPATCHER: job (0, 0, 24) finished
21:11:43 DISPATCHER: register_result: lock acquired
21:11:43 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:11:43 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 629, 'last_n_outputs': 42, 'leak_rate': 0.8979654428534103, 'lr': 0.004226475550415295, 'optimizer': 'Adam', 'sparsity': 0.7523411390681075, 'steps_to_train': 44, 'weight_decay': 0.025763236544710657}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8684160660173623, 'info': {'number_mnist': 0.8684160660173623, 'config': "{'batch_size': 64, 'hidden_dim': 629, 'last_n_outputs': 42, 'leak_rate': 0.8979654428534103, 'lr': 0.004226475550415295, 'optimizer': 'Adam', 'sparsity': 0.7523411390681075, 'steps_to_train': 44, 'weight_decay': 0.025763236544710657}"}}
exception: None

21:11:43 job_callback for (0, 0, 24) started
21:11:43 job_callback for (0, 0, 24) got condition
21:11:43 DISPATCHER: Trying to submit another job.
21:11:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:11:43 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.912589





21:11:43 HBMASTER: Trying to run another job!
21:11:43 job_callback for (0, 0, 24) finished
21:11:43 start sampling a new configuration.
21:11:43 best_vector: [2, 0.18444428315522987, 0.526476458254499, 0.8607271038797453, 0.1168007163516218, 1, 0.6438148232656622, 0.40863462218176216, 0.044361660042537276], 0.0070486402118652616, 0.041833526871717056, 0.0002948694797121308
21:11:43 done sampling a new configuration.
21:11:43 HBMASTER: schedule new run for iteration 0
21:11:43 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
21:11:43 HBMASTER: submitting job (0, 0, 25) to dispatcher
21:11:43 DISPATCHER: trying to submit job (0, 0, 25)
21:11:43 DISPATCHER: trying to notify the job_runner thread.
21:11:43 HBMASTER: job (0, 0, 25) submitted to dispatcher
21:11:43 DISPATCHER: Trying to submit another job.
21:11:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:11:43 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:11:43 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:11:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:11:43 WORKER: start processing job (0, 0, 25)
21:11:43 WORKER: args: ()
21:11:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 347, 'last_n_outputs': 31, 'leak_rate': 0.9651817759699364, 'lr': 0.0017123850702589038, 'optimizer': 'SGD', 'sparsity': 0.9045155575837589, 'steps_to_train': 47, 'weight_decay': 0.011421308184121199}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:12:36 WORKER: done with job (0, 0, 25), trying to register it.
21:12:36 WORKER: registered result for job (0, 0, 25) with dispatcher
21:12:36 DISPATCHER: job (0, 0, 25) finished
21:12:36 DISPATCHER: register_result: lock acquired
21:12:36 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:12:36 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 347, 'last_n_outputs': 31, 'leak_rate': 0.9651817759699364, 'lr': 0.0017123850702589038, 'optimizer': 'SGD', 'sparsity': 0.9045155575837589, 'steps_to_train': 47, 'weight_decay': 0.011421308184121199}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7551982398862138, 'info': {'number_mnist': 0.7551982398862138, 'config': "{'batch_size': 64, 'hidden_dim': 347, 'last_n_outputs': 31, 'leak_rate': 0.9651817759699364, 'lr': 0.0017123850702589038, 'optimizer': 'SGD', 'sparsity': 0.9045155575837589, 'steps_to_train': 47, 'weight_decay': 0.011421308184121199}"}}
exception: None

21:12:36 job_callback for (0, 0, 25) started
21:12:36 DISPATCHER: Trying to submit another job.
21:12:36 job_callback for (0, 0, 25) got condition
21:12:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:12:36 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.912589





21:12:36 HBMASTER: Trying to run another job!
21:12:36 job_callback for (0, 0, 25) finished
21:12:36 start sampling a new configuration.
21:12:36 best_vector: [2, 0.3193702265707744, 0.5466451508966538, 0.5252374216070683, 0.3072065766044507, 1, 0.42134680231449656, 0.3187553587148336, 0.04784144382355432], 0.006772965393568102, 0.2084757824237463, 0.0014119992597530669
21:12:36 done sampling a new configuration.
21:12:36 HBMASTER: schedule new run for iteration 0
21:12:36 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
21:12:36 HBMASTER: submitting job (0, 0, 26) to dispatcher
21:12:36 DISPATCHER: trying to submit job (0, 0, 26)
21:12:36 DISPATCHER: trying to notify the job_runner thread.
21:12:36 HBMASTER: job (0, 0, 26) submitted to dispatcher
21:12:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:12:36 DISPATCHER: Trying to submit another job.
21:12:36 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:12:36 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:12:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:12:36 WORKER: start processing job (0, 0, 26)
21:12:36 WORKER: args: ()
21:12:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:12:38 DISPATCHER: Starting worker discovery
21:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:38 DISPATCHER: Finished worker discovery
21:13:30 WORKER: done with job (0, 0, 26), trying to register it.
21:13:30 WORKER: registered result for job (0, 0, 26) with dispatcher
21:13:30 DISPATCHER: job (0, 0, 26) finished
21:13:30 DISPATCHER: register_result: lock acquired
21:13:30 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:13:30 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8740833117678469, 'info': {'number_mnist': 0.8740833117678469, 'config': "{'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}"}}
exception: None

21:13:30 job_callback for (0, 0, 26) started
21:13:30 DISPATCHER: Trying to submit another job.
21:13:30 job_callback for (0, 0, 26) got condition
21:13:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:13:30 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.912589





21:13:30 HBMASTER: Trying to run another job!
21:13:30 job_callback for (0, 0, 26) finished
21:13:30 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
21:13:30 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
21:13:30 HBMASTER: schedule new run for iteration 0
21:13:30 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
21:13:30 HBMASTER: submitting job (0, 0, 1) to dispatcher
21:13:30 DISPATCHER: trying to submit job (0, 0, 1)
21:13:30 DISPATCHER: trying to notify the job_runner thread.
21:13:30 HBMASTER: job (0, 0, 1) submitted to dispatcher
21:13:30 DISPATCHER: Trying to submit another job.
21:13:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:13:30 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:13:30 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:13:30 WORKER: start processing job (0, 0, 1)
21:13:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:13:30 WORKER: args: ()
21:13:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:13:38 DISPATCHER: Starting worker discovery
21:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:38 DISPATCHER: Finished worker discovery
21:14:38 DISPATCHER: Starting worker discovery
21:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:38 DISPATCHER: Finished worker discovery
21:15:38 DISPATCHER: Starting worker discovery
21:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:38 DISPATCHER: Finished worker discovery
21:15:54 WORKER: done with job (0, 0, 1), trying to register it.
21:15:54 WORKER: registered result for job (0, 0, 1) with dispatcher
21:15:54 DISPATCHER: job (0, 0, 1) finished
21:15:54 DISPATCHER: register_result: lock acquired
21:15:54 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:15:54 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9144220132536751, 'info': {'number_mnist': 0.9144220132536751, 'config': "{'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}"}}
exception: None

21:15:54 job_callback for (0, 0, 1) started
21:15:54 job_callback for (0, 0, 1) got condition
21:15:54 DISPATCHER: Trying to submit another job.
21:15:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:15:54 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:15:54 HBMASTER: Trying to run another job!
21:15:54 job_callback for (0, 0, 1) finished
21:15:54 HBMASTER: schedule new run for iteration 0
21:15:54 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
21:15:54 HBMASTER: submitting job (0, 0, 5) to dispatcher
21:15:54 DISPATCHER: trying to submit job (0, 0, 5)
21:15:54 DISPATCHER: trying to notify the job_runner thread.
21:15:54 HBMASTER: job (0, 0, 5) submitted to dispatcher
21:15:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:15:54 DISPATCHER: Trying to submit another job.
21:15:54 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:15:54 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:15:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:15:54 WORKER: start processing job (0, 0, 5)
21:15:54 WORKER: args: ()
21:15:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 374, 'last_n_outputs': 35, 'leak_rate': 0.7966197654549849, 'lr': 0.025135809416683596, 'optimizer': 'SGD', 'sparsity': 0.8756642178952916, 'steps_to_train': 40, 'weight_decay': 0.18023387258406645}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:16:38 DISPATCHER: Starting worker discovery
21:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:38 DISPATCHER: Finished worker discovery
21:17:38 DISPATCHER: Starting worker discovery
21:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:38 DISPATCHER: Finished worker discovery
21:18:19 WORKER: done with job (0, 0, 5), trying to register it.
21:18:19 WORKER: registered result for job (0, 0, 5) with dispatcher
21:18:19 DISPATCHER: job (0, 0, 5) finished
21:18:19 DISPATCHER: register_result: lock acquired
21:18:19 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:18:19 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 374, 'last_n_outputs': 35, 'leak_rate': 0.7966197654549849, 'lr': 0.025135809416683596, 'optimizer': 'SGD', 'sparsity': 0.8756642178952916, 'steps_to_train': 40, 'weight_decay': 0.18023387258406645}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8593633963117748, 'info': {'number_mnist': 0.8593633963117748, 'config': "{'batch_size': 64, 'hidden_dim': 374, 'last_n_outputs': 35, 'leak_rate': 0.7966197654549849, 'lr': 0.025135809416683596, 'optimizer': 'SGD', 'sparsity': 0.8756642178952916, 'steps_to_train': 40, 'weight_decay': 0.18023387258406645}"}}
exception: None

21:18:19 job_callback for (0, 0, 5) started
21:18:19 job_callback for (0, 0, 5) got condition
21:18:19 DISPATCHER: Trying to submit another job.
21:18:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:18:19 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:18:19 HBMASTER: Trying to run another job!
21:18:19 job_callback for (0, 0, 5) finished
21:18:19 HBMASTER: schedule new run for iteration 0
21:18:19 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
21:18:19 HBMASTER: submitting job (0, 0, 8) to dispatcher
21:18:19 DISPATCHER: trying to submit job (0, 0, 8)
21:18:19 DISPATCHER: trying to notify the job_runner thread.
21:18:19 HBMASTER: job (0, 0, 8) submitted to dispatcher
21:18:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:18:19 DISPATCHER: Trying to submit another job.
21:18:19 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:18:19 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:18:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:18:19 WORKER: start processing job (0, 0, 8)
21:18:19 WORKER: args: ()
21:18:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 732, 'last_n_outputs': 13, 'leak_rate': 0.9403700638641588, 'lr': 0.004153137600636875, 'optimizer': 'SGD', 'sparsity': 0.9201881340288672, 'steps_to_train': 67, 'weight_decay': 0.11491393642004158}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:18:38 DISPATCHER: Starting worker discovery
21:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:38 DISPATCHER: Finished worker discovery
21:19:38 DISPATCHER: Starting worker discovery
21:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:38 DISPATCHER: Finished worker discovery
21:20:38 DISPATCHER: Starting worker discovery
21:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:38 DISPATCHER: Finished worker discovery
21:20:42 WORKER: done with job (0, 0, 8), trying to register it.
21:20:42 WORKER: registered result for job (0, 0, 8) with dispatcher
21:20:42 DISPATCHER: job (0, 0, 8) finished
21:20:42 DISPATCHER: register_result: lock acquired
21:20:42 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:20:42 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 732, 'last_n_outputs': 13, 'leak_rate': 0.9403700638641588, 'lr': 0.004153137600636875, 'optimizer': 'SGD', 'sparsity': 0.9201881340288672, 'steps_to_train': 67, 'weight_decay': 0.11491393642004158}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8636912245203417, 'info': {'number_mnist': 0.8636912245203417, 'config': "{'batch_size': 32, 'hidden_dim': 732, 'last_n_outputs': 13, 'leak_rate': 0.9403700638641588, 'lr': 0.004153137600636875, 'optimizer': 'SGD', 'sparsity': 0.9201881340288672, 'steps_to_train': 67, 'weight_decay': 0.11491393642004158}"}}
exception: None

21:20:42 job_callback for (0, 0, 8) started
21:20:42 DISPATCHER: Trying to submit another job.
21:20:42 job_callback for (0, 0, 8) got condition
21:20:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:20:42 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:20:42 HBMASTER: Trying to run another job!
21:20:42 job_callback for (0, 0, 8) finished
21:20:42 HBMASTER: schedule new run for iteration 0
21:20:42 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
21:20:42 HBMASTER: submitting job (0, 0, 12) to dispatcher
21:20:42 DISPATCHER: trying to submit job (0, 0, 12)
21:20:42 DISPATCHER: trying to notify the job_runner thread.
21:20:42 HBMASTER: job (0, 0, 12) submitted to dispatcher
21:20:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:20:42 DISPATCHER: Trying to submit another job.
21:20:42 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:20:42 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:20:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:20:42 WORKER: start processing job (0, 0, 12)
21:20:42 WORKER: args: ()
21:20:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 1000, 'last_n_outputs': 22, 'leak_rate': 0.7829813609015187, 'lr': 0.0015351580287575955, 'optimizer': 'SGD', 'sparsity': 0.8471153323848389, 'steps_to_train': 81, 'weight_decay': 0.07212697636435808}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:21:38 DISPATCHER: Starting worker discovery
21:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:38 DISPATCHER: Finished worker discovery
21:22:38 DISPATCHER: Starting worker discovery
21:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:38 DISPATCHER: Finished worker discovery
21:23:07 WORKER: done with job (0, 0, 12), trying to register it.
21:23:07 WORKER: registered result for job (0, 0, 12) with dispatcher
21:23:07 DISPATCHER: job (0, 0, 12) finished
21:23:07 DISPATCHER: register_result: lock acquired
21:23:07 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:23:07 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 1000, 'last_n_outputs': 22, 'leak_rate': 0.7829813609015187, 'lr': 0.0015351580287575955, 'optimizer': 'SGD', 'sparsity': 0.8471153323848389, 'steps_to_train': 81, 'weight_decay': 0.07212697636435808}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8987027844529107, 'info': {'number_mnist': 0.8987027844529107, 'config': "{'batch_size': 128, 'hidden_dim': 1000, 'last_n_outputs': 22, 'leak_rate': 0.7829813609015187, 'lr': 0.0015351580287575955, 'optimizer': 'SGD', 'sparsity': 0.8471153323848389, 'steps_to_train': 81, 'weight_decay': 0.07212697636435808}"}}
exception: None

21:23:07 job_callback for (0, 0, 12) started
21:23:07 job_callback for (0, 0, 12) got condition
21:23:07 DISPATCHER: Trying to submit another job.
21:23:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:23:07 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:23:07 HBMASTER: Trying to run another job!
21:23:07 job_callback for (0, 0, 12) finished
21:23:07 HBMASTER: schedule new run for iteration 0
21:23:07 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
21:23:07 HBMASTER: submitting job (0, 0, 15) to dispatcher
21:23:07 DISPATCHER: trying to submit job (0, 0, 15)
21:23:07 DISPATCHER: trying to notify the job_runner thread.
21:23:07 HBMASTER: job (0, 0, 15) submitted to dispatcher
21:23:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:23:07 DISPATCHER: Trying to submit another job.
21:23:07 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:23:07 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:23:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:23:07 WORKER: start processing job (0, 0, 15)
21:23:07 WORKER: args: ()
21:23:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:23:38 DISPATCHER: Starting worker discovery
21:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:38 DISPATCHER: Finished worker discovery
21:24:38 DISPATCHER: Starting worker discovery
21:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:38 DISPATCHER: Finished worker discovery
21:25:31 WORKER: done with job (0, 0, 15), trying to register it.
21:25:31 WORKER: registered result for job (0, 0, 15) with dispatcher
21:25:31 DISPATCHER: job (0, 0, 15) finished
21:25:31 DISPATCHER: register_result: lock acquired
21:25:31 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:25:31 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9214045711258301, 'info': {'number_mnist': 0.9214045711258301, 'config': "{'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}"}}
exception: None

21:25:31 job_callback for (0, 0, 15) started
21:25:31 DISPATCHER: Trying to submit another job.
21:25:31 job_callback for (0, 0, 15) got condition
21:25:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:25:31 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:25:31 HBMASTER: Trying to run another job!
21:25:31 job_callback for (0, 0, 15) finished
21:25:31 HBMASTER: schedule new run for iteration 0
21:25:31 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
21:25:31 HBMASTER: submitting job (0, 0, 17) to dispatcher
21:25:31 DISPATCHER: trying to submit job (0, 0, 17)
21:25:31 DISPATCHER: trying to notify the job_runner thread.
21:25:31 HBMASTER: job (0, 0, 17) submitted to dispatcher
21:25:31 DISPATCHER: Trying to submit another job.
21:25:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:25:31 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:25:31 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:25:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:25:31 WORKER: start processing job (0, 0, 17)
21:25:31 WORKER: args: ()
21:25:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 390, 'last_n_outputs': 15, 'leak_rate': 0.7671508842359258, 'lr': 0.002080106702784618, 'optimizer': 'SGD', 'sparsity': 0.8480354552951481, 'steps_to_train': 45, 'weight_decay': 0.1066294929207693}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:25:38 DISPATCHER: Starting worker discovery
21:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:38 DISPATCHER: Finished worker discovery
21:26:38 DISPATCHER: Starting worker discovery
21:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:38 DISPATCHER: Finished worker discovery
21:27:38 DISPATCHER: Starting worker discovery
21:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:38 DISPATCHER: Finished worker discovery
21:27:55 WORKER: done with job (0, 0, 17), trying to register it.
21:27:55 WORKER: registered result for job (0, 0, 17) with dispatcher
21:27:55 DISPATCHER: job (0, 0, 17) finished
21:27:55 DISPATCHER: register_result: lock acquired
21:27:55 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:27:55 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 390, 'last_n_outputs': 15, 'leak_rate': 0.7671508842359258, 'lr': 0.002080106702784618, 'optimizer': 'SGD', 'sparsity': 0.8480354552951481, 'steps_to_train': 45, 'weight_decay': 0.1066294929207693}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8388029659620193, 'info': {'number_mnist': 0.8388029659620193, 'config': "{'batch_size': 64, 'hidden_dim': 390, 'last_n_outputs': 15, 'leak_rate': 0.7671508842359258, 'lr': 0.002080106702784618, 'optimizer': 'SGD', 'sparsity': 0.8480354552951481, 'steps_to_train': 45, 'weight_decay': 0.1066294929207693}"}}
exception: None

21:27:55 job_callback for (0, 0, 17) started
21:27:55 job_callback for (0, 0, 17) got condition
21:27:55 DISPATCHER: Trying to submit another job.
21:27:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:27:55 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:27:55 HBMASTER: Trying to run another job!
21:27:55 job_callback for (0, 0, 17) finished
21:27:55 HBMASTER: schedule new run for iteration 0
21:27:55 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
21:27:55 HBMASTER: submitting job (0, 0, 22) to dispatcher
21:27:55 DISPATCHER: trying to submit job (0, 0, 22)
21:27:55 DISPATCHER: trying to notify the job_runner thread.
21:27:55 HBMASTER: job (0, 0, 22) submitted to dispatcher
21:27:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:27:55 DISPATCHER: Trying to submit another job.
21:27:55 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:27:55 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:27:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:27:55 WORKER: start processing job (0, 0, 22)
21:27:55 WORKER: args: ()
21:27:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 537, 'last_n_outputs': 18, 'leak_rate': 0.9145625166275464, 'lr': 0.004012863564213359, 'optimizer': 'Adam', 'sparsity': 0.8749910182223402, 'steps_to_train': 83, 'weight_decay': 0.07707331488126659}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:28:38 DISPATCHER: Starting worker discovery
21:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:38 DISPATCHER: Finished worker discovery
21:29:38 DISPATCHER: Starting worker discovery
21:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:38 DISPATCHER: Finished worker discovery
21:30:20 WORKER: done with job (0, 0, 22), trying to register it.
21:30:20 WORKER: registered result for job (0, 0, 22) with dispatcher
21:30:20 DISPATCHER: job (0, 0, 22) finished
21:30:20 DISPATCHER: register_result: lock acquired
21:30:20 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:30:20 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 537, 'last_n_outputs': 18, 'leak_rate': 0.9145625166275464, 'lr': 0.004012863564213359, 'optimizer': 'Adam', 'sparsity': 0.8749910182223402, 'steps_to_train': 83, 'weight_decay': 0.07707331488126659}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7587869723481769, 'info': {'number_mnist': 0.7587869723481769, 'config': "{'batch_size': 64, 'hidden_dim': 537, 'last_n_outputs': 18, 'leak_rate': 0.9145625166275464, 'lr': 0.004012863564213359, 'optimizer': 'Adam', 'sparsity': 0.8749910182223402, 'steps_to_train': 83, 'weight_decay': 0.07707331488126659}"}}
exception: None

21:30:20 job_callback for (0, 0, 22) started
21:30:20 DISPATCHER: Trying to submit another job.
21:30:20 job_callback for (0, 0, 22) got condition
21:30:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:30:20 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:30:20 HBMASTER: Trying to run another job!
21:30:20 job_callback for (0, 0, 22) finished
21:30:20 HBMASTER: schedule new run for iteration 0
21:30:20 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
21:30:20 HBMASTER: submitting job (0, 0, 24) to dispatcher
21:30:20 DISPATCHER: trying to submit job (0, 0, 24)
21:30:20 DISPATCHER: trying to notify the job_runner thread.
21:30:20 HBMASTER: job (0, 0, 24) submitted to dispatcher
21:30:20 DISPATCHER: Trying to submit another job.
21:30:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:30:20 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:30:20 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:30:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:30:20 WORKER: start processing job (0, 0, 24)
21:30:20 WORKER: args: ()
21:30:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 629, 'last_n_outputs': 42, 'leak_rate': 0.8979654428534103, 'lr': 0.004226475550415295, 'optimizer': 'Adam', 'sparsity': 0.7523411390681075, 'steps_to_train': 44, 'weight_decay': 0.025763236544710657}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:30:38 DISPATCHER: Starting worker discovery
21:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:38 DISPATCHER: Finished worker discovery
21:31:38 DISPATCHER: Starting worker discovery
21:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:38 DISPATCHER: Finished worker discovery
21:32:38 DISPATCHER: Starting worker discovery
21:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:38 DISPATCHER: Finished worker discovery
21:32:44 WORKER: done with job (0, 0, 24), trying to register it.
21:32:44 WORKER: registered result for job (0, 0, 24) with dispatcher
21:32:44 DISPATCHER: job (0, 0, 24) finished
21:32:44 DISPATCHER: register_result: lock acquired
21:32:44 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:32:44 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 629, 'last_n_outputs': 42, 'leak_rate': 0.8979654428534103, 'lr': 0.004226475550415295, 'optimizer': 'Adam', 'sparsity': 0.7523411390681075, 'steps_to_train': 44, 'weight_decay': 0.025763236544710657}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7400877494094474, 'info': {'number_mnist': 0.7400877494094474, 'config': "{'batch_size': 64, 'hidden_dim': 629, 'last_n_outputs': 42, 'leak_rate': 0.8979654428534103, 'lr': 0.004226475550415295, 'optimizer': 'Adam', 'sparsity': 0.7523411390681075, 'steps_to_train': 44, 'weight_decay': 0.025763236544710657}"}}
exception: None

21:32:44 job_callback for (0, 0, 24) started
21:32:44 DISPATCHER: Trying to submit another job.
21:32:44 job_callback for (0, 0, 24) got condition
21:32:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:32:44 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:32:44 HBMASTER: Trying to run another job!
21:32:44 job_callback for (0, 0, 24) finished
21:32:44 HBMASTER: schedule new run for iteration 0
21:32:44 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
21:32:44 HBMASTER: submitting job (0, 0, 26) to dispatcher
21:32:44 DISPATCHER: trying to submit job (0, 0, 26)
21:32:44 DISPATCHER: trying to notify the job_runner thread.
21:32:44 HBMASTER: job (0, 0, 26) submitted to dispatcher
21:32:44 DISPATCHER: Trying to submit another job.
21:32:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:32:44 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:32:44 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:32:44 WORKER: start processing job (0, 0, 26)
21:32:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:32:44 WORKER: args: ()
21:32:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:33:38 DISPATCHER: Starting worker discovery
21:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:38 DISPATCHER: Finished worker discovery
21:34:38 DISPATCHER: Starting worker discovery
21:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:38 DISPATCHER: Finished worker discovery
21:35:08 WORKER: done with job (0, 0, 26), trying to register it.
21:35:08 WORKER: registered result for job (0, 0, 26) with dispatcher
21:35:08 DISPATCHER: job (0, 0, 26) finished
21:35:08 DISPATCHER: register_result: lock acquired
21:35:08 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:35:08 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9015482883918846, 'info': {'number_mnist': 0.9015482883918846, 'config': "{'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}"}}
exception: None

21:35:08 job_callback for (0, 0, 26) started
21:35:08 DISPATCHER: Trying to submit another job.
21:35:08 job_callback for (0, 0, 26) got condition
21:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:35:08 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
21:35:08 HBMASTER: Trying to run another job!
21:35:08 job_callback for (0, 0, 26) finished
21:35:08 ITERATION: Advancing config (0, 0, 1) to next budget 400.000000
21:35:08 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
21:35:08 ITERATION: Advancing config (0, 0, 26) to next budget 400.000000
21:35:08 HBMASTER: schedule new run for iteration 0
21:35:08 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
21:35:08 HBMASTER: submitting job (0, 0, 1) to dispatcher
21:35:08 DISPATCHER: trying to submit job (0, 0, 1)
21:35:08 DISPATCHER: trying to notify the job_runner thread.
21:35:08 HBMASTER: job (0, 0, 1) submitted to dispatcher
21:35:08 DISPATCHER: Trying to submit another job.
21:35:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:35:08 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:35:08 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:35:08 WORKER: start processing job (0, 0, 1)
21:35:08 WORKER: args: ()
21:35:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}, 'budget': 400.0, 'working_directory': '.'}
21:35:38 DISPATCHER: Starting worker discovery
21:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:38 DISPATCHER: Finished worker discovery
21:36:38 DISPATCHER: Starting worker discovery
21:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:38 DISPATCHER: Finished worker discovery
21:37:38 DISPATCHER: Starting worker discovery
21:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:38 DISPATCHER: Finished worker discovery
21:38:38 DISPATCHER: Starting worker discovery
21:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:38 DISPATCHER: Finished worker discovery
21:39:38 DISPATCHER: Starting worker discovery
21:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:38 DISPATCHER: Finished worker discovery
21:40:38 DISPATCHER: Starting worker discovery
21:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:38 DISPATCHER: Finished worker discovery
21:41:38 DISPATCHER: Starting worker discovery
21:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:38 DISPATCHER: Finished worker discovery
21:42:04 WORKER: done with job (0, 0, 1), trying to register it.
21:42:04 WORKER: registered result for job (0, 0, 1) with dispatcher
21:42:04 DISPATCHER: job (0, 0, 1) finished
21:42:04 DISPATCHER: register_result: lock acquired
21:42:04 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:42:04 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9179043945331573, 'info': {'number_mnist': 0.9179043945331573, 'config': "{'batch_size': 32, 'hidden_dim': 580, 'last_n_outputs': 30, 'leak_rate': 0.9518547455344641, 'lr': 0.0038883382115860337, 'optimizer': 'SGD', 'sparsity': 0.9678751011067943, 'steps_to_train': 38, 'weight_decay': 0.0321834869726467}"}}
exception: None

21:42:04 job_callback for (0, 0, 1) started
21:42:04 DISPATCHER: Trying to submit another job.
21:42:04 job_callback for (0, 0, 1) got condition
21:42:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:42:04 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:42:04 HBMASTER: Trying to run another job!
21:42:04 job_callback for (0, 0, 1) finished
21:42:04 HBMASTER: schedule new run for iteration 0
21:42:04 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
21:42:04 HBMASTER: submitting job (0, 0, 15) to dispatcher
21:42:04 DISPATCHER: trying to submit job (0, 0, 15)
21:42:04 DISPATCHER: trying to notify the job_runner thread.
21:42:04 HBMASTER: job (0, 0, 15) submitted to dispatcher
21:42:04 DISPATCHER: Trying to submit another job.
21:42:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:42:04 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:42:04 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:42:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:42:04 WORKER: start processing job (0, 0, 15)
21:42:04 WORKER: args: ()
21:42:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 400.0, 'working_directory': '.'}
21:42:38 DISPATCHER: Starting worker discovery
21:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:38 DISPATCHER: Finished worker discovery
21:43:38 DISPATCHER: Starting worker discovery
21:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:38 DISPATCHER: Finished worker discovery
21:44:38 DISPATCHER: Starting worker discovery
21:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:38 DISPATCHER: Finished worker discovery
21:45:38 DISPATCHER: Starting worker discovery
21:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:38 DISPATCHER: Finished worker discovery
21:46:38 DISPATCHER: Starting worker discovery
21:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:38 DISPATCHER: Finished worker discovery
21:47:38 DISPATCHER: Starting worker discovery
21:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:38 DISPATCHER: Finished worker discovery
21:48:38 DISPATCHER: Starting worker discovery
21:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:38 DISPATCHER: Finished worker discovery
21:49:00 WORKER: done with job (0, 0, 15), trying to register it.
21:49:00 WORKER: registered result for job (0, 0, 15) with dispatcher
21:49:00 DISPATCHER: job (0, 0, 15) finished
21:49:00 DISPATCHER: register_result: lock acquired
21:49:00 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:49:00 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9330796781313372, 'info': {'number_mnist': 0.9330796781313372, 'config': "{'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}"}}
exception: None

21:49:00 job_callback for (0, 0, 15) started
21:49:00 DISPATCHER: Trying to submit another job.
21:49:00 job_callback for (0, 0, 15) got condition
21:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:49:00 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:49:00 HBMASTER: Trying to run another job!
21:49:00 job_callback for (0, 0, 15) finished
21:49:00 HBMASTER: schedule new run for iteration 0
21:49:00 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
21:49:00 HBMASTER: submitting job (0, 0, 26) to dispatcher
21:49:00 DISPATCHER: trying to submit job (0, 0, 26)
21:49:00 DISPATCHER: trying to notify the job_runner thread.
21:49:00 HBMASTER: job (0, 0, 26) submitted to dispatcher
21:49:00 DISPATCHER: Trying to submit another job.
21:49:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:49:00 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:49:00 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:49:00 WORKER: start processing job (0, 0, 26)
21:49:00 WORKER: args: ()
21:49:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}, 'budget': 400.0, 'working_directory': '.'}
21:49:38 DISPATCHER: Starting worker discovery
21:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:38 DISPATCHER: Finished worker discovery
21:50:38 DISPATCHER: Starting worker discovery
21:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:38 DISPATCHER: Finished worker discovery
21:51:38 DISPATCHER: Starting worker discovery
21:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:38 DISPATCHER: Finished worker discovery
21:52:38 DISPATCHER: Starting worker discovery
21:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:38 DISPATCHER: Finished worker discovery
21:53:38 DISPATCHER: Starting worker discovery
21:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:38 DISPATCHER: Finished worker discovery
21:54:38 DISPATCHER: Starting worker discovery
21:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:38 DISPATCHER: Finished worker discovery
21:55:38 DISPATCHER: Starting worker discovery
21:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:38 DISPATCHER: Finished worker discovery
21:55:54 WORKER: done with job (0, 0, 26), trying to register it.
21:55:54 WORKER: registered result for job (0, 0, 26) with dispatcher
21:55:54 DISPATCHER: job (0, 0, 26) finished
21:55:54 DISPATCHER: register_result: lock acquired
21:55:54 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:55:54 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9242296697075498, 'info': {'number_mnist': 0.9242296697075498, 'config': "{'batch_size': 64, 'hidden_dim': 455, 'last_n_outputs': 32, 'leak_rate': 0.881309355401767, 'lr': 0.00411541042336288, 'optimizer': 'SGD', 'sparsity': 0.8511232325554792, 'steps_to_train': 39, 'weight_decay': 0.011540992357914948}"}}
exception: None

21:55:54 job_callback for (0, 0, 26) started
21:55:54 job_callback for (0, 0, 26) got condition
21:55:54 DISPATCHER: Trying to submit another job.
21:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:55:54 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:55:54 HBMASTER: Trying to run another job!
21:55:54 job_callback for (0, 0, 26) finished
21:55:54 ITERATION: Advancing config (0, 0, 15) to next budget 1200.000000
21:55:54 HBMASTER: schedule new run for iteration 0
21:55:54 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
21:55:54 HBMASTER: submitting job (0, 0, 15) to dispatcher
21:55:54 DISPATCHER: trying to submit job (0, 0, 15)
21:55:54 DISPATCHER: trying to notify the job_runner thread.
21:55:54 HBMASTER: job (0, 0, 15) submitted to dispatcher
21:55:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:55:54 DISPATCHER: Trying to submit another job.
21:55:54 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:55:54 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:55:54 WORKER: start processing job (0, 0, 15)
21:55:54 WORKER: args: ()
21:55:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 1200.0, 'working_directory': '.'}
21:56:38 DISPATCHER: Starting worker discovery
21:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:38 DISPATCHER: Finished worker discovery
21:57:38 DISPATCHER: Starting worker discovery
21:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:38 DISPATCHER: Finished worker discovery
21:58:38 DISPATCHER: Starting worker discovery
21:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:38 DISPATCHER: Finished worker discovery
21:59:38 DISPATCHER: Starting worker discovery
21:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:38 DISPATCHER: Finished worker discovery
22:00:38 DISPATCHER: Starting worker discovery
22:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:38 DISPATCHER: Finished worker discovery
22:01:38 DISPATCHER: Starting worker discovery
22:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:38 DISPATCHER: Finished worker discovery
22:02:38 DISPATCHER: Starting worker discovery
22:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:38 DISPATCHER: Finished worker discovery
22:03:38 DISPATCHER: Starting worker discovery
22:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:38 DISPATCHER: Finished worker discovery
22:04:38 DISPATCHER: Starting worker discovery
22:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:38 DISPATCHER: Finished worker discovery
22:05:38 DISPATCHER: Starting worker discovery
22:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:38 DISPATCHER: Finished worker discovery
22:06:38 DISPATCHER: Starting worker discovery
22:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:38 DISPATCHER: Finished worker discovery
22:07:38 DISPATCHER: Starting worker discovery
22:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:38 DISPATCHER: Finished worker discovery
22:08:38 DISPATCHER: Starting worker discovery
22:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:38 DISPATCHER: Finished worker discovery
22:09:38 DISPATCHER: Starting worker discovery
22:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:38 DISPATCHER: Finished worker discovery
22:10:38 DISPATCHER: Starting worker discovery
22:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:38 DISPATCHER: Finished worker discovery
22:11:38 DISPATCHER: Starting worker discovery
22:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:38 DISPATCHER: Finished worker discovery
22:12:38 DISPATCHER: Starting worker discovery
22:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:38 DISPATCHER: Finished worker discovery
22:13:38 DISPATCHER: Starting worker discovery
22:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:38 DISPATCHER: Finished worker discovery
22:14:38 DISPATCHER: Starting worker discovery
22:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:38 DISPATCHER: Finished worker discovery
22:15:38 DISPATCHER: Starting worker discovery
22:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:38 DISPATCHER: Finished worker discovery
22:16:30 WORKER: done with job (0, 0, 15), trying to register it.
22:16:30 WORKER: registered result for job (0, 0, 15) with dispatcher
22:16:30 DISPATCHER: job (0, 0, 15) finished
22:16:30 DISPATCHER: register_result: lock acquired
22:16:30 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:16:30 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9372475307809907, 'info': {'number_mnist': 0.9372475307809907, 'config': "{'batch_size': 16, 'hidden_dim': 883, 'last_n_outputs': 21, 'leak_rate': 0.7722005574803851, 'lr': 0.004582211027673508, 'optimizer': 'SGD', 'sparsity': 0.9312040886869429, 'steps_to_train': 38, 'weight_decay': 0.02662487830673106}"}}
exception: None

22:16:30 job_callback for (0, 0, 15) started
22:16:30 DISPATCHER: Trying to submit another job.
22:16:30 job_callback for (0, 0, 15) got condition
22:16:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:30 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
22:16:30 HBMASTER: Trying to run another job!
22:16:30 job_callback for (0, 0, 15) finished
22:16:30 start sampling a new configuration.
22:16:30 best_vector: [1, 0.8461878222654898, 0.23342083064200558, 0.889132001416968, 0.039278112816018784, 1, 0.7536150948409924, 0.5359920988397662, 0.9913719240438137], 0.003920722330301594, 0.1106067428272118, 0.0004336583264845749
22:16:30 done sampling a new configuration.
22:16:30 HBMASTER: schedule new run for iteration 1
22:16:30 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
22:16:30 HBMASTER: submitting job (1, 0, 0) to dispatcher
22:16:30 DISPATCHER: trying to submit job (1, 0, 0)
22:16:30 DISPATCHER: trying to notify the job_runner thread.
22:16:30 HBMASTER: job (1, 0, 0) submitted to dispatcher
22:16:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:30 DISPATCHER: Trying to submit another job.
22:16:30 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:16:30 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:16:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:30 WORKER: start processing job (1, 0, 0)
22:16:30 WORKER: args: ()
22:16:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 877, 'last_n_outputs': 19, 'leak_rate': 0.972283000354242, 'lr': 0.0011982742468875133, 'optimizer': 'SGD', 'sparsity': 0.9308676227618382, 'steps_to_train': 58, 'weight_decay': 0.19489675580616767}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:16:38 DISPATCHER: Starting worker discovery
22:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:38 DISPATCHER: Finished worker discovery
22:17:38 DISPATCHER: Starting worker discovery
22:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:38 DISPATCHER: Finished worker discovery
22:18:38 DISPATCHER: Starting worker discovery
22:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:38 DISPATCHER: Finished worker discovery
22:18:54 WORKER: done with job (1, 0, 0), trying to register it.
22:18:54 WORKER: registered result for job (1, 0, 0) with dispatcher
22:18:54 DISPATCHER: job (1, 0, 0) finished
22:18:54 DISPATCHER: register_result: lock acquired
22:18:54 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:18:54 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 877, 'last_n_outputs': 19, 'leak_rate': 0.972283000354242, 'lr': 0.0011982742468875133, 'optimizer': 'SGD', 'sparsity': 0.9308676227618382, 'steps_to_train': 58, 'weight_decay': 0.19489675580616767}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8686271319072539, 'info': {'number_mnist': 0.8686271319072539, 'config': "{'batch_size': 32, 'hidden_dim': 877, 'last_n_outputs': 19, 'leak_rate': 0.972283000354242, 'lr': 0.0011982742468875133, 'optimizer': 'SGD', 'sparsity': 0.9308676227618382, 'steps_to_train': 58, 'weight_decay': 0.19489675580616767}"}}
exception: None

22:18:54 job_callback for (1, 0, 0) started
22:18:54 job_callback for (1, 0, 0) got condition
22:18:54 DISPATCHER: Trying to submit another job.
22:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:54 HBMASTER: Trying to run another job!
22:18:54 job_callback for (1, 0, 0) finished
22:18:54 start sampling a new configuration.
22:18:54 done sampling a new configuration.
22:18:54 HBMASTER: schedule new run for iteration 1
22:18:54 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
22:18:54 HBMASTER: submitting job (1, 0, 1) to dispatcher
22:18:54 DISPATCHER: trying to submit job (1, 0, 1)
22:18:54 DISPATCHER: trying to notify the job_runner thread.
22:18:54 HBMASTER: job (1, 0, 1) submitted to dispatcher
22:18:54 DISPATCHER: Trying to submit another job.
22:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:54 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:18:54 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:54 WORKER: start processing job (1, 0, 1)
22:18:54 WORKER: args: ()
22:18:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 466, 'last_n_outputs': 30, 'leak_rate': 0.9646077725966722, 'lr': 0.057344863680800766, 'optimizer': 'SGD', 'sparsity': 0.8035653422794244, 'steps_to_train': 59, 'weight_decay': 0.048893815524432595}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:19:38 DISPATCHER: Starting worker discovery
22:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:38 DISPATCHER: Finished worker discovery
22:20:38 DISPATCHER: Starting worker discovery
22:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:38 DISPATCHER: Finished worker discovery
22:21:17 WORKER: done with job (1, 0, 1), trying to register it.
22:21:17 WORKER: registered result for job (1, 0, 1) with dispatcher
22:21:17 DISPATCHER: job (1, 0, 1) finished
22:21:17 DISPATCHER: register_result: lock acquired
22:21:17 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:21:17 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 466, 'last_n_outputs': 30, 'leak_rate': 0.9646077725966722, 'lr': 0.057344863680800766, 'optimizer': 'SGD', 'sparsity': 0.8035653422794244, 'steps_to_train': 59, 'weight_decay': 0.048893815524432595}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8165320200689287, 'info': {'number_mnist': 0.8165320200689287, 'config': "{'batch_size': 128, 'hidden_dim': 466, 'last_n_outputs': 30, 'leak_rate': 0.9646077725966722, 'lr': 0.057344863680800766, 'optimizer': 'SGD', 'sparsity': 0.8035653422794244, 'steps_to_train': 59, 'weight_decay': 0.048893815524432595}"}}
exception: None

22:21:17 job_callback for (1, 0, 1) started
22:21:17 DISPATCHER: Trying to submit another job.
22:21:17 job_callback for (1, 0, 1) got condition
22:21:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:21:17 HBMASTER: Trying to run another job!
22:21:17 job_callback for (1, 0, 1) finished
22:21:17 start sampling a new configuration.
22:21:17 best_vector: [0, 0.42091192084849194, 0.5617907190005941, 0.742288371510232, 0.20198197510476507, 1, 0.47305835203252744, 0.5588167614471973, 0.17790955237272194], 0.00680950098098361, 0.5588729081360757, 0.0038056456161977706
22:21:17 done sampling a new configuration.
22:21:17 HBMASTER: schedule new run for iteration 1
22:21:17 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
22:21:17 HBMASTER: submitting job (1, 0, 2) to dispatcher
22:21:17 DISPATCHER: trying to submit job (1, 0, 2)
22:21:17 DISPATCHER: trying to notify the job_runner thread.
22:21:17 HBMASTER: job (1, 0, 2) submitted to dispatcher
22:21:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:21:17 DISPATCHER: Trying to submit another job.
22:21:17 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:21:17 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:21:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:21:17 WORKER: start processing job (1, 0, 2)
22:21:17 WORKER: args: ()
22:21:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 33, 'leak_rate': 0.9355720928775579, 'lr': 0.0025349182040090086, 'optimizer': 'SGD', 'sparsity': 0.8635340044878066, 'steps_to_train': 60, 'weight_decay': 0.017039845949032257}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:21:38 DISPATCHER: Starting worker discovery
22:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:38 DISPATCHER: Finished worker discovery
22:22:38 DISPATCHER: Starting worker discovery
22:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:38 DISPATCHER: Finished worker discovery
22:23:38 DISPATCHER: Starting worker discovery
22:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:38 DISPATCHER: Finished worker discovery
22:23:41 WORKER: done with job (1, 0, 2), trying to register it.
22:23:41 WORKER: registered result for job (1, 0, 2) with dispatcher
22:23:41 DISPATCHER: job (1, 0, 2) finished
22:23:41 DISPATCHER: register_result: lock acquired
22:23:41 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:23:41 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 33, 'leak_rate': 0.9355720928775579, 'lr': 0.0025349182040090086, 'optimizer': 'SGD', 'sparsity': 0.8635340044878066, 'steps_to_train': 60, 'weight_decay': 0.017039845949032257}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8961128838988706, 'info': {'number_mnist': 0.8961128838988706, 'config': "{'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 33, 'leak_rate': 0.9355720928775579, 'lr': 0.0025349182040090086, 'optimizer': 'SGD', 'sparsity': 0.8635340044878066, 'steps_to_train': 60, 'weight_decay': 0.017039845949032257}"}}
exception: None

22:23:41 job_callback for (1, 0, 2) started
22:23:41 DISPATCHER: Trying to submit another job.
22:23:41 job_callback for (1, 0, 2) got condition
22:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:41 HBMASTER: Trying to run another job!
22:23:41 job_callback for (1, 0, 2) finished
22:23:41 start sampling a new configuration.
22:23:41 best_vector: [2, 0.8200404200653201, 0.49536518775590044, 0.03659881055391195, 0.22790800589922477, 1, 0.7599511229560708, 0.5436331148869822, 0.19148165304775777], 0.006137452047174329, 0.21359348113534052, 0.0013109197480571872
22:23:41 done sampling a new configuration.
22:23:41 HBMASTER: schedule new run for iteration 1
22:23:41 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
22:23:41 HBMASTER: submitting job (1, 0, 3) to dispatcher
22:23:41 DISPATCHER: trying to submit job (1, 0, 3)
22:23:41 DISPATCHER: trying to notify the job_runner thread.
22:23:41 HBMASTER: job (1, 0, 3) submitted to dispatcher
22:23:41 DISPATCHER: Trying to submit another job.
22:23:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:41 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:23:41 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:41 WORKER: start processing job (1, 0, 3)
22:23:41 WORKER: args: ()
22:23:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:24:38 DISPATCHER: Starting worker discovery
22:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:38 DISPATCHER: Finished worker discovery
22:25:38 DISPATCHER: Starting worker discovery
22:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:38 DISPATCHER: Finished worker discovery
22:26:05 WORKER: done with job (1, 0, 3), trying to register it.
22:26:05 WORKER: registered result for job (1, 0, 3) with dispatcher
22:26:05 DISPATCHER: job (1, 0, 3) finished
22:26:05 DISPATCHER: register_result: lock acquired
22:26:05 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:26:05 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9180508241170185, 'info': {'number_mnist': 0.9180508241170185, 'config': "{'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}"}}
exception: None

22:26:05 job_callback for (1, 0, 3) started
22:26:05 DISPATCHER: Trying to submit another job.
22:26:05 job_callback for (1, 0, 3) got condition
22:26:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:26:05 HBMASTER: Trying to run another job!
22:26:05 job_callback for (1, 0, 3) finished
22:26:05 start sampling a new configuration.
22:26:05 best_vector: [3, 0.40342662446159894, 0.22741109840045154, 0.302659202257752, 0.1701410817882348, 1, 0.6246393745645152, 0.16119962578753477, 0.027245763672996224], 0.011688638803263415, 0.10459144462470922, 0.001222531618129753
22:26:05 done sampling a new configuration.
22:26:05 HBMASTER: schedule new run for iteration 1
22:26:05 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
22:26:05 HBMASTER: submitting job (1, 0, 4) to dispatcher
22:26:05 DISPATCHER: trying to submit job (1, 0, 4)
22:26:05 DISPATCHER: trying to notify the job_runner thread.
22:26:05 HBMASTER: job (1, 0, 4) submitted to dispatcher
22:26:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:26:05 DISPATCHER: Trying to submit another job.
22:26:05 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:26:05 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:26:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:26:05 WORKER: start processing job (1, 0, 4)
22:26:05 WORKER: args: ()
22:26:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 19, 'leak_rate': 0.825664800564438, 'lr': 0.002189183486872639, 'optimizer': 'SGD', 'sparsity': 0.8999134498954837, 'steps_to_train': 24, 'weight_decay': 0.010850445147311677}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:26:38 DISPATCHER: Starting worker discovery
22:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:38 DISPATCHER: Finished worker discovery
22:27:38 DISPATCHER: Starting worker discovery
22:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:38 DISPATCHER: Finished worker discovery
22:28:31 WORKER: done with job (1, 0, 4), trying to register it.
22:28:31 WORKER: registered result for job (1, 0, 4) with dispatcher
22:28:31 DISPATCHER: job (1, 0, 4) finished
22:28:31 DISPATCHER: register_result: lock acquired
22:28:31 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:28:31 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 19, 'leak_rate': 0.825664800564438, 'lr': 0.002189183486872639, 'optimizer': 'SGD', 'sparsity': 0.8999134498954837, 'steps_to_train': 24, 'weight_decay': 0.010850445147311677}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8959770350244075, 'info': {'number_mnist': 0.8959770350244075, 'config': "{'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 19, 'leak_rate': 0.825664800564438, 'lr': 0.002189183486872639, 'optimizer': 'SGD', 'sparsity': 0.8999134498954837, 'steps_to_train': 24, 'weight_decay': 0.010850445147311677}"}}
exception: None

22:28:31 job_callback for (1, 0, 4) started
22:28:31 DISPATCHER: Trying to submit another job.
22:28:31 job_callback for (1, 0, 4) got condition
22:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:28:31 HBMASTER: Trying to run another job!
22:28:31 job_callback for (1, 0, 4) finished
22:28:31 start sampling a new configuration.
22:28:31 best_vector: [3, 0.16209352600579666, 0.28315143473347465, 0.9882103372610961, 0.19309717286964406, 1, 0.5294321123814958, 0.6886548087996215, 0.20358971682011973], 0.0026652217699830254, 0.12742177958198586, 0.0003396073009118873
22:28:31 done sampling a new configuration.
22:28:31 HBMASTER: schedule new run for iteration 1
22:28:31 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
22:28:31 HBMASTER: submitting job (1, 0, 5) to dispatcher
22:28:31 DISPATCHER: trying to submit job (1, 0, 5)
22:28:31 DISPATCHER: trying to notify the job_runner thread.
22:28:31 HBMASTER: job (1, 0, 5) submitted to dispatcher
22:28:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:28:31 DISPATCHER: Trying to submit another job.
22:28:31 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:28:31 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:28:31 WORKER: start processing job (1, 0, 5)
22:28:31 WORKER: args: ()
22:28:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 329, 'last_n_outputs': 21, 'leak_rate': 0.997052584315274, 'lr': 0.0024332926581016167, 'optimizer': 'SGD', 'sparsity': 0.877063706971559, 'steps_to_train': 72, 'weight_decay': 0.018402478897590648}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:28:38 DISPATCHER: Starting worker discovery
22:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:38 DISPATCHER: Finished worker discovery
22:29:38 DISPATCHER: Starting worker discovery
22:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:38 DISPATCHER: Finished worker discovery
22:30:38 DISPATCHER: Starting worker discovery
22:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:38 DISPATCHER: Finished worker discovery
22:30:54 WORKER: done with job (1, 0, 5), trying to register it.
22:30:54 WORKER: registered result for job (1, 0, 5) with dispatcher
22:30:54 DISPATCHER: job (1, 0, 5) finished
22:30:54 DISPATCHER: register_result: lock acquired
22:30:54 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:30:54 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 329, 'last_n_outputs': 21, 'leak_rate': 0.997052584315274, 'lr': 0.0024332926581016167, 'optimizer': 'SGD', 'sparsity': 0.877063706971559, 'steps_to_train': 72, 'weight_decay': 0.018402478897590648}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8550432496994272, 'info': {'number_mnist': 0.8550432496994272, 'config': "{'batch_size': 128, 'hidden_dim': 329, 'last_n_outputs': 21, 'leak_rate': 0.997052584315274, 'lr': 0.0024332926581016167, 'optimizer': 'SGD', 'sparsity': 0.877063706971559, 'steps_to_train': 72, 'weight_decay': 0.018402478897590648}"}}
exception: None

22:30:54 job_callback for (1, 0, 5) started
22:30:54 job_callback for (1, 0, 5) got condition
22:30:54 DISPATCHER: Trying to submit another job.
22:30:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:30:54 HBMASTER: Trying to run another job!
22:30:54 job_callback for (1, 0, 5) finished
22:30:54 start sampling a new configuration.
22:30:54 best_vector: [3, 0.32939390454309503, 0.3404460131470938, 0.9271831438044598, 0.32163968103967716, 1, 0.9144384361573689, 0.4154719504012264, 0.16461455973525316], 0.00396071264969046, 0.5733404063169943, 0.002270836599878388
22:30:54 done sampling a new configuration.
22:30:54 HBMASTER: schedule new run for iteration 1
22:30:54 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
22:30:54 HBMASTER: submitting job (1, 0, 6) to dispatcher
22:30:54 DISPATCHER: trying to submit job (1, 0, 6)
22:30:54 DISPATCHER: trying to notify the job_runner thread.
22:30:54 HBMASTER: job (1, 0, 6) submitted to dispatcher
22:30:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:30:54 DISPATCHER: Trying to submit another job.
22:30:54 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:30:54 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:30:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:30:54 WORKER: start processing job (1, 0, 6)
22:30:54 WORKER: args: ()
22:30:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 463, 'last_n_outputs': 23, 'leak_rate': 0.9817957859511149, 'lr': 0.004398244437174426, 'optimizer': 'SGD', 'sparsity': 0.9694652246777685, 'steps_to_train': 47, 'weight_decay': 0.016374516302228408}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:31:38 DISPATCHER: Starting worker discovery
22:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:38 DISPATCHER: Finished worker discovery
22:32:38 DISPATCHER: Starting worker discovery
22:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:38 DISPATCHER: Finished worker discovery
22:33:18 WORKER: done with job (1, 0, 6), trying to register it.
22:33:18 WORKER: registered result for job (1, 0, 6) with dispatcher
22:33:18 DISPATCHER: job (1, 0, 6) finished
22:33:18 DISPATCHER: register_result: lock acquired
22:33:18 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:33:18 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 463, 'last_n_outputs': 23, 'leak_rate': 0.9817957859511149, 'lr': 0.004398244437174426, 'optimizer': 'SGD', 'sparsity': 0.9694652246777685, 'steps_to_train': 47, 'weight_decay': 0.016374516302228408}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9217725371218921, 'info': {'number_mnist': 0.9217725371218921, 'config': "{'batch_size': 128, 'hidden_dim': 463, 'last_n_outputs': 23, 'leak_rate': 0.9817957859511149, 'lr': 0.004398244437174426, 'optimizer': 'SGD', 'sparsity': 0.9694652246777685, 'steps_to_train': 47, 'weight_decay': 0.016374516302228408}"}}
exception: None

22:33:18 job_callback for (1, 0, 6) started
22:33:18 DISPATCHER: Trying to submit another job.
22:33:18 job_callback for (1, 0, 6) got condition
22:33:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:33:18 HBMASTER: Trying to run another job!
22:33:18 job_callback for (1, 0, 6) finished
22:33:18 start sampling a new configuration.
22:33:18 best_vector: [2, 0.12234302365656613, 0.862075856170713, 0.4743346195837115, 0.2584013828624869, 1, 0.7294931492942143, 0.4888809248830882, 0.04380059809975956], 0.0042949480222503845, 0.15209629837110278, 0.0006532456958805722
22:33:18 done sampling a new configuration.
22:33:18 HBMASTER: schedule new run for iteration 1
22:33:18 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
22:33:18 HBMASTER: submitting job (1, 0, 7) to dispatcher
22:33:18 DISPATCHER: trying to submit job (1, 0, 7)
22:33:18 DISPATCHER: trying to notify the job_runner thread.
22:33:18 HBMASTER: job (1, 0, 7) submitted to dispatcher
22:33:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:33:18 DISPATCHER: Trying to submit another job.
22:33:18 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:33:18 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:33:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:33:18 WORKER: start processing job (1, 0, 7)
22:33:18 WORKER: args: ()
22:33:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 297, 'last_n_outputs': 45, 'leak_rate': 0.8685836548959278, 'lr': 0.0032870231724269634, 'optimizer': 'SGD', 'sparsity': 0.9250783558306115, 'steps_to_train': 54, 'weight_decay': 0.011402127471801004}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:33:38 DISPATCHER: Starting worker discovery
22:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:38 DISPATCHER: Finished worker discovery
22:34:38 DISPATCHER: Starting worker discovery
22:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:38 DISPATCHER: Finished worker discovery
22:35:38 DISPATCHER: Starting worker discovery
22:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:38 DISPATCHER: Finished worker discovery
22:35:42 WORKER: done with job (1, 0, 7), trying to register it.
22:35:42 WORKER: registered result for job (1, 0, 7) with dispatcher
22:35:42 DISPATCHER: job (1, 0, 7) finished
22:35:42 DISPATCHER: register_result: lock acquired
22:35:42 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:35:42 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 297, 'last_n_outputs': 45, 'leak_rate': 0.8685836548959278, 'lr': 0.0032870231724269634, 'optimizer': 'SGD', 'sparsity': 0.9250783558306115, 'steps_to_train': 54, 'weight_decay': 0.011402127471801004}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8523531920755798, 'info': {'number_mnist': 0.8523531920755798, 'config': "{'batch_size': 64, 'hidden_dim': 297, 'last_n_outputs': 45, 'leak_rate': 0.8685836548959278, 'lr': 0.0032870231724269634, 'optimizer': 'SGD', 'sparsity': 0.9250783558306115, 'steps_to_train': 54, 'weight_decay': 0.011402127471801004}"}}
exception: None

22:35:42 job_callback for (1, 0, 7) started
22:35:42 DISPATCHER: Trying to submit another job.
22:35:42 job_callback for (1, 0, 7) got condition
22:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:42 HBMASTER: Trying to run another job!
22:35:42 job_callback for (1, 0, 7) finished
22:35:42 start sampling a new configuration.
22:35:42 best_vector: [3, 0.06560222474560629, 0.5850189792986709, 0.9081027909522854, 0.17607246404235108, 1, 0.5759816300218304, 0.6024603958011221, 0.28637505468928354], 0.0028843817856259208, 0.40489544506760156, 0.0011678730468358905
22:35:42 done sampling a new configuration.
22:35:42 HBMASTER: schedule new run for iteration 1
22:35:42 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
22:35:42 HBMASTER: submitting job (1, 0, 8) to dispatcher
22:35:42 DISPATCHER: trying to submit job (1, 0, 8)
22:35:42 DISPATCHER: trying to notify the job_runner thread.
22:35:42 HBMASTER: job (1, 0, 8) submitted to dispatcher
22:35:42 DISPATCHER: Trying to submit another job.
22:35:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:42 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:35:42 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:42 WORKER: start processing job (1, 0, 8)
22:35:42 WORKER: args: ()
22:35:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 252, 'last_n_outputs': 33, 'leak_rate': 0.9770256977380714, 'lr': 0.002249805261399023, 'optimizer': 'SGD', 'sparsity': 0.8882355912052393, 'steps_to_train': 64, 'weight_decay': 0.02358210323073846}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:36:38 DISPATCHER: Starting worker discovery
22:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:38 DISPATCHER: Finished worker discovery
22:37:38 DISPATCHER: Starting worker discovery
22:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:38 DISPATCHER: Finished worker discovery
22:38:05 WORKER: done with job (1, 0, 8), trying to register it.
22:38:05 WORKER: registered result for job (1, 0, 8) with dispatcher
22:38:05 DISPATCHER: job (1, 0, 8) finished
22:38:05 DISPATCHER: register_result: lock acquired
22:38:05 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:38:05 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 252, 'last_n_outputs': 33, 'leak_rate': 0.9770256977380714, 'lr': 0.002249805261399023, 'optimizer': 'SGD', 'sparsity': 0.8882355912052393, 'steps_to_train': 64, 'weight_decay': 0.02358210323073846}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8530517066512018, 'info': {'number_mnist': 0.8530517066512018, 'config': "{'batch_size': 128, 'hidden_dim': 252, 'last_n_outputs': 33, 'leak_rate': 0.9770256977380714, 'lr': 0.002249805261399023, 'optimizer': 'SGD', 'sparsity': 0.8882355912052393, 'steps_to_train': 64, 'weight_decay': 0.02358210323073846}"}}
exception: None

22:38:05 job_callback for (1, 0, 8) started
22:38:05 DISPATCHER: Trying to submit another job.
22:38:05 job_callback for (1, 0, 8) got condition
22:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:38:05 HBMASTER: Trying to run another job!
22:38:05 job_callback for (1, 0, 8) finished
22:38:05 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
22:38:05 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
22:38:05 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
22:38:05 HBMASTER: schedule new run for iteration 1
22:38:05 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
22:38:05 HBMASTER: submitting job (1, 0, 2) to dispatcher
22:38:05 DISPATCHER: trying to submit job (1, 0, 2)
22:38:05 DISPATCHER: trying to notify the job_runner thread.
22:38:05 HBMASTER: job (1, 0, 2) submitted to dispatcher
22:38:05 DISPATCHER: Trying to submit another job.
22:38:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:38:05 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:38:05 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:38:05 WORKER: start processing job (1, 0, 2)
22:38:05 WORKER: args: ()
22:38:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 33, 'leak_rate': 0.9355720928775579, 'lr': 0.0025349182040090086, 'optimizer': 'SGD', 'sparsity': 0.8635340044878066, 'steps_to_train': 60, 'weight_decay': 0.017039845949032257}, 'budget': 400.0, 'working_directory': '.'}
22:38:38 DISPATCHER: Starting worker discovery
22:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:38 DISPATCHER: Finished worker discovery
22:39:38 DISPATCHER: Starting worker discovery
22:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:38 DISPATCHER: Finished worker discovery
22:40:38 DISPATCHER: Starting worker discovery
22:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:38 DISPATCHER: Finished worker discovery
22:41:38 DISPATCHER: Starting worker discovery
22:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:38 DISPATCHER: Finished worker discovery
22:42:38 DISPATCHER: Starting worker discovery
22:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:38 DISPATCHER: Finished worker discovery
22:43:38 DISPATCHER: Starting worker discovery
22:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:38 DISPATCHER: Finished worker discovery
22:44:38 DISPATCHER: Starting worker discovery
22:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:38 DISPATCHER: Finished worker discovery
22:45:00 WORKER: done with job (1, 0, 2), trying to register it.
22:45:00 WORKER: registered result for job (1, 0, 2) with dispatcher
22:45:00 DISPATCHER: job (1, 0, 2) finished
22:45:00 DISPATCHER: register_result: lock acquired
22:45:00 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:45:00 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 33, 'leak_rate': 0.9355720928775579, 'lr': 0.0025349182040090086, 'optimizer': 'SGD', 'sparsity': 0.8635340044878066, 'steps_to_train': 60, 'weight_decay': 0.017039845949032257}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9130654591983568, 'info': {'number_mnist': 0.9130654591983568, 'config': "{'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 33, 'leak_rate': 0.9355720928775579, 'lr': 0.0025349182040090086, 'optimizer': 'SGD', 'sparsity': 0.8635340044878066, 'steps_to_train': 60, 'weight_decay': 0.017039845949032257}"}}
exception: None

22:45:00 job_callback for (1, 0, 2) started
22:45:00 job_callback for (1, 0, 2) got condition
22:45:00 DISPATCHER: Trying to submit another job.
22:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:00 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:45:00 HBMASTER: Trying to run another job!
22:45:00 job_callback for (1, 0, 2) finished
22:45:00 HBMASTER: schedule new run for iteration 1
22:45:00 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
22:45:00 HBMASTER: submitting job (1, 0, 3) to dispatcher
22:45:00 DISPATCHER: trying to submit job (1, 0, 3)
22:45:00 DISPATCHER: trying to notify the job_runner thread.
22:45:00 HBMASTER: job (1, 0, 3) submitted to dispatcher
22:45:00 DISPATCHER: Trying to submit another job.
22:45:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:00 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:45:00 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:00 WORKER: start processing job (1, 0, 3)
22:45:00 WORKER: args: ()
22:45:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}, 'budget': 400.0, 'working_directory': '.'}
22:45:38 DISPATCHER: Starting worker discovery
22:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:38 DISPATCHER: Finished worker discovery
22:46:38 DISPATCHER: Starting worker discovery
22:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:38 DISPATCHER: Finished worker discovery
22:47:38 DISPATCHER: Starting worker discovery
22:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:38 DISPATCHER: Finished worker discovery
22:48:38 DISPATCHER: Starting worker discovery
22:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:38 DISPATCHER: Finished worker discovery
22:49:38 DISPATCHER: Starting worker discovery
22:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:38 DISPATCHER: Finished worker discovery
22:50:38 DISPATCHER: Starting worker discovery
22:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:38 DISPATCHER: Finished worker discovery
22:51:38 DISPATCHER: Starting worker discovery
22:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:38 DISPATCHER: Finished worker discovery
22:51:53 WORKER: done with job (1, 0, 3), trying to register it.
22:51:53 WORKER: registered result for job (1, 0, 3) with dispatcher
22:51:53 DISPATCHER: job (1, 0, 3) finished
22:51:53 DISPATCHER: register_result: lock acquired
22:51:53 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:51:53 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9325116048629662, 'info': {'number_mnist': 0.9325116048629662, 'config': "{'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}"}}
exception: None

22:51:53 job_callback for (1, 0, 3) started
22:51:53 DISPATCHER: Trying to submit another job.
22:51:53 job_callback for (1, 0, 3) got condition
22:51:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:53 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:51:53 HBMASTER: Trying to run another job!
22:51:53 job_callback for (1, 0, 3) finished
22:51:53 HBMASTER: schedule new run for iteration 1
22:51:53 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
22:51:53 HBMASTER: submitting job (1, 0, 6) to dispatcher
22:51:53 DISPATCHER: trying to submit job (1, 0, 6)
22:51:53 DISPATCHER: trying to notify the job_runner thread.
22:51:53 HBMASTER: job (1, 0, 6) submitted to dispatcher
22:51:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:53 DISPATCHER: Trying to submit another job.
22:51:53 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:51:53 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:51:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:53 WORKER: start processing job (1, 0, 6)
22:51:53 WORKER: args: ()
22:51:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 463, 'last_n_outputs': 23, 'leak_rate': 0.9817957859511149, 'lr': 0.004398244437174426, 'optimizer': 'SGD', 'sparsity': 0.9694652246777685, 'steps_to_train': 47, 'weight_decay': 0.016374516302228408}, 'budget': 400.0, 'working_directory': '.'}
22:52:38 DISPATCHER: Starting worker discovery
22:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:38 DISPATCHER: Finished worker discovery
22:53:38 DISPATCHER: Starting worker discovery
22:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:38 DISPATCHER: Finished worker discovery
22:54:38 DISPATCHER: Starting worker discovery
22:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:38 DISPATCHER: Finished worker discovery
22:55:38 DISPATCHER: Starting worker discovery
22:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:38 DISPATCHER: Finished worker discovery
22:56:38 DISPATCHER: Starting worker discovery
22:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:38 DISPATCHER: Finished worker discovery
22:57:38 DISPATCHER: Starting worker discovery
22:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:38 DISPATCHER: Finished worker discovery
22:58:38 DISPATCHER: Starting worker discovery
22:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:38 DISPATCHER: Finished worker discovery
22:58:48 WORKER: done with job (1, 0, 6), trying to register it.
22:58:48 WORKER: registered result for job (1, 0, 6) with dispatcher
22:58:48 DISPATCHER: job (1, 0, 6) finished
22:58:48 DISPATCHER: register_result: lock acquired
22:58:48 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:58:48 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 463, 'last_n_outputs': 23, 'leak_rate': 0.9817957859511149, 'lr': 0.004398244437174426, 'optimizer': 'SGD', 'sparsity': 0.9694652246777685, 'steps_to_train': 47, 'weight_decay': 0.016374516302228408}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9281787914951745, 'info': {'number_mnist': 0.9281787914951745, 'config': "{'batch_size': 128, 'hidden_dim': 463, 'last_n_outputs': 23, 'leak_rate': 0.9817957859511149, 'lr': 0.004398244437174426, 'optimizer': 'SGD', 'sparsity': 0.9694652246777685, 'steps_to_train': 47, 'weight_decay': 0.016374516302228408}"}}
exception: None

22:58:48 job_callback for (1, 0, 6) started
22:58:48 DISPATCHER: Trying to submit another job.
22:58:48 job_callback for (1, 0, 6) got condition
22:58:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:48 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:58:48 HBMASTER: Trying to run another job!
22:58:48 job_callback for (1, 0, 6) finished
22:58:48 ITERATION: Advancing config (1, 0, 3) to next budget 1200.000000
22:58:48 HBMASTER: schedule new run for iteration 1
22:58:48 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
22:58:48 HBMASTER: submitting job (1, 0, 3) to dispatcher
22:58:48 DISPATCHER: trying to submit job (1, 0, 3)
22:58:48 DISPATCHER: trying to notify the job_runner thread.
22:58:48 HBMASTER: job (1, 0, 3) submitted to dispatcher
22:58:48 DISPATCHER: Trying to submit another job.
22:58:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:48 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:58:48 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:58:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:48 WORKER: start processing job (1, 0, 3)
22:58:48 WORKER: args: ()
22:58:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}, 'budget': 1200.0, 'working_directory': '.'}
22:59:38 DISPATCHER: Starting worker discovery
22:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:38 DISPATCHER: Finished worker discovery
23:00:38 DISPATCHER: Starting worker discovery
23:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:39 DISPATCHER: Finished worker discovery
23:01:39 DISPATCHER: Starting worker discovery
23:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:39 DISPATCHER: Finished worker discovery
23:02:39 DISPATCHER: Starting worker discovery
23:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:39 DISPATCHER: Finished worker discovery
23:03:39 DISPATCHER: Starting worker discovery
23:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:39 DISPATCHER: Finished worker discovery
23:04:39 DISPATCHER: Starting worker discovery
23:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:39 DISPATCHER: Finished worker discovery
23:05:39 DISPATCHER: Starting worker discovery
23:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:39 DISPATCHER: Finished worker discovery
23:06:39 DISPATCHER: Starting worker discovery
23:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:39 DISPATCHER: Finished worker discovery
23:07:39 DISPATCHER: Starting worker discovery
23:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:39 DISPATCHER: Finished worker discovery
23:08:39 DISPATCHER: Starting worker discovery
23:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:39 DISPATCHER: Finished worker discovery
23:09:39 DISPATCHER: Starting worker discovery
23:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:39 DISPATCHER: Finished worker discovery
23:10:39 DISPATCHER: Starting worker discovery
23:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:39 DISPATCHER: Finished worker discovery
23:11:39 DISPATCHER: Starting worker discovery
23:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:39 DISPATCHER: Finished worker discovery
23:12:39 DISPATCHER: Starting worker discovery
23:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:39 DISPATCHER: Finished worker discovery
23:13:39 DISPATCHER: Starting worker discovery
23:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:39 DISPATCHER: Finished worker discovery
23:14:39 DISPATCHER: Starting worker discovery
23:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:39 DISPATCHER: Finished worker discovery
23:15:39 DISPATCHER: Starting worker discovery
23:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:39 DISPATCHER: Finished worker discovery
23:16:39 DISPATCHER: Starting worker discovery
23:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:39 DISPATCHER: Finished worker discovery
23:17:39 DISPATCHER: Starting worker discovery
23:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:39 DISPATCHER: Finished worker discovery
23:18:39 DISPATCHER: Starting worker discovery
23:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:39 DISPATCHER: Finished worker discovery
23:19:09 WORKER: done with job (1, 0, 3), trying to register it.
23:19:09 WORKER: registered result for job (1, 0, 3) with dispatcher
23:19:09 DISPATCHER: job (1, 0, 3) finished
23:19:09 DISPATCHER: register_result: lock acquired
23:19:09 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:19:09 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9330582725697698, 'info': {'number_mnist': 0.9330582725697698, 'config': "{'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 30, 'leak_rate': 0.759149702638478, 'lr': 0.0028563801858568732, 'optimizer': 'SGD', 'sparsity': 0.932388269509457, 'steps_to_train': 59, 'weight_decay': 0.017746935636543906}"}}
exception: None

23:19:09 job_callback for (1, 0, 3) started
23:19:09 job_callback for (1, 0, 3) got condition
23:19:09 DISPATCHER: Trying to submit another job.
23:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:19:09 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:19:09 HBMASTER: Trying to run another job!
23:19:09 job_callback for (1, 0, 3) finished
23:19:09 start sampling a new configuration.
23:19:10 best_vector: [3, 0.040831924114445195, 0.5539372744653798, 0.2982007639069859, 0.03898063426407872, 0, 0.7838715596360681, 0.4354241278318606, 0.006481380428981831], 0.0044806582309812664, 0.05823451464330813, 0.00026092895736373766
23:19:10 done sampling a new configuration.
23:19:10 HBMASTER: schedule new run for iteration 2
23:19:10 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
23:19:10 HBMASTER: submitting job (2, 0, 0) to dispatcher
23:19:10 DISPATCHER: trying to submit job (2, 0, 0)
23:19:10 DISPATCHER: trying to notify the job_runner thread.
23:19:10 HBMASTER: job (2, 0, 0) submitted to dispatcher
23:19:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:19:10 DISPATCHER: Trying to submit another job.
23:19:10 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:19:10 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:19:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:19:10 WORKER: start processing job (2, 0, 0)
23:19:10 WORKER: args: ()
23:19:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 232, 'last_n_outputs': 32, 'leak_rate': 0.8245501909767465, 'lr': 0.0011966338077422176, 'optimizer': 'Adam', 'sparsity': 0.9381291743126563, 'steps_to_train': 49, 'weight_decay': 0.010196062063327136}, 'budget': 400.0, 'working_directory': '.'}
23:19:39 DISPATCHER: Starting worker discovery
23:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:39 DISPATCHER: Finished worker discovery
23:20:39 DISPATCHER: Starting worker discovery
23:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:39 DISPATCHER: Finished worker discovery
23:21:39 DISPATCHER: Starting worker discovery
23:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:39 DISPATCHER: Finished worker discovery
23:22:39 DISPATCHER: Starting worker discovery
23:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:39 DISPATCHER: Finished worker discovery
23:23:39 DISPATCHER: Starting worker discovery
23:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:39 DISPATCHER: Finished worker discovery
23:24:39 DISPATCHER: Starting worker discovery
23:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:39 DISPATCHER: Finished worker discovery
23:25:39 DISPATCHER: Starting worker discovery
23:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:39 DISPATCHER: Finished worker discovery
23:26:05 WORKER: done with job (2, 0, 0), trying to register it.
23:26:05 WORKER: registered result for job (2, 0, 0) with dispatcher
23:26:05 DISPATCHER: job (2, 0, 0) finished
23:26:05 DISPATCHER: register_result: lock acquired
23:26:05 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:26:05 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 232, 'last_n_outputs': 32, 'leak_rate': 0.8245501909767465, 'lr': 0.0011966338077422176, 'optimizer': 'Adam', 'sparsity': 0.9381291743126563, 'steps_to_train': 49, 'weight_decay': 0.010196062063327136}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9282709767600743, 'info': {'number_mnist': 0.9282709767600743, 'config': "{'batch_size': 128, 'hidden_dim': 232, 'last_n_outputs': 32, 'leak_rate': 0.8245501909767465, 'lr': 0.0011966338077422176, 'optimizer': 'Adam', 'sparsity': 0.9381291743126563, 'steps_to_train': 49, 'weight_decay': 0.010196062063327136}"}}
exception: None

23:26:05 job_callback for (2, 0, 0) started
23:26:05 DISPATCHER: Trying to submit another job.
23:26:05 job_callback for (2, 0, 0) got condition
23:26:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:26:05 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:26:05 HBMASTER: Trying to run another job!
23:26:05 job_callback for (2, 0, 0) finished
23:26:05 start sampling a new configuration.
23:26:05 best_vector: [3, 0.8544912973065721, 0.28266107316000605, 0.9692586880388847, 0.15261960939507974, 1, 0.5026538931137876, 0.6023001272097172, 0.7768854749118521], 0.0030699829375512495, 0.1761463432140779, 0.0005407662681792655
23:26:05 done sampling a new configuration.
23:26:05 HBMASTER: schedule new run for iteration 2
23:26:05 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
23:26:05 HBMASTER: submitting job (2, 0, 1) to dispatcher
23:26:05 DISPATCHER: trying to submit job (2, 0, 1)
23:26:05 DISPATCHER: trying to notify the job_runner thread.
23:26:05 HBMASTER: job (2, 0, 1) submitted to dispatcher
23:26:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:26:05 DISPATCHER: Trying to submit another job.
23:26:05 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:26:05 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:26:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:26:05 WORKER: start processing job (2, 0, 1)
23:26:05 WORKER: args: ()
23:26:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 884, 'last_n_outputs': 21, 'leak_rate': 0.9923146720097211, 'lr': 0.0020194784297590347, 'optimizer': 'SGD', 'sparsity': 0.870636934347309, 'steps_to_train': 64, 'weight_decay': 0.10250647661220308}, 'budget': 400.0, 'working_directory': '.'}
23:26:39 DISPATCHER: Starting worker discovery
23:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:39 DISPATCHER: Finished worker discovery
23:27:39 DISPATCHER: Starting worker discovery
23:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:39 DISPATCHER: Finished worker discovery
23:28:39 DISPATCHER: Starting worker discovery
23:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:39 DISPATCHER: Finished worker discovery
23:29:39 DISPATCHER: Starting worker discovery
23:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:39 DISPATCHER: Finished worker discovery
23:30:39 DISPATCHER: Starting worker discovery
23:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:39 DISPATCHER: Finished worker discovery
23:31:39 DISPATCHER: Starting worker discovery
23:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:39 DISPATCHER: Finished worker discovery
23:32:39 DISPATCHER: Starting worker discovery
23:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:39 DISPATCHER: Finished worker discovery
23:32:58 WORKER: done with job (2, 0, 1), trying to register it.
23:32:58 WORKER: registered result for job (2, 0, 1) with dispatcher
23:32:58 DISPATCHER: job (2, 0, 1) finished
23:32:58 DISPATCHER: register_result: lock acquired
23:32:58 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:32:58 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 884, 'last_n_outputs': 21, 'leak_rate': 0.9923146720097211, 'lr': 0.0020194784297590347, 'optimizer': 'SGD', 'sparsity': 0.870636934347309, 'steps_to_train': 64, 'weight_decay': 0.10250647661220308}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9099572044721163, 'info': {'number_mnist': 0.9099572044721163, 'config': "{'batch_size': 128, 'hidden_dim': 884, 'last_n_outputs': 21, 'leak_rate': 0.9923146720097211, 'lr': 0.0020194784297590347, 'optimizer': 'SGD', 'sparsity': 0.870636934347309, 'steps_to_train': 64, 'weight_decay': 0.10250647661220308}"}}
exception: None

23:32:58 job_callback for (2, 0, 1) started
23:32:58 job_callback for (2, 0, 1) got condition
23:32:58 DISPATCHER: Trying to submit another job.
23:32:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:32:58 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:32:58 HBMASTER: Trying to run another job!
23:32:58 job_callback for (2, 0, 1) finished
23:32:58 start sampling a new configuration.
23:32:58 done sampling a new configuration.
23:32:58 HBMASTER: schedule new run for iteration 2
23:32:58 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
23:32:58 HBMASTER: submitting job (2, 0, 2) to dispatcher
23:32:58 DISPATCHER: trying to submit job (2, 0, 2)
23:32:58 DISPATCHER: trying to notify the job_runner thread.
23:32:58 HBMASTER: job (2, 0, 2) submitted to dispatcher
23:32:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:32:58 DISPATCHER: Trying to submit another job.
23:32:58 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:32:58 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:32:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:32:58 WORKER: start processing job (2, 0, 2)
23:32:58 WORKER: args: ()
23:32:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 23, 'leak_rate': 0.90574119835699, 'lr': 0.011558282688389269, 'optimizer': 'Adam', 'sparsity': 0.8696947899385336, 'steps_to_train': 56, 'weight_decay': 0.02733372458455521}, 'budget': 400.0, 'working_directory': '.'}
23:33:39 DISPATCHER: Starting worker discovery
23:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:39 DISPATCHER: Finished worker discovery
23:34:39 DISPATCHER: Starting worker discovery
23:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:39 DISPATCHER: Finished worker discovery
23:35:39 DISPATCHER: Starting worker discovery
23:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:39 DISPATCHER: Finished worker discovery
23:36:39 DISPATCHER: Starting worker discovery
23:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:39 DISPATCHER: Finished worker discovery
23:37:39 DISPATCHER: Starting worker discovery
23:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:39 DISPATCHER: Finished worker discovery
23:38:39 DISPATCHER: Starting worker discovery
23:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:39 DISPATCHER: Finished worker discovery
23:39:39 DISPATCHER: Starting worker discovery
23:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:39 DISPATCHER: Finished worker discovery
23:39:52 WORKER: done with job (2, 0, 2), trying to register it.
23:39:52 WORKER: registered result for job (2, 0, 2) with dispatcher
23:39:52 DISPATCHER: job (2, 0, 2) finished
23:39:52 DISPATCHER: register_result: lock acquired
23:39:52 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:39:52 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 23, 'leak_rate': 0.90574119835699, 'lr': 0.011558282688389269, 'optimizer': 'Adam', 'sparsity': 0.8696947899385336, 'steps_to_train': 56, 'weight_decay': 0.02733372458455521}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6597700438486261, 'info': {'number_mnist': 0.6597700438486261, 'config': "{'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 23, 'leak_rate': 0.90574119835699, 'lr': 0.011558282688389269, 'optimizer': 'Adam', 'sparsity': 0.8696947899385336, 'steps_to_train': 56, 'weight_decay': 0.02733372458455521}"}}
exception: None

23:39:52 job_callback for (2, 0, 2) started
23:39:52 DISPATCHER: Trying to submit another job.
23:39:52 job_callback for (2, 0, 2) got condition
23:39:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:39:52 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:39:52 HBMASTER: Trying to run another job!
23:39:52 job_callback for (2, 0, 2) finished
23:39:52 start sampling a new configuration.
23:39:52 best_vector: [3, 0.8884459994797236, 0.04832428849510245, 0.3006153539881872, 0.1692376878517512, 1, 0.4322175428239554, 0.8732032799213969, 0.6339124677143225], 0.001844859279300243, 0.4787278612631569, 0.0008831855371108944
23:39:52 done sampling a new configuration.
23:39:52 HBMASTER: schedule new run for iteration 2
23:39:52 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
23:39:52 HBMASTER: submitting job (2, 0, 3) to dispatcher
23:39:52 DISPATCHER: trying to submit job (2, 0, 3)
23:39:52 DISPATCHER: trying to notify the job_runner thread.
23:39:52 HBMASTER: job (2, 0, 3) submitted to dispatcher
23:39:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:39:52 DISPATCHER: Trying to submit another job.
23:39:52 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:39:52 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:39:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:39:52 WORKER: start processing job (2, 0, 3)
23:39:52 WORKER: args: ()
23:39:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 911, 'last_n_outputs': 11, 'leak_rate': 0.8251538384970468, 'lr': 0.002180094783314456, 'optimizer': 'SGD', 'sparsity': 0.8537322102777493, 'steps_to_train': 89, 'weight_decay': 0.06679425882624059}, 'budget': 400.0, 'working_directory': '.'}
23:40:39 DISPATCHER: Starting worker discovery
23:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:39 DISPATCHER: Finished worker discovery
23:41:39 DISPATCHER: Starting worker discovery
23:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:39 DISPATCHER: Finished worker discovery
23:42:39 DISPATCHER: Starting worker discovery
23:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:39 DISPATCHER: Finished worker discovery
23:43:39 DISPATCHER: Starting worker discovery
23:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:39 DISPATCHER: Finished worker discovery
23:44:39 DISPATCHER: Starting worker discovery
23:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:39 DISPATCHER: Finished worker discovery
23:45:39 DISPATCHER: Starting worker discovery
23:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:39 DISPATCHER: Finished worker discovery
23:46:39 DISPATCHER: Starting worker discovery
23:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:39 DISPATCHER: Finished worker discovery
23:46:45 WORKER: done with job (2, 0, 3), trying to register it.
23:46:45 WORKER: registered result for job (2, 0, 3) with dispatcher
23:46:45 DISPATCHER: job (2, 0, 3) finished
23:46:45 DISPATCHER: register_result: lock acquired
23:46:45 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:46:45 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 911, 'last_n_outputs': 11, 'leak_rate': 0.8251538384970468, 'lr': 0.002180094783314456, 'optimizer': 'SGD', 'sparsity': 0.8537322102777493, 'steps_to_train': 89, 'weight_decay': 0.06679425882624059}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8732823665960161, 'info': {'number_mnist': 0.8732823665960161, 'config': "{'batch_size': 128, 'hidden_dim': 911, 'last_n_outputs': 11, 'leak_rate': 0.8251538384970468, 'lr': 0.002180094783314456, 'optimizer': 'SGD', 'sparsity': 0.8537322102777493, 'steps_to_train': 89, 'weight_decay': 0.06679425882624059}"}}
exception: None

23:46:45 job_callback for (2, 0, 3) started
23:46:45 job_callback for (2, 0, 3) got condition
23:46:45 DISPATCHER: Trying to submit another job.
23:46:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:45 HBMASTER: Trying to run another job!
23:46:45 job_callback for (2, 0, 3) finished
23:46:45 start sampling a new configuration.
23:46:45 done sampling a new configuration.
23:46:45 HBMASTER: schedule new run for iteration 2
23:46:45 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
23:46:45 HBMASTER: submitting job (2, 0, 4) to dispatcher
23:46:45 DISPATCHER: trying to submit job (2, 0, 4)
23:46:45 DISPATCHER: trying to notify the job_runner thread.
23:46:45 HBMASTER: job (2, 0, 4) submitted to dispatcher
23:46:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:45 DISPATCHER: Trying to submit another job.
23:46:45 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:46:45 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:46:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:45 WORKER: start processing job (2, 0, 4)
23:46:45 WORKER: args: ()
23:46:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 762, 'last_n_outputs': 46, 'leak_rate': 0.9152705102029588, 'lr': 0.0030765792570823522, 'optimizer': 'Adam', 'sparsity': 0.8127870925411702, 'steps_to_train': 51, 'weight_decay': 0.18019907257077125}, 'budget': 400.0, 'working_directory': '.'}
23:47:39 DISPATCHER: Starting worker discovery
23:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:39 DISPATCHER: Finished worker discovery
23:48:39 DISPATCHER: Starting worker discovery
23:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:39 DISPATCHER: Finished worker discovery
23:49:39 DISPATCHER: Starting worker discovery
23:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:39 DISPATCHER: Finished worker discovery
23:50:39 DISPATCHER: Starting worker discovery
23:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:39 DISPATCHER: Finished worker discovery
23:51:39 DISPATCHER: Starting worker discovery
23:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:39 DISPATCHER: Finished worker discovery
23:52:39 DISPATCHER: Starting worker discovery
23:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:39 DISPATCHER: Finished worker discovery
23:53:39 DISPATCHER: Starting worker discovery
23:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:39 DISPATCHER: Finished worker discovery
23:53:39 WORKER: done with job (2, 0, 4), trying to register it.
23:53:39 WORKER: registered result for job (2, 0, 4) with dispatcher
23:53:39 DISPATCHER: job (2, 0, 4) finished
23:53:39 DISPATCHER: register_result: lock acquired
23:53:39 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:53:39 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 762, 'last_n_outputs': 46, 'leak_rate': 0.9152705102029588, 'lr': 0.0030765792570823522, 'optimizer': 'Adam', 'sparsity': 0.8127870925411702, 'steps_to_train': 51, 'weight_decay': 0.18019907257077125}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5223694922896346, 'info': {'number_mnist': 0.5223694922896346, 'config': "{'batch_size': 32, 'hidden_dim': 762, 'last_n_outputs': 46, 'leak_rate': 0.9152705102029588, 'lr': 0.0030765792570823522, 'optimizer': 'Adam', 'sparsity': 0.8127870925411702, 'steps_to_train': 51, 'weight_decay': 0.18019907257077125}"}}
exception: None

23:53:39 job_callback for (2, 0, 4) started
23:53:39 job_callback for (2, 0, 4) got condition
23:53:39 DISPATCHER: Trying to submit another job.
23:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:53:39 HBMASTER: Trying to run another job!
23:53:39 job_callback for (2, 0, 4) finished
23:53:39 start sampling a new configuration.
23:53:40 best_vector: [3, 0.5527008062679839, 0.14587929185378018, 0.9834696259433423, 0.35839920321889973, 1, 0.2847981141493419, 0.7587617847898565, 0.12091048577263924], 0.015857531185014234, 0.021882643574319648, 0.0003470047028903252
23:53:40 done sampling a new configuration.
23:53:40 HBMASTER: schedule new run for iteration 2
23:53:40 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
23:53:40 HBMASTER: submitting job (2, 0, 5) to dispatcher
23:53:40 DISPATCHER: trying to submit job (2, 0, 5)
23:53:40 DISPATCHER: trying to notify the job_runner thread.
23:53:40 HBMASTER: job (2, 0, 5) submitted to dispatcher
23:53:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:53:40 DISPATCHER: Trying to submit another job.
23:53:40 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:53:40 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:53:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:53:40 WORKER: start processing job (2, 0, 5)
23:53:40 WORKER: args: ()
23:53:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 15, 'leak_rate': 0.9958674064858356, 'lr': 0.005209528357862607, 'optimizer': 'SGD', 'sparsity': 0.818351547395842, 'steps_to_train': 79, 'weight_decay': 0.01436508396371318}, 'budget': 400.0, 'working_directory': '.'}
23:54:39 DISPATCHER: Starting worker discovery
23:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:39 DISPATCHER: Finished worker discovery
23:55:39 DISPATCHER: Starting worker discovery
23:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:39 DISPATCHER: Finished worker discovery
23:56:39 DISPATCHER: Starting worker discovery
23:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:39 DISPATCHER: Finished worker discovery
23:57:39 DISPATCHER: Starting worker discovery
23:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:39 DISPATCHER: Finished worker discovery
23:58:39 DISPATCHER: Starting worker discovery
23:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:39 DISPATCHER: Finished worker discovery
23:59:39 DISPATCHER: Starting worker discovery
23:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:39 DISPATCHER: Finished worker discovery
00:00:33 WORKER: done with job (2, 0, 5), trying to register it.
00:00:33 WORKER: registered result for job (2, 0, 5) with dispatcher
00:00:33 DISPATCHER: job (2, 0, 5) finished
00:00:33 DISPATCHER: register_result: lock acquired
00:00:33 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:00:33 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 15, 'leak_rate': 0.9958674064858356, 'lr': 0.005209528357862607, 'optimizer': 'SGD', 'sparsity': 0.818351547395842, 'steps_to_train': 79, 'weight_decay': 0.01436508396371318}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9320825835884423, 'info': {'number_mnist': 0.9320825835884423, 'config': "{'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 15, 'leak_rate': 0.9958674064858356, 'lr': 0.005209528357862607, 'optimizer': 'SGD', 'sparsity': 0.818351547395842, 'steps_to_train': 79, 'weight_decay': 0.01436508396371318}"}}
exception: None

00:00:33 job_callback for (2, 0, 5) started
00:00:33 job_callback for (2, 0, 5) got condition
00:00:33 DISPATCHER: Trying to submit another job.
00:00:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:00:33 HBMASTER: Trying to run another job!
00:00:33 job_callback for (2, 0, 5) finished
00:00:33 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
00:00:33 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
00:00:33 HBMASTER: schedule new run for iteration 2
00:00:33 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
00:00:33 HBMASTER: submitting job (2, 0, 0) to dispatcher
00:00:33 DISPATCHER: trying to submit job (2, 0, 0)
00:00:33 DISPATCHER: trying to notify the job_runner thread.
00:00:33 HBMASTER: job (2, 0, 0) submitted to dispatcher
00:00:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:00:33 DISPATCHER: Trying to submit another job.
00:00:33 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:00:33 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:00:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:00:33 WORKER: start processing job (2, 0, 0)
00:00:33 WORKER: args: ()
00:00:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 232, 'last_n_outputs': 32, 'leak_rate': 0.8245501909767465, 'lr': 0.0011966338077422176, 'optimizer': 'Adam', 'sparsity': 0.9381291743126563, 'steps_to_train': 49, 'weight_decay': 0.010196062063327136}, 'budget': 1200.0, 'working_directory': '.'}
00:00:39 DISPATCHER: Starting worker discovery
00:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:39 DISPATCHER: Finished worker discovery
00:01:39 DISPATCHER: Starting worker discovery
00:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:39 DISPATCHER: Finished worker discovery
00:02:39 DISPATCHER: Starting worker discovery
00:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:39 DISPATCHER: Finished worker discovery
00:03:39 DISPATCHER: Starting worker discovery
00:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:39 DISPATCHER: Finished worker discovery
00:04:39 DISPATCHER: Starting worker discovery
00:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:39 DISPATCHER: Finished worker discovery
00:05:39 DISPATCHER: Starting worker discovery
00:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:39 DISPATCHER: Finished worker discovery
00:06:39 DISPATCHER: Starting worker discovery
00:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:39 DISPATCHER: Finished worker discovery
00:07:39 DISPATCHER: Starting worker discovery
00:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:39 DISPATCHER: Finished worker discovery
00:08:39 DISPATCHER: Starting worker discovery
00:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:39 DISPATCHER: Finished worker discovery
00:09:39 DISPATCHER: Starting worker discovery
00:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:39 DISPATCHER: Finished worker discovery
00:10:39 DISPATCHER: Starting worker discovery
00:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:39 DISPATCHER: Finished worker discovery
00:11:39 DISPATCHER: Starting worker discovery
00:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:39 DISPATCHER: Finished worker discovery
00:12:39 DISPATCHER: Starting worker discovery
00:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:39 DISPATCHER: Finished worker discovery
00:13:39 DISPATCHER: Starting worker discovery
00:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:39 DISPATCHER: Finished worker discovery
00:14:39 DISPATCHER: Starting worker discovery
00:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:39 DISPATCHER: Finished worker discovery
00:15:39 DISPATCHER: Starting worker discovery
00:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:39 DISPATCHER: Finished worker discovery
00:16:39 DISPATCHER: Starting worker discovery
00:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:39 DISPATCHER: Finished worker discovery
00:17:39 DISPATCHER: Starting worker discovery
00:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:39 DISPATCHER: Finished worker discovery
00:18:39 DISPATCHER: Starting worker discovery
00:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:39 DISPATCHER: Finished worker discovery
00:19:39 DISPATCHER: Starting worker discovery
00:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:39 DISPATCHER: Finished worker discovery
00:20:39 DISPATCHER: Starting worker discovery
00:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:39 DISPATCHER: Finished worker discovery
00:21:01 WORKER: done with job (2, 0, 0), trying to register it.
00:21:01 WORKER: registered result for job (2, 0, 0) with dispatcher
00:21:01 DISPATCHER: job (2, 0, 0) finished
00:21:01 DISPATCHER: register_result: lock acquired
00:21:01 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:21:01 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 232, 'last_n_outputs': 32, 'leak_rate': 0.8245501909767465, 'lr': 0.0011966338077422176, 'optimizer': 'Adam', 'sparsity': 0.9381291743126563, 'steps_to_train': 49, 'weight_decay': 0.010196062063327136}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9318736622231711, 'info': {'number_mnist': 0.9318736622231711, 'config': "{'batch_size': 128, 'hidden_dim': 232, 'last_n_outputs': 32, 'leak_rate': 0.8245501909767465, 'lr': 0.0011966338077422176, 'optimizer': 'Adam', 'sparsity': 0.9381291743126563, 'steps_to_train': 49, 'weight_decay': 0.010196062063327136}"}}
exception: None

00:21:01 job_callback for (2, 0, 0) started
00:21:01 DISPATCHER: Trying to submit another job.
00:21:01 job_callback for (2, 0, 0) got condition
00:21:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:21:01 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:21:01 HBMASTER: Trying to run another job!
00:21:01 job_callback for (2, 0, 0) finished
00:21:01 HBMASTER: schedule new run for iteration 2
00:21:01 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
00:21:01 HBMASTER: submitting job (2, 0, 5) to dispatcher
00:21:01 DISPATCHER: trying to submit job (2, 0, 5)
00:21:01 DISPATCHER: trying to notify the job_runner thread.
00:21:01 HBMASTER: job (2, 0, 5) submitted to dispatcher
00:21:01 DISPATCHER: Trying to submit another job.
00:21:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:21:01 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:21:01 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:21:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:21:01 WORKER: start processing job (2, 0, 5)
00:21:01 WORKER: args: ()
00:21:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 15, 'leak_rate': 0.9958674064858356, 'lr': 0.005209528357862607, 'optimizer': 'SGD', 'sparsity': 0.818351547395842, 'steps_to_train': 79, 'weight_decay': 0.01436508396371318}, 'budget': 1200.0, 'working_directory': '.'}
00:21:39 DISPATCHER: Starting worker discovery
00:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:39 DISPATCHER: Finished worker discovery
00:22:39 DISPATCHER: Starting worker discovery
00:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:39 DISPATCHER: Finished worker discovery
00:23:39 DISPATCHER: Starting worker discovery
00:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:39 DISPATCHER: Finished worker discovery
00:24:39 DISPATCHER: Starting worker discovery
00:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:39 DISPATCHER: Finished worker discovery
00:25:39 DISPATCHER: Starting worker discovery
00:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:39 DISPATCHER: Finished worker discovery
00:26:39 DISPATCHER: Starting worker discovery
00:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:39 DISPATCHER: Finished worker discovery
00:27:39 DISPATCHER: Starting worker discovery
00:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:39 DISPATCHER: Finished worker discovery
00:28:39 DISPATCHER: Starting worker discovery
00:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:39 DISPATCHER: Finished worker discovery
00:29:39 DISPATCHER: Starting worker discovery
00:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:39 DISPATCHER: Finished worker discovery
00:30:39 DISPATCHER: Starting worker discovery
00:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:39 DISPATCHER: Finished worker discovery
00:31:39 DISPATCHER: Starting worker discovery
00:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:39 DISPATCHER: Finished worker discovery
00:32:39 DISPATCHER: Starting worker discovery
00:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:39 DISPATCHER: Finished worker discovery
00:33:39 DISPATCHER: Starting worker discovery
00:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:39 DISPATCHER: Finished worker discovery
00:34:39 DISPATCHER: Starting worker discovery
00:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:39 DISPATCHER: Finished worker discovery
00:35:39 DISPATCHER: Starting worker discovery
00:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:39 DISPATCHER: Finished worker discovery
00:36:39 DISPATCHER: Starting worker discovery
00:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:39 DISPATCHER: Finished worker discovery
00:37:39 DISPATCHER: Starting worker discovery
00:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:39 DISPATCHER: Finished worker discovery
00:38:39 DISPATCHER: Starting worker discovery
00:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:39 DISPATCHER: Finished worker discovery
00:39:39 DISPATCHER: Starting worker discovery
00:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:39 DISPATCHER: Finished worker discovery
00:40:39 DISPATCHER: Starting worker discovery
00:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:39 DISPATCHER: Finished worker discovery
00:41:22 WORKER: done with job (2, 0, 5), trying to register it.
00:41:22 WORKER: registered result for job (2, 0, 5) with dispatcher
00:41:22 DISPATCHER: job (2, 0, 5) finished
00:41:22 DISPATCHER: register_result: lock acquired
00:41:22 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:41:22 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 15, 'leak_rate': 0.9958674064858356, 'lr': 0.005209528357862607, 'optimizer': 'SGD', 'sparsity': 0.818351547395842, 'steps_to_train': 79, 'weight_decay': 0.01436508396371318}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9359971767597224, 'info': {'number_mnist': 0.9359971767597224, 'config': "{'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 15, 'leak_rate': 0.9958674064858356, 'lr': 0.005209528357862607, 'optimizer': 'SGD', 'sparsity': 0.818351547395842, 'steps_to_train': 79, 'weight_decay': 0.01436508396371318}"}}
exception: None

00:41:22 job_callback for (2, 0, 5) started
00:41:22 DISPATCHER: Trying to submit another job.
00:41:22 job_callback for (2, 0, 5) got condition
00:41:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:41:22 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:41:22 HBMASTER: Trying to run another job!
00:41:22 job_callback for (2, 0, 5) finished
00:41:22 start sampling a new configuration.
00:41:22 best_vector: [3, 0.1454134927918782, 0.8822252339365156, 0.4625571763593546, 0.049897075783535666, 1, 0.6601068311060398, 0.45340150867609214, 0.12542971316997265], 0.007580700003552377, 0.09324948312210782, 0.0007068963570350201
00:41:22 done sampling a new configuration.
00:41:22 HBMASTER: schedule new run for iteration 3
00:41:22 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
00:41:22 HBMASTER: submitting job (3, 0, 0) to dispatcher
00:41:22 DISPATCHER: trying to submit job (3, 0, 0)
00:41:22 DISPATCHER: trying to notify the job_runner thread.
00:41:22 HBMASTER: job (3, 0, 0) submitted to dispatcher
00:41:22 DISPATCHER: Trying to submit another job.
00:41:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:41:22 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:41:22 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:41:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:41:22 WORKER: start processing job (3, 0, 0)
00:41:22 WORKER: args: ()
00:41:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 316, 'last_n_outputs': 46, 'leak_rate': 0.8656392940898386, 'lr': 0.0012583288432726006, 'optimizer': 'SGD', 'sparsity': 0.9084256394654495, 'steps_to_train': 51, 'weight_decay': 0.014560886585849224}, 'budget': 1200.0, 'working_directory': '.'}
00:41:39 DISPATCHER: Starting worker discovery
00:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:39 DISPATCHER: Finished worker discovery
00:42:39 DISPATCHER: Starting worker discovery
00:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:39 DISPATCHER: Finished worker discovery
00:43:39 DISPATCHER: Starting worker discovery
00:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:39 DISPATCHER: Finished worker discovery
00:44:39 DISPATCHER: Starting worker discovery
00:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:39 DISPATCHER: Finished worker discovery
00:45:39 DISPATCHER: Starting worker discovery
00:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:39 DISPATCHER: Finished worker discovery
00:46:39 DISPATCHER: Starting worker discovery
00:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:39 DISPATCHER: Finished worker discovery
00:47:39 DISPATCHER: Starting worker discovery
00:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:39 DISPATCHER: Finished worker discovery
00:48:39 DISPATCHER: Starting worker discovery
00:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:39 DISPATCHER: Finished worker discovery
00:49:39 DISPATCHER: Starting worker discovery
00:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:39 DISPATCHER: Finished worker discovery
00:50:39 DISPATCHER: Starting worker discovery
00:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:39 DISPATCHER: Finished worker discovery
00:51:39 DISPATCHER: Starting worker discovery
00:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:39 DISPATCHER: Finished worker discovery
00:52:39 DISPATCHER: Starting worker discovery
00:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:39 DISPATCHER: Finished worker discovery
00:53:39 DISPATCHER: Starting worker discovery
00:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:39 DISPATCHER: Finished worker discovery
00:54:39 DISPATCHER: Starting worker discovery
00:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:39 DISPATCHER: Finished worker discovery
00:55:39 DISPATCHER: Starting worker discovery
00:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:39 DISPATCHER: Finished worker discovery
00:56:39 DISPATCHER: Starting worker discovery
00:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:39 DISPATCHER: Finished worker discovery
00:57:39 DISPATCHER: Starting worker discovery
00:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:39 DISPATCHER: Finished worker discovery
00:58:39 DISPATCHER: Starting worker discovery
00:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:39 DISPATCHER: Finished worker discovery
00:59:39 DISPATCHER: Starting worker discovery
00:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:39 DISPATCHER: Finished worker discovery
01:00:39 DISPATCHER: Starting worker discovery
01:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:39 DISPATCHER: Finished worker discovery
01:01:39 DISPATCHER: Starting worker discovery
01:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:40 DISPATCHER: Finished worker discovery
01:01:48 WORKER: done with job (3, 0, 0), trying to register it.
01:01:48 WORKER: registered result for job (3, 0, 0) with dispatcher
01:01:48 DISPATCHER: job (3, 0, 0) finished
01:01:48 DISPATCHER: register_result: lock acquired
01:01:48 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:01:48 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 316, 'last_n_outputs': 46, 'leak_rate': 0.8656392940898386, 'lr': 0.0012583288432726006, 'optimizer': 'SGD', 'sparsity': 0.9084256394654495, 'steps_to_train': 51, 'weight_decay': 0.014560886585849224}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8847452322543515, 'info': {'number_mnist': 0.8847452322543515, 'config': "{'batch_size': 128, 'hidden_dim': 316, 'last_n_outputs': 46, 'leak_rate': 0.8656392940898386, 'lr': 0.0012583288432726006, 'optimizer': 'SGD', 'sparsity': 0.9084256394654495, 'steps_to_train': 51, 'weight_decay': 0.014560886585849224}"}}
exception: None

01:01:48 job_callback for (3, 0, 0) started
01:01:48 DISPATCHER: Trying to submit another job.
01:01:48 job_callback for (3, 0, 0) got condition
01:01:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:01:48 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:01:48 HBMASTER: Trying to run another job!
01:01:48 job_callback for (3, 0, 0) finished
01:01:48 start sampling a new configuration.
01:01:48 done sampling a new configuration.
01:01:48 HBMASTER: schedule new run for iteration 3
01:01:48 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
01:01:48 HBMASTER: submitting job (3, 0, 1) to dispatcher
01:01:48 DISPATCHER: trying to submit job (3, 0, 1)
01:01:48 DISPATCHER: trying to notify the job_runner thread.
01:01:48 HBMASTER: job (3, 0, 1) submitted to dispatcher
01:01:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:01:48 DISPATCHER: Trying to submit another job.
01:01:48 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:01:48 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:01:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:01:48 WORKER: start processing job (3, 0, 1)
01:01:48 WORKER: args: ()
01:01:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 411, 'last_n_outputs': 47, 'leak_rate': 0.8686349865224786, 'lr': 0.009503585296137295, 'optimizer': 'Adam', 'sparsity': 0.8675836146245202, 'steps_to_train': 65, 'weight_decay': 0.013505376333880841}, 'budget': 1200.0, 'working_directory': '.'}
01:02:40 DISPATCHER: Starting worker discovery
01:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:40 DISPATCHER: Finished worker discovery
01:03:40 DISPATCHER: Starting worker discovery
01:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:40 DISPATCHER: Finished worker discovery
01:04:40 DISPATCHER: Starting worker discovery
01:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:40 DISPATCHER: Finished worker discovery
01:05:40 DISPATCHER: Starting worker discovery
01:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:40 DISPATCHER: Finished worker discovery
01:06:40 DISPATCHER: Starting worker discovery
01:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:40 DISPATCHER: Finished worker discovery
01:07:40 DISPATCHER: Starting worker discovery
01:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:40 DISPATCHER: Finished worker discovery
01:08:40 DISPATCHER: Starting worker discovery
01:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:40 DISPATCHER: Finished worker discovery
01:09:40 DISPATCHER: Starting worker discovery
01:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:40 DISPATCHER: Finished worker discovery
01:10:40 DISPATCHER: Starting worker discovery
01:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:40 DISPATCHER: Finished worker discovery
01:11:40 DISPATCHER: Starting worker discovery
01:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:40 DISPATCHER: Finished worker discovery
01:12:40 DISPATCHER: Starting worker discovery
01:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:40 DISPATCHER: Finished worker discovery
01:13:40 DISPATCHER: Starting worker discovery
01:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:40 DISPATCHER: Finished worker discovery
01:14:40 DISPATCHER: Starting worker discovery
01:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:40 DISPATCHER: Finished worker discovery
01:15:40 DISPATCHER: Starting worker discovery
01:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:40 DISPATCHER: Finished worker discovery
01:16:40 DISPATCHER: Starting worker discovery
01:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:40 DISPATCHER: Finished worker discovery
01:17:40 DISPATCHER: Starting worker discovery
01:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:40 DISPATCHER: Finished worker discovery
01:18:40 DISPATCHER: Starting worker discovery
01:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:40 DISPATCHER: Finished worker discovery
01:19:40 DISPATCHER: Starting worker discovery
01:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:40 DISPATCHER: Finished worker discovery
01:20:40 DISPATCHER: Starting worker discovery
01:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:40 DISPATCHER: Finished worker discovery
01:21:40 DISPATCHER: Starting worker discovery
01:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:40 DISPATCHER: Finished worker discovery
01:22:11 WORKER: done with job (3, 0, 1), trying to register it.
01:22:11 WORKER: registered result for job (3, 0, 1) with dispatcher
01:22:11 DISPATCHER: job (3, 0, 1) finished
01:22:11 DISPATCHER: register_result: lock acquired
01:22:11 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:22:11 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 411, 'last_n_outputs': 47, 'leak_rate': 0.8686349865224786, 'lr': 0.009503585296137295, 'optimizer': 'Adam', 'sparsity': 0.8675836146245202, 'steps_to_train': 65, 'weight_decay': 0.013505376333880841}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7345856974702915, 'info': {'number_mnist': 0.7345856974702915, 'config': "{'batch_size': 32, 'hidden_dim': 411, 'last_n_outputs': 47, 'leak_rate': 0.8686349865224786, 'lr': 0.009503585296137295, 'optimizer': 'Adam', 'sparsity': 0.8675836146245202, 'steps_to_train': 65, 'weight_decay': 0.013505376333880841}"}}
exception: None

01:22:11 job_callback for (3, 0, 1) started
01:22:11 DISPATCHER: Trying to submit another job.
01:22:11 job_callback for (3, 0, 1) got condition
01:22:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:11 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:22:11 HBMASTER: Trying to run another job!
01:22:11 job_callback for (3, 0, 1) finished
01:22:11 start sampling a new configuration.
01:22:11 best_vector: [2, 0.5300138908194363, 0.38877332649969165, 0.9979682847963575, 0.010813328831353108, 1, 0.5884224191107621, 0.22460024510188648, 0.017347630315840634], 0.007566140263551958, 0.19821630193213272, 0.001499732342941081
01:22:11 done sampling a new configuration.
01:22:11 HBMASTER: schedule new run for iteration 3
01:22:11 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
01:22:11 HBMASTER: submitting job (3, 0, 2) to dispatcher
01:22:11 DISPATCHER: trying to submit job (3, 0, 2)
01:22:11 DISPATCHER: trying to notify the job_runner thread.
01:22:11 HBMASTER: job (3, 0, 2) submitted to dispatcher
01:22:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:11 DISPATCHER: Trying to submit another job.
01:22:11 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:22:11 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:22:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:11 WORKER: start processing job (3, 0, 2)
01:22:11 WORKER: args: ()
01:22:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 624, 'last_n_outputs': 25, 'leak_rate': 0.9994920711990893, 'lr': 0.0010510579407578544, 'optimizer': 'SGD', 'sparsity': 0.891221380586583, 'steps_to_train': 30, 'weight_decay': 0.010533429366973077}, 'budget': 1200.0, 'working_directory': '.'}
01:22:40 DISPATCHER: Starting worker discovery
01:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:40 DISPATCHER: Finished worker discovery
01:23:40 DISPATCHER: Starting worker discovery
01:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:40 DISPATCHER: Finished worker discovery
01:24:40 DISPATCHER: Starting worker discovery
01:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:40 DISPATCHER: Finished worker discovery
01:25:40 DISPATCHER: Starting worker discovery
01:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:40 DISPATCHER: Finished worker discovery
01:26:40 DISPATCHER: Starting worker discovery
01:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:40 DISPATCHER: Finished worker discovery
01:27:40 DISPATCHER: Starting worker discovery
01:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:40 DISPATCHER: Finished worker discovery
01:28:40 DISPATCHER: Starting worker discovery
01:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:40 DISPATCHER: Finished worker discovery
01:29:40 DISPATCHER: Starting worker discovery
01:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:40 DISPATCHER: Finished worker discovery
01:30:40 DISPATCHER: Starting worker discovery
01:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:40 DISPATCHER: Finished worker discovery
01:31:40 DISPATCHER: Starting worker discovery
01:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:40 DISPATCHER: Finished worker discovery
01:32:40 DISPATCHER: Starting worker discovery
01:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:40 DISPATCHER: Finished worker discovery
01:33:40 DISPATCHER: Starting worker discovery
01:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:40 DISPATCHER: Finished worker discovery
01:34:40 DISPATCHER: Starting worker discovery
01:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:40 DISPATCHER: Finished worker discovery
01:35:40 DISPATCHER: Starting worker discovery
01:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:40 DISPATCHER: Finished worker discovery
01:36:40 DISPATCHER: Starting worker discovery
01:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:40 DISPATCHER: Finished worker discovery
01:37:40 DISPATCHER: Starting worker discovery
01:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:40 DISPATCHER: Finished worker discovery
01:38:40 DISPATCHER: Starting worker discovery
01:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:40 DISPATCHER: Finished worker discovery
01:39:40 DISPATCHER: Starting worker discovery
01:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:40 DISPATCHER: Finished worker discovery
01:40:40 DISPATCHER: Starting worker discovery
01:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:40 DISPATCHER: Finished worker discovery
01:41:40 DISPATCHER: Starting worker discovery
01:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:40 DISPATCHER: Finished worker discovery
01:42:40 DISPATCHER: Starting worker discovery
01:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:40 DISPATCHER: Finished worker discovery
01:42:42 WORKER: done with job (3, 0, 2), trying to register it.
01:42:42 WORKER: registered result for job (3, 0, 2) with dispatcher
01:42:42 DISPATCHER: job (3, 0, 2) finished
01:42:42 DISPATCHER: register_result: lock acquired
01:42:42 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:42:42 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 624, 'last_n_outputs': 25, 'leak_rate': 0.9994920711990893, 'lr': 0.0010510579407578544, 'optimizer': 'SGD', 'sparsity': 0.891221380586583, 'steps_to_train': 30, 'weight_decay': 0.010533429366973077}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8930405558122634, 'info': {'number_mnist': 0.8930405558122634, 'config': "{'batch_size': 64, 'hidden_dim': 624, 'last_n_outputs': 25, 'leak_rate': 0.9994920711990893, 'lr': 0.0010510579407578544, 'optimizer': 'SGD', 'sparsity': 0.891221380586583, 'steps_to_train': 30, 'weight_decay': 0.010533429366973077}"}}
exception: None

01:42:42 job_callback for (3, 0, 2) started
01:42:42 job_callback for (3, 0, 2) got condition
01:42:42 DISPATCHER: Trying to submit another job.
01:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:42 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:42:42 HBMASTER: Trying to run another job!
01:42:42 job_callback for (3, 0, 2) finished
01:42:42 start sampling a new configuration.
01:42:42 best_vector: [2, 0.5573299257372342, 0.6073233812457318, 0.8516674840569101, 0.34316823096258897, 0, 0.07807209934508261, 0.31741187945284133, 0.3027211141249613], 0.015658722208215594, 0.714062687639364, 0.011181309264996622
01:42:42 done sampling a new configuration.
01:42:42 HBMASTER: schedule new run for iteration 3
01:42:42 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
01:42:42 HBMASTER: submitting job (3, 0, 3) to dispatcher
01:42:42 DISPATCHER: trying to submit job (3, 0, 3)
01:42:42 DISPATCHER: trying to notify the job_runner thread.
01:42:42 HBMASTER: job (3, 0, 3) submitted to dispatcher
01:42:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:42 DISPATCHER: Trying to submit another job.
01:42:42 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:42:42 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:42 WORKER: start processing job (3, 0, 3)
01:42:42 WORKER: args: ()
01:42:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 646, 'last_n_outputs': 34, 'leak_rate': 0.9629168710142275, 'lr': 0.004856646144710519, 'optimizer': 'Adam', 'sparsity': 0.7687373038428198, 'steps_to_train': 38, 'weight_decay': 0.024765622560900688}, 'budget': 1200.0, 'working_directory': '.'}
01:43:40 DISPATCHER: Starting worker discovery
01:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:40 DISPATCHER: Finished worker discovery
01:44:40 DISPATCHER: Starting worker discovery
01:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:40 DISPATCHER: Finished worker discovery
01:45:40 DISPATCHER: Starting worker discovery
01:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:40 DISPATCHER: Finished worker discovery
01:46:40 DISPATCHER: Starting worker discovery
01:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:40 DISPATCHER: Finished worker discovery
01:47:40 DISPATCHER: Starting worker discovery
01:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:40 DISPATCHER: Finished worker discovery
01:48:40 DISPATCHER: Starting worker discovery
01:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:40 DISPATCHER: Finished worker discovery
01:49:40 DISPATCHER: Starting worker discovery
01:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:40 DISPATCHER: Finished worker discovery
01:50:40 DISPATCHER: Starting worker discovery
01:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:40 DISPATCHER: Finished worker discovery
01:51:40 DISPATCHER: Starting worker discovery
01:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:40 DISPATCHER: Finished worker discovery
01:52:40 DISPATCHER: Starting worker discovery
01:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:40 DISPATCHER: Finished worker discovery
01:53:40 DISPATCHER: Starting worker discovery
01:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:40 DISPATCHER: Finished worker discovery
01:54:40 DISPATCHER: Starting worker discovery
01:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:40 DISPATCHER: Finished worker discovery
01:55:40 DISPATCHER: Starting worker discovery
01:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:40 DISPATCHER: Finished worker discovery
01:56:40 DISPATCHER: Starting worker discovery
01:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:40 DISPATCHER: Finished worker discovery
01:57:40 DISPATCHER: Starting worker discovery
01:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:40 DISPATCHER: Finished worker discovery
01:58:40 DISPATCHER: Starting worker discovery
01:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:40 DISPATCHER: Finished worker discovery
01:59:40 DISPATCHER: Starting worker discovery
01:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:40 DISPATCHER: Finished worker discovery
02:00:40 DISPATCHER: Starting worker discovery
02:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:40 DISPATCHER: Finished worker discovery
02:01:40 DISPATCHER: Starting worker discovery
02:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:40 DISPATCHER: Finished worker discovery
02:02:40 DISPATCHER: Starting worker discovery
02:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:40 DISPATCHER: Finished worker discovery
02:03:09 WORKER: done with job (3, 0, 3), trying to register it.
02:03:09 WORKER: registered result for job (3, 0, 3) with dispatcher
02:03:09 DISPATCHER: job (3, 0, 3) finished
02:03:09 DISPATCHER: register_result: lock acquired
02:03:09 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:03:09 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 646, 'last_n_outputs': 34, 'leak_rate': 0.9629168710142275, 'lr': 0.004856646144710519, 'optimizer': 'Adam', 'sparsity': 0.7687373038428198, 'steps_to_train': 38, 'weight_decay': 0.024765622560900688}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7888112671199174, 'info': {'number_mnist': 0.7888112671199174, 'config': "{'batch_size': 64, 'hidden_dim': 646, 'last_n_outputs': 34, 'leak_rate': 0.9629168710142275, 'lr': 0.004856646144710519, 'optimizer': 'Adam', 'sparsity': 0.7687373038428198, 'steps_to_train': 38, 'weight_decay': 0.024765622560900688}"}}
exception: None

02:03:09 job_callback for (3, 0, 3) started
02:03:09 job_callback for (3, 0, 3) got condition
02:03:09 DISPATCHER: Trying to submit another job.
02:03:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:03:09 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:03:09 HBMASTER: Trying to run another job!
02:03:09 job_callback for (3, 0, 3) finished
02:03:09 start sampling a new configuration.
02:03:09 done sampling a new configuration.
02:03:09 HBMASTER: schedule new run for iteration 4
02:03:09 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
02:03:09 HBMASTER: submitting job (4, 0, 0) to dispatcher
02:03:09 DISPATCHER: trying to submit job (4, 0, 0)
02:03:09 DISPATCHER: trying to notify the job_runner thread.
02:03:09 HBMASTER: job (4, 0, 0) submitted to dispatcher
02:03:09 DISPATCHER: Trying to submit another job.
02:03:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:03:09 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:03:09 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:03:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:03:09 WORKER: start processing job (4, 0, 0)
02:03:09 WORKER: args: ()
02:03:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 320, 'last_n_outputs': 21, 'leak_rate': 0.8545444587644996, 'lr': 0.023803430822438396, 'optimizer': 'SGD', 'sparsity': 0.8834504567744133, 'steps_to_train': 75, 'weight_decay': 0.022563744003712666}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:03:40 DISPATCHER: Starting worker discovery
02:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:40 DISPATCHER: Finished worker discovery
02:04:03 WORKER: done with job (4, 0, 0), trying to register it.
02:04:03 WORKER: registered result for job (4, 0, 0) with dispatcher
02:04:03 DISPATCHER: job (4, 0, 0) finished
02:04:03 DISPATCHER: register_result: lock acquired
02:04:03 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:04:03 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 320, 'last_n_outputs': 21, 'leak_rate': 0.8545444587644996, 'lr': 0.023803430822438396, 'optimizer': 'SGD', 'sparsity': 0.8834504567744133, 'steps_to_train': 75, 'weight_decay': 0.022563744003712666}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9164453828743291, 'info': {'number_mnist': 0.9164453828743291, 'config': "{'batch_size': 128, 'hidden_dim': 320, 'last_n_outputs': 21, 'leak_rate': 0.8545444587644996, 'lr': 0.023803430822438396, 'optimizer': 'SGD', 'sparsity': 0.8834504567744133, 'steps_to_train': 75, 'weight_decay': 0.022563744003712666}"}}
exception: None

02:04:03 job_callback for (4, 0, 0) started
02:04:03 job_callback for (4, 0, 0) got condition
02:04:03 DISPATCHER: Trying to submit another job.
02:04:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:03 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.916445





02:04:03 HBMASTER: Trying to run another job!
02:04:03 job_callback for (4, 0, 0) finished
02:04:03 start sampling a new configuration.
02:04:03 done sampling a new configuration.
02:04:03 HBMASTER: schedule new run for iteration 4
02:04:03 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
02:04:03 HBMASTER: submitting job (4, 0, 1) to dispatcher
02:04:03 DISPATCHER: trying to submit job (4, 0, 1)
02:04:03 DISPATCHER: trying to notify the job_runner thread.
02:04:03 HBMASTER: job (4, 0, 1) submitted to dispatcher
02:04:03 DISPATCHER: Trying to submit another job.
02:04:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:03 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:04:03 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:04:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:03 WORKER: start processing job (4, 0, 1)
02:04:03 WORKER: args: ()
02:04:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 487, 'last_n_outputs': 26, 'leak_rate': 0.9286576122150444, 'lr': 0.018782236280421395, 'optimizer': 'SGD', 'sparsity': 0.8089705855130074, 'steps_to_train': 67, 'weight_decay': 0.02702607168938952}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:04:40 DISPATCHER: Starting worker discovery
02:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:40 DISPATCHER: Finished worker discovery
02:04:57 WORKER: done with job (4, 0, 1), trying to register it.
02:04:57 WORKER: registered result for job (4, 0, 1) with dispatcher
02:04:57 DISPATCHER: job (4, 0, 1) finished
02:04:57 DISPATCHER: register_result: lock acquired
02:04:57 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:04:57 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 487, 'last_n_outputs': 26, 'leak_rate': 0.9286576122150444, 'lr': 0.018782236280421395, 'optimizer': 'SGD', 'sparsity': 0.8089705855130074, 'steps_to_train': 67, 'weight_decay': 0.02702607168938952}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9260369075322094, 'info': {'number_mnist': 0.9260369075322094, 'config': "{'batch_size': 16, 'hidden_dim': 487, 'last_n_outputs': 26, 'leak_rate': 0.9286576122150444, 'lr': 0.018782236280421395, 'optimizer': 'SGD', 'sparsity': 0.8089705855130074, 'steps_to_train': 67, 'weight_decay': 0.02702607168938952}"}}
exception: None

02:04:57 job_callback for (4, 0, 1) started
02:04:57 job_callback for (4, 0, 1) got condition
02:04:57 DISPATCHER: Trying to submit another job.
02:04:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:57 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.926037





02:04:57 HBMASTER: Trying to run another job!
02:04:57 job_callback for (4, 0, 1) finished
02:04:57 start sampling a new configuration.
02:04:57 best_vector: [1, 0.3945431073142731, 0.3092538142805947, 0.44977822437765397, 0.5485716174467224, 1, 0.6877717419130974, 0.85283589778598, 0.024327422818980537], 0.014496421891679939, 0.34269551264417486, 0.004967858731675496
02:04:57 done sampling a new configuration.
02:04:57 HBMASTER: schedule new run for iteration 4
02:04:57 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
02:04:57 HBMASTER: submitting job (4, 0, 2) to dispatcher
02:04:57 DISPATCHER: trying to submit job (4, 0, 2)
02:04:57 DISPATCHER: trying to notify the job_runner thread.
02:04:57 HBMASTER: job (4, 0, 2) submitted to dispatcher
02:04:57 DISPATCHER: Trying to submit another job.
02:04:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:57 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:04:57 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:04:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:57 WORKER: start processing job (4, 0, 2)
02:04:57 WORKER: args: ()
02:04:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 516, 'last_n_outputs': 22, 'leak_rate': 0.8624445560944135, 'lr': 0.012506714468175984, 'optimizer': 'SGD', 'sparsity': 0.9150652180591434, 'steps_to_train': 87, 'weight_decay': 0.010755997851582166}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:05:40 DISPATCHER: Starting worker discovery
02:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:40 DISPATCHER: Finished worker discovery
02:05:50 WORKER: done with job (4, 0, 2), trying to register it.
02:05:50 WORKER: registered result for job (4, 0, 2) with dispatcher
02:05:50 DISPATCHER: job (4, 0, 2) finished
02:05:50 DISPATCHER: register_result: lock acquired
02:05:50 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:05:50 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 516, 'last_n_outputs': 22, 'leak_rate': 0.8624445560944135, 'lr': 0.012506714468175984, 'optimizer': 'SGD', 'sparsity': 0.9150652180591434, 'steps_to_train': 87, 'weight_decay': 0.010755997851582166}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9329834329433546, 'info': {'number_mnist': 0.9329834329433546, 'config': "{'batch_size': 32, 'hidden_dim': 516, 'last_n_outputs': 22, 'leak_rate': 0.8624445560944135, 'lr': 0.012506714468175984, 'optimizer': 'SGD', 'sparsity': 0.9150652180591434, 'steps_to_train': 87, 'weight_decay': 0.010755997851582166}"}}
exception: None

02:05:50 job_callback for (4, 0, 2) started
02:05:50 job_callback for (4, 0, 2) got condition
02:05:50 DISPATCHER: Trying to submit another job.
02:05:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:05:50 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.932983





02:05:50 HBMASTER: Trying to run another job!
02:05:50 job_callback for (4, 0, 2) finished
02:05:50 start sampling a new configuration.
02:05:50 best_vector: [2, 0.7870497876614015, 0.1676804023337506, 0.1646755147438034, 0.07780728316261953, 1, 0.20820965596306773, 0.881881123262144, 0.293605171312984], 0.004200665183443477, 0.22896190886608844, 0.0009617923189085359
02:05:50 done sampling a new configuration.
02:05:50 HBMASTER: schedule new run for iteration 4
02:05:50 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
02:05:50 HBMASTER: submitting job (4, 0, 3) to dispatcher
02:05:50 DISPATCHER: trying to submit job (4, 0, 3)
02:05:50 DISPATCHER: trying to notify the job_runner thread.
02:05:50 HBMASTER: job (4, 0, 3) submitted to dispatcher
02:05:50 DISPATCHER: Trying to submit another job.
02:05:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:05:50 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:05:50 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:05:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:05:50 WORKER: start processing job (4, 0, 3)
02:05:50 WORKER: args: ()
02:05:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 830, 'last_n_outputs': 16, 'leak_rate': 0.7911688786859509, 'lr': 0.0014309174052052518, 'optimizer': 'SGD', 'sparsity': 0.7999703174311362, 'steps_to_train': 90, 'weight_decay': 0.024098451380916153}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:06:40 DISPATCHER: Starting worker discovery
02:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:40 DISPATCHER: Finished worker discovery
02:06:45 WORKER: done with job (4, 0, 3), trying to register it.
02:06:45 WORKER: registered result for job (4, 0, 3) with dispatcher
02:06:45 DISPATCHER: job (4, 0, 3) finished
02:06:45 DISPATCHER: register_result: lock acquired
02:06:45 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:06:45 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 830, 'last_n_outputs': 16, 'leak_rate': 0.7911688786859509, 'lr': 0.0014309174052052518, 'optimizer': 'SGD', 'sparsity': 0.7999703174311362, 'steps_to_train': 90, 'weight_decay': 0.024098451380916153}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.844232836619596, 'info': {'number_mnist': 0.844232836619596, 'config': "{'batch_size': 64, 'hidden_dim': 830, 'last_n_outputs': 16, 'leak_rate': 0.7911688786859509, 'lr': 0.0014309174052052518, 'optimizer': 'SGD', 'sparsity': 0.7999703174311362, 'steps_to_train': 90, 'weight_decay': 0.024098451380916153}"}}
exception: None

02:06:45 job_callback for (4, 0, 3) started
02:06:45 job_callback for (4, 0, 3) got condition
02:06:45 DISPATCHER: Trying to submit another job.
02:06:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:06:45 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.932983





02:06:45 HBMASTER: Trying to run another job!
02:06:45 job_callback for (4, 0, 3) finished
02:06:45 start sampling a new configuration.
02:06:45 done sampling a new configuration.
02:06:45 HBMASTER: schedule new run for iteration 4
02:06:45 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
02:06:45 HBMASTER: submitting job (4, 0, 4) to dispatcher
02:06:45 DISPATCHER: trying to submit job (4, 0, 4)
02:06:45 DISPATCHER: trying to notify the job_runner thread.
02:06:45 HBMASTER: job (4, 0, 4) submitted to dispatcher
02:06:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:06:45 DISPATCHER: Trying to submit another job.
02:06:45 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:06:45 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:06:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:06:45 WORKER: start processing job (4, 0, 4)
02:06:45 WORKER: args: ()
02:06:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 459, 'last_n_outputs': 42, 'leak_rate': 0.7979832503005791, 'lr': 0.0029098114111174764, 'optimizer': 'SGD', 'sparsity': 0.7911469758625644, 'steps_to_train': 14, 'weight_decay': 0.046532844981712826}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:07:40 WORKER: done with job (4, 0, 4), trying to register it.
02:07:40 WORKER: registered result for job (4, 0, 4) with dispatcher
02:07:40 DISPATCHER: job (4, 0, 4) finished
02:07:40 DISPATCHER: register_result: lock acquired
02:07:40 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:07:40 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 459, 'last_n_outputs': 42, 'leak_rate': 0.7979832503005791, 'lr': 0.0029098114111174764, 'optimizer': 'SGD', 'sparsity': 0.7911469758625644, 'steps_to_train': 14, 'weight_decay': 0.046532844981712826}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8332155934165486, 'info': {'number_mnist': 0.8332155934165486, 'config': "{'batch_size': 16, 'hidden_dim': 459, 'last_n_outputs': 42, 'leak_rate': 0.7979832503005791, 'lr': 0.0029098114111174764, 'optimizer': 'SGD', 'sparsity': 0.7911469758625644, 'steps_to_train': 14, 'weight_decay': 0.046532844981712826}"}}
exception: None

02:07:40 job_callback for (4, 0, 4) started
02:07:40 DISPATCHER: Trying to submit another job.
02:07:40 job_callback for (4, 0, 4) got condition
02:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:07:40 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.932983





02:07:40 HBMASTER: Trying to run another job!
02:07:40 job_callback for (4, 0, 4) finished
02:07:40 start sampling a new configuration.
02:07:40 best_vector: [1, 0.9467672107505171, 0.4228355220878284, 0.05082673269483563, 0.09259750812357535, 1, 0.6044696468948256, 0.9967304184013629, 0.10148014483260925], 0.00229078783206794, 0.08886647888546068, 0.00020357424850953582
02:07:40 done sampling a new configuration.
02:07:40 HBMASTER: schedule new run for iteration 4
02:07:40 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
02:07:40 HBMASTER: submitting job (4, 0, 5) to dispatcher
02:07:40 DISPATCHER: trying to submit job (4, 0, 5)
02:07:40 DISPATCHER: trying to notify the job_runner thread.
02:07:40 HBMASTER: job (4, 0, 5) submitted to dispatcher
02:07:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:07:40 DISPATCHER: Trying to submit another job.
02:07:40 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:07:40 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:07:40 WORKER: start processing job (4, 0, 5)
02:07:40 WORKER: args: ()
02:07:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 958, 'last_n_outputs': 27, 'leak_rate': 0.7627066831737089, 'lr': 0.0015317751378839605, 'optimizer': 'SGD', 'sparsity': 0.8950727152547582, 'steps_to_train': 100, 'weight_decay': 0.013552790105774213}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:07:40 DISPATCHER: Starting worker discovery
02:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:40 DISPATCHER: Finished worker discovery
02:08:34 WORKER: done with job (4, 0, 5), trying to register it.
02:08:34 WORKER: registered result for job (4, 0, 5) with dispatcher
02:08:34 DISPATCHER: job (4, 0, 5) finished
02:08:34 DISPATCHER: register_result: lock acquired
02:08:34 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:08:34 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 958, 'last_n_outputs': 27, 'leak_rate': 0.7627066831737089, 'lr': 0.0015317751378839605, 'optimizer': 'SGD', 'sparsity': 0.8950727152547582, 'steps_to_train': 100, 'weight_decay': 0.013552790105774213}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8787857378202738, 'info': {'number_mnist': 0.8787857378202738, 'config': "{'batch_size': 32, 'hidden_dim': 958, 'last_n_outputs': 27, 'leak_rate': 0.7627066831737089, 'lr': 0.0015317751378839605, 'optimizer': 'SGD', 'sparsity': 0.8950727152547582, 'steps_to_train': 100, 'weight_decay': 0.013552790105774213}"}}
exception: None

02:08:34 job_callback for (4, 0, 5) started
02:08:34 job_callback for (4, 0, 5) got condition
02:08:34 DISPATCHER: Trying to submit another job.
02:08:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:34 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.932983





02:08:34 HBMASTER: Trying to run another job!
02:08:34 job_callback for (4, 0, 5) finished
02:08:34 start sampling a new configuration.
02:08:34 best_vector: [0, 0.4665972018244651, 0.28940126525534093, 0.3287763680263076, 0.5751806189612383, 1, 0.6406774107253328, 0.7940617481522612, 0.09937048836739143], 0.004110857743249168, 2.09909958843162, 0.008629099796955267
02:08:34 done sampling a new configuration.
02:08:34 HBMASTER: schedule new run for iteration 4
02:08:34 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
02:08:34 HBMASTER: submitting job (4, 0, 6) to dispatcher
02:08:34 DISPATCHER: trying to submit job (4, 0, 6)
02:08:34 DISPATCHER: trying to notify the job_runner thread.
02:08:34 HBMASTER: job (4, 0, 6) submitted to dispatcher
02:08:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:34 DISPATCHER: Trying to submit another job.
02:08:34 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:08:34 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:08:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:34 WORKER: start processing job (4, 0, 6)
02:08:34 WORKER: args: ()
02:08:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 573, 'last_n_outputs': 21, 'leak_rate': 0.8321940920065769, 'lr': 0.014137129553667256, 'optimizer': 'SGD', 'sparsity': 0.9037625785740799, 'steps_to_train': 82, 'weight_decay': 0.013467407026929782}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:08:40 DISPATCHER: Starting worker discovery
02:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:40 DISPATCHER: Finished worker discovery
02:09:29 WORKER: done with job (4, 0, 6), trying to register it.
02:09:29 WORKER: registered result for job (4, 0, 6) with dispatcher
02:09:29 DISPATCHER: job (4, 0, 6) finished
02:09:29 DISPATCHER: register_result: lock acquired
02:09:29 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:09:29 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 573, 'last_n_outputs': 21, 'leak_rate': 0.8321940920065769, 'lr': 0.014137129553667256, 'optimizer': 'SGD', 'sparsity': 0.9037625785740799, 'steps_to_train': 82, 'weight_decay': 0.013467407026929782}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9219274857095271, 'info': {'number_mnist': 0.9219274857095271, 'config': "{'batch_size': 16, 'hidden_dim': 573, 'last_n_outputs': 21, 'leak_rate': 0.8321940920065769, 'lr': 0.014137129553667256, 'optimizer': 'SGD', 'sparsity': 0.9037625785740799, 'steps_to_train': 82, 'weight_decay': 0.013467407026929782}"}}
exception: None

02:09:29 job_callback for (4, 0, 6) started
02:09:29 job_callback for (4, 0, 6) got condition
02:09:29 DISPATCHER: Trying to submit another job.
02:09:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:09:29 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.932983





02:09:29 HBMASTER: Trying to run another job!
02:09:29 job_callback for (4, 0, 6) finished
02:09:29 start sampling a new configuration.
02:09:29 done sampling a new configuration.
02:09:29 HBMASTER: schedule new run for iteration 4
02:09:29 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
02:09:29 HBMASTER: submitting job (4, 0, 7) to dispatcher
02:09:29 DISPATCHER: trying to submit job (4, 0, 7)
02:09:29 DISPATCHER: trying to notify the job_runner thread.
02:09:29 HBMASTER: job (4, 0, 7) submitted to dispatcher
02:09:29 DISPATCHER: Trying to submit another job.
02:09:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:09:29 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:09:29 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:09:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:09:29 WORKER: start processing job (4, 0, 7)
02:09:29 WORKER: args: ()
02:09:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 21, 'leak_rate': 0.7893925384280664, 'lr': 0.009211785621215508, 'optimizer': 'SGD', 'sparsity': 0.9530549994582724, 'steps_to_train': 78, 'weight_decay': 0.0885586773689844}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:09:40 DISPATCHER: Starting worker discovery
02:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:40 DISPATCHER: Finished worker discovery
02:10:23 WORKER: done with job (4, 0, 7), trying to register it.
02:10:23 WORKER: registered result for job (4, 0, 7) with dispatcher
02:10:23 DISPATCHER: job (4, 0, 7) finished
02:10:23 DISPATCHER: register_result: lock acquired
02:10:23 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:10:23 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 21, 'leak_rate': 0.7893925384280664, 'lr': 0.009211785621215508, 'optimizer': 'SGD', 'sparsity': 0.9530549994582724, 'steps_to_train': 78, 'weight_decay': 0.0885586773689844}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9012241824543717, 'info': {'number_mnist': 0.9012241824543717, 'config': "{'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 21, 'leak_rate': 0.7893925384280664, 'lr': 0.009211785621215508, 'optimizer': 'SGD', 'sparsity': 0.9530549994582724, 'steps_to_train': 78, 'weight_decay': 0.0885586773689844}"}}
exception: None

02:10:23 job_callback for (4, 0, 7) started
02:10:23 DISPATCHER: Trying to submit another job.
02:10:23 job_callback for (4, 0, 7) got condition
02:10:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:10:23 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.932983





02:10:23 HBMASTER: Trying to run another job!
02:10:23 job_callback for (4, 0, 7) finished
02:10:23 start sampling a new configuration.
02:10:23 best_vector: [3, 0.5334566295990555, 0.28532434259446304, 0.43954030577777425, 0.6020370628598813, 1, 0.7041781590975175, 0.7420291215434957, 0.16128707923493513], 0.002128429507432348, 4.819282207471422, 0.010257502455025878
02:10:23 done sampling a new configuration.
02:10:23 HBMASTER: schedule new run for iteration 4
02:10:23 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
02:10:23 HBMASTER: submitting job (4, 0, 8) to dispatcher
02:10:23 DISPATCHER: trying to submit job (4, 0, 8)
02:10:23 DISPATCHER: trying to notify the job_runner thread.
02:10:23 HBMASTER: job (4, 0, 8) submitted to dispatcher
02:10:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:10:23 DISPATCHER: Trying to submit another job.
02:10:23 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:10:23 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:10:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:10:23 WORKER: start processing job (4, 0, 8)
02:10:23 WORKER: args: ()
02:10:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 627, 'last_n_outputs': 21, 'leak_rate': 0.8598850764444436, 'lr': 0.015998310657228128, 'optimizer': 'SGD', 'sparsity': 0.9190027581834042, 'steps_to_train': 77, 'weight_decay': 0.016212102019183872}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:10:40 DISPATCHER: Starting worker discovery
02:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:40 DISPATCHER: Finished worker discovery
02:11:16 WORKER: done with job (4, 0, 8), trying to register it.
02:11:16 WORKER: registered result for job (4, 0, 8) with dispatcher
02:11:16 DISPATCHER: job (4, 0, 8) finished
02:11:16 DISPATCHER: register_result: lock acquired
02:11:16 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:11:16 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 627, 'last_n_outputs': 21, 'leak_rate': 0.8598850764444436, 'lr': 0.015998310657228128, 'optimizer': 'SGD', 'sparsity': 0.9190027581834042, 'steps_to_train': 77, 'weight_decay': 0.016212102019183872}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9383106078455157, 'info': {'number_mnist': 0.9383106078455157, 'config': "{'batch_size': 128, 'hidden_dim': 627, 'last_n_outputs': 21, 'leak_rate': 0.8598850764444436, 'lr': 0.015998310657228128, 'optimizer': 'SGD', 'sparsity': 0.9190027581834042, 'steps_to_train': 77, 'weight_decay': 0.016212102019183872}"}}
exception: None

02:11:16 job_callback for (4, 0, 8) started
02:11:16 DISPATCHER: Trying to submit another job.
02:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:11:16 job_callback for (4, 0, 8) got condition
02:11:16 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.938311





02:11:16 HBMASTER: Trying to run another job!
02:11:16 job_callback for (4, 0, 8) finished
02:11:16 start sampling a new configuration.
02:11:16 done sampling a new configuration.
02:11:16 HBMASTER: schedule new run for iteration 4
02:11:16 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
02:11:16 HBMASTER: submitting job (4, 0, 9) to dispatcher
02:11:16 DISPATCHER: trying to submit job (4, 0, 9)
02:11:16 DISPATCHER: trying to notify the job_runner thread.
02:11:16 HBMASTER: job (4, 0, 9) submitted to dispatcher
02:11:16 DISPATCHER: Trying to submit another job.
02:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:11:16 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:11:16 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:11:16 WORKER: start processing job (4, 0, 9)
02:11:16 WORKER: args: ()
02:11:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 614, 'last_n_outputs': 43, 'leak_rate': 0.8985941621973896, 'lr': 0.01875046532788569, 'optimizer': 'Adam', 'sparsity': 0.9463870104357064, 'steps_to_train': 22, 'weight_decay': 0.03533397120986117}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:11:40 DISPATCHER: Starting worker discovery
02:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:40 DISPATCHER: Finished worker discovery
02:12:10 WORKER: done with job (4, 0, 9), trying to register it.
02:12:10 WORKER: registered result for job (4, 0, 9) with dispatcher
02:12:10 DISPATCHER: job (4, 0, 9) finished
02:12:10 DISPATCHER: register_result: lock acquired
02:12:10 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:12:10 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 614, 'last_n_outputs': 43, 'leak_rate': 0.8985941621973896, 'lr': 0.01875046532788569, 'optimizer': 'Adam', 'sparsity': 0.9463870104357064, 'steps_to_train': 22, 'weight_decay': 0.03533397120986117}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34083386092293255, 'info': {'number_mnist': 0.34083386092293255, 'config': "{'batch_size': 64, 'hidden_dim': 614, 'last_n_outputs': 43, 'leak_rate': 0.8985941621973896, 'lr': 0.01875046532788569, 'optimizer': 'Adam', 'sparsity': 0.9463870104357064, 'steps_to_train': 22, 'weight_decay': 0.03533397120986117}"}}
exception: None

02:12:10 job_callback for (4, 0, 9) started
02:12:10 DISPATCHER: Trying to submit another job.
02:12:10 job_callback for (4, 0, 9) got condition
02:12:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:10 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.938311





02:12:10 HBMASTER: Trying to run another job!
02:12:10 job_callback for (4, 0, 9) finished
02:12:10 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
02:12:11 best_vector: [2, 0.7136964143388038, 0.4063619478749817, 0.05847054512990595, 0.4666206866038983, 1, 0.8091254548549052, 0.24149548176982297, 0.4712487769395488], 0.0037338131802576516, 1.8033741895012518, 0.006733462317696234
02:12:11 done sampling a new configuration.
02:12:11 HBMASTER: schedule new run for iteration 4
02:12:11 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
02:12:11 HBMASTER: submitting job (4, 0, 10) to dispatcher
02:12:11 DISPATCHER: trying to submit job (4, 0, 10)
02:12:11 DISPATCHER: trying to notify the job_runner thread.
02:12:11 HBMASTER: job (4, 0, 10) submitted to dispatcher
02:12:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:11 DISPATCHER: Trying to submit another job.
02:12:11 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:12:11 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:12:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:11 WORKER: start processing job (4, 0, 10)
02:12:11 WORKER: args: ()
02:12:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:12:40 DISPATCHER: Starting worker discovery
02:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:40 DISPATCHER: Finished worker discovery
02:13:04 WORKER: done with job (4, 0, 10), trying to register it.
02:13:04 WORKER: registered result for job (4, 0, 10) with dispatcher
02:13:04 DISPATCHER: job (4, 0, 10) finished
02:13:04 DISPATCHER: register_result: lock acquired
02:13:04 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:13:04 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9363869124964306, 'info': {'number_mnist': 0.9363869124964306, 'config': "{'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}"}}
exception: None

02:13:04 job_callback for (4, 0, 10) started
02:13:04 DISPATCHER: Trying to submit another job.
02:13:04 job_callback for (4, 0, 10) got condition
02:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:13:04 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.938311





02:13:04 HBMASTER: Trying to run another job!
02:13:04 job_callback for (4, 0, 10) finished
02:13:04 start sampling a new configuration.
02:13:05 best_vector: [3, 0.3608642817647599, 0.30439240675426055, 0.43694718401260785, 0.6705810309516542, 1, 0.9918459974765439, 0.9193331257215794, 0.12739397162225996], 0.0006518006933686803, 2.517099835006119, 0.001640647417735179
02:13:05 done sampling a new configuration.
02:13:05 HBMASTER: schedule new run for iteration 4
02:13:05 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
02:13:05 HBMASTER: submitting job (4, 0, 11) to dispatcher
02:13:05 DISPATCHER: trying to submit job (4, 0, 11)
02:13:05 DISPATCHER: trying to notify the job_runner thread.
02:13:05 HBMASTER: job (4, 0, 11) submitted to dispatcher
02:13:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:13:05 DISPATCHER: Trying to submit another job.
02:13:05 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:13:05 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:13:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:13:05 WORKER: start processing job (4, 0, 11)
02:13:05 WORKER: args: ()
02:13:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 22, 'leak_rate': 0.859236796003152, 'lr': 0.021936233580328972, 'optimizer': 'SGD', 'sparsity': 0.9880430393943705, 'steps_to_train': 93, 'weight_decay': 0.014646821145152809}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:13:40 DISPATCHER: Starting worker discovery
02:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:40 DISPATCHER: Finished worker discovery
02:13:59 WORKER: done with job (4, 0, 11), trying to register it.
02:13:59 WORKER: registered result for job (4, 0, 11) with dispatcher
02:13:59 DISPATCHER: job (4, 0, 11) finished
02:13:59 DISPATCHER: register_result: lock acquired
02:13:59 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:13:59 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 22, 'leak_rate': 0.859236796003152, 'lr': 0.021936233580328972, 'optimizer': 'SGD', 'sparsity': 0.9880430393943705, 'steps_to_train': 93, 'weight_decay': 0.014646821145152809}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9427408724446295, 'info': {'number_mnist': 0.9427408724446295, 'config': "{'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 22, 'leak_rate': 0.859236796003152, 'lr': 0.021936233580328972, 'optimizer': 'SGD', 'sparsity': 0.9880430393943705, 'steps_to_train': 93, 'weight_decay': 0.014646821145152809}"}}
exception: None

02:13:59 job_callback for (4, 0, 11) started
02:13:59 job_callback for (4, 0, 11) got condition
02:13:59 DISPATCHER: Trying to submit another job.
02:13:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:13:59 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.942741





02:13:59 HBMASTER: Trying to run another job!
02:13:59 job_callback for (4, 0, 11) finished
02:13:59 start sampling a new configuration.
02:13:59 best_vector: [1, 0.00011781060958898637, 0.33157564547171525, 0.1402273413210522, 0.6395596768701335, 1, 0.706229219672577, 0.8166309066655507, 0.16747099417443528], 0.0003262282975593032, 3.7857329846638286, 0.0012350132266009805
02:13:59 done sampling a new configuration.
02:13:59 HBMASTER: schedule new run for iteration 4
02:13:59 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
02:13:59 HBMASTER: submitting job (4, 0, 12) to dispatcher
02:13:59 DISPATCHER: trying to submit job (4, 0, 12)
02:13:59 DISPATCHER: trying to notify the job_runner thread.
02:13:59 HBMASTER: job (4, 0, 12) submitted to dispatcher
02:13:59 DISPATCHER: Trying to submit another job.
02:13:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:13:59 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:13:59 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:13:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:13:59 WORKER: start processing job (4, 0, 12)
02:13:59 WORKER: args: ()
02:13:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 200, 'last_n_outputs': 23, 'leak_rate': 0.785056835330263, 'lr': 0.01901600810128598, 'optimizer': 'SGD', 'sparsity': 0.9194950127214185, 'steps_to_train': 84, 'weight_decay': 0.016515236104815017}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:14:40 DISPATCHER: Starting worker discovery
02:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:40 DISPATCHER: Finished worker discovery
02:14:53 WORKER: done with job (4, 0, 12), trying to register it.
02:14:53 WORKER: registered result for job (4, 0, 12) with dispatcher
02:14:53 DISPATCHER: job (4, 0, 12) finished
02:14:53 DISPATCHER: register_result: lock acquired
02:14:53 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:14:53 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 200, 'last_n_outputs': 23, 'leak_rate': 0.785056835330263, 'lr': 0.01901600810128598, 'optimizer': 'SGD', 'sparsity': 0.9194950127214185, 'steps_to_train': 84, 'weight_decay': 0.016515236104815017}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8746548165984253, 'info': {'number_mnist': 0.8746548165984253, 'config': "{'batch_size': 32, 'hidden_dim': 200, 'last_n_outputs': 23, 'leak_rate': 0.785056835330263, 'lr': 0.01901600810128598, 'optimizer': 'SGD', 'sparsity': 0.9194950127214185, 'steps_to_train': 84, 'weight_decay': 0.016515236104815017}"}}
exception: None

02:14:53 job_callback for (4, 0, 12) started
02:14:53 DISPATCHER: Trying to submit another job.
02:14:53 job_callback for (4, 0, 12) got condition
02:14:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:14:53 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.942741





02:14:53 HBMASTER: Trying to run another job!
02:14:53 job_callback for (4, 0, 12) finished
02:14:53 start sampling a new configuration.
02:14:53 done sampling a new configuration.
02:14:53 HBMASTER: schedule new run for iteration 4
02:14:53 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
02:14:53 HBMASTER: submitting job (4, 0, 13) to dispatcher
02:14:53 DISPATCHER: trying to submit job (4, 0, 13)
02:14:53 DISPATCHER: trying to notify the job_runner thread.
02:14:53 HBMASTER: job (4, 0, 13) submitted to dispatcher
02:14:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:14:53 DISPATCHER: Trying to submit another job.
02:14:53 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:14:53 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:14:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:14:53 WORKER: start processing job (4, 0, 13)
02:14:53 WORKER: args: ()
02:14:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 531, 'last_n_outputs': 47, 'leak_rate': 0.884374136248678, 'lr': 0.0023043953901348657, 'optimizer': 'SGD', 'sparsity': 0.8263193784536315, 'steps_to_train': 80, 'weight_decay': 0.011182239780519451}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:15:40 DISPATCHER: Starting worker discovery
02:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:40 DISPATCHER: Finished worker discovery
02:15:47 WORKER: done with job (4, 0, 13), trying to register it.
02:15:47 WORKER: registered result for job (4, 0, 13) with dispatcher
02:15:47 DISPATCHER: job (4, 0, 13) finished
02:15:47 DISPATCHER: register_result: lock acquired
02:15:47 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:15:47 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 531, 'last_n_outputs': 47, 'leak_rate': 0.884374136248678, 'lr': 0.0023043953901348657, 'optimizer': 'SGD', 'sparsity': 0.8263193784536315, 'steps_to_train': 80, 'weight_decay': 0.011182239780519451}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8329312845217189, 'info': {'number_mnist': 0.8329312845217189, 'config': "{'batch_size': 64, 'hidden_dim': 531, 'last_n_outputs': 47, 'leak_rate': 0.884374136248678, 'lr': 0.0023043953901348657, 'optimizer': 'SGD', 'sparsity': 0.8263193784536315, 'steps_to_train': 80, 'weight_decay': 0.011182239780519451}"}}
exception: None

02:15:47 job_callback for (4, 0, 13) started
02:15:47 DISPATCHER: Trying to submit another job.
02:15:47 job_callback for (4, 0, 13) got condition
02:15:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:15:47 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.942741





02:15:47 HBMASTER: Trying to run another job!
02:15:47 job_callback for (4, 0, 13) finished
02:15:47 start sampling a new configuration.
02:15:47 done sampling a new configuration.
02:15:47 HBMASTER: schedule new run for iteration 4
02:15:47 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
02:15:47 HBMASTER: submitting job (4, 0, 14) to dispatcher
02:15:47 DISPATCHER: trying to submit job (4, 0, 14)
02:15:47 DISPATCHER: trying to notify the job_runner thread.
02:15:47 HBMASTER: job (4, 0, 14) submitted to dispatcher
02:15:47 DISPATCHER: Trying to submit another job.
02:15:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:15:47 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:15:47 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:15:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:15:47 WORKER: start processing job (4, 0, 14)
02:15:47 WORKER: args: ()
02:15:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 35, 'leak_rate': 0.8330122316458477, 'lr': 0.019626385527445684, 'optimizer': 'SGD', 'sparsity': 0.9700401830164377, 'steps_to_train': 33, 'weight_decay': 0.038186472150382095}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:16:40 DISPATCHER: Starting worker discovery
02:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:40 DISPATCHER: Finished worker discovery
02:16:41 WORKER: done with job (4, 0, 14), trying to register it.
02:16:41 WORKER: registered result for job (4, 0, 14) with dispatcher
02:16:41 DISPATCHER: job (4, 0, 14) finished
02:16:41 DISPATCHER: register_result: lock acquired
02:16:41 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:16:41 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 35, 'leak_rate': 0.8330122316458477, 'lr': 0.019626385527445684, 'optimizer': 'SGD', 'sparsity': 0.9700401830164377, 'steps_to_train': 33, 'weight_decay': 0.038186472150382095}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.940120882496685, 'info': {'number_mnist': 0.940120882496685, 'config': "{'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 35, 'leak_rate': 0.8330122316458477, 'lr': 0.019626385527445684, 'optimizer': 'SGD', 'sparsity': 0.9700401830164377, 'steps_to_train': 33, 'weight_decay': 0.038186472150382095}"}}
exception: None

02:16:41 job_callback for (4, 0, 14) started
02:16:41 job_callback for (4, 0, 14) got condition
02:16:41 DISPATCHER: Trying to submit another job.
02:16:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:16:41 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.942741





02:16:41 HBMASTER: Trying to run another job!
02:16:41 job_callback for (4, 0, 14) finished
02:16:41 start sampling a new configuration.
02:16:41 best_vector: [3, 0.639050886589907, 0.3301391964368321, 0.1338171798384475, 0.3716339150170408, 1, 0.8446808407714638, 0.3044272792859403, 0.5895188658237993], 0.004128619231596125, 8.322307786838165, 0.03435963998000223
02:16:41 done sampling a new configuration.
02:16:41 HBMASTER: schedule new run for iteration 4
02:16:41 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
02:16:41 HBMASTER: submitting job (4, 0, 15) to dispatcher
02:16:41 DISPATCHER: trying to submit job (4, 0, 15)
02:16:41 DISPATCHER: trying to notify the job_runner thread.
02:16:41 HBMASTER: job (4, 0, 15) submitted to dispatcher
02:16:41 DISPATCHER: Trying to submit another job.
02:16:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:16:41 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:16:41 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:16:41 WORKER: start processing job (4, 0, 15)
02:16:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:16:41 WORKER: args: ()
02:16:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 23, 'leak_rate': 0.7834542949596118, 'lr': 0.00553691466273967, 'optimizer': 'SGD', 'sparsity': 0.9527234017851514, 'steps_to_train': 37, 'weight_decay': 0.058476548014026034}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:17:35 WORKER: done with job (4, 0, 15), trying to register it.
02:17:35 WORKER: registered result for job (4, 0, 15) with dispatcher
02:17:35 DISPATCHER: job (4, 0, 15) finished
02:17:35 DISPATCHER: register_result: lock acquired
02:17:35 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:17:35 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 23, 'leak_rate': 0.7834542949596118, 'lr': 0.00553691466273967, 'optimizer': 'SGD', 'sparsity': 0.9527234017851514, 'steps_to_train': 37, 'weight_decay': 0.058476548014026034}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9112101228911715, 'info': {'number_mnist': 0.9112101228911715, 'config': "{'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 23, 'leak_rate': 0.7834542949596118, 'lr': 0.00553691466273967, 'optimizer': 'SGD', 'sparsity': 0.9527234017851514, 'steps_to_train': 37, 'weight_decay': 0.058476548014026034}"}}
exception: None

02:17:35 job_callback for (4, 0, 15) started
02:17:35 DISPATCHER: Trying to submit another job.
02:17:35 job_callback for (4, 0, 15) got condition
02:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:35 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.942741





02:17:35 HBMASTER: Trying to run another job!
02:17:35 job_callback for (4, 0, 15) finished
02:17:35 start sampling a new configuration.
02:17:35 best_vector: [3, 0.44022887141097194, 0.32422854939454965, 0.6417301156117388, 0.6669591085450616, 1, 0.29460835536088675, 0.9536469641664662, 0.1385662026340238], 0.0021977751436917364, 3.210687149675035, 0.007056368411726261
02:17:35 done sampling a new configuration.
02:17:35 HBMASTER: schedule new run for iteration 4
02:17:35 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
02:17:35 HBMASTER: submitting job (4, 0, 16) to dispatcher
02:17:35 DISPATCHER: trying to submit job (4, 0, 16)
02:17:35 DISPATCHER: trying to notify the job_runner thread.
02:17:35 HBMASTER: job (4, 0, 16) submitted to dispatcher
02:17:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:35 DISPATCHER: Trying to submit another job.
02:17:35 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:17:35 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:35 WORKER: start processing job (4, 0, 16)
02:17:35 WORKER: args: ()
02:17:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 552, 'last_n_outputs': 23, 'leak_rate': 0.9104325289029347, 'lr': 0.021573381180079582, 'optimizer': 'SGD', 'sparsity': 0.8207060052866129, 'steps_to_train': 96, 'weight_decay': 0.015145331584767555}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:17:40 DISPATCHER: Starting worker discovery
02:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:40 DISPATCHER: Finished worker discovery
02:18:29 WORKER: done with job (4, 0, 16), trying to register it.
02:18:29 WORKER: registered result for job (4, 0, 16) with dispatcher
02:18:29 DISPATCHER: job (4, 0, 16) finished
02:18:29 DISPATCHER: register_result: lock acquired
02:18:29 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:18:29 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 552, 'last_n_outputs': 23, 'leak_rate': 0.9104325289029347, 'lr': 0.021573381180079582, 'optimizer': 'SGD', 'sparsity': 0.8207060052866129, 'steps_to_train': 96, 'weight_decay': 0.015145331584767555}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9359777460922233, 'info': {'number_mnist': 0.9359777460922233, 'config': "{'batch_size': 128, 'hidden_dim': 552, 'last_n_outputs': 23, 'leak_rate': 0.9104325289029347, 'lr': 0.021573381180079582, 'optimizer': 'SGD', 'sparsity': 0.8207060052866129, 'steps_to_train': 96, 'weight_decay': 0.015145331584767555}"}}
exception: None

02:18:29 job_callback for (4, 0, 16) started
02:18:29 DISPATCHER: Trying to submit another job.
02:18:29 job_callback for (4, 0, 16) got condition
02:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:18:29 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.942741





02:18:29 HBMASTER: Trying to run another job!
02:18:29 job_callback for (4, 0, 16) finished
02:18:29 start sampling a new configuration.
02:18:29 best_vector: [2, 0.7107783646251019, 0.26228411893860726, 0.4650580574930775, 0.6658926337040565, 1, 0.4661875651249646, 0.4981648056466512, 0.1043089394970329], 0.0031380828661913716, 6.10363704829079, 0.019153718842692204
02:18:29 done sampling a new configuration.
02:18:29 HBMASTER: schedule new run for iteration 4
02:18:29 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
02:18:29 HBMASTER: submitting job (4, 0, 17) to dispatcher
02:18:29 DISPATCHER: trying to submit job (4, 0, 17)
02:18:29 DISPATCHER: trying to notify the job_runner thread.
02:18:29 HBMASTER: job (4, 0, 17) submitted to dispatcher
02:18:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:18:29 DISPATCHER: Trying to submit another job.
02:18:29 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:18:29 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:18:29 WORKER: start processing job (4, 0, 17)
02:18:29 WORKER: args: ()
02:18:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:18:40 DISPATCHER: Starting worker discovery
02:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:40 DISPATCHER: Finished worker discovery
02:19:24 WORKER: done with job (4, 0, 17), trying to register it.
02:19:24 WORKER: registered result for job (4, 0, 17) with dispatcher
02:19:24 DISPATCHER: job (4, 0, 17) finished
02:19:24 DISPATCHER: register_result: lock acquired
02:19:24 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:19:24 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9447179141780443, 'info': {'number_mnist': 0.9447179141780443, 'config': "{'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}"}}
exception: None

02:19:24 job_callback for (4, 0, 17) started
02:19:24 DISPATCHER: Trying to submit another job.
02:19:24 job_callback for (4, 0, 17) got condition
02:19:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:19:24 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.944718





02:19:24 HBMASTER: Trying to run another job!
02:19:24 job_callback for (4, 0, 17) finished
02:19:24 start sampling a new configuration.
02:19:24 best_vector: [2, 0.27982051063287205, 0.33438534350756793, 0.7054320386849338, 0.6270156319690361, 1, 0.5155104682511774, 0.970629152098266, 0.066086555096553], 0.00026973102495687917, 21.14853506062237, 0.0057044160382381665
02:19:24 done sampling a new configuration.
02:19:24 HBMASTER: schedule new run for iteration 4
02:19:24 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
02:19:24 HBMASTER: submitting job (4, 0, 18) to dispatcher
02:19:24 DISPATCHER: trying to submit job (4, 0, 18)
02:19:24 DISPATCHER: trying to notify the job_runner thread.
02:19:24 HBMASTER: job (4, 0, 18) submitted to dispatcher
02:19:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:19:24 DISPATCHER: Trying to submit another job.
02:19:24 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:19:24 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:19:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:19:24 WORKER: start processing job (4, 0, 18)
02:19:24 WORKER: args: ()
02:19:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 424, 'last_n_outputs': 23, 'leak_rate': 0.9263580096712334, 'lr': 0.017948628305479507, 'optimizer': 'SGD', 'sparsity': 0.8737225123802825, 'steps_to_train': 98, 'weight_decay': 0.012189351210021104}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:19:40 DISPATCHER: Starting worker discovery
02:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:40 DISPATCHER: Finished worker discovery
02:20:20 WORKER: done with job (4, 0, 18), trying to register it.
02:20:20 WORKER: registered result for job (4, 0, 18) with dispatcher
02:20:20 DISPATCHER: job (4, 0, 18) finished
02:20:20 DISPATCHER: register_result: lock acquired
02:20:20 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:20:20 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 424, 'last_n_outputs': 23, 'leak_rate': 0.9263580096712334, 'lr': 0.017948628305479507, 'optimizer': 'SGD', 'sparsity': 0.8737225123802825, 'steps_to_train': 98, 'weight_decay': 0.012189351210021104}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9195349654526418, 'info': {'number_mnist': 0.9195349654526418, 'config': "{'batch_size': 64, 'hidden_dim': 424, 'last_n_outputs': 23, 'leak_rate': 0.9263580096712334, 'lr': 0.017948628305479507, 'optimizer': 'SGD', 'sparsity': 0.8737225123802825, 'steps_to_train': 98, 'weight_decay': 0.012189351210021104}"}}
exception: None

02:20:20 job_callback for (4, 0, 18) started
02:20:20 DISPATCHER: Trying to submit another job.
02:20:20 job_callback for (4, 0, 18) got condition
02:20:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:20:20 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.944718





02:20:20 HBMASTER: Trying to run another job!
02:20:20 job_callback for (4, 0, 18) finished
02:20:20 start sampling a new configuration.
02:20:20 best_vector: [1, 0.6939421239908294, 0.5613879131883164, 0.3013011161348689, 0.6219503943586611, 1, 0.8070623676031705, 0.17004315394946345, 0.4328106306341636], 0.005487645835262382, 16.645916132775124, 0.09134689234015031
02:20:20 done sampling a new configuration.
02:20:20 HBMASTER: schedule new run for iteration 4
02:20:20 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
02:20:20 HBMASTER: submitting job (4, 0, 19) to dispatcher
02:20:20 DISPATCHER: trying to submit job (4, 0, 19)
02:20:20 DISPATCHER: trying to notify the job_runner thread.
02:20:20 HBMASTER: job (4, 0, 19) submitted to dispatcher
02:20:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:20:20 DISPATCHER: Trying to submit another job.
02:20:20 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:20:20 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:20:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:20:20 WORKER: start processing job (4, 0, 19)
02:20:20 WORKER: args: ()
02:20:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 755, 'last_n_outputs': 33, 'leak_rate': 0.8253252790337172, 'lr': 0.017534798868950315, 'optimizer': 'SGD', 'sparsity': 0.943694968224761, 'steps_to_train': 25, 'weight_decay': 0.03656786566742894}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:20:40 DISPATCHER: Starting worker discovery
02:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:40 DISPATCHER: Finished worker discovery
02:21:15 WORKER: done with job (4, 0, 19), trying to register it.
02:21:15 WORKER: registered result for job (4, 0, 19) with dispatcher
02:21:15 DISPATCHER: job (4, 0, 19) finished
02:21:15 DISPATCHER: register_result: lock acquired
02:21:15 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:21:15 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 755, 'last_n_outputs': 33, 'leak_rate': 0.8253252790337172, 'lr': 0.017534798868950315, 'optimizer': 'SGD', 'sparsity': 0.943694968224761, 'steps_to_train': 25, 'weight_decay': 0.03656786566742894}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9253628301165728, 'info': {'number_mnist': 0.9253628301165728, 'config': "{'batch_size': 32, 'hidden_dim': 755, 'last_n_outputs': 33, 'leak_rate': 0.8253252790337172, 'lr': 0.017534798868950315, 'optimizer': 'SGD', 'sparsity': 0.943694968224761, 'steps_to_train': 25, 'weight_decay': 0.03656786566742894}"}}
exception: None

02:21:15 job_callback for (4, 0, 19) started
02:21:15 job_callback for (4, 0, 19) got condition
02:21:15 DISPATCHER: Trying to submit another job.
02:21:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:21:15 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.944718





02:21:15 HBMASTER: Trying to run another job!
02:21:15 job_callback for (4, 0, 19) finished
02:21:15 start sampling a new configuration.
02:21:15 best_vector: [1, 0.48519462288802173, 0.36862900254476283, 0.414149127098633, 0.5663192597006733, 1, 0.9340232118747879, 0.9077126780233966, 0.18823135131654994], 0.0011864548311058829, 25.315199922323643, 0.03003534124825216
02:21:15 done sampling a new configuration.
02:21:15 HBMASTER: schedule new run for iteration 4
02:21:15 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
02:21:15 HBMASTER: submitting job (4, 0, 20) to dispatcher
02:21:15 DISPATCHER: trying to submit job (4, 0, 20)
02:21:15 DISPATCHER: trying to notify the job_runner thread.
02:21:15 HBMASTER: job (4, 0, 20) submitted to dispatcher
02:21:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:21:15 DISPATCHER: Trying to submit another job.
02:21:15 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:21:15 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:21:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:21:15 WORKER: start processing job (4, 0, 20)
02:21:15 WORKER: args: ()
02:21:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 588, 'last_n_outputs': 25, 'leak_rate': 0.8535372817746583, 'lr': 0.013571833385754555, 'optimizer': 'SGD', 'sparsity': 0.974165570849949, 'steps_to_train': 92, 'weight_decay': 0.017574971692514874}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:21:40 DISPATCHER: Starting worker discovery
02:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:40 DISPATCHER: Finished worker discovery
02:22:08 WORKER: done with job (4, 0, 20), trying to register it.
02:22:08 WORKER: registered result for job (4, 0, 20) with dispatcher
02:22:08 DISPATCHER: job (4, 0, 20) finished
02:22:08 DISPATCHER: register_result: lock acquired
02:22:08 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:22:08 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 588, 'last_n_outputs': 25, 'leak_rate': 0.8535372817746583, 'lr': 0.013571833385754555, 'optimizer': 'SGD', 'sparsity': 0.974165570849949, 'steps_to_train': 92, 'weight_decay': 0.017574971692514874}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9251303491121897, 'info': {'number_mnist': 0.9251303491121897, 'config': "{'batch_size': 32, 'hidden_dim': 588, 'last_n_outputs': 25, 'leak_rate': 0.8535372817746583, 'lr': 0.013571833385754555, 'optimizer': 'SGD', 'sparsity': 0.974165570849949, 'steps_to_train': 92, 'weight_decay': 0.017574971692514874}"}}
exception: None

02:22:08 job_callback for (4, 0, 20) started
02:22:08 DISPATCHER: Trying to submit another job.
02:22:08 job_callback for (4, 0, 20) got condition
02:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:22:08 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.944718





02:22:08 HBMASTER: Trying to run another job!
02:22:08 job_callback for (4, 0, 20) finished
02:22:08 start sampling a new configuration.
02:22:08 best_vector: [1, 0.2754435171967671, 0.4106565032202411, 0.7396713815999054, 0.595326974782803, 1, 0.3444266825604899, 0.3933852740999474, 0.3953829685370379], 0.0032434816013306752, 15.169766758980728, 0.04920285937923166
02:22:08 done sampling a new configuration.
02:22:08 HBMASTER: schedule new run for iteration 4
02:22:08 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
02:22:08 HBMASTER: submitting job (4, 0, 21) to dispatcher
02:22:08 DISPATCHER: trying to submit job (4, 0, 21)
02:22:08 DISPATCHER: trying to notify the job_runner thread.
02:22:08 HBMASTER: job (4, 0, 21) submitted to dispatcher
02:22:08 DISPATCHER: Trying to submit another job.
02:22:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:22:08 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:22:08 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:22:08 WORKER: start processing job (4, 0, 21)
02:22:08 WORKER: args: ()
02:22:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 26, 'leak_rate': 0.9349178453999764, 'lr': 0.01551150544257133, 'optimizer': 'SGD', 'sparsity': 0.8326624038145176, 'steps_to_train': 45, 'weight_decay': 0.03268926093707517}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:22:40 DISPATCHER: Starting worker discovery
02:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:40 DISPATCHER: Finished worker discovery
02:23:02 WORKER: done with job (4, 0, 21), trying to register it.
02:23:02 WORKER: registered result for job (4, 0, 21) with dispatcher
02:23:02 DISPATCHER: job (4, 0, 21) finished
02:23:02 DISPATCHER: register_result: lock acquired
02:23:02 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:23:02 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 26, 'leak_rate': 0.9349178453999764, 'lr': 0.01551150544257133, 'optimizer': 'SGD', 'sparsity': 0.8326624038145176, 'steps_to_train': 45, 'weight_decay': 0.03268926093707517}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9198494986481888, 'info': {'number_mnist': 0.9198494986481888, 'config': "{'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 26, 'leak_rate': 0.9349178453999764, 'lr': 0.01551150544257133, 'optimizer': 'SGD', 'sparsity': 0.8326624038145176, 'steps_to_train': 45, 'weight_decay': 0.03268926093707517}"}}
exception: None

02:23:02 job_callback for (4, 0, 21) started
02:23:02 job_callback for (4, 0, 21) got condition
02:23:02 DISPATCHER: Trying to submit another job.
02:23:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:23:02 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.944718





02:23:02 HBMASTER: Trying to run another job!
02:23:02 job_callback for (4, 0, 21) finished
02:23:02 start sampling a new configuration.
02:23:02 done sampling a new configuration.
02:23:02 HBMASTER: schedule new run for iteration 4
02:23:02 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
02:23:02 HBMASTER: submitting job (4, 0, 22) to dispatcher
02:23:02 DISPATCHER: trying to submit job (4, 0, 22)
02:23:02 DISPATCHER: trying to notify the job_runner thread.
02:23:02 HBMASTER: job (4, 0, 22) submitted to dispatcher
02:23:02 DISPATCHER: Trying to submit another job.
02:23:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:23:02 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:23:02 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:23:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:23:02 WORKER: start processing job (4, 0, 22)
02:23:02 WORKER: args: ()
02:23:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 405, 'last_n_outputs': 37, 'leak_rate': 0.9806848734108928, 'lr': 0.08708517531949535, 'optimizer': 'Adam', 'sparsity': 0.9027863084633836, 'steps_to_train': 11, 'weight_decay': 0.08953589687256988}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:23:40 DISPATCHER: Starting worker discovery
02:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:40 DISPATCHER: Finished worker discovery
02:23:57 WORKER: done with job (4, 0, 22), trying to register it.
02:23:57 WORKER: registered result for job (4, 0, 22) with dispatcher
02:23:57 DISPATCHER: job (4, 0, 22) finished
02:23:57 DISPATCHER: register_result: lock acquired
02:23:57 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:23:57 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 405, 'last_n_outputs': 37, 'leak_rate': 0.9806848734108928, 'lr': 0.08708517531949535, 'optimizer': 'Adam', 'sparsity': 0.9027863084633836, 'steps_to_train': 11, 'weight_decay': 0.08953589687256988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06622078892385558, 'info': {'number_mnist': 0.06622078892385558, 'config': "{'batch_size': 16, 'hidden_dim': 405, 'last_n_outputs': 37, 'leak_rate': 0.9806848734108928, 'lr': 0.08708517531949535, 'optimizer': 'Adam', 'sparsity': 0.9027863084633836, 'steps_to_train': 11, 'weight_decay': 0.08953589687256988}"}}
exception: None

02:23:57 job_callback for (4, 0, 22) started
02:23:57 job_callback for (4, 0, 22) got condition
02:23:57 DISPATCHER: Trying to submit another job.
02:23:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:23:57 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.944718





02:23:57 HBMASTER: Trying to run another job!
02:23:57 job_callback for (4, 0, 22) finished
02:23:57 start sampling a new configuration.
02:23:57 done sampling a new configuration.
02:23:57 HBMASTER: schedule new run for iteration 4
02:23:57 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
02:23:57 HBMASTER: submitting job (4, 0, 23) to dispatcher
02:23:57 DISPATCHER: trying to submit job (4, 0, 23)
02:23:57 DISPATCHER: trying to notify the job_runner thread.
02:23:57 HBMASTER: job (4, 0, 23) submitted to dispatcher
02:23:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:23:57 DISPATCHER: Trying to submit another job.
02:23:57 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:23:57 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:23:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:23:57 WORKER: start processing job (4, 0, 23)
02:23:57 WORKER: args: ()
02:23:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 50, 'leak_rate': 0.7640831106133994, 'lr': 0.019857110752179424, 'optimizer': 'Adam', 'sparsity': 0.9601462932651892, 'steps_to_train': 20, 'weight_decay': 0.01951476494703738}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:24:40 DISPATCHER: Starting worker discovery
02:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:40 DISPATCHER: Finished worker discovery
02:24:51 WORKER: done with job (4, 0, 23), trying to register it.
02:24:51 WORKER: registered result for job (4, 0, 23) with dispatcher
02:24:51 DISPATCHER: job (4, 0, 23) finished
02:24:51 DISPATCHER: register_result: lock acquired
02:24:51 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:24:51 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 50, 'leak_rate': 0.7640831106133994, 'lr': 0.019857110752179424, 'optimizer': 'Adam', 'sparsity': 0.9601462932651892, 'steps_to_train': 20, 'weight_decay': 0.01951476494703738}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.333337215135287, 'info': {'number_mnist': 0.333337215135287, 'config': "{'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 50, 'leak_rate': 0.7640831106133994, 'lr': 0.019857110752179424, 'optimizer': 'Adam', 'sparsity': 0.9601462932651892, 'steps_to_train': 20, 'weight_decay': 0.01951476494703738}"}}
exception: None

02:24:51 job_callback for (4, 0, 23) started
02:24:51 job_callback for (4, 0, 23) got condition
02:24:51 DISPATCHER: Trying to submit another job.
02:24:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:24:51 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.944718





02:24:51 HBMASTER: Trying to run another job!
02:24:51 job_callback for (4, 0, 23) finished
02:24:51 start sampling a new configuration.
02:24:51 best_vector: [3, 0.8938181795729764, 0.1884982301092909, 0.6226221211988554, 0.6207078212340512, 1, 0.18367119770506235, 0.3280125259309301, 0.1563468414037722], 0.0014884821312645658, 2.4776080086426884, 0.0036878752491426255
02:24:51 done sampling a new configuration.
02:24:51 HBMASTER: schedule new run for iteration 4
02:24:51 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
02:24:51 HBMASTER: submitting job (4, 0, 24) to dispatcher
02:24:51 DISPATCHER: trying to submit job (4, 0, 24)
02:24:51 DISPATCHER: trying to notify the job_runner thread.
02:24:51 HBMASTER: job (4, 0, 24) submitted to dispatcher
02:24:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:24:51 DISPATCHER: Trying to submit another job.
02:24:51 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:24:51 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:24:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:24:51 WORKER: start processing job (4, 0, 24)
02:24:51 WORKER: args: ()
02:24:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:25:40 DISPATCHER: Starting worker discovery
02:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:40 DISPATCHER: Finished worker discovery
02:25:46 WORKER: done with job (4, 0, 24), trying to register it.
02:25:46 WORKER: registered result for job (4, 0, 24) with dispatcher
02:25:46 DISPATCHER: job (4, 0, 24) finished
02:25:46 DISPATCHER: register_result: lock acquired
02:25:46 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:25:46 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9481487762268366, 'info': {'number_mnist': 0.9481487762268366, 'config': "{'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}"}}
exception: None

02:25:46 job_callback for (4, 0, 24) started
02:25:46 DISPATCHER: Trying to submit another job.
02:25:46 job_callback for (4, 0, 24) got condition
02:25:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:25:46 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.948149





02:25:46 HBMASTER: Trying to run another job!
02:25:46 job_callback for (4, 0, 24) finished
02:25:46 start sampling a new configuration.
02:25:46 best_vector: [1, 0.9283603674020557, 0.08076476889434145, 0.8971436316518491, 0.6541268526197533, 1, 0.21408414627522887, 0.012292220632486583, 0.3605837547350898], 0.0009841216715277127, 0.62498086671484, 0.000615057215224247
02:25:46 done sampling a new configuration.
02:25:46 HBMASTER: schedule new run for iteration 4
02:25:46 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
02:25:46 HBMASTER: submitting job (4, 0, 25) to dispatcher
02:25:46 DISPATCHER: trying to submit job (4, 0, 25)
02:25:46 DISPATCHER: trying to notify the job_runner thread.
02:25:46 HBMASTER: job (4, 0, 25) submitted to dispatcher
02:25:46 DISPATCHER: Trying to submit another job.
02:25:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:25:46 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:25:46 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:25:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:25:46 WORKER: start processing job (4, 0, 25)
02:25:46 WORKER: args: ()
02:25:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 943, 'last_n_outputs': 13, 'leak_rate': 0.9742859079129622, 'lr': 0.02033544615844506, 'optimizer': 'SGD', 'sparsity': 0.801380195106055, 'steps_to_train': 11, 'weight_decay': 0.02945305042038728}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:26:40 DISPATCHER: Starting worker discovery
02:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:40 DISPATCHER: Finished worker discovery
02:26:42 WORKER: done with job (4, 0, 25), trying to register it.
02:26:42 WORKER: registered result for job (4, 0, 25) with dispatcher
02:26:42 DISPATCHER: job (4, 0, 25) finished
02:26:42 DISPATCHER: register_result: lock acquired
02:26:42 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:26:42 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 943, 'last_n_outputs': 13, 'leak_rate': 0.9742859079129622, 'lr': 0.02033544615844506, 'optimizer': 'SGD', 'sparsity': 0.801380195106055, 'steps_to_train': 11, 'weight_decay': 0.02945305042038728}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9229102779777685, 'info': {'number_mnist': 0.9229102779777685, 'config': "{'batch_size': 32, 'hidden_dim': 943, 'last_n_outputs': 13, 'leak_rate': 0.9742859079129622, 'lr': 0.02033544615844506, 'optimizer': 'SGD', 'sparsity': 0.801380195106055, 'steps_to_train': 11, 'weight_decay': 0.02945305042038728}"}}
exception: None

02:26:42 job_callback for (4, 0, 25) started
02:26:42 job_callback for (4, 0, 25) got condition
02:26:42 DISPATCHER: Trying to submit another job.
02:26:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:26:42 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.948149





02:26:42 HBMASTER: Trying to run another job!
02:26:42 job_callback for (4, 0, 25) finished
02:26:42 start sampling a new configuration.
02:26:42 done sampling a new configuration.
02:26:42 HBMASTER: schedule new run for iteration 4
02:26:42 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
02:26:42 HBMASTER: submitting job (4, 0, 26) to dispatcher
02:26:42 DISPATCHER: trying to submit job (4, 0, 26)
02:26:42 DISPATCHER: trying to notify the job_runner thread.
02:26:42 HBMASTER: job (4, 0, 26) submitted to dispatcher
02:26:42 DISPATCHER: Trying to submit another job.
02:26:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:26:42 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:26:42 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:26:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:26:42 WORKER: start processing job (4, 0, 26)
02:26:42 WORKER: args: ()
02:26:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 338, 'last_n_outputs': 15, 'leak_rate': 0.8374167573098722, 'lr': 0.020876379488205074, 'optimizer': 'SGD', 'sparsity': 0.9664694969549312, 'steps_to_train': 57, 'weight_decay': 0.06885158093719647}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:27:35 WORKER: done with job (4, 0, 26), trying to register it.
02:27:35 WORKER: registered result for job (4, 0, 26) with dispatcher
02:27:35 DISPATCHER: job (4, 0, 26) finished
02:27:35 DISPATCHER: register_result: lock acquired
02:27:35 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:27:35 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 338, 'last_n_outputs': 15, 'leak_rate': 0.8374167573098722, 'lr': 0.020876379488205074, 'optimizer': 'SGD', 'sparsity': 0.9664694969549312, 'steps_to_train': 57, 'weight_decay': 0.06885158093719647}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8607788970992917, 'info': {'number_mnist': 0.8607788970992917, 'config': "{'batch_size': 32, 'hidden_dim': 338, 'last_n_outputs': 15, 'leak_rate': 0.8374167573098722, 'lr': 0.020876379488205074, 'optimizer': 'SGD', 'sparsity': 0.9664694969549312, 'steps_to_train': 57, 'weight_decay': 0.06885158093719647}"}}
exception: None

02:27:35 job_callback for (4, 0, 26) started
02:27:35 DISPATCHER: Trying to submit another job.
02:27:35 job_callback for (4, 0, 26) got condition
02:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:27:35 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.948149





02:27:35 HBMASTER: Trying to run another job!
02:27:35 job_callback for (4, 0, 26) finished
02:27:35 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
02:27:35 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
02:27:35 HBMASTER: schedule new run for iteration 4
02:27:35 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
02:27:35 HBMASTER: submitting job (4, 0, 1) to dispatcher
02:27:35 DISPATCHER: trying to submit job (4, 0, 1)
02:27:35 DISPATCHER: trying to notify the job_runner thread.
02:27:35 HBMASTER: job (4, 0, 1) submitted to dispatcher
02:27:35 DISPATCHER: Trying to submit another job.
02:27:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:27:35 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:27:35 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:27:35 WORKER: start processing job (4, 0, 1)
02:27:35 WORKER: args: ()
02:27:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 487, 'last_n_outputs': 26, 'leak_rate': 0.9286576122150444, 'lr': 0.018782236280421395, 'optimizer': 'SGD', 'sparsity': 0.8089705855130074, 'steps_to_train': 67, 'weight_decay': 0.02702607168938952}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:27:40 DISPATCHER: Starting worker discovery
02:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:40 DISPATCHER: Finished worker discovery
02:28:40 DISPATCHER: Starting worker discovery
02:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:40 DISPATCHER: Finished worker discovery
02:29:40 DISPATCHER: Starting worker discovery
02:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:40 DISPATCHER: Finished worker discovery
02:29:59 WORKER: done with job (4, 0, 1), trying to register it.
02:29:59 WORKER: registered result for job (4, 0, 1) with dispatcher
02:29:59 DISPATCHER: job (4, 0, 1) finished
02:29:59 DISPATCHER: register_result: lock acquired
02:29:59 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:29:59 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 487, 'last_n_outputs': 26, 'leak_rate': 0.9286576122150444, 'lr': 0.018782236280421395, 'optimizer': 'SGD', 'sparsity': 0.8089705855130074, 'steps_to_train': 67, 'weight_decay': 0.02702607168938952}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9218903844707319, 'info': {'number_mnist': 0.9218903844707319, 'config': "{'batch_size': 16, 'hidden_dim': 487, 'last_n_outputs': 26, 'leak_rate': 0.9286576122150444, 'lr': 0.018782236280421395, 'optimizer': 'SGD', 'sparsity': 0.8089705855130074, 'steps_to_train': 67, 'weight_decay': 0.02702607168938952}"}}
exception: None

02:29:59 job_callback for (4, 0, 1) started
02:29:59 DISPATCHER: Trying to submit another job.
02:29:59 job_callback for (4, 0, 1) got condition
02:29:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:29:59 HBMASTER: Trying to run another job!
02:29:59 job_callback for (4, 0, 1) finished
02:29:59 HBMASTER: schedule new run for iteration 4
02:29:59 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
02:29:59 HBMASTER: submitting job (4, 0, 2) to dispatcher
02:29:59 DISPATCHER: trying to submit job (4, 0, 2)
02:29:59 DISPATCHER: trying to notify the job_runner thread.
02:29:59 HBMASTER: job (4, 0, 2) submitted to dispatcher
02:29:59 DISPATCHER: Trying to submit another job.
02:29:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:29:59 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:29:59 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:29:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:29:59 WORKER: start processing job (4, 0, 2)
02:29:59 WORKER: args: ()
02:29:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 516, 'last_n_outputs': 22, 'leak_rate': 0.8624445560944135, 'lr': 0.012506714468175984, 'optimizer': 'SGD', 'sparsity': 0.9150652180591434, 'steps_to_train': 87, 'weight_decay': 0.010755997851582166}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:30:40 DISPATCHER: Starting worker discovery
02:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:40 DISPATCHER: Finished worker discovery
02:31:40 DISPATCHER: Starting worker discovery
02:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:40 DISPATCHER: Finished worker discovery
02:32:23 WORKER: done with job (4, 0, 2), trying to register it.
02:32:23 WORKER: registered result for job (4, 0, 2) with dispatcher
02:32:23 DISPATCHER: job (4, 0, 2) finished
02:32:23 DISPATCHER: register_result: lock acquired
02:32:23 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:32:23 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 516, 'last_n_outputs': 22, 'leak_rate': 0.8624445560944135, 'lr': 0.012506714468175984, 'optimizer': 'SGD', 'sparsity': 0.9150652180591434, 'steps_to_train': 87, 'weight_decay': 0.010755997851582166}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9303316129571164, 'info': {'number_mnist': 0.9303316129571164, 'config': "{'batch_size': 32, 'hidden_dim': 516, 'last_n_outputs': 22, 'leak_rate': 0.8624445560944135, 'lr': 0.012506714468175984, 'optimizer': 'SGD', 'sparsity': 0.9150652180591434, 'steps_to_train': 87, 'weight_decay': 0.010755997851582166}"}}
exception: None

02:32:23 job_callback for (4, 0, 2) started
02:32:23 job_callback for (4, 0, 2) got condition
02:32:23 DISPATCHER: Trying to submit another job.
02:32:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:32:23 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.930332





02:32:23 HBMASTER: Trying to run another job!
02:32:23 job_callback for (4, 0, 2) finished
02:32:23 HBMASTER: schedule new run for iteration 4
02:32:23 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
02:32:23 HBMASTER: submitting job (4, 0, 8) to dispatcher
02:32:23 DISPATCHER: trying to submit job (4, 0, 8)
02:32:23 DISPATCHER: trying to notify the job_runner thread.
02:32:23 HBMASTER: job (4, 0, 8) submitted to dispatcher
02:32:23 DISPATCHER: Trying to submit another job.
02:32:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:32:23 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:32:23 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:32:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:32:23 WORKER: start processing job (4, 0, 8)
02:32:23 WORKER: args: ()
02:32:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 627, 'last_n_outputs': 21, 'leak_rate': 0.8598850764444436, 'lr': 0.015998310657228128, 'optimizer': 'SGD', 'sparsity': 0.9190027581834042, 'steps_to_train': 77, 'weight_decay': 0.016212102019183872}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:32:40 DISPATCHER: Starting worker discovery
02:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:40 DISPATCHER: Finished worker discovery
02:33:40 DISPATCHER: Starting worker discovery
02:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:40 DISPATCHER: Finished worker discovery
02:34:40 DISPATCHER: Starting worker discovery
02:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:40 DISPATCHER: Finished worker discovery
02:34:47 WORKER: done with job (4, 0, 8), trying to register it.
02:34:47 WORKER: registered result for job (4, 0, 8) with dispatcher
02:34:47 DISPATCHER: job (4, 0, 8) finished
02:34:47 DISPATCHER: register_result: lock acquired
02:34:47 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:34:47 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 627, 'last_n_outputs': 21, 'leak_rate': 0.8598850764444436, 'lr': 0.015998310657228128, 'optimizer': 'SGD', 'sparsity': 0.9190027581834042, 'steps_to_train': 77, 'weight_decay': 0.016212102019183872}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9398450565362709, 'info': {'number_mnist': 0.9398450565362709, 'config': "{'batch_size': 128, 'hidden_dim': 627, 'last_n_outputs': 21, 'leak_rate': 0.8598850764444436, 'lr': 0.015998310657228128, 'optimizer': 'SGD', 'sparsity': 0.9190027581834042, 'steps_to_train': 77, 'weight_decay': 0.016212102019183872}"}}
exception: None

02:34:47 job_callback for (4, 0, 8) started
02:34:47 DISPATCHER: Trying to submit another job.
02:34:47 job_callback for (4, 0, 8) got condition
02:34:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:34:47 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.939845





02:34:47 HBMASTER: Trying to run another job!
02:34:47 job_callback for (4, 0, 8) finished
02:34:47 HBMASTER: schedule new run for iteration 4
02:34:47 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
02:34:47 HBMASTER: submitting job (4, 0, 10) to dispatcher
02:34:47 DISPATCHER: trying to submit job (4, 0, 10)
02:34:47 DISPATCHER: trying to notify the job_runner thread.
02:34:47 HBMASTER: job (4, 0, 10) submitted to dispatcher
02:34:47 DISPATCHER: Trying to submit another job.
02:34:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:34:47 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:34:47 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:34:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:34:47 WORKER: start processing job (4, 0, 10)
02:34:47 WORKER: args: ()
02:34:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:35:40 DISPATCHER: Starting worker discovery
02:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:40 DISPATCHER: Finished worker discovery
02:36:40 DISPATCHER: Starting worker discovery
02:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:40 DISPATCHER: Finished worker discovery
02:37:12 WORKER: done with job (4, 0, 10), trying to register it.
02:37:12 WORKER: registered result for job (4, 0, 10) with dispatcher
02:37:12 DISPATCHER: job (4, 0, 10) finished
02:37:12 DISPATCHER: register_result: lock acquired
02:37:12 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:37:12 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9433062295060299, 'info': {'number_mnist': 0.9433062295060299, 'config': "{'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}"}}
exception: None

02:37:12 job_callback for (4, 0, 10) started
02:37:12 job_callback for (4, 0, 10) got condition
02:37:12 DISPATCHER: Trying to submit another job.
02:37:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:37:12 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.943306





02:37:12 HBMASTER: Trying to run another job!
02:37:12 job_callback for (4, 0, 10) finished
02:37:12 HBMASTER: schedule new run for iteration 4
02:37:12 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
02:37:12 HBMASTER: submitting job (4, 0, 11) to dispatcher
02:37:12 DISPATCHER: trying to submit job (4, 0, 11)
02:37:12 DISPATCHER: trying to notify the job_runner thread.
02:37:12 HBMASTER: job (4, 0, 11) submitted to dispatcher
02:37:12 DISPATCHER: Trying to submit another job.
02:37:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:37:12 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:37:12 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:37:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:37:12 WORKER: start processing job (4, 0, 11)
02:37:12 WORKER: args: ()
02:37:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 22, 'leak_rate': 0.859236796003152, 'lr': 0.021936233580328972, 'optimizer': 'SGD', 'sparsity': 0.9880430393943705, 'steps_to_train': 93, 'weight_decay': 0.014646821145152809}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:37:40 DISPATCHER: Starting worker discovery
02:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:40 DISPATCHER: Finished worker discovery
02:38:40 DISPATCHER: Starting worker discovery
02:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:40 DISPATCHER: Finished worker discovery
02:39:36 WORKER: done with job (4, 0, 11), trying to register it.
02:39:36 WORKER: registered result for job (4, 0, 11) with dispatcher
02:39:36 DISPATCHER: job (4, 0, 11) finished
02:39:36 DISPATCHER: register_result: lock acquired
02:39:36 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:39:36 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 22, 'leak_rate': 0.859236796003152, 'lr': 0.021936233580328972, 'optimizer': 'SGD', 'sparsity': 0.9880430393943705, 'steps_to_train': 93, 'weight_decay': 0.014646821145152809}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9296660232762073, 'info': {'number_mnist': 0.9296660232762073, 'config': "{'batch_size': 128, 'hidden_dim': 489, 'last_n_outputs': 22, 'leak_rate': 0.859236796003152, 'lr': 0.021936233580328972, 'optimizer': 'SGD', 'sparsity': 0.9880430393943705, 'steps_to_train': 93, 'weight_decay': 0.014646821145152809}"}}
exception: None

02:39:36 job_callback for (4, 0, 11) started
02:39:36 job_callback for (4, 0, 11) got condition
02:39:36 DISPATCHER: Trying to submit another job.
02:39:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:39:36 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.943306





02:39:36 HBMASTER: Trying to run another job!
02:39:36 job_callback for (4, 0, 11) finished
02:39:36 HBMASTER: schedule new run for iteration 4
02:39:36 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
02:39:36 HBMASTER: submitting job (4, 0, 14) to dispatcher
02:39:36 DISPATCHER: trying to submit job (4, 0, 14)
02:39:36 DISPATCHER: trying to notify the job_runner thread.
02:39:36 HBMASTER: job (4, 0, 14) submitted to dispatcher
02:39:36 DISPATCHER: Trying to submit another job.
02:39:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:39:36 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:39:36 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:39:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:39:36 WORKER: start processing job (4, 0, 14)
02:39:36 WORKER: args: ()
02:39:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 35, 'leak_rate': 0.8330122316458477, 'lr': 0.019626385527445684, 'optimizer': 'SGD', 'sparsity': 0.9700401830164377, 'steps_to_train': 33, 'weight_decay': 0.038186472150382095}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:39:40 DISPATCHER: Starting worker discovery
02:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:40 DISPATCHER: Finished worker discovery
02:40:40 DISPATCHER: Starting worker discovery
02:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:40 DISPATCHER: Finished worker discovery
02:41:40 DISPATCHER: Starting worker discovery
02:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:40 DISPATCHER: Finished worker discovery
02:42:00 WORKER: done with job (4, 0, 14), trying to register it.
02:42:00 WORKER: registered result for job (4, 0, 14) with dispatcher
02:42:00 DISPATCHER: job (4, 0, 14) finished
02:42:00 DISPATCHER: register_result: lock acquired
02:42:00 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:42:00 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 35, 'leak_rate': 0.8330122316458477, 'lr': 0.019626385527445684, 'optimizer': 'SGD', 'sparsity': 0.9700401830164377, 'steps_to_train': 33, 'weight_decay': 0.038186472150382095}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9398346070535293, 'info': {'number_mnist': 0.9398346070535293, 'config': "{'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 35, 'leak_rate': 0.8330122316458477, 'lr': 0.019626385527445684, 'optimizer': 'SGD', 'sparsity': 0.9700401830164377, 'steps_to_train': 33, 'weight_decay': 0.038186472150382095}"}}
exception: None

02:42:00 job_callback for (4, 0, 14) started
02:42:00 DISPATCHER: Trying to submit another job.
02:42:00 job_callback for (4, 0, 14) got condition
02:42:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:42:00 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.943306





02:42:00 HBMASTER: Trying to run another job!
02:42:00 job_callback for (4, 0, 14) finished
02:42:00 HBMASTER: schedule new run for iteration 4
02:42:00 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
02:42:00 HBMASTER: submitting job (4, 0, 16) to dispatcher
02:42:00 DISPATCHER: trying to submit job (4, 0, 16)
02:42:00 DISPATCHER: trying to notify the job_runner thread.
02:42:00 HBMASTER: job (4, 0, 16) submitted to dispatcher
02:42:00 DISPATCHER: Trying to submit another job.
02:42:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:42:00 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:42:00 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:42:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:42:00 WORKER: start processing job (4, 0, 16)
02:42:00 WORKER: args: ()
02:42:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 552, 'last_n_outputs': 23, 'leak_rate': 0.9104325289029347, 'lr': 0.021573381180079582, 'optimizer': 'SGD', 'sparsity': 0.8207060052866129, 'steps_to_train': 96, 'weight_decay': 0.015145331584767555}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:42:40 DISPATCHER: Starting worker discovery
02:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:40 DISPATCHER: Finished worker discovery
02:43:40 DISPATCHER: Starting worker discovery
02:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:40 DISPATCHER: Finished worker discovery
02:44:25 WORKER: done with job (4, 0, 16), trying to register it.
02:44:25 WORKER: registered result for job (4, 0, 16) with dispatcher
02:44:25 DISPATCHER: job (4, 0, 16) finished
02:44:25 DISPATCHER: register_result: lock acquired
02:44:25 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:44:25 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 552, 'last_n_outputs': 23, 'leak_rate': 0.9104325289029347, 'lr': 0.021573381180079582, 'optimizer': 'SGD', 'sparsity': 0.8207060052866129, 'steps_to_train': 96, 'weight_decay': 0.015145331584767555}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9323490169439361, 'info': {'number_mnist': 0.9323490169439361, 'config': "{'batch_size': 128, 'hidden_dim': 552, 'last_n_outputs': 23, 'leak_rate': 0.9104325289029347, 'lr': 0.021573381180079582, 'optimizer': 'SGD', 'sparsity': 0.8207060052866129, 'steps_to_train': 96, 'weight_decay': 0.015145331584767555}"}}
exception: None

02:44:25 job_callback for (4, 0, 16) started
02:44:25 DISPATCHER: Trying to submit another job.
02:44:25 job_callback for (4, 0, 16) got condition
02:44:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:44:25 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.943306





02:44:25 HBMASTER: Trying to run another job!
02:44:25 job_callback for (4, 0, 16) finished
02:44:25 HBMASTER: schedule new run for iteration 4
02:44:25 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
02:44:25 HBMASTER: submitting job (4, 0, 17) to dispatcher
02:44:25 DISPATCHER: trying to submit job (4, 0, 17)
02:44:25 DISPATCHER: trying to notify the job_runner thread.
02:44:25 HBMASTER: job (4, 0, 17) submitted to dispatcher
02:44:25 DISPATCHER: Trying to submit another job.
02:44:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:44:25 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:44:25 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:44:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:44:25 WORKER: start processing job (4, 0, 17)
02:44:25 WORKER: args: ()
02:44:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:44:40 DISPATCHER: Starting worker discovery
02:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:40 DISPATCHER: Finished worker discovery
02:45:40 DISPATCHER: Starting worker discovery
02:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:40 DISPATCHER: Finished worker discovery
02:46:40 DISPATCHER: Starting worker discovery
02:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:40 DISPATCHER: Finished worker discovery
02:46:48 WORKER: done with job (4, 0, 17), trying to register it.
02:46:48 WORKER: registered result for job (4, 0, 17) with dispatcher
02:46:48 DISPATCHER: job (4, 0, 17) finished
02:46:48 DISPATCHER: register_result: lock acquired
02:46:48 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:46:48 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9500332732631438, 'info': {'number_mnist': 0.9500332732631438, 'config': "{'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}"}}
exception: None

02:46:48 job_callback for (4, 0, 17) started
02:46:48 DISPATCHER: Trying to submit another job.
02:46:48 job_callback for (4, 0, 17) got condition
02:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:46:48 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.950033





02:46:48 HBMASTER: Trying to run another job!
02:46:48 job_callback for (4, 0, 17) finished
02:46:48 HBMASTER: schedule new run for iteration 4
02:46:48 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
02:46:48 HBMASTER: submitting job (4, 0, 24) to dispatcher
02:46:48 DISPATCHER: trying to submit job (4, 0, 24)
02:46:48 DISPATCHER: trying to notify the job_runner thread.
02:46:48 HBMASTER: job (4, 0, 24) submitted to dispatcher
02:46:48 DISPATCHER: Trying to submit another job.
02:46:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:46:48 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:46:48 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:46:48 WORKER: start processing job (4, 0, 24)
02:46:48 WORKER: args: ()
02:46:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:47:40 DISPATCHER: Starting worker discovery
02:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:40 DISPATCHER: Finished worker discovery
02:48:40 DISPATCHER: Starting worker discovery
02:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:40 DISPATCHER: Finished worker discovery
02:49:13 WORKER: done with job (4, 0, 24), trying to register it.
02:49:13 WORKER: registered result for job (4, 0, 24) with dispatcher
02:49:13 DISPATCHER: job (4, 0, 24) finished
02:49:13 DISPATCHER: register_result: lock acquired
02:49:13 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:49:13 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9532987333911627, 'info': {'number_mnist': 0.9532987333911627, 'config': "{'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}"}}
exception: None

02:49:13 job_callback for (4, 0, 24) started
02:49:13 DISPATCHER: Trying to submit another job.
02:49:13 job_callback for (4, 0, 24) got condition
02:49:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:49:13 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.953299





02:49:13 HBMASTER: Trying to run another job!
02:49:13 job_callback for (4, 0, 24) finished
02:49:13 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
02:49:13 ITERATION: Advancing config (4, 0, 17) to next budget 400.000000
02:49:13 ITERATION: Advancing config (4, 0, 24) to next budget 400.000000
02:49:13 HBMASTER: schedule new run for iteration 4
02:49:13 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
02:49:13 HBMASTER: submitting job (4, 0, 10) to dispatcher
02:49:13 DISPATCHER: trying to submit job (4, 0, 10)
02:49:13 DISPATCHER: trying to notify the job_runner thread.
02:49:13 HBMASTER: job (4, 0, 10) submitted to dispatcher
02:49:13 DISPATCHER: Trying to submit another job.
02:49:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:49:13 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:49:13 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:49:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:49:13 WORKER: start processing job (4, 0, 10)
02:49:13 WORKER: args: ()
02:49:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}, 'budget': 400.0, 'working_directory': '.'}
02:49:40 DISPATCHER: Starting worker discovery
02:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:40 DISPATCHER: Finished worker discovery
02:50:40 DISPATCHER: Starting worker discovery
02:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:40 DISPATCHER: Finished worker discovery
02:51:40 DISPATCHER: Starting worker discovery
02:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:40 DISPATCHER: Finished worker discovery
02:52:40 DISPATCHER: Starting worker discovery
02:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:40 DISPATCHER: Finished worker discovery
02:53:40 DISPATCHER: Starting worker discovery
02:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:40 DISPATCHER: Finished worker discovery
02:54:40 DISPATCHER: Starting worker discovery
02:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:40 DISPATCHER: Finished worker discovery
02:55:40 DISPATCHER: Starting worker discovery
02:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:40 DISPATCHER: Finished worker discovery
02:56:10 WORKER: done with job (4, 0, 10), trying to register it.
02:56:10 WORKER: registered result for job (4, 0, 10) with dispatcher
02:56:10 DISPATCHER: job (4, 0, 10) finished
02:56:10 DISPATCHER: register_result: lock acquired
02:56:10 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:56:10 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9299075819309881, 'info': {'number_mnist': 0.9299075819309881, 'config': "{'batch_size': 64, 'hidden_dim': 771, 'last_n_outputs': 26, 'leak_rate': 0.7646176362824765, 'lr': 0.008575143041295936, 'optimizer': 'SGD', 'sparsity': 0.9441901091651772, 'steps_to_train': 31, 'weight_decay': 0.04103068752456969}"}}
exception: None

02:56:10 job_callback for (4, 0, 10) started
02:56:10 DISPATCHER: Trying to submit another job.
02:56:10 job_callback for (4, 0, 10) got condition
02:56:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:56:10 HBMASTER: Trying to run another job!
02:56:10 job_callback for (4, 0, 10) finished
02:56:10 HBMASTER: schedule new run for iteration 4
02:56:10 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
02:56:10 HBMASTER: submitting job (4, 0, 17) to dispatcher
02:56:10 DISPATCHER: trying to submit job (4, 0, 17)
02:56:10 DISPATCHER: trying to notify the job_runner thread.
02:56:10 HBMASTER: job (4, 0, 17) submitted to dispatcher
02:56:10 DISPATCHER: Trying to submit another job.
02:56:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:56:10 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:56:10 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:56:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:56:10 WORKER: start processing job (4, 0, 17)
02:56:10 WORKER: args: ()
02:56:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}, 'budget': 400.0, 'working_directory': '.'}
02:56:40 DISPATCHER: Starting worker discovery
02:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:40 DISPATCHER: Finished worker discovery
02:57:40 DISPATCHER: Starting worker discovery
02:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:40 DISPATCHER: Finished worker discovery
02:58:40 DISPATCHER: Starting worker discovery
02:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:40 DISPATCHER: Finished worker discovery
02:59:40 DISPATCHER: Starting worker discovery
02:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:40 DISPATCHER: Finished worker discovery
03:00:40 DISPATCHER: Starting worker discovery
03:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:40 DISPATCHER: Finished worker discovery
03:01:40 DISPATCHER: Starting worker discovery
03:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:40 DISPATCHER: Finished worker discovery
03:02:40 DISPATCHER: Starting worker discovery
03:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:40 DISPATCHER: Finished worker discovery
03:03:03 WORKER: done with job (4, 0, 17), trying to register it.
03:03:03 WORKER: registered result for job (4, 0, 17) with dispatcher
03:03:03 DISPATCHER: job (4, 0, 17) finished
03:03:03 DISPATCHER: register_result: lock acquired
03:03:03 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:03:03 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9527806177564531, 'info': {'number_mnist': 0.9527806177564531, 'config': "{'batch_size': 64, 'hidden_dim': 769, 'last_n_outputs': 20, 'leak_rate': 0.8662645143732693, 'lr': 0.021467687631890137, 'optimizer': 'SGD', 'sparsity': 0.8618850156299915, 'steps_to_train': 55, 'weight_decay': 0.013668128687729618}"}}
exception: None

03:03:03 job_callback for (4, 0, 17) started
03:03:03 DISPATCHER: Trying to submit another job.
03:03:03 job_callback for (4, 0, 17) got condition
03:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:03:03 HBMASTER: Trying to run another job!
03:03:03 job_callback for (4, 0, 17) finished
03:03:03 HBMASTER: schedule new run for iteration 4
03:03:03 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
03:03:03 HBMASTER: submitting job (4, 0, 24) to dispatcher
03:03:03 DISPATCHER: trying to submit job (4, 0, 24)
03:03:03 DISPATCHER: trying to notify the job_runner thread.
03:03:03 HBMASTER: job (4, 0, 24) submitted to dispatcher
03:03:03 DISPATCHER: Trying to submit another job.
03:03:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:03:03 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:03:03 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:03:03 WORKER: start processing job (4, 0, 24)
03:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:03:03 WORKER: args: ()
03:03:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 400.0, 'working_directory': '.'}
03:03:40 DISPATCHER: Starting worker discovery
03:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:40 DISPATCHER: Finished worker discovery
03:04:40 DISPATCHER: Starting worker discovery
03:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:40 DISPATCHER: Finished worker discovery
03:05:40 DISPATCHER: Starting worker discovery
03:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:40 DISPATCHER: Finished worker discovery
03:06:40 DISPATCHER: Starting worker discovery
03:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:40 DISPATCHER: Finished worker discovery
03:07:40 DISPATCHER: Starting worker discovery
03:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:40 DISPATCHER: Finished worker discovery
03:08:40 DISPATCHER: Starting worker discovery
03:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:40 DISPATCHER: Finished worker discovery
03:09:40 DISPATCHER: Starting worker discovery
03:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:41 DISPATCHER: Finished worker discovery
03:09:59 WORKER: done with job (4, 0, 24), trying to register it.
03:09:59 WORKER: registered result for job (4, 0, 24) with dispatcher
03:09:59 DISPATCHER: job (4, 0, 24) finished
03:09:59 DISPATCHER: register_result: lock acquired
03:09:59 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:09:59 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9530951689468089, 'info': {'number_mnist': 0.9530951689468089, 'config': "{'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}"}}
exception: None

03:09:59 job_callback for (4, 0, 24) started
03:09:59 DISPATCHER: Trying to submit another job.
03:09:59 job_callback for (4, 0, 24) got condition
03:09:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:59 HBMASTER: Trying to run another job!
03:09:59 job_callback for (4, 0, 24) finished
03:09:59 ITERATION: Advancing config (4, 0, 24) to next budget 1200.000000
03:09:59 HBMASTER: schedule new run for iteration 4
03:09:59 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
03:09:59 HBMASTER: submitting job (4, 0, 24) to dispatcher
03:09:59 DISPATCHER: trying to submit job (4, 0, 24)
03:09:59 DISPATCHER: trying to notify the job_runner thread.
03:09:59 HBMASTER: job (4, 0, 24) submitted to dispatcher
03:09:59 DISPATCHER: Trying to submit another job.
03:09:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:59 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:09:59 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:09:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:59 WORKER: start processing job (4, 0, 24)
03:09:59 WORKER: args: ()
03:09:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 1200.0, 'working_directory': '.'}
03:10:41 DISPATCHER: Starting worker discovery
03:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:41 DISPATCHER: Finished worker discovery
03:11:41 DISPATCHER: Starting worker discovery
03:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:41 DISPATCHER: Finished worker discovery
03:12:41 DISPATCHER: Starting worker discovery
03:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:41 DISPATCHER: Finished worker discovery
03:13:41 DISPATCHER: Starting worker discovery
03:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:41 DISPATCHER: Finished worker discovery
03:14:41 DISPATCHER: Starting worker discovery
03:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:41 DISPATCHER: Finished worker discovery
03:15:41 DISPATCHER: Starting worker discovery
03:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:41 DISPATCHER: Finished worker discovery
03:16:41 DISPATCHER: Starting worker discovery
03:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:41 DISPATCHER: Finished worker discovery
03:17:41 DISPATCHER: Starting worker discovery
03:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:41 DISPATCHER: Finished worker discovery
03:18:41 DISPATCHER: Starting worker discovery
03:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:41 DISPATCHER: Finished worker discovery
03:19:41 DISPATCHER: Starting worker discovery
03:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:41 DISPATCHER: Finished worker discovery
03:20:41 DISPATCHER: Starting worker discovery
03:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:41 DISPATCHER: Finished worker discovery
03:21:41 DISPATCHER: Starting worker discovery
03:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:41 DISPATCHER: Finished worker discovery
03:22:41 DISPATCHER: Starting worker discovery
03:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:41 DISPATCHER: Finished worker discovery
03:23:41 DISPATCHER: Starting worker discovery
03:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:41 DISPATCHER: Finished worker discovery
03:24:41 DISPATCHER: Starting worker discovery
03:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:41 DISPATCHER: Finished worker discovery
03:25:41 DISPATCHER: Starting worker discovery
03:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:41 DISPATCHER: Finished worker discovery
03:26:41 DISPATCHER: Starting worker discovery
03:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:41 DISPATCHER: Finished worker discovery
03:27:41 DISPATCHER: Starting worker discovery
03:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:41 DISPATCHER: Finished worker discovery
03:28:41 DISPATCHER: Starting worker discovery
03:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:41 DISPATCHER: Finished worker discovery
03:29:41 DISPATCHER: Starting worker discovery
03:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:41 DISPATCHER: Finished worker discovery
03:30:32 WORKER: done with job (4, 0, 24), trying to register it.
03:30:32 WORKER: registered result for job (4, 0, 24) with dispatcher
03:30:32 DISPATCHER: job (4, 0, 24) finished
03:30:32 DISPATCHER: register_result: lock acquired
03:30:32 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:30:32 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9478255442198341, 'info': {'number_mnist': 0.9478255442198341, 'config': "{'batch_size': 128, 'hidden_dim': 915, 'last_n_outputs': 17, 'leak_rate': 0.9056555302997138, 'lr': 0.017434746713640568, 'optimizer': 'SGD', 'sparsity': 0.794081087449215, 'steps_to_train': 39, 'weight_decay': 0.01597393564344518}"}}
exception: None

03:30:32 job_callback for (4, 0, 24) started
03:30:32 DISPATCHER: Trying to submit another job.
03:30:32 job_callback for (4, 0, 24) got condition
03:30:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:32 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:30:32 HBMASTER: Trying to run another job!
03:30:32 job_callback for (4, 0, 24) finished
03:30:32 start sampling a new configuration.
03:30:32 best_vector: [3, 0.7660846216896058, 0.4191002896919823, 0.5191463323354034, 0.5685170006977999, 1, 0.7871191132911513, 0.9399927689392218, 0.12353613792908827], 0.0010031150837234496, 1.9391307447182318, 0.0019451712993387442
03:30:32 done sampling a new configuration.
03:30:32 HBMASTER: schedule new run for iteration 5
03:30:32 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
03:30:32 HBMASTER: submitting job (5, 0, 0) to dispatcher
03:30:32 DISPATCHER: trying to submit job (5, 0, 0)
03:30:32 DISPATCHER: trying to notify the job_runner thread.
03:30:32 HBMASTER: job (5, 0, 0) submitted to dispatcher
03:30:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:32 DISPATCHER: Trying to submit another job.
03:30:32 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:30:32 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:30:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:32 WORKER: start processing job (5, 0, 0)
03:30:32 WORKER: args: ()
03:30:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:30:41 DISPATCHER: Starting worker discovery
03:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:41 DISPATCHER: Finished worker discovery
03:31:41 DISPATCHER: Starting worker discovery
03:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:41 DISPATCHER: Finished worker discovery
03:32:41 DISPATCHER: Starting worker discovery
03:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:41 DISPATCHER: Finished worker discovery
03:32:56 WORKER: done with job (5, 0, 0), trying to register it.
03:32:56 WORKER: registered result for job (5, 0, 0) with dispatcher
03:32:56 DISPATCHER: job (5, 0, 0) finished
03:32:56 DISPATCHER: register_result: lock acquired
03:32:56 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:32:56 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9519064926028519, 'info': {'number_mnist': 0.9519064926028519, 'config': "{'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}"}}
exception: None

03:32:56 job_callback for (5, 0, 0) started
03:32:56 DISPATCHER: Trying to submit another job.
03:32:56 job_callback for (5, 0, 0) got condition
03:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:32:56 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.953299





03:32:56 HBMASTER: Trying to run another job!
03:32:56 job_callback for (5, 0, 0) finished
03:32:56 start sampling a new configuration.
03:32:56 best_vector: [3, 0.8922356038063701, 0.460435858281832, 0.8112388991546315, 0.6612436178059256, 1, 0.3133549825262113, 0.8954440090172291, 0.1600938924615003], 0.0014746140576316876, 0.37512114359614196, 0.0005531589116617459
03:32:56 done sampling a new configuration.
03:32:56 HBMASTER: schedule new run for iteration 5
03:32:56 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
03:32:56 HBMASTER: submitting job (5, 0, 1) to dispatcher
03:32:56 DISPATCHER: trying to submit job (5, 0, 1)
03:32:56 DISPATCHER: trying to notify the job_runner thread.
03:32:56 HBMASTER: job (5, 0, 1) submitted to dispatcher
03:32:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:32:56 DISPATCHER: Trying to submit another job.
03:32:56 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:32:56 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:32:56 WORKER: start processing job (5, 0, 1)
03:32:56 WORKER: args: ()
03:32:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 914, 'last_n_outputs': 28, 'leak_rate': 0.9528097247886579, 'lr': 0.02101296008759309, 'optimizer': 'SGD', 'sparsity': 0.8252051958062907, 'steps_to_train': 91, 'weight_decay': 0.016154255823550137}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:33:41 DISPATCHER: Starting worker discovery
03:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:41 DISPATCHER: Finished worker discovery
03:34:41 DISPATCHER: Starting worker discovery
03:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:41 DISPATCHER: Finished worker discovery
03:35:21 WORKER: done with job (5, 0, 1), trying to register it.
03:35:21 WORKER: registered result for job (5, 0, 1) with dispatcher
03:35:21 DISPATCHER: job (5, 0, 1) finished
03:35:21 DISPATCHER: register_result: lock acquired
03:35:21 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:35:21 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 914, 'last_n_outputs': 28, 'leak_rate': 0.9528097247886579, 'lr': 0.02101296008759309, 'optimizer': 'SGD', 'sparsity': 0.8252051958062907, 'steps_to_train': 91, 'weight_decay': 0.016154255823550137}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9443451917387189, 'info': {'number_mnist': 0.9443451917387189, 'config': "{'batch_size': 128, 'hidden_dim': 914, 'last_n_outputs': 28, 'leak_rate': 0.9528097247886579, 'lr': 0.02101296008759309, 'optimizer': 'SGD', 'sparsity': 0.8252051958062907, 'steps_to_train': 91, 'weight_decay': 0.016154255823550137}"}}
exception: None

03:35:21 job_callback for (5, 0, 1) started
03:35:21 job_callback for (5, 0, 1) got condition
03:35:21 DISPATCHER: Trying to submit another job.
03:35:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:35:21 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.953299





03:35:21 HBMASTER: Trying to run another job!
03:35:21 job_callback for (5, 0, 1) finished
03:35:21 start sampling a new configuration.
03:35:21 best_vector: [3, 0.6969807053101675, 0.09725012254541482, 0.3809646458924221, 0.6139119078539181, 1, 0.7214441300454331, 0.7053633839144051, 0.09309670963357895], 0.0008003377778980136, 9.04645621309742, 0.007240220663442068
03:35:21 done sampling a new configuration.
03:35:21 HBMASTER: schedule new run for iteration 5
03:35:21 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
03:35:21 HBMASTER: submitting job (5, 0, 2) to dispatcher
03:35:21 DISPATCHER: trying to submit job (5, 0, 2)
03:35:21 DISPATCHER: trying to notify the job_runner thread.
03:35:21 HBMASTER: job (5, 0, 2) submitted to dispatcher
03:35:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:35:21 DISPATCHER: Trying to submit another job.
03:35:21 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:35:21 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:35:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:35:21 WORKER: start processing job (5, 0, 2)
03:35:21 WORKER: args: ()
03:35:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 758, 'last_n_outputs': 13, 'leak_rate': 0.8452411614731056, 'lr': 0.01689755293791529, 'optimizer': 'SGD', 'sparsity': 0.9231465912109039, 'steps_to_train': 74, 'weight_decay': 0.013216656769928555}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:35:41 DISPATCHER: Starting worker discovery
03:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:41 DISPATCHER: Finished worker discovery
03:36:41 DISPATCHER: Starting worker discovery
03:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:41 DISPATCHER: Finished worker discovery
03:37:41 DISPATCHER: Starting worker discovery
03:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:41 DISPATCHER: Finished worker discovery
03:37:46 WORKER: done with job (5, 0, 2), trying to register it.
03:37:46 WORKER: registered result for job (5, 0, 2) with dispatcher
03:37:46 DISPATCHER: job (5, 0, 2) finished
03:37:46 DISPATCHER: register_result: lock acquired
03:37:46 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:37:46 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 758, 'last_n_outputs': 13, 'leak_rate': 0.8452411614731056, 'lr': 0.01689755293791529, 'optimizer': 'SGD', 'sparsity': 0.9231465912109039, 'steps_to_train': 74, 'weight_decay': 0.013216656769928555}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9403773817293248, 'info': {'number_mnist': 0.9403773817293248, 'config': "{'batch_size': 128, 'hidden_dim': 758, 'last_n_outputs': 13, 'leak_rate': 0.8452411614731056, 'lr': 0.01689755293791529, 'optimizer': 'SGD', 'sparsity': 0.9231465912109039, 'steps_to_train': 74, 'weight_decay': 0.013216656769928555}"}}
exception: None

03:37:46 job_callback for (5, 0, 2) started
03:37:46 job_callback for (5, 0, 2) got condition
03:37:46 DISPATCHER: Trying to submit another job.
03:37:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:37:46 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.953299





03:37:46 HBMASTER: Trying to run another job!
03:37:46 job_callback for (5, 0, 2) finished
03:37:46 start sampling a new configuration.
03:37:46 best_vector: [2, 0.9857741659159369, 0.8084356290305394, 0.3188863517977071, 0.6594783388240888, 1, 0.7253188986842419, 0.13864160158059197, 0.4778088160202691], 8.639788561997836e-05, 8.686562229258586, 0.0007505006099143075
03:37:46 done sampling a new configuration.
03:37:46 HBMASTER: schedule new run for iteration 5
03:37:46 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
03:37:46 HBMASTER: submitting job (5, 0, 3) to dispatcher
03:37:46 DISPATCHER: trying to submit job (5, 0, 3)
03:37:46 DISPATCHER: trying to notify the job_runner thread.
03:37:46 HBMASTER: job (5, 0, 3) submitted to dispatcher
03:37:46 DISPATCHER: Trying to submit another job.
03:37:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:37:46 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:37:46 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:37:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:37:46 WORKER: start processing job (5, 0, 3)
03:37:46 WORKER: args: ()
03:37:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 989, 'last_n_outputs': 43, 'leak_rate': 0.8297215879494267, 'lr': 0.020842829584120755, 'optimizer': 'SGD', 'sparsity': 0.924076535684218, 'steps_to_train': 22, 'weight_decay': 0.041845002855910876}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:38:41 DISPATCHER: Starting worker discovery
03:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:41 DISPATCHER: Finished worker discovery
03:39:41 DISPATCHER: Starting worker discovery
03:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:41 DISPATCHER: Finished worker discovery
03:40:11 WORKER: done with job (5, 0, 3), trying to register it.
03:40:11 WORKER: registered result for job (5, 0, 3) with dispatcher
03:40:11 DISPATCHER: job (5, 0, 3) finished
03:40:11 DISPATCHER: register_result: lock acquired
03:40:11 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:40:11 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 989, 'last_n_outputs': 43, 'leak_rate': 0.8297215879494267, 'lr': 0.020842829584120755, 'optimizer': 'SGD', 'sparsity': 0.924076535684218, 'steps_to_train': 22, 'weight_decay': 0.041845002855910876}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9396159568852676, 'info': {'number_mnist': 0.9396159568852676, 'config': "{'batch_size': 64, 'hidden_dim': 989, 'last_n_outputs': 43, 'leak_rate': 0.8297215879494267, 'lr': 0.020842829584120755, 'optimizer': 'SGD', 'sparsity': 0.924076535684218, 'steps_to_train': 22, 'weight_decay': 0.041845002855910876}"}}
exception: None

03:40:11 job_callback for (5, 0, 3) started
03:40:11 job_callback for (5, 0, 3) got condition
03:40:11 DISPATCHER: Trying to submit another job.
03:40:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:40:11 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.953299





03:40:11 HBMASTER: Trying to run another job!
03:40:11 job_callback for (5, 0, 3) finished
03:40:11 start sampling a new configuration.
03:40:11 done sampling a new configuration.
03:40:11 HBMASTER: schedule new run for iteration 5
03:40:11 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
03:40:11 HBMASTER: submitting job (5, 0, 4) to dispatcher
03:40:11 DISPATCHER: trying to submit job (5, 0, 4)
03:40:11 DISPATCHER: trying to notify the job_runner thread.
03:40:11 HBMASTER: job (5, 0, 4) submitted to dispatcher
03:40:11 DISPATCHER: Trying to submit another job.
03:40:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:40:11 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:40:11 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:40:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:40:11 WORKER: start processing job (5, 0, 4)
03:40:11 WORKER: args: ()
03:40:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 545, 'last_n_outputs': 25, 'leak_rate': 0.9232357225222851, 'lr': 0.07606302403937001, 'optimizer': 'Adam', 'sparsity': 0.9814370160052132, 'steps_to_train': 31, 'weight_decay': 0.17719659494842632}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:40:41 DISPATCHER: Starting worker discovery
03:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:41 DISPATCHER: Finished worker discovery
03:41:41 DISPATCHER: Starting worker discovery
03:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:41 DISPATCHER: Finished worker discovery
03:42:37 WORKER: done with job (5, 0, 4), trying to register it.
03:42:37 WORKER: registered result for job (5, 0, 4) with dispatcher
03:42:37 DISPATCHER: job (5, 0, 4) finished
03:42:37 DISPATCHER: register_result: lock acquired
03:42:37 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:42:37 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 545, 'last_n_outputs': 25, 'leak_rate': 0.9232357225222851, 'lr': 0.07606302403937001, 'optimizer': 'Adam', 'sparsity': 0.9814370160052132, 'steps_to_train': 31, 'weight_decay': 0.17719659494842632}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.018843316223353508, 'info': {'number_mnist': 0.018843316223353508, 'config': "{'batch_size': 32, 'hidden_dim': 545, 'last_n_outputs': 25, 'leak_rate': 0.9232357225222851, 'lr': 0.07606302403937001, 'optimizer': 'Adam', 'sparsity': 0.9814370160052132, 'steps_to_train': 31, 'weight_decay': 0.17719659494842632}"}}
exception: None

03:42:37 job_callback for (5, 0, 4) started
03:42:37 job_callback for (5, 0, 4) got condition
03:42:37 DISPATCHER: Trying to submit another job.
03:42:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:37 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.953299





03:42:37 HBMASTER: Trying to run another job!
03:42:37 job_callback for (5, 0, 4) finished
03:42:37 start sampling a new configuration.
03:42:37 done sampling a new configuration.
03:42:37 HBMASTER: schedule new run for iteration 5
03:42:37 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
03:42:37 HBMASTER: submitting job (5, 0, 5) to dispatcher
03:42:37 DISPATCHER: trying to submit job (5, 0, 5)
03:42:37 DISPATCHER: trying to notify the job_runner thread.
03:42:37 HBMASTER: job (5, 0, 5) submitted to dispatcher
03:42:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:37 DISPATCHER: Trying to submit another job.
03:42:37 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:42:37 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:42:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:37 WORKER: start processing job (5, 0, 5)
03:42:37 WORKER: args: ()
03:42:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 380, 'last_n_outputs': 21, 'leak_rate': 0.9293862033971095, 'lr': 0.00982558935687275, 'optimizer': 'Adam', 'sparsity': 0.9751997626065124, 'steps_to_train': 30, 'weight_decay': 0.02009179820776161}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:42:41 DISPATCHER: Starting worker discovery
03:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:41 DISPATCHER: Finished worker discovery
03:43:41 DISPATCHER: Starting worker discovery
03:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:41 DISPATCHER: Finished worker discovery
03:44:41 DISPATCHER: Starting worker discovery
03:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:41 DISPATCHER: Finished worker discovery
03:45:01 WORKER: done with job (5, 0, 5), trying to register it.
03:45:01 WORKER: registered result for job (5, 0, 5) with dispatcher
03:45:01 DISPATCHER: job (5, 0, 5) finished
03:45:01 DISPATCHER: register_result: lock acquired
03:45:01 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:45:01 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 380, 'last_n_outputs': 21, 'leak_rate': 0.9293862033971095, 'lr': 0.00982558935687275, 'optimizer': 'Adam', 'sparsity': 0.9751997626065124, 'steps_to_train': 30, 'weight_decay': 0.02009179820776161}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.567802880258994, 'info': {'number_mnist': 0.567802880258994, 'config': "{'batch_size': 32, 'hidden_dim': 380, 'last_n_outputs': 21, 'leak_rate': 0.9293862033971095, 'lr': 0.00982558935687275, 'optimizer': 'Adam', 'sparsity': 0.9751997626065124, 'steps_to_train': 30, 'weight_decay': 0.02009179820776161}"}}
exception: None

03:45:01 job_callback for (5, 0, 5) started
03:45:01 job_callback for (5, 0, 5) got condition
03:45:01 DISPATCHER: Trying to submit another job.
03:45:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:01 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.953299





03:45:01 HBMASTER: Trying to run another job!
03:45:01 job_callback for (5, 0, 5) finished
03:45:01 start sampling a new configuration.
03:45:02 best_vector: [2, 0.9627737770091771, 0.9896812711253941, 0.058735361489584914, 0.8227720675669995, 1, 0.5388333051636894, 0.03890399976326046, 0.16367581561924438], 0.00030093770527055076, 0.0036126999333165573, 1.0871976277633566e-06
03:45:02 done sampling a new configuration.
03:45:02 HBMASTER: schedule new run for iteration 5
03:45:02 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
03:45:02 HBMASTER: submitting job (5, 0, 6) to dispatcher
03:45:02 DISPATCHER: trying to submit job (5, 0, 6)
03:45:02 DISPATCHER: trying to notify the job_runner thread.
03:45:02 HBMASTER: job (5, 0, 6) submitted to dispatcher
03:45:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:02 DISPATCHER: Trying to submit another job.
03:45:02 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:45:02 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:45:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:02 WORKER: start processing job (5, 0, 6)
03:45:02 WORKER: args: ()
03:45:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 971, 'last_n_outputs': 50, 'leak_rate': 0.7646838403723962, 'lr': 0.04421240454052854, 'optimizer': 'SGD', 'sparsity': 0.8793199932392854, 'steps_to_train': 13, 'weight_decay': 0.01632853215023091}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:45:41 DISPATCHER: Starting worker discovery
03:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:41 DISPATCHER: Finished worker discovery
03:46:41 DISPATCHER: Starting worker discovery
03:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:41 DISPATCHER: Finished worker discovery
03:47:29 WORKER: done with job (5, 0, 6), trying to register it.
03:47:29 WORKER: registered result for job (5, 0, 6) with dispatcher
03:47:29 DISPATCHER: job (5, 0, 6) finished
03:47:29 DISPATCHER: register_result: lock acquired
03:47:29 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:47:29 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 971, 'last_n_outputs': 50, 'leak_rate': 0.7646838403723962, 'lr': 0.04421240454052854, 'optimizer': 'SGD', 'sparsity': 0.8793199932392854, 'steps_to_train': 13, 'weight_decay': 0.01632853215023091}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.935050064309864, 'info': {'number_mnist': 0.935050064309864, 'config': "{'batch_size': 64, 'hidden_dim': 971, 'last_n_outputs': 50, 'leak_rate': 0.7646838403723962, 'lr': 0.04421240454052854, 'optimizer': 'SGD', 'sparsity': 0.8793199932392854, 'steps_to_train': 13, 'weight_decay': 0.01632853215023091}"}}
exception: None

03:47:29 job_callback for (5, 0, 6) started
03:47:29 DISPATCHER: Trying to submit another job.
03:47:29 job_callback for (5, 0, 6) got condition
03:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:47:29 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.953299





03:47:29 HBMASTER: Trying to run another job!
03:47:29 job_callback for (5, 0, 6) finished
03:47:29 start sampling a new configuration.
03:47:29 done sampling a new configuration.
03:47:29 HBMASTER: schedule new run for iteration 5
03:47:29 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
03:47:29 HBMASTER: submitting job (5, 0, 7) to dispatcher
03:47:29 DISPATCHER: trying to submit job (5, 0, 7)
03:47:29 DISPATCHER: trying to notify the job_runner thread.
03:47:29 HBMASTER: job (5, 0, 7) submitted to dispatcher
03:47:29 DISPATCHER: Trying to submit another job.
03:47:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:47:29 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:47:29 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:47:29 WORKER: start processing job (5, 0, 7)
03:47:29 WORKER: args: ()
03:47:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 990, 'last_n_outputs': 26, 'leak_rate': 0.8797820122672418, 'lr': 0.011164118658555988, 'optimizer': 'SGD', 'sparsity': 0.8063526421057234, 'steps_to_train': 49, 'weight_decay': 0.018378972149716618}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:47:41 DISPATCHER: Starting worker discovery
03:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:41 DISPATCHER: Finished worker discovery
03:48:41 DISPATCHER: Starting worker discovery
03:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:41 DISPATCHER: Finished worker discovery
03:49:41 DISPATCHER: Starting worker discovery
03:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:41 DISPATCHER: Finished worker discovery
03:49:53 WORKER: done with job (5, 0, 7), trying to register it.
03:49:53 WORKER: registered result for job (5, 0, 7) with dispatcher
03:49:53 DISPATCHER: job (5, 0, 7) finished
03:49:53 DISPATCHER: register_result: lock acquired
03:49:53 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:49:53 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 990, 'last_n_outputs': 26, 'leak_rate': 0.8797820122672418, 'lr': 0.011164118658555988, 'optimizer': 'SGD', 'sparsity': 0.8063526421057234, 'steps_to_train': 49, 'weight_decay': 0.018378972149716618}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9506951363085568, 'info': {'number_mnist': 0.9506951363085568, 'config': "{'batch_size': 32, 'hidden_dim': 990, 'last_n_outputs': 26, 'leak_rate': 0.8797820122672418, 'lr': 0.011164118658555988, 'optimizer': 'SGD', 'sparsity': 0.8063526421057234, 'steps_to_train': 49, 'weight_decay': 0.018378972149716618}"}}
exception: None

03:49:53 job_callback for (5, 0, 7) started
03:49:53 job_callback for (5, 0, 7) got condition
03:49:53 DISPATCHER: Trying to submit another job.
03:49:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:53 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.953299





03:49:53 HBMASTER: Trying to run another job!
03:49:53 job_callback for (5, 0, 7) finished
03:49:53 start sampling a new configuration.
03:49:53 best_vector: [0, 0.9868714775616876, 0.09903435830402299, 0.7921953390715223, 0.6943048403687928, 1, 0.18110582355737614, 0.24323345208693375, 0.14313112029433508], 3.407068506247912e-05, 5.158431778238149, 0.0001757513045326361
03:49:53 done sampling a new configuration.
03:49:53 HBMASTER: schedule new run for iteration 5
03:49:53 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
03:49:53 HBMASTER: submitting job (5, 0, 8) to dispatcher
03:49:53 DISPATCHER: trying to submit job (5, 0, 8)
03:49:53 DISPATCHER: trying to notify the job_runner thread.
03:49:53 HBMASTER: job (5, 0, 8) submitted to dispatcher
03:49:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:53 DISPATCHER: Trying to submit another job.
03:49:53 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:49:53 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:49:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:53 WORKER: start processing job (5, 0, 8)
03:49:53 WORKER: args: ()
03:49:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 990, 'last_n_outputs': 14, 'leak_rate': 0.9480488347678806, 'lr': 0.02446863151434141, 'optimizer': 'SGD', 'sparsity': 0.7934653976537702, 'steps_to_train': 32, 'weight_decay': 0.015353870765987569}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:50:41 DISPATCHER: Starting worker discovery
03:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:41 DISPATCHER: Finished worker discovery
03:51:41 DISPATCHER: Starting worker discovery
03:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:41 DISPATCHER: Finished worker discovery
03:52:18 WORKER: done with job (5, 0, 8), trying to register it.
03:52:18 WORKER: registered result for job (5, 0, 8) with dispatcher
03:52:18 DISPATCHER: job (5, 0, 8) finished
03:52:18 DISPATCHER: register_result: lock acquired
03:52:18 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:52:18 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 990, 'last_n_outputs': 14, 'leak_rate': 0.9480488347678806, 'lr': 0.02446863151434141, 'optimizer': 'SGD', 'sparsity': 0.7934653976537702, 'steps_to_train': 32, 'weight_decay': 0.015353870765987569}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9365868231784285, 'info': {'number_mnist': 0.9365868231784285, 'config': "{'batch_size': 16, 'hidden_dim': 990, 'last_n_outputs': 14, 'leak_rate': 0.9480488347678806, 'lr': 0.02446863151434141, 'optimizer': 'SGD', 'sparsity': 0.7934653976537702, 'steps_to_train': 32, 'weight_decay': 0.015353870765987569}"}}
exception: None

03:52:18 job_callback for (5, 0, 8) started
03:52:18 DISPATCHER: Trying to submit another job.
03:52:18 job_callback for (5, 0, 8) got condition
03:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:52:18 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.953299





03:52:18 HBMASTER: Trying to run another job!
03:52:18 job_callback for (5, 0, 8) finished
03:52:18 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
03:52:18 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
03:52:18 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
03:52:18 HBMASTER: schedule new run for iteration 5
03:52:18 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
03:52:18 HBMASTER: submitting job (5, 0, 0) to dispatcher
03:52:18 DISPATCHER: trying to submit job (5, 0, 0)
03:52:18 DISPATCHER: trying to notify the job_runner thread.
03:52:18 HBMASTER: job (5, 0, 0) submitted to dispatcher
03:52:18 DISPATCHER: Trying to submit another job.
03:52:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:52:18 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:52:18 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:52:18 WORKER: start processing job (5, 0, 0)
03:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:52:18 WORKER: args: ()
03:52:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}, 'budget': 400.0, 'working_directory': '.'}
03:52:41 DISPATCHER: Starting worker discovery
03:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:41 DISPATCHER: Finished worker discovery
03:53:41 DISPATCHER: Starting worker discovery
03:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:41 DISPATCHER: Finished worker discovery
03:54:41 DISPATCHER: Starting worker discovery
03:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:41 DISPATCHER: Finished worker discovery
03:55:41 DISPATCHER: Starting worker discovery
03:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:41 DISPATCHER: Finished worker discovery
03:56:41 DISPATCHER: Starting worker discovery
03:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:41 DISPATCHER: Finished worker discovery
03:57:41 DISPATCHER: Starting worker discovery
03:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:41 DISPATCHER: Finished worker discovery
03:58:41 DISPATCHER: Starting worker discovery
03:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:41 DISPATCHER: Finished worker discovery
03:59:12 WORKER: done with job (5, 0, 0), trying to register it.
03:59:12 WORKER: registered result for job (5, 0, 0) with dispatcher
03:59:12 DISPATCHER: job (5, 0, 0) finished
03:59:12 DISPATCHER: register_result: lock acquired
03:59:12 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:59:12 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9557572009678514, 'info': {'number_mnist': 0.9557572009678514, 'config': "{'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}"}}
exception: None

03:59:12 job_callback for (5, 0, 0) started
03:59:12 DISPATCHER: Trying to submit another job.
03:59:12 job_callback for (5, 0, 0) got condition
03:59:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:59:12 HBMASTER: Trying to run another job!
03:59:12 job_callback for (5, 0, 0) finished
03:59:12 HBMASTER: schedule new run for iteration 5
03:59:12 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
03:59:12 HBMASTER: submitting job (5, 0, 1) to dispatcher
03:59:12 DISPATCHER: trying to submit job (5, 0, 1)
03:59:12 DISPATCHER: trying to notify the job_runner thread.
03:59:12 HBMASTER: job (5, 0, 1) submitted to dispatcher
03:59:12 DISPATCHER: Trying to submit another job.
03:59:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:59:12 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:59:12 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:59:12 WORKER: start processing job (5, 0, 1)
03:59:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:59:12 WORKER: args: ()
03:59:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 914, 'last_n_outputs': 28, 'leak_rate': 0.9528097247886579, 'lr': 0.02101296008759309, 'optimizer': 'SGD', 'sparsity': 0.8252051958062907, 'steps_to_train': 91, 'weight_decay': 0.016154255823550137}, 'budget': 400.0, 'working_directory': '.'}
03:59:41 DISPATCHER: Starting worker discovery
03:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:41 DISPATCHER: Finished worker discovery
04:00:41 DISPATCHER: Starting worker discovery
04:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:41 DISPATCHER: Finished worker discovery
04:01:41 DISPATCHER: Starting worker discovery
04:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:41 DISPATCHER: Finished worker discovery
04:02:41 DISPATCHER: Starting worker discovery
04:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:41 DISPATCHER: Finished worker discovery
04:03:41 DISPATCHER: Starting worker discovery
04:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:41 DISPATCHER: Finished worker discovery
04:04:41 DISPATCHER: Starting worker discovery
04:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:41 DISPATCHER: Finished worker discovery
04:05:41 DISPATCHER: Starting worker discovery
04:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:41 DISPATCHER: Finished worker discovery
04:06:06 WORKER: done with job (5, 0, 1), trying to register it.
04:06:06 WORKER: registered result for job (5, 0, 1) with dispatcher
04:06:06 DISPATCHER: job (5, 0, 1) finished
04:06:06 DISPATCHER: register_result: lock acquired
04:06:06 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:06:06 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 914, 'last_n_outputs': 28, 'leak_rate': 0.9528097247886579, 'lr': 0.02101296008759309, 'optimizer': 'SGD', 'sparsity': 0.8252051958062907, 'steps_to_train': 91, 'weight_decay': 0.016154255823550137}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9489271022923931, 'info': {'number_mnist': 0.9489271022923931, 'config': "{'batch_size': 128, 'hidden_dim': 914, 'last_n_outputs': 28, 'leak_rate': 0.9528097247886579, 'lr': 0.02101296008759309, 'optimizer': 'SGD', 'sparsity': 0.8252051958062907, 'steps_to_train': 91, 'weight_decay': 0.016154255823550137}"}}
exception: None

04:06:06 job_callback for (5, 0, 1) started
04:06:06 DISPATCHER: Trying to submit another job.
04:06:06 job_callback for (5, 0, 1) got condition
04:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:06 HBMASTER: Trying to run another job!
04:06:06 job_callback for (5, 0, 1) finished
04:06:06 HBMASTER: schedule new run for iteration 5
04:06:06 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
04:06:06 HBMASTER: submitting job (5, 0, 7) to dispatcher
04:06:06 DISPATCHER: trying to submit job (5, 0, 7)
04:06:06 DISPATCHER: trying to notify the job_runner thread.
04:06:06 HBMASTER: job (5, 0, 7) submitted to dispatcher
04:06:06 DISPATCHER: Trying to submit another job.
04:06:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:06 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:06:06 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:06 WORKER: start processing job (5, 0, 7)
04:06:06 WORKER: args: ()
04:06:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 990, 'last_n_outputs': 26, 'leak_rate': 0.8797820122672418, 'lr': 0.011164118658555988, 'optimizer': 'SGD', 'sparsity': 0.8063526421057234, 'steps_to_train': 49, 'weight_decay': 0.018378972149716618}, 'budget': 400.0, 'working_directory': '.'}
04:06:41 DISPATCHER: Starting worker discovery
04:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:41 DISPATCHER: Finished worker discovery
04:07:41 DISPATCHER: Starting worker discovery
04:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:41 DISPATCHER: Finished worker discovery
04:08:41 DISPATCHER: Starting worker discovery
04:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:41 DISPATCHER: Finished worker discovery
04:09:41 DISPATCHER: Starting worker discovery
04:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:41 DISPATCHER: Finished worker discovery
04:10:41 DISPATCHER: Starting worker discovery
04:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:41 DISPATCHER: Finished worker discovery
04:11:41 DISPATCHER: Starting worker discovery
04:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:41 DISPATCHER: Finished worker discovery
04:12:41 DISPATCHER: Starting worker discovery
04:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:41 DISPATCHER: Finished worker discovery
04:13:01 WORKER: done with job (5, 0, 7), trying to register it.
04:13:01 WORKER: registered result for job (5, 0, 7) with dispatcher
04:13:01 DISPATCHER: job (5, 0, 7) finished
04:13:01 DISPATCHER: register_result: lock acquired
04:13:01 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:13:01 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 990, 'last_n_outputs': 26, 'leak_rate': 0.8797820122672418, 'lr': 0.011164118658555988, 'optimizer': 'SGD', 'sparsity': 0.8063526421057234, 'steps_to_train': 49, 'weight_decay': 0.018378972149716618}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9514846072831341, 'info': {'number_mnist': 0.9514846072831341, 'config': "{'batch_size': 32, 'hidden_dim': 990, 'last_n_outputs': 26, 'leak_rate': 0.8797820122672418, 'lr': 0.011164118658555988, 'optimizer': 'SGD', 'sparsity': 0.8063526421057234, 'steps_to_train': 49, 'weight_decay': 0.018378972149716618}"}}
exception: None

04:13:01 job_callback for (5, 0, 7) started
04:13:01 DISPATCHER: Trying to submit another job.
04:13:01 job_callback for (5, 0, 7) got condition
04:13:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:01 HBMASTER: Trying to run another job!
04:13:01 job_callback for (5, 0, 7) finished
04:13:01 ITERATION: Advancing config (5, 0, 0) to next budget 1200.000000
04:13:01 HBMASTER: schedule new run for iteration 5
04:13:01 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
04:13:01 HBMASTER: submitting job (5, 0, 0) to dispatcher
04:13:01 DISPATCHER: trying to submit job (5, 0, 0)
04:13:01 DISPATCHER: trying to notify the job_runner thread.
04:13:01 HBMASTER: job (5, 0, 0) submitted to dispatcher
04:13:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:01 DISPATCHER: Trying to submit another job.
04:13:01 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:13:01 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:13:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:01 WORKER: start processing job (5, 0, 0)
04:13:01 WORKER: args: ()
04:13:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}, 'budget': 1200.0, 'working_directory': '.'}
04:13:41 DISPATCHER: Starting worker discovery
04:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:41 DISPATCHER: Finished worker discovery
04:14:41 DISPATCHER: Starting worker discovery
04:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:41 DISPATCHER: Finished worker discovery
04:15:41 DISPATCHER: Starting worker discovery
04:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:41 DISPATCHER: Finished worker discovery
04:16:41 DISPATCHER: Starting worker discovery
04:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:41 DISPATCHER: Finished worker discovery
04:17:41 DISPATCHER: Starting worker discovery
04:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:41 DISPATCHER: Finished worker discovery
04:18:41 DISPATCHER: Starting worker discovery
04:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:41 DISPATCHER: Finished worker discovery
04:19:41 DISPATCHER: Starting worker discovery
04:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:41 DISPATCHER: Finished worker discovery
04:20:41 DISPATCHER: Starting worker discovery
04:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:41 DISPATCHER: Finished worker discovery
04:21:41 DISPATCHER: Starting worker discovery
04:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:41 DISPATCHER: Finished worker discovery
04:22:41 DISPATCHER: Starting worker discovery
04:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:41 DISPATCHER: Finished worker discovery
04:23:41 DISPATCHER: Starting worker discovery
04:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:41 DISPATCHER: Finished worker discovery
04:24:41 DISPATCHER: Starting worker discovery
04:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:41 DISPATCHER: Finished worker discovery
04:25:41 DISPATCHER: Starting worker discovery
04:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:41 DISPATCHER: Finished worker discovery
04:26:41 DISPATCHER: Starting worker discovery
04:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:41 DISPATCHER: Finished worker discovery
04:27:41 DISPATCHER: Starting worker discovery
04:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:41 DISPATCHER: Finished worker discovery
04:28:41 DISPATCHER: Starting worker discovery
04:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:41 DISPATCHER: Finished worker discovery
04:29:41 DISPATCHER: Starting worker discovery
04:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:41 DISPATCHER: Finished worker discovery
04:30:41 DISPATCHER: Starting worker discovery
04:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:41 DISPATCHER: Finished worker discovery
04:31:41 DISPATCHER: Starting worker discovery
04:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:41 DISPATCHER: Finished worker discovery
04:32:41 DISPATCHER: Starting worker discovery
04:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:41 DISPATCHER: Finished worker discovery
04:33:21 WORKER: done with job (5, 0, 0), trying to register it.
04:33:21 WORKER: registered result for job (5, 0, 0) with dispatcher
04:33:21 DISPATCHER: job (5, 0, 0) finished
04:33:21 DISPATCHER: register_result: lock acquired
04:33:21 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:33:21 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9554994365392516, 'info': {'number_mnist': 0.9554994365392516, 'config': "{'batch_size': 128, 'hidden_dim': 813, 'last_n_outputs': 27, 'leak_rate': 0.8797865830838508, 'lr': 0.013709890982169305, 'optimizer': 'SGD', 'sparsity': 0.9389085871898764, 'steps_to_train': 95, 'weight_decay': 0.01447852168746301}"}}
exception: None

04:33:21 job_callback for (5, 0, 0) started
04:33:21 job_callback for (5, 0, 0) got condition
04:33:21 DISPATCHER: Trying to submit another job.
04:33:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:33:21 HBMASTER: Trying to run another job!
04:33:21 job_callback for (5, 0, 0) finished
04:33:21 start sampling a new configuration.
04:33:21 done sampling a new configuration.
04:33:21 HBMASTER: schedule new run for iteration 6
04:33:21 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
04:33:21 HBMASTER: submitting job (6, 0, 0) to dispatcher
04:33:21 DISPATCHER: trying to submit job (6, 0, 0)
04:33:21 DISPATCHER: trying to notify the job_runner thread.
04:33:21 HBMASTER: job (6, 0, 0) submitted to dispatcher
04:33:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:33:21 DISPATCHER: Trying to submit another job.
04:33:21 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:33:21 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:33:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:33:21 WORKER: start processing job (6, 0, 0)
04:33:21 WORKER: args: ()
04:33:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 49, 'leak_rate': 0.756555064215515, 'lr': 0.0020237788603615376, 'optimizer': 'Adam', 'sparsity': 0.8182844876524983, 'steps_to_train': 71, 'weight_decay': 0.03584932708805191}, 'budget': 400.0, 'working_directory': '.'}
04:33:41 DISPATCHER: Starting worker discovery
04:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:41 DISPATCHER: Finished worker discovery
04:34:41 DISPATCHER: Starting worker discovery
04:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:41 DISPATCHER: Finished worker discovery
04:35:41 DISPATCHER: Starting worker discovery
04:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:41 DISPATCHER: Finished worker discovery
04:36:41 DISPATCHER: Starting worker discovery
04:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:41 DISPATCHER: Finished worker discovery
04:37:41 DISPATCHER: Starting worker discovery
04:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:41 DISPATCHER: Finished worker discovery
04:38:41 DISPATCHER: Starting worker discovery
04:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:41 DISPATCHER: Finished worker discovery
04:39:41 DISPATCHER: Starting worker discovery
04:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:41 DISPATCHER: Finished worker discovery
04:40:13 WORKER: done with job (6, 0, 0), trying to register it.
04:40:13 WORKER: registered result for job (6, 0, 0) with dispatcher
04:40:13 DISPATCHER: job (6, 0, 0) finished
04:40:13 DISPATCHER: register_result: lock acquired
04:40:13 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:40:13 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 49, 'leak_rate': 0.756555064215515, 'lr': 0.0020237788603615376, 'optimizer': 'Adam', 'sparsity': 0.8182844876524983, 'steps_to_train': 71, 'weight_decay': 0.03584932708805191}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9100938040386592, 'info': {'number_mnist': 0.9100938040386592, 'config': "{'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 49, 'leak_rate': 0.756555064215515, 'lr': 0.0020237788603615376, 'optimizer': 'Adam', 'sparsity': 0.8182844876524983, 'steps_to_train': 71, 'weight_decay': 0.03584932708805191}"}}
exception: None

04:40:13 job_callback for (6, 0, 0) started
04:40:13 DISPATCHER: Trying to submit another job.
04:40:13 job_callback for (6, 0, 0) got condition
04:40:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:40:13 HBMASTER: Trying to run another job!
04:40:13 job_callback for (6, 0, 0) finished
04:40:13 start sampling a new configuration.
04:40:13 done sampling a new configuration.
04:40:13 HBMASTER: schedule new run for iteration 6
04:40:13 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
04:40:13 HBMASTER: submitting job (6, 0, 1) to dispatcher
04:40:13 DISPATCHER: trying to submit job (6, 0, 1)
04:40:13 DISPATCHER: trying to notify the job_runner thread.
04:40:13 HBMASTER: job (6, 0, 1) submitted to dispatcher
04:40:13 DISPATCHER: Trying to submit another job.
04:40:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:40:13 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:40:13 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:40:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:40:13 WORKER: start processing job (6, 0, 1)
04:40:13 WORKER: args: ()
04:40:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 929, 'last_n_outputs': 20, 'leak_rate': 0.8239036231606564, 'lr': 0.0015803883076903984, 'optimizer': 'Adam', 'sparsity': 0.8351519473389513, 'steps_to_train': 37, 'weight_decay': 0.021020143347317156}, 'budget': 400.0, 'working_directory': '.'}
04:40:41 DISPATCHER: Starting worker discovery
04:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:41 DISPATCHER: Finished worker discovery
04:41:41 DISPATCHER: Starting worker discovery
04:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:41 DISPATCHER: Finished worker discovery
04:42:41 DISPATCHER: Starting worker discovery
04:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:41 DISPATCHER: Finished worker discovery
04:43:41 DISPATCHER: Starting worker discovery
04:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:41 DISPATCHER: Finished worker discovery
04:44:41 DISPATCHER: Starting worker discovery
04:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:41 DISPATCHER: Finished worker discovery
04:45:41 DISPATCHER: Starting worker discovery
04:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:41 DISPATCHER: Finished worker discovery
04:46:41 DISPATCHER: Starting worker discovery
04:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:41 DISPATCHER: Finished worker discovery
04:47:09 WORKER: done with job (6, 0, 1), trying to register it.
04:47:09 WORKER: registered result for job (6, 0, 1) with dispatcher
04:47:09 DISPATCHER: job (6, 0, 1) finished
04:47:09 DISPATCHER: register_result: lock acquired
04:47:09 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:47:09 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 929, 'last_n_outputs': 20, 'leak_rate': 0.8239036231606564, 'lr': 0.0015803883076903984, 'optimizer': 'Adam', 'sparsity': 0.8351519473389513, 'steps_to_train': 37, 'weight_decay': 0.021020143347317156}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9079410618546525, 'info': {'number_mnist': 0.9079410618546525, 'config': "{'batch_size': 64, 'hidden_dim': 929, 'last_n_outputs': 20, 'leak_rate': 0.8239036231606564, 'lr': 0.0015803883076903984, 'optimizer': 'Adam', 'sparsity': 0.8351519473389513, 'steps_to_train': 37, 'weight_decay': 0.021020143347317156}"}}
exception: None

04:47:09 job_callback for (6, 0, 1) started
04:47:09 DISPATCHER: Trying to submit another job.
04:47:09 job_callback for (6, 0, 1) got condition
04:47:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:47:09 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.955757





04:47:09 HBMASTER: Trying to run another job!
04:47:09 job_callback for (6, 0, 1) finished
04:47:09 start sampling a new configuration.
04:47:09 best_vector: [1, 0.2352517648646771, 0.42963548706183774, 0.32877513476996173, 0.9703702854085042, 0, 0.9615749642377601, 0.6080271613059796, 0.16128384517335007], 1.3653513655177767e-05, 0.002212375123286726, 3.0206693956170904e-08
04:47:09 done sampling a new configuration.
04:47:09 HBMASTER: schedule new run for iteration 6
04:47:09 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
04:47:09 HBMASTER: submitting job (6, 0, 2) to dispatcher
04:47:09 DISPATCHER: trying to submit job (6, 0, 2)
04:47:09 DISPATCHER: trying to notify the job_runner thread.
04:47:09 HBMASTER: job (6, 0, 2) submitted to dispatcher
04:47:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:47:09 DISPATCHER: Trying to submit another job.
04:47:09 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:47:09 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:47:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:47:09 WORKER: start processing job (6, 0, 2)
04:47:09 WORKER: args: ()
04:47:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 388, 'last_n_outputs': 27, 'leak_rate': 0.8321937836924904, 'lr': 0.08724500478816331, 'optimizer': 'Adam', 'sparsity': 0.9807779914170625, 'steps_to_train': 65, 'weight_decay': 0.016211944950896576}, 'budget': 400.0, 'working_directory': '.'}
04:47:41 DISPATCHER: Starting worker discovery
04:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:41 DISPATCHER: Finished worker discovery
04:48:41 DISPATCHER: Starting worker discovery
04:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:41 DISPATCHER: Finished worker discovery
04:49:41 DISPATCHER: Starting worker discovery
04:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:41 DISPATCHER: Finished worker discovery
04:50:41 DISPATCHER: Starting worker discovery
04:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:41 DISPATCHER: Finished worker discovery
04:51:41 DISPATCHER: Starting worker discovery
04:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:41 DISPATCHER: Finished worker discovery
04:52:41 DISPATCHER: Starting worker discovery
04:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:41 DISPATCHER: Finished worker discovery
04:53:41 DISPATCHER: Starting worker discovery
04:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:41 DISPATCHER: Finished worker discovery
04:54:02 WORKER: done with job (6, 0, 2), trying to register it.
04:54:02 WORKER: registered result for job (6, 0, 2) with dispatcher
04:54:02 DISPATCHER: job (6, 0, 2) finished
04:54:02 DISPATCHER: register_result: lock acquired
04:54:02 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:54:02 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 388, 'last_n_outputs': 27, 'leak_rate': 0.8321937836924904, 'lr': 0.08724500478816331, 'optimizer': 'Adam', 'sparsity': 0.9807779914170625, 'steps_to_train': 65, 'weight_decay': 0.016211944950896576}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2174193612641936, 'info': {'number_mnist': 0.2174193612641936, 'config': "{'batch_size': 32, 'hidden_dim': 388, 'last_n_outputs': 27, 'leak_rate': 0.8321937836924904, 'lr': 0.08724500478816331, 'optimizer': 'Adam', 'sparsity': 0.9807779914170625, 'steps_to_train': 65, 'weight_decay': 0.016211944950896576}"}}
exception: None

04:54:02 job_callback for (6, 0, 2) started
04:54:02 DISPATCHER: Trying to submit another job.
04:54:02 job_callback for (6, 0, 2) got condition
04:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:54:02 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.955757





04:54:02 HBMASTER: Trying to run another job!
04:54:02 job_callback for (6, 0, 2) finished
04:54:02 start sampling a new configuration.
04:54:02 best_vector: [3, 0.9467284993920211, 0.559840474960071, 0.34073809970701857, 0.2013159118920284, 1, 0.811906303844828, 0.7875956076133327, 0.0882112398982915], 0.005400575493671321, 0.7366689839682737, 0.003978436461766811
04:54:02 done sampling a new configuration.
04:54:02 HBMASTER: schedule new run for iteration 6
04:54:02 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
04:54:02 HBMASTER: submitting job (6, 0, 3) to dispatcher
04:54:02 DISPATCHER: trying to submit job (6, 0, 3)
04:54:02 DISPATCHER: trying to notify the job_runner thread.
04:54:02 HBMASTER: job (6, 0, 3) submitted to dispatcher
04:54:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:54:02 DISPATCHER: Trying to submit another job.
04:54:02 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:54:02 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:54:02 WORKER: start processing job (6, 0, 3)
04:54:02 WORKER: args: ()
04:54:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 958, 'last_n_outputs': 32, 'leak_rate': 0.8351845249267547, 'lr': 0.002527154674832949, 'optimizer': 'SGD', 'sparsity': 0.9448575129227588, 'steps_to_train': 81, 'weight_decay': 0.013024632226188358}, 'budget': 400.0, 'working_directory': '.'}
04:54:41 DISPATCHER: Starting worker discovery
04:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:41 DISPATCHER: Finished worker discovery
04:55:41 DISPATCHER: Starting worker discovery
04:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:41 DISPATCHER: Finished worker discovery
04:56:41 DISPATCHER: Starting worker discovery
04:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:41 DISPATCHER: Finished worker discovery
04:57:41 DISPATCHER: Starting worker discovery
04:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:41 DISPATCHER: Finished worker discovery
04:58:41 DISPATCHER: Starting worker discovery
04:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:41 DISPATCHER: Finished worker discovery
04:59:41 DISPATCHER: Starting worker discovery
04:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:41 DISPATCHER: Finished worker discovery
05:00:41 DISPATCHER: Starting worker discovery
05:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:41 DISPATCHER: Finished worker discovery
05:00:55 WORKER: done with job (6, 0, 3), trying to register it.
05:00:55 WORKER: registered result for job (6, 0, 3) with dispatcher
05:00:55 DISPATCHER: job (6, 0, 3) finished
05:00:55 DISPATCHER: register_result: lock acquired
05:00:55 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:00:55 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 958, 'last_n_outputs': 32, 'leak_rate': 0.8351845249267547, 'lr': 0.002527154674832949, 'optimizer': 'SGD', 'sparsity': 0.9448575129227588, 'steps_to_train': 81, 'weight_decay': 0.013024632226188358}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9303080431049426, 'info': {'number_mnist': 0.9303080431049426, 'config': "{'batch_size': 128, 'hidden_dim': 958, 'last_n_outputs': 32, 'leak_rate': 0.8351845249267547, 'lr': 0.002527154674832949, 'optimizer': 'SGD', 'sparsity': 0.9448575129227588, 'steps_to_train': 81, 'weight_decay': 0.013024632226188358}"}}
exception: None

05:00:55 job_callback for (6, 0, 3) started
05:00:55 job_callback for (6, 0, 3) got condition
05:00:55 DISPATCHER: Trying to submit another job.
05:00:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:00:55 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.955757





05:00:55 HBMASTER: Trying to run another job!
05:00:55 job_callback for (6, 0, 3) finished
05:00:55 start sampling a new configuration.
05:00:55 best_vector: [2, 0.750652434679619, 0.5442097761303584, 0.25057083883530173, 0.199650321630805, 1, 0.8360819307648345, 0.9112823326435384, 0.09396379557899309], 0.00047785991968651246, 3.9645840345739614, 0.0018945158083519427
05:00:55 done sampling a new configuration.
05:00:55 HBMASTER: schedule new run for iteration 6
05:00:55 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
05:00:55 HBMASTER: submitting job (6, 0, 4) to dispatcher
05:00:55 DISPATCHER: trying to submit job (6, 0, 4)
05:00:55 DISPATCHER: trying to notify the job_runner thread.
05:00:55 HBMASTER: job (6, 0, 4) submitted to dispatcher
05:00:55 DISPATCHER: Trying to submit another job.
05:00:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:00:55 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:00:55 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:00:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:00:55 WORKER: start processing job (6, 0, 4)
05:00:55 WORKER: args: ()
05:00:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 801, 'last_n_outputs': 32, 'leak_rate': 0.8126427097088255, 'lr': 0.0025078447245612287, 'optimizer': 'SGD', 'sparsity': 0.9506596633835602, 'steps_to_train': 92, 'weight_decay': 0.013251032420905796}, 'budget': 400.0, 'working_directory': '.'}
05:01:41 DISPATCHER: Starting worker discovery
05:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:41 DISPATCHER: Finished worker discovery
05:02:41 DISPATCHER: Starting worker discovery
05:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:41 DISPATCHER: Finished worker discovery
05:03:41 DISPATCHER: Starting worker discovery
05:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:41 DISPATCHER: Finished worker discovery
05:04:41 DISPATCHER: Starting worker discovery
05:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:41 DISPATCHER: Finished worker discovery
05:05:41 DISPATCHER: Starting worker discovery
05:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:41 DISPATCHER: Finished worker discovery
05:06:41 DISPATCHER: Starting worker discovery
05:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:41 DISPATCHER: Finished worker discovery
05:07:41 DISPATCHER: Starting worker discovery
05:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:41 DISPATCHER: Finished worker discovery
05:07:47 WORKER: done with job (6, 0, 4), trying to register it.
05:07:47 WORKER: registered result for job (6, 0, 4) with dispatcher
05:07:47 DISPATCHER: job (6, 0, 4) finished
05:07:47 DISPATCHER: register_result: lock acquired
05:07:47 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:07:47 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 801, 'last_n_outputs': 32, 'leak_rate': 0.8126427097088255, 'lr': 0.0025078447245612287, 'optimizer': 'SGD', 'sparsity': 0.9506596633835602, 'steps_to_train': 92, 'weight_decay': 0.013251032420905796}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9142260657154045, 'info': {'number_mnist': 0.9142260657154045, 'config': "{'batch_size': 64, 'hidden_dim': 801, 'last_n_outputs': 32, 'leak_rate': 0.8126427097088255, 'lr': 0.0025078447245612287, 'optimizer': 'SGD', 'sparsity': 0.9506596633835602, 'steps_to_train': 92, 'weight_decay': 0.013251032420905796}"}}
exception: None

05:07:47 job_callback for (6, 0, 4) started
05:07:47 DISPATCHER: Trying to submit another job.
05:07:47 job_callback for (6, 0, 4) got condition
05:07:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:07:47 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.955757





05:07:47 HBMASTER: Trying to run another job!
05:07:47 job_callback for (6, 0, 4) finished
05:07:47 start sampling a new configuration.
05:07:47 best_vector: [1, 0.7656001978607864, 0.3440377545123474, 0.37738926959121444, 0.8984892571202777, 1, 0.4561184436696737, 0.9201271895590724, 0.08271660139554915], 0.0017581269408878115, 1.1035539297129782, 0.0019401878945510013
05:07:47 done sampling a new configuration.
05:07:47 HBMASTER: schedule new run for iteration 6
05:07:47 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
05:07:47 HBMASTER: submitting job (6, 0, 5) to dispatcher
05:07:47 DISPATCHER: trying to submit job (6, 0, 5)
05:07:47 DISPATCHER: trying to notify the job_runner thread.
05:07:47 HBMASTER: job (6, 0, 5) submitted to dispatcher
05:07:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:07:47 DISPATCHER: Trying to submit another job.
05:07:47 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:07:47 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:07:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:07:47 WORKER: start processing job (6, 0, 5)
05:07:47 WORKER: args: ()
05:07:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 24, 'leak_rate': 0.8443473173978036, 'lr': 0.06265828651033924, 'optimizer': 'SGD', 'sparsity': 0.8594684264807216, 'steps_to_train': 93, 'weight_decay': 0.012811995562007022}, 'budget': 400.0, 'working_directory': '.'}
05:08:41 DISPATCHER: Starting worker discovery
05:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:41 DISPATCHER: Finished worker discovery
05:09:41 DISPATCHER: Starting worker discovery
05:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:41 DISPATCHER: Finished worker discovery
05:10:41 DISPATCHER: Starting worker discovery
05:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:41 DISPATCHER: Finished worker discovery
05:11:41 DISPATCHER: Starting worker discovery
05:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:41 DISPATCHER: Finished worker discovery
05:12:41 DISPATCHER: Starting worker discovery
05:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:41 DISPATCHER: Finished worker discovery
05:13:41 DISPATCHER: Starting worker discovery
05:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:41 DISPATCHER: Finished worker discovery
05:14:40 WORKER: done with job (6, 0, 5), trying to register it.
05:14:40 WORKER: registered result for job (6, 0, 5) with dispatcher
05:14:40 DISPATCHER: job (6, 0, 5) finished
05:14:40 DISPATCHER: register_result: lock acquired
05:14:40 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:14:40 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 24, 'leak_rate': 0.8443473173978036, 'lr': 0.06265828651033924, 'optimizer': 'SGD', 'sparsity': 0.8594684264807216, 'steps_to_train': 93, 'weight_decay': 0.012811995562007022}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9283043975331309, 'info': {'number_mnist': 0.9283043975331309, 'config': "{'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 24, 'leak_rate': 0.8443473173978036, 'lr': 0.06265828651033924, 'optimizer': 'SGD', 'sparsity': 0.8594684264807216, 'steps_to_train': 93, 'weight_decay': 0.012811995562007022}"}}
exception: None

05:14:40 job_callback for (6, 0, 5) started
05:14:40 DISPATCHER: Trying to submit another job.
05:14:40 job_callback for (6, 0, 5) got condition
05:14:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:14:40 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.955757





05:14:40 HBMASTER: Trying to run another job!
05:14:40 job_callback for (6, 0, 5) finished
05:14:40 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
05:14:40 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
05:14:40 HBMASTER: schedule new run for iteration 6
05:14:40 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
05:14:40 HBMASTER: submitting job (6, 0, 3) to dispatcher
05:14:40 DISPATCHER: trying to submit job (6, 0, 3)
05:14:40 DISPATCHER: trying to notify the job_runner thread.
05:14:40 HBMASTER: job (6, 0, 3) submitted to dispatcher
05:14:40 DISPATCHER: Trying to submit another job.
05:14:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:14:40 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:14:40 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:14:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:14:40 WORKER: start processing job (6, 0, 3)
05:14:40 WORKER: args: ()
05:14:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 958, 'last_n_outputs': 32, 'leak_rate': 0.8351845249267547, 'lr': 0.002527154674832949, 'optimizer': 'SGD', 'sparsity': 0.9448575129227588, 'steps_to_train': 81, 'weight_decay': 0.013024632226188358}, 'budget': 1200.0, 'working_directory': '.'}
05:14:41 DISPATCHER: Starting worker discovery
05:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:41 DISPATCHER: Finished worker discovery
05:15:41 DISPATCHER: Starting worker discovery
05:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:41 DISPATCHER: Finished worker discovery
05:16:41 DISPATCHER: Starting worker discovery
05:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:41 DISPATCHER: Finished worker discovery
05:17:41 DISPATCHER: Starting worker discovery
05:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:41 DISPATCHER: Finished worker discovery
05:18:41 DISPATCHER: Starting worker discovery
05:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:41 DISPATCHER: Finished worker discovery
05:19:41 DISPATCHER: Starting worker discovery
05:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:41 DISPATCHER: Finished worker discovery
05:20:41 DISPATCHER: Starting worker discovery
05:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:41 DISPATCHER: Finished worker discovery
05:21:41 DISPATCHER: Starting worker discovery
05:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:41 DISPATCHER: Finished worker discovery
05:22:41 DISPATCHER: Starting worker discovery
05:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:41 DISPATCHER: Finished worker discovery
05:23:41 DISPATCHER: Starting worker discovery
05:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:41 DISPATCHER: Finished worker discovery
05:24:41 DISPATCHER: Starting worker discovery
05:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:41 DISPATCHER: Finished worker discovery
05:25:41 DISPATCHER: Starting worker discovery
05:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:41 DISPATCHER: Finished worker discovery
05:26:41 DISPATCHER: Starting worker discovery
05:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:41 DISPATCHER: Finished worker discovery
05:27:41 DISPATCHER: Starting worker discovery
05:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:41 DISPATCHER: Finished worker discovery
05:28:41 DISPATCHER: Starting worker discovery
05:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:41 DISPATCHER: Finished worker discovery
05:29:41 DISPATCHER: Starting worker discovery
05:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:41 DISPATCHER: Finished worker discovery
05:30:41 DISPATCHER: Starting worker discovery
05:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:41 DISPATCHER: Finished worker discovery
05:31:41 DISPATCHER: Starting worker discovery
05:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:41 DISPATCHER: Finished worker discovery
05:32:41 DISPATCHER: Starting worker discovery
05:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:41 DISPATCHER: Finished worker discovery
05:33:41 DISPATCHER: Starting worker discovery
05:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:41 DISPATCHER: Finished worker discovery
05:34:41 DISPATCHER: Starting worker discovery
05:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:41 DISPATCHER: Finished worker discovery
05:35:01 WORKER: done with job (6, 0, 3), trying to register it.
05:35:01 WORKER: registered result for job (6, 0, 3) with dispatcher
05:35:01 DISPATCHER: job (6, 0, 3) finished
05:35:01 DISPATCHER: register_result: lock acquired
05:35:01 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:35:01 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 958, 'last_n_outputs': 32, 'leak_rate': 0.8351845249267547, 'lr': 0.002527154674832949, 'optimizer': 'SGD', 'sparsity': 0.9448575129227588, 'steps_to_train': 81, 'weight_decay': 0.013024632226188358}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9349300410342007, 'info': {'number_mnist': 0.9349300410342007, 'config': "{'batch_size': 128, 'hidden_dim': 958, 'last_n_outputs': 32, 'leak_rate': 0.8351845249267547, 'lr': 0.002527154674832949, 'optimizer': 'SGD', 'sparsity': 0.9448575129227588, 'steps_to_train': 81, 'weight_decay': 0.013024632226188358}"}}
exception: None

05:35:01 job_callback for (6, 0, 3) started
05:35:01 DISPATCHER: Trying to submit another job.
05:35:01 job_callback for (6, 0, 3) got condition
05:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:01 HBMASTER: Trying to run another job!
05:35:01 job_callback for (6, 0, 3) finished
05:35:01 HBMASTER: schedule new run for iteration 6
05:35:01 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
05:35:01 HBMASTER: submitting job (6, 0, 5) to dispatcher
05:35:01 DISPATCHER: trying to submit job (6, 0, 5)
05:35:01 DISPATCHER: trying to notify the job_runner thread.
05:35:01 HBMASTER: job (6, 0, 5) submitted to dispatcher
05:35:01 DISPATCHER: Trying to submit another job.
05:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:01 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:35:01 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:01 WORKER: start processing job (6, 0, 5)
05:35:01 WORKER: args: ()
05:35:01 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 24, 'leak_rate': 0.8443473173978036, 'lr': 0.06265828651033924, 'optimizer': 'SGD', 'sparsity': 0.8594684264807216, 'steps_to_train': 93, 'weight_decay': 0.012811995562007022}, 'budget': 1200.0, 'working_directory': '.'}
05:35:41 DISPATCHER: Starting worker discovery
05:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:41 DISPATCHER: Finished worker discovery
05:36:41 DISPATCHER: Starting worker discovery
05:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:41 DISPATCHER: Finished worker discovery
05:37:41 DISPATCHER: Starting worker discovery
05:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:41 DISPATCHER: Finished worker discovery
05:38:41 DISPATCHER: Starting worker discovery
05:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:41 DISPATCHER: Finished worker discovery
05:39:41 DISPATCHER: Starting worker discovery
05:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:41 DISPATCHER: Finished worker discovery
05:40:41 DISPATCHER: Starting worker discovery
05:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:41 DISPATCHER: Finished worker discovery
05:41:41 DISPATCHER: Starting worker discovery
05:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:41 DISPATCHER: Finished worker discovery
05:42:41 DISPATCHER: Starting worker discovery
05:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:41 DISPATCHER: Finished worker discovery
05:43:41 DISPATCHER: Starting worker discovery
05:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:41 DISPATCHER: Finished worker discovery
05:44:41 DISPATCHER: Starting worker discovery
05:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:41 DISPATCHER: Finished worker discovery
05:45:41 DISPATCHER: Starting worker discovery
05:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:41 DISPATCHER: Finished worker discovery
05:46:41 DISPATCHER: Starting worker discovery
05:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:41 DISPATCHER: Finished worker discovery
05:47:41 DISPATCHER: Starting worker discovery
05:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:41 DISPATCHER: Finished worker discovery
05:48:41 DISPATCHER: Starting worker discovery
05:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:41 DISPATCHER: Finished worker discovery
05:49:41 DISPATCHER: Starting worker discovery
05:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:41 DISPATCHER: Finished worker discovery
05:50:41 DISPATCHER: Starting worker discovery
05:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:41 DISPATCHER: Finished worker discovery
05:51:41 DISPATCHER: Starting worker discovery
05:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:41 DISPATCHER: Finished worker discovery
05:52:41 DISPATCHER: Starting worker discovery
05:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:41 DISPATCHER: Finished worker discovery
05:53:41 DISPATCHER: Starting worker discovery
05:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:41 DISPATCHER: Finished worker discovery
05:54:41 DISPATCHER: Starting worker discovery
05:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:41 DISPATCHER: Finished worker discovery
05:55:18 WORKER: done with job (6, 0, 5), trying to register it.
05:55:18 WORKER: registered result for job (6, 0, 5) with dispatcher
05:55:18 DISPATCHER: job (6, 0, 5) finished
05:55:18 DISPATCHER: register_result: lock acquired
05:55:18 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:55:18 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 24, 'leak_rate': 0.8443473173978036, 'lr': 0.06265828651033924, 'optimizer': 'SGD', 'sparsity': 0.8594684264807216, 'steps_to_train': 93, 'weight_decay': 0.012811995562007022}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9282863039991001, 'info': {'number_mnist': 0.9282863039991001, 'config': "{'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 24, 'leak_rate': 0.8443473173978036, 'lr': 0.06265828651033924, 'optimizer': 'SGD', 'sparsity': 0.8594684264807216, 'steps_to_train': 93, 'weight_decay': 0.012811995562007022}"}}
exception: None

05:55:18 job_callback for (6, 0, 5) started
05:55:18 job_callback for (6, 0, 5) got condition
05:55:18 DISPATCHER: Trying to submit another job.
05:55:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:55:18 HBMASTER: Trying to run another job!
05:55:18 job_callback for (6, 0, 5) finished
05:55:18 start sampling a new configuration.
05:55:18 best_vector: [1, 0.7829260984781865, 0.11080295553133455, 0.9622817036818319, 0.5782772696792399, 1, 0.21767209911635943, 0.1415174520872281, 0.19547583271643623], 0.001535416031504856, 2.739133962061895, 0.004205710197789247
05:55:18 done sampling a new configuration.
05:55:18 HBMASTER: schedule new run for iteration 7
05:55:18 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
05:55:18 HBMASTER: submitting job (7, 0, 0) to dispatcher
05:55:18 DISPATCHER: trying to submit job (7, 0, 0)
05:55:18 DISPATCHER: trying to notify the job_runner thread.
05:55:18 HBMASTER: job (7, 0, 0) submitted to dispatcher
05:55:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:55:18 DISPATCHER: Trying to submit another job.
05:55:18 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:55:18 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:55:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:55:18 WORKER: start processing job (7, 0, 0)
05:55:18 WORKER: args: ()
05:55:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 827, 'last_n_outputs': 14, 'leak_rate': 0.990570425920458, 'lr': 0.01434017790873558, 'optimizer': 'SGD', 'sparsity': 0.8022413037879262, 'steps_to_train': 22, 'weight_decay': 0.01796056199314936}, 'budget': 1200.0, 'working_directory': '.'}
05:55:41 DISPATCHER: Starting worker discovery
05:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:41 DISPATCHER: Finished worker discovery
05:56:41 DISPATCHER: Starting worker discovery
05:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:41 DISPATCHER: Finished worker discovery
05:57:41 DISPATCHER: Starting worker discovery
05:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:41 DISPATCHER: Finished worker discovery
05:58:41 DISPATCHER: Starting worker discovery
05:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:41 DISPATCHER: Finished worker discovery
05:59:41 DISPATCHER: Starting worker discovery
05:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:41 DISPATCHER: Finished worker discovery
06:00:41 DISPATCHER: Starting worker discovery
06:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:41 DISPATCHER: Finished worker discovery
06:01:41 DISPATCHER: Starting worker discovery
06:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:41 DISPATCHER: Finished worker discovery
06:02:41 DISPATCHER: Starting worker discovery
06:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:41 DISPATCHER: Finished worker discovery
06:03:41 DISPATCHER: Starting worker discovery
06:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:41 DISPATCHER: Finished worker discovery
06:04:41 DISPATCHER: Starting worker discovery
06:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:41 DISPATCHER: Finished worker discovery
06:05:41 DISPATCHER: Starting worker discovery
06:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:41 DISPATCHER: Finished worker discovery
06:06:41 DISPATCHER: Starting worker discovery
06:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:41 DISPATCHER: Finished worker discovery
06:07:41 DISPATCHER: Starting worker discovery
06:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:41 DISPATCHER: Finished worker discovery
06:08:41 DISPATCHER: Starting worker discovery
06:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:41 DISPATCHER: Finished worker discovery
06:09:41 DISPATCHER: Starting worker discovery
06:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:41 DISPATCHER: Finished worker discovery
06:10:41 DISPATCHER: Starting worker discovery
06:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:41 DISPATCHER: Finished worker discovery
06:11:41 DISPATCHER: Starting worker discovery
06:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:41 DISPATCHER: Finished worker discovery
06:12:41 DISPATCHER: Starting worker discovery
06:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:41 DISPATCHER: Finished worker discovery
06:13:41 DISPATCHER: Starting worker discovery
06:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:41 DISPATCHER: Finished worker discovery
06:14:41 DISPATCHER: Starting worker discovery
06:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:41 DISPATCHER: Finished worker discovery
06:15:41 DISPATCHER: Starting worker discovery
06:15:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:42 DISPATCHER: Finished worker discovery
06:16:05 WORKER: done with job (7, 0, 0), trying to register it.
06:16:05 WORKER: registered result for job (7, 0, 0) with dispatcher
06:16:05 DISPATCHER: job (7, 0, 0) finished
06:16:05 DISPATCHER: register_result: lock acquired
06:16:05 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:16:05 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 827, 'last_n_outputs': 14, 'leak_rate': 0.990570425920458, 'lr': 0.01434017790873558, 'optimizer': 'SGD', 'sparsity': 0.8022413037879262, 'steps_to_train': 22, 'weight_decay': 0.01796056199314936}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9374571419386514, 'info': {'number_mnist': 0.9374571419386514, 'config': "{'batch_size': 32, 'hidden_dim': 827, 'last_n_outputs': 14, 'leak_rate': 0.990570425920458, 'lr': 0.01434017790873558, 'optimizer': 'SGD', 'sparsity': 0.8022413037879262, 'steps_to_train': 22, 'weight_decay': 0.01796056199314936}"}}
exception: None

06:16:05 job_callback for (7, 0, 0) started
06:16:05 DISPATCHER: Trying to submit another job.
06:16:05 job_callback for (7, 0, 0) got condition
06:16:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:16:05 HBMASTER: Trying to run another job!
06:16:05 job_callback for (7, 0, 0) finished
06:16:05 start sampling a new configuration.
06:16:05 done sampling a new configuration.
06:16:05 HBMASTER: schedule new run for iteration 7
06:16:05 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
06:16:05 HBMASTER: submitting job (7, 0, 1) to dispatcher
06:16:05 DISPATCHER: trying to submit job (7, 0, 1)
06:16:05 DISPATCHER: trying to notify the job_runner thread.
06:16:05 HBMASTER: job (7, 0, 1) submitted to dispatcher
06:16:05 DISPATCHER: Trying to submit another job.
06:16:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:16:05 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:16:05 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:16:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:16:05 WORKER: start processing job (7, 0, 1)
06:16:05 WORKER: args: ()
06:16:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 223, 'last_n_outputs': 49, 'leak_rate': 0.9608736897304884, 'lr': 0.06325136501458266, 'optimizer': 'Adam', 'sparsity': 0.7846709262550969, 'steps_to_train': 83, 'weight_decay': 0.013053585343385701}, 'budget': 1200.0, 'working_directory': '.'}
06:16:42 DISPATCHER: Starting worker discovery
06:16:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:42 DISPATCHER: Finished worker discovery
06:17:42 DISPATCHER: Starting worker discovery
06:17:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:42 DISPATCHER: Finished worker discovery
06:18:42 DISPATCHER: Starting worker discovery
06:18:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:42 DISPATCHER: Finished worker discovery
06:19:42 DISPATCHER: Starting worker discovery
06:19:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:42 DISPATCHER: Finished worker discovery
06:20:42 DISPATCHER: Starting worker discovery
06:20:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:42 DISPATCHER: Finished worker discovery
06:21:42 DISPATCHER: Starting worker discovery
06:21:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:42 DISPATCHER: Finished worker discovery
06:22:42 DISPATCHER: Starting worker discovery
06:22:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:42 DISPATCHER: Finished worker discovery
06:23:42 DISPATCHER: Starting worker discovery
06:23:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:42 DISPATCHER: Finished worker discovery
06:24:42 DISPATCHER: Starting worker discovery
06:24:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:42 DISPATCHER: Finished worker discovery
06:25:42 DISPATCHER: Starting worker discovery
06:25:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:42 DISPATCHER: Finished worker discovery
06:26:42 DISPATCHER: Starting worker discovery
06:26:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:42 DISPATCHER: Finished worker discovery
06:27:42 DISPATCHER: Starting worker discovery
06:27:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:42 DISPATCHER: Finished worker discovery
06:28:42 DISPATCHER: Starting worker discovery
06:28:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:42 DISPATCHER: Finished worker discovery
06:29:42 DISPATCHER: Starting worker discovery
06:29:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:42 DISPATCHER: Finished worker discovery
06:30:42 DISPATCHER: Starting worker discovery
06:30:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:42 DISPATCHER: Finished worker discovery
06:31:42 DISPATCHER: Starting worker discovery
06:31:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:42 DISPATCHER: Finished worker discovery
06:32:42 DISPATCHER: Starting worker discovery
06:32:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:42 DISPATCHER: Finished worker discovery
06:33:42 DISPATCHER: Starting worker discovery
06:33:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:42 DISPATCHER: Finished worker discovery
06:34:42 DISPATCHER: Starting worker discovery
06:34:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:42 DISPATCHER: Finished worker discovery
06:35:42 DISPATCHER: Starting worker discovery
06:35:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:42 DISPATCHER: Finished worker discovery
06:36:25 WORKER: done with job (7, 0, 1), trying to register it.
06:36:25 WORKER: registered result for job (7, 0, 1) with dispatcher
06:36:25 DISPATCHER: job (7, 0, 1) finished
06:36:25 DISPATCHER: register_result: lock acquired
06:36:25 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:36:25 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 223, 'last_n_outputs': 49, 'leak_rate': 0.9608736897304884, 'lr': 0.06325136501458266, 'optimizer': 'Adam', 'sparsity': 0.7846709262550969, 'steps_to_train': 83, 'weight_decay': 0.013053585343385701}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4428228911836993, 'info': {'number_mnist': 0.4428228911836993, 'config': "{'batch_size': 128, 'hidden_dim': 223, 'last_n_outputs': 49, 'leak_rate': 0.9608736897304884, 'lr': 0.06325136501458266, 'optimizer': 'Adam', 'sparsity': 0.7846709262550969, 'steps_to_train': 83, 'weight_decay': 0.013053585343385701}"}}
exception: None

06:36:25 job_callback for (7, 0, 1) started
06:36:25 job_callback for (7, 0, 1) got condition
06:36:25 DISPATCHER: Trying to submit another job.
06:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:36:25 HBMASTER: Trying to run another job!
06:36:25 job_callback for (7, 0, 1) finished
06:36:25 start sampling a new configuration.
06:36:25 best_vector: [1, 0.6980219015688998, 0.24118130220086684, 0.9595149008369053, 0.5533594131441258, 1, 0.06985199221716815, 0.045120898352093486, 0.17067498182076052], 0.0017353367615954509, 0.5927409756414244, 0.0010286052051345174
06:36:25 done sampling a new configuration.
06:36:25 HBMASTER: schedule new run for iteration 7
06:36:25 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
06:36:25 HBMASTER: submitting job (7, 0, 2) to dispatcher
06:36:25 DISPATCHER: trying to submit job (7, 0, 2)
06:36:25 DISPATCHER: trying to notify the job_runner thread.
06:36:25 HBMASTER: job (7, 0, 2) submitted to dispatcher
06:36:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:36:25 DISPATCHER: Trying to submit another job.
06:36:25 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:36:25 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:36:25 WORKER: start processing job (7, 0, 2)
06:36:25 WORKER: args: ()
06:36:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 759, 'last_n_outputs': 19, 'leak_rate': 0.9898787252092263, 'lr': 0.012785532670045905, 'optimizer': 'SGD', 'sparsity': 0.7667644781321203, 'steps_to_train': 14, 'weight_decay': 0.016674517307774927}, 'budget': 1200.0, 'working_directory': '.'}
06:36:42 DISPATCHER: Starting worker discovery
06:36:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:42 DISPATCHER: Finished worker discovery
06:37:42 DISPATCHER: Starting worker discovery
06:37:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:42 DISPATCHER: Finished worker discovery
06:38:42 DISPATCHER: Starting worker discovery
06:38:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:42 DISPATCHER: Finished worker discovery
06:39:42 DISPATCHER: Starting worker discovery
06:39:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:42 DISPATCHER: Finished worker discovery
06:40:42 DISPATCHER: Starting worker discovery
06:40:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:42 DISPATCHER: Finished worker discovery
06:41:42 DISPATCHER: Starting worker discovery
06:41:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:42 DISPATCHER: Finished worker discovery
06:42:42 DISPATCHER: Starting worker discovery
06:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:42 DISPATCHER: Finished worker discovery
06:43:42 DISPATCHER: Starting worker discovery
06:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:42 DISPATCHER: Finished worker discovery
06:44:42 DISPATCHER: Starting worker discovery
06:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:42 DISPATCHER: Finished worker discovery
06:45:42 DISPATCHER: Starting worker discovery
06:45:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:42 DISPATCHER: Finished worker discovery
06:46:42 DISPATCHER: Starting worker discovery
06:46:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:42 DISPATCHER: Finished worker discovery
06:47:42 DISPATCHER: Starting worker discovery
06:47:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:42 DISPATCHER: Finished worker discovery
06:48:42 DISPATCHER: Starting worker discovery
06:48:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:42 DISPATCHER: Finished worker discovery
06:49:42 DISPATCHER: Starting worker discovery
06:49:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:42 DISPATCHER: Finished worker discovery
06:50:42 DISPATCHER: Starting worker discovery
06:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:42 DISPATCHER: Finished worker discovery
06:51:42 DISPATCHER: Starting worker discovery
06:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:42 DISPATCHER: Finished worker discovery
06:52:42 DISPATCHER: Starting worker discovery
06:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:42 DISPATCHER: Finished worker discovery
06:53:42 DISPATCHER: Starting worker discovery
06:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:42 DISPATCHER: Finished worker discovery
06:54:42 DISPATCHER: Starting worker discovery
06:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:42 DISPATCHER: Finished worker discovery
06:55:42 DISPATCHER: Starting worker discovery
06:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:42 DISPATCHER: Finished worker discovery
06:56:42 DISPATCHER: Starting worker discovery
06:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:42 DISPATCHER: Finished worker discovery
06:57:31 WORKER: done with job (7, 0, 2), trying to register it.
06:57:31 WORKER: registered result for job (7, 0, 2) with dispatcher
06:57:31 DISPATCHER: job (7, 0, 2) finished
06:57:31 DISPATCHER: register_result: lock acquired
06:57:31 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:57:31 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 759, 'last_n_outputs': 19, 'leak_rate': 0.9898787252092263, 'lr': 0.012785532670045905, 'optimizer': 'SGD', 'sparsity': 0.7667644781321203, 'steps_to_train': 14, 'weight_decay': 0.016674517307774927}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9447178074008897, 'info': {'number_mnist': 0.9447178074008897, 'config': "{'batch_size': 32, 'hidden_dim': 759, 'last_n_outputs': 19, 'leak_rate': 0.9898787252092263, 'lr': 0.012785532670045905, 'optimizer': 'SGD', 'sparsity': 0.7667644781321203, 'steps_to_train': 14, 'weight_decay': 0.016674517307774927}"}}
exception: None

06:57:31 job_callback for (7, 0, 2) started
06:57:31 job_callback for (7, 0, 2) got condition
06:57:31 DISPATCHER: Trying to submit another job.
06:57:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:57:31 HBMASTER: Trying to run another job!
06:57:31 job_callback for (7, 0, 2) finished
06:57:31 start sampling a new configuration.
06:57:31 best_vector: [1, 0.8342272206380439, 0.21619615922177715, 0.11072632000299432, 0.1641355984843991, 1, 0.9589115526800617, 0.40349768676236475, 0.2580308735762037], 0.0018257439705086978, 4.437304528290251, 0.008101381987836867
06:57:31 done sampling a new configuration.
06:57:31 HBMASTER: schedule new run for iteration 7
06:57:31 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
06:57:31 HBMASTER: submitting job (7, 0, 3) to dispatcher
06:57:31 DISPATCHER: trying to submit job (7, 0, 3)
06:57:31 DISPATCHER: trying to notify the job_runner thread.
06:57:31 HBMASTER: job (7, 0, 3) submitted to dispatcher
06:57:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:57:31 DISPATCHER: Trying to submit another job.
06:57:31 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:57:31 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:57:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:57:31 WORKER: start processing job (7, 0, 3)
06:57:31 WORKER: args: ()
06:57:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 868, 'last_n_outputs': 18, 'leak_rate': 0.7776815800007486, 'lr': 0.0021294683861430392, 'optimizer': 'SGD', 'sparsity': 0.9801387726432148, 'steps_to_train': 46, 'weight_decay': 0.021662366851807127}, 'budget': 1200.0, 'working_directory': '.'}
06:57:42 DISPATCHER: Starting worker discovery
06:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:42 DISPATCHER: Finished worker discovery
06:58:42 DISPATCHER: Starting worker discovery
06:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:42 DISPATCHER: Finished worker discovery
06:59:42 DISPATCHER: Starting worker discovery
06:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:42 DISPATCHER: Finished worker discovery
07:00:42 DISPATCHER: Starting worker discovery
07:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:42 DISPATCHER: Finished worker discovery
07:01:42 DISPATCHER: Starting worker discovery
07:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:42 DISPATCHER: Finished worker discovery
07:02:42 DISPATCHER: Starting worker discovery
07:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:42 DISPATCHER: Finished worker discovery
07:03:42 DISPATCHER: Starting worker discovery
07:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:42 DISPATCHER: Finished worker discovery
07:04:42 DISPATCHER: Starting worker discovery
07:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:42 DISPATCHER: Finished worker discovery
07:05:42 DISPATCHER: Starting worker discovery
07:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:42 DISPATCHER: Finished worker discovery
07:06:42 DISPATCHER: Starting worker discovery
07:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:42 DISPATCHER: Finished worker discovery
07:07:42 DISPATCHER: Starting worker discovery
07:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:42 DISPATCHER: Finished worker discovery
07:08:42 DISPATCHER: Starting worker discovery
07:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:42 DISPATCHER: Finished worker discovery
07:09:42 DISPATCHER: Starting worker discovery
07:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:42 DISPATCHER: Finished worker discovery
07:10:42 DISPATCHER: Starting worker discovery
07:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:42 DISPATCHER: Finished worker discovery
07:11:42 DISPATCHER: Starting worker discovery
07:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:42 DISPATCHER: Finished worker discovery
07:12:42 DISPATCHER: Starting worker discovery
07:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:42 DISPATCHER: Finished worker discovery
07:13:42 DISPATCHER: Starting worker discovery
07:13:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:42 DISPATCHER: Finished worker discovery
07:14:42 DISPATCHER: Starting worker discovery
07:14:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:42 DISPATCHER: Finished worker discovery
07:15:42 DISPATCHER: Starting worker discovery
07:15:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:42 DISPATCHER: Finished worker discovery
07:16:42 DISPATCHER: Starting worker discovery
07:16:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:42 DISPATCHER: Finished worker discovery
07:17:42 DISPATCHER: Starting worker discovery
07:17:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:42 DISPATCHER: Finished worker discovery
07:17:59 WORKER: done with job (7, 0, 3), trying to register it.
07:17:59 WORKER: registered result for job (7, 0, 3) with dispatcher
07:17:59 DISPATCHER: job (7, 0, 3) finished
07:17:59 DISPATCHER: register_result: lock acquired
07:17:59 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:17:59 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 868, 'last_n_outputs': 18, 'leak_rate': 0.7776815800007486, 'lr': 0.0021294683861430392, 'optimizer': 'SGD', 'sparsity': 0.9801387726432148, 'steps_to_train': 46, 'weight_decay': 0.021662366851807127}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9305334839033128, 'info': {'number_mnist': 0.9305334839033128, 'config': "{'batch_size': 32, 'hidden_dim': 868, 'last_n_outputs': 18, 'leak_rate': 0.7776815800007486, 'lr': 0.0021294683861430392, 'optimizer': 'SGD', 'sparsity': 0.9801387726432148, 'steps_to_train': 46, 'weight_decay': 0.021662366851807127}"}}
exception: None

07:17:59 job_callback for (7, 0, 3) started
07:17:59 job_callback for (7, 0, 3) got condition
07:17:59 DISPATCHER: Trying to submit another job.
07:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:17:59 HBMASTER: Trying to run another job!
07:17:59 job_callback for (7, 0, 3) finished
07:17:59 start sampling a new configuration.
07:17:59 done sampling a new configuration.
07:17:59 HBMASTER: schedule new run for iteration 8
07:17:59 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
07:17:59 HBMASTER: submitting job (8, 0, 0) to dispatcher
07:17:59 DISPATCHER: trying to submit job (8, 0, 0)
07:17:59 DISPATCHER: trying to notify the job_runner thread.
07:17:59 HBMASTER: job (8, 0, 0) submitted to dispatcher
07:17:59 DISPATCHER: Trying to submit another job.
07:17:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:17:59 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:17:59 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:17:59 WORKER: start processing job (8, 0, 0)
07:17:59 WORKER: args: ()
07:17:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 697, 'last_n_outputs': 17, 'leak_rate': 0.7992473643384642, 'lr': 0.08374875912160545, 'optimizer': 'SGD', 'sparsity': 0.9893851344948412, 'steps_to_train': 77, 'weight_decay': 0.03177892598037331}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:18:42 DISPATCHER: Starting worker discovery
07:18:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:42 DISPATCHER: Finished worker discovery
07:18:52 WORKER: done with job (8, 0, 0), trying to register it.
07:18:52 WORKER: registered result for job (8, 0, 0) with dispatcher
07:18:52 DISPATCHER: job (8, 0, 0) finished
07:18:52 DISPATCHER: register_result: lock acquired
07:18:52 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:18:52 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 697, 'last_n_outputs': 17, 'leak_rate': 0.7992473643384642, 'lr': 0.08374875912160545, 'optimizer': 'SGD', 'sparsity': 0.9893851344948412, 'steps_to_train': 77, 'weight_decay': 0.03177892598037331}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.81410086015686, 'info': {'number_mnist': 0.81410086015686, 'config': "{'batch_size': 64, 'hidden_dim': 697, 'last_n_outputs': 17, 'leak_rate': 0.7992473643384642, 'lr': 0.08374875912160545, 'optimizer': 'SGD', 'sparsity': 0.9893851344948412, 'steps_to_train': 77, 'weight_decay': 0.03177892598037331}"}}
exception: None

07:18:52 job_callback for (8, 0, 0) started
07:18:52 DISPATCHER: Trying to submit another job.
07:18:52 job_callback for (8, 0, 0) got condition
07:18:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:52 HBMASTER: Trying to run another job!
07:18:52 job_callback for (8, 0, 0) finished
07:18:52 start sampling a new configuration.
07:18:52 best_vector: [3, 0.8500152109095178, 0.571739435686529, 0.21936405352194716, 0.26881853324678495, 0, 0.4231370656576809, 0.9607852499852557, 0.5725689946850736], 0.0, inf, 0.02219553126193242
07:18:52 done sampling a new configuration.
07:18:52 HBMASTER: schedule new run for iteration 8
07:18:52 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
07:18:52 HBMASTER: submitting job (8, 0, 1) to dispatcher
07:18:52 DISPATCHER: trying to submit job (8, 0, 1)
07:18:52 DISPATCHER: trying to notify the job_runner thread.
07:18:52 HBMASTER: job (8, 0, 1) submitted to dispatcher
07:18:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:52 DISPATCHER: Trying to submit another job.
07:18:52 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:18:52 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:18:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:52 WORKER: start processing job (8, 0, 1)
07:18:52 WORKER: args: ()
07:18:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 880, 'last_n_outputs': 33, 'leak_rate': 0.8048410133804867, 'lr': 0.0034485542827827117, 'optimizer': 'Adam', 'sparsity': 0.8515528957578434, 'steps_to_train': 97, 'weight_decay': 0.055581394235902616}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:19:42 DISPATCHER: Starting worker discovery
07:19:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:42 DISPATCHER: Finished worker discovery
07:19:47 WORKER: done with job (8, 0, 1), trying to register it.
07:19:47 WORKER: registered result for job (8, 0, 1) with dispatcher
07:19:47 DISPATCHER: job (8, 0, 1) finished
07:19:47 DISPATCHER: register_result: lock acquired
07:19:47 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:19:47 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 880, 'last_n_outputs': 33, 'leak_rate': 0.8048410133804867, 'lr': 0.0034485542827827117, 'optimizer': 'Adam', 'sparsity': 0.8515528957578434, 'steps_to_train': 97, 'weight_decay': 0.055581394235902616}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8937969027722321, 'info': {'number_mnist': 0.8937969027722321, 'config': "{'batch_size': 128, 'hidden_dim': 880, 'last_n_outputs': 33, 'leak_rate': 0.8048410133804867, 'lr': 0.0034485542827827117, 'optimizer': 'Adam', 'sparsity': 0.8515528957578434, 'steps_to_train': 97, 'weight_decay': 0.055581394235902616}"}}
exception: None

07:19:47 job_callback for (8, 0, 1) started
07:19:47 job_callback for (8, 0, 1) got condition
07:19:47 DISPATCHER: Trying to submit another job.
07:19:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:19:47 HBMASTER: Trying to run another job!
07:19:47 job_callback for (8, 0, 1) finished
07:19:47 start sampling a new configuration.
07:19:47 done sampling a new configuration.
07:19:47 HBMASTER: schedule new run for iteration 8
07:19:47 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
07:19:47 HBMASTER: submitting job (8, 0, 2) to dispatcher
07:19:47 DISPATCHER: trying to submit job (8, 0, 2)
07:19:47 DISPATCHER: trying to notify the job_runner thread.
07:19:47 HBMASTER: job (8, 0, 2) submitted to dispatcher
07:19:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:19:47 DISPATCHER: Trying to submit another job.
07:19:47 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:19:47 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:19:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:19:47 WORKER: start processing job (8, 0, 2)
07:19:47 WORKER: args: ()
07:19:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 529, 'last_n_outputs': 30, 'leak_rate': 0.9007562518011478, 'lr': 0.0020896445605356113, 'optimizer': 'Adam', 'sparsity': 0.7855880401491476, 'steps_to_train': 32, 'weight_decay': 0.02299238890165762}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:20:41 WORKER: done with job (8, 0, 2), trying to register it.
07:20:41 WORKER: registered result for job (8, 0, 2) with dispatcher
07:20:41 DISPATCHER: job (8, 0, 2) finished
07:20:41 DISPATCHER: register_result: lock acquired
07:20:41 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:20:41 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 529, 'last_n_outputs': 30, 'leak_rate': 0.9007562518011478, 'lr': 0.0020896445605356113, 'optimizer': 'Adam', 'sparsity': 0.7855880401491476, 'steps_to_train': 32, 'weight_decay': 0.02299238890165762}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8144330162996427, 'info': {'number_mnist': 0.8144330162996427, 'config': "{'batch_size': 32, 'hidden_dim': 529, 'last_n_outputs': 30, 'leak_rate': 0.9007562518011478, 'lr': 0.0020896445605356113, 'optimizer': 'Adam', 'sparsity': 0.7855880401491476, 'steps_to_train': 32, 'weight_decay': 0.02299238890165762}"}}
exception: None

07:20:41 job_callback for (8, 0, 2) started
07:20:41 DISPATCHER: Trying to submit another job.
07:20:41 job_callback for (8, 0, 2) got condition
07:20:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:20:41 HBMASTER: Trying to run another job!
07:20:41 job_callback for (8, 0, 2) finished
07:20:41 start sampling a new configuration.
07:20:41 best_vector: [3, 0.9391519304812849, 0.16101822713832514, 0.0179646129433505, 0.8268082558976501, 1, 0.4914585077934751, 0.2855346233787486, 0.15240019684103406], 0.012949683388124127, 0.22478237820937244, 0.002910860629040945
07:20:41 done sampling a new configuration.
07:20:41 HBMASTER: schedule new run for iteration 8
07:20:41 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
07:20:41 HBMASTER: submitting job (8, 0, 3) to dispatcher
07:20:41 DISPATCHER: trying to submit job (8, 0, 3)
07:20:41 DISPATCHER: trying to notify the job_runner thread.
07:20:41 HBMASTER: job (8, 0, 3) submitted to dispatcher
07:20:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:20:41 DISPATCHER: Trying to submit another job.
07:20:41 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:20:41 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:20:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:20:41 WORKER: start processing job (8, 0, 3)
07:20:41 WORKER: args: ()
07:20:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:20:42 DISPATCHER: Starting worker discovery
07:20:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:42 DISPATCHER: Finished worker discovery
07:21:35 WORKER: done with job (8, 0, 3), trying to register it.
07:21:35 WORKER: registered result for job (8, 0, 3) with dispatcher
07:21:35 DISPATCHER: job (8, 0, 3) finished
07:21:35 DISPATCHER: register_result: lock acquired
07:21:35 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:21:35 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9510658967046681, 'info': {'number_mnist': 0.9510658967046681, 'config': "{'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}"}}
exception: None

07:21:35 job_callback for (8, 0, 3) started
07:21:35 job_callback for (8, 0, 3) got condition
07:21:35 DISPATCHER: Trying to submit another job.
07:21:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:21:35 HBMASTER: Trying to run another job!
07:21:35 job_callback for (8, 0, 3) finished
07:21:35 start sampling a new configuration.
07:21:36 best_vector: [2, 0.9630217643411065, 0.4184366091901438, 0.139167562616011, 0.16772952293865312, 1, 0.9869992619514303, 0.30168226258963315, 0.19042500554865457], 0.00208968563616294, 1.7419547633147705, 0.00364013784774449
07:21:36 done sampling a new configuration.
07:21:36 HBMASTER: schedule new run for iteration 8
07:21:36 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
07:21:36 HBMASTER: submitting job (8, 0, 4) to dispatcher
07:21:36 DISPATCHER: trying to submit job (8, 0, 4)
07:21:36 DISPATCHER: trying to notify the job_runner thread.
07:21:36 HBMASTER: job (8, 0, 4) submitted to dispatcher
07:21:36 DISPATCHER: Trying to submit another job.
07:21:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:21:36 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:21:36 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:21:36 WORKER: start processing job (8, 0, 4)
07:21:36 WORKER: args: ()
07:21:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 971, 'last_n_outputs': 27, 'leak_rate': 0.7847918906540028, 'lr': 0.002165005708880088, 'optimizer': 'SGD', 'sparsity': 0.9868798228683433, 'steps_to_train': 37, 'weight_decay': 0.0176908477186746}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:21:42 DISPATCHER: Starting worker discovery
07:21:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:42 DISPATCHER: Finished worker discovery
07:22:30 WORKER: done with job (8, 0, 4), trying to register it.
07:22:30 WORKER: registered result for job (8, 0, 4) with dispatcher
07:22:30 DISPATCHER: job (8, 0, 4) finished
07:22:30 DISPATCHER: register_result: lock acquired
07:22:30 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:22:30 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 971, 'last_n_outputs': 27, 'leak_rate': 0.7847918906540028, 'lr': 0.002165005708880088, 'optimizer': 'SGD', 'sparsity': 0.9868798228683433, 'steps_to_train': 37, 'weight_decay': 0.0176908477186746}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.877577614908266, 'info': {'number_mnist': 0.877577614908266, 'config': "{'batch_size': 64, 'hidden_dim': 971, 'last_n_outputs': 27, 'leak_rate': 0.7847918906540028, 'lr': 0.002165005708880088, 'optimizer': 'SGD', 'sparsity': 0.9868798228683433, 'steps_to_train': 37, 'weight_decay': 0.0176908477186746}"}}
exception: None

07:22:30 job_callback for (8, 0, 4) started
07:22:30 job_callback for (8, 0, 4) got condition
07:22:30 DISPATCHER: Trying to submit another job.
07:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:22:30 HBMASTER: Trying to run another job!
07:22:30 job_callback for (8, 0, 4) finished
07:22:30 start sampling a new configuration.
07:22:30 done sampling a new configuration.
07:22:30 HBMASTER: schedule new run for iteration 8
07:22:30 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
07:22:30 HBMASTER: submitting job (8, 0, 5) to dispatcher
07:22:30 DISPATCHER: trying to submit job (8, 0, 5)
07:22:30 DISPATCHER: trying to notify the job_runner thread.
07:22:30 HBMASTER: job (8, 0, 5) submitted to dispatcher
07:22:30 DISPATCHER: Trying to submit another job.
07:22:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:22:30 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:22:30 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:22:30 WORKER: start processing job (8, 0, 5)
07:22:30 WORKER: args: ()
07:22:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 372, 'last_n_outputs': 50, 'leak_rate': 0.8979890277363756, 'lr': 0.004659404300400164, 'optimizer': 'Adam', 'sparsity': 0.9186427019881015, 'steps_to_train': 95, 'weight_decay': 0.012751533859587267}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:22:42 DISPATCHER: Starting worker discovery
07:22:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:42 DISPATCHER: Finished worker discovery
07:23:24 WORKER: done with job (8, 0, 5), trying to register it.
07:23:24 WORKER: registered result for job (8, 0, 5) with dispatcher
07:23:24 DISPATCHER: job (8, 0, 5) finished
07:23:24 DISPATCHER: register_result: lock acquired
07:23:24 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:23:24 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 372, 'last_n_outputs': 50, 'leak_rate': 0.8979890277363756, 'lr': 0.004659404300400164, 'optimizer': 'Adam', 'sparsity': 0.9186427019881015, 'steps_to_train': 95, 'weight_decay': 0.012751533859587267}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8697485868299826, 'info': {'number_mnist': 0.8697485868299826, 'config': "{'batch_size': 64, 'hidden_dim': 372, 'last_n_outputs': 50, 'leak_rate': 0.8979890277363756, 'lr': 0.004659404300400164, 'optimizer': 'Adam', 'sparsity': 0.9186427019881015, 'steps_to_train': 95, 'weight_decay': 0.012751533859587267}"}}
exception: None

07:23:24 job_callback for (8, 0, 5) started
07:23:24 DISPATCHER: Trying to submit another job.
07:23:24 job_callback for (8, 0, 5) got condition
07:23:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:23:24 HBMASTER: Trying to run another job!
07:23:24 job_callback for (8, 0, 5) finished
07:23:24 start sampling a new configuration.
07:23:24 done sampling a new configuration.
07:23:24 HBMASTER: schedule new run for iteration 8
07:23:24 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
07:23:24 HBMASTER: submitting job (8, 0, 6) to dispatcher
07:23:24 DISPATCHER: trying to submit job (8, 0, 6)
07:23:24 DISPATCHER: trying to notify the job_runner thread.
07:23:24 HBMASTER: job (8, 0, 6) submitted to dispatcher
07:23:24 DISPATCHER: Trying to submit another job.
07:23:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:23:24 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:23:24 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:23:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:23:24 WORKER: start processing job (8, 0, 6)
07:23:24 WORKER: args: ()
07:23:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 924, 'last_n_outputs': 36, 'leak_rate': 0.7911458723188842, 'lr': 0.01333369791204396, 'optimizer': 'SGD', 'sparsity': 0.8754539615383006, 'steps_to_train': 46, 'weight_decay': 0.17461559675378624}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:23:42 DISPATCHER: Starting worker discovery
07:23:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:42 DISPATCHER: Finished worker discovery
07:24:18 WORKER: done with job (8, 0, 6), trying to register it.
07:24:18 WORKER: registered result for job (8, 0, 6) with dispatcher
07:24:18 DISPATCHER: job (8, 0, 6) finished
07:24:18 DISPATCHER: register_result: lock acquired
07:24:18 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:24:18 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 924, 'last_n_outputs': 36, 'leak_rate': 0.7911458723188842, 'lr': 0.01333369791204396, 'optimizer': 'SGD', 'sparsity': 0.8754539615383006, 'steps_to_train': 46, 'weight_decay': 0.17461559675378624}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8895462169629363, 'info': {'number_mnist': 0.8895462169629363, 'config': "{'batch_size': 32, 'hidden_dim': 924, 'last_n_outputs': 36, 'leak_rate': 0.7911458723188842, 'lr': 0.01333369791204396, 'optimizer': 'SGD', 'sparsity': 0.8754539615383006, 'steps_to_train': 46, 'weight_decay': 0.17461559675378624}"}}
exception: None

07:24:18 job_callback for (8, 0, 6) started
07:24:18 DISPATCHER: Trying to submit another job.
07:24:18 job_callback for (8, 0, 6) got condition
07:24:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:24:18 HBMASTER: Trying to run another job!
07:24:18 job_callback for (8, 0, 6) finished
07:24:18 start sampling a new configuration.
07:24:18 best_vector: [3, 0.25520376266806777, 0.9099348668525975, 0.35268502420105263, 0.3950292979336627, 0, 0.954835415354675, 0.9411263591732926, 0.1007497667332159], 0.0, inf, 0.010021196102763879
07:24:18 done sampling a new configuration.
07:24:18 HBMASTER: schedule new run for iteration 8
07:24:18 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
07:24:18 HBMASTER: submitting job (8, 0, 7) to dispatcher
07:24:18 DISPATCHER: trying to submit job (8, 0, 7)
07:24:18 DISPATCHER: trying to notify the job_runner thread.
07:24:18 HBMASTER: job (8, 0, 7) submitted to dispatcher
07:24:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:24:18 DISPATCHER: Trying to submit another job.
07:24:18 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:24:18 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:24:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:24:18 WORKER: start processing job (8, 0, 7)
07:24:18 WORKER: args: ()
07:24:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 404, 'last_n_outputs': 47, 'leak_rate': 0.8381712560502632, 'lr': 0.006166781996866859, 'optimizer': 'Adam', 'sparsity': 0.979160499685122, 'steps_to_train': 95, 'weight_decay': 0.013523168785112755}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:24:42 DISPATCHER: Starting worker discovery
07:24:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:42 DISPATCHER: Finished worker discovery
07:25:11 WORKER: done with job (8, 0, 7), trying to register it.
07:25:11 WORKER: registered result for job (8, 0, 7) with dispatcher
07:25:11 DISPATCHER: job (8, 0, 7) finished
07:25:11 DISPATCHER: register_result: lock acquired
07:25:11 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:25:11 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 404, 'last_n_outputs': 47, 'leak_rate': 0.8381712560502632, 'lr': 0.006166781996866859, 'optimizer': 'Adam', 'sparsity': 0.979160499685122, 'steps_to_train': 95, 'weight_decay': 0.013523168785112755}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.869498003246359, 'info': {'number_mnist': 0.869498003246359, 'config': "{'batch_size': 128, 'hidden_dim': 404, 'last_n_outputs': 47, 'leak_rate': 0.8381712560502632, 'lr': 0.006166781996866859, 'optimizer': 'Adam', 'sparsity': 0.979160499685122, 'steps_to_train': 95, 'weight_decay': 0.013523168785112755}"}}
exception: None

07:25:11 job_callback for (8, 0, 7) started
07:25:11 DISPATCHER: Trying to submit another job.
07:25:11 job_callback for (8, 0, 7) got condition
07:25:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:25:11 HBMASTER: Trying to run another job!
07:25:11 job_callback for (8, 0, 7) finished
07:25:11 start sampling a new configuration.
07:25:11 best_vector: [2, 0.6778647910191344, 0.2216415623244498, 0.5732789374191439, 0.5890928302990862, 1, 0.09588921558514676, 0.5284434270309695, 0.16993625640789906], 0.01168072265021029, 3.126366287920747, 0.03651821751216973
07:25:11 done sampling a new configuration.
07:25:11 HBMASTER: schedule new run for iteration 8
07:25:11 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:25:11 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:25:11 DISPATCHER: trying to submit job (8, 0, 8)
07:25:11 DISPATCHER: trying to notify the job_runner thread.
07:25:11 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:25:11 DISPATCHER: Trying to submit another job.
07:25:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:25:11 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:25:11 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:25:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:25:11 WORKER: start processing job (8, 0, 8)
07:25:11 WORKER: args: ()
07:25:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:25:42 DISPATCHER: Starting worker discovery
07:25:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:42 DISPATCHER: Finished worker discovery
07:26:06 WORKER: done with job (8, 0, 8), trying to register it.
07:26:06 WORKER: registered result for job (8, 0, 8) with dispatcher
07:26:06 DISPATCHER: job (8, 0, 8) finished
07:26:06 DISPATCHER: register_result: lock acquired
07:26:06 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:26:06 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9317707395173234, 'info': {'number_mnist': 0.9317707395173234, 'config': "{'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}"}}
exception: None

07:26:06 job_callback for (8, 0, 8) started
07:26:06 DISPATCHER: Trying to submit another job.
07:26:06 job_callback for (8, 0, 8) got condition
07:26:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:26:06 HBMASTER: Trying to run another job!
07:26:06 job_callback for (8, 0, 8) finished
07:26:06 start sampling a new configuration.
07:26:06 done sampling a new configuration.
07:26:06 HBMASTER: schedule new run for iteration 8
07:26:06 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
07:26:06 HBMASTER: submitting job (8, 0, 9) to dispatcher
07:26:06 DISPATCHER: trying to submit job (8, 0, 9)
07:26:06 DISPATCHER: trying to notify the job_runner thread.
07:26:06 HBMASTER: job (8, 0, 9) submitted to dispatcher
07:26:06 DISPATCHER: Trying to submit another job.
07:26:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:26:06 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:26:06 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:26:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:26:06 WORKER: start processing job (8, 0, 9)
07:26:06 WORKER: args: ()
07:26:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 434, 'last_n_outputs': 42, 'leak_rate': 0.9967499339036138, 'lr': 0.0199445358074094, 'optimizer': 'Adam', 'sparsity': 0.9701251100836021, 'steps_to_train': 81, 'weight_decay': 0.012107141038245657}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:26:42 DISPATCHER: Starting worker discovery
07:26:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:42 DISPATCHER: Finished worker discovery
07:27:00 WORKER: done with job (8, 0, 9), trying to register it.
07:27:00 WORKER: registered result for job (8, 0, 9) with dispatcher
07:27:00 DISPATCHER: job (8, 0, 9) finished
07:27:00 DISPATCHER: register_result: lock acquired
07:27:00 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:27:00 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 434, 'last_n_outputs': 42, 'leak_rate': 0.9967499339036138, 'lr': 0.0199445358074094, 'optimizer': 'Adam', 'sparsity': 0.9701251100836021, 'steps_to_train': 81, 'weight_decay': 0.012107141038245657}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5697734303555044, 'info': {'number_mnist': 0.5697734303555044, 'config': "{'batch_size': 128, 'hidden_dim': 434, 'last_n_outputs': 42, 'leak_rate': 0.9967499339036138, 'lr': 0.0199445358074094, 'optimizer': 'Adam', 'sparsity': 0.9701251100836021, 'steps_to_train': 81, 'weight_decay': 0.012107141038245657}"}}
exception: None

07:27:00 job_callback for (8, 0, 9) started
07:27:00 job_callback for (8, 0, 9) got condition
07:27:00 DISPATCHER: Trying to submit another job.
07:27:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:27:00 HBMASTER: Trying to run another job!
07:27:00 job_callback for (8, 0, 9) finished
07:27:00 start sampling a new configuration.
07:27:00 best_vector: [3, 0.9515234663380775, 0.21434996560190883, 0.9661026422933294, 0.7636821725714436, 1, 0.07481275780317895, 0.5628253183450208, 0.035511768553197195], 0.005155368741470183, 0.5968048366819623, 0.0030767489997884055
07:27:00 done sampling a new configuration.
07:27:00 HBMASTER: schedule new run for iteration 8
07:27:00 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
07:27:00 HBMASTER: submitting job (8, 0, 10) to dispatcher
07:27:00 DISPATCHER: trying to submit job (8, 0, 10)
07:27:00 DISPATCHER: trying to notify the job_runner thread.
07:27:00 HBMASTER: job (8, 0, 10) submitted to dispatcher
07:27:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:27:00 DISPATCHER: Trying to submit another job.
07:27:00 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:27:00 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:27:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:27:00 WORKER: start processing job (8, 0, 10)
07:27:00 WORKER: args: ()
07:27:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 18, 'leak_rate': 0.9915256605733324, 'lr': 0.03367939993964732, 'optimizer': 'SGD', 'sparsity': 0.767955061872763, 'steps_to_train': 61, 'weight_decay': 0.011122486213022233}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:27:42 DISPATCHER: Starting worker discovery
07:27:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:42 DISPATCHER: Finished worker discovery
07:27:56 WORKER: done with job (8, 0, 10), trying to register it.
07:27:56 WORKER: registered result for job (8, 0, 10) with dispatcher
07:27:56 DISPATCHER: job (8, 0, 10) finished
07:27:56 DISPATCHER: register_result: lock acquired
07:27:56 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:27:56 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 18, 'leak_rate': 0.9915256605733324, 'lr': 0.03367939993964732, 'optimizer': 'SGD', 'sparsity': 0.767955061872763, 'steps_to_train': 61, 'weight_decay': 0.011122486213022233}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9437518304337249, 'info': {'number_mnist': 0.9437518304337249, 'config': "{'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 18, 'leak_rate': 0.9915256605733324, 'lr': 0.03367939993964732, 'optimizer': 'SGD', 'sparsity': 0.767955061872763, 'steps_to_train': 61, 'weight_decay': 0.011122486213022233}"}}
exception: None

07:27:56 job_callback for (8, 0, 10) started
07:27:56 DISPATCHER: Trying to submit another job.
07:27:56 job_callback for (8, 0, 10) got condition
07:27:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:27:56 HBMASTER: Trying to run another job!
07:27:56 job_callback for (8, 0, 10) finished
07:27:56 start sampling a new configuration.
07:27:56 best_vector: [1, 0.8041209508574189, 0.14088678671494181, 0.046514327204708154, 0.6520634970195054, 1, 0.8808590447656317, 0.24416818820913372, 0.30403464434364247], 0.0021274309970621954, 0.7374347847772158, 0.0015688416194469376
07:27:56 done sampling a new configuration.
07:27:56 HBMASTER: schedule new run for iteration 8
07:27:56 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
07:27:56 HBMASTER: submitting job (8, 0, 11) to dispatcher
07:27:56 DISPATCHER: trying to submit job (8, 0, 11)
07:27:56 DISPATCHER: trying to notify the job_runner thread.
07:27:56 HBMASTER: job (8, 0, 11) submitted to dispatcher
07:27:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:27:56 DISPATCHER: Trying to submit another job.
07:27:56 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:27:56 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:27:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:27:56 WORKER: start processing job (8, 0, 11)
07:27:56 WORKER: args: ()
07:27:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 844, 'last_n_outputs': 15, 'leak_rate': 0.761628581801177, 'lr': 0.02014313178296849, 'optimizer': 'SGD', 'sparsity': 0.9614061707437516, 'steps_to_train': 32, 'weight_decay': 0.024863266899436874}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:28:42 DISPATCHER: Starting worker discovery
07:28:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:42 DISPATCHER: Finished worker discovery
07:28:50 WORKER: done with job (8, 0, 11), trying to register it.
07:28:50 WORKER: registered result for job (8, 0, 11) with dispatcher
07:28:50 DISPATCHER: job (8, 0, 11) finished
07:28:50 DISPATCHER: register_result: lock acquired
07:28:50 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:28:50 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 844, 'last_n_outputs': 15, 'leak_rate': 0.761628581801177, 'lr': 0.02014313178296849, 'optimizer': 'SGD', 'sparsity': 0.9614061707437516, 'steps_to_train': 32, 'weight_decay': 0.024863266899436874}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9348451375524436, 'info': {'number_mnist': 0.9348451375524436, 'config': "{'batch_size': 32, 'hidden_dim': 844, 'last_n_outputs': 15, 'leak_rate': 0.761628581801177, 'lr': 0.02014313178296849, 'optimizer': 'SGD', 'sparsity': 0.9614061707437516, 'steps_to_train': 32, 'weight_decay': 0.024863266899436874}"}}
exception: None

07:28:50 job_callback for (8, 0, 11) started
07:28:50 job_callback for (8, 0, 11) got condition
07:28:50 DISPATCHER: Trying to submit another job.
07:28:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:28:50 HBMASTER: Trying to run another job!
07:28:50 job_callback for (8, 0, 11) finished
07:28:50 start sampling a new configuration.
07:28:50 done sampling a new configuration.
07:28:50 HBMASTER: schedule new run for iteration 8
07:28:50 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
07:28:50 HBMASTER: submitting job (8, 0, 12) to dispatcher
07:28:50 DISPATCHER: trying to submit job (8, 0, 12)
07:28:50 DISPATCHER: trying to notify the job_runner thread.
07:28:50 HBMASTER: job (8, 0, 12) submitted to dispatcher
07:28:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:28:50 DISPATCHER: Trying to submit another job.
07:28:50 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:28:50 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:28:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:28:50 WORKER: start processing job (8, 0, 12)
07:28:50 WORKER: args: ()
07:28:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 357, 'last_n_outputs': 19, 'leak_rate': 0.91098323025739, 'lr': 0.005210224237896378, 'optimizer': 'Adam', 'sparsity': 0.8323200880498969, 'steps_to_train': 10, 'weight_decay': 0.014527355484742405}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:29:42 DISPATCHER: Starting worker discovery
07:29:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:42 DISPATCHER: Finished worker discovery
07:29:45 WORKER: done with job (8, 0, 12), trying to register it.
07:29:45 WORKER: registered result for job (8, 0, 12) with dispatcher
07:29:45 DISPATCHER: job (8, 0, 12) finished
07:29:45 DISPATCHER: register_result: lock acquired
07:29:45 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:29:45 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 357, 'last_n_outputs': 19, 'leak_rate': 0.91098323025739, 'lr': 0.005210224237896378, 'optimizer': 'Adam', 'sparsity': 0.8323200880498969, 'steps_to_train': 10, 'weight_decay': 0.014527355484742405}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.354780306785075, 'info': {'number_mnist': 0.354780306785075, 'config': "{'batch_size': 64, 'hidden_dim': 357, 'last_n_outputs': 19, 'leak_rate': 0.91098323025739, 'lr': 0.005210224237896378, 'optimizer': 'Adam', 'sparsity': 0.8323200880498969, 'steps_to_train': 10, 'weight_decay': 0.014527355484742405}"}}
exception: None

07:29:45 job_callback for (8, 0, 12) started
07:29:45 DISPATCHER: Trying to submit another job.
07:29:45 job_callback for (8, 0, 12) got condition
07:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:29:45 HBMASTER: Trying to run another job!
07:29:45 job_callback for (8, 0, 12) finished
07:29:45 start sampling a new configuration.
07:29:45 best_vector: [2, 0.9732347203990637, 0.640167897323624, 0.6349755120235321, 0.38461044347928786, 1, 0.06600609046461359, 0.9185166440323629, 0.253126191449591], 0.015621045919712268, 0.26098504785037363, 0.00407685941682899
07:29:45 done sampling a new configuration.
07:29:45 HBMASTER: schedule new run for iteration 8
07:29:45 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
07:29:45 HBMASTER: submitting job (8, 0, 13) to dispatcher
07:29:45 DISPATCHER: trying to submit job (8, 0, 13)
07:29:45 DISPATCHER: trying to notify the job_runner thread.
07:29:45 HBMASTER: job (8, 0, 13) submitted to dispatcher
07:29:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:29:45 DISPATCHER: Trying to submit another job.
07:29:45 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:29:45 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:29:45 WORKER: start processing job (8, 0, 13)
07:29:45 WORKER: args: ()
07:29:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 979, 'last_n_outputs': 36, 'leak_rate': 0.908743878005883, 'lr': 0.005877882320877374, 'optimizer': 'SGD', 'sparsity': 0.7658414617115072, 'steps_to_train': 93, 'weight_decay': 0.021346406122391658}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:30:39 WORKER: done with job (8, 0, 13), trying to register it.
07:30:39 WORKER: registered result for job (8, 0, 13) with dispatcher
07:30:39 DISPATCHER: job (8, 0, 13) finished
07:30:39 DISPATCHER: register_result: lock acquired
07:30:39 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:30:39 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 979, 'last_n_outputs': 36, 'leak_rate': 0.908743878005883, 'lr': 0.005877882320877374, 'optimizer': 'SGD', 'sparsity': 0.7658414617115072, 'steps_to_train': 93, 'weight_decay': 0.021346406122391658}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9257863225503612, 'info': {'number_mnist': 0.9257863225503612, 'config': "{'batch_size': 64, 'hidden_dim': 979, 'last_n_outputs': 36, 'leak_rate': 0.908743878005883, 'lr': 0.005877882320877374, 'optimizer': 'SGD', 'sparsity': 0.7658414617115072, 'steps_to_train': 93, 'weight_decay': 0.021346406122391658}"}}
exception: None

07:30:39 job_callback for (8, 0, 13) started
07:30:39 DISPATCHER: Trying to submit another job.
07:30:39 job_callback for (8, 0, 13) got condition
07:30:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:30:39 HBMASTER: Trying to run another job!
07:30:39 job_callback for (8, 0, 13) finished
07:30:39 start sampling a new configuration.
07:30:40 best_vector: [2, 0.63812690769747, 0.22463830649324212, 0.8373542113274901, 0.6732651120064732, 1, 0.1362838333645443, 0.12308161761513314, 0.05658553150806225], 0.005223422653901497, 0.4920083655792985, 0.0025699676426759574
07:30:40 done sampling a new configuration.
07:30:40 HBMASTER: schedule new run for iteration 8
07:30:40 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:30:40 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:30:40 DISPATCHER: trying to submit job (8, 0, 14)
07:30:40 DISPATCHER: trying to notify the job_runner thread.
07:30:40 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:30:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:30:40 DISPATCHER: Trying to submit another job.
07:30:40 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:30:40 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:30:40 WORKER: start processing job (8, 0, 14)
07:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:30:40 WORKER: args: ()
07:30:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:30:42 DISPATCHER: Starting worker discovery
07:30:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:42 DISPATCHER: Finished worker discovery
07:31:33 WORKER: done with job (8, 0, 14), trying to register it.
07:31:33 WORKER: registered result for job (8, 0, 14) with dispatcher
07:31:33 DISPATCHER: job (8, 0, 14) finished
07:31:33 DISPATCHER: register_result: lock acquired
07:31:33 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:31:33 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9480015454041077, 'info': {'number_mnist': 0.9480015454041077, 'config': "{'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}"}}
exception: None

07:31:33 job_callback for (8, 0, 14) started
07:31:33 DISPATCHER: Trying to submit another job.
07:31:33 job_callback for (8, 0, 14) got condition
07:31:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:31:33 HBMASTER: Trying to run another job!
07:31:33 job_callback for (8, 0, 14) finished
07:31:33 start sampling a new configuration.
07:31:34 best_vector: [1, 0.9770755616233369, 0.188284162781413, 0.8275347479738727, 0.7404560333248154, 1, 0.004894665112831209, 0.4880802533693379, 0.308325420190468], 0.00820799578142404, 1.428281008141393, 0.011723324489512627
07:31:34 done sampling a new configuration.
07:31:34 HBMASTER: schedule new run for iteration 8
07:31:34 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
07:31:34 HBMASTER: submitting job (8, 0, 15) to dispatcher
07:31:34 DISPATCHER: trying to submit job (8, 0, 15)
07:31:34 DISPATCHER: trying to notify the job_runner thread.
07:31:34 HBMASTER: job (8, 0, 15) submitted to dispatcher
07:31:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:31:34 DISPATCHER: Trying to submit another job.
07:31:34 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:31:34 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:31:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:31:34 WORKER: start processing job (8, 0, 15)
07:31:34 WORKER: args: ()
07:31:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 982, 'last_n_outputs': 17, 'leak_rate': 0.9568836869934682, 'lr': 0.03026300618807144, 'optimizer': 'SGD', 'sparsity': 0.7511747196270795, 'steps_to_train': 54, 'weight_decay': 0.025184922576848172}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:31:42 DISPATCHER: Starting worker discovery
07:31:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:42 DISPATCHER: Finished worker discovery
07:32:29 WORKER: done with job (8, 0, 15), trying to register it.
07:32:29 WORKER: registered result for job (8, 0, 15) with dispatcher
07:32:29 DISPATCHER: job (8, 0, 15) finished
07:32:29 DISPATCHER: register_result: lock acquired
07:32:29 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:32:29 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 982, 'last_n_outputs': 17, 'leak_rate': 0.9568836869934682, 'lr': 0.03026300618807144, 'optimizer': 'SGD', 'sparsity': 0.7511747196270795, 'steps_to_train': 54, 'weight_decay': 0.025184922576848172}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9089649201486232, 'info': {'number_mnist': 0.9089649201486232, 'config': "{'batch_size': 32, 'hidden_dim': 982, 'last_n_outputs': 17, 'leak_rate': 0.9568836869934682, 'lr': 0.03026300618807144, 'optimizer': 'SGD', 'sparsity': 0.7511747196270795, 'steps_to_train': 54, 'weight_decay': 0.025184922576848172}"}}
exception: None

07:32:29 job_callback for (8, 0, 15) started
07:32:29 DISPATCHER: Trying to submit another job.
07:32:29 job_callback for (8, 0, 15) got condition
07:32:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:32:29 HBMASTER: Trying to run another job!
07:32:29 job_callback for (8, 0, 15) finished
07:32:29 start sampling a new configuration.
07:32:29 best_vector: [0, 0.9078985229275784, 0.28025043714385717, 0.8474834579636707, 0.7823225411106672, 1, 0.0073847542975545855, 0.37796278278557377, 0.10382876905622979], 0.0015045701391811445, 3.673006815313292, 0.005526296375329212
07:32:29 done sampling a new configuration.
07:32:29 HBMASTER: schedule new run for iteration 8
07:32:29 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
07:32:29 HBMASTER: submitting job (8, 0, 16) to dispatcher
07:32:29 DISPATCHER: trying to submit job (8, 0, 16)
07:32:29 DISPATCHER: trying to notify the job_runner thread.
07:32:29 HBMASTER: job (8, 0, 16) submitted to dispatcher
07:32:29 DISPATCHER: Trying to submit another job.
07:32:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:32:29 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:32:29 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:32:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:32:29 WORKER: start processing job (8, 0, 16)
07:32:29 WORKER: args: ()
07:32:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 21, 'leak_rate': 0.9618708644909177, 'lr': 0.03669822695898837, 'optimizer': 'SGD', 'sparsity': 0.7517723410314131, 'steps_to_train': 44, 'weight_decay': 0.013648481736906049}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:32:42 DISPATCHER: Starting worker discovery
07:32:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:42 DISPATCHER: Finished worker discovery
07:33:23 WORKER: done with job (8, 0, 16), trying to register it.
07:33:23 WORKER: registered result for job (8, 0, 16) with dispatcher
07:33:23 DISPATCHER: job (8, 0, 16) finished
07:33:23 DISPATCHER: register_result: lock acquired
07:33:23 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:33:23 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 21, 'leak_rate': 0.9618708644909177, 'lr': 0.03669822695898837, 'optimizer': 'SGD', 'sparsity': 0.7517723410314131, 'steps_to_train': 44, 'weight_decay': 0.013648481736906049}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9433339679717001, 'info': {'number_mnist': 0.9433339679717001, 'config': "{'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 21, 'leak_rate': 0.9618708644909177, 'lr': 0.03669822695898837, 'optimizer': 'SGD', 'sparsity': 0.7517723410314131, 'steps_to_train': 44, 'weight_decay': 0.013648481736906049}"}}
exception: None

07:33:23 job_callback for (8, 0, 16) started
07:33:23 DISPATCHER: Trying to submit another job.
07:33:23 job_callback for (8, 0, 16) got condition
07:33:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:33:23 HBMASTER: Trying to run another job!
07:33:23 job_callback for (8, 0, 16) finished
07:33:23 start sampling a new configuration.
07:33:23 done sampling a new configuration.
07:33:23 HBMASTER: schedule new run for iteration 8
07:33:23 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
07:33:23 HBMASTER: submitting job (8, 0, 17) to dispatcher
07:33:23 DISPATCHER: trying to submit job (8, 0, 17)
07:33:23 DISPATCHER: trying to notify the job_runner thread.
07:33:23 HBMASTER: job (8, 0, 17) submitted to dispatcher
07:33:23 DISPATCHER: Trying to submit another job.
07:33:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:33:23 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:33:23 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:33:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:33:23 WORKER: start processing job (8, 0, 17)
07:33:23 WORKER: args: ()
07:33:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 668, 'last_n_outputs': 48, 'leak_rate': 0.8778019742593993, 'lr': 0.01059756754171507, 'optimizer': 'Adam', 'sparsity': 0.8438911376669925, 'steps_to_train': 42, 'weight_decay': 0.070739601941327}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:33:42 DISPATCHER: Starting worker discovery
07:33:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:42 DISPATCHER: Finished worker discovery
07:34:17 WORKER: done with job (8, 0, 17), trying to register it.
07:34:17 WORKER: registered result for job (8, 0, 17) with dispatcher
07:34:17 DISPATCHER: job (8, 0, 17) finished
07:34:17 DISPATCHER: register_result: lock acquired
07:34:17 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:34:17 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 668, 'last_n_outputs': 48, 'leak_rate': 0.8778019742593993, 'lr': 0.01059756754171507, 'optimizer': 'Adam', 'sparsity': 0.8438911376669925, 'steps_to_train': 42, 'weight_decay': 0.070739601941327}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40415817727429965, 'info': {'number_mnist': 0.40415817727429965, 'config': "{'batch_size': 16, 'hidden_dim': 668, 'last_n_outputs': 48, 'leak_rate': 0.8778019742593993, 'lr': 0.01059756754171507, 'optimizer': 'Adam', 'sparsity': 0.8438911376669925, 'steps_to_train': 42, 'weight_decay': 0.070739601941327}"}}
exception: None

07:34:17 job_callback for (8, 0, 17) started
07:34:17 DISPATCHER: Trying to submit another job.
07:34:17 job_callback for (8, 0, 17) got condition
07:34:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:34:17 HBMASTER: Trying to run another job!
07:34:17 job_callback for (8, 0, 17) finished
07:34:17 start sampling a new configuration.
07:34:17 done sampling a new configuration.
07:34:17 HBMASTER: schedule new run for iteration 8
07:34:17 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
07:34:17 HBMASTER: submitting job (8, 0, 18) to dispatcher
07:34:17 DISPATCHER: trying to submit job (8, 0, 18)
07:34:17 DISPATCHER: trying to notify the job_runner thread.
07:34:17 HBMASTER: job (8, 0, 18) submitted to dispatcher
07:34:17 DISPATCHER: Trying to submit another job.
07:34:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:34:17 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:34:17 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:34:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:34:17 WORKER: start processing job (8, 0, 18)
07:34:17 WORKER: args: ()
07:34:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 451, 'last_n_outputs': 40, 'leak_rate': 0.757776766941443, 'lr': 0.014695732165762976, 'optimizer': 'Adam', 'sparsity': 0.9766778941690759, 'steps_to_train': 42, 'weight_decay': 0.13075130680079367}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:34:42 DISPATCHER: Starting worker discovery
07:34:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:42 DISPATCHER: Finished worker discovery
07:35:10 WORKER: done with job (8, 0, 18), trying to register it.
07:35:10 WORKER: registered result for job (8, 0, 18) with dispatcher
07:35:10 DISPATCHER: job (8, 0, 18) finished
07:35:10 DISPATCHER: register_result: lock acquired
07:35:10 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:35:10 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 451, 'last_n_outputs': 40, 'leak_rate': 0.757776766941443, 'lr': 0.014695732165762976, 'optimizer': 'Adam', 'sparsity': 0.9766778941690759, 'steps_to_train': 42, 'weight_decay': 0.13075130680079367}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2043524364783327, 'info': {'number_mnist': 0.2043524364783327, 'config': "{'batch_size': 128, 'hidden_dim': 451, 'last_n_outputs': 40, 'leak_rate': 0.757776766941443, 'lr': 0.014695732165762976, 'optimizer': 'Adam', 'sparsity': 0.9766778941690759, 'steps_to_train': 42, 'weight_decay': 0.13075130680079367}"}}
exception: None

07:35:10 job_callback for (8, 0, 18) started
07:35:10 DISPATCHER: Trying to submit another job.
07:35:10 job_callback for (8, 0, 18) got condition
07:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:35:10 HBMASTER: Trying to run another job!
07:35:10 job_callback for (8, 0, 18) finished
07:35:10 start sampling a new configuration.
07:35:11 best_vector: [3, 0.929457082246773, 0.5193835063458251, 0.10412983348014071, 0.2184870996291225, 1, 0.9182320446264741, 0.07788560704438618, 0.037978069978905196], 0.005750141836080362, 0.2835435415905171, 0.0016304155808500244
07:35:11 done sampling a new configuration.
07:35:11 HBMASTER: schedule new run for iteration 8
07:35:11 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
07:35:11 HBMASTER: submitting job (8, 0, 19) to dispatcher
07:35:11 DISPATCHER: trying to submit job (8, 0, 19)
07:35:11 DISPATCHER: trying to notify the job_runner thread.
07:35:11 HBMASTER: job (8, 0, 19) submitted to dispatcher
07:35:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:35:11 DISPATCHER: Trying to submit another job.
07:35:11 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:35:11 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:35:11 WORKER: start processing job (8, 0, 19)
07:35:11 WORKER: args: ()
07:35:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 944, 'last_n_outputs': 31, 'leak_rate': 0.7760324583700352, 'lr': 0.002735106233185717, 'optimizer': 'SGD', 'sparsity': 0.9703756907103538, 'steps_to_train': 17, 'weight_decay': 0.011204967681064574}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:35:42 DISPATCHER: Starting worker discovery
07:35:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:42 DISPATCHER: Finished worker discovery
07:36:06 WORKER: done with job (8, 0, 19), trying to register it.
07:36:06 WORKER: registered result for job (8, 0, 19) with dispatcher
07:36:06 DISPATCHER: job (8, 0, 19) finished
07:36:06 DISPATCHER: register_result: lock acquired
07:36:06 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:36:06 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 944, 'last_n_outputs': 31, 'leak_rate': 0.7760324583700352, 'lr': 0.002735106233185717, 'optimizer': 'SGD', 'sparsity': 0.9703756907103538, 'steps_to_train': 17, 'weight_decay': 0.011204967681064574}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8990697969279814, 'info': {'number_mnist': 0.8990697969279814, 'config': "{'batch_size': 128, 'hidden_dim': 944, 'last_n_outputs': 31, 'leak_rate': 0.7760324583700352, 'lr': 0.002735106233185717, 'optimizer': 'SGD', 'sparsity': 0.9703756907103538, 'steps_to_train': 17, 'weight_decay': 0.011204967681064574}"}}
exception: None

07:36:06 job_callback for (8, 0, 19) started
07:36:06 job_callback for (8, 0, 19) got condition
07:36:06 DISPATCHER: Trying to submit another job.
07:36:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:06 HBMASTER: Trying to run another job!
07:36:06 job_callback for (8, 0, 19) finished
07:36:06 start sampling a new configuration.
07:36:06 best_vector: [0, 0.9796574390687115, 0.04598582396179404, 0.9744346843023806, 0.645343694802246, 1, 0.02050166675000975, 0.04379815077363103, 0.34898071843074524], 0.0011435639966794091, 0.15240978244054731, 0.0001742903399407515
07:36:06 done sampling a new configuration.
07:36:06 HBMASTER: schedule new run for iteration 8
07:36:06 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
07:36:06 HBMASTER: submitting job (8, 0, 20) to dispatcher
07:36:06 DISPATCHER: trying to submit job (8, 0, 20)
07:36:06 DISPATCHER: trying to notify the job_runner thread.
07:36:06 HBMASTER: job (8, 0, 20) submitted to dispatcher
07:36:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:06 DISPATCHER: Trying to submit another job.
07:36:06 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:36:06 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:36:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:06 WORKER: start processing job (8, 0, 20)
07:36:06 WORKER: args: ()
07:36:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 984, 'last_n_outputs': 11, 'leak_rate': 0.9936086710755951, 'lr': 0.019529332048903784, 'optimizer': 'SGD', 'sparsity': 0.7549204000200024, 'steps_to_train': 13, 'weight_decay': 0.028446863090250924}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:36:42 DISPATCHER: Starting worker discovery
07:36:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:42 DISPATCHER: Finished worker discovery
07:37:02 WORKER: done with job (8, 0, 20), trying to register it.
07:37:02 WORKER: registered result for job (8, 0, 20) with dispatcher
07:37:02 DISPATCHER: job (8, 0, 20) finished
07:37:02 DISPATCHER: register_result: lock acquired
07:37:02 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:37:02 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 984, 'last_n_outputs': 11, 'leak_rate': 0.9936086710755951, 'lr': 0.019529332048903784, 'optimizer': 'SGD', 'sparsity': 0.7549204000200024, 'steps_to_train': 13, 'weight_decay': 0.028446863090250924}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.846878318235271, 'info': {'number_mnist': 0.846878318235271, 'config': "{'batch_size': 16, 'hidden_dim': 984, 'last_n_outputs': 11, 'leak_rate': 0.9936086710755951, 'lr': 0.019529332048903784, 'optimizer': 'SGD', 'sparsity': 0.7549204000200024, 'steps_to_train': 13, 'weight_decay': 0.028446863090250924}"}}
exception: None

07:37:02 job_callback for (8, 0, 20) started
07:37:02 DISPATCHER: Trying to submit another job.
07:37:02 job_callback for (8, 0, 20) got condition
07:37:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:37:02 HBMASTER: Trying to run another job!
07:37:02 job_callback for (8, 0, 20) finished
07:37:02 start sampling a new configuration.
07:37:02 best_vector: [0, 0.6671985762933548, 0.19877167554391523, 0.01478102774596407, 0.29041235117428194, 1, 0.9911182748139701, 0.014251765270997474, 0.13550286084146013], 0.007331544672852399, 0.060980476769802484, 0.0004470810896096449
07:37:02 done sampling a new configuration.
07:37:02 HBMASTER: schedule new run for iteration 8
07:37:02 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
07:37:02 HBMASTER: submitting job (8, 0, 21) to dispatcher
07:37:02 DISPATCHER: trying to submit job (8, 0, 21)
07:37:02 DISPATCHER: trying to notify the job_runner thread.
07:37:02 HBMASTER: job (8, 0, 21) submitted to dispatcher
07:37:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:37:02 DISPATCHER: Trying to submit another job.
07:37:02 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:37:02 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:37:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:37:02 WORKER: start processing job (8, 0, 21)
07:37:02 WORKER: args: ()
07:37:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 734, 'last_n_outputs': 18, 'leak_rate': 0.753695256936491, 'lr': 0.003809120418768757, 'optimizer': 'SGD', 'sparsity': 0.9878683859553528, 'steps_to_train': 11, 'weight_decay': 0.015006979402334131}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:37:42 DISPATCHER: Starting worker discovery
07:37:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:42 DISPATCHER: Finished worker discovery
07:37:58 WORKER: done with job (8, 0, 21), trying to register it.
07:37:58 WORKER: registered result for job (8, 0, 21) with dispatcher
07:37:58 DISPATCHER: job (8, 0, 21) finished
07:37:58 DISPATCHER: register_result: lock acquired
07:37:58 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:37:58 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 734, 'last_n_outputs': 18, 'leak_rate': 0.753695256936491, 'lr': 0.003809120418768757, 'optimizer': 'SGD', 'sparsity': 0.9878683859553528, 'steps_to_train': 11, 'weight_decay': 0.015006979402334131}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8964136649701384, 'info': {'number_mnist': 0.8964136649701384, 'config': "{'batch_size': 16, 'hidden_dim': 734, 'last_n_outputs': 18, 'leak_rate': 0.753695256936491, 'lr': 0.003809120418768757, 'optimizer': 'SGD', 'sparsity': 0.9878683859553528, 'steps_to_train': 11, 'weight_decay': 0.015006979402334131}"}}
exception: None

07:37:58 job_callback for (8, 0, 21) started
07:37:58 DISPATCHER: Trying to submit another job.
07:37:58 job_callback for (8, 0, 21) got condition
07:37:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:37:58 HBMASTER: Trying to run another job!
07:37:58 job_callback for (8, 0, 21) finished
07:37:58 start sampling a new configuration.
07:37:58 done sampling a new configuration.
07:37:58 HBMASTER: schedule new run for iteration 8
07:37:58 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
07:37:58 HBMASTER: submitting job (8, 0, 22) to dispatcher
07:37:58 DISPATCHER: trying to submit job (8, 0, 22)
07:37:58 DISPATCHER: trying to notify the job_runner thread.
07:37:58 HBMASTER: job (8, 0, 22) submitted to dispatcher
07:37:58 DISPATCHER: Trying to submit another job.
07:37:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:37:58 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:37:58 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:37:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:37:58 WORKER: start processing job (8, 0, 22)
07:37:58 WORKER: args: ()
07:37:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 389, 'last_n_outputs': 34, 'leak_rate': 0.8128087296617248, 'lr': 0.010633900509282406, 'optimizer': 'SGD', 'sparsity': 0.9874168317113573, 'steps_to_train': 60, 'weight_decay': 0.06348233590381025}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:38:42 DISPATCHER: Starting worker discovery
07:38:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:42 DISPATCHER: Finished worker discovery
07:38:52 WORKER: done with job (8, 0, 22), trying to register it.
07:38:52 WORKER: registered result for job (8, 0, 22) with dispatcher
07:38:52 DISPATCHER: job (8, 0, 22) finished
07:38:52 DISPATCHER: register_result: lock acquired
07:38:52 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:38:52 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 389, 'last_n_outputs': 34, 'leak_rate': 0.8128087296617248, 'lr': 0.010633900509282406, 'optimizer': 'SGD', 'sparsity': 0.9874168317113573, 'steps_to_train': 60, 'weight_decay': 0.06348233590381025}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9044102279341932, 'info': {'number_mnist': 0.9044102279341932, 'config': "{'batch_size': 128, 'hidden_dim': 389, 'last_n_outputs': 34, 'leak_rate': 0.8128087296617248, 'lr': 0.010633900509282406, 'optimizer': 'SGD', 'sparsity': 0.9874168317113573, 'steps_to_train': 60, 'weight_decay': 0.06348233590381025}"}}
exception: None

07:38:52 job_callback for (8, 0, 22) started
07:38:52 DISPATCHER: Trying to submit another job.
07:38:52 job_callback for (8, 0, 22) got condition
07:38:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:52 HBMASTER: Trying to run another job!
07:38:52 job_callback for (8, 0, 22) finished
07:38:52 start sampling a new configuration.
07:38:52 best_vector: [2, 0.6630158882129342, 0.24156322040145342, 0.044873002254932515, 0.9175544461743708, 1, 0.42959697829138993, 0.15097884639289533, 0.021143912292091088], 0.004373136088939374, 0.10216749150032949, 0.00044679234419649764
07:38:52 done sampling a new configuration.
07:38:52 HBMASTER: schedule new run for iteration 8
07:38:52 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
07:38:52 HBMASTER: submitting job (8, 0, 23) to dispatcher
07:38:52 DISPATCHER: trying to submit job (8, 0, 23)
07:38:52 DISPATCHER: trying to notify the job_runner thread.
07:38:52 HBMASTER: job (8, 0, 23) submitted to dispatcher
07:38:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:52 DISPATCHER: Trying to submit another job.
07:38:52 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:38:52 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:38:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:52 WORKER: start processing job (8, 0, 23)
07:38:52 WORKER: args: ()
07:38:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 731, 'last_n_outputs': 19, 'leak_rate': 0.7612182505637332, 'lr': 0.06840831486149927, 'optimizer': 'SGD', 'sparsity': 0.8531032747899336, 'steps_to_train': 23, 'weight_decay': 0.010653906084784413}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:39:42 DISPATCHER: Starting worker discovery
07:39:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:42 DISPATCHER: Finished worker discovery
07:39:47 WORKER: done with job (8, 0, 23), trying to register it.
07:39:47 WORKER: registered result for job (8, 0, 23) with dispatcher
07:39:47 DISPATCHER: job (8, 0, 23) finished
07:39:47 DISPATCHER: register_result: lock acquired
07:39:47 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:39:47 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 731, 'last_n_outputs': 19, 'leak_rate': 0.7612182505637332, 'lr': 0.06840831486149927, 'optimizer': 'SGD', 'sparsity': 0.8531032747899336, 'steps_to_train': 23, 'weight_decay': 0.010653906084784413}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9351443217255138, 'info': {'number_mnist': 0.9351443217255138, 'config': "{'batch_size': 64, 'hidden_dim': 731, 'last_n_outputs': 19, 'leak_rate': 0.7612182505637332, 'lr': 0.06840831486149927, 'optimizer': 'SGD', 'sparsity': 0.8531032747899336, 'steps_to_train': 23, 'weight_decay': 0.010653906084784413}"}}
exception: None

07:39:47 job_callback for (8, 0, 23) started
07:39:47 job_callback for (8, 0, 23) got condition
07:39:47 DISPATCHER: Trying to submit another job.
07:39:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:39:47 HBMASTER: Trying to run another job!
07:39:47 job_callback for (8, 0, 23) finished
07:39:47 start sampling a new configuration.
07:39:47 done sampling a new configuration.
07:39:47 HBMASTER: schedule new run for iteration 8
07:39:47 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
07:39:47 HBMASTER: submitting job (8, 0, 24) to dispatcher
07:39:47 DISPATCHER: trying to submit job (8, 0, 24)
07:39:47 DISPATCHER: trying to notify the job_runner thread.
07:39:47 HBMASTER: job (8, 0, 24) submitted to dispatcher
07:39:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:39:47 DISPATCHER: Trying to submit another job.
07:39:47 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:39:47 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:39:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:39:47 WORKER: start processing job (8, 0, 24)
07:39:47 WORKER: args: ()
07:39:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 851, 'last_n_outputs': 31, 'leak_rate': 0.7636967110679888, 'lr': 0.004721490774237749, 'optimizer': 'Adam', 'sparsity': 0.9013737262447641, 'steps_to_train': 83, 'weight_decay': 0.03833946386946682}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:40:40 WORKER: done with job (8, 0, 24), trying to register it.
07:40:40 WORKER: registered result for job (8, 0, 24) with dispatcher
07:40:40 DISPATCHER: job (8, 0, 24) finished
07:40:40 DISPATCHER: register_result: lock acquired
07:40:40 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:40:40 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 851, 'last_n_outputs': 31, 'leak_rate': 0.7636967110679888, 'lr': 0.004721490774237749, 'optimizer': 'Adam', 'sparsity': 0.9013737262447641, 'steps_to_train': 83, 'weight_decay': 0.03833946386946682}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37671342692499643, 'info': {'number_mnist': 0.37671342692499643, 'config': "{'batch_size': 16, 'hidden_dim': 851, 'last_n_outputs': 31, 'leak_rate': 0.7636967110679888, 'lr': 0.004721490774237749, 'optimizer': 'Adam', 'sparsity': 0.9013737262447641, 'steps_to_train': 83, 'weight_decay': 0.03833946386946682}"}}
exception: None

07:40:40 job_callback for (8, 0, 24) started
07:40:40 job_callback for (8, 0, 24) got condition
07:40:40 DISPATCHER: Trying to submit another job.
07:40:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:40:40 HBMASTER: Trying to run another job!
07:40:40 job_callback for (8, 0, 24) finished
07:40:40 start sampling a new configuration.
07:40:40 best_vector: [2, 0.8289414267714419, 0.05966801941863298, 0.3951075126639174, 0.5864569631538992, 1, 0.361840441381731, 0.08339657297416342, 0.15743258808600963], 0.004548656284058412, 2.580392617529503, 0.011737319095063507
07:40:40 done sampling a new configuration.
07:40:40 HBMASTER: schedule new run for iteration 8
07:40:40 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:40:40 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:40:40 DISPATCHER: trying to submit job (8, 0, 25)
07:40:40 DISPATCHER: trying to notify the job_runner thread.
07:40:40 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:40:40 DISPATCHER: Trying to submit another job.
07:40:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:40:40 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:40:40 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:40:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:40:40 WORKER: start processing job (8, 0, 25)
07:40:40 WORKER: args: ()
07:40:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 863, 'last_n_outputs': 12, 'leak_rate': 0.8487768781659794, 'lr': 0.014890659275085349, 'optimizer': 'SGD', 'sparsity': 0.8368417059316154, 'steps_to_train': 17, 'weight_decay': 0.016025977157782794}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:40:42 DISPATCHER: Starting worker discovery
07:40:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:42 DISPATCHER: Finished worker discovery
07:41:34 WORKER: done with job (8, 0, 25), trying to register it.
07:41:34 WORKER: registered result for job (8, 0, 25) with dispatcher
07:41:34 DISPATCHER: job (8, 0, 25) finished
07:41:34 DISPATCHER: register_result: lock acquired
07:41:34 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:41:34 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 863, 'last_n_outputs': 12, 'leak_rate': 0.8487768781659794, 'lr': 0.014890659275085349, 'optimizer': 'SGD', 'sparsity': 0.8368417059316154, 'steps_to_train': 17, 'weight_decay': 0.016025977157782794}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9061412602985002, 'info': {'number_mnist': 0.9061412602985002, 'config': "{'batch_size': 64, 'hidden_dim': 863, 'last_n_outputs': 12, 'leak_rate': 0.8487768781659794, 'lr': 0.014890659275085349, 'optimizer': 'SGD', 'sparsity': 0.8368417059316154, 'steps_to_train': 17, 'weight_decay': 0.016025977157782794}"}}
exception: None

07:41:34 job_callback for (8, 0, 25) started
07:41:34 DISPATCHER: Trying to submit another job.
07:41:34 job_callback for (8, 0, 25) got condition
07:41:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:41:34 HBMASTER: Trying to run another job!
07:41:34 job_callback for (8, 0, 25) finished
07:41:34 start sampling a new configuration.
07:41:35 best_vector: [3, 0.8707077348751933, 0.4027260210571514, 0.03895452156087219, 0.40943721488428114, 1, 0.8855012841502217, 0.41220544878861665, 0.30827430232040154], 0.0008941571216061176, 10.05614205681721, 0.008991771035985899
07:41:35 done sampling a new configuration.
07:41:35 HBMASTER: schedule new run for iteration 8
07:41:35 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
07:41:35 HBMASTER: submitting job (8, 0, 26) to dispatcher
07:41:35 DISPATCHER: trying to submit job (8, 0, 26)
07:41:35 DISPATCHER: trying to notify the job_runner thread.
07:41:35 HBMASTER: job (8, 0, 26) submitted to dispatcher
07:41:35 DISPATCHER: Trying to submit another job.
07:41:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:41:35 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:41:35 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:41:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:41:35 WORKER: start processing job (8, 0, 26)
07:41:35 WORKER: args: ()
07:41:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 897, 'last_n_outputs': 26, 'leak_rate': 0.759738630390218, 'lr': 0.006589833317973808, 'optimizer': 'SGD', 'sparsity': 0.9625203081960532, 'steps_to_train': 47, 'weight_decay': 0.025181066167601757}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:41:42 DISPATCHER: Starting worker discovery
07:41:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:42 DISPATCHER: Finished worker discovery
07:42:29 WORKER: done with job (8, 0, 26), trying to register it.
07:42:29 WORKER: registered result for job (8, 0, 26) with dispatcher
07:42:29 DISPATCHER: job (8, 0, 26) finished
07:42:29 DISPATCHER: register_result: lock acquired
07:42:29 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:42:29 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 897, 'last_n_outputs': 26, 'leak_rate': 0.759738630390218, 'lr': 0.006589833317973808, 'optimizer': 'SGD', 'sparsity': 0.9625203081960532, 'steps_to_train': 47, 'weight_decay': 0.025181066167601757}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9167190964501559, 'info': {'number_mnist': 0.9167190964501559, 'config': "{'batch_size': 128, 'hidden_dim': 897, 'last_n_outputs': 26, 'leak_rate': 0.759738630390218, 'lr': 0.006589833317973808, 'optimizer': 'SGD', 'sparsity': 0.9625203081960532, 'steps_to_train': 47, 'weight_decay': 0.025181066167601757}"}}
exception: None

07:42:29 job_callback for (8, 0, 26) started
07:42:29 DISPATCHER: Trying to submit another job.
07:42:29 job_callback for (8, 0, 26) got condition
07:42:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:42:29 HBMASTER: Trying to run another job!
07:42:29 job_callback for (8, 0, 26) finished
07:42:29 ITERATION: Advancing config (8, 0, 3) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
07:42:29 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
07:42:29 HBMASTER: schedule new run for iteration 8
07:42:29 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
07:42:29 HBMASTER: submitting job (8, 0, 3) to dispatcher
07:42:29 DISPATCHER: trying to submit job (8, 0, 3)
07:42:29 DISPATCHER: trying to notify the job_runner thread.
07:42:29 HBMASTER: job (8, 0, 3) submitted to dispatcher
07:42:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:42:29 DISPATCHER: Trying to submit another job.
07:42:29 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:42:29 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:42:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:42:29 WORKER: start processing job (8, 0, 3)
07:42:29 WORKER: args: ()
07:42:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:42:42 DISPATCHER: Starting worker discovery
07:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:42 DISPATCHER: Finished worker discovery
07:43:42 DISPATCHER: Starting worker discovery
07:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:42 DISPATCHER: Finished worker discovery
07:44:42 DISPATCHER: Starting worker discovery
07:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:42 DISPATCHER: Finished worker discovery
07:44:54 WORKER: done with job (8, 0, 3), trying to register it.
07:44:54 WORKER: registered result for job (8, 0, 3) with dispatcher
07:44:54 DISPATCHER: job (8, 0, 3) finished
07:44:54 DISPATCHER: register_result: lock acquired
07:44:54 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:44:54 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9509596942727808, 'info': {'number_mnist': 0.9509596942727808, 'config': "{'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}"}}
exception: None

07:44:54 job_callback for (8, 0, 3) started
07:44:54 DISPATCHER: Trying to submit another job.
07:44:54 job_callback for (8, 0, 3) got condition
07:44:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:44:54 HBMASTER: Trying to run another job!
07:44:54 job_callback for (8, 0, 3) finished
07:44:54 HBMASTER: schedule new run for iteration 8
07:44:54 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:44:54 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:44:54 DISPATCHER: trying to submit job (8, 0, 8)
07:44:54 DISPATCHER: trying to notify the job_runner thread.
07:44:54 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:44:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:44:54 DISPATCHER: Trying to submit another job.
07:44:54 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:44:54 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:44:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:44:54 WORKER: start processing job (8, 0, 8)
07:44:54 WORKER: args: ()
07:44:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:45:42 DISPATCHER: Starting worker discovery
07:45:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:42 DISPATCHER: Finished worker discovery
07:46:42 DISPATCHER: Starting worker discovery
07:46:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:42 DISPATCHER: Finished worker discovery
07:47:17 WORKER: done with job (8, 0, 8), trying to register it.
07:47:17 WORKER: registered result for job (8, 0, 8) with dispatcher
07:47:17 DISPATCHER: job (8, 0, 8) finished
07:47:17 DISPATCHER: register_result: lock acquired
07:47:17 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:47:17 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9504578620266986, 'info': {'number_mnist': 0.9504578620266986, 'config': "{'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}"}}
exception: None

07:47:17 job_callback for (8, 0, 8) started
07:47:17 DISPATCHER: Trying to submit another job.
07:47:17 job_callback for (8, 0, 8) got condition
07:47:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:47:17 HBMASTER: Trying to run another job!
07:47:17 job_callback for (8, 0, 8) finished
07:47:17 HBMASTER: schedule new run for iteration 8
07:47:17 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
07:47:17 HBMASTER: submitting job (8, 0, 10) to dispatcher
07:47:17 DISPATCHER: trying to submit job (8, 0, 10)
07:47:17 DISPATCHER: trying to notify the job_runner thread.
07:47:17 HBMASTER: job (8, 0, 10) submitted to dispatcher
07:47:17 DISPATCHER: Trying to submit another job.
07:47:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:47:17 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:47:17 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:47:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:47:17 WORKER: start processing job (8, 0, 10)
07:47:17 WORKER: args: ()
07:47:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 18, 'leak_rate': 0.9915256605733324, 'lr': 0.03367939993964732, 'optimizer': 'SGD', 'sparsity': 0.767955061872763, 'steps_to_train': 61, 'weight_decay': 0.011122486213022233}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:47:42 DISPATCHER: Starting worker discovery
07:47:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:42 DISPATCHER: Finished worker discovery
07:48:42 DISPATCHER: Starting worker discovery
07:48:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:42 DISPATCHER: Finished worker discovery
07:49:42 WORKER: done with job (8, 0, 10), trying to register it.
07:49:42 WORKER: registered result for job (8, 0, 10) with dispatcher
07:49:42 DISPATCHER: job (8, 0, 10) finished
07:49:42 DISPATCHER: register_result: lock acquired
07:49:42 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:49:42 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 18, 'leak_rate': 0.9915256605733324, 'lr': 0.03367939993964732, 'optimizer': 'SGD', 'sparsity': 0.767955061872763, 'steps_to_train': 61, 'weight_decay': 0.011122486213022233}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9493488199039075, 'info': {'number_mnist': 0.9493488199039075, 'config': "{'batch_size': 128, 'hidden_dim': 962, 'last_n_outputs': 18, 'leak_rate': 0.9915256605733324, 'lr': 0.03367939993964732, 'optimizer': 'SGD', 'sparsity': 0.767955061872763, 'steps_to_train': 61, 'weight_decay': 0.011122486213022233}"}}
exception: None

07:49:42 job_callback for (8, 0, 10) started
07:49:42 job_callback for (8, 0, 10) got condition
07:49:42 DISPATCHER: Trying to submit another job.
07:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:49:42 HBMASTER: Trying to run another job!
07:49:42 job_callback for (8, 0, 10) finished
07:49:42 HBMASTER: schedule new run for iteration 8
07:49:42 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
07:49:42 HBMASTER: submitting job (8, 0, 11) to dispatcher
07:49:42 DISPATCHER: trying to submit job (8, 0, 11)
07:49:42 DISPATCHER: trying to notify the job_runner thread.
07:49:42 HBMASTER: job (8, 0, 11) submitted to dispatcher
07:49:42 DISPATCHER: Trying to submit another job.
07:49:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:49:42 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:49:42 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:49:42 WORKER: start processing job (8, 0, 11)
07:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:49:42 WORKER: args: ()
07:49:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 844, 'last_n_outputs': 15, 'leak_rate': 0.761628581801177, 'lr': 0.02014313178296849, 'optimizer': 'SGD', 'sparsity': 0.9614061707437516, 'steps_to_train': 32, 'weight_decay': 0.024863266899436874}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:49:42 DISPATCHER: Starting worker discovery
07:49:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:42 DISPATCHER: Finished worker discovery
07:50:42 DISPATCHER: Starting worker discovery
07:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:42 DISPATCHER: Finished worker discovery
07:51:42 DISPATCHER: Starting worker discovery
07:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:42 DISPATCHER: Finished worker discovery
07:52:07 WORKER: done with job (8, 0, 11), trying to register it.
07:52:07 WORKER: registered result for job (8, 0, 11) with dispatcher
07:52:07 DISPATCHER: job (8, 0, 11) finished
07:52:07 DISPATCHER: register_result: lock acquired
07:52:07 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:52:07 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 844, 'last_n_outputs': 15, 'leak_rate': 0.761628581801177, 'lr': 0.02014313178296849, 'optimizer': 'SGD', 'sparsity': 0.9614061707437516, 'steps_to_train': 32, 'weight_decay': 0.024863266899436874}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9365881872951217, 'info': {'number_mnist': 0.9365881872951217, 'config': "{'batch_size': 32, 'hidden_dim': 844, 'last_n_outputs': 15, 'leak_rate': 0.761628581801177, 'lr': 0.02014313178296849, 'optimizer': 'SGD', 'sparsity': 0.9614061707437516, 'steps_to_train': 32, 'weight_decay': 0.024863266899436874}"}}
exception: None

07:52:07 job_callback for (8, 0, 11) started
07:52:07 DISPATCHER: Trying to submit another job.
07:52:07 job_callback for (8, 0, 11) got condition
07:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:52:07 HBMASTER: Trying to run another job!
07:52:07 job_callback for (8, 0, 11) finished
07:52:07 HBMASTER: schedule new run for iteration 8
07:52:07 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
07:52:07 HBMASTER: submitting job (8, 0, 13) to dispatcher
07:52:07 DISPATCHER: trying to submit job (8, 0, 13)
07:52:07 DISPATCHER: trying to notify the job_runner thread.
07:52:07 HBMASTER: job (8, 0, 13) submitted to dispatcher
07:52:07 DISPATCHER: Trying to submit another job.
07:52:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:52:07 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:52:07 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:52:07 WORKER: start processing job (8, 0, 13)
07:52:07 WORKER: args: ()
07:52:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 979, 'last_n_outputs': 36, 'leak_rate': 0.908743878005883, 'lr': 0.005877882320877374, 'optimizer': 'SGD', 'sparsity': 0.7658414617115072, 'steps_to_train': 93, 'weight_decay': 0.021346406122391658}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:52:42 DISPATCHER: Starting worker discovery
07:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:42 DISPATCHER: Finished worker discovery
07:53:42 DISPATCHER: Starting worker discovery
07:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:42 DISPATCHER: Finished worker discovery
07:54:30 WORKER: done with job (8, 0, 13), trying to register it.
07:54:30 WORKER: registered result for job (8, 0, 13) with dispatcher
07:54:30 DISPATCHER: job (8, 0, 13) finished
07:54:30 DISPATCHER: register_result: lock acquired
07:54:30 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:54:30 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 979, 'last_n_outputs': 36, 'leak_rate': 0.908743878005883, 'lr': 0.005877882320877374, 'optimizer': 'SGD', 'sparsity': 0.7658414617115072, 'steps_to_train': 93, 'weight_decay': 0.021346406122391658}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9371021438192205, 'info': {'number_mnist': 0.9371021438192205, 'config': "{'batch_size': 64, 'hidden_dim': 979, 'last_n_outputs': 36, 'leak_rate': 0.908743878005883, 'lr': 0.005877882320877374, 'optimizer': 'SGD', 'sparsity': 0.7658414617115072, 'steps_to_train': 93, 'weight_decay': 0.021346406122391658}"}}
exception: None

07:54:30 job_callback for (8, 0, 13) started
07:54:30 DISPATCHER: Trying to submit another job.
07:54:30 job_callback for (8, 0, 13) got condition
07:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:54:30 HBMASTER: Trying to run another job!
07:54:30 job_callback for (8, 0, 13) finished
07:54:30 HBMASTER: schedule new run for iteration 8
07:54:30 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:54:30 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:54:30 DISPATCHER: trying to submit job (8, 0, 14)
07:54:30 DISPATCHER: trying to notify the job_runner thread.
07:54:30 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:54:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:54:30 DISPATCHER: Trying to submit another job.
07:54:30 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:54:30 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:54:30 WORKER: start processing job (8, 0, 14)
07:54:30 WORKER: args: ()
07:54:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:54:42 DISPATCHER: Starting worker discovery
07:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:42 DISPATCHER: Finished worker discovery
07:55:42 DISPATCHER: Starting worker discovery
07:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:42 DISPATCHER: Finished worker discovery
07:56:42 DISPATCHER: Starting worker discovery
07:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:42 DISPATCHER: Finished worker discovery
07:56:56 WORKER: done with job (8, 0, 14), trying to register it.
07:56:56 WORKER: registered result for job (8, 0, 14) with dispatcher
07:56:56 DISPATCHER: job (8, 0, 14) finished
07:56:56 DISPATCHER: register_result: lock acquired
07:56:56 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:56:56 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9496737205766582, 'info': {'number_mnist': 0.9496737205766582, 'config': "{'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}"}}
exception: None

07:56:56 job_callback for (8, 0, 14) started
07:56:56 DISPATCHER: Trying to submit another job.
07:56:56 job_callback for (8, 0, 14) got condition
07:56:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:56:56 HBMASTER: Trying to run another job!
07:56:56 job_callback for (8, 0, 14) finished
07:56:56 HBMASTER: schedule new run for iteration 8
07:56:56 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
07:56:56 HBMASTER: submitting job (8, 0, 16) to dispatcher
07:56:56 DISPATCHER: trying to submit job (8, 0, 16)
07:56:56 DISPATCHER: trying to notify the job_runner thread.
07:56:56 HBMASTER: job (8, 0, 16) submitted to dispatcher
07:56:56 DISPATCHER: Trying to submit another job.
07:56:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:56:56 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:56:56 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:56:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:56:56 WORKER: start processing job (8, 0, 16)
07:56:56 WORKER: args: ()
07:56:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 21, 'leak_rate': 0.9618708644909177, 'lr': 0.03669822695898837, 'optimizer': 'SGD', 'sparsity': 0.7517723410314131, 'steps_to_train': 44, 'weight_decay': 0.013648481736906049}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:57:42 DISPATCHER: Starting worker discovery
07:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:42 DISPATCHER: Finished worker discovery
07:58:42 DISPATCHER: Starting worker discovery
07:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:42 DISPATCHER: Finished worker discovery
07:59:20 WORKER: done with job (8, 0, 16), trying to register it.
07:59:20 WORKER: registered result for job (8, 0, 16) with dispatcher
07:59:20 DISPATCHER: job (8, 0, 16) finished
07:59:20 DISPATCHER: register_result: lock acquired
07:59:20 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:59:20 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 21, 'leak_rate': 0.9618708644909177, 'lr': 0.03669822695898837, 'optimizer': 'SGD', 'sparsity': 0.7517723410314131, 'steps_to_train': 44, 'weight_decay': 0.013648481736906049}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9491397831193431, 'info': {'number_mnist': 0.9491397831193431, 'config': "{'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 21, 'leak_rate': 0.9618708644909177, 'lr': 0.03669822695898837, 'optimizer': 'SGD', 'sparsity': 0.7517723410314131, 'steps_to_train': 44, 'weight_decay': 0.013648481736906049}"}}
exception: None

07:59:20 job_callback for (8, 0, 16) started
07:59:20 DISPATCHER: Trying to submit another job.
07:59:20 job_callback for (8, 0, 16) got condition
07:59:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:59:20 HBMASTER: Trying to run another job!
07:59:20 job_callback for (8, 0, 16) finished
07:59:20 HBMASTER: schedule new run for iteration 8
07:59:20 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
07:59:20 HBMASTER: submitting job (8, 0, 23) to dispatcher
07:59:20 DISPATCHER: trying to submit job (8, 0, 23)
07:59:20 DISPATCHER: trying to notify the job_runner thread.
07:59:20 HBMASTER: job (8, 0, 23) submitted to dispatcher
07:59:20 DISPATCHER: Trying to submit another job.
07:59:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:59:20 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:59:20 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:59:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:59:20 WORKER: start processing job (8, 0, 23)
07:59:20 WORKER: args: ()
07:59:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 731, 'last_n_outputs': 19, 'leak_rate': 0.7612182505637332, 'lr': 0.06840831486149927, 'optimizer': 'SGD', 'sparsity': 0.8531032747899336, 'steps_to_train': 23, 'weight_decay': 0.010653906084784413}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:59:42 DISPATCHER: Starting worker discovery
07:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:42 DISPATCHER: Finished worker discovery
08:00:42 DISPATCHER: Starting worker discovery
08:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:42 DISPATCHER: Finished worker discovery
08:01:42 DISPATCHER: Starting worker discovery
08:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:42 DISPATCHER: Finished worker discovery
08:01:46 WORKER: done with job (8, 0, 23), trying to register it.
08:01:46 WORKER: registered result for job (8, 0, 23) with dispatcher
08:01:46 DISPATCHER: job (8, 0, 23) finished
08:01:46 DISPATCHER: register_result: lock acquired
08:01:46 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:01:46 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 731, 'last_n_outputs': 19, 'leak_rate': 0.7612182505637332, 'lr': 0.06840831486149927, 'optimizer': 'SGD', 'sparsity': 0.8531032747899336, 'steps_to_train': 23, 'weight_decay': 0.010653906084784413}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8981217554269461, 'info': {'number_mnist': 0.8981217554269461, 'config': "{'batch_size': 64, 'hidden_dim': 731, 'last_n_outputs': 19, 'leak_rate': 0.7612182505637332, 'lr': 0.06840831486149927, 'optimizer': 'SGD', 'sparsity': 0.8531032747899336, 'steps_to_train': 23, 'weight_decay': 0.010653906084784413}"}}
exception: None

08:01:46 job_callback for (8, 0, 23) started
08:01:46 job_callback for (8, 0, 23) got condition
08:01:46 DISPATCHER: Trying to submit another job.
08:01:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:01:46 HBMASTER: Trying to run another job!
08:01:46 job_callback for (8, 0, 23) finished
08:01:46 HBMASTER: schedule new run for iteration 8
08:01:46 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
08:01:46 HBMASTER: submitting job (8, 0, 26) to dispatcher
08:01:46 DISPATCHER: trying to submit job (8, 0, 26)
08:01:46 DISPATCHER: trying to notify the job_runner thread.
08:01:46 HBMASTER: job (8, 0, 26) submitted to dispatcher
08:01:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:01:46 DISPATCHER: Trying to submit another job.
08:01:46 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:01:46 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:01:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:01:46 WORKER: start processing job (8, 0, 26)
08:01:46 WORKER: args: ()
08:01:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 897, 'last_n_outputs': 26, 'leak_rate': 0.759738630390218, 'lr': 0.006589833317973808, 'optimizer': 'SGD', 'sparsity': 0.9625203081960532, 'steps_to_train': 47, 'weight_decay': 0.025181066167601757}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:02:42 DISPATCHER: Starting worker discovery
08:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:42 DISPATCHER: Finished worker discovery
08:03:42 DISPATCHER: Starting worker discovery
08:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:42 DISPATCHER: Finished worker discovery
08:04:11 WORKER: done with job (8, 0, 26), trying to register it.
08:04:11 WORKER: registered result for job (8, 0, 26) with dispatcher
08:04:11 DISPATCHER: job (8, 0, 26) finished
08:04:11 DISPATCHER: register_result: lock acquired
08:04:11 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:04:11 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 897, 'last_n_outputs': 26, 'leak_rate': 0.759738630390218, 'lr': 0.006589833317973808, 'optimizer': 'SGD', 'sparsity': 0.9625203081960532, 'steps_to_train': 47, 'weight_decay': 0.025181066167601757}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9439777381907544, 'info': {'number_mnist': 0.9439777381907544, 'config': "{'batch_size': 128, 'hidden_dim': 897, 'last_n_outputs': 26, 'leak_rate': 0.759738630390218, 'lr': 0.006589833317973808, 'optimizer': 'SGD', 'sparsity': 0.9625203081960532, 'steps_to_train': 47, 'weight_decay': 0.025181066167601757}"}}
exception: None

08:04:11 job_callback for (8, 0, 26) started
08:04:11 DISPATCHER: Trying to submit another job.
08:04:11 job_callback for (8, 0, 26) got condition
08:04:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:04:11 HBMASTER: Trying to run another job!
08:04:11 job_callback for (8, 0, 26) finished
08:04:11 ITERATION: Advancing config (8, 0, 3) to next budget 400.000000
08:04:11 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
08:04:11 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
08:04:11 HBMASTER: schedule new run for iteration 8
08:04:11 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
08:04:11 HBMASTER: submitting job (8, 0, 3) to dispatcher
08:04:11 DISPATCHER: trying to submit job (8, 0, 3)
08:04:11 DISPATCHER: trying to notify the job_runner thread.
08:04:11 HBMASTER: job (8, 0, 3) submitted to dispatcher
08:04:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:04:11 DISPATCHER: Trying to submit another job.
08:04:11 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:04:11 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:04:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:04:11 WORKER: start processing job (8, 0, 3)
08:04:11 WORKER: args: ()
08:04:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}, 'budget': 400.0, 'working_directory': '.'}
08:04:42 DISPATCHER: Starting worker discovery
08:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:42 DISPATCHER: Finished worker discovery
08:05:42 DISPATCHER: Starting worker discovery
08:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:42 DISPATCHER: Finished worker discovery
08:06:42 DISPATCHER: Starting worker discovery
08:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:42 DISPATCHER: Finished worker discovery
08:07:42 DISPATCHER: Starting worker discovery
08:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:42 DISPATCHER: Finished worker discovery
08:08:42 DISPATCHER: Starting worker discovery
08:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:42 DISPATCHER: Finished worker discovery
08:09:42 DISPATCHER: Starting worker discovery
08:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:42 DISPATCHER: Finished worker discovery
08:10:42 DISPATCHER: Starting worker discovery
08:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:42 DISPATCHER: Finished worker discovery
08:11:08 WORKER: done with job (8, 0, 3), trying to register it.
08:11:08 WORKER: registered result for job (8, 0, 3) with dispatcher
08:11:08 DISPATCHER: job (8, 0, 3) finished
08:11:08 DISPATCHER: register_result: lock acquired
08:11:08 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:11:08 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9553713927660055, 'info': {'number_mnist': 0.9553713927660055, 'config': "{'batch_size': 128, 'hidden_dim': 952, 'last_n_outputs': 16, 'leak_rate': 0.7544911532358376, 'lr': 0.04504188026815226, 'optimizer': 'SGD', 'sparsity': 0.867950041870434, 'steps_to_train': 35, 'weight_decay': 0.015786186431874474}"}}
exception: None

08:11:08 job_callback for (8, 0, 3) started
08:11:08 DISPATCHER: Trying to submit another job.
08:11:08 job_callback for (8, 0, 3) got condition
08:11:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:11:08 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.955757





08:11:08 HBMASTER: Trying to run another job!
08:11:08 job_callback for (8, 0, 3) finished
08:11:08 HBMASTER: schedule new run for iteration 8
08:11:08 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
08:11:08 HBMASTER: submitting job (8, 0, 8) to dispatcher
08:11:08 DISPATCHER: trying to submit job (8, 0, 8)
08:11:08 DISPATCHER: trying to notify the job_runner thread.
08:11:08 HBMASTER: job (8, 0, 8) submitted to dispatcher
08:11:08 DISPATCHER: Trying to submit another job.
08:11:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:11:08 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:11:08 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:11:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:11:08 WORKER: start processing job (8, 0, 8)
08:11:08 WORKER: args: ()
08:11:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}, 'budget': 400.0, 'working_directory': '.'}
08:11:42 DISPATCHER: Starting worker discovery
08:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:42 DISPATCHER: Finished worker discovery
08:12:42 DISPATCHER: Starting worker discovery
08:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:42 DISPATCHER: Finished worker discovery
08:13:42 DISPATCHER: Starting worker discovery
08:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:43 DISPATCHER: Finished worker discovery
08:14:43 DISPATCHER: Starting worker discovery
08:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:43 DISPATCHER: Finished worker discovery
08:15:43 DISPATCHER: Starting worker discovery
08:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:43 DISPATCHER: Finished worker discovery
08:16:43 DISPATCHER: Starting worker discovery
08:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:43 DISPATCHER: Finished worker discovery
08:17:43 DISPATCHER: Starting worker discovery
08:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:43 DISPATCHER: Finished worker discovery
08:18:02 WORKER: done with job (8, 0, 8), trying to register it.
08:18:02 WORKER: registered result for job (8, 0, 8) with dispatcher
08:18:02 DISPATCHER: job (8, 0, 8) finished
08:18:02 DISPATCHER: register_result: lock acquired
08:18:02 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:18:02 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9547974071762726, 'info': {'number_mnist': 0.9547974071762726, 'config': "{'batch_size': 64, 'hidden_dim': 742, 'last_n_outputs': 19, 'leak_rate': 0.893319734354786, 'lr': 0.015072512773817584, 'optimizer': 'SGD', 'sparsity': 0.7730134117404353, 'steps_to_train': 58, 'weight_decay': 0.016637657009508915}"}}
exception: None

08:18:02 job_callback for (8, 0, 8) started
08:18:02 DISPATCHER: Trying to submit another job.
08:18:02 job_callback for (8, 0, 8) got condition
08:18:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:02 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.955757





08:18:02 HBMASTER: Trying to run another job!
08:18:02 job_callback for (8, 0, 8) finished
08:18:02 HBMASTER: schedule new run for iteration 8
08:18:02 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
08:18:02 HBMASTER: submitting job (8, 0, 14) to dispatcher
08:18:02 DISPATCHER: trying to submit job (8, 0, 14)
08:18:02 DISPATCHER: trying to notify the job_runner thread.
08:18:02 HBMASTER: job (8, 0, 14) submitted to dispatcher
08:18:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:02 DISPATCHER: Trying to submit another job.
08:18:02 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:18:02 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:18:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:02 WORKER: start processing job (8, 0, 14)
08:18:02 WORKER: args: ()
08:18:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 400.0, 'working_directory': '.'}
08:18:43 DISPATCHER: Starting worker discovery
08:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:43 DISPATCHER: Finished worker discovery
08:19:43 DISPATCHER: Starting worker discovery
08:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:43 DISPATCHER: Finished worker discovery
08:20:43 DISPATCHER: Starting worker discovery
08:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:43 DISPATCHER: Finished worker discovery
08:21:43 DISPATCHER: Starting worker discovery
08:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:43 DISPATCHER: Finished worker discovery
08:22:43 DISPATCHER: Starting worker discovery
08:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:43 DISPATCHER: Finished worker discovery
08:23:43 DISPATCHER: Starting worker discovery
08:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:43 DISPATCHER: Finished worker discovery
08:24:43 DISPATCHER: Starting worker discovery
08:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:43 DISPATCHER: Finished worker discovery
08:25:02 WORKER: done with job (8, 0, 14), trying to register it.
08:25:02 WORKER: registered result for job (8, 0, 14) with dispatcher
08:25:02 DISPATCHER: job (8, 0, 14) finished
08:25:02 DISPATCHER: register_result: lock acquired
08:25:02 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:25:02 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9580305153885138, 'info': {'number_mnist': 0.9580305153885138, 'config': "{'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}"}}
exception: None

08:25:02 job_callback for (8, 0, 14) started
08:25:02 DISPATCHER: Trying to submit another job.
08:25:02 job_callback for (8, 0, 14) got condition
08:25:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:02 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.958031





08:25:02 HBMASTER: Trying to run another job!
08:25:02 job_callback for (8, 0, 14) finished
08:25:02 ITERATION: Advancing config (8, 0, 14) to next budget 1200.000000
08:25:02 HBMASTER: schedule new run for iteration 8
08:25:02 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
08:25:02 HBMASTER: submitting job (8, 0, 14) to dispatcher
08:25:02 DISPATCHER: trying to submit job (8, 0, 14)
08:25:02 DISPATCHER: trying to notify the job_runner thread.
08:25:02 HBMASTER: job (8, 0, 14) submitted to dispatcher
08:25:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:25:02 DISPATCHER: Trying to submit another job.
08:25:02 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:25:02 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:25:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:25:02 WORKER: start processing job (8, 0, 14)
08:25:02 WORKER: args: ()
08:25:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 1200.0, 'working_directory': '.'}
08:25:43 DISPATCHER: Starting worker discovery
08:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:43 DISPATCHER: Finished worker discovery
08:26:43 DISPATCHER: Starting worker discovery
08:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:43 DISPATCHER: Finished worker discovery
08:27:43 DISPATCHER: Starting worker discovery
08:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:43 DISPATCHER: Finished worker discovery
08:28:43 DISPATCHER: Starting worker discovery
08:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:43 DISPATCHER: Finished worker discovery
08:29:43 DISPATCHER: Starting worker discovery
08:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:43 DISPATCHER: Finished worker discovery
08:30:43 DISPATCHER: Starting worker discovery
08:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:43 DISPATCHER: Finished worker discovery
08:31:43 DISPATCHER: Starting worker discovery
08:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:43 DISPATCHER: Finished worker discovery
08:32:43 DISPATCHER: Starting worker discovery
08:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:43 DISPATCHER: Finished worker discovery
08:33:43 DISPATCHER: Starting worker discovery
08:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:43 DISPATCHER: Finished worker discovery
08:34:43 DISPATCHER: Starting worker discovery
08:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:43 DISPATCHER: Finished worker discovery
08:35:43 DISPATCHER: Starting worker discovery
08:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:43 DISPATCHER: Finished worker discovery
08:36:43 DISPATCHER: Starting worker discovery
08:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:43 DISPATCHER: Finished worker discovery
08:37:43 DISPATCHER: Starting worker discovery
08:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:43 DISPATCHER: Finished worker discovery
08:38:43 DISPATCHER: Starting worker discovery
08:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:43 DISPATCHER: Finished worker discovery
08:39:43 DISPATCHER: Starting worker discovery
08:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:43 DISPATCHER: Finished worker discovery
08:40:43 DISPATCHER: Starting worker discovery
08:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:43 DISPATCHER: Finished worker discovery
08:41:43 DISPATCHER: Starting worker discovery
08:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:43 DISPATCHER: Finished worker discovery
08:42:43 DISPATCHER: Starting worker discovery
08:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:43 DISPATCHER: Finished worker discovery
08:43:43 DISPATCHER: Starting worker discovery
08:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:43 DISPATCHER: Finished worker discovery
08:44:43 DISPATCHER: Starting worker discovery
08:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:43 DISPATCHER: Finished worker discovery
08:45:43 DISPATCHER: Starting worker discovery
08:45:43 WORKER: done with job (8, 0, 14), trying to register it.
08:45:43 WORKER: registered result for job (8, 0, 14) with dispatcher
08:45:43 DISPATCHER: job (8, 0, 14) finished
08:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:43 DISPATCHER: Finished worker discovery
08:45:43 DISPATCHER: register_result: lock acquired
08:45:43 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:45:43 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9484068921187736, 'info': {'number_mnist': 0.9484068921187736, 'config': "{'batch_size': 64, 'hidden_dim': 711, 'last_n_outputs': 19, 'leak_rate': 0.9593385528318725, 'lr': 0.022209062384037578, 'optimizer': 'SGD', 'sparsity': 0.7827081200074907, 'steps_to_train': 21, 'weight_decay': 0.011847302398253946}"}}
exception: None

08:45:43 job_callback for (8, 0, 14) started
08:45:43 job_callback for (8, 0, 14) got condition
08:45:43 DISPATCHER: Trying to submit another job.
08:45:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:45:43 HBMASTER: Trying to run another job!
08:45:43 job_callback for (8, 0, 14) finished
08:45:43 start sampling a new configuration.
08:45:43 best_vector: [3, 0.6260740161915794, 0.2988461746150409, 0.5769576936626661, 0.8546181511097863, 1, 0.7212037827352656, 0.37798621362830853, 0.09563989979439169], 0.006559805766656557, 4.714776270757893, 0.030928016569413123
08:45:43 done sampling a new configuration.
08:45:43 HBMASTER: schedule new run for iteration 9
08:45:43 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
08:45:43 HBMASTER: submitting job (9, 0, 0) to dispatcher
08:45:43 DISPATCHER: trying to submit job (9, 0, 0)
08:45:43 DISPATCHER: trying to notify the job_runner thread.
08:45:43 HBMASTER: job (9, 0, 0) submitted to dispatcher
08:45:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:45:43 DISPATCHER: Trying to submit another job.
08:45:43 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:45:43 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:45:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:45:43 WORKER: start processing job (9, 0, 0)
08:45:43 WORKER: args: ()
08:45:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 22, 'leak_rate': 0.8942394234156665, 'lr': 0.051196032043663665, 'optimizer': 'SGD', 'sparsity': 0.9230889078564637, 'steps_to_train': 44, 'weight_decay': 0.013317735290855}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:46:43 DISPATCHER: Starting worker discovery
08:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:43 DISPATCHER: Finished worker discovery
08:47:43 DISPATCHER: Starting worker discovery
08:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:43 DISPATCHER: Finished worker discovery
08:48:08 WORKER: done with job (9, 0, 0), trying to register it.
08:48:08 WORKER: registered result for job (9, 0, 0) with dispatcher
08:48:08 DISPATCHER: job (9, 0, 0) finished
08:48:08 DISPATCHER: register_result: lock acquired
08:48:08 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:48:08 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 22, 'leak_rate': 0.8942394234156665, 'lr': 0.051196032043663665, 'optimizer': 'SGD', 'sparsity': 0.9230889078564637, 'steps_to_train': 44, 'weight_decay': 0.013317735290855}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9443258889227266, 'info': {'number_mnist': 0.9443258889227266, 'config': "{'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 22, 'leak_rate': 0.8942394234156665, 'lr': 0.051196032043663665, 'optimizer': 'SGD', 'sparsity': 0.9230889078564637, 'steps_to_train': 44, 'weight_decay': 0.013317735290855}"}}
exception: None

08:48:08 job_callback for (9, 0, 0) started
08:48:08 DISPATCHER: Trying to submit another job.
08:48:08 job_callback for (9, 0, 0) got condition
08:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:48:08 HBMASTER: Trying to run another job!
08:48:08 job_callback for (9, 0, 0) finished
08:48:08 start sampling a new configuration.
08:48:08 best_vector: [0, 0.9083878227041112, 0.076370448096242, 0.3063302077210699, 0.8835643366468608, 1, 0.3826498875158878, 0.44610705868803835, 0.12341175715528926], 0.0021263147127313694, 9.372366730264932, 0.019928601271676324
08:48:08 done sampling a new configuration.
08:48:08 HBMASTER: schedule new run for iteration 9
08:48:08 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
08:48:08 HBMASTER: submitting job (9, 0, 1) to dispatcher
08:48:08 DISPATCHER: trying to submit job (9, 0, 1)
08:48:08 DISPATCHER: trying to notify the job_runner thread.
08:48:08 HBMASTER: job (9, 0, 1) submitted to dispatcher
08:48:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:48:08 DISPATCHER: Trying to submit another job.
08:48:08 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:48:08 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:48:08 WORKER: start processing job (9, 0, 1)
08:48:08 WORKER: args: ()
08:48:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 13, 'leak_rate': 0.8265825519302674, 'lr': 0.058496337212675074, 'optimizer': 'SGD', 'sparsity': 0.8418359730038131, 'steps_to_train': 50, 'weight_decay': 0.014473127828773467}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:48:43 DISPATCHER: Starting worker discovery
08:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:43 DISPATCHER: Finished worker discovery
08:49:43 DISPATCHER: Starting worker discovery
08:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:43 DISPATCHER: Finished worker discovery
08:50:33 WORKER: done with job (9, 0, 1), trying to register it.
08:50:33 WORKER: registered result for job (9, 0, 1) with dispatcher
08:50:33 DISPATCHER: job (9, 0, 1) finished
08:50:33 DISPATCHER: register_result: lock acquired
08:50:33 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:50:33 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 13, 'leak_rate': 0.8265825519302674, 'lr': 0.058496337212675074, 'optimizer': 'SGD', 'sparsity': 0.8418359730038131, 'steps_to_train': 50, 'weight_decay': 0.014473127828773467}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8627977190224703, 'info': {'number_mnist': 0.8627977190224703, 'config': "{'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 13, 'leak_rate': 0.8265825519302674, 'lr': 0.058496337212675074, 'optimizer': 'SGD', 'sparsity': 0.8418359730038131, 'steps_to_train': 50, 'weight_decay': 0.014473127828773467}"}}
exception: None

08:50:33 job_callback for (9, 0, 1) started
08:50:33 DISPATCHER: Trying to submit another job.
08:50:33 job_callback for (9, 0, 1) got condition
08:50:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:50:33 HBMASTER: Trying to run another job!
08:50:33 job_callback for (9, 0, 1) finished
08:50:33 start sampling a new configuration.
08:50:33 best_vector: [1, 0.9101454780085034, 0.2083353956985453, 0.23273541681439214, 0.9752989956324225, 1, 0.17815547215657931, 0.21899288748829338, 0.14836275250317302], 0.00017010768014563194, 5.920304999720235, 0.0010070893492569954
08:50:33 done sampling a new configuration.
08:50:33 HBMASTER: schedule new run for iteration 9
08:50:33 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
08:50:33 HBMASTER: submitting job (9, 0, 2) to dispatcher
08:50:33 DISPATCHER: trying to submit job (9, 0, 2)
08:50:33 DISPATCHER: trying to notify the job_runner thread.
08:50:33 HBMASTER: job (9, 0, 2) submitted to dispatcher
08:50:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:50:33 DISPATCHER: Trying to submit another job.
08:50:33 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:50:33 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:50:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:50:33 WORKER: start processing job (9, 0, 2)
08:50:33 WORKER: args: ()
08:50:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 929, 'last_n_outputs': 18, 'leak_rate': 0.8081838542035981, 'lr': 0.08924789697801258, 'optimizer': 'SGD', 'sparsity': 0.792757313317579, 'steps_to_train': 29, 'weight_decay': 0.015596400943078449}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:50:43 DISPATCHER: Starting worker discovery
08:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:43 DISPATCHER: Finished worker discovery
08:51:43 DISPATCHER: Starting worker discovery
08:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:43 DISPATCHER: Finished worker discovery
08:52:43 DISPATCHER: Starting worker discovery
08:52:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:43 DISPATCHER: Finished worker discovery
08:52:58 WORKER: done with job (9, 0, 2), trying to register it.
08:52:58 WORKER: registered result for job (9, 0, 2) with dispatcher
08:52:58 DISPATCHER: job (9, 0, 2) finished
08:52:58 DISPATCHER: register_result: lock acquired
08:52:58 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:52:58 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 929, 'last_n_outputs': 18, 'leak_rate': 0.8081838542035981, 'lr': 0.08924789697801258, 'optimizer': 'SGD', 'sparsity': 0.792757313317579, 'steps_to_train': 29, 'weight_decay': 0.015596400943078449}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8828486709499176, 'info': {'number_mnist': 0.8828486709499176, 'config': "{'batch_size': 32, 'hidden_dim': 929, 'last_n_outputs': 18, 'leak_rate': 0.8081838542035981, 'lr': 0.08924789697801258, 'optimizer': 'SGD', 'sparsity': 0.792757313317579, 'steps_to_train': 29, 'weight_decay': 0.015596400943078449}"}}
exception: None

08:52:58 job_callback for (9, 0, 2) started
08:52:58 job_callback for (9, 0, 2) got condition
08:52:58 DISPATCHER: Trying to submit another job.
08:52:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:52:58 HBMASTER: Trying to run another job!
08:52:58 job_callback for (9, 0, 2) finished
08:52:58 start sampling a new configuration.
08:52:58 done sampling a new configuration.
08:52:58 HBMASTER: schedule new run for iteration 9
08:52:58 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
08:52:58 HBMASTER: submitting job (9, 0, 3) to dispatcher
08:52:58 DISPATCHER: trying to submit job (9, 0, 3)
08:52:58 DISPATCHER: trying to notify the job_runner thread.
08:52:58 HBMASTER: job (9, 0, 3) submitted to dispatcher
08:52:58 DISPATCHER: Trying to submit another job.
08:52:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:52:58 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:52:58 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:52:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:52:58 WORKER: start processing job (9, 0, 3)
08:52:58 WORKER: args: ()
08:52:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 419, 'last_n_outputs': 16, 'leak_rate': 0.9700982214617713, 'lr': 0.017282613748641647, 'optimizer': 'Adam', 'sparsity': 0.9717291916675292, 'steps_to_train': 94, 'weight_decay': 0.04177252001326715}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:53:43 DISPATCHER: Starting worker discovery
08:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:43 DISPATCHER: Finished worker discovery
08:54:43 DISPATCHER: Starting worker discovery
08:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:43 DISPATCHER: Finished worker discovery
08:55:22 WORKER: done with job (9, 0, 3), trying to register it.
08:55:22 WORKER: registered result for job (9, 0, 3) with dispatcher
08:55:22 DISPATCHER: job (9, 0, 3) finished
08:55:22 DISPATCHER: register_result: lock acquired
08:55:22 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:55:22 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 419, 'last_n_outputs': 16, 'leak_rate': 0.9700982214617713, 'lr': 0.017282613748641647, 'optimizer': 'Adam', 'sparsity': 0.9717291916675292, 'steps_to_train': 94, 'weight_decay': 0.04177252001326715}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3589842979261577, 'info': {'number_mnist': 0.3589842979261577, 'config': "{'batch_size': 16, 'hidden_dim': 419, 'last_n_outputs': 16, 'leak_rate': 0.9700982214617713, 'lr': 0.017282613748641647, 'optimizer': 'Adam', 'sparsity': 0.9717291916675292, 'steps_to_train': 94, 'weight_decay': 0.04177252001326715}"}}
exception: None

08:55:22 job_callback for (9, 0, 3) started
08:55:22 job_callback for (9, 0, 3) got condition
08:55:22 DISPATCHER: Trying to submit another job.
08:55:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:55:22 HBMASTER: Trying to run another job!
08:55:22 job_callback for (9, 0, 3) finished
08:55:22 start sampling a new configuration.
08:55:22 best_vector: [3, 0.6538569092158548, 0.050218238060493914, 0.24215170667054728, 0.7741394888086726, 1, 0.10003096631670416, 0.30726375419098173, 0.21180465749599778], 0.0014659922677108272, 0.8975677776879989, 0.001315827421836997
08:55:22 done sampling a new configuration.
08:55:22 HBMASTER: schedule new run for iteration 9
08:55:22 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
08:55:22 HBMASTER: submitting job (9, 0, 4) to dispatcher
08:55:22 DISPATCHER: trying to submit job (9, 0, 4)
08:55:22 DISPATCHER: trying to notify the job_runner thread.
08:55:22 HBMASTER: job (9, 0, 4) submitted to dispatcher
08:55:22 DISPATCHER: Trying to submit another job.
08:55:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:55:22 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:55:22 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:55:22 WORKER: start processing job (9, 0, 4)
08:55:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:55:22 WORKER: args: ()
08:55:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 723, 'last_n_outputs': 12, 'leak_rate': 0.8105379266676368, 'lr': 0.03534101168439845, 'optimizer': 'SGD', 'sparsity': 0.774007431916009, 'steps_to_train': 37, 'weight_decay': 0.01886097817924684}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:55:43 DISPATCHER: Starting worker discovery
08:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:43 DISPATCHER: Finished worker discovery
08:56:43 DISPATCHER: Starting worker discovery
08:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:43 DISPATCHER: Finished worker discovery
08:57:43 DISPATCHER: Starting worker discovery
08:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:43 DISPATCHER: Finished worker discovery
08:57:48 WORKER: done with job (9, 0, 4), trying to register it.
08:57:48 WORKER: registered result for job (9, 0, 4) with dispatcher
08:57:48 DISPATCHER: job (9, 0, 4) finished
08:57:48 DISPATCHER: register_result: lock acquired
08:57:48 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:57:48 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 723, 'last_n_outputs': 12, 'leak_rate': 0.8105379266676368, 'lr': 0.03534101168439845, 'optimizer': 'SGD', 'sparsity': 0.774007431916009, 'steps_to_train': 37, 'weight_decay': 0.01886097817924684}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9060816711189887, 'info': {'number_mnist': 0.9060816711189887, 'config': "{'batch_size': 128, 'hidden_dim': 723, 'last_n_outputs': 12, 'leak_rate': 0.8105379266676368, 'lr': 0.03534101168439845, 'optimizer': 'SGD', 'sparsity': 0.774007431916009, 'steps_to_train': 37, 'weight_decay': 0.01886097817924684}"}}
exception: None

08:57:48 job_callback for (9, 0, 4) started
08:57:48 DISPATCHER: Trying to submit another job.
08:57:48 job_callback for (9, 0, 4) got condition
08:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:48 HBMASTER: Trying to run another job!
08:57:48 job_callback for (9, 0, 4) finished
08:57:48 start sampling a new configuration.
08:57:48 best_vector: [1, 0.880663798694407, 0.15599715169863043, 0.682823376841327, 0.6784623072052621, 1, 0.009726801964546339, 0.04900160047502766, 0.15386896813171166], 6.321717338988454e-05, 12.233201786432774, 0.0007733484384463659
08:57:48 done sampling a new configuration.
08:57:48 HBMASTER: schedule new run for iteration 9
08:57:48 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
08:57:48 HBMASTER: submitting job (9, 0, 5) to dispatcher
08:57:48 DISPATCHER: trying to submit job (9, 0, 5)
08:57:48 DISPATCHER: trying to notify the job_runner thread.
08:57:48 HBMASTER: job (9, 0, 5) submitted to dispatcher
08:57:48 DISPATCHER: Trying to submit another job.
08:57:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:48 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:57:48 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:57:48 WORKER: start processing job (9, 0, 5)
08:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:48 WORKER: args: ()
08:57:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:58:43 DISPATCHER: Starting worker discovery
08:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:43 DISPATCHER: Finished worker discovery
08:59:43 DISPATCHER: Starting worker discovery
08:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:43 DISPATCHER: Finished worker discovery
09:00:16 WORKER: done with job (9, 0, 5), trying to register it.
09:00:16 WORKER: registered result for job (9, 0, 5) with dispatcher
09:00:16 DISPATCHER: job (9, 0, 5) finished
09:00:16 DISPATCHER: register_result: lock acquired
09:00:16 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:00:16 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9550659676626658, 'info': {'number_mnist': 0.9550659676626658, 'config': "{'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}"}}
exception: None

09:00:16 job_callback for (9, 0, 5) started
09:00:16 DISPATCHER: Trying to submit another job.
09:00:16 job_callback for (9, 0, 5) got condition
09:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:00:16 HBMASTER: Trying to run another job!
09:00:16 job_callback for (9, 0, 5) finished
09:00:16 start sampling a new configuration.
09:00:16 best_vector: [3, 0.8437817282847163, 0.0528892765603112, 0.8123858571155422, 0.6204265749698529, 1, 7.795065753962716e-05, 0.13943384270618608, 0.09702821511031573], 0.00021229947550843202, 2.892735351999086, 0.0006141261980141054
09:00:16 done sampling a new configuration.
09:00:16 HBMASTER: schedule new run for iteration 9
09:00:16 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
09:00:16 HBMASTER: submitting job (9, 0, 6) to dispatcher
09:00:16 DISPATCHER: trying to submit job (9, 0, 6)
09:00:16 DISPATCHER: trying to notify the job_runner thread.
09:00:16 HBMASTER: job (9, 0, 6) submitted to dispatcher
09:00:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:00:16 DISPATCHER: Trying to submit another job.
09:00:16 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:00:16 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:00:16 WORKER: start processing job (9, 0, 6)
09:00:16 WORKER: args: ()
09:00:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 875, 'last_n_outputs': 12, 'leak_rate': 0.9530964642788855, 'lr': 0.01741218007506591, 'optimizer': 'SGD', 'sparsity': 0.7500187081578095, 'steps_to_train': 22, 'weight_decay': 0.013373239372887313}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:00:43 DISPATCHER: Starting worker discovery
09:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:43 DISPATCHER: Finished worker discovery
09:01:43 DISPATCHER: Starting worker discovery
09:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:43 DISPATCHER: Finished worker discovery
09:02:43 DISPATCHER: Starting worker discovery
09:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:43 DISPATCHER: Finished worker discovery
09:02:43 WORKER: done with job (9, 0, 6), trying to register it.
09:02:43 WORKER: registered result for job (9, 0, 6) with dispatcher
09:02:43 DISPATCHER: job (9, 0, 6) finished
09:02:43 DISPATCHER: register_result: lock acquired
09:02:43 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:02:43 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 875, 'last_n_outputs': 12, 'leak_rate': 0.9530964642788855, 'lr': 0.01741218007506591, 'optimizer': 'SGD', 'sparsity': 0.7500187081578095, 'steps_to_train': 22, 'weight_decay': 0.013373239372887313}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9212052740836912, 'info': {'number_mnist': 0.9212052740836912, 'config': "{'batch_size': 128, 'hidden_dim': 875, 'last_n_outputs': 12, 'leak_rate': 0.9530964642788855, 'lr': 0.01741218007506591, 'optimizer': 'SGD', 'sparsity': 0.7500187081578095, 'steps_to_train': 22, 'weight_decay': 0.013373239372887313}"}}
exception: None

09:02:43 job_callback for (9, 0, 6) started
09:02:43 job_callback for (9, 0, 6) got condition
09:02:43 DISPATCHER: Trying to submit another job.
09:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:02:43 HBMASTER: Trying to run another job!
09:02:43 job_callback for (9, 0, 6) finished
09:02:43 start sampling a new configuration.
09:02:43 done sampling a new configuration.
09:02:43 HBMASTER: schedule new run for iteration 9
09:02:43 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
09:02:43 HBMASTER: submitting job (9, 0, 7) to dispatcher
09:02:43 DISPATCHER: trying to submit job (9, 0, 7)
09:02:43 DISPATCHER: trying to notify the job_runner thread.
09:02:43 HBMASTER: job (9, 0, 7) submitted to dispatcher
09:02:43 DISPATCHER: Trying to submit another job.
09:02:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:02:43 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:02:43 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:02:43 WORKER: start processing job (9, 0, 7)
09:02:43 WORKER: args: ()
09:02:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 482, 'last_n_outputs': 18, 'leak_rate': 0.9021022073062969, 'lr': 0.0013883583030671195, 'optimizer': 'Adam', 'sparsity': 0.7539684854410004, 'steps_to_train': 74, 'weight_decay': 0.048944655756835286}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:03:43 DISPATCHER: Starting worker discovery
09:03:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:43 DISPATCHER: Finished worker discovery
09:04:43 DISPATCHER: Starting worker discovery
09:04:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:43 DISPATCHER: Finished worker discovery
09:05:06 WORKER: done with job (9, 0, 7), trying to register it.
09:05:06 WORKER: registered result for job (9, 0, 7) with dispatcher
09:05:06 DISPATCHER: job (9, 0, 7) finished
09:05:06 DISPATCHER: register_result: lock acquired
09:05:06 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:05:06 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 482, 'last_n_outputs': 18, 'leak_rate': 0.9021022073062969, 'lr': 0.0013883583030671195, 'optimizer': 'Adam', 'sparsity': 0.7539684854410004, 'steps_to_train': 74, 'weight_decay': 0.048944655756835286}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.794274801638642, 'info': {'number_mnist': 0.794274801638642, 'config': "{'batch_size': 16, 'hidden_dim': 482, 'last_n_outputs': 18, 'leak_rate': 0.9021022073062969, 'lr': 0.0013883583030671195, 'optimizer': 'Adam', 'sparsity': 0.7539684854410004, 'steps_to_train': 74, 'weight_decay': 0.048944655756835286}"}}
exception: None

09:05:06 job_callback for (9, 0, 7) started
09:05:06 DISPATCHER: Trying to submit another job.
09:05:06 job_callback for (9, 0, 7) got condition
09:05:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:05:06 HBMASTER: Trying to run another job!
09:05:06 job_callback for (9, 0, 7) finished
09:05:06 start sampling a new configuration.
09:05:06 best_vector: [0, 0.5327657367045706, 0.07336752364768495, 0.9381691449599819, 0.7306007263015694, 0, 0.9129222696828079, 0.7291751449767627, 0.227221477282611], 0.0, inf, 0.00878721372855819
09:05:06 done sampling a new configuration.
09:05:06 HBMASTER: schedule new run for iteration 9
09:05:06 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
09:05:06 HBMASTER: submitting job (9, 0, 8) to dispatcher
09:05:06 DISPATCHER: trying to submit job (9, 0, 8)
09:05:06 DISPATCHER: trying to notify the job_runner thread.
09:05:06 HBMASTER: job (9, 0, 8) submitted to dispatcher
09:05:06 DISPATCHER: Trying to submit another job.
09:05:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:05:06 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:05:06 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:05:06 WORKER: start processing job (9, 0, 8)
09:05:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:05:06 WORKER: args: ()
09:05:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 626, 'last_n_outputs': 13, 'leak_rate': 0.9845422862399955, 'lr': 0.028920210692646123, 'optimizer': 'Adam', 'sparsity': 0.9691013447238739, 'steps_to_train': 76, 'weight_decay': 0.019752494866709658}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:05:43 DISPATCHER: Starting worker discovery
09:05:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:43 DISPATCHER: Finished worker discovery
09:06:43 DISPATCHER: Starting worker discovery
09:06:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:43 DISPATCHER: Finished worker discovery
09:07:31 WORKER: done with job (9, 0, 8), trying to register it.
09:07:31 WORKER: registered result for job (9, 0, 8) with dispatcher
09:07:31 DISPATCHER: job (9, 0, 8) finished
09:07:31 DISPATCHER: register_result: lock acquired
09:07:31 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:07:31 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 626, 'last_n_outputs': 13, 'leak_rate': 0.9845422862399955, 'lr': 0.028920210692646123, 'optimizer': 'Adam', 'sparsity': 0.9691013447238739, 'steps_to_train': 76, 'weight_decay': 0.019752494866709658}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38385917908777945, 'info': {'number_mnist': 0.38385917908777945, 'config': "{'batch_size': 16, 'hidden_dim': 626, 'last_n_outputs': 13, 'leak_rate': 0.9845422862399955, 'lr': 0.028920210692646123, 'optimizer': 'Adam', 'sparsity': 0.9691013447238739, 'steps_to_train': 76, 'weight_decay': 0.019752494866709658}"}}
exception: None

09:07:31 job_callback for (9, 0, 8) started
09:07:31 DISPATCHER: Trying to submit another job.
09:07:31 job_callback for (9, 0, 8) got condition
09:07:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:07:31 HBMASTER: Trying to run another job!
09:07:31 job_callback for (9, 0, 8) finished
09:07:31 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
09:07:31 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
09:07:31 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
09:07:31 HBMASTER: schedule new run for iteration 9
09:07:31 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
09:07:31 HBMASTER: submitting job (9, 0, 0) to dispatcher
09:07:31 DISPATCHER: trying to submit job (9, 0, 0)
09:07:31 DISPATCHER: trying to notify the job_runner thread.
09:07:31 HBMASTER: job (9, 0, 0) submitted to dispatcher
09:07:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:07:31 DISPATCHER: Trying to submit another job.
09:07:31 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:07:31 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:07:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:07:31 WORKER: start processing job (9, 0, 0)
09:07:31 WORKER: args: ()
09:07:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 22, 'leak_rate': 0.8942394234156665, 'lr': 0.051196032043663665, 'optimizer': 'SGD', 'sparsity': 0.9230889078564637, 'steps_to_train': 44, 'weight_decay': 0.013317735290855}, 'budget': 400.0, 'working_directory': '.'}
09:07:43 DISPATCHER: Starting worker discovery
09:07:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:43 DISPATCHER: Finished worker discovery
09:08:43 DISPATCHER: Starting worker discovery
09:08:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:43 DISPATCHER: Finished worker discovery
09:09:43 DISPATCHER: Starting worker discovery
09:09:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:43 DISPATCHER: Finished worker discovery
09:10:43 DISPATCHER: Starting worker discovery
09:10:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:43 DISPATCHER: Finished worker discovery
09:11:43 DISPATCHER: Starting worker discovery
09:11:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:43 DISPATCHER: Finished worker discovery
09:12:43 DISPATCHER: Starting worker discovery
09:12:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:43 DISPATCHER: Finished worker discovery
09:13:43 DISPATCHER: Starting worker discovery
09:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:43 DISPATCHER: Finished worker discovery
09:14:27 WORKER: done with job (9, 0, 0), trying to register it.
09:14:27 WORKER: registered result for job (9, 0, 0) with dispatcher
09:14:27 DISPATCHER: job (9, 0, 0) finished
09:14:27 DISPATCHER: register_result: lock acquired
09:14:27 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:14:27 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 22, 'leak_rate': 0.8942394234156665, 'lr': 0.051196032043663665, 'optimizer': 'SGD', 'sparsity': 0.9230889078564637, 'steps_to_train': 44, 'weight_decay': 0.013317735290855}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9418103327585876, 'info': {'number_mnist': 0.9418103327585876, 'config': "{'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 22, 'leak_rate': 0.8942394234156665, 'lr': 0.051196032043663665, 'optimizer': 'SGD', 'sparsity': 0.9230889078564637, 'steps_to_train': 44, 'weight_decay': 0.013317735290855}"}}
exception: None

09:14:27 job_callback for (9, 0, 0) started
09:14:27 DISPATCHER: Trying to submit another job.
09:14:27 job_callback for (9, 0, 0) got condition
09:14:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:14:27 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.958031





09:14:27 HBMASTER: Trying to run another job!
09:14:27 job_callback for (9, 0, 0) finished
09:14:27 HBMASTER: schedule new run for iteration 9
09:14:27 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
09:14:27 HBMASTER: submitting job (9, 0, 5) to dispatcher
09:14:27 DISPATCHER: trying to submit job (9, 0, 5)
09:14:27 DISPATCHER: trying to notify the job_runner thread.
09:14:27 HBMASTER: job (9, 0, 5) submitted to dispatcher
09:14:27 DISPATCHER: Trying to submit another job.
09:14:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:14:27 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:14:27 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:14:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:14:27 WORKER: start processing job (9, 0, 5)
09:14:27 WORKER: args: ()
09:14:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}, 'budget': 400.0, 'working_directory': '.'}
09:14:43 DISPATCHER: Starting worker discovery
09:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:43 DISPATCHER: Finished worker discovery
09:15:43 DISPATCHER: Starting worker discovery
09:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:43 DISPATCHER: Finished worker discovery
09:16:43 DISPATCHER: Starting worker discovery
09:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:43 DISPATCHER: Finished worker discovery
09:17:43 DISPATCHER: Starting worker discovery
09:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:43 DISPATCHER: Finished worker discovery
09:18:43 DISPATCHER: Starting worker discovery
09:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:43 DISPATCHER: Finished worker discovery
09:19:43 DISPATCHER: Starting worker discovery
09:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:43 DISPATCHER: Finished worker discovery
09:20:43 DISPATCHER: Starting worker discovery
09:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:43 DISPATCHER: Finished worker discovery
09:21:34 WORKER: done with job (9, 0, 5), trying to register it.
09:21:34 WORKER: registered result for job (9, 0, 5) with dispatcher
09:21:34 DISPATCHER: job (9, 0, 5) finished
09:21:34 DISPATCHER: register_result: lock acquired
09:21:34 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:21:34 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9428784504582235, 'info': {'number_mnist': 0.9428784504582235, 'config': "{'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}"}}
exception: None

09:21:34 job_callback for (9, 0, 5) started
09:21:34 DISPATCHER: Trying to submit another job.
09:21:34 job_callback for (9, 0, 5) got condition
09:21:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:21:34 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.958031





09:21:34 HBMASTER: Trying to run another job!
09:21:34 job_callback for (9, 0, 5) finished
09:21:34 HBMASTER: schedule new run for iteration 9
09:21:34 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
09:21:34 HBMASTER: submitting job (9, 0, 6) to dispatcher
09:21:34 DISPATCHER: trying to submit job (9, 0, 6)
09:21:34 DISPATCHER: trying to notify the job_runner thread.
09:21:34 HBMASTER: job (9, 0, 6) submitted to dispatcher
09:21:34 DISPATCHER: Trying to submit another job.
09:21:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:21:34 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:21:34 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:21:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:21:34 WORKER: start processing job (9, 0, 6)
09:21:34 WORKER: args: ()
09:21:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 875, 'last_n_outputs': 12, 'leak_rate': 0.9530964642788855, 'lr': 0.01741218007506591, 'optimizer': 'SGD', 'sparsity': 0.7500187081578095, 'steps_to_train': 22, 'weight_decay': 0.013373239372887313}, 'budget': 400.0, 'working_directory': '.'}
09:21:43 DISPATCHER: Starting worker discovery
09:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:43 DISPATCHER: Finished worker discovery
09:22:43 DISPATCHER: Starting worker discovery
09:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:43 DISPATCHER: Finished worker discovery
09:23:43 DISPATCHER: Starting worker discovery
09:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:43 DISPATCHER: Finished worker discovery
09:24:43 DISPATCHER: Starting worker discovery
09:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:43 DISPATCHER: Finished worker discovery
09:25:43 DISPATCHER: Starting worker discovery
09:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:43 DISPATCHER: Finished worker discovery
09:26:43 DISPATCHER: Starting worker discovery
09:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:43 DISPATCHER: Finished worker discovery
09:27:43 DISPATCHER: Starting worker discovery
09:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:43 DISPATCHER: Finished worker discovery
09:28:35 WORKER: done with job (9, 0, 6), trying to register it.
09:28:35 WORKER: registered result for job (9, 0, 6) with dispatcher
09:28:35 DISPATCHER: job (9, 0, 6) finished
09:28:35 DISPATCHER: register_result: lock acquired
09:28:35 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:28:35 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 875, 'last_n_outputs': 12, 'leak_rate': 0.9530964642788855, 'lr': 0.01741218007506591, 'optimizer': 'SGD', 'sparsity': 0.7500187081578095, 'steps_to_train': 22, 'weight_decay': 0.013373239372887313}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9305293769351454, 'info': {'number_mnist': 0.9305293769351454, 'config': "{'batch_size': 128, 'hidden_dim': 875, 'last_n_outputs': 12, 'leak_rate': 0.9530964642788855, 'lr': 0.01741218007506591, 'optimizer': 'SGD', 'sparsity': 0.7500187081578095, 'steps_to_train': 22, 'weight_decay': 0.013373239372887313}"}}
exception: None

09:28:35 job_callback for (9, 0, 6) started
09:28:35 DISPATCHER: Trying to submit another job.
09:28:35 job_callback for (9, 0, 6) got condition
09:28:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:35 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.958031





09:28:35 HBMASTER: Trying to run another job!
09:28:35 job_callback for (9, 0, 6) finished
09:28:35 ITERATION: Advancing config (9, 0, 5) to next budget 1200.000000
09:28:35 HBMASTER: schedule new run for iteration 9
09:28:35 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
09:28:35 HBMASTER: submitting job (9, 0, 5) to dispatcher
09:28:35 DISPATCHER: trying to submit job (9, 0, 5)
09:28:35 DISPATCHER: trying to notify the job_runner thread.
09:28:35 HBMASTER: job (9, 0, 5) submitted to dispatcher
09:28:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:35 DISPATCHER: Trying to submit another job.
09:28:35 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:28:35 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:28:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:35 WORKER: start processing job (9, 0, 5)
09:28:35 WORKER: args: ()
09:28:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}, 'budget': 1200.0, 'working_directory': '.'}
09:28:43 DISPATCHER: Starting worker discovery
09:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:43 DISPATCHER: Finished worker discovery
09:29:43 DISPATCHER: Starting worker discovery
09:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:43 DISPATCHER: Finished worker discovery
09:30:43 DISPATCHER: Starting worker discovery
09:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:43 DISPATCHER: Finished worker discovery
09:31:43 DISPATCHER: Starting worker discovery
09:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:43 DISPATCHER: Finished worker discovery
09:32:43 DISPATCHER: Starting worker discovery
09:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:43 DISPATCHER: Finished worker discovery
09:33:43 DISPATCHER: Starting worker discovery
09:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:43 DISPATCHER: Finished worker discovery
09:34:43 DISPATCHER: Starting worker discovery
09:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:43 DISPATCHER: Finished worker discovery
09:35:43 DISPATCHER: Starting worker discovery
09:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:43 DISPATCHER: Finished worker discovery
09:36:43 DISPATCHER: Starting worker discovery
09:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:43 DISPATCHER: Finished worker discovery
09:37:43 DISPATCHER: Starting worker discovery
09:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:43 DISPATCHER: Finished worker discovery
09:38:43 DISPATCHER: Starting worker discovery
09:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:43 DISPATCHER: Finished worker discovery
09:39:43 DISPATCHER: Starting worker discovery
09:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:43 DISPATCHER: Finished worker discovery
09:40:43 DISPATCHER: Starting worker discovery
09:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:43 DISPATCHER: Finished worker discovery
09:41:43 DISPATCHER: Starting worker discovery
09:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:43 DISPATCHER: Finished worker discovery
09:42:43 DISPATCHER: Starting worker discovery
09:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:43 DISPATCHER: Finished worker discovery
09:43:43 DISPATCHER: Starting worker discovery
09:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:43 DISPATCHER: Finished worker discovery
09:44:43 DISPATCHER: Starting worker discovery
09:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:43 DISPATCHER: Finished worker discovery
09:45:43 DISPATCHER: Starting worker discovery
09:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:43 DISPATCHER: Finished worker discovery
09:46:43 DISPATCHER: Starting worker discovery
09:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:43 DISPATCHER: Finished worker discovery
09:47:43 DISPATCHER: Starting worker discovery
09:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:43 DISPATCHER: Finished worker discovery
09:48:43 DISPATCHER: Starting worker discovery
09:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:43 DISPATCHER: Finished worker discovery
09:49:43 DISPATCHER: Starting worker discovery
09:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:43 DISPATCHER: Finished worker discovery
09:49:47 WORKER: done with job (9, 0, 5), trying to register it.
09:49:47 WORKER: registered result for job (9, 0, 5) with dispatcher
09:49:47 DISPATCHER: job (9, 0, 5) finished
09:49:47 DISPATCHER: register_result: lock acquired
09:49:47 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:49:47 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9402117969973034, 'info': {'number_mnist': 0.9402117969973034, 'config': "{'batch_size': 32, 'hidden_dim': 905, 'last_n_outputs': 16, 'leak_rate': 0.9207058442103317, 'lr': 0.022747025496868235, 'optimizer': 'SGD', 'sparsity': 0.7523344324714911, 'steps_to_train': 14, 'weight_decay': 0.015855799409185627}"}}
exception: None

09:49:47 job_callback for (9, 0, 5) started
09:49:47 job_callback for (9, 0, 5) got condition
09:49:47 DISPATCHER: Trying to submit another job.
09:49:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:47 HBMASTER: Trying to run another job!
09:49:47 job_callback for (9, 0, 5) finished
09:49:47 HBMASTER: shutdown initiated, shutdown_workers = True
09:49:47 WORKER: shutting down now!
09:49:47 DISPATCHER: Dispatcher shutting down
09:49:47 DISPATCHER: discover_workers shutting down
09:49:47 DISPATCHER: Trying to submit another job.
09:49:47 DISPATCHER: 'discover_worker' thread exited
09:49:47 DISPATCHER: job_runner shutting down
09:49:47 DISPATCHER: 'job_runner' thread exited
09:49:47 DISPATCHER: shut down complete
09:49:47 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f7d4bf89208; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31674>
09:49:47 WORKER: No dispatcher found. Waiting for one to initiate contact.
09:49:47 WORKER: start listening for jobs
09:49:47 wait_for_workers trying to get the condition
09:49:47 DISPATCHER: started the 'discover_worker' thread
09:49:47 DISPATCHER: started the 'job_runner' thread
09:49:47 DISPATCHER: Pyro daemon running on localhost:44999
09:49:47 DISPATCHER: Starting worker discovery
09:49:47 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
09:49:47 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.29881140179544557376
09:49:47 HBMASTER: number of workers changed to 1
09:49:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:47 HBMASTER: only 1 worker(s) available, waiting for at least 1.
09:49:47 adjust_queue_size: lock accquired
09:49:47 HBMASTER: adjusted queue size to (0, 1)
09:49:47 DISPATCHER: Finished worker discovery
09:49:47 DISPATCHER: A new worker triggered discover_worker
09:49:47 DISPATCHER: Trying to submit another job.
09:49:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:47 Enough workers to start this run!
09:49:47 DISPATCHER: Starting worker discovery
09:49:47 HBMASTER: starting run at 1583830187.5134208
09:49:47 start sampling a new configuration.
09:49:47 done sampling a new configuration.
09:49:47 HBMASTER: schedule new run for iteration 0
09:49:47 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
09:49:47 HBMASTER: submitting job (0, 0, 0) to dispatcher
09:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:47 DISPATCHER: trying to submit job (0, 0, 0)
09:49:47 DISPATCHER: Finished worker discovery
09:49:47 DISPATCHER: trying to notify the job_runner thread.
09:49:47 HBMASTER: job (0, 0, 0) submitted to dispatcher
09:49:47 DISPATCHER: Trying to submit another job.
09:49:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:49:47 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:49:47 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:49:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:49:47 WORKER: start processing job (0, 0, 0)
09:49:47 WORKER: args: ()
09:49:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008512423681621549, 'num_filters_1': 46, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.1384606640867405}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:50:43 WORKER: done with job (0, 0, 0), trying to register it.
09:50:43 WORKER: registered result for job (0, 0, 0) with dispatcher
09:50:43 DISPATCHER: job (0, 0, 0) finished
09:50:43 DISPATCHER: register_result: lock acquired
09:50:43 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:50:43 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008512423681621549, 'num_filters_1': 46, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.1384606640867405}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39657037249336424, 'info': {'number_mnist': 0.39657037249336424, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008512423681621549, 'num_filters_1': 46, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.1384606640867405}"}}
exception: None

09:50:43 job_callback for (0, 0, 0) started
09:50:43 job_callback for (0, 0, 0) got condition
09:50:43 DISPATCHER: Trying to submit another job.
09:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:50:43 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:50:43 HBMASTER: Trying to run another job!
09:50:43 job_callback for (0, 0, 0) finished
09:50:43 start sampling a new configuration.
09:50:43 done sampling a new configuration.
09:50:43 HBMASTER: schedule new run for iteration 0
09:50:43 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
09:50:43 HBMASTER: submitting job (0, 0, 1) to dispatcher
09:50:43 DISPATCHER: trying to submit job (0, 0, 1)
09:50:43 DISPATCHER: trying to notify the job_runner thread.
09:50:43 HBMASTER: job (0, 0, 1) submitted to dispatcher
09:50:43 DISPATCHER: Trying to submit another job.
09:50:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:50:43 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:50:43 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:50:43 WORKER: start processing job (0, 0, 1)
09:50:43 WORKER: args: ()
09:50:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008340300771960072, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.03455017141067082, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 43, 'num_filters_3': 26, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:50:47 DISPATCHER: Starting worker discovery
09:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:47 DISPATCHER: Finished worker discovery
09:51:37 WORKER: done with job (0, 0, 1), trying to register it.
09:51:37 WORKER: registered result for job (0, 0, 1) with dispatcher
09:51:37 DISPATCHER: job (0, 0, 1) finished
09:51:37 DISPATCHER: register_result: lock acquired
09:51:37 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:51:37 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008340300771960072, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.03455017141067082, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 43, 'num_filters_3': 26, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008340300771960072, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.03455017141067082, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 43, 'num_filters_3': 26, 'num_filters_4': 32}"}}
exception: None

09:51:37 job_callback for (0, 0, 1) started
09:51:37 DISPATCHER: Trying to submit another job.
09:51:37 job_callback for (0, 0, 1) got condition
09:51:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:37 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:51:37 HBMASTER: Trying to run another job!
09:51:37 job_callback for (0, 0, 1) finished
09:51:37 start sampling a new configuration.
09:51:37 done sampling a new configuration.
09:51:37 HBMASTER: schedule new run for iteration 0
09:51:37 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
09:51:37 HBMASTER: submitting job (0, 0, 2) to dispatcher
09:51:37 DISPATCHER: trying to submit job (0, 0, 2)
09:51:37 DISPATCHER: trying to notify the job_runner thread.
09:51:37 HBMASTER: job (0, 0, 2) submitted to dispatcher
09:51:37 DISPATCHER: Trying to submit another job.
09:51:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:37 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:51:37 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:51:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:37 WORKER: start processing job (0, 0, 2)
09:51:37 WORKER: args: ()
09:51:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004661488027735711, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.08777387726618863, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 96, 'num_filters_3': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:51:47 DISPATCHER: Starting worker discovery
09:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:47 DISPATCHER: Finished worker discovery
09:52:32 WORKER: done with job (0, 0, 2), trying to register it.
09:52:32 WORKER: registered result for job (0, 0, 2) with dispatcher
09:52:32 DISPATCHER: job (0, 0, 2) finished
09:52:32 DISPATCHER: register_result: lock acquired
09:52:32 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:52:32 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004661488027735711, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.08777387726618863, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 96, 'num_filters_3': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09043904370570528, 'info': {'number_mnist': 0.09043904370570528, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004661488027735711, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.08777387726618863, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 96, 'num_filters_3': 106}"}}
exception: None

09:52:32 job_callback for (0, 0, 2) started
09:52:32 job_callback for (0, 0, 2) got condition
09:52:32 DISPATCHER: Trying to submit another job.
09:52:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:52:32 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:52:32 HBMASTER: Trying to run another job!
09:52:32 job_callback for (0, 0, 2) finished
09:52:32 start sampling a new configuration.
09:52:32 done sampling a new configuration.
09:52:32 HBMASTER: schedule new run for iteration 0
09:52:32 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
09:52:32 HBMASTER: submitting job (0, 0, 3) to dispatcher
09:52:32 DISPATCHER: trying to submit job (0, 0, 3)
09:52:32 DISPATCHER: trying to notify the job_runner thread.
09:52:32 HBMASTER: job (0, 0, 3) submitted to dispatcher
09:52:32 DISPATCHER: Trying to submit another job.
09:52:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:52:32 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:52:32 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:52:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:52:32 WORKER: start processing job (0, 0, 3)
09:52:32 WORKER: args: ()
09:52:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011220023779767877, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.03738010403481854}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:52:47 DISPATCHER: Starting worker discovery
09:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:47 DISPATCHER: Finished worker discovery
09:53:26 WORKER: done with job (0, 0, 3), trying to register it.
09:53:26 WORKER: registered result for job (0, 0, 3) with dispatcher
09:53:26 DISPATCHER: job (0, 0, 3) finished
09:53:26 DISPATCHER: register_result: lock acquired
09:53:26 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:53:26 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011220023779767877, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.03738010403481854}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.462394279632336, 'info': {'number_mnist': 0.462394279632336, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011220023779767877, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.03738010403481854}"}}
exception: None

09:53:26 job_callback for (0, 0, 3) started
09:53:26 job_callback for (0, 0, 3) got condition
09:53:26 DISPATCHER: Trying to submit another job.
09:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:53:26 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:53:26 HBMASTER: Trying to run another job!
09:53:26 job_callback for (0, 0, 3) finished
09:53:26 start sampling a new configuration.
09:53:26 done sampling a new configuration.
09:53:26 HBMASTER: schedule new run for iteration 0
09:53:26 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
09:53:26 HBMASTER: submitting job (0, 0, 4) to dispatcher
09:53:26 DISPATCHER: trying to submit job (0, 0, 4)
09:53:26 DISPATCHER: trying to notify the job_runner thread.
09:53:26 HBMASTER: job (0, 0, 4) submitted to dispatcher
09:53:26 DISPATCHER: Trying to submit another job.
09:53:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:53:26 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:53:26 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:53:26 WORKER: start processing job (0, 0, 4)
09:53:26 WORKER: args: ()
09:53:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001294816494638346, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.018796304059183387}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:53:47 DISPATCHER: Starting worker discovery
09:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:47 DISPATCHER: Finished worker discovery
09:54:19 WORKER: done with job (0, 0, 4), trying to register it.
09:54:19 WORKER: registered result for job (0, 0, 4) with dispatcher
09:54:19 DISPATCHER: job (0, 0, 4) finished
09:54:19 DISPATCHER: register_result: lock acquired
09:54:19 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:54:19 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001294816494638346, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.018796304059183387}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9172513740105388, 'info': {'number_mnist': 0.9172513740105388, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001294816494638346, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.018796304059183387}"}}
exception: None

09:54:19 job_callback for (0, 0, 4) started
09:54:19 DISPATCHER: Trying to submit another job.
09:54:19 job_callback for (0, 0, 4) got condition
09:54:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:54:19 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:54:19 HBMASTER: Trying to run another job!
09:54:19 job_callback for (0, 0, 4) finished
09:54:19 start sampling a new configuration.
09:54:19 done sampling a new configuration.
09:54:19 HBMASTER: schedule new run for iteration 0
09:54:19 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
09:54:19 HBMASTER: submitting job (0, 0, 5) to dispatcher
09:54:19 DISPATCHER: trying to submit job (0, 0, 5)
09:54:19 DISPATCHER: trying to notify the job_runner thread.
09:54:19 HBMASTER: job (0, 0, 5) submitted to dispatcher
09:54:19 DISPATCHER: Trying to submit another job.
09:54:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:54:19 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:54:19 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:54:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:54:19 WORKER: start processing job (0, 0, 5)
09:54:19 WORKER: args: ()
09:54:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04215016010288545, 'num_filters_1': 73, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03612828854744237, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:54:47 DISPATCHER: Starting worker discovery
09:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:47 DISPATCHER: Finished worker discovery
09:55:14 WORKER: done with job (0, 0, 5), trying to register it.
09:55:14 WORKER: registered result for job (0, 0, 5) with dispatcher
09:55:14 DISPATCHER: job (0, 0, 5) finished
09:55:14 DISPATCHER: register_result: lock acquired
09:55:14 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:55:14 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04215016010288545, 'num_filters_1': 73, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03612828854744237, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.023505966043172177, 'info': {'number_mnist': 0.023505966043172177, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04215016010288545, 'num_filters_1': 73, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03612828854744237, 'kernel_size_2': 7, 'num_filters_2': 33}"}}
exception: None

09:55:14 job_callback for (0, 0, 5) started
09:55:14 DISPATCHER: Trying to submit another job.
09:55:14 job_callback for (0, 0, 5) got condition
09:55:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:14 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:55:14 HBMASTER: Trying to run another job!
09:55:14 job_callback for (0, 0, 5) finished
09:55:14 start sampling a new configuration.
09:55:14 done sampling a new configuration.
09:55:14 HBMASTER: schedule new run for iteration 0
09:55:14 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
09:55:14 HBMASTER: submitting job (0, 0, 6) to dispatcher
09:55:14 DISPATCHER: trying to submit job (0, 0, 6)
09:55:14 DISPATCHER: trying to notify the job_runner thread.
09:55:14 HBMASTER: job (0, 0, 6) submitted to dispatcher
09:55:14 DISPATCHER: Trying to submit another job.
09:55:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:14 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:55:14 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:55:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:14 WORKER: start processing job (0, 0, 6)
09:55:14 WORKER: args: ()
09:55:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012687894121124352, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.08607546916938469, 'kernel_size_2': 3, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:55:47 DISPATCHER: Starting worker discovery
09:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:47 DISPATCHER: Finished worker discovery
09:56:06 WORKER: done with job (0, 0, 6), trying to register it.
09:56:06 WORKER: registered result for job (0, 0, 6) with dispatcher
09:56:06 DISPATCHER: job (0, 0, 6) finished
09:56:06 DISPATCHER: register_result: lock acquired
09:56:06 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:56:06 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012687894121124352, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.08607546916938469, 'kernel_size_2': 3, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4975284246749385, 'info': {'number_mnist': 0.4975284246749385, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012687894121124352, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.08607546916938469, 'kernel_size_2': 3, 'num_filters_2': 29}"}}
exception: None

09:56:06 job_callback for (0, 0, 6) started
09:56:06 DISPATCHER: Trying to submit another job.
09:56:06 job_callback for (0, 0, 6) got condition
09:56:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:56:06 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:56:06 HBMASTER: Trying to run another job!
09:56:06 job_callback for (0, 0, 6) finished
09:56:06 start sampling a new configuration.
09:56:06 done sampling a new configuration.
09:56:06 HBMASTER: schedule new run for iteration 0
09:56:06 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
09:56:06 HBMASTER: submitting job (0, 0, 7) to dispatcher
09:56:06 DISPATCHER: trying to submit job (0, 0, 7)
09:56:06 DISPATCHER: trying to notify the job_runner thread.
09:56:06 HBMASTER: job (0, 0, 7) submitted to dispatcher
09:56:06 DISPATCHER: Trying to submit another job.
09:56:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:56:06 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:56:06 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:56:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:56:06 WORKER: start processing job (0, 0, 7)
09:56:06 WORKER: args: ()
09:56:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03175237681663815, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.12668377381566082, 'kernel_size_2': 7, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:56:47 DISPATCHER: Starting worker discovery
09:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:47 DISPATCHER: Finished worker discovery
09:57:02 WORKER: done with job (0, 0, 7), trying to register it.
09:57:02 WORKER: registered result for job (0, 0, 7) with dispatcher
09:57:02 DISPATCHER: job (0, 0, 7) finished
09:57:02 DISPATCHER: register_result: lock acquired
09:57:02 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:57:02 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03175237681663815, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.12668377381566082, 'kernel_size_2': 7, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07398942179387054, 'info': {'number_mnist': 0.07398942179387054, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03175237681663815, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.12668377381566082, 'kernel_size_2': 7, 'num_filters_2': 16}"}}
exception: None

09:57:02 job_callback for (0, 0, 7) started
09:57:02 job_callback for (0, 0, 7) got condition
09:57:02 DISPATCHER: Trying to submit another job.
09:57:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:57:02 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:57:02 HBMASTER: Trying to run another job!
09:57:02 job_callback for (0, 0, 7) finished
09:57:02 start sampling a new configuration.
09:57:02 done sampling a new configuration.
09:57:02 HBMASTER: schedule new run for iteration 0
09:57:02 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
09:57:02 HBMASTER: submitting job (0, 0, 8) to dispatcher
09:57:02 DISPATCHER: trying to submit job (0, 0, 8)
09:57:02 DISPATCHER: trying to notify the job_runner thread.
09:57:02 HBMASTER: job (0, 0, 8) submitted to dispatcher
09:57:02 DISPATCHER: Trying to submit another job.
09:57:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:57:02 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:57:02 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:57:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:57:02 WORKER: start processing job (0, 0, 8)
09:57:02 WORKER: args: ()
09:57:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.014320924847913516, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.021626539737059098, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 92, 'num_filters_4': 30, 'num_filters_5': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:57:47 DISPATCHER: Starting worker discovery
09:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:47 DISPATCHER: Finished worker discovery
09:57:56 WORKER: done with job (0, 0, 8), trying to register it.
09:57:56 WORKER: registered result for job (0, 0, 8) with dispatcher
09:57:56 DISPATCHER: job (0, 0, 8) finished
09:57:56 DISPATCHER: register_result: lock acquired
09:57:56 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:57:56 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.014320924847913516, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.021626539737059098, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 92, 'num_filters_4': 30, 'num_filters_5': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.014320924847913516, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.021626539737059098, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 92, 'num_filters_4': 30, 'num_filters_5': 24}"}}
exception: None

09:57:56 job_callback for (0, 0, 8) started
09:57:56 DISPATCHER: Trying to submit another job.
09:57:56 job_callback for (0, 0, 8) got condition
09:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:57:56 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:57:56 HBMASTER: Trying to run another job!
09:57:56 job_callback for (0, 0, 8) finished
09:57:56 start sampling a new configuration.
09:57:56 done sampling a new configuration.
09:57:56 HBMASTER: schedule new run for iteration 0
09:57:56 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
09:57:56 HBMASTER: submitting job (0, 0, 9) to dispatcher
09:57:56 DISPATCHER: trying to submit job (0, 0, 9)
09:57:56 DISPATCHER: trying to notify the job_runner thread.
09:57:56 HBMASTER: job (0, 0, 9) submitted to dispatcher
09:57:56 DISPATCHER: Trying to submit another job.
09:57:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:57:56 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:57:56 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:57:56 WORKER: start processing job (0, 0, 9)
09:57:56 WORKER: args: ()
09:57:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.008536288283384175, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.052526770264497855, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 64, 'num_filters_3': 30, 'num_filters_4': 43, 'num_filters_5': 93}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:58:47 DISPATCHER: Starting worker discovery
09:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:47 DISPATCHER: Finished worker discovery
09:58:50 WORKER: done with job (0, 0, 9), trying to register it.
09:58:50 WORKER: registered result for job (0, 0, 9) with dispatcher
09:58:50 DISPATCHER: job (0, 0, 9) finished
09:58:50 DISPATCHER: register_result: lock acquired
09:58:50 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:58:50 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.008536288283384175, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.052526770264497855, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 64, 'num_filters_3': 30, 'num_filters_4': 43, 'num_filters_5': 93}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5441955885831401, 'info': {'number_mnist': 0.5441955885831401, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.008536288283384175, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.052526770264497855, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 64, 'num_filters_3': 30, 'num_filters_4': 43, 'num_filters_5': 93}"}}
exception: None

09:58:50 job_callback for (0, 0, 9) started
09:58:50 DISPATCHER: Trying to submit another job.
09:58:50 job_callback for (0, 0, 9) got condition
09:58:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:58:50 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:58:50 HBMASTER: Trying to run another job!
09:58:50 job_callback for (0, 0, 9) finished
09:58:50 start sampling a new configuration.
09:58:50 done sampling a new configuration.
09:58:50 HBMASTER: schedule new run for iteration 0
09:58:50 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
09:58:50 HBMASTER: submitting job (0, 0, 10) to dispatcher
09:58:50 DISPATCHER: trying to submit job (0, 0, 10)
09:58:50 DISPATCHER: trying to notify the job_runner thread.
09:58:50 HBMASTER: job (0, 0, 10) submitted to dispatcher
09:58:50 DISPATCHER: Trying to submit another job.
09:58:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:58:50 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:58:50 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:58:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:58:50 WORKER: start processing job (0, 0, 10)
09:58:50 WORKER: args: ()
09:58:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0067759363774171685, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.041461895193255126, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 93, 'num_filters_3': 54, 'num_filters_4': 27, 'num_filters_5': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:59:44 WORKER: done with job (0, 0, 10), trying to register it.
09:59:44 WORKER: registered result for job (0, 0, 10) with dispatcher
09:59:44 DISPATCHER: job (0, 0, 10) finished
09:59:44 DISPATCHER: register_result: lock acquired
09:59:44 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:59:44 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0067759363774171685, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.041461895193255126, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 93, 'num_filters_3': 54, 'num_filters_4': 27, 'num_filters_5': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5603198189065407, 'info': {'number_mnist': 0.5603198189065407, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0067759363774171685, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.041461895193255126, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 93, 'num_filters_3': 54, 'num_filters_4': 27, 'num_filters_5': 111}"}}
exception: None

09:59:44 job_callback for (0, 0, 10) started
09:59:44 job_callback for (0, 0, 10) got condition
09:59:44 DISPATCHER: Trying to submit another job.
09:59:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:44 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:59:44 HBMASTER: Trying to run another job!
09:59:44 job_callback for (0, 0, 10) finished
09:59:44 start sampling a new configuration.
09:59:44 done sampling a new configuration.
09:59:44 HBMASTER: schedule new run for iteration 0
09:59:44 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
09:59:44 HBMASTER: submitting job (0, 0, 11) to dispatcher
09:59:44 DISPATCHER: trying to submit job (0, 0, 11)
09:59:44 DISPATCHER: trying to notify the job_runner thread.
09:59:44 HBMASTER: job (0, 0, 11) submitted to dispatcher
09:59:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:44 DISPATCHER: Trying to submit another job.
09:59:44 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:59:44 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:59:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:44 WORKER: start processing job (0, 0, 11)
09:59:44 WORKER: args: ()
09:59:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004868305453900309, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02673221684634609, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:59:47 DISPATCHER: Starting worker discovery
09:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:47 DISPATCHER: Finished worker discovery
10:00:37 WORKER: done with job (0, 0, 11), trying to register it.
10:00:37 WORKER: registered result for job (0, 0, 11) with dispatcher
10:00:37 DISPATCHER: job (0, 0, 11) finished
10:00:37 DISPATCHER: register_result: lock acquired
10:00:37 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:00:37 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004868305453900309, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02673221684634609, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9159708493844103, 'info': {'number_mnist': 0.9159708493844103, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004868305453900309, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02673221684634609, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 25}"}}
exception: None

10:00:37 job_callback for (0, 0, 11) started
10:00:37 job_callback for (0, 0, 11) got condition
10:00:37 DISPATCHER: Trying to submit another job.
10:00:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:00:37 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:00:37 HBMASTER: Trying to run another job!
10:00:37 job_callback for (0, 0, 11) finished
10:00:37 start sampling a new configuration.
10:00:37 done sampling a new configuration.
10:00:37 HBMASTER: schedule new run for iteration 0
10:00:37 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
10:00:37 HBMASTER: submitting job (0, 0, 12) to dispatcher
10:00:37 DISPATCHER: trying to submit job (0, 0, 12)
10:00:37 DISPATCHER: trying to notify the job_runner thread.
10:00:37 HBMASTER: job (0, 0, 12) submitted to dispatcher
10:00:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:00:37 DISPATCHER: Trying to submit another job.
10:00:37 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:00:37 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:00:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:00:37 WORKER: start processing job (0, 0, 12)
10:00:37 WORKER: args: ()
10:00:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017949854700723723, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1180395982469779}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:00:47 DISPATCHER: Starting worker discovery
10:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:47 DISPATCHER: Finished worker discovery
10:01:31 WORKER: done with job (0, 0, 12), trying to register it.
10:01:31 WORKER: registered result for job (0, 0, 12) with dispatcher
10:01:31 DISPATCHER: job (0, 0, 12) finished
10:01:31 DISPATCHER: register_result: lock acquired
10:01:31 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:01:31 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017949854700723723, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1180395982469779}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48469061549131476, 'info': {'number_mnist': 0.48469061549131476, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017949854700723723, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1180395982469779}"}}
exception: None

10:01:31 job_callback for (0, 0, 12) started
10:01:31 DISPATCHER: Trying to submit another job.
10:01:31 job_callback for (0, 0, 12) got condition
10:01:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:01:31 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:01:31 HBMASTER: Trying to run another job!
10:01:31 job_callback for (0, 0, 12) finished
10:01:31 start sampling a new configuration.
10:01:31 done sampling a new configuration.
10:01:31 HBMASTER: schedule new run for iteration 0
10:01:31 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:01:31 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:01:31 DISPATCHER: trying to submit job (0, 0, 13)
10:01:31 DISPATCHER: trying to notify the job_runner thread.
10:01:31 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:01:31 DISPATCHER: Trying to submit another job.
10:01:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:01:31 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:01:31 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:01:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:01:31 WORKER: start processing job (0, 0, 13)
10:01:31 WORKER: args: ()
10:01:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:01:47 DISPATCHER: Starting worker discovery
10:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:47 DISPATCHER: Finished worker discovery
10:02:26 WORKER: done with job (0, 0, 13), trying to register it.
10:02:26 WORKER: registered result for job (0, 0, 13) with dispatcher
10:02:26 DISPATCHER: job (0, 0, 13) finished
10:02:26 DISPATCHER: register_result: lock acquired
10:02:26 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:02:26 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9345348123248876, 'info': {'number_mnist': 0.9345348123248876, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}"}}
exception: None

10:02:26 job_callback for (0, 0, 13) started
10:02:26 job_callback for (0, 0, 13) got condition
10:02:26 DISPATCHER: Trying to submit another job.
10:02:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:26 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:02:26 HBMASTER: Trying to run another job!
10:02:26 job_callback for (0, 0, 13) finished
10:02:26 start sampling a new configuration.
10:02:26 done sampling a new configuration.
10:02:26 HBMASTER: schedule new run for iteration 0
10:02:26 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
10:02:26 HBMASTER: submitting job (0, 0, 14) to dispatcher
10:02:26 DISPATCHER: trying to submit job (0, 0, 14)
10:02:26 DISPATCHER: trying to notify the job_runner thread.
10:02:26 HBMASTER: job (0, 0, 14) submitted to dispatcher
10:02:26 DISPATCHER: Trying to submit another job.
10:02:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:26 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:02:26 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:02:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:26 WORKER: start processing job (0, 0, 14)
10:02:26 WORKER: args: ()
10:02:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08193671415580978, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.023589072021286194, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 122, 'num_filters_4': 16, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:02:47 DISPATCHER: Starting worker discovery
10:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:47 DISPATCHER: Finished worker discovery
10:03:19 WORKER: done with job (0, 0, 14), trying to register it.
10:03:19 WORKER: registered result for job (0, 0, 14) with dispatcher
10:03:19 DISPATCHER: job (0, 0, 14) finished
10:03:19 DISPATCHER: register_result: lock acquired
10:03:19 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:03:19 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08193671415580978, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.023589072021286194, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 122, 'num_filters_4': 16, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 4.86889751981507e-05, 'info': {'number_mnist': -4.86889751981507e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08193671415580978, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.023589072021286194, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 122, 'num_filters_4': 16, 'num_filters_5': 36}"}}
exception: None

10:03:19 job_callback for (0, 0, 14) started
10:03:19 DISPATCHER: Trying to submit another job.
10:03:19 job_callback for (0, 0, 14) got condition
10:03:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:03:19 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:03:19 HBMASTER: Trying to run another job!
10:03:19 job_callback for (0, 0, 14) finished
10:03:19 start sampling a new configuration.
10:03:19 done sampling a new configuration.
10:03:19 HBMASTER: schedule new run for iteration 0
10:03:19 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
10:03:19 HBMASTER: submitting job (0, 0, 15) to dispatcher
10:03:19 DISPATCHER: trying to submit job (0, 0, 15)
10:03:19 DISPATCHER: trying to notify the job_runner thread.
10:03:19 HBMASTER: job (0, 0, 15) submitted to dispatcher
10:03:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:03:19 DISPATCHER: Trying to submit another job.
10:03:19 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:03:19 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:03:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:03:19 WORKER: start processing job (0, 0, 15)
10:03:19 WORKER: args: ()
10:03:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09462344431781579, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.1306877233635718, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 27, 'num_filters_4': 24, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:03:47 DISPATCHER: Starting worker discovery
10:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:47 DISPATCHER: Finished worker discovery
10:04:13 WORKER: done with job (0, 0, 15), trying to register it.
10:04:13 WORKER: registered result for job (0, 0, 15) with dispatcher
10:04:13 DISPATCHER: job (0, 0, 15) finished
10:04:13 DISPATCHER: register_result: lock acquired
10:04:13 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:04:13 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09462344431781579, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.1306877233635718, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 27, 'num_filters_4': 24, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09462344431781579, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.1306877233635718, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 27, 'num_filters_4': 24, 'num_filters_5': 23}"}}
exception: None

10:04:13 job_callback for (0, 0, 15) started
10:04:13 job_callback for (0, 0, 15) got condition
10:04:13 DISPATCHER: Trying to submit another job.
10:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:04:13 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:04:13 HBMASTER: Trying to run another job!
10:04:13 job_callback for (0, 0, 15) finished
10:04:13 start sampling a new configuration.
10:04:13 done sampling a new configuration.
10:04:13 HBMASTER: schedule new run for iteration 0
10:04:13 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
10:04:13 HBMASTER: submitting job (0, 0, 16) to dispatcher
10:04:13 DISPATCHER: trying to submit job (0, 0, 16)
10:04:13 DISPATCHER: trying to notify the job_runner thread.
10:04:13 HBMASTER: job (0, 0, 16) submitted to dispatcher
10:04:13 DISPATCHER: Trying to submit another job.
10:04:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:04:13 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:04:13 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:04:13 WORKER: start processing job (0, 0, 16)
10:04:13 WORKER: args: ()
10:04:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008418610013429908, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.09922065933175665, 'kernel_size_2': 7, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:04:47 DISPATCHER: Starting worker discovery
10:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:47 DISPATCHER: Finished worker discovery
10:05:07 WORKER: done with job (0, 0, 16), trying to register it.
10:05:07 WORKER: registered result for job (0, 0, 16) with dispatcher
10:05:07 DISPATCHER: job (0, 0, 16) finished
10:05:07 DISPATCHER: register_result: lock acquired
10:05:07 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:05:07 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008418610013429908, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.09922065933175665, 'kernel_size_2': 7, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1471540083802891, 'info': {'number_mnist': 0.1471540083802891, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008418610013429908, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.09922065933175665, 'kernel_size_2': 7, 'num_filters_2': 74}"}}
exception: None

10:05:07 job_callback for (0, 0, 16) started
10:05:07 DISPATCHER: Trying to submit another job.
10:05:07 job_callback for (0, 0, 16) got condition
10:05:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:05:07 HBMASTER: Trying to run another job!
10:05:07 job_callback for (0, 0, 16) finished
10:05:07 start sampling a new configuration.
10:05:07 done sampling a new configuration.
10:05:07 HBMASTER: schedule new run for iteration 0
10:05:07 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
10:05:07 HBMASTER: submitting job (0, 0, 17) to dispatcher
10:05:07 DISPATCHER: trying to submit job (0, 0, 17)
10:05:07 DISPATCHER: trying to notify the job_runner thread.
10:05:07 HBMASTER: job (0, 0, 17) submitted to dispatcher
10:05:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:05:07 DISPATCHER: Trying to submit another job.
10:05:07 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:05:07 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:05:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:05:07 WORKER: start processing job (0, 0, 17)
10:05:07 WORKER: args: ()
10:05:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.027520798437307308, 'num_filters_1': 72, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.013642010372224293, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 109, 'num_filters_3': 39, 'num_filters_4': 29, 'num_filters_5': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:05:47 DISPATCHER: Starting worker discovery
10:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:47 DISPATCHER: Finished worker discovery
10:06:02 WORKER: done with job (0, 0, 17), trying to register it.
10:06:02 WORKER: registered result for job (0, 0, 17) with dispatcher
10:06:02 DISPATCHER: job (0, 0, 17) finished
10:06:02 DISPATCHER: register_result: lock acquired
10:06:02 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:06:02 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.027520798437307308, 'num_filters_1': 72, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.013642010372224293, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 109, 'num_filters_3': 39, 'num_filters_4': 29, 'num_filters_5': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.027520798437307308, 'num_filters_1': 72, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.013642010372224293, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 109, 'num_filters_3': 39, 'num_filters_4': 29, 'num_filters_5': 113}"}}
exception: None

10:06:02 job_callback for (0, 0, 17) started
10:06:02 DISPATCHER: Trying to submit another job.
10:06:02 job_callback for (0, 0, 17) got condition
10:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:06:02 HBMASTER: Trying to run another job!
10:06:02 job_callback for (0, 0, 17) finished
10:06:02 start sampling a new configuration.
10:06:02 done sampling a new configuration.
10:06:02 HBMASTER: schedule new run for iteration 0
10:06:02 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
10:06:02 HBMASTER: submitting job (0, 0, 18) to dispatcher
10:06:02 DISPATCHER: trying to submit job (0, 0, 18)
10:06:02 DISPATCHER: trying to notify the job_runner thread.
10:06:02 HBMASTER: job (0, 0, 18) submitted to dispatcher
10:06:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:06:02 DISPATCHER: Trying to submit another job.
10:06:02 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:06:02 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:06:02 WORKER: start processing job (0, 0, 18)
10:06:02 WORKER: args: ()
10:06:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020387700717751224, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.038097384750370465, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:06:47 DISPATCHER: Starting worker discovery
10:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:47 DISPATCHER: Finished worker discovery
10:06:56 WORKER: done with job (0, 0, 18), trying to register it.
10:06:56 WORKER: registered result for job (0, 0, 18) with dispatcher
10:06:56 DISPATCHER: job (0, 0, 18) finished
10:06:56 DISPATCHER: register_result: lock acquired
10:06:56 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:06:56 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020387700717751224, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.038097384750370465, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7445919372695707, 'info': {'number_mnist': 0.7445919372695707, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020387700717751224, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.038097384750370465, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

10:06:56 job_callback for (0, 0, 18) started
10:06:56 job_callback for (0, 0, 18) got condition
10:06:56 DISPATCHER: Trying to submit another job.
10:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:06:56 HBMASTER: Trying to run another job!
10:06:56 job_callback for (0, 0, 18) finished
10:06:56 start sampling a new configuration.
10:06:56 done sampling a new configuration.
10:06:56 HBMASTER: schedule new run for iteration 0
10:06:56 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
10:06:56 HBMASTER: submitting job (0, 0, 19) to dispatcher
10:06:56 DISPATCHER: trying to submit job (0, 0, 19)
10:06:56 DISPATCHER: trying to notify the job_runner thread.
10:06:56 HBMASTER: job (0, 0, 19) submitted to dispatcher
10:06:56 DISPATCHER: Trying to submit another job.
10:06:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:06:56 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:06:56 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:06:56 WORKER: start processing job (0, 0, 19)
10:06:56 WORKER: args: ()
10:06:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02938989010214065, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.09460733442281559, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 42, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:07:47 DISPATCHER: Starting worker discovery
10:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:47 DISPATCHER: Finished worker discovery
10:07:51 WORKER: done with job (0, 0, 19), trying to register it.
10:07:51 WORKER: registered result for job (0, 0, 19) with dispatcher
10:07:51 DISPATCHER: job (0, 0, 19) finished
10:07:51 DISPATCHER: register_result: lock acquired
10:07:51 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:07:51 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02938989010214065, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.09460733442281559, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 42, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02938989010214065, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.09460733442281559, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 42, 'num_filters_3': 68}"}}
exception: None

10:07:51 job_callback for (0, 0, 19) started
10:07:51 job_callback for (0, 0, 19) got condition
10:07:51 DISPATCHER: Trying to submit another job.
10:07:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:07:51 HBMASTER: Trying to run another job!
10:07:51 job_callback for (0, 0, 19) finished
10:07:51 start sampling a new configuration.
10:07:51 done sampling a new configuration.
10:07:51 HBMASTER: schedule new run for iteration 0
10:07:51 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
10:07:51 HBMASTER: submitting job (0, 0, 20) to dispatcher
10:07:51 DISPATCHER: trying to submit job (0, 0, 20)
10:07:51 DISPATCHER: trying to notify the job_runner thread.
10:07:51 HBMASTER: job (0, 0, 20) submitted to dispatcher
10:07:51 DISPATCHER: Trying to submit another job.
10:07:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:07:51 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:07:51 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:07:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:07:51 WORKER: start processing job (0, 0, 20)
10:07:51 WORKER: args: ()
10:07:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004578994067608454, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.02732439430338216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 84, 'num_filters_4': 40, 'num_filters_5': 116}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:08:45 WORKER: done with job (0, 0, 20), trying to register it.
10:08:45 WORKER: registered result for job (0, 0, 20) with dispatcher
10:08:45 DISPATCHER: job (0, 0, 20) finished
10:08:45 DISPATCHER: register_result: lock acquired
10:08:45 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:08:45 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004578994067608454, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.02732439430338216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 84, 'num_filters_4': 40, 'num_filters_5': 116}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6928212470381437, 'info': {'number_mnist': 0.6928212470381437, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004578994067608454, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.02732439430338216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 84, 'num_filters_4': 40, 'num_filters_5': 116}"}}
exception: None

10:08:45 job_callback for (0, 0, 20) started
10:08:45 DISPATCHER: Trying to submit another job.
10:08:45 job_callback for (0, 0, 20) got condition
10:08:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:08:45 HBMASTER: Trying to run another job!
10:08:45 job_callback for (0, 0, 20) finished
10:08:45 start sampling a new configuration.
10:08:45 done sampling a new configuration.
10:08:45 HBMASTER: schedule new run for iteration 0
10:08:45 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
10:08:45 HBMASTER: submitting job (0, 0, 21) to dispatcher
10:08:45 DISPATCHER: trying to submit job (0, 0, 21)
10:08:45 DISPATCHER: trying to notify the job_runner thread.
10:08:45 HBMASTER: job (0, 0, 21) submitted to dispatcher
10:08:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:08:45 DISPATCHER: Trying to submit another job.
10:08:45 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:08:45 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:08:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:08:45 WORKER: start processing job (0, 0, 21)
10:08:45 WORKER: args: ()
10:08:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:08:47 DISPATCHER: Starting worker discovery
10:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:47 DISPATCHER: Finished worker discovery
10:09:38 WORKER: done with job (0, 0, 21), trying to register it.
10:09:38 WORKER: registered result for job (0, 0, 21) with dispatcher
10:09:38 DISPATCHER: job (0, 0, 21) finished
10:09:38 DISPATCHER: register_result: lock acquired
10:09:38 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:09:38 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9335442480342078, 'info': {'number_mnist': 0.9335442480342078, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}"}}
exception: None

10:09:38 job_callback for (0, 0, 21) started
10:09:38 DISPATCHER: Trying to submit another job.
10:09:38 job_callback for (0, 0, 21) got condition
10:09:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:09:38 HBMASTER: Trying to run another job!
10:09:38 job_callback for (0, 0, 21) finished
10:09:38 start sampling a new configuration.
10:09:38 done sampling a new configuration.
10:09:38 HBMASTER: schedule new run for iteration 0
10:09:38 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
10:09:38 HBMASTER: submitting job (0, 0, 22) to dispatcher
10:09:38 DISPATCHER: trying to submit job (0, 0, 22)
10:09:38 DISPATCHER: trying to notify the job_runner thread.
10:09:38 HBMASTER: job (0, 0, 22) submitted to dispatcher
10:09:38 DISPATCHER: Trying to submit another job.
10:09:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:09:38 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:09:38 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:09:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:09:38 WORKER: start processing job (0, 0, 22)
10:09:38 WORKER: args: ()
10:09:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012765551817581742, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.06664543853420139, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 74, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:09:47 DISPATCHER: Starting worker discovery
10:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:47 DISPATCHER: Finished worker discovery
10:10:32 WORKER: done with job (0, 0, 22), trying to register it.
10:10:32 WORKER: registered result for job (0, 0, 22) with dispatcher
10:10:32 DISPATCHER: job (0, 0, 22) finished
10:10:32 DISPATCHER: register_result: lock acquired
10:10:32 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:10:32 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012765551817581742, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.06664543853420139, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 74, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27217375832549073, 'info': {'number_mnist': 0.27217375832549073, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012765551817581742, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.06664543853420139, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 74, 'num_filters_3': 27}"}}
exception: None

10:10:32 job_callback for (0, 0, 22) started
10:10:32 job_callback for (0, 0, 22) got condition
10:10:32 DISPATCHER: Trying to submit another job.
10:10:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:10:32 HBMASTER: Trying to run another job!
10:10:32 job_callback for (0, 0, 22) finished
10:10:32 start sampling a new configuration.
10:10:32 done sampling a new configuration.
10:10:32 HBMASTER: schedule new run for iteration 0
10:10:32 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
10:10:32 HBMASTER: submitting job (0, 0, 23) to dispatcher
10:10:32 DISPATCHER: trying to submit job (0, 0, 23)
10:10:32 DISPATCHER: trying to notify the job_runner thread.
10:10:32 HBMASTER: job (0, 0, 23) submitted to dispatcher
10:10:32 DISPATCHER: Trying to submit another job.
10:10:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:10:32 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:10:32 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:10:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:10:32 WORKER: start processing job (0, 0, 23)
10:10:32 WORKER: args: ()
10:10:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08025176532587862, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05452880312618445, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 114, 'num_filters_3': 64, 'num_filters_4': 20, 'num_filters_5': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:10:47 DISPATCHER: Starting worker discovery
10:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:47 DISPATCHER: Finished worker discovery
10:11:25 WORKER: done with job (0, 0, 23), trying to register it.
10:11:25 WORKER: registered result for job (0, 0, 23) with dispatcher
10:11:25 DISPATCHER: job (0, 0, 23) finished
10:11:25 DISPATCHER: register_result: lock acquired
10:11:25 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:11:25 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08025176532587862, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05452880312618445, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 114, 'num_filters_3': 64, 'num_filters_4': 20, 'num_filters_5': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.028458396572720514, 'info': {'number_mnist': 0.028458396572720514, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08025176532587862, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05452880312618445, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 114, 'num_filters_3': 64, 'num_filters_4': 20, 'num_filters_5': 119}"}}
exception: None

10:11:25 job_callback for (0, 0, 23) started
10:11:25 job_callback for (0, 0, 23) got condition
10:11:25 DISPATCHER: Trying to submit another job.
10:11:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:11:25 HBMASTER: Trying to run another job!
10:11:25 job_callback for (0, 0, 23) finished
10:11:25 start sampling a new configuration.
10:11:25 done sampling a new configuration.
10:11:25 HBMASTER: schedule new run for iteration 0
10:11:25 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
10:11:25 HBMASTER: submitting job (0, 0, 24) to dispatcher
10:11:25 DISPATCHER: trying to submit job (0, 0, 24)
10:11:25 DISPATCHER: trying to notify the job_runner thread.
10:11:25 HBMASTER: job (0, 0, 24) submitted to dispatcher
10:11:25 DISPATCHER: Trying to submit another job.
10:11:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:11:25 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:11:25 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:11:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:11:25 WORKER: start processing job (0, 0, 24)
10:11:25 WORKER: args: ()
10:11:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01708423499822727, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.04039487851179355}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:11:47 DISPATCHER: Starting worker discovery
10:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:47 DISPATCHER: Finished worker discovery
10:12:24 WORKER: done with job (0, 0, 24), trying to register it.
10:12:24 WORKER: registered result for job (0, 0, 24) with dispatcher
10:12:24 DISPATCHER: job (0, 0, 24) finished
10:12:24 DISPATCHER: register_result: lock acquired
10:12:24 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:12:24 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01708423499822727, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.04039487851179355}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6827958635163727, 'info': {'number_mnist': 0.6827958635163727, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01708423499822727, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.04039487851179355}"}}
exception: None

10:12:24 job_callback for (0, 0, 24) started
10:12:24 DISPATCHER: Trying to submit another job.
10:12:24 job_callback for (0, 0, 24) got condition
10:12:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:24 HBMASTER: Trying to run another job!
10:12:24 job_callback for (0, 0, 24) finished
10:12:24 start sampling a new configuration.
10:12:24 done sampling a new configuration.
10:12:24 HBMASTER: schedule new run for iteration 0
10:12:24 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:12:24 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:12:24 DISPATCHER: trying to submit job (0, 0, 25)
10:12:24 DISPATCHER: trying to notify the job_runner thread.
10:12:24 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:12:24 DISPATCHER: Trying to submit another job.
10:12:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:24 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:12:24 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:12:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:24 WORKER: start processing job (0, 0, 25)
10:12:24 WORKER: args: ()
10:12:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:12:47 DISPATCHER: Starting worker discovery
10:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:47 DISPATCHER: Finished worker discovery
10:13:17 WORKER: done with job (0, 0, 25), trying to register it.
10:13:17 WORKER: registered result for job (0, 0, 25) with dispatcher
10:13:17 DISPATCHER: job (0, 0, 25) finished
10:13:17 DISPATCHER: register_result: lock acquired
10:13:17 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:13:17 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9222031707347809, 'info': {'number_mnist': 0.9222031707347809, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}"}}
exception: None

10:13:17 job_callback for (0, 0, 25) started
10:13:17 DISPATCHER: Trying to submit another job.
10:13:17 job_callback for (0, 0, 25) got condition
10:13:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:13:17 HBMASTER: Trying to run another job!
10:13:17 job_callback for (0, 0, 25) finished
10:13:17 start sampling a new configuration.
10:13:17 done sampling a new configuration.
10:13:17 HBMASTER: schedule new run for iteration 0
10:13:17 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
10:13:17 HBMASTER: submitting job (0, 0, 26) to dispatcher
10:13:17 DISPATCHER: trying to submit job (0, 0, 26)
10:13:17 DISPATCHER: trying to notify the job_runner thread.
10:13:17 HBMASTER: job (0, 0, 26) submitted to dispatcher
10:13:17 DISPATCHER: Trying to submit another job.
10:13:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:13:17 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:13:17 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:13:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:13:17 WORKER: start processing job (0, 0, 26)
10:13:17 WORKER: args: ()
10:13:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010078722716681911, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019402890534047392, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 81, 'num_filters_3': 83, 'num_filters_4': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:13:47 DISPATCHER: Starting worker discovery
10:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:47 DISPATCHER: Finished worker discovery
10:14:11 WORKER: done with job (0, 0, 26), trying to register it.
10:14:11 WORKER: registered result for job (0, 0, 26) with dispatcher
10:14:11 DISPATCHER: job (0, 0, 26) finished
10:14:11 DISPATCHER: register_result: lock acquired
10:14:11 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:14:11 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010078722716681911, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019402890534047392, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 81, 'num_filters_3': 83, 'num_filters_4': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.606380615232764, 'info': {'number_mnist': 0.606380615232764, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010078722716681911, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019402890534047392, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 81, 'num_filters_3': 83, 'num_filters_4': 79}"}}
exception: None

10:14:11 job_callback for (0, 0, 26) started
10:14:11 DISPATCHER: Trying to submit another job.
10:14:11 job_callback for (0, 0, 26) got condition
10:14:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:14:11 HBMASTER: Trying to run another job!
10:14:11 job_callback for (0, 0, 26) finished
10:14:11 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 13) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 21) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
10:14:11 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
10:14:11 HBMASTER: schedule new run for iteration 0
10:14:11 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
10:14:11 HBMASTER: submitting job (0, 0, 4) to dispatcher
10:14:11 DISPATCHER: trying to submit job (0, 0, 4)
10:14:11 DISPATCHER: trying to notify the job_runner thread.
10:14:11 HBMASTER: job (0, 0, 4) submitted to dispatcher
10:14:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:14:11 DISPATCHER: Trying to submit another job.
10:14:11 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:14:11 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:14:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:14:11 WORKER: start processing job (0, 0, 4)
10:14:11 WORKER: args: ()
10:14:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001294816494638346, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.018796304059183387}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:14:47 DISPATCHER: Starting worker discovery
10:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:47 DISPATCHER: Finished worker discovery
10:15:47 DISPATCHER: Starting worker discovery
10:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:47 DISPATCHER: Finished worker discovery
10:16:35 WORKER: done with job (0, 0, 4), trying to register it.
10:16:35 WORKER: registered result for job (0, 0, 4) with dispatcher
10:16:35 DISPATCHER: job (0, 0, 4) finished
10:16:35 DISPATCHER: register_result: lock acquired
10:16:35 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:16:35 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001294816494638346, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.018796304059183387}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9235368103235225, 'info': {'number_mnist': 0.9235368103235225, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001294816494638346, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.018796304059183387}"}}
exception: None

10:16:35 job_callback for (0, 0, 4) started
10:16:35 job_callback for (0, 0, 4) got condition
10:16:35 DISPATCHER: Trying to submit another job.
10:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:16:35 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:16:35 HBMASTER: Trying to run another job!
10:16:35 job_callback for (0, 0, 4) finished
10:16:35 HBMASTER: schedule new run for iteration 0
10:16:35 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
10:16:35 HBMASTER: submitting job (0, 0, 11) to dispatcher
10:16:35 DISPATCHER: trying to submit job (0, 0, 11)
10:16:35 DISPATCHER: trying to notify the job_runner thread.
10:16:35 HBMASTER: job (0, 0, 11) submitted to dispatcher
10:16:35 DISPATCHER: Trying to submit another job.
10:16:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:16:35 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:16:35 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:16:35 WORKER: start processing job (0, 0, 11)
10:16:35 WORKER: args: ()
10:16:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004868305453900309, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02673221684634609, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:16:47 DISPATCHER: Starting worker discovery
10:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:47 DISPATCHER: Finished worker discovery
10:17:47 DISPATCHER: Starting worker discovery
10:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:47 DISPATCHER: Finished worker discovery
10:18:47 DISPATCHER: Starting worker discovery
10:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:47 DISPATCHER: Finished worker discovery
10:18:59 WORKER: done with job (0, 0, 11), trying to register it.
10:18:59 WORKER: registered result for job (0, 0, 11) with dispatcher
10:18:59 DISPATCHER: job (0, 0, 11) finished
10:18:59 DISPATCHER: register_result: lock acquired
10:18:59 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:18:59 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004868305453900309, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02673221684634609, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8785773354609155, 'info': {'number_mnist': 0.8785773354609155, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004868305453900309, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02673221684634609, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 25}"}}
exception: None

10:18:59 job_callback for (0, 0, 11) started
10:18:59 DISPATCHER: Trying to submit another job.
10:18:59 job_callback for (0, 0, 11) got condition
10:18:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:18:59 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:18:59 HBMASTER: Trying to run another job!
10:18:59 job_callback for (0, 0, 11) finished
10:18:59 HBMASTER: schedule new run for iteration 0
10:18:59 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:18:59 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:18:59 DISPATCHER: trying to submit job (0, 0, 13)
10:18:59 DISPATCHER: trying to notify the job_runner thread.
10:18:59 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:18:59 DISPATCHER: Trying to submit another job.
10:18:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:18:59 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:18:59 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:18:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:18:59 WORKER: start processing job (0, 0, 13)
10:18:59 WORKER: args: ()
10:18:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:19:47 DISPATCHER: Starting worker discovery
10:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:47 DISPATCHER: Finished worker discovery
10:20:47 DISPATCHER: Starting worker discovery
10:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:47 DISPATCHER: Finished worker discovery
10:21:26 WORKER: done with job (0, 0, 13), trying to register it.
10:21:26 WORKER: registered result for job (0, 0, 13) with dispatcher
10:21:26 DISPATCHER: job (0, 0, 13) finished
10:21:26 DISPATCHER: register_result: lock acquired
10:21:26 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:21:26 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9514820359142095, 'info': {'number_mnist': 0.9514820359142095, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}"}}
exception: None

10:21:26 job_callback for (0, 0, 13) started
10:21:26 job_callback for (0, 0, 13) got condition
10:21:26 DISPATCHER: Trying to submit another job.
10:21:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:21:26 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:21:26 HBMASTER: Trying to run another job!
10:21:26 job_callback for (0, 0, 13) finished
10:21:26 HBMASTER: schedule new run for iteration 0
10:21:26 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
10:21:26 HBMASTER: submitting job (0, 0, 18) to dispatcher
10:21:26 DISPATCHER: trying to submit job (0, 0, 18)
10:21:26 DISPATCHER: trying to notify the job_runner thread.
10:21:26 HBMASTER: job (0, 0, 18) submitted to dispatcher
10:21:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:21:26 DISPATCHER: Trying to submit another job.
10:21:26 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:21:26 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:21:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:21:26 WORKER: start processing job (0, 0, 18)
10:21:26 WORKER: args: ()
10:21:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020387700717751224, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.038097384750370465, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:21:47 DISPATCHER: Starting worker discovery
10:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:47 DISPATCHER: Finished worker discovery
10:22:47 DISPATCHER: Starting worker discovery
10:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:47 DISPATCHER: Finished worker discovery
10:23:47 DISPATCHER: Starting worker discovery
10:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:47 DISPATCHER: Finished worker discovery
10:23:53 WORKER: done with job (0, 0, 18), trying to register it.
10:23:53 WORKER: registered result for job (0, 0, 18) with dispatcher
10:23:53 DISPATCHER: job (0, 0, 18) finished
10:23:53 DISPATCHER: register_result: lock acquired
10:23:53 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:23:53 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020387700717751224, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.038097384750370465, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7827409897304194, 'info': {'number_mnist': 0.7827409897304194, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020387700717751224, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.038097384750370465, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

10:23:53 job_callback for (0, 0, 18) started
10:23:53 job_callback for (0, 0, 18) got condition
10:23:53 DISPATCHER: Trying to submit another job.
10:23:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:23:53 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:23:53 HBMASTER: Trying to run another job!
10:23:53 job_callback for (0, 0, 18) finished
10:23:53 HBMASTER: schedule new run for iteration 0
10:23:53 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
10:23:53 HBMASTER: submitting job (0, 0, 20) to dispatcher
10:23:53 DISPATCHER: trying to submit job (0, 0, 20)
10:23:53 DISPATCHER: trying to notify the job_runner thread.
10:23:53 HBMASTER: job (0, 0, 20) submitted to dispatcher
10:23:53 DISPATCHER: Trying to submit another job.
10:23:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:23:53 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:23:53 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:23:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:23:53 WORKER: start processing job (0, 0, 20)
10:23:53 WORKER: args: ()
10:23:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004578994067608454, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.02732439430338216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 84, 'num_filters_4': 40, 'num_filters_5': 116}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:24:47 DISPATCHER: Starting worker discovery
10:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:47 DISPATCHER: Finished worker discovery
10:25:47 DISPATCHER: Starting worker discovery
10:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:47 DISPATCHER: Finished worker discovery
10:26:17 WORKER: done with job (0, 0, 20), trying to register it.
10:26:17 WORKER: registered result for job (0, 0, 20) with dispatcher
10:26:17 DISPATCHER: job (0, 0, 20) finished
10:26:17 DISPATCHER: register_result: lock acquired
10:26:17 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:26:17 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004578994067608454, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.02732439430338216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 84, 'num_filters_4': 40, 'num_filters_5': 116}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0001481844741224552, 'info': {'number_mnist': 0.0001481844741224552, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004578994067608454, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.02732439430338216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 84, 'num_filters_4': 40, 'num_filters_5': 116}"}}
exception: None

10:26:17 job_callback for (0, 0, 20) started
10:26:17 DISPATCHER: Trying to submit another job.
10:26:17 job_callback for (0, 0, 20) got condition
10:26:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:26:17 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:26:17 HBMASTER: Trying to run another job!
10:26:17 job_callback for (0, 0, 20) finished
10:26:17 HBMASTER: schedule new run for iteration 0
10:26:17 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
10:26:17 HBMASTER: submitting job (0, 0, 21) to dispatcher
10:26:17 DISPATCHER: trying to submit job (0, 0, 21)
10:26:17 DISPATCHER: trying to notify the job_runner thread.
10:26:17 HBMASTER: job (0, 0, 21) submitted to dispatcher
10:26:17 DISPATCHER: Trying to submit another job.
10:26:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:26:17 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:26:17 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:26:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:26:17 WORKER: start processing job (0, 0, 21)
10:26:17 WORKER: args: ()
10:26:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:26:47 DISPATCHER: Starting worker discovery
10:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:47 DISPATCHER: Finished worker discovery
10:27:47 DISPATCHER: Starting worker discovery
10:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:47 DISPATCHER: Finished worker discovery
10:28:42 WORKER: done with job (0, 0, 21), trying to register it.
10:28:42 WORKER: registered result for job (0, 0, 21) with dispatcher
10:28:42 DISPATCHER: job (0, 0, 21) finished
10:28:42 DISPATCHER: register_result: lock acquired
10:28:42 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:28:42 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9268705394641423, 'info': {'number_mnist': 0.9268705394641423, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}"}}
exception: None

10:28:42 job_callback for (0, 0, 21) started
10:28:42 DISPATCHER: Trying to submit another job.
10:28:42 job_callback for (0, 0, 21) got condition
10:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:28:42 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:28:42 HBMASTER: Trying to run another job!
10:28:42 job_callback for (0, 0, 21) finished
10:28:42 HBMASTER: schedule new run for iteration 0
10:28:42 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
10:28:42 HBMASTER: submitting job (0, 0, 24) to dispatcher
10:28:42 DISPATCHER: trying to submit job (0, 0, 24)
10:28:42 DISPATCHER: trying to notify the job_runner thread.
10:28:42 HBMASTER: job (0, 0, 24) submitted to dispatcher
10:28:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:28:42 DISPATCHER: Trying to submit another job.
10:28:42 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:28:42 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:28:42 WORKER: start processing job (0, 0, 24)
10:28:42 WORKER: args: ()
10:28:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01708423499822727, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.04039487851179355}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:28:47 DISPATCHER: Starting worker discovery
10:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:47 DISPATCHER: Finished worker discovery
10:29:47 DISPATCHER: Starting worker discovery
10:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:47 DISPATCHER: Finished worker discovery
10:30:47 DISPATCHER: Starting worker discovery
10:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:47 DISPATCHER: Finished worker discovery
10:31:22 WORKER: done with job (0, 0, 24), trying to register it.
10:31:22 WORKER: registered result for job (0, 0, 24) with dispatcher
10:31:22 DISPATCHER: job (0, 0, 24) finished
10:31:22 DISPATCHER: register_result: lock acquired
10:31:22 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:31:22 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01708423499822727, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.04039487851179355}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.676184977814388, 'info': {'number_mnist': 0.676184977814388, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.01708423499822727, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.04039487851179355}"}}
exception: None

10:31:22 job_callback for (0, 0, 24) started
10:31:22 job_callback for (0, 0, 24) got condition
10:31:22 DISPATCHER: Trying to submit another job.
10:31:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:31:22 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:31:22 HBMASTER: Trying to run another job!
10:31:22 job_callback for (0, 0, 24) finished
10:31:22 HBMASTER: schedule new run for iteration 0
10:31:22 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:31:22 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:31:22 DISPATCHER: trying to submit job (0, 0, 25)
10:31:22 DISPATCHER: trying to notify the job_runner thread.
10:31:22 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:31:22 DISPATCHER: Trying to submit another job.
10:31:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:31:22 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:31:22 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:31:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:31:22 WORKER: start processing job (0, 0, 25)
10:31:22 WORKER: args: ()
10:31:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:31:47 DISPATCHER: Starting worker discovery
10:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:47 DISPATCHER: Finished worker discovery
10:32:47 DISPATCHER: Starting worker discovery
10:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:47 DISPATCHER: Finished worker discovery
10:33:45 WORKER: done with job (0, 0, 25), trying to register it.
10:33:45 WORKER: registered result for job (0, 0, 25) with dispatcher
10:33:45 DISPATCHER: job (0, 0, 25) finished
10:33:45 DISPATCHER: register_result: lock acquired
10:33:45 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:33:45 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9589364796405166, 'info': {'number_mnist': 0.9589364796405166, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}"}}
exception: None

10:33:45 job_callback for (0, 0, 25) started
10:33:45 job_callback for (0, 0, 25) got condition
10:33:45 DISPATCHER: Trying to submit another job.
10:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:33:45 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:33:45 HBMASTER: Trying to run another job!
10:33:45 job_callback for (0, 0, 25) finished
10:33:45 HBMASTER: schedule new run for iteration 0
10:33:45 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
10:33:45 HBMASTER: submitting job (0, 0, 26) to dispatcher
10:33:45 DISPATCHER: trying to submit job (0, 0, 26)
10:33:45 DISPATCHER: trying to notify the job_runner thread.
10:33:45 HBMASTER: job (0, 0, 26) submitted to dispatcher
10:33:45 DISPATCHER: Trying to submit another job.
10:33:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:33:45 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:33:45 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:33:45 WORKER: start processing job (0, 0, 26)
10:33:45 WORKER: args: ()
10:33:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010078722716681911, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019402890534047392, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 81, 'num_filters_3': 83, 'num_filters_4': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:33:47 DISPATCHER: Starting worker discovery
10:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:47 DISPATCHER: Finished worker discovery
10:34:47 DISPATCHER: Starting worker discovery
10:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:47 DISPATCHER: Finished worker discovery
10:35:47 DISPATCHER: Starting worker discovery
10:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:47 DISPATCHER: Finished worker discovery
10:36:09 WORKER: done with job (0, 0, 26), trying to register it.
10:36:09 WORKER: registered result for job (0, 0, 26) with dispatcher
10:36:09 DISPATCHER: job (0, 0, 26) finished
10:36:09 DISPATCHER: register_result: lock acquired
10:36:09 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:36:09 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010078722716681911, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019402890534047392, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 81, 'num_filters_3': 83, 'num_filters_4': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8245814318120004, 'info': {'number_mnist': 0.8245814318120004, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010078722716681911, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019402890534047392, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 81, 'num_filters_3': 83, 'num_filters_4': 79}"}}
exception: None

10:36:09 job_callback for (0, 0, 26) started
10:36:09 DISPATCHER: Trying to submit another job.
10:36:09 job_callback for (0, 0, 26) got condition
10:36:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:36:09 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:36:09 HBMASTER: Trying to run another job!
10:36:09 job_callback for (0, 0, 26) finished
10:36:09 ITERATION: Advancing config (0, 0, 13) to next budget 400.000000
10:36:09 ITERATION: Advancing config (0, 0, 21) to next budget 400.000000
10:36:09 ITERATION: Advancing config (0, 0, 25) to next budget 400.000000
10:36:09 HBMASTER: schedule new run for iteration 0
10:36:09 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:36:09 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:36:09 DISPATCHER: trying to submit job (0, 0, 13)
10:36:09 DISPATCHER: trying to notify the job_runner thread.
10:36:09 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:36:09 DISPATCHER: Trying to submit another job.
10:36:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:36:09 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:36:09 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:36:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:36:09 WORKER: start processing job (0, 0, 13)
10:36:09 WORKER: args: ()
10:36:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 400.0, 'working_directory': '.'}
10:36:47 DISPATCHER: Starting worker discovery
10:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:47 DISPATCHER: Finished worker discovery
10:37:47 DISPATCHER: Starting worker discovery
10:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:47 DISPATCHER: Finished worker discovery
10:38:47 DISPATCHER: Starting worker discovery
10:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:47 DISPATCHER: Finished worker discovery
10:39:47 DISPATCHER: Starting worker discovery
10:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:47 DISPATCHER: Finished worker discovery
10:40:47 DISPATCHER: Starting worker discovery
10:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:47 DISPATCHER: Finished worker discovery
10:41:47 DISPATCHER: Starting worker discovery
10:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:47 DISPATCHER: Finished worker discovery
10:42:47 DISPATCHER: Starting worker discovery
10:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:47 DISPATCHER: Finished worker discovery
10:43:12 WORKER: done with job (0, 0, 13), trying to register it.
10:43:12 WORKER: registered result for job (0, 0, 13) with dispatcher
10:43:12 DISPATCHER: job (0, 0, 13) finished
10:43:12 DISPATCHER: register_result: lock acquired
10:43:12 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:43:12 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9500836157613077, 'info': {'number_mnist': 0.9500836157613077, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}"}}
exception: None

10:43:12 job_callback for (0, 0, 13) started
10:43:12 job_callback for (0, 0, 13) got condition
10:43:12 DISPATCHER: Trying to submit another job.
10:43:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:43:12 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:43:12 HBMASTER: Trying to run another job!
10:43:12 job_callback for (0, 0, 13) finished
10:43:12 HBMASTER: schedule new run for iteration 0
10:43:12 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
10:43:12 HBMASTER: submitting job (0, 0, 21) to dispatcher
10:43:12 DISPATCHER: trying to submit job (0, 0, 21)
10:43:12 DISPATCHER: trying to notify the job_runner thread.
10:43:12 HBMASTER: job (0, 0, 21) submitted to dispatcher
10:43:12 DISPATCHER: Trying to submit another job.
10:43:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:43:12 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:43:12 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:43:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:43:12 WORKER: start processing job (0, 0, 21)
10:43:12 WORKER: args: ()
10:43:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}, 'budget': 400.0, 'working_directory': '.'}
10:43:47 DISPATCHER: Starting worker discovery
10:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:47 DISPATCHER: Finished worker discovery
10:44:47 DISPATCHER: Starting worker discovery
10:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:47 DISPATCHER: Finished worker discovery
10:45:47 DISPATCHER: Starting worker discovery
10:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:47 DISPATCHER: Finished worker discovery
10:46:47 DISPATCHER: Starting worker discovery
10:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:47 DISPATCHER: Finished worker discovery
10:47:47 DISPATCHER: Starting worker discovery
10:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:47 DISPATCHER: Finished worker discovery
10:48:47 DISPATCHER: Starting worker discovery
10:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:47 DISPATCHER: Finished worker discovery
10:49:47 DISPATCHER: Starting worker discovery
10:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:47 DISPATCHER: Finished worker discovery
10:50:10 WORKER: done with job (0, 0, 21), trying to register it.
10:50:10 WORKER: registered result for job (0, 0, 21) with dispatcher
10:50:10 DISPATCHER: job (0, 0, 21) finished
10:50:10 DISPATCHER: register_result: lock acquired
10:50:10 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:50:10 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9418199769802493, 'info': {'number_mnist': 0.9418199769802493, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014812606313576629, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011156391305434324, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 67, 'num_filters_5': 62}"}}
exception: None

10:50:10 job_callback for (0, 0, 21) started
10:50:10 DISPATCHER: Trying to submit another job.
10:50:10 job_callback for (0, 0, 21) got condition
10:50:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:10 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:50:10 HBMASTER: Trying to run another job!
10:50:10 job_callback for (0, 0, 21) finished
10:50:10 HBMASTER: schedule new run for iteration 0
10:50:10 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:50:10 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:50:10 DISPATCHER: trying to submit job (0, 0, 25)
10:50:10 DISPATCHER: trying to notify the job_runner thread.
10:50:10 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:50:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:10 DISPATCHER: Trying to submit another job.
10:50:10 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:50:10 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:50:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:10 WORKER: start processing job (0, 0, 25)
10:50:10 WORKER: args: ()
10:50:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}, 'budget': 400.0, 'working_directory': '.'}
10:50:47 DISPATCHER: Starting worker discovery
10:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:47 DISPATCHER: Finished worker discovery
10:51:47 DISPATCHER: Starting worker discovery
10:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:47 DISPATCHER: Finished worker discovery
10:52:47 DISPATCHER: Starting worker discovery
10:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:47 DISPATCHER: Finished worker discovery
10:53:47 DISPATCHER: Starting worker discovery
10:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:47 DISPATCHER: Finished worker discovery
10:54:47 DISPATCHER: Starting worker discovery
10:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:47 DISPATCHER: Finished worker discovery
10:55:47 DISPATCHER: Starting worker discovery
10:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:48 DISPATCHER: Finished worker discovery
10:56:48 DISPATCHER: Starting worker discovery
10:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:48 DISPATCHER: Finished worker discovery
10:57:05 WORKER: done with job (0, 0, 25), trying to register it.
10:57:05 WORKER: registered result for job (0, 0, 25) with dispatcher
10:57:05 DISPATCHER: job (0, 0, 25) finished
10:57:05 DISPATCHER: register_result: lock acquired
10:57:05 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:57:05 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9468931472855238, 'info': {'number_mnist': 0.9468931472855238, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030388770774845593, 'num_filters_1': 91, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.017376023638074712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 71, 'num_filters_4': 30, 'num_filters_5': 20}"}}
exception: None

10:57:05 job_callback for (0, 0, 25) started
10:57:05 DISPATCHER: Trying to submit another job.
10:57:05 job_callback for (0, 0, 25) got condition
10:57:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:57:05 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:57:05 HBMASTER: Trying to run another job!
10:57:05 job_callback for (0, 0, 25) finished
10:57:05 ITERATION: Advancing config (0, 0, 13) to next budget 1200.000000
10:57:05 HBMASTER: schedule new run for iteration 0
10:57:05 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:57:05 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:57:05 DISPATCHER: trying to submit job (0, 0, 13)
10:57:05 DISPATCHER: trying to notify the job_runner thread.
10:57:05 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:57:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:57:05 DISPATCHER: Trying to submit another job.
10:57:05 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:57:05 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:57:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:57:05 WORKER: start processing job (0, 0, 13)
10:57:05 WORKER: args: ()
10:57:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 1200.0, 'working_directory': '.'}
10:57:48 DISPATCHER: Starting worker discovery
10:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:48 DISPATCHER: Finished worker discovery
10:58:48 DISPATCHER: Starting worker discovery
10:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:48 DISPATCHER: Finished worker discovery
10:59:48 DISPATCHER: Starting worker discovery
10:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:48 DISPATCHER: Finished worker discovery
11:00:48 DISPATCHER: Starting worker discovery
11:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:48 DISPATCHER: Finished worker discovery
11:01:48 DISPATCHER: Starting worker discovery
11:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:48 DISPATCHER: Finished worker discovery
11:02:48 DISPATCHER: Starting worker discovery
11:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:48 DISPATCHER: Finished worker discovery
11:03:48 DISPATCHER: Starting worker discovery
11:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:48 DISPATCHER: Finished worker discovery
11:04:48 DISPATCHER: Starting worker discovery
11:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:48 DISPATCHER: Finished worker discovery
11:05:48 DISPATCHER: Starting worker discovery
11:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:48 DISPATCHER: Finished worker discovery
11:06:48 DISPATCHER: Starting worker discovery
11:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:48 DISPATCHER: Finished worker discovery
11:07:48 DISPATCHER: Starting worker discovery
11:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:48 DISPATCHER: Finished worker discovery
11:08:48 DISPATCHER: Starting worker discovery
11:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:48 DISPATCHER: Finished worker discovery
11:09:48 DISPATCHER: Starting worker discovery
11:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:48 DISPATCHER: Finished worker discovery
11:10:48 DISPATCHER: Starting worker discovery
11:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:48 DISPATCHER: Finished worker discovery
11:11:48 DISPATCHER: Starting worker discovery
11:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:48 DISPATCHER: Finished worker discovery
11:12:48 DISPATCHER: Starting worker discovery
11:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:48 DISPATCHER: Finished worker discovery
11:13:48 DISPATCHER: Starting worker discovery
11:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:48 DISPATCHER: Finished worker discovery
11:14:48 DISPATCHER: Starting worker discovery
11:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:48 DISPATCHER: Finished worker discovery
11:15:48 DISPATCHER: Starting worker discovery
11:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:48 DISPATCHER: Finished worker discovery
11:16:48 DISPATCHER: Starting worker discovery
11:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:48 DISPATCHER: Finished worker discovery
11:17:48 DISPATCHER: Starting worker discovery
11:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:48 DISPATCHER: Finished worker discovery
11:17:59 WORKER: done with job (0, 0, 13), trying to register it.
11:17:59 WORKER: registered result for job (0, 0, 13) with dispatcher
11:17:59 DISPATCHER: job (0, 0, 13) finished
11:17:59 DISPATCHER: register_result: lock acquired
11:17:59 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:17:59 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9543782729759168, 'info': {'number_mnist': 0.9543782729759168, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013283682799786303, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01006174958612902, 'kernel_size_2': 7, 'num_filters_2': 55}"}}
exception: None

11:17:59 job_callback for (0, 0, 13) started
11:17:59 job_callback for (0, 0, 13) got condition
11:17:59 DISPATCHER: Trying to submit another job.
11:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:17:59 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
11:17:59 HBMASTER: Trying to run another job!
11:17:59 job_callback for (0, 0, 13) finished
11:17:59 start sampling a new configuration.
11:17:59 done sampling a new configuration.
11:17:59 HBMASTER: schedule new run for iteration 1
11:17:59 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
11:17:59 HBMASTER: submitting job (1, 0, 0) to dispatcher
11:17:59 DISPATCHER: trying to submit job (1, 0, 0)
11:17:59 DISPATCHER: trying to notify the job_runner thread.
11:17:59 HBMASTER: job (1, 0, 0) submitted to dispatcher
11:17:59 DISPATCHER: Trying to submit another job.
11:17:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:17:59 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:17:59 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:17:59 WORKER: start processing job (1, 0, 0)
11:17:59 WORKER: args: ()
11:17:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:18:48 DISPATCHER: Starting worker discovery
11:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:48 DISPATCHER: Finished worker discovery
11:19:48 DISPATCHER: Starting worker discovery
11:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:48 DISPATCHER: Finished worker discovery
11:20:23 WORKER: done with job (1, 0, 0), trying to register it.
11:20:23 WORKER: registered result for job (1, 0, 0) with dispatcher
11:20:23 DISPATCHER: job (1, 0, 0) finished
11:20:23 DISPATCHER: register_result: lock acquired
11:20:23 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:20:23 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9169377951868702, 'info': {'number_mnist': 0.9169377951868702, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}"}}
exception: None

11:20:23 job_callback for (1, 0, 0) started
11:20:23 DISPATCHER: Trying to submit another job.
11:20:23 job_callback for (1, 0, 0) got condition
11:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:20:23 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:20:23 HBMASTER: Trying to run another job!
11:20:23 job_callback for (1, 0, 0) finished
11:20:23 start sampling a new configuration.
11:20:23 done sampling a new configuration.
11:20:23 HBMASTER: schedule new run for iteration 1
11:20:23 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
11:20:23 HBMASTER: submitting job (1, 0, 1) to dispatcher
11:20:23 DISPATCHER: trying to submit job (1, 0, 1)
11:20:23 DISPATCHER: trying to notify the job_runner thread.
11:20:23 HBMASTER: job (1, 0, 1) submitted to dispatcher
11:20:23 DISPATCHER: Trying to submit another job.
11:20:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:20:23 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:20:23 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:20:23 WORKER: start processing job (1, 0, 1)
11:20:23 WORKER: args: ()
11:20:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002443155227978165, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.1171125932599436, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 20, 'num_filters_4': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:20:48 DISPATCHER: Starting worker discovery
11:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:48 DISPATCHER: Finished worker discovery
11:21:48 DISPATCHER: Starting worker discovery
11:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:48 DISPATCHER: Finished worker discovery
11:22:48 WORKER: done with job (1, 0, 1), trying to register it.
11:22:48 WORKER: registered result for job (1, 0, 1) with dispatcher
11:22:48 DISPATCHER: job (1, 0, 1) finished
11:22:48 DISPATCHER: register_result: lock acquired
11:22:48 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:22:48 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002443155227978165, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.1171125932599436, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 20, 'num_filters_4': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6248880740626462, 'info': {'number_mnist': 0.6248880740626462, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002443155227978165, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.1171125932599436, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 20, 'num_filters_4': 74}"}}
exception: None

11:22:48 job_callback for (1, 0, 1) started
11:22:48 job_callback for (1, 0, 1) got condition
11:22:48 DISPATCHER: Trying to submit another job.
11:22:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:22:48 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:22:48 HBMASTER: Trying to run another job!
11:22:48 job_callback for (1, 0, 1) finished
11:22:48 start sampling a new configuration.
11:22:48 done sampling a new configuration.
11:22:48 HBMASTER: schedule new run for iteration 1
11:22:48 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
11:22:48 HBMASTER: submitting job (1, 0, 2) to dispatcher
11:22:48 DISPATCHER: trying to submit job (1, 0, 2)
11:22:48 DISPATCHER: trying to notify the job_runner thread.
11:22:48 HBMASTER: job (1, 0, 2) submitted to dispatcher
11:22:48 DISPATCHER: Trying to submit another job.
11:22:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:22:48 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:22:48 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:22:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:22:48 WORKER: start processing job (1, 0, 2)
11:22:48 WORKER: args: ()
11:22:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0038526732436873633, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.06914711877771584, 'kernel_size_2': 7, 'num_filters_2': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:22:48 DISPATCHER: Starting worker discovery
11:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:48 DISPATCHER: Finished worker discovery
11:23:48 DISPATCHER: Starting worker discovery
11:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:48 DISPATCHER: Finished worker discovery
11:24:48 DISPATCHER: Starting worker discovery
11:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:48 DISPATCHER: Finished worker discovery
11:25:13 WORKER: done with job (1, 0, 2), trying to register it.
11:25:13 WORKER: registered result for job (1, 0, 2) with dispatcher
11:25:13 DISPATCHER: job (1, 0, 2) finished
11:25:13 DISPATCHER: register_result: lock acquired
11:25:13 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:25:13 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0038526732436873633, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.06914711877771584, 'kernel_size_2': 7, 'num_filters_2': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7343019226802173, 'info': {'number_mnist': 0.7343019226802173, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0038526732436873633, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.06914711877771584, 'kernel_size_2': 7, 'num_filters_2': 52}"}}
exception: None

11:25:13 job_callback for (1, 0, 2) started
11:25:13 job_callback for (1, 0, 2) got condition
11:25:13 DISPATCHER: Trying to submit another job.
11:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:25:13 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:25:13 HBMASTER: Trying to run another job!
11:25:13 job_callback for (1, 0, 2) finished
11:25:13 start sampling a new configuration.
11:25:13 done sampling a new configuration.
11:25:13 HBMASTER: schedule new run for iteration 1
11:25:13 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
11:25:13 HBMASTER: submitting job (1, 0, 3) to dispatcher
11:25:13 DISPATCHER: trying to submit job (1, 0, 3)
11:25:13 DISPATCHER: trying to notify the job_runner thread.
11:25:13 HBMASTER: job (1, 0, 3) submitted to dispatcher
11:25:13 DISPATCHER: Trying to submit another job.
11:25:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:25:13 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:25:13 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:25:13 WORKER: start processing job (1, 0, 3)
11:25:13 WORKER: args: ()
11:25:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.015539071049658525, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.1251082020944275, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 20, 'num_filters_4': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:25:48 DISPATCHER: Starting worker discovery
11:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:48 DISPATCHER: Finished worker discovery
11:26:48 DISPATCHER: Starting worker discovery
11:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:48 DISPATCHER: Finished worker discovery
11:27:41 WORKER: done with job (1, 0, 3), trying to register it.
11:27:41 WORKER: registered result for job (1, 0, 3) with dispatcher
11:27:41 DISPATCHER: job (1, 0, 3) finished
11:27:41 DISPATCHER: register_result: lock acquired
11:27:41 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:27:41 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.015539071049658525, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.1251082020944275, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 20, 'num_filters_4': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.042231074502353035, 'info': {'number_mnist': 0.042231074502353035, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.015539071049658525, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.1251082020944275, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 20, 'num_filters_4': 46}"}}
exception: None

11:27:41 job_callback for (1, 0, 3) started
11:27:41 DISPATCHER: Trying to submit another job.
11:27:41 job_callback for (1, 0, 3) got condition
11:27:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:27:41 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:27:41 HBMASTER: Trying to run another job!
11:27:41 job_callback for (1, 0, 3) finished
11:27:41 start sampling a new configuration.
11:27:41 done sampling a new configuration.
11:27:41 HBMASTER: schedule new run for iteration 1
11:27:41 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
11:27:41 HBMASTER: submitting job (1, 0, 4) to dispatcher
11:27:41 DISPATCHER: trying to submit job (1, 0, 4)
11:27:41 DISPATCHER: trying to notify the job_runner thread.
11:27:41 HBMASTER: job (1, 0, 4) submitted to dispatcher
11:27:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:27:41 DISPATCHER: Trying to submit another job.
11:27:41 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:27:41 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:27:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:27:41 WORKER: start processing job (1, 0, 4)
11:27:41 WORKER: args: ()
11:27:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06665703367162497, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.014763883659886092}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:27:48 DISPATCHER: Starting worker discovery
11:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:48 DISPATCHER: Finished worker discovery
11:28:48 DISPATCHER: Starting worker discovery
11:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:48 DISPATCHER: Finished worker discovery
11:29:48 DISPATCHER: Starting worker discovery
11:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:48 DISPATCHER: Finished worker discovery
11:30:07 WORKER: done with job (1, 0, 4), trying to register it.
11:30:07 WORKER: registered result for job (1, 0, 4) with dispatcher
11:30:07 DISPATCHER: job (1, 0, 4) finished
11:30:07 DISPATCHER: register_result: lock acquired
11:30:07 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:30:07 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06665703367162497, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.014763883659886092}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.856666042798355, 'info': {'number_mnist': 0.856666042798355, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06665703367162497, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.014763883659886092}"}}
exception: None

11:30:07 job_callback for (1, 0, 4) started
11:30:07 DISPATCHER: Trying to submit another job.
11:30:07 job_callback for (1, 0, 4) got condition
11:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:30:07 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:30:07 HBMASTER: Trying to run another job!
11:30:07 job_callback for (1, 0, 4) finished
11:30:07 start sampling a new configuration.
11:30:07 done sampling a new configuration.
11:30:07 HBMASTER: schedule new run for iteration 1
11:30:07 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
11:30:07 HBMASTER: submitting job (1, 0, 5) to dispatcher
11:30:07 DISPATCHER: trying to submit job (1, 0, 5)
11:30:07 DISPATCHER: trying to notify the job_runner thread.
11:30:07 HBMASTER: job (1, 0, 5) submitted to dispatcher
11:30:07 DISPATCHER: Trying to submit another job.
11:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:30:07 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:30:07 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:30:07 WORKER: start processing job (1, 0, 5)
11:30:07 WORKER: args: ()
11:30:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015381061922177317, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.025254272006505495, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 67, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:30:48 DISPATCHER: Starting worker discovery
11:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:48 DISPATCHER: Finished worker discovery
11:31:48 DISPATCHER: Starting worker discovery
11:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:48 DISPATCHER: Finished worker discovery
11:32:34 WORKER: done with job (1, 0, 5), trying to register it.
11:32:34 WORKER: registered result for job (1, 0, 5) with dispatcher
11:32:34 DISPATCHER: job (1, 0, 5) finished
11:32:34 DISPATCHER: register_result: lock acquired
11:32:34 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:32:34 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015381061922177317, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.025254272006505495, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 67, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7432468108404529, 'info': {'number_mnist': 0.7432468108404529, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015381061922177317, 'num_filters_1': 103, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.025254272006505495, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 67, 'num_filters_4': 16}"}}
exception: None

11:32:34 job_callback for (1, 0, 5) started
11:32:34 DISPATCHER: Trying to submit another job.
11:32:34 job_callback for (1, 0, 5) got condition
11:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:32:34 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:32:34 HBMASTER: Trying to run another job!
11:32:34 job_callback for (1, 0, 5) finished
11:32:34 start sampling a new configuration.
11:32:34 done sampling a new configuration.
11:32:34 HBMASTER: schedule new run for iteration 1
11:32:34 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
11:32:34 HBMASTER: submitting job (1, 0, 6) to dispatcher
11:32:34 DISPATCHER: trying to submit job (1, 0, 6)
11:32:34 DISPATCHER: trying to notify the job_runner thread.
11:32:34 HBMASTER: job (1, 0, 6) submitted to dispatcher
11:32:34 DISPATCHER: Trying to submit another job.
11:32:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:32:34 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:32:34 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:32:34 WORKER: start processing job (1, 0, 6)
11:32:34 WORKER: args: ()
11:32:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02181423408716945, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02676183843616804, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 27, 'num_filters_4': 103, 'num_filters_5': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:32:48 DISPATCHER: Starting worker discovery
11:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:48 DISPATCHER: Finished worker discovery
11:33:48 DISPATCHER: Starting worker discovery
11:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:48 DISPATCHER: Finished worker discovery
11:34:48 DISPATCHER: Starting worker discovery
11:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:48 DISPATCHER: Finished worker discovery
11:34:58 WORKER: done with job (1, 0, 6), trying to register it.
11:34:58 WORKER: registered result for job (1, 0, 6) with dispatcher
11:34:58 DISPATCHER: job (1, 0, 6) finished
11:34:58 DISPATCHER: register_result: lock acquired
11:34:58 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:34:58 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02181423408716945, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02676183843616804, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 27, 'num_filters_4': 103, 'num_filters_5': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8321464037505162, 'info': {'number_mnist': 0.8321464037505162, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02181423408716945, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02676183843616804, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 27, 'num_filters_4': 103, 'num_filters_5': 54}"}}
exception: None

11:34:58 job_callback for (1, 0, 6) started
11:34:58 DISPATCHER: Trying to submit another job.
11:34:58 job_callback for (1, 0, 6) got condition
11:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:34:58 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:34:58 HBMASTER: Trying to run another job!
11:34:58 job_callback for (1, 0, 6) finished
11:34:58 start sampling a new configuration.
11:34:58 done sampling a new configuration.
11:34:58 HBMASTER: schedule new run for iteration 1
11:34:58 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
11:34:58 HBMASTER: submitting job (1, 0, 7) to dispatcher
11:34:58 DISPATCHER: trying to submit job (1, 0, 7)
11:34:58 DISPATCHER: trying to notify the job_runner thread.
11:34:58 HBMASTER: job (1, 0, 7) submitted to dispatcher
11:34:58 DISPATCHER: Trying to submit another job.
11:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:34:58 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:34:58 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:34:58 WORKER: start processing job (1, 0, 7)
11:34:58 WORKER: args: ()
11:34:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001953926484944889, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.0867767392524241, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 38, 'num_filters_4': 41, 'num_filters_5': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:35:48 DISPATCHER: Starting worker discovery
11:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:48 DISPATCHER: Finished worker discovery
11:36:48 DISPATCHER: Starting worker discovery
11:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:48 DISPATCHER: Finished worker discovery
11:37:30 WORKER: done with job (1, 0, 7), trying to register it.
11:37:30 WORKER: registered result for job (1, 0, 7) with dispatcher
11:37:30 DISPATCHER: job (1, 0, 7) finished
11:37:30 DISPATCHER: register_result: lock acquired
11:37:30 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:37:30 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001953926484944889, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.0867767392524241, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 38, 'num_filters_4': 41, 'num_filters_5': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.013149310930267447, 'info': {'number_mnist': 0.013149310930267447, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001953926484944889, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.0867767392524241, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 38, 'num_filters_4': 41, 'num_filters_5': 87}"}}
exception: None

11:37:30 job_callback for (1, 0, 7) started
11:37:30 job_callback for (1, 0, 7) got condition
11:37:30 DISPATCHER: Trying to submit another job.
11:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:37:30 HBMASTER: Trying to run another job!
11:37:30 job_callback for (1, 0, 7) finished
11:37:30 start sampling a new configuration.
11:37:30 done sampling a new configuration.
11:37:30 HBMASTER: schedule new run for iteration 1
11:37:30 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
11:37:30 HBMASTER: submitting job (1, 0, 8) to dispatcher
11:37:30 DISPATCHER: trying to submit job (1, 0, 8)
11:37:30 DISPATCHER: trying to notify the job_runner thread.
11:37:30 HBMASTER: job (1, 0, 8) submitted to dispatcher
11:37:30 DISPATCHER: Trying to submit another job.
11:37:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:37:30 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:37:30 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:37:30 WORKER: start processing job (1, 0, 8)
11:37:30 WORKER: args: ()
11:37:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.008955003081811264, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.1455334128270715, 'kernel_size_2': 3, 'num_filters_2': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:37:48 DISPATCHER: Starting worker discovery
11:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:48 DISPATCHER: Finished worker discovery
11:38:48 DISPATCHER: Starting worker discovery
11:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:48 DISPATCHER: Finished worker discovery
11:39:48 DISPATCHER: Starting worker discovery
11:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:48 DISPATCHER: Finished worker discovery
11:39:57 WORKER: done with job (1, 0, 8), trying to register it.
11:39:57 WORKER: registered result for job (1, 0, 8) with dispatcher
11:39:57 DISPATCHER: job (1, 0, 8) finished
11:39:57 DISPATCHER: register_result: lock acquired
11:39:57 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:39:57 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.008955003081811264, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.1455334128270715, 'kernel_size_2': 3, 'num_filters_2': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07711677449011999, 'info': {'number_mnist': 0.07711677449011999, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.008955003081811264, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.1455334128270715, 'kernel_size_2': 3, 'num_filters_2': 23}"}}
exception: None

11:39:57 job_callback for (1, 0, 8) started
11:39:57 DISPATCHER: Trying to submit another job.
11:39:57 job_callback for (1, 0, 8) got condition
11:39:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:39:58 HBMASTER: Trying to run another job!
11:39:58 job_callback for (1, 0, 8) finished
11:39:58 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
11:39:58 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
11:39:58 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
11:39:58 HBMASTER: schedule new run for iteration 1
11:39:58 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
11:39:58 HBMASTER: submitting job (1, 0, 0) to dispatcher
11:39:58 DISPATCHER: trying to submit job (1, 0, 0)
11:39:58 DISPATCHER: trying to notify the job_runner thread.
11:39:58 HBMASTER: job (1, 0, 0) submitted to dispatcher
11:39:58 DISPATCHER: Trying to submit another job.
11:39:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:39:58 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:39:58 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:39:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:39:58 WORKER: start processing job (1, 0, 0)
11:39:58 WORKER: args: ()
11:39:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}, 'budget': 400.0, 'working_directory': '.'}
11:40:48 DISPATCHER: Starting worker discovery
11:40:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:48 DISPATCHER: Finished worker discovery
11:41:48 DISPATCHER: Starting worker discovery
11:41:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:48 DISPATCHER: Finished worker discovery
11:42:48 DISPATCHER: Starting worker discovery
11:42:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:48 DISPATCHER: Finished worker discovery
11:43:48 DISPATCHER: Starting worker discovery
11:43:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:48 DISPATCHER: Finished worker discovery
11:44:48 DISPATCHER: Starting worker discovery
11:44:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:48 DISPATCHER: Finished worker discovery
11:45:48 DISPATCHER: Starting worker discovery
11:45:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:48 DISPATCHER: Finished worker discovery
11:46:48 DISPATCHER: Starting worker discovery
11:46:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:48 DISPATCHER: Finished worker discovery
11:46:53 WORKER: done with job (1, 0, 0), trying to register it.
11:46:53 WORKER: registered result for job (1, 0, 0) with dispatcher
11:46:53 DISPATCHER: job (1, 0, 0) finished
11:46:53 DISPATCHER: register_result: lock acquired
11:46:53 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:46:53 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9221209658431659, 'info': {'number_mnist': 0.9221209658431659, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}"}}
exception: None

11:46:53 job_callback for (1, 0, 0) started
11:46:53 DISPATCHER: Trying to submit another job.
11:46:53 job_callback for (1, 0, 0) got condition
11:46:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:46:53 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:46:53 HBMASTER: Trying to run another job!
11:46:53 job_callback for (1, 0, 0) finished
11:46:53 HBMASTER: schedule new run for iteration 1
11:46:53 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
11:46:53 HBMASTER: submitting job (1, 0, 4) to dispatcher
11:46:53 DISPATCHER: trying to submit job (1, 0, 4)
11:46:53 DISPATCHER: trying to notify the job_runner thread.
11:46:53 HBMASTER: job (1, 0, 4) submitted to dispatcher
11:46:53 DISPATCHER: Trying to submit another job.
11:46:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:46:53 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:46:53 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:46:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:46:53 WORKER: start processing job (1, 0, 4)
11:46:53 WORKER: args: ()
11:46:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06665703367162497, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.014763883659886092}, 'budget': 400.0, 'working_directory': '.'}
11:47:48 DISPATCHER: Starting worker discovery
11:47:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:48 DISPATCHER: Finished worker discovery
11:48:48 DISPATCHER: Starting worker discovery
11:48:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:48 DISPATCHER: Finished worker discovery
11:49:48 DISPATCHER: Starting worker discovery
11:49:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:48 DISPATCHER: Finished worker discovery
11:50:48 DISPATCHER: Starting worker discovery
11:50:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:48 DISPATCHER: Finished worker discovery
11:51:48 DISPATCHER: Starting worker discovery
11:51:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:48 DISPATCHER: Finished worker discovery
11:52:48 DISPATCHER: Starting worker discovery
11:52:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:48 DISPATCHER: Finished worker discovery
11:53:48 DISPATCHER: Starting worker discovery
11:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:48 DISPATCHER: Finished worker discovery
11:53:54 WORKER: done with job (1, 0, 4), trying to register it.
11:53:54 WORKER: registered result for job (1, 0, 4) with dispatcher
11:53:54 DISPATCHER: job (1, 0, 4) finished
11:53:54 DISPATCHER: register_result: lock acquired
11:53:54 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:53:54 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06665703367162497, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.014763883659886092}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9076355125436022, 'info': {'number_mnist': 0.9076355125436022, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06665703367162497, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.014763883659886092}"}}
exception: None

11:53:54 job_callback for (1, 0, 4) started
11:53:54 DISPATCHER: Trying to submit another job.
11:53:54 job_callback for (1, 0, 4) got condition
11:53:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:53:54 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:53:54 HBMASTER: Trying to run another job!
11:53:54 job_callback for (1, 0, 4) finished
11:53:54 HBMASTER: schedule new run for iteration 1
11:53:54 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
11:53:54 HBMASTER: submitting job (1, 0, 6) to dispatcher
11:53:54 DISPATCHER: trying to submit job (1, 0, 6)
11:53:54 DISPATCHER: trying to notify the job_runner thread.
11:53:54 HBMASTER: job (1, 0, 6) submitted to dispatcher
11:53:54 DISPATCHER: Trying to submit another job.
11:53:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:53:54 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:53:54 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:53:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:53:54 WORKER: start processing job (1, 0, 6)
11:53:54 WORKER: args: ()
11:53:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02181423408716945, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02676183843616804, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 27, 'num_filters_4': 103, 'num_filters_5': 54}, 'budget': 400.0, 'working_directory': '.'}
11:54:48 DISPATCHER: Starting worker discovery
11:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:48 DISPATCHER: Finished worker discovery
11:55:48 DISPATCHER: Starting worker discovery
11:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:48 DISPATCHER: Finished worker discovery
11:56:48 DISPATCHER: Starting worker discovery
11:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:48 DISPATCHER: Finished worker discovery
11:57:48 DISPATCHER: Starting worker discovery
11:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:48 DISPATCHER: Finished worker discovery
11:58:48 DISPATCHER: Starting worker discovery
11:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:48 DISPATCHER: Finished worker discovery
11:59:48 DISPATCHER: Starting worker discovery
11:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:48 DISPATCHER: Finished worker discovery
12:00:48 DISPATCHER: Starting worker discovery
12:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:49 DISPATCHER: Finished worker discovery
12:00:50 WORKER: done with job (1, 0, 6), trying to register it.
12:00:50 WORKER: registered result for job (1, 0, 6) with dispatcher
12:00:50 DISPATCHER: job (1, 0, 6) finished
12:00:50 DISPATCHER: register_result: lock acquired
12:00:50 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:00:50 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02181423408716945, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02676183843616804, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 27, 'num_filters_4': 103, 'num_filters_5': 54}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8584222973899767, 'info': {'number_mnist': 0.8584222973899767, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02181423408716945, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02676183843616804, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 27, 'num_filters_4': 103, 'num_filters_5': 54}"}}
exception: None

12:00:50 job_callback for (1, 0, 6) started
12:00:50 DISPATCHER: Trying to submit another job.
12:00:50 job_callback for (1, 0, 6) got condition
12:00:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:00:50 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:00:50 HBMASTER: Trying to run another job!
12:00:50 job_callback for (1, 0, 6) finished
12:00:50 ITERATION: Advancing config (1, 0, 0) to next budget 1200.000000
12:00:50 HBMASTER: schedule new run for iteration 1
12:00:50 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
12:00:50 HBMASTER: submitting job (1, 0, 0) to dispatcher
12:00:50 DISPATCHER: trying to submit job (1, 0, 0)
12:00:50 DISPATCHER: trying to notify the job_runner thread.
12:00:50 HBMASTER: job (1, 0, 0) submitted to dispatcher
12:00:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:00:50 DISPATCHER: Trying to submit another job.
12:00:50 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:00:50 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:00:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:00:50 WORKER: start processing job (1, 0, 0)
12:00:50 WORKER: args: ()
12:00:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}, 'budget': 1200.0, 'working_directory': '.'}
12:01:49 DISPATCHER: Starting worker discovery
12:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:49 DISPATCHER: Finished worker discovery
12:02:49 DISPATCHER: Starting worker discovery
12:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:49 DISPATCHER: Finished worker discovery
12:03:49 DISPATCHER: Starting worker discovery
12:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:49 DISPATCHER: Finished worker discovery
12:04:49 DISPATCHER: Starting worker discovery
12:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:49 DISPATCHER: Finished worker discovery
12:05:49 DISPATCHER: Starting worker discovery
12:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:49 DISPATCHER: Finished worker discovery
12:06:49 DISPATCHER: Starting worker discovery
12:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:49 DISPATCHER: Finished worker discovery
12:07:49 DISPATCHER: Starting worker discovery
12:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:49 DISPATCHER: Finished worker discovery
12:08:49 DISPATCHER: Starting worker discovery
12:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:49 DISPATCHER: Finished worker discovery
12:09:49 DISPATCHER: Starting worker discovery
12:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:49 DISPATCHER: Finished worker discovery
12:10:49 DISPATCHER: Starting worker discovery
12:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:49 DISPATCHER: Finished worker discovery
12:11:49 DISPATCHER: Starting worker discovery
12:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:49 DISPATCHER: Finished worker discovery
12:12:49 DISPATCHER: Starting worker discovery
12:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:49 DISPATCHER: Finished worker discovery
12:13:49 DISPATCHER: Starting worker discovery
12:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:49 DISPATCHER: Finished worker discovery
12:14:49 DISPATCHER: Starting worker discovery
12:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:49 DISPATCHER: Finished worker discovery
12:15:49 DISPATCHER: Starting worker discovery
12:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:49 DISPATCHER: Finished worker discovery
12:16:49 DISPATCHER: Starting worker discovery
12:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:49 DISPATCHER: Finished worker discovery
12:17:49 DISPATCHER: Starting worker discovery
12:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:49 DISPATCHER: Finished worker discovery
12:18:49 DISPATCHER: Starting worker discovery
12:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:49 DISPATCHER: Finished worker discovery
12:19:49 DISPATCHER: Starting worker discovery
12:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:49 DISPATCHER: Finished worker discovery
12:20:49 DISPATCHER: Starting worker discovery
12:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:49 DISPATCHER: Finished worker discovery
12:21:19 WORKER: done with job (1, 0, 0), trying to register it.
12:21:19 WORKER: registered result for job (1, 0, 0) with dispatcher
12:21:19 DISPATCHER: job (1, 0, 0) finished
12:21:19 DISPATCHER: register_result: lock acquired
12:21:19 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:21:19 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9248674335813034, 'info': {'number_mnist': 0.9248674335813034, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001315582219820231, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.013225398018534954}"}}
exception: None

12:21:19 job_callback for (1, 0, 0) started
12:21:19 job_callback for (1, 0, 0) got condition
12:21:19 DISPATCHER: Trying to submit another job.
12:21:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:21:19 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:21:19 HBMASTER: Trying to run another job!
12:21:19 job_callback for (1, 0, 0) finished
12:21:19 start sampling a new configuration.
12:21:19 done sampling a new configuration.
12:21:19 HBMASTER: schedule new run for iteration 2
12:21:19 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
12:21:19 HBMASTER: submitting job (2, 0, 0) to dispatcher
12:21:19 DISPATCHER: trying to submit job (2, 0, 0)
12:21:19 DISPATCHER: trying to notify the job_runner thread.
12:21:19 HBMASTER: job (2, 0, 0) submitted to dispatcher
12:21:19 DISPATCHER: Trying to submit another job.
12:21:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:21:19 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:21:19 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:21:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:21:19 WORKER: start processing job (2, 0, 0)
12:21:19 WORKER: args: ()
12:21:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008321451965775262, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0326558957770536, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 400.0, 'working_directory': '.'}
12:21:49 DISPATCHER: Starting worker discovery
12:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:49 DISPATCHER: Finished worker discovery
12:22:49 DISPATCHER: Starting worker discovery
12:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:49 DISPATCHER: Finished worker discovery
12:23:49 DISPATCHER: Starting worker discovery
12:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:49 DISPATCHER: Finished worker discovery
12:24:49 DISPATCHER: Starting worker discovery
12:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:49 DISPATCHER: Finished worker discovery
12:25:49 DISPATCHER: Starting worker discovery
12:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:49 DISPATCHER: Finished worker discovery
12:26:49 DISPATCHER: Starting worker discovery
12:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:49 DISPATCHER: Finished worker discovery
12:27:49 DISPATCHER: Starting worker discovery
12:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:49 DISPATCHER: Finished worker discovery
12:28:12 WORKER: done with job (2, 0, 0), trying to register it.
12:28:12 WORKER: registered result for job (2, 0, 0) with dispatcher
12:28:12 DISPATCHER: job (2, 0, 0) finished
12:28:12 DISPATCHER: register_result: lock acquired
12:28:12 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:28:12 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008321451965775262, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0326558957770536, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8462243031127266, 'info': {'number_mnist': 0.8462243031127266, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008321451965775262, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0326558957770536, 'kernel_size_2': 5, 'num_filters_2': 74}"}}
exception: None

12:28:12 job_callback for (2, 0, 0) started
12:28:12 DISPATCHER: Trying to submit another job.
12:28:12 job_callback for (2, 0, 0) got condition
12:28:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:28:12 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:28:12 HBMASTER: Trying to run another job!
12:28:12 job_callback for (2, 0, 0) finished
12:28:12 start sampling a new configuration.
12:28:12 done sampling a new configuration.
12:28:12 HBMASTER: schedule new run for iteration 2
12:28:12 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
12:28:12 HBMASTER: submitting job (2, 0, 1) to dispatcher
12:28:12 DISPATCHER: trying to submit job (2, 0, 1)
12:28:12 DISPATCHER: trying to notify the job_runner thread.
12:28:12 HBMASTER: job (2, 0, 1) submitted to dispatcher
12:28:12 DISPATCHER: Trying to submit another job.
12:28:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:28:12 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:28:12 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:28:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:28:12 WORKER: start processing job (2, 0, 1)
12:28:12 WORKER: args: ()
12:28:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004064540702532689, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.04490959692472633, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 36, 'num_filters_3': 39, 'num_filters_4': 82}, 'budget': 400.0, 'working_directory': '.'}
12:28:49 DISPATCHER: Starting worker discovery
12:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:49 DISPATCHER: Finished worker discovery
12:29:49 DISPATCHER: Starting worker discovery
12:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:49 DISPATCHER: Finished worker discovery
12:30:49 DISPATCHER: Starting worker discovery
12:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:49 DISPATCHER: Finished worker discovery
12:31:49 DISPATCHER: Starting worker discovery
12:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:49 DISPATCHER: Finished worker discovery
12:32:49 DISPATCHER: Starting worker discovery
12:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:49 DISPATCHER: Finished worker discovery
12:33:49 DISPATCHER: Starting worker discovery
12:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:49 DISPATCHER: Finished worker discovery
12:34:49 DISPATCHER: Starting worker discovery
12:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:49 DISPATCHER: Finished worker discovery
12:35:05 WORKER: done with job (2, 0, 1), trying to register it.
12:35:05 WORKER: registered result for job (2, 0, 1) with dispatcher
12:35:05 DISPATCHER: job (2, 0, 1) finished
12:35:05 DISPATCHER: register_result: lock acquired
12:35:05 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:35:05 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004064540702532689, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.04490959692472633, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 36, 'num_filters_3': 39, 'num_filters_4': 82}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7457399799713926, 'info': {'number_mnist': 0.7457399799713926, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004064540702532689, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.04490959692472633, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 36, 'num_filters_3': 39, 'num_filters_4': 82}"}}
exception: None

12:35:05 job_callback for (2, 0, 1) started
12:35:05 DISPATCHER: Trying to submit another job.
12:35:05 job_callback for (2, 0, 1) got condition
12:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:35:05 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:35:05 HBMASTER: Trying to run another job!
12:35:05 job_callback for (2, 0, 1) finished
12:35:05 start sampling a new configuration.
12:35:05 done sampling a new configuration.
12:35:05 HBMASTER: schedule new run for iteration 2
12:35:05 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
12:35:05 HBMASTER: submitting job (2, 0, 2) to dispatcher
12:35:05 DISPATCHER: trying to submit job (2, 0, 2)
12:35:05 DISPATCHER: trying to notify the job_runner thread.
12:35:05 HBMASTER: job (2, 0, 2) submitted to dispatcher
12:35:05 DISPATCHER: Trying to submit another job.
12:35:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:35:05 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:35:05 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:35:05 WORKER: start processing job (2, 0, 2)
12:35:05 WORKER: args: ()
12:35:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006140836760103339, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.015543654724101356, 'kernel_size_2': 3, 'num_filters_2': 80}, 'budget': 400.0, 'working_directory': '.'}
12:35:49 DISPATCHER: Starting worker discovery
12:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:49 DISPATCHER: Finished worker discovery
12:36:49 DISPATCHER: Starting worker discovery
12:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:49 DISPATCHER: Finished worker discovery
12:37:49 DISPATCHER: Starting worker discovery
12:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:49 DISPATCHER: Finished worker discovery
12:38:49 DISPATCHER: Starting worker discovery
12:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:49 DISPATCHER: Finished worker discovery
12:39:49 DISPATCHER: Starting worker discovery
12:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:49 DISPATCHER: Finished worker discovery
12:40:49 DISPATCHER: Starting worker discovery
12:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:49 DISPATCHER: Finished worker discovery
12:41:49 DISPATCHER: Starting worker discovery
12:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:49 DISPATCHER: Finished worker discovery
12:42:37 WORKER: done with job (2, 0, 2), trying to register it.
12:42:37 WORKER: registered result for job (2, 0, 2) with dispatcher
12:42:37 DISPATCHER: job (2, 0, 2) finished
12:42:37 DISPATCHER: register_result: lock acquired
12:42:37 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:42:37 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006140836760103339, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.015543654724101356, 'kernel_size_2': 3, 'num_filters_2': 80}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7952751258479748, 'info': {'number_mnist': 0.7952751258479748, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006140836760103339, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.015543654724101356, 'kernel_size_2': 3, 'num_filters_2': 80}"}}
exception: None

12:42:37 job_callback for (2, 0, 2) started
12:42:37 job_callback for (2, 0, 2) got condition
12:42:37 DISPATCHER: Trying to submit another job.
12:42:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:42:37 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:42:37 HBMASTER: Trying to run another job!
12:42:37 job_callback for (2, 0, 2) finished
12:42:37 start sampling a new configuration.
12:42:37 done sampling a new configuration.
12:42:37 HBMASTER: schedule new run for iteration 2
12:42:37 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
12:42:37 HBMASTER: submitting job (2, 0, 3) to dispatcher
12:42:37 DISPATCHER: trying to submit job (2, 0, 3)
12:42:37 DISPATCHER: trying to notify the job_runner thread.
12:42:37 HBMASTER: job (2, 0, 3) submitted to dispatcher
12:42:37 DISPATCHER: Trying to submit another job.
12:42:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:42:37 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:42:37 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:42:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:42:37 WORKER: start processing job (2, 0, 3)
12:42:37 WORKER: args: ()
12:42:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04103817580286797, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.16727096565754423, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 93, 'num_filters_3': 42, 'num_filters_4': 99}, 'budget': 400.0, 'working_directory': '.'}
12:42:49 DISPATCHER: Starting worker discovery
12:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:49 DISPATCHER: Finished worker discovery
12:43:49 DISPATCHER: Starting worker discovery
12:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:49 DISPATCHER: Finished worker discovery
12:44:49 DISPATCHER: Starting worker discovery
12:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:49 DISPATCHER: Finished worker discovery
12:45:49 DISPATCHER: Starting worker discovery
12:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:49 DISPATCHER: Finished worker discovery
12:46:49 DISPATCHER: Starting worker discovery
12:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:49 DISPATCHER: Finished worker discovery
12:47:49 DISPATCHER: Starting worker discovery
12:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:49 DISPATCHER: Finished worker discovery
12:48:49 DISPATCHER: Starting worker discovery
12:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:49 DISPATCHER: Finished worker discovery
12:49:32 WORKER: done with job (2, 0, 3), trying to register it.
12:49:32 WORKER: registered result for job (2, 0, 3) with dispatcher
12:49:32 DISPATCHER: job (2, 0, 3) finished
12:49:32 DISPATCHER: register_result: lock acquired
12:49:32 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:49:32 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04103817580286797, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.16727096565754423, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 93, 'num_filters_3': 42, 'num_filters_4': 99}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.00015681331492386374, 'info': {'number_mnist': 0.00015681331492386374, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04103817580286797, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.16727096565754423, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 93, 'num_filters_3': 42, 'num_filters_4': 99}"}}
exception: None

12:49:32 job_callback for (2, 0, 3) started
12:49:32 DISPATCHER: Trying to submit another job.
12:49:32 job_callback for (2, 0, 3) got condition
12:49:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:49:32 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:49:32 HBMASTER: Trying to run another job!
12:49:32 job_callback for (2, 0, 3) finished
12:49:32 start sampling a new configuration.
12:49:32 done sampling a new configuration.
12:49:32 HBMASTER: schedule new run for iteration 2
12:49:32 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
12:49:32 HBMASTER: submitting job (2, 0, 4) to dispatcher
12:49:32 DISPATCHER: trying to submit job (2, 0, 4)
12:49:32 DISPATCHER: trying to notify the job_runner thread.
12:49:32 HBMASTER: job (2, 0, 4) submitted to dispatcher
12:49:32 DISPATCHER: Trying to submit another job.
12:49:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:49:32 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:49:32 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:49:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:49:32 WORKER: start processing job (2, 0, 4)
12:49:32 WORKER: args: ()
12:49:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001233418618853257, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.03986024640605939, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 109, 'num_filters_3': 16}, 'budget': 400.0, 'working_directory': '.'}
12:49:49 DISPATCHER: Starting worker discovery
12:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:49 DISPATCHER: Finished worker discovery
12:50:49 DISPATCHER: Starting worker discovery
12:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:49 DISPATCHER: Finished worker discovery
12:51:49 DISPATCHER: Starting worker discovery
12:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:49 DISPATCHER: Finished worker discovery
12:52:49 DISPATCHER: Starting worker discovery
12:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:49 DISPATCHER: Finished worker discovery
12:53:49 DISPATCHER: Starting worker discovery
12:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:49 DISPATCHER: Finished worker discovery
12:54:49 DISPATCHER: Starting worker discovery
12:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:49 DISPATCHER: Finished worker discovery
12:55:49 DISPATCHER: Starting worker discovery
12:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:49 DISPATCHER: Finished worker discovery
12:56:34 WORKER: done with job (2, 0, 4), trying to register it.
12:56:34 WORKER: registered result for job (2, 0, 4) with dispatcher
12:56:34 DISPATCHER: job (2, 0, 4) finished
12:56:34 DISPATCHER: register_result: lock acquired
12:56:34 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:56:34 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001233418618853257, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.03986024640605939, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 109, 'num_filters_3': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7179034643227078, 'info': {'number_mnist': 0.7179034643227078, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001233418618853257, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.03986024640605939, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 109, 'num_filters_3': 16}"}}
exception: None

12:56:34 job_callback for (2, 0, 4) started
12:56:34 job_callback for (2, 0, 4) got condition
12:56:34 DISPATCHER: Trying to submit another job.
12:56:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:56:34 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:56:34 HBMASTER: Trying to run another job!
12:56:34 job_callback for (2, 0, 4) finished
12:56:34 start sampling a new configuration.
12:56:34 done sampling a new configuration.
12:56:34 HBMASTER: schedule new run for iteration 2
12:56:34 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
12:56:34 HBMASTER: submitting job (2, 0, 5) to dispatcher
12:56:34 DISPATCHER: trying to submit job (2, 0, 5)
12:56:34 DISPATCHER: trying to notify the job_runner thread.
12:56:34 HBMASTER: job (2, 0, 5) submitted to dispatcher
12:56:34 DISPATCHER: Trying to submit another job.
12:56:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:56:34 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:56:34 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:56:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:56:34 WORKER: start processing job (2, 0, 5)
12:56:34 WORKER: args: ()
12:56:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06992808376914887, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.03824946920443567, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 54}, 'budget': 400.0, 'working_directory': '.'}
12:56:49 DISPATCHER: Starting worker discovery
12:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:49 DISPATCHER: Finished worker discovery
12:57:49 DISPATCHER: Starting worker discovery
12:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:49 DISPATCHER: Finished worker discovery
12:58:49 DISPATCHER: Starting worker discovery
12:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:49 DISPATCHER: Finished worker discovery
12:59:49 DISPATCHER: Starting worker discovery
12:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:49 DISPATCHER: Finished worker discovery
13:00:49 DISPATCHER: Starting worker discovery
13:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:49 DISPATCHER: Finished worker discovery
13:01:49 DISPATCHER: Starting worker discovery
13:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:49 DISPATCHER: Finished worker discovery
13:02:49 DISPATCHER: Starting worker discovery
13:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:49 DISPATCHER: Finished worker discovery
13:03:29 WORKER: done with job (2, 0, 5), trying to register it.
13:03:29 WORKER: registered result for job (2, 0, 5) with dispatcher
13:03:29 DISPATCHER: job (2, 0, 5) finished
13:03:29 DISPATCHER: register_result: lock acquired
13:03:29 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:03:29 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06992808376914887, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.03824946920443567, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 54}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5980362377359871, 'info': {'number_mnist': 0.5980362377359871, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06992808376914887, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.03824946920443567, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 54}"}}
exception: None

13:03:29 job_callback for (2, 0, 5) started
13:03:29 DISPATCHER: Trying to submit another job.
13:03:29 job_callback for (2, 0, 5) got condition
13:03:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:03:29 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:03:29 HBMASTER: Trying to run another job!
13:03:29 job_callback for (2, 0, 5) finished
13:03:29 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
13:03:29 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
13:03:29 HBMASTER: schedule new run for iteration 2
13:03:29 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
13:03:29 HBMASTER: submitting job (2, 0, 0) to dispatcher
13:03:29 DISPATCHER: trying to submit job (2, 0, 0)
13:03:29 DISPATCHER: trying to notify the job_runner thread.
13:03:29 HBMASTER: job (2, 0, 0) submitted to dispatcher
13:03:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:03:29 DISPATCHER: Trying to submit another job.
13:03:29 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:03:29 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:03:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:03:29 WORKER: start processing job (2, 0, 0)
13:03:29 WORKER: args: ()
13:03:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008321451965775262, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0326558957770536, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 1200.0, 'working_directory': '.'}
13:03:49 DISPATCHER: Starting worker discovery
13:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:49 DISPATCHER: Finished worker discovery
13:04:49 DISPATCHER: Starting worker discovery
13:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:49 DISPATCHER: Finished worker discovery
13:05:49 DISPATCHER: Starting worker discovery
13:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:49 DISPATCHER: Finished worker discovery
13:06:49 DISPATCHER: Starting worker discovery
13:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:49 DISPATCHER: Finished worker discovery
13:07:49 DISPATCHER: Starting worker discovery
13:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:49 DISPATCHER: Finished worker discovery
13:08:49 DISPATCHER: Starting worker discovery
13:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:49 DISPATCHER: Finished worker discovery
13:09:49 DISPATCHER: Starting worker discovery
13:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:49 DISPATCHER: Finished worker discovery
13:10:49 DISPATCHER: Starting worker discovery
13:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:49 DISPATCHER: Finished worker discovery
13:11:49 DISPATCHER: Starting worker discovery
13:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:49 DISPATCHER: Finished worker discovery
13:12:49 DISPATCHER: Starting worker discovery
13:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:49 DISPATCHER: Finished worker discovery
13:13:49 DISPATCHER: Starting worker discovery
13:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:49 DISPATCHER: Finished worker discovery
13:14:49 DISPATCHER: Starting worker discovery
13:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:49 DISPATCHER: Finished worker discovery
13:15:49 DISPATCHER: Starting worker discovery
13:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:49 DISPATCHER: Finished worker discovery
13:16:49 DISPATCHER: Starting worker discovery
13:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:49 DISPATCHER: Finished worker discovery
13:17:49 DISPATCHER: Starting worker discovery
13:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:49 DISPATCHER: Finished worker discovery
13:18:49 DISPATCHER: Starting worker discovery
13:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:49 DISPATCHER: Finished worker discovery
13:19:49 DISPATCHER: Starting worker discovery
13:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:49 DISPATCHER: Finished worker discovery
13:20:49 DISPATCHER: Starting worker discovery
13:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:49 DISPATCHER: Finished worker discovery
13:21:49 DISPATCHER: Starting worker discovery
13:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:49 DISPATCHER: Finished worker discovery
13:22:49 DISPATCHER: Starting worker discovery
13:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:49 DISPATCHER: Finished worker discovery
13:23:49 DISPATCHER: Starting worker discovery
13:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:49 DISPATCHER: Finished worker discovery
13:23:51 WORKER: done with job (2, 0, 0), trying to register it.
13:23:51 WORKER: registered result for job (2, 0, 0) with dispatcher
13:23:51 DISPATCHER: job (2, 0, 0) finished
13:23:51 DISPATCHER: register_result: lock acquired
13:23:51 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:23:51 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008321451965775262, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0326558957770536, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8820755821841126, 'info': {'number_mnist': 0.8820755821841126, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008321451965775262, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0326558957770536, 'kernel_size_2': 5, 'num_filters_2': 74}"}}
exception: None

13:23:51 job_callback for (2, 0, 0) started
13:23:51 DISPATCHER: Trying to submit another job.
13:23:51 job_callback for (2, 0, 0) got condition
13:23:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:23:51 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:23:51 HBMASTER: Trying to run another job!
13:23:51 job_callback for (2, 0, 0) finished
13:23:51 HBMASTER: schedule new run for iteration 2
13:23:51 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
13:23:51 HBMASTER: submitting job (2, 0, 2) to dispatcher
13:23:51 DISPATCHER: trying to submit job (2, 0, 2)
13:23:51 DISPATCHER: trying to notify the job_runner thread.
13:23:51 HBMASTER: job (2, 0, 2) submitted to dispatcher
13:23:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:23:51 DISPATCHER: Trying to submit another job.
13:23:51 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:23:51 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:23:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:23:51 WORKER: start processing job (2, 0, 2)
13:23:51 WORKER: args: ()
13:23:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006140836760103339, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.015543654724101356, 'kernel_size_2': 3, 'num_filters_2': 80}, 'budget': 1200.0, 'working_directory': '.'}
13:24:49 DISPATCHER: Starting worker discovery
13:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:49 DISPATCHER: Finished worker discovery
13:25:49 DISPATCHER: Starting worker discovery
13:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:49 DISPATCHER: Finished worker discovery
13:26:49 DISPATCHER: Starting worker discovery
13:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:49 DISPATCHER: Finished worker discovery
13:27:49 DISPATCHER: Starting worker discovery
13:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:49 DISPATCHER: Finished worker discovery
13:28:49 DISPATCHER: Starting worker discovery
13:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:49 DISPATCHER: Finished worker discovery
13:29:49 DISPATCHER: Starting worker discovery
13:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:49 DISPATCHER: Finished worker discovery
13:30:49 DISPATCHER: Starting worker discovery
13:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:49 DISPATCHER: Finished worker discovery
13:31:49 DISPATCHER: Starting worker discovery
13:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:49 DISPATCHER: Finished worker discovery
13:32:49 DISPATCHER: Starting worker discovery
13:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:49 DISPATCHER: Finished worker discovery
13:33:49 DISPATCHER: Starting worker discovery
13:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:49 DISPATCHER: Finished worker discovery
13:34:49 DISPATCHER: Starting worker discovery
13:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:49 DISPATCHER: Finished worker discovery
13:35:49 DISPATCHER: Starting worker discovery
13:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:49 DISPATCHER: Finished worker discovery
13:36:49 DISPATCHER: Starting worker discovery
13:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:49 DISPATCHER: Finished worker discovery
13:37:49 DISPATCHER: Starting worker discovery
13:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:49 DISPATCHER: Finished worker discovery
13:38:49 DISPATCHER: Starting worker discovery
13:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:49 DISPATCHER: Finished worker discovery
13:39:49 DISPATCHER: Starting worker discovery
13:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:49 DISPATCHER: Finished worker discovery
13:40:49 DISPATCHER: Starting worker discovery
13:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:49 DISPATCHER: Finished worker discovery
13:41:49 DISPATCHER: Starting worker discovery
13:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:49 DISPATCHER: Finished worker discovery
13:42:49 DISPATCHER: Starting worker discovery
13:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:49 DISPATCHER: Finished worker discovery
13:43:49 DISPATCHER: Starting worker discovery
13:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:49 DISPATCHER: Finished worker discovery
13:44:49 DISPATCHER: Starting worker discovery
13:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:50 DISPATCHER: Finished worker discovery
13:45:50 DISPATCHER: Starting worker discovery
13:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:50 DISPATCHER: Finished worker discovery
13:46:09 WORKER: done with job (2, 0, 2), trying to register it.
13:46:09 WORKER: registered result for job (2, 0, 2) with dispatcher
13:46:09 DISPATCHER: job (2, 0, 2) finished
13:46:09 DISPATCHER: register_result: lock acquired
13:46:09 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:46:09 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006140836760103339, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.015543654724101356, 'kernel_size_2': 3, 'num_filters_2': 80}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7493450129703831, 'info': {'number_mnist': 0.7493450129703831, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006140836760103339, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.015543654724101356, 'kernel_size_2': 3, 'num_filters_2': 80}"}}
exception: None

13:46:09 job_callback for (2, 0, 2) started
13:46:09 job_callback for (2, 0, 2) got condition
13:46:09 DISPATCHER: Trying to submit another job.
13:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:46:09 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:46:09 HBMASTER: Trying to run another job!
13:46:09 job_callback for (2, 0, 2) finished
13:46:09 start sampling a new configuration.
13:46:09 done sampling a new configuration.
13:46:09 HBMASTER: schedule new run for iteration 3
13:46:09 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
13:46:09 HBMASTER: submitting job (3, 0, 0) to dispatcher
13:46:09 DISPATCHER: trying to submit job (3, 0, 0)
13:46:09 DISPATCHER: trying to notify the job_runner thread.
13:46:09 HBMASTER: job (3, 0, 0) submitted to dispatcher
13:46:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:46:09 DISPATCHER: Trying to submit another job.
13:46:09 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:46:09 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:46:09 WORKER: start processing job (3, 0, 0)
13:46:09 WORKER: args: ()
13:46:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004055556081956606, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.14272635318731688}, 'budget': 1200.0, 'working_directory': '.'}
13:46:50 DISPATCHER: Starting worker discovery
13:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:50 DISPATCHER: Finished worker discovery
13:47:50 DISPATCHER: Starting worker discovery
13:47:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:50 DISPATCHER: Finished worker discovery
13:48:50 DISPATCHER: Starting worker discovery
13:48:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:50 DISPATCHER: Finished worker discovery
13:49:50 DISPATCHER: Starting worker discovery
13:49:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:50 DISPATCHER: Finished worker discovery
13:50:50 DISPATCHER: Starting worker discovery
13:50:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:50 DISPATCHER: Finished worker discovery
13:51:50 DISPATCHER: Starting worker discovery
13:51:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:50 DISPATCHER: Finished worker discovery
13:52:50 DISPATCHER: Starting worker discovery
13:52:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:50 DISPATCHER: Finished worker discovery
13:53:50 DISPATCHER: Starting worker discovery
13:53:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:50 DISPATCHER: Finished worker discovery
13:54:50 DISPATCHER: Starting worker discovery
13:54:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:50 DISPATCHER: Finished worker discovery
13:55:50 DISPATCHER: Starting worker discovery
13:55:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:50 DISPATCHER: Finished worker discovery
13:56:50 DISPATCHER: Starting worker discovery
13:56:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:50 DISPATCHER: Finished worker discovery
13:57:50 DISPATCHER: Starting worker discovery
13:57:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:50 DISPATCHER: Finished worker discovery
13:58:50 DISPATCHER: Starting worker discovery
13:58:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:50 DISPATCHER: Finished worker discovery
13:59:50 DISPATCHER: Starting worker discovery
13:59:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:50 DISPATCHER: Finished worker discovery
14:00:50 DISPATCHER: Starting worker discovery
14:00:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:50 DISPATCHER: Finished worker discovery
14:01:50 DISPATCHER: Starting worker discovery
14:01:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:50 DISPATCHER: Finished worker discovery
14:02:50 DISPATCHER: Starting worker discovery
14:02:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:50 DISPATCHER: Finished worker discovery
14:03:50 DISPATCHER: Starting worker discovery
14:03:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:50 DISPATCHER: Finished worker discovery
14:04:50 DISPATCHER: Starting worker discovery
14:04:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:50 DISPATCHER: Finished worker discovery
14:05:50 DISPATCHER: Starting worker discovery
14:05:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:50 DISPATCHER: Finished worker discovery
14:06:50 DISPATCHER: Starting worker discovery
14:06:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:50 DISPATCHER: Finished worker discovery
14:07:28 WORKER: done with job (3, 0, 0), trying to register it.
14:07:28 WORKER: registered result for job (3, 0, 0) with dispatcher
14:07:28 DISPATCHER: job (3, 0, 0) finished
14:07:28 DISPATCHER: register_result: lock acquired
14:07:28 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:07:28 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004055556081956606, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.14272635318731688}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.07370695196648881, 'info': {'number_mnist': 0.07370695196648881, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004055556081956606, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.14272635318731688}"}}
exception: None

14:07:28 job_callback for (3, 0, 0) started
14:07:28 DISPATCHER: Trying to submit another job.
14:07:28 job_callback for (3, 0, 0) got condition
14:07:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:07:28 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:07:28 HBMASTER: Trying to run another job!
14:07:28 job_callback for (3, 0, 0) finished
14:07:28 start sampling a new configuration.
14:07:28 done sampling a new configuration.
14:07:28 HBMASTER: schedule new run for iteration 3
14:07:28 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
14:07:28 HBMASTER: submitting job (3, 0, 1) to dispatcher
14:07:28 DISPATCHER: trying to submit job (3, 0, 1)
14:07:28 DISPATCHER: trying to notify the job_runner thread.
14:07:28 HBMASTER: job (3, 0, 1) submitted to dispatcher
14:07:28 DISPATCHER: Trying to submit another job.
14:07:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:07:28 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:07:28 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:07:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:07:28 WORKER: start processing job (3, 0, 1)
14:07:28 WORKER: args: ()
14:07:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002429998810957601, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.04463239277311918}, 'budget': 1200.0, 'working_directory': '.'}
14:07:50 DISPATCHER: Starting worker discovery
14:07:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:50 DISPATCHER: Finished worker discovery
14:08:50 DISPATCHER: Starting worker discovery
14:08:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:50 DISPATCHER: Finished worker discovery
14:09:50 DISPATCHER: Starting worker discovery
14:09:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:50 DISPATCHER: Finished worker discovery
14:10:50 DISPATCHER: Starting worker discovery
14:10:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:50 DISPATCHER: Finished worker discovery
14:11:50 DISPATCHER: Starting worker discovery
14:11:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:50 DISPATCHER: Finished worker discovery
14:12:50 DISPATCHER: Starting worker discovery
14:12:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:50 DISPATCHER: Finished worker discovery
14:13:50 DISPATCHER: Starting worker discovery
14:13:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:50 DISPATCHER: Finished worker discovery
14:14:50 DISPATCHER: Starting worker discovery
14:14:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:50 DISPATCHER: Finished worker discovery
14:15:50 DISPATCHER: Starting worker discovery
14:15:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:50 DISPATCHER: Finished worker discovery
14:16:50 DISPATCHER: Starting worker discovery
14:16:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:50 DISPATCHER: Finished worker discovery
14:17:50 DISPATCHER: Starting worker discovery
14:17:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:50 DISPATCHER: Finished worker discovery
14:18:50 DISPATCHER: Starting worker discovery
14:18:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:50 DISPATCHER: Finished worker discovery
14:19:50 DISPATCHER: Starting worker discovery
14:19:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:50 DISPATCHER: Finished worker discovery
14:20:50 DISPATCHER: Starting worker discovery
14:20:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:50 DISPATCHER: Finished worker discovery
14:21:50 DISPATCHER: Starting worker discovery
14:21:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:50 DISPATCHER: Finished worker discovery
14:22:50 DISPATCHER: Starting worker discovery
14:22:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:50 DISPATCHER: Finished worker discovery
14:23:50 DISPATCHER: Starting worker discovery
14:23:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:50 DISPATCHER: Finished worker discovery
14:24:50 DISPATCHER: Starting worker discovery
14:24:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:50 DISPATCHER: Finished worker discovery
14:25:50 DISPATCHER: Starting worker discovery
14:25:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:50 DISPATCHER: Finished worker discovery
14:26:50 DISPATCHER: Starting worker discovery
14:26:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:50 DISPATCHER: Finished worker discovery
14:27:50 DISPATCHER: Starting worker discovery
14:27:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:50 DISPATCHER: Finished worker discovery
14:28:50 DISPATCHER: Starting worker discovery
14:28:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:50 DISPATCHER: Finished worker discovery
14:29:43 WORKER: done with job (3, 0, 1), trying to register it.
14:29:43 WORKER: registered result for job (3, 0, 1) with dispatcher
14:29:43 DISPATCHER: job (3, 0, 1) finished
14:29:43 DISPATCHER: register_result: lock acquired
14:29:43 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:29:43 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002429998810957601, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.04463239277311918}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7789817860810604, 'info': {'number_mnist': 0.7789817860810604, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002429998810957601, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.04463239277311918}"}}
exception: None

14:29:43 job_callback for (3, 0, 1) started
14:29:43 DISPATCHER: Trying to submit another job.
14:29:43 job_callback for (3, 0, 1) got condition
14:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:29:43 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:29:43 HBMASTER: Trying to run another job!
14:29:43 job_callback for (3, 0, 1) finished
14:29:43 start sampling a new configuration.
14:29:43 done sampling a new configuration.
14:29:43 HBMASTER: schedule new run for iteration 3
14:29:43 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
14:29:43 HBMASTER: submitting job (3, 0, 2) to dispatcher
14:29:43 DISPATCHER: trying to submit job (3, 0, 2)
14:29:43 DISPATCHER: trying to notify the job_runner thread.
14:29:43 HBMASTER: job (3, 0, 2) submitted to dispatcher
14:29:43 DISPATCHER: Trying to submit another job.
14:29:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:29:43 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:29:43 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:29:43 WORKER: start processing job (3, 0, 2)
14:29:43 WORKER: args: ()
14:29:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02987356856334237, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.012355143852670515, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 90, 'num_filters_4': 18, 'num_filters_5': 117}, 'budget': 1200.0, 'working_directory': '.'}
14:29:50 DISPATCHER: Starting worker discovery
14:29:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:50 DISPATCHER: Finished worker discovery
14:30:50 DISPATCHER: Starting worker discovery
14:30:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:50 DISPATCHER: Finished worker discovery
14:31:50 DISPATCHER: Starting worker discovery
14:31:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:50 DISPATCHER: Finished worker discovery
14:32:50 DISPATCHER: Starting worker discovery
14:32:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:50 DISPATCHER: Finished worker discovery
14:33:50 DISPATCHER: Starting worker discovery
14:33:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:50 DISPATCHER: Finished worker discovery
14:34:50 DISPATCHER: Starting worker discovery
14:34:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:50 DISPATCHER: Finished worker discovery
14:35:50 DISPATCHER: Starting worker discovery
14:35:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:51 DISPATCHER: Finished worker discovery
14:36:51 DISPATCHER: Starting worker discovery
14:36:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:51 DISPATCHER: Finished worker discovery
14:37:51 DISPATCHER: Starting worker discovery
14:37:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:51 DISPATCHER: Finished worker discovery
14:38:51 DISPATCHER: Starting worker discovery
14:38:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:51 DISPATCHER: Finished worker discovery
14:39:51 DISPATCHER: Starting worker discovery
14:39:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:51 DISPATCHER: Finished worker discovery
14:40:51 DISPATCHER: Starting worker discovery
14:40:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:51 DISPATCHER: Finished worker discovery
14:41:51 DISPATCHER: Starting worker discovery
14:41:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:51 DISPATCHER: Finished worker discovery
14:42:51 DISPATCHER: Starting worker discovery
14:42:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:51 DISPATCHER: Finished worker discovery
14:43:51 DISPATCHER: Starting worker discovery
14:43:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:51 DISPATCHER: Finished worker discovery
14:44:51 DISPATCHER: Starting worker discovery
14:44:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:51 DISPATCHER: Finished worker discovery
14:45:51 DISPATCHER: Starting worker discovery
14:45:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:51 DISPATCHER: Finished worker discovery
14:46:51 DISPATCHER: Starting worker discovery
14:46:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:51 DISPATCHER: Finished worker discovery
14:47:51 DISPATCHER: Starting worker discovery
14:47:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:51 DISPATCHER: Finished worker discovery
14:48:51 DISPATCHER: Starting worker discovery
14:48:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:51 DISPATCHER: Finished worker discovery
14:49:51 DISPATCHER: Starting worker discovery
14:49:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:51 DISPATCHER: Finished worker discovery
14:50:36 WORKER: done with job (3, 0, 2), trying to register it.
14:50:36 WORKER: registered result for job (3, 0, 2) with dispatcher
14:50:36 DISPATCHER: job (3, 0, 2) finished
14:50:36 DISPATCHER: register_result: lock acquired
14:50:36 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:50:36 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02987356856334237, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.012355143852670515, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 90, 'num_filters_4': 18, 'num_filters_5': 117}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02987356856334237, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.012355143852670515, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 90, 'num_filters_4': 18, 'num_filters_5': 117}"}}
exception: None

14:50:36 job_callback for (3, 0, 2) started
14:50:36 job_callback for (3, 0, 2) got condition
14:50:36 DISPATCHER: Trying to submit another job.
14:50:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:36 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:50:36 HBMASTER: Trying to run another job!
14:50:36 job_callback for (3, 0, 2) finished
14:50:36 start sampling a new configuration.
14:50:36 done sampling a new configuration.
14:50:36 HBMASTER: schedule new run for iteration 3
14:50:36 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
14:50:36 HBMASTER: submitting job (3, 0, 3) to dispatcher
14:50:36 DISPATCHER: trying to submit job (3, 0, 3)
14:50:36 DISPATCHER: trying to notify the job_runner thread.
14:50:36 HBMASTER: job (3, 0, 3) submitted to dispatcher
14:50:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:36 DISPATCHER: Trying to submit another job.
14:50:36 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:50:36 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:50:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:36 WORKER: start processing job (3, 0, 3)
14:50:36 WORKER: args: ()
14:50:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002514666272533635, 'num_filters_1': 119, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.08024286309275985, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 35}, 'budget': 1200.0, 'working_directory': '.'}
14:50:51 DISPATCHER: Starting worker discovery
14:50:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:51 DISPATCHER: Finished worker discovery
14:51:51 DISPATCHER: Starting worker discovery
14:51:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:51 DISPATCHER: Finished worker discovery
14:52:51 DISPATCHER: Starting worker discovery
14:52:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:51 DISPATCHER: Finished worker discovery
14:53:51 DISPATCHER: Starting worker discovery
14:53:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:51 DISPATCHER: Finished worker discovery
14:54:51 DISPATCHER: Starting worker discovery
14:54:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:51 DISPATCHER: Finished worker discovery
14:55:51 DISPATCHER: Starting worker discovery
14:55:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:51 DISPATCHER: Finished worker discovery
14:56:51 DISPATCHER: Starting worker discovery
14:56:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:51 DISPATCHER: Finished worker discovery
14:57:51 DISPATCHER: Starting worker discovery
14:57:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:51 DISPATCHER: Finished worker discovery
14:58:51 DISPATCHER: Starting worker discovery
14:58:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:51 DISPATCHER: Finished worker discovery
14:59:51 DISPATCHER: Starting worker discovery
14:59:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:51 DISPATCHER: Finished worker discovery
15:00:51 DISPATCHER: Starting worker discovery
15:00:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:51 DISPATCHER: Finished worker discovery
15:01:51 DISPATCHER: Starting worker discovery
15:01:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:51 DISPATCHER: Finished worker discovery
15:02:51 DISPATCHER: Starting worker discovery
15:02:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:51 DISPATCHER: Finished worker discovery
15:03:51 DISPATCHER: Starting worker discovery
15:03:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:51 DISPATCHER: Finished worker discovery
15:04:51 DISPATCHER: Starting worker discovery
15:04:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:51 DISPATCHER: Finished worker discovery
15:05:51 DISPATCHER: Starting worker discovery
15:05:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:51 DISPATCHER: Finished worker discovery
15:06:51 DISPATCHER: Starting worker discovery
15:06:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:51 DISPATCHER: Finished worker discovery
15:07:51 DISPATCHER: Starting worker discovery
15:07:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:51 DISPATCHER: Finished worker discovery
15:08:51 DISPATCHER: Starting worker discovery
15:08:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:51 DISPATCHER: Finished worker discovery
15:09:51 DISPATCHER: Starting worker discovery
15:09:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:51 DISPATCHER: Finished worker discovery
15:10:51 DISPATCHER: Starting worker discovery
15:10:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:51 DISPATCHER: Finished worker discovery
15:11:35 WORKER: done with job (3, 0, 3), trying to register it.
15:11:35 WORKER: registered result for job (3, 0, 3) with dispatcher
15:11:35 DISPATCHER: job (3, 0, 3) finished
15:11:35 DISPATCHER: register_result: lock acquired
15:11:35 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:11:35 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002514666272533635, 'num_filters_1': 119, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.08024286309275985, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 35}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6656385413003888, 'info': {'number_mnist': 0.6656385413003888, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002514666272533635, 'num_filters_1': 119, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.08024286309275985, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 35}"}}
exception: None

15:11:35 job_callback for (3, 0, 3) started
15:11:35 job_callback for (3, 0, 3) got condition
15:11:35 DISPATCHER: Trying to submit another job.
15:11:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:11:35 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:11:35 HBMASTER: Trying to run another job!
15:11:35 job_callback for (3, 0, 3) finished
15:11:35 start sampling a new configuration.
15:11:35 done sampling a new configuration.
15:11:35 HBMASTER: schedule new run for iteration 4
15:11:35 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
15:11:35 HBMASTER: submitting job (4, 0, 0) to dispatcher
15:11:35 DISPATCHER: trying to submit job (4, 0, 0)
15:11:35 DISPATCHER: trying to notify the job_runner thread.
15:11:35 HBMASTER: job (4, 0, 0) submitted to dispatcher
15:11:35 DISPATCHER: Trying to submit another job.
15:11:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:11:35 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:11:35 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:11:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:11:35 WORKER: start processing job (4, 0, 0)
15:11:35 WORKER: args: ()
15:11:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011305789457210587, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.014729388055822336}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:11:51 DISPATCHER: Starting worker discovery
15:11:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:51 DISPATCHER: Finished worker discovery
15:12:29 WORKER: done with job (4, 0, 0), trying to register it.
15:12:29 WORKER: registered result for job (4, 0, 0) with dispatcher
15:12:29 DISPATCHER: job (4, 0, 0) finished
15:12:29 DISPATCHER: register_result: lock acquired
15:12:29 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:12:29 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011305789457210587, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.014729388055822336}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9248265500930083, 'info': {'number_mnist': 0.9248265500930083, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011305789457210587, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.014729388055822336}"}}
exception: None

15:12:29 job_callback for (4, 0, 0) started
15:12:29 DISPATCHER: Trying to submit another job.
15:12:29 job_callback for (4, 0, 0) got condition
15:12:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:12:29 HBMASTER: Trying to run another job!
15:12:29 job_callback for (4, 0, 0) finished
15:12:29 start sampling a new configuration.
15:12:29 done sampling a new configuration.
15:12:29 HBMASTER: schedule new run for iteration 4
15:12:29 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
15:12:29 HBMASTER: submitting job (4, 0, 1) to dispatcher
15:12:29 DISPATCHER: trying to submit job (4, 0, 1)
15:12:29 DISPATCHER: trying to notify the job_runner thread.
15:12:29 HBMASTER: job (4, 0, 1) submitted to dispatcher
15:12:29 DISPATCHER: Trying to submit another job.
15:12:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:12:29 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:12:29 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:12:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:12:29 WORKER: start processing job (4, 0, 1)
15:12:29 WORKER: args: ()
15:12:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001586154415374132, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.02393567574788662, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 24, 'num_filters_3': 57, 'num_filters_4': 52, 'num_filters_5': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:12:51 DISPATCHER: Starting worker discovery
15:12:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:51 DISPATCHER: Finished worker discovery
15:13:23 WORKER: done with job (4, 0, 1), trying to register it.
15:13:23 WORKER: registered result for job (4, 0, 1) with dispatcher
15:13:23 DISPATCHER: job (4, 0, 1) finished
15:13:23 DISPATCHER: register_result: lock acquired
15:13:23 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:13:23 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001586154415374132, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.02393567574788662, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 24, 'num_filters_3': 57, 'num_filters_4': 52, 'num_filters_5': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7538653277064682, 'info': {'number_mnist': 0.7538653277064682, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001586154415374132, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.02393567574788662, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 24, 'num_filters_3': 57, 'num_filters_4': 52, 'num_filters_5': 53}"}}
exception: None

15:13:23 job_callback for (4, 0, 1) started
15:13:23 DISPATCHER: Trying to submit another job.
15:13:23 job_callback for (4, 0, 1) got condition
15:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:13:23 HBMASTER: Trying to run another job!
15:13:23 job_callback for (4, 0, 1) finished
15:13:23 start sampling a new configuration.
15:13:23 done sampling a new configuration.
15:13:23 HBMASTER: schedule new run for iteration 4
15:13:23 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
15:13:23 HBMASTER: submitting job (4, 0, 2) to dispatcher
15:13:23 DISPATCHER: trying to submit job (4, 0, 2)
15:13:23 DISPATCHER: trying to notify the job_runner thread.
15:13:23 HBMASTER: job (4, 0, 2) submitted to dispatcher
15:13:23 DISPATCHER: Trying to submit another job.
15:13:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:13:23 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:13:23 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:13:23 WORKER: start processing job (4, 0, 2)
15:13:23 WORKER: args: ()
15:13:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.021896757666075083, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.04643915624646122, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:13:51 DISPATCHER: Starting worker discovery
15:13:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:51 DISPATCHER: Finished worker discovery
15:14:18 WORKER: done with job (4, 0, 2), trying to register it.
15:14:18 WORKER: registered result for job (4, 0, 2) with dispatcher
15:14:18 DISPATCHER: job (4, 0, 2) finished
15:14:18 DISPATCHER: register_result: lock acquired
15:14:18 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:14:18 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.021896757666075083, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.04643915624646122, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006654928497900771, 'info': {'number_mnist': 0.006654928497900771, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.021896757666075083, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.04643915624646122, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 25}"}}
exception: None

15:14:18 job_callback for (4, 0, 2) started
15:14:18 job_callback for (4, 0, 2) got condition
15:14:18 DISPATCHER: Trying to submit another job.
15:14:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:14:18 HBMASTER: Trying to run another job!
15:14:18 job_callback for (4, 0, 2) finished
15:14:18 start sampling a new configuration.
15:14:18 done sampling a new configuration.
15:14:18 HBMASTER: schedule new run for iteration 4
15:14:18 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
15:14:18 HBMASTER: submitting job (4, 0, 3) to dispatcher
15:14:18 DISPATCHER: trying to submit job (4, 0, 3)
15:14:18 DISPATCHER: trying to notify the job_runner thread.
15:14:18 HBMASTER: job (4, 0, 3) submitted to dispatcher
15:14:18 DISPATCHER: Trying to submit another job.
15:14:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:14:18 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:14:18 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:14:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:14:18 WORKER: start processing job (4, 0, 3)
15:14:18 WORKER: args: ()
15:14:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009697218984597068, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.14182013171224883}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:14:51 DISPATCHER: Starting worker discovery
15:14:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:51 DISPATCHER: Finished worker discovery
15:15:11 WORKER: done with job (4, 0, 3), trying to register it.
15:15:11 WORKER: registered result for job (4, 0, 3) with dispatcher
15:15:11 DISPATCHER: job (4, 0, 3) finished
15:15:11 DISPATCHER: register_result: lock acquired
15:15:11 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:15:11 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009697218984597068, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.14182013171224883}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.318074622322183, 'info': {'number_mnist': 0.318074622322183, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009697218984597068, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.14182013171224883}"}}
exception: None

15:15:11 job_callback for (4, 0, 3) started
15:15:11 DISPATCHER: Trying to submit another job.
15:15:11 job_callback for (4, 0, 3) got condition
15:15:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:15:11 HBMASTER: Trying to run another job!
15:15:11 job_callback for (4, 0, 3) finished
15:15:11 start sampling a new configuration.
15:15:11 done sampling a new configuration.
15:15:11 HBMASTER: schedule new run for iteration 4
15:15:11 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
15:15:11 HBMASTER: submitting job (4, 0, 4) to dispatcher
15:15:11 DISPATCHER: trying to submit job (4, 0, 4)
15:15:11 DISPATCHER: trying to notify the job_runner thread.
15:15:11 HBMASTER: job (4, 0, 4) submitted to dispatcher
15:15:11 DISPATCHER: Trying to submit another job.
15:15:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:15:11 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:15:11 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:15:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:15:11 WORKER: start processing job (4, 0, 4)
15:15:11 WORKER: args: ()
15:15:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0033041991006918818, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01610908535126511, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:15:51 DISPATCHER: Starting worker discovery
15:15:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:51 DISPATCHER: Finished worker discovery
15:16:06 WORKER: done with job (4, 0, 4), trying to register it.
15:16:06 WORKER: registered result for job (4, 0, 4) with dispatcher
15:16:06 DISPATCHER: job (4, 0, 4) finished
15:16:06 DISPATCHER: register_result: lock acquired
15:16:06 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:16:06 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0033041991006918818, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01610908535126511, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7987058679660722, 'info': {'number_mnist': 0.7987058679660722, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0033041991006918818, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01610908535126511, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 17}"}}
exception: None

15:16:06 job_callback for (4, 0, 4) started
15:16:06 DISPATCHER: Trying to submit another job.
15:16:06 job_callback for (4, 0, 4) got condition
15:16:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:16:06 HBMASTER: Trying to run another job!
15:16:06 job_callback for (4, 0, 4) finished
15:16:06 start sampling a new configuration.
15:16:06 done sampling a new configuration.
15:16:06 HBMASTER: schedule new run for iteration 4
15:16:06 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
15:16:06 HBMASTER: submitting job (4, 0, 5) to dispatcher
15:16:06 DISPATCHER: trying to submit job (4, 0, 5)
15:16:06 DISPATCHER: trying to notify the job_runner thread.
15:16:06 HBMASTER: job (4, 0, 5) submitted to dispatcher
15:16:06 DISPATCHER: Trying to submit another job.
15:16:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:16:06 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:16:06 WORKER: start processing job (4, 0, 5)
15:16:06 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:16:06 WORKER: args: ()
15:16:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:16:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020059100167091415, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.011951359026500652, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 107, 'num_filters_4': 96, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:16:51 DISPATCHER: Starting worker discovery
15:16:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:51 DISPATCHER: Finished worker discovery
15:17:00 WORKER: done with job (4, 0, 5), trying to register it.
15:17:00 WORKER: registered result for job (4, 0, 5) with dispatcher
15:17:00 DISPATCHER: job (4, 0, 5) finished
15:17:00 DISPATCHER: register_result: lock acquired
15:17:00 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:17:00 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020059100167091415, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.011951359026500652, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 107, 'num_filters_4': 96, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8679958541832503, 'info': {'number_mnist': 0.8679958541832503, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0020059100167091415, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.011951359026500652, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 107, 'num_filters_4': 96, 'num_filters_5': 52}"}}
exception: None

15:17:00 job_callback for (4, 0, 5) started
15:17:00 job_callback for (4, 0, 5) got condition
15:17:00 DISPATCHER: Trying to submit another job.
15:17:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:17:00 HBMASTER: Trying to run another job!
15:17:00 job_callback for (4, 0, 5) finished
15:17:00 start sampling a new configuration.
15:17:00 done sampling a new configuration.
15:17:00 HBMASTER: schedule new run for iteration 4
15:17:00 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
15:17:00 HBMASTER: submitting job (4, 0, 6) to dispatcher
15:17:00 DISPATCHER: trying to submit job (4, 0, 6)
15:17:00 DISPATCHER: trying to notify the job_runner thread.
15:17:00 HBMASTER: job (4, 0, 6) submitted to dispatcher
15:17:00 DISPATCHER: Trying to submit another job.
15:17:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:17:00 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:17:00 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:17:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:17:00 WORKER: start processing job (4, 0, 6)
15:17:00 WORKER: args: ()
15:17:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007923819922572649, 'num_filters_1': 63, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.09078990141662983, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 21, 'num_filters_4': 113, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:17:51 DISPATCHER: Starting worker discovery
15:17:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:51 DISPATCHER: Finished worker discovery
15:17:54 WORKER: done with job (4, 0, 6), trying to register it.
15:17:54 WORKER: registered result for job (4, 0, 6) with dispatcher
15:17:54 DISPATCHER: job (4, 0, 6) finished
15:17:54 DISPATCHER: register_result: lock acquired
15:17:54 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:17:54 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007923819922572649, 'num_filters_1': 63, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.09078990141662983, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 21, 'num_filters_4': 113, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.011136873447262493, 'info': {'number_mnist': 0.011136873447262493, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.007923819922572649, 'num_filters_1': 63, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.09078990141662983, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 21, 'num_filters_4': 113, 'num_filters_5': 27}"}}
exception: None

15:17:54 job_callback for (4, 0, 6) started
15:17:54 DISPATCHER: Trying to submit another job.
15:17:54 job_callback for (4, 0, 6) got condition
15:17:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:17:54 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.934535





15:17:54 HBMASTER: Trying to run another job!
15:17:54 job_callback for (4, 0, 6) finished
15:17:54 start sampling a new configuration.
15:17:54 sampled vector: [0, 0, 0.8242091227733688, 0.3018090888822122, 0.5054558702773175, 1, 0.8167495845901755, 0.6686423480695238, 2, 2, 2, 2, 0.49761466774365914, 0.6006218293080295, 0.2469082854586609, 0.46147428033409094] has EI value inf
15:17:54 data in the KDEs:
[[1.00000000e+00 1.00000000e+00 6.16592483e-02 4.36256510e-01
  2.99999200e-01 0.00000000e+00 3.35164799e-01 2.05491383e-03
  2.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  5.98789470e-01 7.06973316e-02 6.92099734e-01 6.55430702e-01]
 [1.00000000e+00 1.00000000e+00 8.53157402e-02 5.24473143e-01
  9.00001600e-01 0.00000000e+00 3.90109866e-01 3.65277808e-02
  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  2.96183948e-01 7.06973316e-02 6.92099734e-01 6.55430702e-01]
 [3.00000000e+00 0.00000000e+00 2.66504468e-02 3.85093827e-01
  9.99984000e-02 0.00000000e+00 5.32967040e-01 1.29270428e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  7.81815396e-01 7.93347517e-01 7.69994942e-01 6.55430702e-01]
 [3.00000000e+00 0.00000000e+00 2.41356567e-01 8.36853457e-01
  9.00001600e-01 0.00000000e+00 7.63736322e-01 1.84431104e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 1.00000000e+00
  8.21004146e-01 7.19515734e-01 3.12212382e-01 1.20511102e-01]
 [2.00000000e+00 0.00000000e+00 5.61041116e-02 9.39226643e-01
  9.99984000e-02 0.00000000e+00 7.96703362e-01 2.10658065e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  6.70441281e-01 3.12212382e-01 4.82419346e-01 8.47131983e-01]
 [2.00000000e+00 0.00000000e+00 3.43688910e-01 4.48226605e-01
  5.00000000e-01 0.00000000e+00 4.34065920e-01 3.28228386e-01
  2.00000000e+00 0.00000000e+00 2.00000000e+00 0.00000000e+00
  8.42020651e-01 2.26011930e-01 5.72270733e-01 5.81276596e-01]
 [0.00000000e+00 2.00000000e+00 1.51155724e-01 5.98789470e-01
  9.00001600e-01 1.00000000e+00 5.10989013e-01 5.95046181e-02
  0.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00
  2.06711555e-01 9.13431508e-01 8.62142562e-01 5.72270733e-01]
 [0.00000000e+00 0.00000000e+00 2.59533104e-01 6.55430702e-01
  5.00000000e-01 1.00000000e+00 3.13186772e-01 1.59159192e-01
  1.00000000e+00 2.00000000e+00 2.00000000e+00 0.00000000e+00
  3.12212382e-01 4.36732032e-02 5.72270733e-01 5.81276596e-01]
 [3.00000000e+00 0.00000000e+00 1.00172732e-01 2.06711555e-01
  9.00001600e-01 1.00000000e+00 4.12087893e-01 2.91342778e-01
  1.00000000e+00 0.00000000e+00 2.00000000e+00 0.00000000e+00
  2.06711555e-01 6.15676748e-01 5.72270733e-01 5.81276596e-01]
 [0.00000000e+00 2.00000000e+00 1.54684125e-01 2.62398612e-01
  2.99999200e-01 0.00000000e+00 4.01098879e-01 4.46488679e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  4.36732032e-02 7.06973316e-02 6.92099734e-01 6.55430702e-01]
 [2.00000000e+00 2.00000000e+00 3.30385040e-01 2.06711555e-01
  9.00001600e-01 0.00000000e+00 4.23076906e-01 3.35542259e-01
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  8.04605038e-01 7.99009783e-01 4.48226605e-01 9.51614955e-01]
 [3.00000000e+00 1.00000000e+00 6.16297768e-01 9.62599641e-02
  9.99984000e-02 1.00000000e+00 9.34065040e-02 4.66035609e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  2.96183948e-01 7.06973316e-02 6.92099734e-01 6.55430702e-01]
 [2.00000000e+00 2.00000000e+00 1.70274858e-03 1.50102742e-02
  7.00000800e-01 1.00000000e+00 6.53846188e-01 2.21260412e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  7.81815396e-01 7.93347517e-01 7.69994942e-01 9.30783677e-01]
 [3.00000000e+00 0.00000000e+00 4.15484660e-01 6.55430702e-01
  9.00001600e-01 1.00000000e+00 2.80219732e-01 4.74738593e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  8.47131983e-01 5.90114116e-01 2.62398612e-01 9.30783677e-01]
 [1.00000000e+00 1.00000000e+00 4.65634537e-01 8.04605038e-01
  9.00001600e-01 1.00000000e+00 7.63736322e-01 5.53700299e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  6.70441281e-01 3.12212382e-01 4.82419346e-01 8.47131983e-01]
 [2.00000000e+00 0.00000000e+00 5.51694773e-01 4.48226605e-01
  2.99999200e-01 1.00000000e+00 8.29670402e-01 7.18568674e-01
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  2.96183948e-01 2.26011930e-01 4.48226605e-01 9.51614955e-01]
 [3.00000000e+00 0.00000000e+00 6.27030469e-01 3.12212382e-01
  9.99984000e-02 1.00000000e+00 9.72527576e-01 8.23983864e-01
  1.00000000e+00 0.00000000e+00 2.00000000e+00 0.00000000e+00
  2.06711555e-01 6.15676748e-01 5.72270733e-01 5.81276596e-01]]
[[3.         2.         0.02499689 0.34272578 0.0999984  1.
  0.55494507 0.44014397 0.         1.         2.         1.
  0.48241935 0.24455523 0.34272578 0.20671155]
 [3.         0.         0.46502662 0.51430515 0.0999984  0.
  0.22527466 0.87724834 1.         1.         0.         1.
  0.6073085  0.14357878 0.93922664 0.26239861]
 [1.         2.         0.4933236  0.62389945 0.0999984  0.
  0.60989013 0.88525083 0.         1.         0.         1.
  0.86214256 0.9089921  0.20671155 0.18658964]
 [2.         0.         0.0530198  0.1205111  0.5        1.
  0.88461547 0.6331679  0.         2.         0.         1.
  0.7390824  0.26239861 0.93922664 0.26239861]
 [2.         0.         0.4626202  0.22601193 0.2999992  1.
  0.40109888 0.76601009 2.         1.         1.         1.
  0.7390824  0.43625651 0.29618395 0.93922664]
 [2.         1.         0.33426229 0.3277152  0.5        0.
  0.23626368 0.72509111 0.         1.         1.         1.
  0.86214256 0.9089921  0.29618395 0.93922664]
 [3.         1.         0.75088812 0.96764339 0.2999992  1.
  0.20329664 0.84757538 2.         1.         0.         1.
  0.01501027 0.9089921  0.93922664 0.26239861]
 [0.         1.         0.9522273  0.1205111  0.9000016  1.
  0.69780224 0.56618677 2.         1.         2.         1.
  0.94339225 0.67044128 0.1205111  0.96368694]
 [1.         1.         0.81239961 0.73264973 0.2999992  0.
  0.34615381 0.42877366 2.         1.         0.         1.
  0.35727442 0.69910421 0.20671155 0.18658964]
 [3.         0.         0.4494673  0.66299556 0.9000016  1.
  0.32417579 0.73636853 1.         1.         0.         1.
  0.6073085  0.14357878 0.93922664 0.26239861]
 [1.         2.         0.67018991 0.1205111  0.5        0.
  0.84065942 0.51258182 0.         2.         0.         1.
  0.85218865 0.22601193 0.93922664 0.26239861]
 [2.         0.         0.71983051 0.72612834 0.9000016  0.
  0.14835157 0.10367046 2.         1.         1.         1.
  0.92218719 0.43625651 0.29618395 0.93922664]
 [0.         0.         0.98799938 0.88144294 0.9000016  0.
  0.23626368 0.85796238 2.         2.         0.         1.
  0.09625996 0.26239861 0.20671155 0.18658964]
 [2.         0.         0.57798553 0.61567675 0.9000016  0.
  0.35714283 0.25747834 1.         1.         1.         1.
  0.44822661 0.84202065 0.31221238 0.20671155]
 [0.         0.         0.46059086 0.43625651 0.7000008  0.
  0.75274731 0.41386456 0.         1.         2.         1.
  0.48241935 0.24455523 0.34272578 0.39841284]
 [3.         0.         0.73409898 0.77594211 0.5        0.
  0.35714283 0.75011707 1.         1.         0.         1.
  0.47129428 0.69910421 0.20671155 0.18658964]
 [2.         0.         0.95673927 0.35727442 0.9000016  0.
  0.69780224 0.28647368 2.         1.         1.         1.
  0.62389945 0.97545834 0.01501027 0.39841284]]
15:17:54 bandwidth of the KDEs:
[1.00954137 0.75763937 0.18752464 0.23573807 0.30613376 0.4591988
 0.21047782 0.20949422 0.72201214 0.64032214 0.70973908 0.82783241
 0.25285913 0.28123943 0.14607535 0.18583184]
[0.97410776 0.70973908 0.25376196 0.24308869 0.27890113 0.43964938
 0.21513115 0.21529958 0.80268628 0.35071888 0.70143776 0.001
 0.24277168 0.27495043 0.30296298 0.27671207]
15:17:54 l(x) = 4.806653756850855e-05
15:17:54 g(x) = inf
15:17:54 best_vector: [0, 0, 0.8242091227733688, 0.3018090888822122, 0.5054558702773175, 1, 0.8167495845901755, 0.6686423480695238, 2, 2, 2, 2, 0.49761466774365914, 0.6006218293080295, 0.2469082854586609, 0.46147428033409094], inf, 4.806653756850855e-05, inf
15:17:54 done sampling a new configuration.
15:17:54 HBMASTER: schedule new run for iteration 4
15:17:54 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
15:17:54 HBMASTER: submitting job (4, 0, 7) to dispatcher
15:17:54 DISPATCHER: trying to submit job (4, 0, 7)
15:17:54 DISPATCHER: trying to notify the job_runner thread.
15:17:54 HBMASTER: job (4, 0, 7) submitted to dispatcher
15:17:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:17:54 DISPATCHER: Trying to submit another job.
15:17:54 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:17:54 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:17:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:17:54 WORKER: start processing job (4, 0, 7)
15:17:54 WORKER: args: ()
15:17:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04450596740699493, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.07411801013846167, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 44, 'num_filters_3': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:18:48 WORKER: done with job (4, 0, 7), trying to register it.
15:18:48 WORKER: registered result for job (4, 0, 7) with dispatcher
15:18:48 DISPATCHER: job (4, 0, 7) finished
15:18:48 DISPATCHER: register_result: lock acquired
15:18:48 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:18:48 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04450596740699493, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.07411801013846167, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 44, 'num_filters_3': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4765473580828438, 'info': {'number_mnist': 0.4765473580828438, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04450596740699493, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.07411801013846167, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 44, 'num_filters_3': 55}"}}
exception: None

15:18:48 job_callback for (4, 0, 7) started
15:18:48 DISPATCHER: Trying to submit another job.
15:18:48 job_callback for (4, 0, 7) got condition
15:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:18:48 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.934535





15:18:48 HBMASTER: Trying to run another job!
15:18:48 job_callback for (4, 0, 7) finished
15:18:48 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/numpy/core/_methods.py:38: RuntimeWarning: invalid value encountered in reduce
  return umr_sum(a, axis, dtype, out, keepdims, initial, where)
15:18:48 best_vector: [0, 0, 0.33517330350757785, 0.6217542749204668, 0.3588392937435691, 0, 0.42880008350280213, 0.09189069380173273, 2, 1, 0, 0, 0.580833332602385, 0.838266607452423, 0.690634946022906, 0.3775703794558073], 1.293290413037609e-29, 0.0007732215362605646, nan
15:18:48 done sampling a new configuration.
15:18:48 HBMASTER: schedule new run for iteration 4
15:18:48 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
15:18:48 HBMASTER: submitting job (4, 0, 8) to dispatcher
15:18:48 DISPATCHER: trying to submit job (4, 0, 8)
15:18:48 DISPATCHER: trying to notify the job_runner thread.
15:18:48 HBMASTER: job (4, 0, 8) submitted to dispatcher
15:18:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:18:48 DISPATCHER: Trying to submit another job.
15:18:48 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:18:48 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:18:48 WORKER: start processing job (4, 0, 8)
15:18:48 WORKER: args: ()
15:18:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004681085860318099, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01316899245847249, 'kernel_size_2': 7, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:18:51 DISPATCHER: Starting worker discovery
15:18:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:51 DISPATCHER: Finished worker discovery
15:19:42 WORKER: done with job (4, 0, 8), trying to register it.
15:19:42 WORKER: registered result for job (4, 0, 8) with dispatcher
15:19:42 DISPATCHER: job (4, 0, 8) finished
15:19:42 DISPATCHER: register_result: lock acquired
15:19:42 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:19:42 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004681085860318099, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01316899245847249, 'kernel_size_2': 7, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8951763715137128, 'info': {'number_mnist': 0.8951763715137128, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004681085860318099, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01316899245847249, 'kernel_size_2': 7, 'num_filters_2': 53}"}}
exception: None

15:19:42 job_callback for (4, 0, 8) started
15:19:42 job_callback for (4, 0, 8) got condition
15:19:42 DISPATCHER: Trying to submit another job.
15:19:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:19:42 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.934535





15:19:42 HBMASTER: Trying to run another job!
15:19:42 job_callback for (4, 0, 8) finished
15:19:42 start sampling a new configuration.
15:19:43 best_vector: [0, 0, 0.13485605586862967, 0.42309603205594526, 0.9910908463535356, 1, 0.5092844107974168, 0.17875731515070115, 2, 1, 1, 0, 0.2955817040008497, 0.7041520232614067, 0.3013391048947092, 0.7008955387807484], 1.1166947137939946e-29, 0.0008954998959406536, nan
15:19:43 done sampling a new configuration.
15:19:43 HBMASTER: schedule new run for iteration 4
15:19:43 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
15:19:43 HBMASTER: submitting job (4, 0, 9) to dispatcher
15:19:43 DISPATCHER: trying to submit job (4, 0, 9)
15:19:43 DISPATCHER: trying to notify the job_runner thread.
15:19:43 HBMASTER: job (4, 0, 9) submitted to dispatcher
15:19:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:19:43 DISPATCHER: Trying to submit another job.
15:19:43 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:19:43 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:19:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:19:43 WORKER: start processing job (4, 0, 9)
15:19:43 WORKER: args: ()
15:19:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018608531919215728, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.017083176539366488, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 69, 'num_filters_4': 29, 'num_filters_5': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:19:51 DISPATCHER: Starting worker discovery
15:19:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:51 DISPATCHER: Finished worker discovery
15:20:36 WORKER: done with job (4, 0, 9), trying to register it.
15:20:36 WORKER: registered result for job (4, 0, 9) with dispatcher
15:20:36 DISPATCHER: job (4, 0, 9) finished
15:20:36 DISPATCHER: register_result: lock acquired
15:20:36 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:20:36 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018608531919215728, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.017083176539366488, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 69, 'num_filters_4': 29, 'num_filters_5': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8379301708944552, 'info': {'number_mnist': 0.8379301708944552, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018608531919215728, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.017083176539366488, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 69, 'num_filters_4': 29, 'num_filters_5': 68}"}}
exception: None

15:20:36 job_callback for (4, 0, 9) started
15:20:36 DISPATCHER: Trying to submit another job.
15:20:36 job_callback for (4, 0, 9) got condition
15:20:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:20:36 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.934535





15:20:36 HBMASTER: Trying to run another job!
15:20:36 job_callback for (4, 0, 9) finished
15:20:36 start sampling a new configuration.
15:20:36 sampled vector: [3, 2, 0.5475855139747047, 0.2666452934715185, 0.8179846720982945, 0, 0.48423448714284034, 0.3942360025343235, 1, 0, 1, 0, 0.7731831881147436, 0.6483796607825483, 0.671786765222774, 0.3113181189026952] has EI value inf
15:20:36 data in the KDEs:
[[1.00000000e+00 1.00000000e+00 6.16592483e-02 4.36256510e-01
  2.99999200e-01 0.00000000e+00 3.35164799e-01 2.05491383e-03
  2.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00
  5.98789470e-01 9.13431508e-01 8.62142562e-01 5.72270733e-01]
 [1.00000000e+00 1.00000000e+00 8.53157402e-02 5.24473143e-01
  9.00001600e-01 0.00000000e+00 3.90109866e-01 3.65277808e-02
  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  2.96183948e-01 7.06973316e-02 6.92099734e-01 6.55430702e-01]
 [3.00000000e+00 0.00000000e+00 2.66504468e-02 3.85093827e-01
  9.99984000e-02 0.00000000e+00 5.32967040e-01 1.29270428e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  7.81815396e-01 7.93347517e-01 7.69994942e-01 5.81276596e-01]
 [3.00000000e+00 0.00000000e+00 2.41356567e-01 8.36853457e-01
  9.00001600e-01 0.00000000e+00 7.63736322e-01 1.84431104e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 1.00000000e+00
  8.21004146e-01 7.19515734e-01 3.12212382e-01 1.20511102e-01]
 [2.00000000e+00 0.00000000e+00 5.61041116e-02 9.39226643e-01
  9.99984000e-02 0.00000000e+00 7.96703362e-01 2.10658065e-01
  0.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00
  2.06711555e-01 9.13431508e-01 8.62142562e-01 5.72270733e-01]
 [2.00000000e+00 0.00000000e+00 3.43688910e-01 4.48226605e-01
  5.00000000e-01 0.00000000e+00 4.34065920e-01 3.28228386e-01
  2.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  8.42020651e-01 2.26011930e-01 6.92099734e-01 6.55430702e-01]
 [0.00000000e+00 0.00000000e+00 3.35173304e-01 6.23899452e-01
  2.99999200e-01 0.00000000e+00 4.34065920e-01 9.18906938e-02
  2.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  5.81276596e-01 7.93347517e-01 7.69994942e-01 1.20511102e-01]
 [0.00000000e+00 2.00000000e+00 1.51155724e-01 5.98789470e-01
  9.00001600e-01 1.00000000e+00 5.10989013e-01 5.95046181e-02
  0.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00
  2.06711555e-01 9.13431508e-01 8.62142562e-01 5.72270733e-01]
 [0.00000000e+00 0.00000000e+00 1.34856056e-01 4.23975468e-01
  9.00001600e-01 1.00000000e+00 5.10989013e-01 1.78757315e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  2.96183948e-01 7.06006428e-01 2.96183948e-01 6.99104210e-01]
 [0.00000000e+00 0.00000000e+00 2.59533104e-01 6.55430702e-01
  5.00000000e-01 1.00000000e+00 3.13186772e-01 1.59159192e-01
  1.00000000e+00 2.00000000e+00 1.00000000e+00 2.00000000e+00
  3.12212382e-01 4.36732032e-02 7.69994942e-01 5.72270733e-01]
 [3.00000000e+00 0.00000000e+00 1.00172732e-01 2.06711555e-01
  9.00001600e-01 1.00000000e+00 4.12087893e-01 2.91342778e-01
  1.00000000e+00 0.00000000e+00 2.00000000e+00 0.00000000e+00
  2.06711555e-01 6.15676748e-01 5.72270733e-01 5.81276596e-01]
 [0.00000000e+00 2.00000000e+00 1.54684125e-01 2.62398612e-01
  2.99999200e-01 0.00000000e+00 4.01098879e-01 4.46488679e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 1.00000000e+00
  4.36732032e-02 7.19515734e-01 3.12212382e-01 1.20511102e-01]
 [2.00000000e+00 2.00000000e+00 3.30385040e-01 2.06711555e-01
  9.00001600e-01 0.00000000e+00 4.23076906e-01 3.35542259e-01
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  8.04605038e-01 7.99009783e-01 4.48226605e-01 9.51614955e-01]
 [3.00000000e+00 1.00000000e+00 6.16297768e-01 9.62599641e-02
  9.99984000e-02 1.00000000e+00 9.34065040e-02 4.66035609e-01
  2.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  5.81276596e-01 7.06973316e-02 6.92099734e-01 6.55430702e-01]
 [2.00000000e+00 2.00000000e+00 1.70274858e-03 1.50102742e-02
  7.00000800e-01 1.00000000e+00 6.53846188e-01 2.21260412e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  7.81815396e-01 7.93347517e-01 7.69994942e-01 9.51614955e-01]
 [3.00000000e+00 0.00000000e+00 4.15484660e-01 6.55430702e-01
  9.00001600e-01 1.00000000e+00 2.80219732e-01 4.74738593e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  8.47131983e-01 5.90114116e-01 2.62398612e-01 9.30783677e-01]
 [1.00000000e+00 1.00000000e+00 4.65634537e-01 8.04605038e-01
  9.00001600e-01 1.00000000e+00 7.63736322e-01 5.53700299e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  6.70441281e-01 3.12212382e-01 4.82419346e-01 8.47131983e-01]]
[[2.         0.         0.55169477 0.44822661 0.2999992  1.
  0.8296704  0.71856867 0.         1.         2.         1.
  0.29618395 0.24455523 0.34272578 0.20671155]
 [3.         0.         0.62703047 0.31221238 0.0999984  1.
  0.97252758 0.82398386 2.         1.         1.         1.
  0.62389945 0.97545834 0.01501027 0.39841284]
 [0.         0.         0.82420912 0.29618395 0.5        1.
  0.81868139 0.66864235 2.         2.         0.         1.
  0.49328864 0.59878947 0.20671155 0.18658964]
 [3.         2.         0.02499689 0.34272578 0.0999984  1.
  0.55494507 0.44014397 2.         2.         0.         1.
  0.09625996 0.26239861 0.20671155 0.18658964]
 [3.         0.         0.46502662 0.51430515 0.0999984  0.
  0.22527466 0.87724834 1.         1.         1.         1.
  0.44822661 0.84202065 0.31221238 0.20671155]
 [1.         2.         0.4933236  0.62389945 0.0999984  0.
  0.60989013 0.88525083 2.         1.         2.         1.
  0.7390824  0.67044128 0.1205111  0.96368694]
 [2.         0.         0.0530198  0.1205111  0.5        1.
  0.88461547 0.6331679  0.         2.         2.         1.
  0.7390824  0.26239861 0.34272578 0.39841284]
 [2.         0.         0.4626202  0.22601193 0.2999992  1.
  0.40109888 0.76601009 2.         1.         1.         1.
  0.7390824  0.43625651 0.29618395 0.93922664]
 [2.         1.         0.33426229 0.3277152  0.5        0.
  0.23626368 0.72509111 0.         1.         2.         1.
  0.86214256 0.9089921  0.1205111  0.96368694]
 [3.         1.         0.75088812 0.96764339 0.2999992  1.
  0.20329664 0.84757538 2.         1.         1.         1.
  0.01501027 0.84202065 0.31221238 0.20671155]
 [0.         1.         0.9522273  0.1205111  0.9000016  1.
  0.69780224 0.56618677 2.         1.         2.         1.
  0.94339225 0.67044128 0.1205111  0.96368694]
 [1.         1.         0.81239961 0.73264973 0.2999992  0.
  0.34615381 0.42877366 2.         2.         0.         1.
  0.35727442 0.26239861 0.93922664 0.26239861]
 [3.         0.         0.4494673  0.66299556 0.9000016  1.
  0.32417579 0.73636853 1.         1.         0.         1.
  0.6073085  0.14357878 0.93922664 0.26239861]
 [1.         2.         0.67018991 0.1205111  0.5        0.
  0.84065942 0.51258182 0.         2.         2.         1.
  0.85218865 0.22601193 0.34272578 0.39841284]
 [0.         0.         0.98799938 0.88144294 0.9000016  0.
  0.23626368 0.85796238 2.         2.         0.         1.
  0.09625996 0.26239861 0.20671155 0.18658964]
 [0.         0.         0.46059086 0.43625651 0.7000008  0.
  0.75274731 0.41386456 0.         1.         2.         1.
  0.48241935 0.24455523 0.34272578 0.20671155]
 [2.         0.         0.71983051 0.72612834 0.9000016  0.
  0.14835157 0.10367046 2.         1.         1.         1.
  0.92218719 0.43625651 0.29618395 0.93922664]
 [2.         0.         0.57798553 0.61567675 0.9000016  0.
  0.35714283 0.25747834 1.         1.         1.         1.
  0.44822661 0.84202065 0.31221238 0.20671155]
 [3.         0.         0.73409898 0.77594211 0.5        0.
  0.35714283 0.75011707 1.         1.         0.         1.
  0.47129428 0.69910421 0.20671155 0.18658964]
 [2.         0.         0.95673927 0.35727442 0.9000016  0.
  0.69780224 0.28647368 2.         1.         1.         1.
  0.62389945 0.97545834 0.01501027 0.39841284]]
15:20:36 bandwidth of the KDEs:
[1.09845711 0.75763937 0.15523242 0.235835   0.29680769 0.4591988
 0.16698926 0.14896313 0.80268628 0.72201214 0.63573195 0.80268628
 0.24649331 0.28017083 0.1937093  0.23721278]
[0.99442303 0.6767616  0.23721075 0.22894593 0.27361251 0.45398548
 0.23918077 0.20366761 0.76892422 0.41818073 0.73430122 0.001
 0.24458095 0.25906804 0.21584128 0.28269118]
15:20:36 l(x) = 0.0003713046832507626
15:20:36 g(x) = inf
15:20:36 best_vector: [3, 2, 0.5475855139747047, 0.2666452934715185, 0.8179846720982945, 0, 0.48423448714284034, 0.3942360025343235, 1, 0, 1, 0, 0.7731831881147436, 0.6483796607825483, 0.671786765222774, 0.3113181189026952], inf, 0.0003713046832507626, inf
15:20:36 done sampling a new configuration.
15:20:36 HBMASTER: schedule new run for iteration 4
15:20:36 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
15:20:36 HBMASTER: submitting job (4, 0, 10) to dispatcher
15:20:36 DISPATCHER: trying to submit job (4, 0, 10)
15:20:36 DISPATCHER: trying to notify the job_runner thread.
15:20:36 HBMASTER: job (4, 0, 10) submitted to dispatcher
15:20:36 DISPATCHER: Trying to submit another job.
15:20:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:20:36 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:20:36 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:20:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:20:36 WORKER: start processing job (4, 0, 10)
15:20:36 WORKER: args: ()
15:20:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012450048061133529, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.03257713328190638, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 61, 'num_filters_4': 64, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:20:51 DISPATCHER: Starting worker discovery
15:20:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:51 DISPATCHER: Finished worker discovery
15:21:30 WORKER: done with job (4, 0, 10), trying to register it.
15:21:30 WORKER: registered result for job (4, 0, 10) with dispatcher
15:21:30 DISPATCHER: job (4, 0, 10) finished
15:21:30 DISPATCHER: register_result: lock acquired
15:21:30 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:21:30 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012450048061133529, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.03257713328190638, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 61, 'num_filters_4': 64, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012450048061133529, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.03257713328190638, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 61, 'num_filters_4': 64, 'num_filters_5': 30}"}}
exception: None

15:21:30 job_callback for (4, 0, 10) started
15:21:30 DISPATCHER: Trying to submit another job.
15:21:30 job_callback for (4, 0, 10) got condition
15:21:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:21:30 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.934535





15:21:30 HBMASTER: Trying to run another job!
15:21:30 job_callback for (4, 0, 10) finished
15:21:30 start sampling a new configuration.
15:21:30 done sampling a new configuration.
15:21:30 HBMASTER: schedule new run for iteration 4
15:21:30 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
15:21:30 HBMASTER: submitting job (4, 0, 11) to dispatcher
15:21:30 DISPATCHER: trying to submit job (4, 0, 11)
15:21:30 DISPATCHER: trying to notify the job_runner thread.
15:21:30 HBMASTER: job (4, 0, 11) submitted to dispatcher
15:21:30 DISPATCHER: Trying to submit another job.
15:21:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:21:30 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:21:30 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:21:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:21:30 WORKER: start processing job (4, 0, 11)
15:21:30 WORKER: args: ()
15:21:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003169046281480994, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.1869197917691789, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 100, 'num_filters_3': 86, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:21:51 DISPATCHER: Starting worker discovery
15:21:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:51 DISPATCHER: Finished worker discovery
15:22:27 WORKER: done with job (4, 0, 11), trying to register it.
15:22:27 WORKER: registered result for job (4, 0, 11) with dispatcher
15:22:27 DISPATCHER: job (4, 0, 11) finished
15:22:27 DISPATCHER: register_result: lock acquired
15:22:27 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:22:27 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003169046281480994, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.1869197917691789, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 100, 'num_filters_3': 86, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015011494491084288, 'info': {'number_mnist': 0.015011494491084288, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003169046281480994, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.1869197917691789, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 100, 'num_filters_3': 86, 'num_filters_4': 30}"}}
exception: None

15:22:27 job_callback for (4, 0, 11) started
15:22:27 DISPATCHER: Trying to submit another job.
15:22:27 job_callback for (4, 0, 11) got condition
15:22:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:22:27 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.934535





15:22:27 HBMASTER: Trying to run another job!
15:22:27 job_callback for (4, 0, 11) finished
15:22:27 start sampling a new configuration.
15:22:27 done sampling a new configuration.
15:22:27 HBMASTER: schedule new run for iteration 4
15:22:27 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
15:22:27 HBMASTER: submitting job (4, 0, 12) to dispatcher
15:22:27 DISPATCHER: trying to submit job (4, 0, 12)
15:22:27 DISPATCHER: trying to notify the job_runner thread.
15:22:27 HBMASTER: job (4, 0, 12) submitted to dispatcher
15:22:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:22:27 DISPATCHER: Trying to submit another job.
15:22:27 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:22:27 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:22:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:22:27 WORKER: start processing job (4, 0, 12)
15:22:27 WORKER: args: ()
15:22:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.050612145933073775, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.12952079962927465, 'kernel_size_2': 3, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:22:51 DISPATCHER: Starting worker discovery
15:22:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:51 DISPATCHER: Finished worker discovery
15:23:21 WORKER: done with job (4, 0, 12), trying to register it.
15:23:21 WORKER: registered result for job (4, 0, 12) with dispatcher
15:23:21 DISPATCHER: job (4, 0, 12) finished
15:23:21 DISPATCHER: register_result: lock acquired
15:23:21 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:23:21 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.050612145933073775, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.12952079962927465, 'kernel_size_2': 3, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0309808190113307, 'info': {'number_mnist': 0.0309808190113307, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.050612145933073775, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.12952079962927465, 'kernel_size_2': 3, 'num_filters_2': 74}"}}
exception: None

15:23:21 job_callback for (4, 0, 12) started
15:23:21 DISPATCHER: Trying to submit another job.
15:23:21 job_callback for (4, 0, 12) got condition
15:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:23:21 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.934535





15:23:21 HBMASTER: Trying to run another job!
15:23:21 job_callback for (4, 0, 12) finished
15:23:21 start sampling a new configuration.
15:23:21 done sampling a new configuration.
15:23:21 HBMASTER: schedule new run for iteration 4
15:23:21 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
15:23:21 HBMASTER: submitting job (4, 0, 13) to dispatcher
15:23:21 DISPATCHER: trying to submit job (4, 0, 13)
15:23:21 DISPATCHER: trying to notify the job_runner thread.
15:23:21 HBMASTER: job (4, 0, 13) submitted to dispatcher
15:23:21 DISPATCHER: Trying to submit another job.
15:23:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:23:21 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:23:21 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:23:21 WORKER: start processing job (4, 0, 13)
15:23:21 WORKER: args: ()
15:23:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.024833322224703695, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1917750947842531}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:23:51 DISPATCHER: Starting worker discovery
15:23:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:51 DISPATCHER: Finished worker discovery
15:24:14 WORKER: done with job (4, 0, 13), trying to register it.
15:24:14 WORKER: registered result for job (4, 0, 13) with dispatcher
15:24:14 DISPATCHER: job (4, 0, 13) finished
15:24:14 DISPATCHER: register_result: lock acquired
15:24:14 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:24:14 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.024833322224703695, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1917750947842531}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02136151840824292, 'info': {'number_mnist': 0.02136151840824292, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.024833322224703695, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1917750947842531}"}}
exception: None

15:24:14 job_callback for (4, 0, 13) started
15:24:14 DISPATCHER: Trying to submit another job.
15:24:14 job_callback for (4, 0, 13) got condition
15:24:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:24:14 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.934535





15:24:14 HBMASTER: Trying to run another job!
15:24:14 job_callback for (4, 0, 13) finished
15:24:14 start sampling a new configuration.
15:24:15 best_vector: [0, 1, 0.2611810883311667, 0.19909003675013043, 0.3460861189445459, 0, 0.624126687507321, 0.10556874193968621, 0, 1, 2, 1, 0.6477886799450405, 0.047681852634716915, 0.6789589507637446, 0.9827531375515536], 2.1071940915520737e-29, 0.0004745647323182463, -1.8838216374865928e-06
15:24:15 done sampling a new configuration.
15:24:15 HBMASTER: schedule new run for iteration 4
15:24:15 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
15:24:15 HBMASTER: submitting job (4, 0, 14) to dispatcher
15:24:15 DISPATCHER: trying to submit job (4, 0, 14)
15:24:15 DISPATCHER: trying to notify the job_runner thread.
15:24:15 HBMASTER: job (4, 0, 14) submitted to dispatcher
15:24:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:24:15 DISPATCHER: Trying to submit another job.
15:24:15 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:24:15 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:24:15 WORKER: start processing job (4, 0, 14)
15:24:15 WORKER: args: ()
15:24:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033293708796928514, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.013719810089122644, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:24:51 DISPATCHER: Starting worker discovery
15:24:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:51 DISPATCHER: Finished worker discovery
15:25:08 WORKER: done with job (4, 0, 14), trying to register it.
15:25:08 WORKER: registered result for job (4, 0, 14) with dispatcher
15:25:08 DISPATCHER: job (4, 0, 14) finished
15:25:08 DISPATCHER: register_result: lock acquired
15:25:08 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:25:08 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033293708796928514, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.013719810089122644, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9096923517607262, 'info': {'number_mnist': 0.9096923517607262, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033293708796928514, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.013719810089122644, 'kernel_size_2': 3, 'num_filters_2': 61}"}}
exception: None

15:25:08 job_callback for (4, 0, 14) started
15:25:08 job_callback for (4, 0, 14) got condition
15:25:08 DISPATCHER: Trying to submit another job.
15:25:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:25:08 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.934535





15:25:08 HBMASTER: Trying to run another job!
15:25:08 job_callback for (4, 0, 14) finished
15:25:08 start sampling a new configuration.
15:25:08 best_vector: [3, 1, 0.12900803006589082, 0.8335853029342568, 0.5669421719359525, 0, 0.442348872041623, 0.07587483557175767, 0, 0, 1, 2, 0.2865297912892028, 0.9994803858611395, 0.9100283736486625, 0.8551491337357519], 7.187720496167777e-05, 0.0012079499166614887, 8.682406374331941e-08
15:25:08 done sampling a new configuration.
15:25:08 HBMASTER: schedule new run for iteration 4
15:25:08 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
15:25:08 HBMASTER: submitting job (4, 0, 15) to dispatcher
15:25:08 DISPATCHER: trying to submit job (4, 0, 15)
15:25:08 DISPATCHER: trying to notify the job_runner thread.
15:25:08 HBMASTER: job (4, 0, 15) submitted to dispatcher
15:25:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:25:08 DISPATCHER: Trying to submit another job.
15:25:08 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:25:08 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:25:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:25:08 WORKER: start processing job (4, 0, 15)
15:25:08 WORKER: args: ()
15:25:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:25:51 DISPATCHER: Starting worker discovery
15:25:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:51 DISPATCHER: Finished worker discovery
15:26:02 WORKER: done with job (4, 0, 15), trying to register it.
15:26:02 WORKER: registered result for job (4, 0, 15) with dispatcher
15:26:02 DISPATCHER: job (4, 0, 15) finished
15:26:02 DISPATCHER: register_result: lock acquired
15:26:02 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:26:02 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9666415981390929, 'info': {'number_mnist': 0.9666415981390929, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}"}}
exception: None

15:26:02 job_callback for (4, 0, 15) started
15:26:02 job_callback for (4, 0, 15) got condition
15:26:02 DISPATCHER: Trying to submit another job.
15:26:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:26:02 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.966642





15:26:02 HBMASTER: Trying to run another job!
15:26:02 job_callback for (4, 0, 15) finished
15:26:02 start sampling a new configuration.
15:26:02 best_vector: [2, 2, 0.24496031115786276, 0.5532592633253731, 0.6474224400462751, 0, 0.21282581555356295, 0.4010172129179672, 1, 1, 2, 1, 0.35201613681614086, 0.9201461691409435, 0.19891214730892742, 0.16398142097833757], 1.5914633492281868e-29, 0.0006283525162454861, -5.288030366835252e-06
15:26:02 done sampling a new configuration.
15:26:02 HBMASTER: schedule new run for iteration 4
15:26:02 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
15:26:02 HBMASTER: submitting job (4, 0, 16) to dispatcher
15:26:02 DISPATCHER: trying to submit job (4, 0, 16)
15:26:02 DISPATCHER: trying to notify the job_runner thread.
15:26:02 HBMASTER: job (4, 0, 16) submitted to dispatcher
15:26:02 DISPATCHER: Trying to submit another job.
15:26:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:26:02 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:26:02 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:26:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:26:02 WORKER: start processing job (4, 0, 16)
15:26:02 WORKER: args: ()
15:26:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0030897306588646444, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03324569549695205, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 109, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:26:51 DISPATCHER: Starting worker discovery
15:26:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:51 DISPATCHER: Finished worker discovery
15:26:56 WORKER: done with job (4, 0, 16), trying to register it.
15:26:56 WORKER: registered result for job (4, 0, 16) with dispatcher
15:26:56 DISPATCHER: job (4, 0, 16) finished
15:26:56 DISPATCHER: register_result: lock acquired
15:26:56 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:26:56 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0030897306588646444, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03324569549695205, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 109, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7032593255461127, 'info': {'number_mnist': 0.7032593255461127, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0030897306588646444, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03324569549695205, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 109, 'num_filters_4': 24}"}}
exception: None

15:26:56 job_callback for (4, 0, 16) started
15:26:56 DISPATCHER: Trying to submit another job.
15:26:56 job_callback for (4, 0, 16) got condition
15:26:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:26:57 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.966642





15:26:57 HBMASTER: Trying to run another job!
15:26:57 job_callback for (4, 0, 16) finished
15:26:57 start sampling a new configuration.
15:26:57 best_vector: [3, 1, 0.06975055592143625, 0.6932933818642404, 0.3050443583867706, 0, 0.024914563173596527, 0.1357850566385685, 1, 2, 1, 2, 0.29325809772919054, 0.555391443372415, 0.7628092343133372, 0.549785064755052], 0.0010384424858014341, 0.0005514686734623927, 5.726685001119064e-07
15:26:57 done sampling a new configuration.
15:26:57 HBMASTER: schedule new run for iteration 4
15:26:57 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
15:26:57 HBMASTER: submitting job (4, 0, 17) to dispatcher
15:26:57 DISPATCHER: trying to submit job (4, 0, 17)
15:26:57 DISPATCHER: trying to notify the job_runner thread.
15:26:57 HBMASTER: job (4, 0, 17) submitted to dispatcher
15:26:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:26:57 DISPATCHER: Trying to submit another job.
15:26:57 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:26:57 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:26:57 WORKER: start processing job (4, 0, 17)
15:26:57 WORKER: args: ()
15:26:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013787994828465772, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01501967141250479, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:27:51 DISPATCHER: Starting worker discovery
15:27:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:51 DISPATCHER: Finished worker discovery
15:27:55 WORKER: done with job (4, 0, 17), trying to register it.
15:27:55 WORKER: registered result for job (4, 0, 17) with dispatcher
15:27:55 DISPATCHER: job (4, 0, 17) finished
15:27:55 DISPATCHER: register_result: lock acquired
15:27:55 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:27:55 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013787994828465772, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01501967141250479, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9100801185351577, 'info': {'number_mnist': 0.9100801185351577, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013787994828465772, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01501967141250479, 'kernel_size_2': 5, 'num_filters_2': 29}"}}
exception: None

15:27:55 job_callback for (4, 0, 17) started
15:27:55 job_callback for (4, 0, 17) got condition
15:27:55 DISPATCHER: Trying to submit another job.
15:27:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:27:55 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.966642





15:27:55 HBMASTER: Trying to run another job!
15:27:55 job_callback for (4, 0, 17) finished
15:27:55 start sampling a new configuration.
15:27:55 best_vector: [0, 0, 0.054124440877904065, 0.5847767266074448, 0.38997843233960605, 1, 0.4271599407203831, 0.14311907242715785, 1, 0, 2, 2, 0.03923125098544322, 0.7185255828138446, 0.5359107634750153, 0.9440518520717496], 0.00033392747955264643, 0.0012496794240701246, 4.173023003285395e-07
15:27:55 done sampling a new configuration.
15:27:55 HBMASTER: schedule new run for iteration 4
15:27:55 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
15:27:55 HBMASTER: submitting job (4, 0, 18) to dispatcher
15:27:55 DISPATCHER: trying to submit job (4, 0, 18)
15:27:55 DISPATCHER: trying to notify the job_runner thread.
15:27:55 HBMASTER: job (4, 0, 18) submitted to dispatcher
15:27:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:27:55 DISPATCHER: Trying to submit another job.
15:27:55 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:27:55 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:27:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:27:55 WORKER: start processing job (4, 0, 18)
15:27:55 WORKER: args: ()
15:27:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001283065660270883, 'num_filters_1': 53, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.015353316621250827, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:28:50 WORKER: done with job (4, 0, 18), trying to register it.
15:28:50 WORKER: registered result for job (4, 0, 18) with dispatcher
15:28:50 DISPATCHER: job (4, 0, 18) finished
15:28:50 DISPATCHER: register_result: lock acquired
15:28:50 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:28:50 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001283065660270883, 'num_filters_1': 53, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.015353316621250827, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6596345585774441, 'info': {'number_mnist': 0.6596345585774441, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001283065660270883, 'num_filters_1': 53, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.015353316621250827, 'kernel_size_2': 5, 'num_filters_2': 17}"}}
exception: None

15:28:50 job_callback for (4, 0, 18) started
15:28:50 DISPATCHER: Trying to submit another job.
15:28:50 job_callback for (4, 0, 18) got condition
15:28:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:28:50 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.966642





15:28:50 HBMASTER: Trying to run another job!
15:28:50 job_callback for (4, 0, 18) finished
15:28:50 start sampling a new configuration.
15:28:50 best_vector: [3, 2, 0.6596485833003815, 0.7856371391253336, 0.6252145521837146, 1, 0.18055128832349326, 0.5507275952227967, 1, 0, 2, 1, 0.588814691749229, 0.31366200812836253, 0.9312107659338201, 0.37770649417570656], 2.410172304113435e-24, 4.1490809528152925e-09, -5.962373899839865e-06
15:28:50 done sampling a new configuration.
15:28:50 HBMASTER: schedule new run for iteration 4
15:28:50 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
15:28:50 HBMASTER: submitting job (4, 0, 19) to dispatcher
15:28:50 DISPATCHER: trying to submit job (4, 0, 19)
15:28:50 DISPATCHER: trying to notify the job_runner thread.
15:28:50 HBMASTER: job (4, 0, 19) submitted to dispatcher
15:28:50 DISPATCHER: Trying to submit another job.
15:28:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:28:50 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:28:50 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:28:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:28:50 WORKER: start processing job (4, 0, 19)
15:28:50 WORKER: args: ()
15:28:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02085917686961769, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.052061073715948245, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 30, 'num_filters_4': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:28:51 DISPATCHER: Starting worker discovery
15:28:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:51 DISPATCHER: Finished worker discovery
15:29:46 WORKER: done with job (4, 0, 19), trying to register it.
15:29:46 WORKER: registered result for job (4, 0, 19) with dispatcher
15:29:46 DISPATCHER: job (4, 0, 19) finished
15:29:46 DISPATCHER: register_result: lock acquired
15:29:46 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:29:46 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02085917686961769, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.052061073715948245, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 30, 'num_filters_4': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5081963125488037, 'info': {'number_mnist': 0.5081963125488037, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02085917686961769, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.052061073715948245, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 30, 'num_filters_4': 111}"}}
exception: None

15:29:46 job_callback for (4, 0, 19) started
15:29:46 job_callback for (4, 0, 19) got condition
15:29:46 DISPATCHER: Trying to submit another job.
15:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:29:46 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.966642





15:29:46 HBMASTER: Trying to run another job!
15:29:46 job_callback for (4, 0, 19) finished
15:29:46 start sampling a new configuration.
15:29:46 best_vector: [3, 1, 0.0687463964673194, 0.45951897243015943, 0.015365913455390179, 0, 0.08128796177343177, 0.40417607432194236, 1, 0, 2, 2, 0.7929629658629449, 0.3312046220286604, 0.941029896342699, 0.39792371689523254], 3.90251020073956e-27, 2.562453263569923e-06, -3.9071811797741725e-07
15:29:46 done sampling a new configuration.
15:29:46 HBMASTER: schedule new run for iteration 4
15:29:46 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
15:29:46 HBMASTER: submitting job (4, 0, 20) to dispatcher
15:29:46 DISPATCHER: trying to submit job (4, 0, 20)
15:29:46 DISPATCHER: trying to notify the job_runner thread.
15:29:46 HBMASTER: job (4, 0, 20) submitted to dispatcher
15:29:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:29:46 DISPATCHER: Trying to submit another job.
15:29:46 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:29:46 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:29:46 WORKER: start processing job (4, 0, 20)
15:29:46 WORKER: args: ()
15:29:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013724381853698533, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.03356179622758223}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:29:51 DISPATCHER: Starting worker discovery
15:29:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:51 DISPATCHER: Finished worker discovery
15:30:44 WORKER: done with job (4, 0, 20), trying to register it.
15:30:44 WORKER: registered result for job (4, 0, 20) with dispatcher
15:30:44 DISPATCHER: job (4, 0, 20) finished
15:30:44 DISPATCHER: register_result: lock acquired
15:30:44 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:30:44 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013724381853698533, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.03356179622758223}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8041796423438408, 'info': {'number_mnist': 0.8041796423438408, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013724381853698533, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.03356179622758223}"}}
exception: None

15:30:44 job_callback for (4, 0, 20) started
15:30:44 job_callback for (4, 0, 20) got condition
15:30:44 DISPATCHER: Trying to submit another job.
15:30:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:30:44 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.966642





15:30:44 HBMASTER: Trying to run another job!
15:30:44 job_callback for (4, 0, 20) finished
15:30:44 start sampling a new configuration.
15:30:44 best_vector: [1, 1, 0.225192382150245, 0.8664962460293113, 0.20039797909349832, 0, 0.5037790818049094, 0.0706432224189642, 2, 0, 2, 0, 0.6375438421521388, 0.9160730818086333, 0.12751827104141672, 0.6198210781585209], 0.00024682373617476516, 0.01643921229402222, 4.057587798180697e-06
15:30:44 done sampling a new configuration.
15:30:44 HBMASTER: schedule new run for iteration 4
15:30:44 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
15:30:44 HBMASTER: submitting job (4, 0, 21) to dispatcher
15:30:44 DISPATCHER: trying to submit job (4, 0, 21)
15:30:44 DISPATCHER: trying to notify the job_runner thread.
15:30:44 HBMASTER: job (4, 0, 21) submitted to dispatcher
15:30:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:30:44 DISPATCHER: Trying to submit another job.
15:30:44 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:30:44 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:30:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:30:44 WORKER: start processing job (4, 0, 21)
15:30:44 WORKER: args: ()
15:30:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0028208809912063804, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012356883476267816, 'kernel_size_2': 7, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:30:51 DISPATCHER: Starting worker discovery
15:30:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:51 DISPATCHER: Finished worker discovery
15:31:38 WORKER: done with job (4, 0, 21), trying to register it.
15:31:38 WORKER: registered result for job (4, 0, 21) with dispatcher
15:31:38 DISPATCHER: job (4, 0, 21) finished
15:31:38 DISPATCHER: register_result: lock acquired
15:31:38 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:31:38 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0028208809912063804, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012356883476267816, 'kernel_size_2': 7, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8735142398366921, 'info': {'number_mnist': 0.8735142398366921, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0028208809912063804, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012356883476267816, 'kernel_size_2': 7, 'num_filters_2': 60}"}}
exception: None

15:31:38 job_callback for (4, 0, 21) started
15:31:38 DISPATCHER: Trying to submit another job.
15:31:38 job_callback for (4, 0, 21) got condition
15:31:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:31:38 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.966642





15:31:38 HBMASTER: Trying to run another job!
15:31:38 job_callback for (4, 0, 21) finished
15:31:38 start sampling a new configuration.
15:31:38 best_vector: [0, 1, 0.010480726580188726, 0.5722348882809979, 0.2528255808861398, 0, 0.35719450036998257, 0.022582736892047997, 0, 2, 2, 0, 0.7543430550674867, 0.5510314290763374, 0.7881329022460379, 0.24232565066041456], 0.002530447613975758, 0.0040420693835197, 1.0228244827051889e-05
15:31:38 done sampling a new configuration.
15:31:38 HBMASTER: schedule new run for iteration 4
15:31:38 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
15:31:38 HBMASTER: submitting job (4, 0, 22) to dispatcher
15:31:38 DISPATCHER: trying to submit job (4, 0, 22)
15:31:38 DISPATCHER: trying to notify the job_runner thread.
15:31:38 HBMASTER: job (4, 0, 22) submitted to dispatcher
15:31:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:31:38 DISPATCHER: Trying to submit another job.
15:31:38 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:31:38 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:31:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:31:38 WORKER: start processing job (4, 0, 22)
15:31:38 WORKER: args: ()
15:31:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:31:51 DISPATCHER: Starting worker discovery
15:31:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:51 DISPATCHER: Finished worker discovery
15:32:33 WORKER: done with job (4, 0, 22), trying to register it.
15:32:33 WORKER: registered result for job (4, 0, 22) with dispatcher
15:32:33 DISPATCHER: job (4, 0, 22) finished
15:32:33 DISPATCHER: register_result: lock acquired
15:32:33 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:32:33 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9343616040851197, 'info': {'number_mnist': 0.9343616040851197, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}"}}
exception: None

15:32:33 job_callback for (4, 0, 22) started
15:32:33 DISPATCHER: Trying to submit another job.
15:32:33 job_callback for (4, 0, 22) got condition
15:32:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:32:33 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.966642





15:32:33 HBMASTER: Trying to run another job!
15:32:33 job_callback for (4, 0, 22) finished
15:32:33 start sampling a new configuration.
15:32:33 best_vector: [2, 2, 0.09455528121229624, 0.933006701483758, 0.22595427754878594, 0, 0.5494279656931423, 0.09683613788506726, 1, 2, 1, 1, 0.6418156374367268, 0.26742396031905935, 0.5218854427339005, 0.5406009718563465], 0.0018179731415158698, 0.005917240596264119, 1.0757384475895518e-05
15:32:33 done sampling a new configuration.
15:32:33 HBMASTER: schedule new run for iteration 4
15:32:33 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
15:32:33 HBMASTER: submitting job (4, 0, 23) to dispatcher
15:32:33 DISPATCHER: trying to submit job (4, 0, 23)
15:32:33 DISPATCHER: trying to notify the job_runner thread.
15:32:33 HBMASTER: job (4, 0, 23) submitted to dispatcher
15:32:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:32:33 DISPATCHER: Trying to submit another job.
15:32:33 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:32:33 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:32:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:32:33 WORKER: start processing job (4, 0, 23)
15:32:33 WORKER: args: ()
15:32:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:32:51 DISPATCHER: Starting worker discovery
15:32:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:51 DISPATCHER: Finished worker discovery
15:33:27 WORKER: done with job (4, 0, 23), trying to register it.
15:33:27 WORKER: registered result for job (4, 0, 23) with dispatcher
15:33:27 DISPATCHER: job (4, 0, 23) finished
15:33:27 DISPATCHER: register_result: lock acquired
15:33:27 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:33:27 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9386744249089023, 'info': {'number_mnist': 0.9386744249089023, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}"}}
exception: None

15:33:27 job_callback for (4, 0, 23) started
15:33:27 job_callback for (4, 0, 23) got condition
15:33:27 DISPATCHER: Trying to submit another job.
15:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:33:27 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.966642





15:33:27 HBMASTER: Trying to run another job!
15:33:27 job_callback for (4, 0, 23) finished
15:33:27 start sampling a new configuration.
15:33:27 best_vector: [2, 2, 0.18893268418010686, 0.6542400925133014, 0.37762670003528676, 0, 0.5405859051644655, 0.22326792108834986, 1, 2, 1, 2, 0.8082724686931584, 0.9313122264620531, 0.406193804143087, 0.23834822575154424], 0.0026632974397809866, 0.003869628128843767, 1.0305970688454096e-05
15:33:27 done sampling a new configuration.
15:33:27 HBMASTER: schedule new run for iteration 4
15:33:27 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
15:33:27 HBMASTER: submitting job (4, 0, 24) to dispatcher
15:33:27 DISPATCHER: trying to submit job (4, 0, 24)
15:33:27 DISPATCHER: trying to notify the job_runner thread.
15:33:27 HBMASTER: job (4, 0, 24) submitted to dispatcher
15:33:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:33:27 DISPATCHER: Trying to submit another job.
15:33:27 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:33:27 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:33:27 WORKER: start processing job (4, 0, 24)
15:33:27 WORKER: args: ()
15:33:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002387071174212022, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.019519930291525836, 'kernel_size_2': 5, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:33:51 DISPATCHER: Starting worker discovery
15:33:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:51 DISPATCHER: Finished worker discovery
15:34:20 WORKER: done with job (4, 0, 24), trying to register it.
15:34:20 WORKER: registered result for job (4, 0, 24) with dispatcher
15:34:20 DISPATCHER: job (4, 0, 24) finished
15:34:20 DISPATCHER: register_result: lock acquired
15:34:20 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:34:20 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002387071174212022, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.019519930291525836, 'kernel_size_2': 5, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9401483499387714, 'info': {'number_mnist': 0.9401483499387714, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002387071174212022, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.019519930291525836, 'kernel_size_2': 5, 'num_filters_2': 86}"}}
exception: None

15:34:20 job_callback for (4, 0, 24) started
15:34:20 job_callback for (4, 0, 24) got condition
15:34:20 DISPATCHER: Trying to submit another job.
15:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:34:20 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.966642





15:34:20 HBMASTER: Trying to run another job!
15:34:20 job_callback for (4, 0, 24) finished
15:34:20 start sampling a new configuration.
15:34:20 done sampling a new configuration.
15:34:20 HBMASTER: schedule new run for iteration 4
15:34:20 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
15:34:20 HBMASTER: submitting job (4, 0, 25) to dispatcher
15:34:20 DISPATCHER: trying to submit job (4, 0, 25)
15:34:20 DISPATCHER: trying to notify the job_runner thread.
15:34:20 HBMASTER: job (4, 0, 25) submitted to dispatcher
15:34:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:34:20 DISPATCHER: Trying to submit another job.
15:34:20 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:34:20 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:34:20 WORKER: start processing job (4, 0, 25)
15:34:20 WORKER: args: ()
15:34:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.015181112626790587, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.022634945143405028, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 64, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:34:51 DISPATCHER: Starting worker discovery
15:34:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:51 DISPATCHER: Finished worker discovery
15:35:14 WORKER: done with job (4, 0, 25), trying to register it.
15:35:14 WORKER: registered result for job (4, 0, 25) with dispatcher
15:35:14 DISPATCHER: job (4, 0, 25) finished
15:35:14 DISPATCHER: register_result: lock acquired
15:35:14 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:35:14 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.015181112626790587, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.022634945143405028, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 64, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.015181112626790587, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.022634945143405028, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 64, 'num_filters_5': 21}"}}
exception: None

15:35:14 job_callback for (4, 0, 25) started
15:35:14 DISPATCHER: Trying to submit another job.
15:35:14 job_callback for (4, 0, 25) got condition
15:35:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:35:14 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.966642





15:35:14 HBMASTER: Trying to run another job!
15:35:14 job_callback for (4, 0, 25) finished
15:35:14 start sampling a new configuration.
15:35:14 done sampling a new configuration.
15:35:14 HBMASTER: schedule new run for iteration 4
15:35:14 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
15:35:14 HBMASTER: submitting job (4, 0, 26) to dispatcher
15:35:14 DISPATCHER: trying to submit job (4, 0, 26)
15:35:14 DISPATCHER: trying to notify the job_runner thread.
15:35:14 HBMASTER: job (4, 0, 26) submitted to dispatcher
15:35:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:35:14 DISPATCHER: Trying to submit another job.
15:35:14 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:35:14 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:35:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:35:14 WORKER: start processing job (4, 0, 26)
15:35:14 WORKER: args: ()
15:35:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07522312902695538, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.018564369310207888, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 50, 'num_filters_4': 47, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:35:51 DISPATCHER: Starting worker discovery
15:35:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:51 DISPATCHER: Finished worker discovery
15:36:10 WORKER: done with job (4, 0, 26), trying to register it.
15:36:10 WORKER: registered result for job (4, 0, 26) with dispatcher
15:36:10 DISPATCHER: job (4, 0, 26) finished
15:36:10 DISPATCHER: register_result: lock acquired
15:36:10 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:36:10 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07522312902695538, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.018564369310207888, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 50, 'num_filters_4': 47, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.454087042553912, 'info': {'number_mnist': 0.454087042553912, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07522312902695538, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.018564369310207888, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 50, 'num_filters_4': 47, 'num_filters_5': 17}"}}
exception: None

15:36:10 job_callback for (4, 0, 26) started
15:36:10 job_callback for (4, 0, 26) got condition
15:36:10 DISPATCHER: Trying to submit another job.
15:36:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:36:10 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.966642





15:36:10 HBMASTER: Trying to run another job!
15:36:10 job_callback for (4, 0, 26) finished
15:36:10 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
15:36:10 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
15:36:10 HBMASTER: schedule new run for iteration 4
15:36:10 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
15:36:10 HBMASTER: submitting job (4, 0, 0) to dispatcher
15:36:10 DISPATCHER: trying to submit job (4, 0, 0)
15:36:10 DISPATCHER: trying to notify the job_runner thread.
15:36:10 HBMASTER: job (4, 0, 0) submitted to dispatcher
15:36:10 DISPATCHER: Trying to submit another job.
15:36:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:36:10 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:36:10 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:36:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:36:10 WORKER: start processing job (4, 0, 0)
15:36:10 WORKER: args: ()
15:36:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011305789457210587, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.014729388055822336}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:36:51 DISPATCHER: Starting worker discovery
15:36:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:51 DISPATCHER: Finished worker discovery
15:37:51 DISPATCHER: Starting worker discovery
15:37:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:51 DISPATCHER: Finished worker discovery
15:38:37 WORKER: done with job (4, 0, 0), trying to register it.
15:38:37 WORKER: registered result for job (4, 0, 0) with dispatcher
15:38:37 DISPATCHER: job (4, 0, 0) finished
15:38:37 DISPATCHER: register_result: lock acquired
15:38:37 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:38:37 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011305789457210587, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.014729388055822336}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9209783516439528, 'info': {'number_mnist': 0.9209783516439528, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011305789457210587, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.014729388055822336}"}}
exception: None

15:38:37 job_callback for (4, 0, 0) started
15:38:37 DISPATCHER: Trying to submit another job.
15:38:37 job_callback for (4, 0, 0) got condition
15:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:38:37 HBMASTER: Trying to run another job!
15:38:37 job_callback for (4, 0, 0) finished
15:38:37 HBMASTER: schedule new run for iteration 4
15:38:37 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
15:38:37 HBMASTER: submitting job (4, 0, 8) to dispatcher
15:38:37 DISPATCHER: trying to submit job (4, 0, 8)
15:38:37 DISPATCHER: trying to notify the job_runner thread.
15:38:37 HBMASTER: job (4, 0, 8) submitted to dispatcher
15:38:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:38:37 DISPATCHER: Trying to submit another job.
15:38:37 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:38:37 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:38:37 WORKER: start processing job (4, 0, 8)
15:38:37 WORKER: args: ()
15:38:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004681085860318099, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01316899245847249, 'kernel_size_2': 7, 'num_filters_2': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:38:51 DISPATCHER: Starting worker discovery
15:38:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:51 DISPATCHER: Finished worker discovery
15:39:51 DISPATCHER: Starting worker discovery
15:39:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:51 DISPATCHER: Finished worker discovery
15:40:51 DISPATCHER: Starting worker discovery
15:40:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:51 DISPATCHER: Finished worker discovery
15:41:04 WORKER: done with job (4, 0, 8), trying to register it.
15:41:04 WORKER: registered result for job (4, 0, 8) with dispatcher
15:41:04 DISPATCHER: job (4, 0, 8) finished
15:41:04 DISPATCHER: register_result: lock acquired
15:41:04 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:41:04 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004681085860318099, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01316899245847249, 'kernel_size_2': 7, 'num_filters_2': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8263583632551581, 'info': {'number_mnist': 0.8263583632551581, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004681085860318099, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01316899245847249, 'kernel_size_2': 7, 'num_filters_2': 53}"}}
exception: None

15:41:04 job_callback for (4, 0, 8) started
15:41:04 DISPATCHER: Trying to submit another job.
15:41:04 job_callback for (4, 0, 8) got condition
15:41:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:41:04 HBMASTER: Trying to run another job!
15:41:04 job_callback for (4, 0, 8) finished
15:41:04 HBMASTER: schedule new run for iteration 4
15:41:04 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
15:41:04 HBMASTER: submitting job (4, 0, 14) to dispatcher
15:41:04 DISPATCHER: trying to submit job (4, 0, 14)
15:41:04 DISPATCHER: trying to notify the job_runner thread.
15:41:04 HBMASTER: job (4, 0, 14) submitted to dispatcher
15:41:04 DISPATCHER: Trying to submit another job.
15:41:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:41:04 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:41:04 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:41:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:41:04 WORKER: start processing job (4, 0, 14)
15:41:04 WORKER: args: ()
15:41:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033293708796928514, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.013719810089122644, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:41:51 DISPATCHER: Starting worker discovery
15:41:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:51 DISPATCHER: Finished worker discovery
15:42:51 DISPATCHER: Starting worker discovery
15:42:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:51 DISPATCHER: Finished worker discovery
15:43:30 WORKER: done with job (4, 0, 14), trying to register it.
15:43:30 WORKER: registered result for job (4, 0, 14) with dispatcher
15:43:30 DISPATCHER: job (4, 0, 14) finished
15:43:30 DISPATCHER: register_result: lock acquired
15:43:30 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:43:30 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033293708796928514, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.013719810089122644, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.884645521453164, 'info': {'number_mnist': 0.884645521453164, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033293708796928514, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.013719810089122644, 'kernel_size_2': 3, 'num_filters_2': 61}"}}
exception: None

15:43:30 job_callback for (4, 0, 14) started
15:43:30 DISPATCHER: Trying to submit another job.
15:43:30 job_callback for (4, 0, 14) got condition
15:43:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:43:30 HBMASTER: Trying to run another job!
15:43:30 job_callback for (4, 0, 14) finished
15:43:30 HBMASTER: schedule new run for iteration 4
15:43:30 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
15:43:30 HBMASTER: submitting job (4, 0, 15) to dispatcher
15:43:30 DISPATCHER: trying to submit job (4, 0, 15)
15:43:30 DISPATCHER: trying to notify the job_runner thread.
15:43:30 HBMASTER: job (4, 0, 15) submitted to dispatcher
15:43:30 DISPATCHER: Trying to submit another job.
15:43:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:43:30 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:43:30 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:43:30 WORKER: start processing job (4, 0, 15)
15:43:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:43:30 WORKER: args: ()
15:43:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:43:51 DISPATCHER: Starting worker discovery
15:43:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:51 DISPATCHER: Finished worker discovery
15:44:51 DISPATCHER: Starting worker discovery
15:44:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:51 DISPATCHER: Finished worker discovery
15:45:51 DISPATCHER: Starting worker discovery
15:45:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:51 DISPATCHER: Finished worker discovery
15:45:55 WORKER: done with job (4, 0, 15), trying to register it.
15:45:55 WORKER: registered result for job (4, 0, 15) with dispatcher
15:45:55 DISPATCHER: job (4, 0, 15) finished
15:45:55 DISPATCHER: register_result: lock acquired
15:45:55 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:45:55 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9363759133114378, 'info': {'number_mnist': 0.9363759133114378, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}"}}
exception: None

15:45:55 job_callback for (4, 0, 15) started
15:45:55 DISPATCHER: Trying to submit another job.
15:45:55 job_callback for (4, 0, 15) got condition
15:45:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:45:55 HBMASTER: Trying to run another job!
15:45:55 job_callback for (4, 0, 15) finished
15:45:55 HBMASTER: schedule new run for iteration 4
15:45:55 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
15:45:55 HBMASTER: submitting job (4, 0, 17) to dispatcher
15:45:55 DISPATCHER: trying to submit job (4, 0, 17)
15:45:55 DISPATCHER: trying to notify the job_runner thread.
15:45:55 HBMASTER: job (4, 0, 17) submitted to dispatcher
15:45:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:45:55 DISPATCHER: Trying to submit another job.
15:45:55 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:45:55 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:45:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:45:55 WORKER: start processing job (4, 0, 17)
15:45:55 WORKER: args: ()
15:45:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013787994828465772, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01501967141250479, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:46:51 DISPATCHER: Starting worker discovery
15:46:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:51 DISPATCHER: Finished worker discovery
15:47:51 DISPATCHER: Starting worker discovery
15:47:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:51 DISPATCHER: Finished worker discovery
15:48:35 WORKER: done with job (4, 0, 17), trying to register it.
15:48:35 WORKER: registered result for job (4, 0, 17) with dispatcher
15:48:35 DISPATCHER: job (4, 0, 17) finished
15:48:35 DISPATCHER: register_result: lock acquired
15:48:35 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:48:35 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013787994828465772, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01501967141250479, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8956745033736575, 'info': {'number_mnist': 0.8956745033736575, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013787994828465772, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01501967141250479, 'kernel_size_2': 5, 'num_filters_2': 29}"}}
exception: None

15:48:35 job_callback for (4, 0, 17) started
15:48:35 DISPATCHER: Trying to submit another job.
15:48:35 job_callback for (4, 0, 17) got condition
15:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:35 HBMASTER: Trying to run another job!
15:48:35 job_callback for (4, 0, 17) finished
15:48:35 HBMASTER: schedule new run for iteration 4
15:48:35 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
15:48:35 HBMASTER: submitting job (4, 0, 21) to dispatcher
15:48:35 DISPATCHER: trying to submit job (4, 0, 21)
15:48:35 DISPATCHER: trying to notify the job_runner thread.
15:48:35 HBMASTER: job (4, 0, 21) submitted to dispatcher
15:48:35 DISPATCHER: Trying to submit another job.
15:48:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:35 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:48:35 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:35 WORKER: start processing job (4, 0, 21)
15:48:35 WORKER: args: ()
15:48:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0028208809912063804, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012356883476267816, 'kernel_size_2': 7, 'num_filters_2': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:48:51 DISPATCHER: Starting worker discovery
15:48:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:51 DISPATCHER: Finished worker discovery
15:49:51 DISPATCHER: Starting worker discovery
15:49:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:51 DISPATCHER: Finished worker discovery
15:50:51 DISPATCHER: Starting worker discovery
15:50:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:51 DISPATCHER: Finished worker discovery
15:51:00 WORKER: done with job (4, 0, 21), trying to register it.
15:51:00 WORKER: registered result for job (4, 0, 21) with dispatcher
15:51:00 DISPATCHER: job (4, 0, 21) finished
15:51:00 DISPATCHER: register_result: lock acquired
15:51:00 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:51:00 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0028208809912063804, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012356883476267816, 'kernel_size_2': 7, 'num_filters_2': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9153616347407685, 'info': {'number_mnist': 0.9153616347407685, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0028208809912063804, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012356883476267816, 'kernel_size_2': 7, 'num_filters_2': 60}"}}
exception: None

15:51:00 job_callback for (4, 0, 21) started
15:51:00 DISPATCHER: Trying to submit another job.
15:51:00 job_callback for (4, 0, 21) got condition
15:51:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:51:00 HBMASTER: Trying to run another job!
15:51:00 job_callback for (4, 0, 21) finished
15:51:00 HBMASTER: schedule new run for iteration 4
15:51:00 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
15:51:00 HBMASTER: submitting job (4, 0, 22) to dispatcher
15:51:00 DISPATCHER: trying to submit job (4, 0, 22)
15:51:00 DISPATCHER: trying to notify the job_runner thread.
15:51:00 HBMASTER: job (4, 0, 22) submitted to dispatcher
15:51:00 DISPATCHER: Trying to submit another job.
15:51:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:51:00 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:51:00 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:51:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:51:00 WORKER: start processing job (4, 0, 22)
15:51:00 WORKER: args: ()
15:51:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:51:51 DISPATCHER: Starting worker discovery
15:51:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:51 DISPATCHER: Finished worker discovery
15:52:51 DISPATCHER: Starting worker discovery
15:52:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:51 DISPATCHER: Finished worker discovery
15:53:28 WORKER: done with job (4, 0, 22), trying to register it.
15:53:28 WORKER: registered result for job (4, 0, 22) with dispatcher
15:53:28 DISPATCHER: job (4, 0, 22) finished
15:53:28 DISPATCHER: register_result: lock acquired
15:53:28 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:53:28 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9243373328355318, 'info': {'number_mnist': 0.9243373328355318, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}"}}
exception: None

15:53:28 job_callback for (4, 0, 22) started
15:53:28 DISPATCHER: Trying to submit another job.
15:53:28 job_callback for (4, 0, 22) got condition
15:53:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:53:28 HBMASTER: Trying to run another job!
15:53:28 job_callback for (4, 0, 22) finished
15:53:28 HBMASTER: schedule new run for iteration 4
15:53:28 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
15:53:28 HBMASTER: submitting job (4, 0, 23) to dispatcher
15:53:28 DISPATCHER: trying to submit job (4, 0, 23)
15:53:28 DISPATCHER: trying to notify the job_runner thread.
15:53:28 HBMASTER: job (4, 0, 23) submitted to dispatcher
15:53:28 DISPATCHER: Trying to submit another job.
15:53:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:53:28 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:53:28 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:53:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:53:28 WORKER: start processing job (4, 0, 23)
15:53:28 WORKER: args: ()
15:53:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:53:51 DISPATCHER: Starting worker discovery
15:53:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:51 DISPATCHER: Finished worker discovery
15:54:51 DISPATCHER: Starting worker discovery
15:54:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:51 DISPATCHER: Finished worker discovery
15:55:51 DISPATCHER: Starting worker discovery
15:55:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:51 WORKER: done with job (4, 0, 23), trying to register it.
15:55:51 WORKER: registered result for job (4, 0, 23) with dispatcher
15:55:51 DISPATCHER: Finished worker discovery
15:55:51 DISPATCHER: job (4, 0, 23) finished
15:55:51 DISPATCHER: register_result: lock acquired
15:55:51 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:55:51 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9582670666790329, 'info': {'number_mnist': 0.9582670666790329, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}"}}
exception: None

15:55:51 job_callback for (4, 0, 23) started
15:55:51 job_callback for (4, 0, 23) got condition
15:55:51 DISPATCHER: Trying to submit another job.
15:55:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:55:51 HBMASTER: Trying to run another job!
15:55:51 job_callback for (4, 0, 23) finished
15:55:51 HBMASTER: schedule new run for iteration 4
15:55:51 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
15:55:51 HBMASTER: submitting job (4, 0, 24) to dispatcher
15:55:51 DISPATCHER: trying to submit job (4, 0, 24)
15:55:51 DISPATCHER: trying to notify the job_runner thread.
15:55:51 HBMASTER: job (4, 0, 24) submitted to dispatcher
15:55:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:55:51 DISPATCHER: Trying to submit another job.
15:55:51 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:55:51 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:55:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:55:51 WORKER: start processing job (4, 0, 24)
15:55:51 WORKER: args: ()
15:55:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002387071174212022, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.019519930291525836, 'kernel_size_2': 5, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:56:51 DISPATCHER: Starting worker discovery
15:56:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:51 DISPATCHER: Finished worker discovery
15:57:51 DISPATCHER: Starting worker discovery
15:57:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:51 DISPATCHER: Finished worker discovery
15:58:15 WORKER: done with job (4, 0, 24), trying to register it.
15:58:15 WORKER: registered result for job (4, 0, 24) with dispatcher
15:58:15 DISPATCHER: job (4, 0, 24) finished
15:58:15 DISPATCHER: register_result: lock acquired
15:58:15 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:58:15 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002387071174212022, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.019519930291525836, 'kernel_size_2': 5, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9177504668011122, 'info': {'number_mnist': 0.9177504668011122, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002387071174212022, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.019519930291525836, 'kernel_size_2': 5, 'num_filters_2': 86}"}}
exception: None

15:58:15 job_callback for (4, 0, 24) started
15:58:15 DISPATCHER: Trying to submit another job.
15:58:15 job_callback for (4, 0, 24) got condition
15:58:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:58:15 HBMASTER: Trying to run another job!
15:58:15 job_callback for (4, 0, 24) finished
15:58:15 ITERATION: Advancing config (4, 0, 15) to next budget 400.000000
15:58:15 ITERATION: Advancing config (4, 0, 22) to next budget 400.000000
15:58:15 ITERATION: Advancing config (4, 0, 23) to next budget 400.000000
15:58:15 HBMASTER: schedule new run for iteration 4
15:58:15 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
15:58:15 HBMASTER: submitting job (4, 0, 15) to dispatcher
15:58:15 DISPATCHER: trying to submit job (4, 0, 15)
15:58:15 DISPATCHER: trying to notify the job_runner thread.
15:58:15 HBMASTER: job (4, 0, 15) submitted to dispatcher
15:58:15 DISPATCHER: Trying to submit another job.
15:58:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:58:15 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:58:15 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:58:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:58:15 WORKER: start processing job (4, 0, 15)
15:58:15 WORKER: args: ()
15:58:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 400.0, 'working_directory': '.'}
15:58:51 DISPATCHER: Starting worker discovery
15:58:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:51 DISPATCHER: Finished worker discovery
15:59:51 DISPATCHER: Starting worker discovery
15:59:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:51 DISPATCHER: Finished worker discovery
16:00:51 DISPATCHER: Starting worker discovery
16:00:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:51 DISPATCHER: Finished worker discovery
16:01:51 DISPATCHER: Starting worker discovery
16:01:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:51 DISPATCHER: Finished worker discovery
16:02:51 DISPATCHER: Starting worker discovery
16:02:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:51 DISPATCHER: Finished worker discovery
16:03:51 DISPATCHER: Starting worker discovery
16:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:52 DISPATCHER: Finished worker discovery
16:04:52 DISPATCHER: Starting worker discovery
16:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:52 DISPATCHER: Finished worker discovery
16:05:15 WORKER: done with job (4, 0, 15), trying to register it.
16:05:15 WORKER: registered result for job (4, 0, 15) with dispatcher
16:05:15 DISPATCHER: job (4, 0, 15) finished
16:05:15 DISPATCHER: register_result: lock acquired
16:05:15 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:05:15 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9485611007711626, 'info': {'number_mnist': 0.9485611007711626, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}"}}
exception: None

16:05:15 job_callback for (4, 0, 15) started
16:05:15 job_callback for (4, 0, 15) got condition
16:05:15 DISPATCHER: Trying to submit another job.
16:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:05:15 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:05:15 HBMASTER: Trying to run another job!
16:05:15 job_callback for (4, 0, 15) finished
16:05:15 HBMASTER: schedule new run for iteration 4
16:05:15 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
16:05:15 HBMASTER: submitting job (4, 0, 22) to dispatcher
16:05:15 DISPATCHER: trying to submit job (4, 0, 22)
16:05:15 DISPATCHER: trying to notify the job_runner thread.
16:05:15 HBMASTER: job (4, 0, 22) submitted to dispatcher
16:05:15 DISPATCHER: Trying to submit another job.
16:05:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:05:15 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:05:15 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:05:15 WORKER: start processing job (4, 0, 22)
16:05:15 WORKER: args: ()
16:05:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 400.0, 'working_directory': '.'}
16:05:52 DISPATCHER: Starting worker discovery
16:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:52 DISPATCHER: Finished worker discovery
16:06:52 DISPATCHER: Starting worker discovery
16:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:52 DISPATCHER: Finished worker discovery
16:07:52 DISPATCHER: Starting worker discovery
16:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:52 DISPATCHER: Finished worker discovery
16:08:52 DISPATCHER: Starting worker discovery
16:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:52 DISPATCHER: Finished worker discovery
16:09:52 DISPATCHER: Starting worker discovery
16:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:52 DISPATCHER: Finished worker discovery
16:10:52 DISPATCHER: Starting worker discovery
16:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:52 DISPATCHER: Finished worker discovery
16:11:52 DISPATCHER: Starting worker discovery
16:11:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:52 DISPATCHER: Finished worker discovery
16:12:20 WORKER: done with job (4, 0, 22), trying to register it.
16:12:20 WORKER: registered result for job (4, 0, 22) with dispatcher
16:12:20 DISPATCHER: job (4, 0, 22) finished
16:12:20 DISPATCHER: register_result: lock acquired
16:12:20 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:12:20 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9188524020256658, 'info': {'number_mnist': 0.9188524020256658, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001049449278151902, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.010699927082518386, 'kernel_size_2': 3, 'num_filters_2': 76}"}}
exception: None

16:12:20 job_callback for (4, 0, 22) started
16:12:20 DISPATCHER: Trying to submit another job.
16:12:20 job_callback for (4, 0, 22) got condition
16:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:12:20 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:12:20 HBMASTER: Trying to run another job!
16:12:20 job_callback for (4, 0, 22) finished
16:12:20 HBMASTER: schedule new run for iteration 4
16:12:20 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
16:12:20 HBMASTER: submitting job (4, 0, 23) to dispatcher
16:12:20 DISPATCHER: trying to submit job (4, 0, 23)
16:12:20 DISPATCHER: trying to notify the job_runner thread.
16:12:20 HBMASTER: job (4, 0, 23) submitted to dispatcher
16:12:20 DISPATCHER: Trying to submit another job.
16:12:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:12:20 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:12:20 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:12:20 WORKER: start processing job (4, 0, 23)
16:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:12:20 WORKER: args: ()
16:12:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}, 'budget': 400.0, 'working_directory': '.'}
16:12:52 DISPATCHER: Starting worker discovery
16:12:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:52 DISPATCHER: Finished worker discovery
16:13:52 DISPATCHER: Starting worker discovery
16:13:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:52 DISPATCHER: Finished worker discovery
16:14:52 DISPATCHER: Starting worker discovery
16:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:52 DISPATCHER: Finished worker discovery
16:15:52 DISPATCHER: Starting worker discovery
16:15:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:52 DISPATCHER: Finished worker discovery
16:16:52 DISPATCHER: Starting worker discovery
16:16:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:52 DISPATCHER: Finished worker discovery
16:17:52 DISPATCHER: Starting worker discovery
16:17:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:52 DISPATCHER: Finished worker discovery
16:18:52 DISPATCHER: Starting worker discovery
16:18:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:52 DISPATCHER: Finished worker discovery
16:19:15 WORKER: done with job (4, 0, 23), trying to register it.
16:19:15 WORKER: registered result for job (4, 0, 23) with dispatcher
16:19:15 DISPATCHER: job (4, 0, 23) finished
16:19:15 DISPATCHER: register_result: lock acquired
16:19:15 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:19:15 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9482384223311596, 'info': {'number_mnist': 0.9482384223311596, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001545647879550862, 'num_filters_1': 112, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013365546464747543, 'kernel_size_2': 5, 'num_filters_2': 60}"}}
exception: None

16:19:15 job_callback for (4, 0, 23) started
16:19:15 job_callback for (4, 0, 23) got condition
16:19:15 DISPATCHER: Trying to submit another job.
16:19:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:19:15 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:19:15 HBMASTER: Trying to run another job!
16:19:15 job_callback for (4, 0, 23) finished
16:19:15 ITERATION: Advancing config (4, 0, 15) to next budget 1200.000000
16:19:15 HBMASTER: schedule new run for iteration 4
16:19:15 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
16:19:15 HBMASTER: submitting job (4, 0, 15) to dispatcher
16:19:15 DISPATCHER: trying to submit job (4, 0, 15)
16:19:15 DISPATCHER: trying to notify the job_runner thread.
16:19:15 HBMASTER: job (4, 0, 15) submitted to dispatcher
16:19:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:19:15 DISPATCHER: Trying to submit another job.
16:19:15 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:19:15 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:19:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:19:15 WORKER: start processing job (4, 0, 15)
16:19:15 WORKER: args: ()
16:19:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 1200.0, 'working_directory': '.'}
16:19:52 DISPATCHER: Starting worker discovery
16:19:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:52 DISPATCHER: Finished worker discovery
16:20:52 DISPATCHER: Starting worker discovery
16:20:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:52 DISPATCHER: Finished worker discovery
16:21:52 DISPATCHER: Starting worker discovery
16:21:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:52 DISPATCHER: Finished worker discovery
16:22:52 DISPATCHER: Starting worker discovery
16:22:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:52 DISPATCHER: Finished worker discovery
16:23:52 DISPATCHER: Starting worker discovery
16:23:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:52 DISPATCHER: Finished worker discovery
16:24:52 DISPATCHER: Starting worker discovery
16:24:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:52 DISPATCHER: Finished worker discovery
16:25:52 DISPATCHER: Starting worker discovery
16:25:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:52 DISPATCHER: Finished worker discovery
16:26:52 DISPATCHER: Starting worker discovery
16:26:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:52 DISPATCHER: Finished worker discovery
16:27:52 DISPATCHER: Starting worker discovery
16:27:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:52 DISPATCHER: Finished worker discovery
16:28:52 DISPATCHER: Starting worker discovery
16:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:52 DISPATCHER: Finished worker discovery
16:29:52 DISPATCHER: Starting worker discovery
16:29:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:52 DISPATCHER: Finished worker discovery
16:30:52 DISPATCHER: Starting worker discovery
16:30:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:52 DISPATCHER: Finished worker discovery
16:31:52 DISPATCHER: Starting worker discovery
16:31:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:52 DISPATCHER: Finished worker discovery
16:32:52 DISPATCHER: Starting worker discovery
16:32:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:52 DISPATCHER: Finished worker discovery
16:33:52 DISPATCHER: Starting worker discovery
16:33:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:52 DISPATCHER: Finished worker discovery
16:34:52 DISPATCHER: Starting worker discovery
16:34:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:52 DISPATCHER: Finished worker discovery
16:35:52 DISPATCHER: Starting worker discovery
16:35:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:52 DISPATCHER: Finished worker discovery
16:36:52 DISPATCHER: Starting worker discovery
16:36:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:52 DISPATCHER: Finished worker discovery
16:37:52 DISPATCHER: Starting worker discovery
16:37:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:52 DISPATCHER: Finished worker discovery
16:38:52 DISPATCHER: Starting worker discovery
16:38:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:52 DISPATCHER: Finished worker discovery
16:39:52 DISPATCHER: Starting worker discovery
16:39:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:52 DISPATCHER: Finished worker discovery
16:40:00 WORKER: done with job (4, 0, 15), trying to register it.
16:40:00 WORKER: registered result for job (4, 0, 15) with dispatcher
16:40:00 DISPATCHER: job (4, 0, 15) finished
16:40:00 DISPATCHER: register_result: lock acquired
16:40:00 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:40:00 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9593214580485574, 'info': {'number_mnist': 0.9593214580485574, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018114070768887696, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012552072440766216, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 128}"}}
exception: None

16:40:00 job_callback for (4, 0, 15) started
16:40:00 job_callback for (4, 0, 15) got condition
16:40:00 DISPATCHER: Trying to submit another job.
16:40:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:40:00 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:40:00 HBMASTER: Trying to run another job!
16:40:00 job_callback for (4, 0, 15) finished
16:40:00 start sampling a new configuration.
16:40:00 done sampling a new configuration.
16:40:00 HBMASTER: schedule new run for iteration 5
16:40:00 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
16:40:00 HBMASTER: submitting job (5, 0, 0) to dispatcher
16:40:00 DISPATCHER: trying to submit job (5, 0, 0)
16:40:00 DISPATCHER: trying to notify the job_runner thread.
16:40:00 HBMASTER: job (5, 0, 0) submitted to dispatcher
16:40:00 DISPATCHER: Trying to submit another job.
16:40:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:40:00 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:40:01 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:40:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:40:01 WORKER: start processing job (5, 0, 0)
16:40:01 WORKER: args: ()
16:40:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027229178054328534, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.015452909402036523, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 63, 'num_filters_4': 54, 'num_filters_5': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:40:52 DISPATCHER: Starting worker discovery
16:40:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:52 DISPATCHER: Finished worker discovery
16:41:52 DISPATCHER: Starting worker discovery
16:41:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:52 DISPATCHER: Finished worker discovery
16:42:24 WORKER: done with job (5, 0, 0), trying to register it.
16:42:24 WORKER: registered result for job (5, 0, 0) with dispatcher
16:42:24 DISPATCHER: job (5, 0, 0) finished
16:42:24 DISPATCHER: register_result: lock acquired
16:42:24 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:42:24 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027229178054328534, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.015452909402036523, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 63, 'num_filters_4': 54, 'num_filters_5': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8783029936947023, 'info': {'number_mnist': 0.8783029936947023, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027229178054328534, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.015452909402036523, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 63, 'num_filters_4': 54, 'num_filters_5': 33}"}}
exception: None

16:42:24 job_callback for (5, 0, 0) started
16:42:24 job_callback for (5, 0, 0) got condition
16:42:24 DISPATCHER: Trying to submit another job.
16:42:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:42:24 HBMASTER: Trying to run another job!
16:42:24 job_callback for (5, 0, 0) finished
16:42:24 start sampling a new configuration.
16:42:24 done sampling a new configuration.
16:42:24 HBMASTER: schedule new run for iteration 5
16:42:24 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
16:42:24 HBMASTER: submitting job (5, 0, 1) to dispatcher
16:42:24 DISPATCHER: trying to submit job (5, 0, 1)
16:42:24 DISPATCHER: trying to notify the job_runner thread.
16:42:24 HBMASTER: job (5, 0, 1) submitted to dispatcher
16:42:24 DISPATCHER: Trying to submit another job.
16:42:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:42:24 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:42:24 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:42:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:42:24 WORKER: start processing job (5, 0, 1)
16:42:24 WORKER: args: ()
16:42:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.030268485351713573, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.12245395278020693, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 34, 'num_filters_3': 38, 'num_filters_4': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:42:52 DISPATCHER: Starting worker discovery
16:42:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:52 DISPATCHER: Finished worker discovery
16:43:52 DISPATCHER: Starting worker discovery
16:43:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:52 DISPATCHER: Finished worker discovery
16:44:48 WORKER: done with job (5, 0, 1), trying to register it.
16:44:48 WORKER: registered result for job (5, 0, 1) with dispatcher
16:44:48 DISPATCHER: job (5, 0, 1) finished
16:44:48 DISPATCHER: register_result: lock acquired
16:44:48 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:44:48 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.030268485351713573, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.12245395278020693, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 34, 'num_filters_3': 38, 'num_filters_4': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.030268485351713573, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.12245395278020693, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 34, 'num_filters_3': 38, 'num_filters_4': 49}"}}
exception: None

16:44:48 job_callback for (5, 0, 1) started
16:44:48 job_callback for (5, 0, 1) got condition
16:44:48 DISPATCHER: Trying to submit another job.
16:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:44:48 HBMASTER: Trying to run another job!
16:44:48 job_callback for (5, 0, 1) finished
16:44:48 start sampling a new configuration.
16:44:48 best_vector: [1, 2, 0.23551180863952953, 0.9497769237054262, 0.6464128152205206, 1, 0.841857202075699, 0.21177013622389296, 0, 1, 1, 2, 0.8749431680429807, 0.5453333123887012, 0.3872967129068352, 0.3759607975212812], 0.001135847270638174, 0.005293007103860213, 6.012047672388088e-06
16:44:48 done sampling a new configuration.
16:44:48 HBMASTER: schedule new run for iteration 5
16:44:48 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
16:44:48 HBMASTER: submitting job (5, 0, 2) to dispatcher
16:44:48 DISPATCHER: trying to submit job (5, 0, 2)
16:44:48 DISPATCHER: trying to notify the job_runner thread.
16:44:48 HBMASTER: job (5, 0, 2) submitted to dispatcher
16:44:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:44:48 DISPATCHER: Trying to submit another job.
16:44:48 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:44:48 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:44:48 WORKER: start processing job (5, 0, 2)
16:44:48 WORKER: args: ()
16:44:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:44:52 DISPATCHER: Starting worker discovery
16:44:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:52 DISPATCHER: Finished worker discovery
16:45:52 DISPATCHER: Starting worker discovery
16:45:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:52 DISPATCHER: Finished worker discovery
16:46:52 DISPATCHER: Starting worker discovery
16:46:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:52 DISPATCHER: Finished worker discovery
16:47:12 WORKER: done with job (5, 0, 2), trying to register it.
16:47:12 WORKER: registered result for job (5, 0, 2) with dispatcher
16:47:12 DISPATCHER: job (5, 0, 2) finished
16:47:12 DISPATCHER: register_result: lock acquired
16:47:12 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:47:12 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8921413383079055, 'info': {'number_mnist': 0.8921413383079055, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}"}}
exception: None

16:47:12 job_callback for (5, 0, 2) started
16:47:12 job_callback for (5, 0, 2) got condition
16:47:12 DISPATCHER: Trying to submit another job.
16:47:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:47:12 HBMASTER: Trying to run another job!
16:47:12 job_callback for (5, 0, 2) finished
16:47:12 start sampling a new configuration.
16:47:12 best_vector: [0, 1, 0.08332858533546192, 0.850493252413947, 0.02577579053446577, 0, 0.03822409050432968, 0.30490801245409516, 1, 1, 2, 2, 0.09071962676359066, 0.39033472582426987, 0.2753471751073352, 0.3925254927034181], 0.0005405076845046487, 0.0009913490686121402, 5.35831789611388e-07
16:47:12 done sampling a new configuration.
16:47:12 HBMASTER: schedule new run for iteration 5
16:47:12 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
16:47:12 HBMASTER: submitting job (5, 0, 3) to dispatcher
16:47:12 DISPATCHER: trying to submit job (5, 0, 3)
16:47:12 DISPATCHER: trying to notify the job_runner thread.
16:47:12 HBMASTER: job (5, 0, 3) submitted to dispatcher
16:47:12 DISPATCHER: Trying to submit another job.
16:47:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:47:12 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:47:12 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:47:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:47:12 WORKER: start processing job (5, 0, 3)
16:47:12 WORKER: args: ()
16:47:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014677671740454834, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.024928403754099875}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:47:52 DISPATCHER: Starting worker discovery
16:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:52 DISPATCHER: Finished worker discovery
16:48:52 DISPATCHER: Starting worker discovery
16:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:52 DISPATCHER: Finished worker discovery
16:49:52 DISPATCHER: Starting worker discovery
16:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:52 DISPATCHER: Finished worker discovery
16:49:54 WORKER: done with job (5, 0, 3), trying to register it.
16:49:54 WORKER: registered result for job (5, 0, 3) with dispatcher
16:49:54 DISPATCHER: job (5, 0, 3) finished
16:49:54 DISPATCHER: register_result: lock acquired
16:49:54 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:49:54 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014677671740454834, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.024928403754099875}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8452136558454004, 'info': {'number_mnist': 0.8452136558454004, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014677671740454834, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.024928403754099875}"}}
exception: None

16:49:54 job_callback for (5, 0, 3) started
16:49:54 DISPATCHER: Trying to submit another job.
16:49:54 job_callback for (5, 0, 3) got condition
16:49:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:49:54 HBMASTER: Trying to run another job!
16:49:54 job_callback for (5, 0, 3) finished
16:49:54 start sampling a new configuration.
16:49:55 best_vector: [3, 2, 0.32061756096430366, 0.02702504347424811, 0.8947632529066787, 0, 0.12222268103431808, 0.34567369076719334, 2, 0, 1, 0, 0.5183425769381023, 0.49060743667669504, 0.9000399678713953, 0.10380465108878312], 4.114561089414766e-27, 2.4303928858235396e-06, -6.829109061008002e-06
16:49:55 done sampling a new configuration.
16:49:55 HBMASTER: schedule new run for iteration 5
16:49:55 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
16:49:55 HBMASTER: submitting job (5, 0, 4) to dispatcher
16:49:55 DISPATCHER: trying to submit job (5, 0, 4)
16:49:55 DISPATCHER: trying to notify the job_runner thread.
16:49:55 HBMASTER: job (5, 0, 4) submitted to dispatcher
16:49:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:49:55 DISPATCHER: Trying to submit another job.
16:49:55 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:49:55 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:49:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:49:55 WORKER: start processing job (5, 0, 4)
16:49:55 WORKER: args: ()
16:49:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004377590386148655, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02816643228855055, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 44, 'num_filters_4': 104, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:50:52 DISPATCHER: Starting worker discovery
16:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:52 DISPATCHER: Finished worker discovery
16:51:52 DISPATCHER: Starting worker discovery
16:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:52 DISPATCHER: Finished worker discovery
16:52:23 WORKER: done with job (5, 0, 4), trying to register it.
16:52:23 WORKER: registered result for job (5, 0, 4) with dispatcher
16:52:23 DISPATCHER: job (5, 0, 4) finished
16:52:23 DISPATCHER: register_result: lock acquired
16:52:23 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:52:23 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004377590386148655, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02816643228855055, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 44, 'num_filters_4': 104, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004377590386148655, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02816643228855055, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 44, 'num_filters_4': 104, 'num_filters_5': 19}"}}
exception: None

16:52:23 job_callback for (5, 0, 4) started
16:52:23 DISPATCHER: Trying to submit another job.
16:52:23 job_callback for (5, 0, 4) got condition
16:52:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:52:23 HBMASTER: Trying to run another job!
16:52:23 job_callback for (5, 0, 4) finished
16:52:23 start sampling a new configuration.
16:52:23 best_vector: [2, 1, 0.48162032183250547, 0.7301140140040806, 0.8744308880155728, 0, 0.34553484540671076, 0.05665194478678204, 0, 2, 2, 2, 0.24725231894122762, 0.9061469435033965, 0.3960145330264112, 0.5103017407884449], 3.203444430975486e-29, 0.0003121639914619928, -5.062748408904913e-05
16:52:23 done sampling a new configuration.
16:52:23 HBMASTER: schedule new run for iteration 5
16:52:23 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
16:52:23 HBMASTER: submitting job (5, 0, 5) to dispatcher
16:52:23 DISPATCHER: trying to submit job (5, 0, 5)
16:52:23 DISPATCHER: trying to notify the job_runner thread.
16:52:23 HBMASTER: job (5, 0, 5) submitted to dispatcher
16:52:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:52:23 DISPATCHER: Trying to submit another job.
16:52:23 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:52:23 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:52:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:52:23 WORKER: start processing job (5, 0, 5)
16:52:23 WORKER: args: ()
16:52:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009188415878893002, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.011849659729413167, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 105, 'num_filters_4': 36, 'num_filters_5': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:52:52 DISPATCHER: Starting worker discovery
16:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:52 DISPATCHER: Finished worker discovery
16:53:52 DISPATCHER: Starting worker discovery
16:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:52 DISPATCHER: Finished worker discovery
16:54:48 WORKER: done with job (5, 0, 5), trying to register it.
16:54:48 WORKER: registered result for job (5, 0, 5) with dispatcher
16:54:48 DISPATCHER: job (5, 0, 5) finished
16:54:48 DISPATCHER: register_result: lock acquired
16:54:48 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:54:48 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009188415878893002, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.011849659729413167, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 105, 'num_filters_4': 36, 'num_filters_5': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009188415878893002, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.011849659729413167, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 105, 'num_filters_4': 36, 'num_filters_5': 46}"}}
exception: None

16:54:48 job_callback for (5, 0, 5) started
16:54:48 DISPATCHER: Trying to submit another job.
16:54:48 job_callback for (5, 0, 5) got condition
16:54:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:54:48 HBMASTER: Trying to run another job!
16:54:48 job_callback for (5, 0, 5) finished
16:54:48 start sampling a new configuration.
16:54:48 best_vector: [1, 2, 0.5076494028255543, 0.8966678195330569, 0.01432655374447156, 0, 0.7651766289909261, 0.31084358240476606, 2, 2, 0, 0, 0.38898537966093905, 0.63791551305896, 0.7543676657946536, 0.454000877191723], 1.0849393355783993e-26, 9.217105207701621e-07, -4.019417890663651e-07
16:54:48 done sampling a new configuration.
16:54:48 HBMASTER: schedule new run for iteration 5
16:54:48 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
16:54:48 HBMASTER: submitting job (5, 0, 6) to dispatcher
16:54:48 DISPATCHER: trying to submit job (5, 0, 6)
16:54:48 DISPATCHER: trying to notify the job_runner thread.
16:54:48 HBMASTER: job (5, 0, 6) submitted to dispatcher
16:54:48 DISPATCHER: Trying to submit another job.
16:54:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:54:48 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:54:48 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:54:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:54:48 WORKER: start processing job (5, 0, 6)
16:54:48 WORKER: args: ()
16:54:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.010358546158853921, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02537562949733882}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:54:52 DISPATCHER: Starting worker discovery
16:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:52 DISPATCHER: Finished worker discovery
16:55:52 DISPATCHER: Starting worker discovery
16:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:52 DISPATCHER: Finished worker discovery
16:56:52 DISPATCHER: Starting worker discovery
16:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:52 DISPATCHER: Finished worker discovery
16:57:12 WORKER: done with job (5, 0, 6), trying to register it.
16:57:12 WORKER: registered result for job (5, 0, 6) with dispatcher
16:57:12 DISPATCHER: job (5, 0, 6) finished
16:57:12 DISPATCHER: register_result: lock acquired
16:57:12 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:57:12 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.010358546158853921, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02537562949733882}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7074419747266969, 'info': {'number_mnist': 0.7074419747266969, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.010358546158853921, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02537562949733882}"}}
exception: None

16:57:12 job_callback for (5, 0, 6) started
16:57:12 job_callback for (5, 0, 6) got condition
16:57:12 DISPATCHER: Trying to submit another job.
16:57:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:12 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.958936





16:57:12 HBMASTER: Trying to run another job!
16:57:12 job_callback for (5, 0, 6) finished
16:57:12 start sampling a new configuration.
16:57:12 best_vector: [2, 0, 0.8521118951034781, 0.497345864097697, 0.4923063097788365, 0, 0.18597065308081556, 0.28949193646725147, 2, 0, 0, 0, 0.34844745132791344, 0.8076973834656593, 0.27241906358374074, 0.22117625468199392], 2.4339741579679302e-27, 4.108507055123697e-06, -1.7604671859840174e-06
16:57:12 done sampling a new configuration.
16:57:12 HBMASTER: schedule new run for iteration 5
16:57:12 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
16:57:12 HBMASTER: submitting job (5, 0, 7) to dispatcher
16:57:12 DISPATCHER: trying to submit job (5, 0, 7)
16:57:12 DISPATCHER: trying to notify the job_runner thread.
16:57:12 HBMASTER: job (5, 0, 7) submitted to dispatcher
16:57:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:12 DISPATCHER: Trying to submit another job.
16:57:12 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:57:12 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:57:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:12 WORKER: start processing job (5, 0, 7)
16:57:12 WORKER: args: ()
16:57:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.050608537859269956, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.02380332864668892, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:57:52 DISPATCHER: Starting worker discovery
16:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:52 DISPATCHER: Finished worker discovery
16:58:52 DISPATCHER: Starting worker discovery
16:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:52 DISPATCHER: Finished worker discovery
16:59:39 WORKER: done with job (5, 0, 7), trying to register it.
16:59:39 WORKER: registered result for job (5, 0, 7) with dispatcher
16:59:39 DISPATCHER: job (5, 0, 7) finished
16:59:39 DISPATCHER: register_result: lock acquired
16:59:39 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:59:39 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.050608537859269956, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.02380332864668892, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.050608537859269956, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.02380332864668892, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 86}"}}
exception: None

16:59:39 job_callback for (5, 0, 7) started
16:59:39 job_callback for (5, 0, 7) got condition
16:59:39 DISPATCHER: Trying to submit another job.
16:59:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:59:39 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.958936





16:59:39 HBMASTER: Trying to run another job!
16:59:39 job_callback for (5, 0, 7) finished
16:59:39 start sampling a new configuration.
16:59:39 best_vector: [0, 2, 0.3378733360919115, 0.19306175765524403, 0.01797428316306393, 0, 0.4723819383093425, 0.26064893844187154, 1, 1, 0, 1, 0.5089057618552877, 0.01720759655148585, 0.6436732457001852, 0.34569470572806893], 7.917093876430044e-30, 0.0012630897341979195, -7.632147756121104e-06
16:59:39 done sampling a new configuration.
16:59:39 HBMASTER: schedule new run for iteration 5
16:59:39 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
16:59:39 HBMASTER: submitting job (5, 0, 8) to dispatcher
16:59:39 DISPATCHER: trying to submit job (5, 0, 8)
16:59:39 DISPATCHER: trying to notify the job_runner thread.
16:59:39 HBMASTER: job (5, 0, 8) submitted to dispatcher
16:59:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:59:39 DISPATCHER: Trying to submit another job.
16:59:39 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:59:39 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:59:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:59:39 WORKER: start processing job (5, 0, 8)
16:59:39 WORKER: args: ()
16:59:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004739654363762451, 'num_filters_1': 23, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.021832933262537053}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:59:52 DISPATCHER: Starting worker discovery
16:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:52 DISPATCHER: Finished worker discovery
17:00:52 DISPATCHER: Starting worker discovery
17:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:52 DISPATCHER: Finished worker discovery
17:01:52 DISPATCHER: Starting worker discovery
17:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:52 DISPATCHER: Finished worker discovery
17:02:06 WORKER: done with job (5, 0, 8), trying to register it.
17:02:06 WORKER: registered result for job (5, 0, 8) with dispatcher
17:02:06 DISPATCHER: job (5, 0, 8) finished
17:02:06 DISPATCHER: register_result: lock acquired
17:02:06 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:02:06 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004739654363762451, 'num_filters_1': 23, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.021832933262537053}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7664776879095124, 'info': {'number_mnist': 0.7664776879095124, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004739654363762451, 'num_filters_1': 23, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.021832933262537053}"}}
exception: None

17:02:06 job_callback for (5, 0, 8) started
17:02:06 job_callback for (5, 0, 8) got condition
17:02:06 DISPATCHER: Trying to submit another job.
17:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:02:06 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.958936





17:02:06 HBMASTER: Trying to run another job!
17:02:06 job_callback for (5, 0, 8) finished
17:02:06 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
17:02:06 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
17:02:06 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
17:02:06 HBMASTER: schedule new run for iteration 5
17:02:06 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
17:02:06 HBMASTER: submitting job (5, 0, 0) to dispatcher
17:02:06 DISPATCHER: trying to submit job (5, 0, 0)
17:02:06 DISPATCHER: trying to notify the job_runner thread.
17:02:06 HBMASTER: job (5, 0, 0) submitted to dispatcher
17:02:06 DISPATCHER: Trying to submit another job.
17:02:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:02:06 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:02:06 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:02:06 WORKER: start processing job (5, 0, 0)
17:02:06 WORKER: args: ()
17:02:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027229178054328534, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.015452909402036523, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 63, 'num_filters_4': 54, 'num_filters_5': 33}, 'budget': 400.0, 'working_directory': '.'}
17:02:52 DISPATCHER: Starting worker discovery
17:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:52 DISPATCHER: Finished worker discovery
17:03:52 DISPATCHER: Starting worker discovery
17:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:52 DISPATCHER: Finished worker discovery
17:04:52 DISPATCHER: Starting worker discovery
17:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:52 DISPATCHER: Finished worker discovery
17:05:52 DISPATCHER: Starting worker discovery
17:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:52 DISPATCHER: Finished worker discovery
17:06:52 DISPATCHER: Starting worker discovery
17:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:52 DISPATCHER: Finished worker discovery
17:07:52 DISPATCHER: Starting worker discovery
17:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:52 DISPATCHER: Finished worker discovery
17:08:52 DISPATCHER: Starting worker discovery
17:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:52 DISPATCHER: Finished worker discovery
17:09:01 WORKER: done with job (5, 0, 0), trying to register it.
17:09:01 WORKER: registered result for job (5, 0, 0) with dispatcher
17:09:01 DISPATCHER: job (5, 0, 0) finished
17:09:01 DISPATCHER: register_result: lock acquired
17:09:01 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:09:01 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027229178054328534, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.015452909402036523, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 63, 'num_filters_4': 54, 'num_filters_5': 33}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8317837010129602, 'info': {'number_mnist': 0.8317837010129602, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027229178054328534, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.015452909402036523, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 63, 'num_filters_4': 54, 'num_filters_5': 33}"}}
exception: None

17:09:01 job_callback for (5, 0, 0) started
17:09:01 DISPATCHER: Trying to submit another job.
17:09:01 job_callback for (5, 0, 0) got condition
17:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:09:01 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:09:01 HBMASTER: Trying to run another job!
17:09:01 job_callback for (5, 0, 0) finished
17:09:01 HBMASTER: schedule new run for iteration 5
17:09:01 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
17:09:01 HBMASTER: submitting job (5, 0, 2) to dispatcher
17:09:01 DISPATCHER: trying to submit job (5, 0, 2)
17:09:01 DISPATCHER: trying to notify the job_runner thread.
17:09:01 HBMASTER: job (5, 0, 2) submitted to dispatcher
17:09:01 DISPATCHER: Trying to submit another job.
17:09:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:09:01 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:09:01 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:09:01 WORKER: start processing job (5, 0, 2)
17:09:01 WORKER: args: ()
17:09:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}, 'budget': 400.0, 'working_directory': '.'}
17:09:52 DISPATCHER: Starting worker discovery
17:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:52 DISPATCHER: Finished worker discovery
17:10:52 DISPATCHER: Starting worker discovery
17:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:52 DISPATCHER: Finished worker discovery
17:11:52 DISPATCHER: Starting worker discovery
17:11:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:52 DISPATCHER: Finished worker discovery
17:12:52 DISPATCHER: Starting worker discovery
17:12:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:52 DISPATCHER: Finished worker discovery
17:13:52 DISPATCHER: Starting worker discovery
17:13:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:52 DISPATCHER: Finished worker discovery
17:14:52 DISPATCHER: Starting worker discovery
17:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:52 DISPATCHER: Finished worker discovery
17:15:52 DISPATCHER: Starting worker discovery
17:15:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:52 DISPATCHER: Finished worker discovery
17:15:57 WORKER: done with job (5, 0, 2), trying to register it.
17:15:57 WORKER: registered result for job (5, 0, 2) with dispatcher
17:15:57 DISPATCHER: job (5, 0, 2) finished
17:15:57 DISPATCHER: register_result: lock acquired
17:15:57 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:15:57 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8735200918321446, 'info': {'number_mnist': 0.8735200918321446, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}"}}
exception: None

17:15:57 job_callback for (5, 0, 2) started
17:15:57 job_callback for (5, 0, 2) got condition
17:15:57 DISPATCHER: Trying to submit another job.
17:15:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:57 HBMASTER: Trying to run another job!
17:15:57 job_callback for (5, 0, 2) finished
17:15:57 HBMASTER: schedule new run for iteration 5
17:15:57 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
17:15:57 HBMASTER: submitting job (5, 0, 3) to dispatcher
17:15:57 DISPATCHER: trying to submit job (5, 0, 3)
17:15:57 DISPATCHER: trying to notify the job_runner thread.
17:15:57 HBMASTER: job (5, 0, 3) submitted to dispatcher
17:15:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:57 DISPATCHER: Trying to submit another job.
17:15:57 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:15:57 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:15:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:57 WORKER: start processing job (5, 0, 3)
17:15:57 WORKER: args: ()
17:15:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014677671740454834, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.024928403754099875}, 'budget': 400.0, 'working_directory': '.'}
17:16:52 DISPATCHER: Starting worker discovery
17:16:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:52 DISPATCHER: Finished worker discovery
17:17:52 DISPATCHER: Starting worker discovery
17:17:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:52 DISPATCHER: Finished worker discovery
17:18:52 DISPATCHER: Starting worker discovery
17:18:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:52 DISPATCHER: Finished worker discovery
17:19:52 DISPATCHER: Starting worker discovery
17:19:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:52 DISPATCHER: Finished worker discovery
17:20:52 DISPATCHER: Starting worker discovery
17:20:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:52 DISPATCHER: Finished worker discovery
17:21:52 DISPATCHER: Starting worker discovery
17:21:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:52 DISPATCHER: Finished worker discovery
17:22:52 DISPATCHER: Starting worker discovery
17:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:53 DISPATCHER: Finished worker discovery
17:23:53 DISPATCHER: Starting worker discovery
17:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:53 DISPATCHER: Finished worker discovery
17:23:59 WORKER: done with job (5, 0, 3), trying to register it.
17:23:59 WORKER: registered result for job (5, 0, 3) with dispatcher
17:23:59 DISPATCHER: job (5, 0, 3) finished
17:23:59 DISPATCHER: register_result: lock acquired
17:23:59 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:23:59 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014677671740454834, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.024928403754099875}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8211565484377532, 'info': {'number_mnist': 0.8211565484377532, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014677671740454834, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.024928403754099875}"}}
exception: None

17:23:59 job_callback for (5, 0, 3) started
17:23:59 DISPATCHER: Trying to submit another job.
17:23:59 job_callback for (5, 0, 3) got condition
17:23:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:23:59 HBMASTER: Trying to run another job!
17:23:59 job_callback for (5, 0, 3) finished
17:23:59 ITERATION: Advancing config (5, 0, 2) to next budget 1200.000000
17:23:59 HBMASTER: schedule new run for iteration 5
17:23:59 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
17:23:59 HBMASTER: submitting job (5, 0, 2) to dispatcher
17:23:59 DISPATCHER: trying to submit job (5, 0, 2)
17:23:59 DISPATCHER: trying to notify the job_runner thread.
17:23:59 HBMASTER: job (5, 0, 2) submitted to dispatcher
17:23:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:23:59 DISPATCHER: Trying to submit another job.
17:23:59 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:23:59 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:23:59 WORKER: start processing job (5, 0, 2)
17:23:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:23:59 WORKER: args: ()
17:23:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}, 'budget': 1200.0, 'working_directory': '.'}
17:24:53 DISPATCHER: Starting worker discovery
17:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:53 DISPATCHER: Finished worker discovery
17:25:53 DISPATCHER: Starting worker discovery
17:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:53 DISPATCHER: Finished worker discovery
17:26:53 DISPATCHER: Starting worker discovery
17:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:53 DISPATCHER: Finished worker discovery
17:27:53 DISPATCHER: Starting worker discovery
17:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:53 DISPATCHER: Finished worker discovery
17:28:53 DISPATCHER: Starting worker discovery
17:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:53 DISPATCHER: Finished worker discovery
17:29:53 DISPATCHER: Starting worker discovery
17:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:53 DISPATCHER: Finished worker discovery
17:30:53 DISPATCHER: Starting worker discovery
17:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:53 DISPATCHER: Finished worker discovery
17:31:53 DISPATCHER: Starting worker discovery
17:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:53 DISPATCHER: Finished worker discovery
17:32:53 DISPATCHER: Starting worker discovery
17:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:53 DISPATCHER: Finished worker discovery
17:33:53 DISPATCHER: Starting worker discovery
17:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:53 DISPATCHER: Finished worker discovery
17:34:53 DISPATCHER: Starting worker discovery
17:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:53 DISPATCHER: Finished worker discovery
17:35:53 DISPATCHER: Starting worker discovery
17:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:53 DISPATCHER: Finished worker discovery
17:36:53 DISPATCHER: Starting worker discovery
17:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:53 DISPATCHER: Finished worker discovery
17:37:53 DISPATCHER: Starting worker discovery
17:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:53 DISPATCHER: Finished worker discovery
17:38:53 DISPATCHER: Starting worker discovery
17:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:53 DISPATCHER: Finished worker discovery
17:39:53 DISPATCHER: Starting worker discovery
17:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:53 DISPATCHER: Finished worker discovery
17:40:53 DISPATCHER: Starting worker discovery
17:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:53 DISPATCHER: Finished worker discovery
17:41:53 DISPATCHER: Starting worker discovery
17:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:53 DISPATCHER: Finished worker discovery
17:42:53 DISPATCHER: Starting worker discovery
17:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:53 DISPATCHER: Finished worker discovery
17:43:53 DISPATCHER: Starting worker discovery
17:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:53 DISPATCHER: Finished worker discovery
17:44:28 WORKER: done with job (5, 0, 2), trying to register it.
17:44:28 WORKER: registered result for job (5, 0, 2) with dispatcher
17:44:28 DISPATCHER: job (5, 0, 2) finished
17:44:28 DISPATCHER: register_result: lock acquired
17:44:28 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:44:28 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9058931456905484, 'info': {'number_mnist': 0.9058931456905484, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0029581733299941086, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.018859027743960356, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 49, 'num_filters_4': 35}"}}
exception: None

17:44:28 job_callback for (5, 0, 2) started
17:44:28 DISPATCHER: Trying to submit another job.
17:44:28 job_callback for (5, 0, 2) got condition
17:44:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:44:29 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:44:29 HBMASTER: Trying to run another job!
17:44:29 job_callback for (5, 0, 2) finished
17:44:29 start sampling a new configuration.
17:44:29 best_vector: [2, 2, 0.3595521099193833, 0.7307941771625243, 0.9172282147681388, 0, 0.3870651159655378, 0.34513572513698443, 2, 0, 2, 1, 0.5893260557937732, 0.32460569851592336, 0.14731645122126047, 0.1787436364408163], 6.388268630800588e-29, 0.00015653693634274716, -3.854718045619501e-06
17:44:29 done sampling a new configuration.
17:44:29 HBMASTER: schedule new run for iteration 6
17:44:29 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
17:44:29 HBMASTER: submitting job (6, 0, 0) to dispatcher
17:44:29 DISPATCHER: trying to submit job (6, 0, 0)
17:44:29 DISPATCHER: trying to notify the job_runner thread.
17:44:29 HBMASTER: job (6, 0, 0) submitted to dispatcher
17:44:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:44:29 DISPATCHER: Trying to submit another job.
17:44:29 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:44:29 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:44:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:44:29 WORKER: start processing job (6, 0, 0)
17:44:29 WORKER: args: ()
17:44:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005237261027029648, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.028121075796195483, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 31, 'num_filters_4': 21, 'num_filters_5': 23}, 'budget': 400.0, 'working_directory': '.'}
17:44:53 DISPATCHER: Starting worker discovery
17:44:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:53 DISPATCHER: Finished worker discovery
17:45:53 DISPATCHER: Starting worker discovery
17:45:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:53 DISPATCHER: Finished worker discovery
17:46:53 DISPATCHER: Starting worker discovery
17:46:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:53 DISPATCHER: Finished worker discovery
17:47:53 DISPATCHER: Starting worker discovery
17:47:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:53 DISPATCHER: Finished worker discovery
17:48:53 DISPATCHER: Starting worker discovery
17:48:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:53 DISPATCHER: Finished worker discovery
17:49:53 DISPATCHER: Starting worker discovery
17:49:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:53 DISPATCHER: Finished worker discovery
17:50:53 DISPATCHER: Starting worker discovery
17:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:53 DISPATCHER: Finished worker discovery
17:51:24 WORKER: done with job (6, 0, 0), trying to register it.
17:51:24 WORKER: registered result for job (6, 0, 0) with dispatcher
17:51:24 DISPATCHER: job (6, 0, 0) finished
17:51:24 DISPATCHER: register_result: lock acquired
17:51:24 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:51:24 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005237261027029648, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.028121075796195483, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 31, 'num_filters_4': 21, 'num_filters_5': 23}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6618960935508567, 'info': {'number_mnist': 0.6618960935508567, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005237261027029648, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.028121075796195483, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 31, 'num_filters_4': 21, 'num_filters_5': 23}"}}
exception: None

17:51:24 job_callback for (6, 0, 0) started
17:51:24 job_callback for (6, 0, 0) got condition
17:51:24 DISPATCHER: Trying to submit another job.
17:51:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:51:24 HBMASTER: Trying to run another job!
17:51:24 job_callback for (6, 0, 0) finished
17:51:24 start sampling a new configuration.
17:51:24 best_vector: [3, 2, 0.22117115886578137, 0.867925715220644, 0.10457996060604033, 0, 0.8554214508832805, 0.11082676769738734, 2, 0, 2, 1, 0.6075362882249675, 0.5752659806779286, 0.4544666649456055, 0.15876676054363129], 0.0009279493267001084, 0.013524477084278386, 1.2550029404327174e-05
17:51:24 done sampling a new configuration.
17:51:24 HBMASTER: schedule new run for iteration 6
17:51:24 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
17:51:24 HBMASTER: submitting job (6, 0, 1) to dispatcher
17:51:24 DISPATCHER: trying to submit job (6, 0, 1)
17:51:24 DISPATCHER: trying to notify the job_runner thread.
17:51:24 HBMASTER: job (6, 0, 1) submitted to dispatcher
17:51:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:51:24 DISPATCHER: Trying to submit another job.
17:51:24 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:51:24 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:51:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:51:24 WORKER: start processing job (6, 0, 1)
17:51:24 WORKER: args: ()
17:51:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0027691234520275197, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013937630574616193}, 'budget': 400.0, 'working_directory': '.'}
17:51:53 DISPATCHER: Starting worker discovery
17:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:53 DISPATCHER: Finished worker discovery
17:52:53 DISPATCHER: Starting worker discovery
17:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:53 DISPATCHER: Finished worker discovery
17:53:53 DISPATCHER: Starting worker discovery
17:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:53 DISPATCHER: Finished worker discovery
17:54:53 DISPATCHER: Starting worker discovery
17:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:53 DISPATCHER: Finished worker discovery
17:55:53 DISPATCHER: Starting worker discovery
17:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:53 DISPATCHER: Finished worker discovery
17:56:53 DISPATCHER: Starting worker discovery
17:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:53 DISPATCHER: Finished worker discovery
17:57:53 DISPATCHER: Starting worker discovery
17:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:53 DISPATCHER: Finished worker discovery
17:58:21 WORKER: done with job (6, 0, 1), trying to register it.
17:58:21 WORKER: registered result for job (6, 0, 1) with dispatcher
17:58:21 DISPATCHER: job (6, 0, 1) finished
17:58:21 DISPATCHER: register_result: lock acquired
17:58:21 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:58:21 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0027691234520275197, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013937630574616193}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9329036909148034, 'info': {'number_mnist': 0.9329036909148034, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0027691234520275197, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013937630574616193}"}}
exception: None

17:58:21 job_callback for (6, 0, 1) started
17:58:21 DISPATCHER: Trying to submit another job.
17:58:21 job_callback for (6, 0, 1) got condition
17:58:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:58:21 HBMASTER: Trying to run another job!
17:58:21 job_callback for (6, 0, 1) finished
17:58:21 start sampling a new configuration.
17:58:21 best_vector: [2, 1, 0.5335453222097752, 0.6303226036033275, 0.7718661522347015, 0, 0.9133817186811963, 0.34025672546136604, 0, 0, 2, 1, 0.7447609095071174, 0.6830781061811576, 0.22262445716742335, 0.15847927734789272], 0.0003928205534370771, 0.0012124998389952907, 4.762948577964969e-07
17:58:21 done sampling a new configuration.
17:58:21 HBMASTER: schedule new run for iteration 6
17:58:21 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
17:58:21 HBMASTER: submitting job (6, 0, 2) to dispatcher
17:58:21 DISPATCHER: trying to submit job (6, 0, 2)
17:58:21 DISPATCHER: trying to notify the job_runner thread.
17:58:21 HBMASTER: job (6, 0, 2) submitted to dispatcher
17:58:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:58:21 DISPATCHER: Trying to submit another job.
17:58:21 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:58:21 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:58:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:58:21 WORKER: start processing job (6, 0, 2)
17:58:21 WORKER: args: ()
17:58:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.011670531748842075, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.027713042389093213, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 75, 'num_filters_3': 66, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
17:58:53 DISPATCHER: Starting worker discovery
17:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:53 DISPATCHER: Finished worker discovery
17:59:53 DISPATCHER: Starting worker discovery
17:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:53 DISPATCHER: Finished worker discovery
18:00:53 DISPATCHER: Starting worker discovery
18:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:53 DISPATCHER: Finished worker discovery
18:01:53 DISPATCHER: Starting worker discovery
18:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:53 DISPATCHER: Finished worker discovery
18:02:53 DISPATCHER: Starting worker discovery
18:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:53 DISPATCHER: Finished worker discovery
18:03:53 DISPATCHER: Starting worker discovery
18:03:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:53 DISPATCHER: Finished worker discovery
18:04:53 DISPATCHER: Starting worker discovery
18:04:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:53 DISPATCHER: Finished worker discovery
18:05:14 WORKER: done with job (6, 0, 2), trying to register it.
18:05:14 WORKER: registered result for job (6, 0, 2) with dispatcher
18:05:14 DISPATCHER: job (6, 0, 2) finished
18:05:14 DISPATCHER: register_result: lock acquired
18:05:14 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:05:14 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.011670531748842075, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.027713042389093213, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 75, 'num_filters_3': 66, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.011670531748842075, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.027713042389093213, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 75, 'num_filters_3': 66, 'num_filters_4': 25}"}}
exception: None

18:05:14 job_callback for (6, 0, 2) started
18:05:14 DISPATCHER: Trying to submit another job.
18:05:14 job_callback for (6, 0, 2) got condition
18:05:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:05:14 HBMASTER: Trying to run another job!
18:05:14 job_callback for (6, 0, 2) finished
18:05:14 start sampling a new configuration.
18:05:14 done sampling a new configuration.
18:05:14 HBMASTER: schedule new run for iteration 6
18:05:14 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
18:05:14 HBMASTER: submitting job (6, 0, 3) to dispatcher
18:05:14 DISPATCHER: trying to submit job (6, 0, 3)
18:05:14 DISPATCHER: trying to notify the job_runner thread.
18:05:14 HBMASTER: job (6, 0, 3) submitted to dispatcher
18:05:14 DISPATCHER: Trying to submit another job.
18:05:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:05:14 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:05:14 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:05:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:05:14 WORKER: start processing job (6, 0, 3)
18:05:14 WORKER: args: ()
18:05:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004524476706551303, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.013688107516955523, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 103, 'num_filters_3': 45, 'num_filters_4': 20, 'num_filters_5': 65}, 'budget': 400.0, 'working_directory': '.'}
18:05:53 DISPATCHER: Starting worker discovery
18:05:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:53 DISPATCHER: Finished worker discovery
18:06:53 DISPATCHER: Starting worker discovery
18:06:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:53 DISPATCHER: Finished worker discovery
18:07:53 DISPATCHER: Starting worker discovery
18:07:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:53 DISPATCHER: Finished worker discovery
18:08:53 DISPATCHER: Starting worker discovery
18:08:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:53 DISPATCHER: Finished worker discovery
18:09:53 DISPATCHER: Starting worker discovery
18:09:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:53 DISPATCHER: Finished worker discovery
18:10:53 DISPATCHER: Starting worker discovery
18:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:53 DISPATCHER: Finished worker discovery
18:11:53 DISPATCHER: Starting worker discovery
18:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:53 DISPATCHER: Finished worker discovery
18:12:05 WORKER: done with job (6, 0, 3), trying to register it.
18:12:05 WORKER: registered result for job (6, 0, 3) with dispatcher
18:12:05 DISPATCHER: job (6, 0, 3) finished
18:12:05 DISPATCHER: register_result: lock acquired
18:12:05 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:12:05 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004524476706551303, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.013688107516955523, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 103, 'num_filters_3': 45, 'num_filters_4': 20, 'num_filters_5': 65}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9174238999740849, 'info': {'number_mnist': 0.9174238999740849, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004524476706551303, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.013688107516955523, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 103, 'num_filters_3': 45, 'num_filters_4': 20, 'num_filters_5': 65}"}}
exception: None

18:12:05 job_callback for (6, 0, 3) started
18:12:05 DISPATCHER: Trying to submit another job.
18:12:05 job_callback for (6, 0, 3) got condition
18:12:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:12:05 HBMASTER: Trying to run another job!
18:12:05 job_callback for (6, 0, 3) finished
18:12:05 start sampling a new configuration.
18:12:06 best_vector: [1, 2, 0.003604810241456202, 0.681169232825667, 0.09545809099295158, 0, 0.9902639632358323, 0.22539947581617367, 2, 2, 2, 1, 0.795276462319107, 0.35241876855731136, 0.0474473526106598, 0.11259823224051718], 6.34338315154019e-06, 0.0026048447328579395, 1.652352819078926e-08
18:12:06 done sampling a new configuration.
18:12:06 HBMASTER: schedule new run for iteration 6
18:12:06 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
18:12:06 HBMASTER: submitting job (6, 0, 4) to dispatcher
18:12:06 DISPATCHER: trying to submit job (6, 0, 4)
18:12:06 DISPATCHER: trying to notify the job_runner thread.
18:12:06 HBMASTER: job (6, 0, 4) submitted to dispatcher
18:12:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:12:06 DISPATCHER: Trying to submit another job.
18:12:06 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:12:06 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:12:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:12:06 WORKER: start processing job (6, 0, 4)
18:12:06 WORKER: args: ()
18:12:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010167393230066143, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.019644974935516184}, 'budget': 400.0, 'working_directory': '.'}
18:12:53 DISPATCHER: Starting worker discovery
18:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:53 DISPATCHER: Finished worker discovery
18:13:53 DISPATCHER: Starting worker discovery
18:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:53 DISPATCHER: Finished worker discovery
18:14:53 DISPATCHER: Starting worker discovery
18:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:53 DISPATCHER: Finished worker discovery
18:15:53 DISPATCHER: Starting worker discovery
18:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:53 DISPATCHER: Finished worker discovery
18:16:53 DISPATCHER: Starting worker discovery
18:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:53 DISPATCHER: Finished worker discovery
18:17:53 DISPATCHER: Starting worker discovery
18:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:53 DISPATCHER: Finished worker discovery
18:18:53 DISPATCHER: Starting worker discovery
18:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:53 DISPATCHER: Finished worker discovery
18:19:01 WORKER: done with job (6, 0, 4), trying to register it.
18:19:01 WORKER: registered result for job (6, 0, 4) with dispatcher
18:19:01 DISPATCHER: job (6, 0, 4) finished
18:19:01 DISPATCHER: register_result: lock acquired
18:19:01 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:19:01 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010167393230066143, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.019644974935516184}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9236121788569851, 'info': {'number_mnist': 0.9236121788569851, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010167393230066143, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.019644974935516184}"}}
exception: None

18:19:02 job_callback for (6, 0, 4) started
18:19:02 DISPATCHER: Trying to submit another job.
18:19:02 job_callback for (6, 0, 4) got condition
18:19:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:19:02 HBMASTER: Trying to run another job!
18:19:02 job_callback for (6, 0, 4) finished
18:19:02 start sampling a new configuration.
18:19:02 done sampling a new configuration.
18:19:02 HBMASTER: schedule new run for iteration 6
18:19:02 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
18:19:02 HBMASTER: submitting job (6, 0, 5) to dispatcher
18:19:02 DISPATCHER: trying to submit job (6, 0, 5)
18:19:02 DISPATCHER: trying to notify the job_runner thread.
18:19:02 HBMASTER: job (6, 0, 5) submitted to dispatcher
18:19:02 DISPATCHER: Trying to submit another job.
18:19:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:19:02 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:19:02 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:19:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:19:02 WORKER: start processing job (6, 0, 5)
18:19:02 WORKER: args: ()
18:19:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006499061154588724, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.04352378687153, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 55, 'num_filters_3': 72, 'num_filters_4': 21, 'num_filters_5': 39}, 'budget': 400.0, 'working_directory': '.'}
18:19:53 DISPATCHER: Starting worker discovery
18:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:53 DISPATCHER: Finished worker discovery
18:20:53 DISPATCHER: Starting worker discovery
18:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:53 DISPATCHER: Finished worker discovery
18:21:53 DISPATCHER: Starting worker discovery
18:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:53 DISPATCHER: Finished worker discovery
18:22:53 DISPATCHER: Starting worker discovery
18:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:53 DISPATCHER: Finished worker discovery
18:23:53 DISPATCHER: Starting worker discovery
18:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:53 DISPATCHER: Finished worker discovery
18:24:53 DISPATCHER: Starting worker discovery
18:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:53 DISPATCHER: Finished worker discovery
18:25:53 DISPATCHER: Starting worker discovery
18:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:53 DISPATCHER: Finished worker discovery
18:25:57 WORKER: done with job (6, 0, 5), trying to register it.
18:25:57 WORKER: registered result for job (6, 0, 5) with dispatcher
18:25:57 DISPATCHER: job (6, 0, 5) finished
18:25:57 DISPATCHER: register_result: lock acquired
18:25:57 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:25:57 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006499061154588724, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.04352378687153, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 55, 'num_filters_3': 72, 'num_filters_4': 21, 'num_filters_5': 39}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006499061154588724, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.04352378687153, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 55, 'num_filters_3': 72, 'num_filters_4': 21, 'num_filters_5': 39}"}}
exception: None

18:25:57 job_callback for (6, 0, 5) started
18:25:57 job_callback for (6, 0, 5) got condition
18:25:57 DISPATCHER: Trying to submit another job.
18:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:25:57 HBMASTER: Trying to run another job!
18:25:57 job_callback for (6, 0, 5) finished
18:25:57 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
18:25:57 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
18:25:57 HBMASTER: schedule new run for iteration 6
18:25:57 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
18:25:57 HBMASTER: submitting job (6, 0, 1) to dispatcher
18:25:57 DISPATCHER: trying to submit job (6, 0, 1)
18:25:57 DISPATCHER: trying to notify the job_runner thread.
18:25:57 HBMASTER: job (6, 0, 1) submitted to dispatcher
18:25:57 DISPATCHER: Trying to submit another job.
18:25:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:25:57 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:25:57 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:25:57 WORKER: start processing job (6, 0, 1)
18:25:57 WORKER: args: ()
18:25:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0027691234520275197, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013937630574616193}, 'budget': 1200.0, 'working_directory': '.'}
18:26:53 DISPATCHER: Starting worker discovery
18:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:53 DISPATCHER: Finished worker discovery
18:27:53 DISPATCHER: Starting worker discovery
18:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:53 DISPATCHER: Finished worker discovery
18:28:53 DISPATCHER: Starting worker discovery
18:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:53 DISPATCHER: Finished worker discovery
18:29:53 DISPATCHER: Starting worker discovery
18:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:53 DISPATCHER: Finished worker discovery
18:30:53 DISPATCHER: Starting worker discovery
18:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:53 DISPATCHER: Finished worker discovery
18:31:53 DISPATCHER: Starting worker discovery
18:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:53 DISPATCHER: Finished worker discovery
18:32:53 DISPATCHER: Starting worker discovery
18:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:53 DISPATCHER: Finished worker discovery
18:33:53 DISPATCHER: Starting worker discovery
18:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:53 DISPATCHER: Finished worker discovery
18:34:53 DISPATCHER: Starting worker discovery
18:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:53 DISPATCHER: Finished worker discovery
18:35:53 DISPATCHER: Starting worker discovery
18:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:53 DISPATCHER: Finished worker discovery
18:36:53 DISPATCHER: Starting worker discovery
18:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:53 DISPATCHER: Finished worker discovery
18:37:53 DISPATCHER: Starting worker discovery
18:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:53 DISPATCHER: Finished worker discovery
18:38:53 DISPATCHER: Starting worker discovery
18:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:53 DISPATCHER: Finished worker discovery
18:39:53 DISPATCHER: Starting worker discovery
18:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:53 DISPATCHER: Finished worker discovery
18:40:53 DISPATCHER: Starting worker discovery
18:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:53 DISPATCHER: Finished worker discovery
18:41:53 DISPATCHER: Starting worker discovery
18:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:53 DISPATCHER: Finished worker discovery
18:42:53 DISPATCHER: Starting worker discovery
18:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:53 DISPATCHER: Finished worker discovery
18:43:53 DISPATCHER: Starting worker discovery
18:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:53 DISPATCHER: Finished worker discovery
18:44:53 DISPATCHER: Starting worker discovery
18:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:54 DISPATCHER: Finished worker discovery
18:45:54 DISPATCHER: Starting worker discovery
18:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:54 DISPATCHER: Finished worker discovery
18:46:35 WORKER: done with job (6, 0, 1), trying to register it.
18:46:35 WORKER: registered result for job (6, 0, 1) with dispatcher
18:46:35 DISPATCHER: job (6, 0, 1) finished
18:46:35 DISPATCHER: register_result: lock acquired
18:46:35 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:46:35 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0027691234520275197, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013937630574616193}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9426632677590938, 'info': {'number_mnist': 0.9426632677590938, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0027691234520275197, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013937630574616193}"}}
exception: None

18:46:35 job_callback for (6, 0, 1) started
18:46:35 job_callback for (6, 0, 1) got condition
18:46:35 DISPATCHER: Trying to submit another job.
18:46:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:35 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:46:35 HBMASTER: Trying to run another job!
18:46:35 job_callback for (6, 0, 1) finished
18:46:35 HBMASTER: schedule new run for iteration 6
18:46:35 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
18:46:35 HBMASTER: submitting job (6, 0, 4) to dispatcher
18:46:35 DISPATCHER: trying to submit job (6, 0, 4)
18:46:35 DISPATCHER: trying to notify the job_runner thread.
18:46:35 HBMASTER: job (6, 0, 4) submitted to dispatcher
18:46:35 DISPATCHER: Trying to submit another job.
18:46:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:35 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:46:35 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:46:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:35 WORKER: start processing job (6, 0, 4)
18:46:35 WORKER: args: ()
18:46:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010167393230066143, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.019644974935516184}, 'budget': 1200.0, 'working_directory': '.'}
18:46:54 DISPATCHER: Starting worker discovery
18:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:54 DISPATCHER: Finished worker discovery
18:47:54 DISPATCHER: Starting worker discovery
18:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:54 DISPATCHER: Finished worker discovery
18:48:54 DISPATCHER: Starting worker discovery
18:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:54 DISPATCHER: Finished worker discovery
18:49:54 DISPATCHER: Starting worker discovery
18:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:54 DISPATCHER: Finished worker discovery
18:50:54 DISPATCHER: Starting worker discovery
18:50:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:54 DISPATCHER: Finished worker discovery
18:51:54 DISPATCHER: Starting worker discovery
18:51:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:54 DISPATCHER: Finished worker discovery
18:52:54 DISPATCHER: Starting worker discovery
18:52:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:54 DISPATCHER: Finished worker discovery
18:53:54 DISPATCHER: Starting worker discovery
18:53:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:54 DISPATCHER: Finished worker discovery
18:54:54 DISPATCHER: Starting worker discovery
18:54:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:54 DISPATCHER: Finished worker discovery
18:55:54 DISPATCHER: Starting worker discovery
18:55:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:54 DISPATCHER: Finished worker discovery
18:56:54 DISPATCHER: Starting worker discovery
18:56:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:54 DISPATCHER: Finished worker discovery
18:57:54 DISPATCHER: Starting worker discovery
18:57:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:54 DISPATCHER: Finished worker discovery
18:58:54 DISPATCHER: Starting worker discovery
18:58:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:54 DISPATCHER: Finished worker discovery
18:59:54 DISPATCHER: Starting worker discovery
18:59:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:54 DISPATCHER: Finished worker discovery
19:00:54 DISPATCHER: Starting worker discovery
19:00:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:54 DISPATCHER: Finished worker discovery
19:01:54 DISPATCHER: Starting worker discovery
19:01:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:54 DISPATCHER: Finished worker discovery
19:02:54 DISPATCHER: Starting worker discovery
19:02:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:54 DISPATCHER: Finished worker discovery
19:03:54 DISPATCHER: Starting worker discovery
19:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:54 DISPATCHER: Finished worker discovery
19:04:54 DISPATCHER: Starting worker discovery
19:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:54 DISPATCHER: Finished worker discovery
19:05:54 DISPATCHER: Starting worker discovery
19:05:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:54 DISPATCHER: Finished worker discovery
19:06:54 DISPATCHER: Starting worker discovery
19:06:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:54 DISPATCHER: Finished worker discovery
19:07:06 WORKER: done with job (6, 0, 4), trying to register it.
19:07:06 WORKER: registered result for job (6, 0, 4) with dispatcher
19:07:06 DISPATCHER: job (6, 0, 4) finished
19:07:06 DISPATCHER: register_result: lock acquired
19:07:06 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:07:06 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010167393230066143, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.019644974935516184}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.919510806331839, 'info': {'number_mnist': 0.919510806331839, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010167393230066143, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.019644974935516184}"}}
exception: None

19:07:06 job_callback for (6, 0, 4) started
19:07:06 job_callback for (6, 0, 4) got condition
19:07:06 DISPATCHER: Trying to submit another job.
19:07:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:07:06 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:07:06 HBMASTER: Trying to run another job!
19:07:06 job_callback for (6, 0, 4) finished
19:07:06 start sampling a new configuration.
19:07:07 best_vector: [2, 2, 0.04122018829289965, 0.16318840376445587, 0.6076042301529114, 0, 0.9963823720879326, 0.06437262105606635, 0, 1, 2, 2, 0.7073182746018012, 0.9257604070285461, 0.4219648151427964, 0.1897581601702455], 7.08699427851181e-30, 0.0014110354272925828, -2.1490959876395067e-07
19:07:07 done sampling a new configuration.
19:07:07 HBMASTER: schedule new run for iteration 7
19:07:07 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
19:07:07 HBMASTER: submitting job (7, 0, 0) to dispatcher
19:07:07 DISPATCHER: trying to submit job (7, 0, 0)
19:07:07 DISPATCHER: trying to notify the job_runner thread.
19:07:07 HBMASTER: job (7, 0, 0) submitted to dispatcher
19:07:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:07:07 DISPATCHER: Trying to submit another job.
19:07:07 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:07:07 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:07:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:07:07 WORKER: start processing job (7, 0, 0)
19:07:07 WORKER: args: ()
19:07:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001209039184995538, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.012126925537420624, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 69, 'num_filters_3': 110, 'num_filters_4': 38}, 'budget': 1200.0, 'working_directory': '.'}
19:07:54 DISPATCHER: Starting worker discovery
19:07:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:54 DISPATCHER: Finished worker discovery
19:08:54 DISPATCHER: Starting worker discovery
19:08:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:54 DISPATCHER: Finished worker discovery
19:09:54 DISPATCHER: Starting worker discovery
19:09:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:54 DISPATCHER: Finished worker discovery
19:10:54 DISPATCHER: Starting worker discovery
19:10:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:54 DISPATCHER: Finished worker discovery
19:11:54 DISPATCHER: Starting worker discovery
19:11:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:54 DISPATCHER: Finished worker discovery
19:12:54 DISPATCHER: Starting worker discovery
19:12:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:54 DISPATCHER: Finished worker discovery
19:13:54 DISPATCHER: Starting worker discovery
19:13:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:54 DISPATCHER: Finished worker discovery
19:14:54 DISPATCHER: Starting worker discovery
19:14:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:54 DISPATCHER: Finished worker discovery
19:15:54 DISPATCHER: Starting worker discovery
19:15:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:54 DISPATCHER: Finished worker discovery
19:16:54 DISPATCHER: Starting worker discovery
19:16:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:54 DISPATCHER: Finished worker discovery
19:17:54 DISPATCHER: Starting worker discovery
19:17:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:54 DISPATCHER: Finished worker discovery
19:18:54 DISPATCHER: Starting worker discovery
19:18:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:54 DISPATCHER: Finished worker discovery
19:19:54 DISPATCHER: Starting worker discovery
19:19:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:54 DISPATCHER: Finished worker discovery
19:20:54 DISPATCHER: Starting worker discovery
19:20:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:54 DISPATCHER: Finished worker discovery
19:21:54 DISPATCHER: Starting worker discovery
19:21:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:54 DISPATCHER: Finished worker discovery
19:22:54 DISPATCHER: Starting worker discovery
19:22:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:54 DISPATCHER: Finished worker discovery
19:23:54 DISPATCHER: Starting worker discovery
19:23:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:54 DISPATCHER: Finished worker discovery
19:24:54 DISPATCHER: Starting worker discovery
19:24:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:54 DISPATCHER: Finished worker discovery
19:25:54 DISPATCHER: Starting worker discovery
19:25:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:54 DISPATCHER: Finished worker discovery
19:26:54 DISPATCHER: Starting worker discovery
19:26:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:54 DISPATCHER: Finished worker discovery
19:27:26 WORKER: done with job (7, 0, 0), trying to register it.
19:27:26 WORKER: registered result for job (7, 0, 0) with dispatcher
19:27:26 DISPATCHER: job (7, 0, 0) finished
19:27:26 DISPATCHER: register_result: lock acquired
19:27:26 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:27:26 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001209039184995538, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.012126925537420624, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 69, 'num_filters_3': 110, 'num_filters_4': 38}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9533582469776898, 'info': {'number_mnist': 0.9533582469776898, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001209039184995538, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.012126925537420624, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 69, 'num_filters_3': 110, 'num_filters_4': 38}"}}
exception: None

19:27:26 job_callback for (7, 0, 0) started
19:27:26 DISPATCHER: Trying to submit another job.
19:27:26 job_callback for (7, 0, 0) got condition
19:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:27:26 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:27:26 HBMASTER: Trying to run another job!
19:27:26 job_callback for (7, 0, 0) finished
19:27:26 start sampling a new configuration.
19:27:26 best_vector: [2, 0, 0.7292581796485735, 0.39894601759335646, 0.9407407253745506, 0, 0.27232381838490305, 0.09445716422762654, 0, 2, 2, 2, 0.1958866134400939, 0.9515275068429337, 0.08932030864961285, 0.17470668809561207], 1.2050700815323331e-27, 8.298272567919272e-06, -1.292470359613362e-05
19:27:26 done sampling a new configuration.
19:27:26 HBMASTER: schedule new run for iteration 7
19:27:26 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
19:27:26 HBMASTER: submitting job (7, 0, 1) to dispatcher
19:27:26 DISPATCHER: trying to submit job (7, 0, 1)
19:27:26 DISPATCHER: trying to notify the job_runner thread.
19:27:26 HBMASTER: job (7, 0, 1) submitted to dispatcher
19:27:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:27:26 DISPATCHER: Trying to submit another job.
19:27:26 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:27:26 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:27:26 WORKER: start processing job (7, 0, 1)
19:27:26 WORKER: args: ()
19:27:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02874195858721984, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01327063193238011, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 23, 'num_filters_3': 116, 'num_filters_4': 19, 'num_filters_5': 22}, 'budget': 1200.0, 'working_directory': '.'}
19:27:54 DISPATCHER: Starting worker discovery
19:27:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:54 DISPATCHER: Finished worker discovery
19:28:54 DISPATCHER: Starting worker discovery
19:28:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:54 DISPATCHER: Finished worker discovery
19:29:54 DISPATCHER: Starting worker discovery
19:29:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:54 DISPATCHER: Finished worker discovery
19:30:54 DISPATCHER: Starting worker discovery
19:30:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:54 DISPATCHER: Finished worker discovery
19:31:54 DISPATCHER: Starting worker discovery
19:31:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:54 DISPATCHER: Finished worker discovery
19:32:54 DISPATCHER: Starting worker discovery
19:32:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:54 DISPATCHER: Finished worker discovery
19:33:54 DISPATCHER: Starting worker discovery
19:33:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:54 DISPATCHER: Finished worker discovery
19:34:54 DISPATCHER: Starting worker discovery
19:34:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:54 DISPATCHER: Finished worker discovery
19:35:54 DISPATCHER: Starting worker discovery
19:35:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:54 DISPATCHER: Finished worker discovery
19:36:54 DISPATCHER: Starting worker discovery
19:36:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:54 DISPATCHER: Finished worker discovery
19:37:54 DISPATCHER: Starting worker discovery
19:37:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:54 DISPATCHER: Finished worker discovery
19:38:54 DISPATCHER: Starting worker discovery
19:38:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:54 DISPATCHER: Finished worker discovery
19:39:54 DISPATCHER: Starting worker discovery
19:39:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:54 DISPATCHER: Finished worker discovery
19:40:54 DISPATCHER: Starting worker discovery
19:40:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:54 DISPATCHER: Finished worker discovery
19:41:54 DISPATCHER: Starting worker discovery
19:41:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:54 DISPATCHER: Finished worker discovery
19:42:54 DISPATCHER: Starting worker discovery
19:42:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:54 DISPATCHER: Finished worker discovery
19:43:54 DISPATCHER: Starting worker discovery
19:43:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:54 DISPATCHER: Finished worker discovery
19:44:54 DISPATCHER: Starting worker discovery
19:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:54 DISPATCHER: Finished worker discovery
19:45:54 DISPATCHER: Starting worker discovery
19:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:54 DISPATCHER: Finished worker discovery
19:46:54 DISPATCHER: Starting worker discovery
19:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:54 DISPATCHER: Finished worker discovery
19:47:54 DISPATCHER: Starting worker discovery
19:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:54 DISPATCHER: Finished worker discovery
19:48:03 WORKER: done with job (7, 0, 1), trying to register it.
19:48:03 WORKER: registered result for job (7, 0, 1) with dispatcher
19:48:03 DISPATCHER: job (7, 0, 1) finished
19:48:03 DISPATCHER: register_result: lock acquired
19:48:03 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:48:03 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02874195858721984, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01327063193238011, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 23, 'num_filters_3': 116, 'num_filters_4': 19, 'num_filters_5': 22}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02874195858721984, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01327063193238011, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 23, 'num_filters_3': 116, 'num_filters_4': 19, 'num_filters_5': 22}"}}
exception: None

19:48:03 job_callback for (7, 0, 1) started
19:48:03 DISPATCHER: Trying to submit another job.
19:48:03 job_callback for (7, 0, 1) got condition
19:48:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:48:03 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:48:03 HBMASTER: Trying to run another job!
19:48:03 job_callback for (7, 0, 1) finished
19:48:03 start sampling a new configuration.
19:48:03 best_vector: [2, 1, 0.6427340424814199, 0.5359520096013852, 0.6841587978516724, 1, 0.24022909622125566, 0.11554738757066456, 0, 0, 0, 2, 0.49913452376591205, 0.5451306234370651, 0.03283003442181709, 0.5352594433188064], 2.805059240069244e-27, 3.5649870980097898e-06, -5.10220928832049e-06
19:48:03 done sampling a new configuration.
19:48:03 HBMASTER: schedule new run for iteration 7
19:48:03 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
19:48:03 HBMASTER: submitting job (7, 0, 2) to dispatcher
19:48:03 DISPATCHER: trying to submit job (7, 0, 2)
19:48:03 DISPATCHER: trying to notify the job_runner thread.
19:48:03 HBMASTER: job (7, 0, 2) submitted to dispatcher
19:48:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:48:03 DISPATCHER: Trying to submit another job.
19:48:03 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:48:03 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:48:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:48:03 WORKER: start processing job (7, 0, 2)
19:48:03 WORKER: args: ()
19:48:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019296035300332734, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014136132823143582, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 49, 'num_filters_4': 17}, 'budget': 1200.0, 'working_directory': '.'}
19:48:54 DISPATCHER: Starting worker discovery
19:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:54 DISPATCHER: Finished worker discovery
19:49:54 DISPATCHER: Starting worker discovery
19:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:54 DISPATCHER: Finished worker discovery
19:50:54 DISPATCHER: Starting worker discovery
19:50:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:54 DISPATCHER: Finished worker discovery
19:51:54 DISPATCHER: Starting worker discovery
19:51:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:54 DISPATCHER: Finished worker discovery
19:52:54 DISPATCHER: Starting worker discovery
19:52:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:54 DISPATCHER: Finished worker discovery
19:53:54 DISPATCHER: Starting worker discovery
19:53:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:54 DISPATCHER: Finished worker discovery
19:54:54 DISPATCHER: Starting worker discovery
19:54:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:54 DISPATCHER: Finished worker discovery
19:55:54 DISPATCHER: Starting worker discovery
19:55:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:54 DISPATCHER: Finished worker discovery
19:56:54 DISPATCHER: Starting worker discovery
19:56:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:54 DISPATCHER: Finished worker discovery
19:57:54 DISPATCHER: Starting worker discovery
19:57:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:54 DISPATCHER: Finished worker discovery
19:58:54 DISPATCHER: Starting worker discovery
19:58:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:54 DISPATCHER: Finished worker discovery
19:59:54 DISPATCHER: Starting worker discovery
19:59:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:54 DISPATCHER: Finished worker discovery
20:00:54 DISPATCHER: Starting worker discovery
20:00:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:54 DISPATCHER: Finished worker discovery
20:01:54 DISPATCHER: Starting worker discovery
20:01:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:54 DISPATCHER: Finished worker discovery
20:02:54 DISPATCHER: Starting worker discovery
20:02:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:54 DISPATCHER: Finished worker discovery
20:03:54 DISPATCHER: Starting worker discovery
20:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:54 DISPATCHER: Finished worker discovery
20:04:54 DISPATCHER: Starting worker discovery
20:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:54 DISPATCHER: Finished worker discovery
20:05:54 DISPATCHER: Starting worker discovery
20:05:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:54 DISPATCHER: Finished worker discovery
20:06:54 DISPATCHER: Starting worker discovery
20:06:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:54 DISPATCHER: Finished worker discovery
20:07:54 DISPATCHER: Starting worker discovery
20:07:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:54 DISPATCHER: Finished worker discovery
20:08:53 WORKER: done with job (7, 0, 2), trying to register it.
20:08:53 WORKER: registered result for job (7, 0, 2) with dispatcher
20:08:53 DISPATCHER: job (7, 0, 2) finished
20:08:53 DISPATCHER: register_result: lock acquired
20:08:53 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:08:53 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019296035300332734, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014136132823143582, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 49, 'num_filters_4': 17}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8497778015504148, 'info': {'number_mnist': 0.8497778015504148, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019296035300332734, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014136132823143582, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 49, 'num_filters_4': 17}"}}
exception: None

20:08:53 job_callback for (7, 0, 2) started
20:08:53 job_callback for (7, 0, 2) got condition
20:08:53 DISPATCHER: Trying to submit another job.
20:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:08:53 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:08:53 HBMASTER: Trying to run another job!
20:08:53 job_callback for (7, 0, 2) finished
20:08:53 start sampling a new configuration.
20:08:53 best_vector: [1, 1, 0.4019340546168541, 0.8394452626593796, 0.053316965119451755, 0, 0.9411717559573418, 0.06957027593190054, 1, 0, 2, 0, 0.2744192404765397, 0.3526176006732651, 0.9553867739443601, 0.3027443455547984], 4.05650470101952e-28, 2.465176484939535e-05, -6.184818282551562e-06
20:08:53 done sampling a new configuration.
20:08:53 HBMASTER: schedule new run for iteration 7
20:08:53 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
20:08:53 HBMASTER: submitting job (7, 0, 3) to dispatcher
20:08:53 DISPATCHER: trying to submit job (7, 0, 3)
20:08:53 DISPATCHER: trying to notify the job_runner thread.
20:08:53 HBMASTER: job (7, 0, 3) submitted to dispatcher
20:08:53 DISPATCHER: Trying to submit another job.
20:08:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:08:53 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:08:53 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:08:53 WORKER: start processing job (7, 0, 3)
20:08:53 WORKER: args: ()
20:08:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0063660216202137306, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.012317228998856053}, 'budget': 1200.0, 'working_directory': '.'}
20:08:54 DISPATCHER: Starting worker discovery
20:08:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:54 DISPATCHER: Finished worker discovery
20:09:54 DISPATCHER: Starting worker discovery
20:09:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:54 DISPATCHER: Finished worker discovery
20:10:54 DISPATCHER: Starting worker discovery
20:10:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:54 DISPATCHER: Finished worker discovery
20:11:54 DISPATCHER: Starting worker discovery
20:11:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:54 DISPATCHER: Finished worker discovery
20:12:54 DISPATCHER: Starting worker discovery
20:12:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:54 DISPATCHER: Finished worker discovery
20:13:54 DISPATCHER: Starting worker discovery
20:13:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:54 DISPATCHER: Finished worker discovery
20:14:54 DISPATCHER: Starting worker discovery
20:14:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:54 DISPATCHER: Finished worker discovery
20:15:54 DISPATCHER: Starting worker discovery
20:15:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:54 DISPATCHER: Finished worker discovery
20:16:54 DISPATCHER: Starting worker discovery
20:16:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:54 DISPATCHER: Finished worker discovery
20:17:54 DISPATCHER: Starting worker discovery
20:17:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:54 DISPATCHER: Finished worker discovery
20:18:54 DISPATCHER: Starting worker discovery
20:18:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:54 DISPATCHER: Finished worker discovery
20:19:54 DISPATCHER: Starting worker discovery
20:19:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:54 DISPATCHER: Finished worker discovery
20:20:54 DISPATCHER: Starting worker discovery
20:20:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:54 DISPATCHER: Finished worker discovery
20:21:54 DISPATCHER: Starting worker discovery
20:21:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:54 DISPATCHER: Finished worker discovery
20:22:54 DISPATCHER: Starting worker discovery
20:22:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:54 DISPATCHER: Finished worker discovery
20:23:54 DISPATCHER: Starting worker discovery
20:23:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:54 DISPATCHER: Finished worker discovery
20:24:54 DISPATCHER: Starting worker discovery
20:24:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:54 DISPATCHER: Finished worker discovery
20:25:54 DISPATCHER: Starting worker discovery
20:25:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:55 DISPATCHER: Finished worker discovery
20:26:55 DISPATCHER: Starting worker discovery
20:26:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:55 DISPATCHER: Finished worker discovery
20:27:55 DISPATCHER: Starting worker discovery
20:27:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:55 DISPATCHER: Finished worker discovery
20:28:55 DISPATCHER: Starting worker discovery
20:28:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:55 DISPATCHER: Finished worker discovery
20:29:23 WORKER: done with job (7, 0, 3), trying to register it.
20:29:23 WORKER: registered result for job (7, 0, 3) with dispatcher
20:29:23 DISPATCHER: job (7, 0, 3) finished
20:29:23 DISPATCHER: register_result: lock acquired
20:29:23 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:29:23 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0063660216202137306, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.012317228998856053}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9031341628626084, 'info': {'number_mnist': 0.9031341628626084, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0063660216202137306, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.012317228998856053}"}}
exception: None

20:29:23 job_callback for (7, 0, 3) started
20:29:23 DISPATCHER: Trying to submit another job.
20:29:23 job_callback for (7, 0, 3) got condition
20:29:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:29:23 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:29:23 HBMASTER: Trying to run another job!
20:29:23 job_callback for (7, 0, 3) finished
20:29:23 start sampling a new configuration.
20:29:23 done sampling a new configuration.
20:29:23 HBMASTER: schedule new run for iteration 8
20:29:23 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
20:29:23 HBMASTER: submitting job (8, 0, 0) to dispatcher
20:29:23 DISPATCHER: trying to submit job (8, 0, 0)
20:29:23 DISPATCHER: trying to notify the job_runner thread.
20:29:23 HBMASTER: job (8, 0, 0) submitted to dispatcher
20:29:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:29:23 DISPATCHER: Trying to submit another job.
20:29:23 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:29:23 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:29:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:29:23 WORKER: start processing job (8, 0, 0)
20:29:23 WORKER: args: ()
20:29:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005024488614546713, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.07620380824838595, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 16, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:29:55 DISPATCHER: Starting worker discovery
20:29:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:55 DISPATCHER: Finished worker discovery
20:30:17 WORKER: done with job (8, 0, 0), trying to register it.
20:30:17 WORKER: registered result for job (8, 0, 0) with dispatcher
20:30:17 DISPATCHER: job (8, 0, 0) finished
20:30:17 DISPATCHER: register_result: lock acquired
20:30:17 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:30:17 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005024488614546713, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.07620380824838595, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 16, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31180033874209745, 'info': {'number_mnist': 0.31180033874209745, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005024488614546713, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.07620380824838595, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 16, 'num_filters_4': 32}"}}
exception: None

20:30:17 job_callback for (8, 0, 0) started
20:30:17 DISPATCHER: Trying to submit another job.
20:30:17 job_callback for (8, 0, 0) got condition
20:30:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:30:17 HBMASTER: Trying to run another job!
20:30:17 job_callback for (8, 0, 0) finished
20:30:17 start sampling a new configuration.
20:30:17 done sampling a new configuration.
20:30:17 HBMASTER: schedule new run for iteration 8
20:30:17 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
20:30:17 HBMASTER: submitting job (8, 0, 1) to dispatcher
20:30:17 DISPATCHER: trying to submit job (8, 0, 1)
20:30:17 DISPATCHER: trying to notify the job_runner thread.
20:30:17 HBMASTER: job (8, 0, 1) submitted to dispatcher
20:30:17 DISPATCHER: Trying to submit another job.
20:30:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:30:17 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:30:17 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:30:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:30:17 WORKER: start processing job (8, 0, 1)
20:30:17 WORKER: args: ()
20:30:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004067837894775981, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01583648497406996, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 37, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:30:55 DISPATCHER: Starting worker discovery
20:30:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:55 DISPATCHER: Finished worker discovery
20:31:12 WORKER: done with job (8, 0, 1), trying to register it.
20:31:12 WORKER: registered result for job (8, 0, 1) with dispatcher
20:31:12 DISPATCHER: job (8, 0, 1) finished
20:31:12 DISPATCHER: register_result: lock acquired
20:31:12 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:31:12 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004067837894775981, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01583648497406996, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 37, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7906671339766526, 'info': {'number_mnist': 0.7906671339766526, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004067837894775981, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01583648497406996, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 37, 'num_filters_4': 29}"}}
exception: None

20:31:12 job_callback for (8, 0, 1) started
20:31:12 DISPATCHER: Trying to submit another job.
20:31:12 job_callback for (8, 0, 1) got condition
20:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:31:12 HBMASTER: Trying to run another job!
20:31:12 job_callback for (8, 0, 1) finished
20:31:12 start sampling a new configuration.
20:31:12 best_vector: [0, 2, 0.006659963514989084, 0.8687996175309889, 0.19403066256380422, 0, 0.3232169694003378, 0.22887298545955906, 2, 2, 2, 2, 0.950980657050547, 0.9769809074182478, 0.907864286975077, 0.33706183809850326], 1.0597627211171488e-28, 9.43607451058337e-05, -6.61952130199091e-07
20:31:12 done sampling a new configuration.
20:31:12 HBMASTER: schedule new run for iteration 8
20:31:12 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
20:31:12 HBMASTER: submitting job (8, 0, 2) to dispatcher
20:31:12 DISPATCHER: trying to submit job (8, 0, 2)
20:31:12 DISPATCHER: trying to notify the job_runner thread.
20:31:12 HBMASTER: job (8, 0, 2) submitted to dispatcher
20:31:12 DISPATCHER: Trying to submit another job.
20:31:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:31:12 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:31:12 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:31:12 WORKER: start processing job (8, 0, 2)
20:31:12 WORKER: args: ()
20:31:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010311454435140005, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.019850462013068657}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:31:55 DISPATCHER: Starting worker discovery
20:31:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:55 DISPATCHER: Finished worker discovery
20:32:07 WORKER: done with job (8, 0, 2), trying to register it.
20:32:07 WORKER: registered result for job (8, 0, 2) with dispatcher
20:32:07 DISPATCHER: job (8, 0, 2) finished
20:32:07 DISPATCHER: register_result: lock acquired
20:32:07 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:32:07 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010311454435140005, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.019850462013068657}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8927482322916805, 'info': {'number_mnist': 0.8927482322916805, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010311454435140005, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.019850462013068657}"}}
exception: None

20:32:07 job_callback for (8, 0, 2) started
20:32:07 DISPATCHER: Trying to submit another job.
20:32:07 job_callback for (8, 0, 2) got condition
20:32:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:32:07 HBMASTER: Trying to run another job!
20:32:07 job_callback for (8, 0, 2) finished
20:32:07 start sampling a new configuration.
20:32:07 done sampling a new configuration.
20:32:07 HBMASTER: schedule new run for iteration 8
20:32:07 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
20:32:07 HBMASTER: submitting job (8, 0, 3) to dispatcher
20:32:07 DISPATCHER: trying to submit job (8, 0, 3)
20:32:07 DISPATCHER: trying to notify the job_runner thread.
20:32:07 HBMASTER: job (8, 0, 3) submitted to dispatcher
20:32:07 DISPATCHER: Trying to submit another job.
20:32:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:32:07 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:32:07 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:32:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:32:07 WORKER: start processing job (8, 0, 3)
20:32:07 WORKER: args: ()
20:32:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00483801762750966, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.011298355267390772, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 100, 'num_filters_3': 33, 'num_filters_4': 104, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:32:55 DISPATCHER: Starting worker discovery
20:32:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:55 DISPATCHER: Finished worker discovery
20:33:00 WORKER: done with job (8, 0, 3), trying to register it.
20:33:00 WORKER: registered result for job (8, 0, 3) with dispatcher
20:33:00 DISPATCHER: job (8, 0, 3) finished
20:33:00 DISPATCHER: register_result: lock acquired
20:33:00 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:33:00 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00483801762750966, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.011298355267390772, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 100, 'num_filters_3': 33, 'num_filters_4': 104, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7385899995706423, 'info': {'number_mnist': 0.7385899995706423, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00483801762750966, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.011298355267390772, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 100, 'num_filters_3': 33, 'num_filters_4': 104, 'num_filters_5': 27}"}}
exception: None

20:33:00 job_callback for (8, 0, 3) started
20:33:00 DISPATCHER: Trying to submit another job.
20:33:00 job_callback for (8, 0, 3) got condition
20:33:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:33:00 HBMASTER: Trying to run another job!
20:33:00 job_callback for (8, 0, 3) finished
20:33:00 start sampling a new configuration.
20:33:00 best_vector: [0, 1, 0.540775408602675, 0.1675966680661305, 0.010935523242955936, 0, 0.32347395008033486, 0.08309875890853176, 1, 0, 1, 0, 0.6031668649739251, 0.8805682411951944, 0.7895793684830983, 0.5658669942049251], 2.4296967172176867e-27, 4.115740013614242e-06, -2.3110583573409373e-06
20:33:00 done sampling a new configuration.
20:33:00 HBMASTER: schedule new run for iteration 8
20:33:00 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
20:33:00 HBMASTER: submitting job (8, 0, 4) to dispatcher
20:33:00 DISPATCHER: trying to submit job (8, 0, 4)
20:33:00 DISPATCHER: trying to notify the job_runner thread.
20:33:00 HBMASTER: job (8, 0, 4) submitted to dispatcher
20:33:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:33:00 DISPATCHER: Trying to submit another job.
20:33:00 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:33:00 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:33:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:33:00 WORKER: start processing job (8, 0, 4)
20:33:00 WORKER: args: ()
20:33:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012065652612722414, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01282667166674885}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:33:55 DISPATCHER: Starting worker discovery
20:33:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:55 DISPATCHER: Finished worker discovery
20:33:55 WORKER: done with job (8, 0, 4), trying to register it.
20:33:55 WORKER: registered result for job (8, 0, 4) with dispatcher
20:33:55 DISPATCHER: job (8, 0, 4) finished
20:33:55 DISPATCHER: register_result: lock acquired
20:33:55 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:33:55 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012065652612722414, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01282667166674885}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7697372691475747, 'info': {'number_mnist': 0.7697372691475747, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012065652612722414, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01282667166674885}"}}
exception: None

20:33:55 job_callback for (8, 0, 4) started
20:33:55 DISPATCHER: Trying to submit another job.
20:33:55 job_callback for (8, 0, 4) got condition
20:33:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:33:55 HBMASTER: Trying to run another job!
20:33:55 job_callback for (8, 0, 4) finished
20:33:55 start sampling a new configuration.
20:33:55 best_vector: [0, 2, 0.042106133055692135, 0.8273222684630099, 0.48056912506651334, 1, 0.9622373230026562, 0.15901070504457412, 2, 0, 1, 0, 0.84361591743513, 0.8531471889203135, 0.5606660493300933, 0.027413132358090453], 0.0008407445244221508, 0.0021652946022662593, 1.8204595806161965e-06
20:33:55 done sampling a new configuration.
20:33:55 HBMASTER: schedule new run for iteration 8
20:33:55 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
20:33:55 HBMASTER: submitting job (8, 0, 5) to dispatcher
20:33:55 DISPATCHER: trying to submit job (8, 0, 5)
20:33:55 DISPATCHER: trying to notify the job_runner thread.
20:33:55 HBMASTER: job (8, 0, 5) submitted to dispatcher
20:33:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:33:55 DISPATCHER: Trying to submit another job.
20:33:55 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:33:55 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:33:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:33:55 WORKER: start processing job (8, 0, 5)
20:33:55 WORKER: args: ()
20:33:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012139820523056997, 'num_filters_1': 89, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.016101921197952628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 94}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:34:49 WORKER: done with job (8, 0, 5), trying to register it.
20:34:49 WORKER: registered result for job (8, 0, 5) with dispatcher
20:34:49 DISPATCHER: job (8, 0, 5) finished
20:34:49 DISPATCHER: register_result: lock acquired
20:34:49 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:34:49 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012139820523056997, 'num_filters_1': 89, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.016101921197952628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 94}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.839052029702911, 'info': {'number_mnist': 0.839052029702911, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012139820523056997, 'num_filters_1': 89, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.016101921197952628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 92, 'num_filters_3': 94}"}}
exception: None

20:34:49 job_callback for (8, 0, 5) started
20:34:49 DISPATCHER: Trying to submit another job.
20:34:49 job_callback for (8, 0, 5) got condition
20:34:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:34:49 HBMASTER: Trying to run another job!
20:34:49 job_callback for (8, 0, 5) finished
20:34:49 start sampling a new configuration.
20:34:49 best_vector: [2, 0, 0.8233414146805772, 0.8115975895145869, 0.17282929932350788, 1, 0.2855760712041336, 0.009696285305959786, 0, 2, 2, 1, 0.5760347677663576, 0.675193856441462, 0.07703375940447194, 0.10960191740464494], 1.4659230746596883e-27, 6.821640352664129e-06, -2.3717887813726947e-06
20:34:49 done sampling a new configuration.
20:34:49 HBMASTER: schedule new run for iteration 8
20:34:49 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
20:34:49 HBMASTER: submitting job (8, 0, 6) to dispatcher
20:34:49 DISPATCHER: trying to submit job (8, 0, 6)
20:34:49 DISPATCHER: trying to notify the job_runner thread.
20:34:49 HBMASTER: job (8, 0, 6) submitted to dispatcher
20:34:49 DISPATCHER: Trying to submit another job.
20:34:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:34:49 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:34:49 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:34:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:34:49 WORKER: start processing job (8, 0, 6)
20:34:49 WORKER: args: ()
20:34:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:34:55 DISPATCHER: Starting worker discovery
20:34:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:55 DISPATCHER: Finished worker discovery
20:35:44 WORKER: done with job (8, 0, 6), trying to register it.
20:35:44 WORKER: registered result for job (8, 0, 6) with dispatcher
20:35:44 DISPATCHER: job (8, 0, 6) finished
20:35:44 DISPATCHER: register_result: lock acquired
20:35:44 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:35:44 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8657730998464412, 'info': {'number_mnist': 0.8657730998464412, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}"}}
exception: None

20:35:44 job_callback for (8, 0, 6) started
20:35:44 job_callback for (8, 0, 6) got condition
20:35:44 DISPATCHER: Trying to submit another job.
20:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:35:44 HBMASTER: Trying to run another job!
20:35:44 job_callback for (8, 0, 6) finished
20:35:44 start sampling a new configuration.
20:35:44 best_vector: [3, 2, 0.7484959562818962, 0.291131034789045, 0.9406525946556968, 0, 0.2979405135128696, 0.03825814582606281, 0, 2, 2, 0, 0.3270533047030281, 0.30703447851542304, 0.8588152752778692, 0.6642879228924305], 8.837134847818073e-29, 0.00011315884811318731, -4.425382337776869e-06
20:35:44 done sampling a new configuration.
20:35:44 HBMASTER: schedule new run for iteration 8
20:35:44 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
20:35:44 HBMASTER: submitting job (8, 0, 7) to dispatcher
20:35:44 DISPATCHER: trying to submit job (8, 0, 7)
20:35:44 DISPATCHER: trying to notify the job_runner thread.
20:35:44 HBMASTER: job (8, 0, 7) submitted to dispatcher
20:35:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:35:44 DISPATCHER: Trying to submit another job.
20:35:44 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:35:44 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:35:44 WORKER: start processing job (8, 0, 7)
20:35:44 WORKER: args: ()
20:35:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03140450211836281, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.011214372955470736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 95, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:35:55 DISPATCHER: Starting worker discovery
20:35:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:55 DISPATCHER: Finished worker discovery
20:36:38 WORKER: done with job (8, 0, 7), trying to register it.
20:36:38 WORKER: registered result for job (8, 0, 7) with dispatcher
20:36:38 DISPATCHER: job (8, 0, 7) finished
20:36:38 DISPATCHER: register_result: lock acquired
20:36:38 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:36:38 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03140450211836281, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.011214372955470736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 95, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03140450211836281, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.011214372955470736, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 95, 'num_filters_5': 63}"}}
exception: None

20:36:38 job_callback for (8, 0, 7) started
20:36:38 job_callback for (8, 0, 7) got condition
20:36:38 DISPATCHER: Trying to submit another job.
20:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:36:38 HBMASTER: Trying to run another job!
20:36:38 job_callback for (8, 0, 7) finished
20:36:38 start sampling a new configuration.
20:36:39 best_vector: [2, 2, 0.08453682709790819, 0.5171745922587505, 0.8368524462019039, 0, 0.42374901900663975, 0.08479101214612715, 1, 0, 2, 0, 0.8711530465846324, 0.6426035972657214, 0.13252167426854466, 0.9567327757556224], 5.872243848514241e-27, 1.7029265572018335e-06, -7.820949553842293e-07
20:36:39 done sampling a new configuration.
20:36:39 HBMASTER: schedule new run for iteration 8
20:36:39 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
20:36:39 HBMASTER: submitting job (8, 0, 8) to dispatcher
20:36:39 DISPATCHER: trying to submit job (8, 0, 8)
20:36:39 DISPATCHER: trying to notify the job_runner thread.
20:36:39 HBMASTER: job (8, 0, 8) submitted to dispatcher
20:36:39 DISPATCHER: Trying to submit another job.
20:36:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:36:39 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:36:39 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:36:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:36:39 WORKER: start processing job (8, 0, 8)
20:36:39 WORKER: args: ()
20:36:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:36:55 DISPATCHER: Starting worker discovery
20:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:55 DISPATCHER: Finished worker discovery
20:37:33 WORKER: done with job (8, 0, 8), trying to register it.
20:37:33 WORKER: registered result for job (8, 0, 8) with dispatcher
20:37:33 DISPATCHER: job (8, 0, 8) finished
20:37:33 DISPATCHER: register_result: lock acquired
20:37:33 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:37:33 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9169556514255457, 'info': {'number_mnist': 0.9169556514255457, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}"}}
exception: None

20:37:33 job_callback for (8, 0, 8) started
20:37:33 DISPATCHER: Trying to submit another job.
20:37:33 job_callback for (8, 0, 8) got condition
20:37:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:37:33 HBMASTER: Trying to run another job!
20:37:33 job_callback for (8, 0, 8) finished
20:37:33 start sampling a new configuration.
20:37:33 best_vector: [2, 1, 0.4989250456331036, 0.7939843327250344, 0.6524329722424418, 0, 0.06343141083636539, 0.016297832013750593, 1, 1, 0, 2, 0.4406260333308625, 0.8025841253847895, 0.038094267800135584, 0.09642695485180497], 9.499424376968616e-29, 0.00010526953637575169, -4.011753737230325e-05
20:37:33 done sampling a new configuration.
20:37:33 HBMASTER: schedule new run for iteration 8
20:37:33 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
20:37:33 HBMASTER: submitting job (8, 0, 9) to dispatcher
20:37:33 DISPATCHER: trying to submit job (8, 0, 9)
20:37:33 DISPATCHER: trying to notify the job_runner thread.
20:37:33 HBMASTER: job (8, 0, 9) submitted to dispatcher
20:37:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:37:33 DISPATCHER: Trying to submit another job.
20:37:33 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:37:33 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:37:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:37:33 WORKER: start processing job (8, 0, 9)
20:37:33 WORKER: args: ()
20:37:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009950618849761247, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.010500354666412566, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 85, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:37:55 DISPATCHER: Starting worker discovery
20:37:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:55 DISPATCHER: Finished worker discovery
20:38:28 WORKER: done with job (8, 0, 9), trying to register it.
20:38:28 WORKER: registered result for job (8, 0, 9) with dispatcher
20:38:28 DISPATCHER: job (8, 0, 9) finished
20:38:28 DISPATCHER: register_result: lock acquired
20:38:28 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:38:28 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009950618849761247, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.010500354666412566, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 85, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009950618849761247, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.010500354666412566, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 85, 'num_filters_4': 17}"}}
exception: None

20:38:28 job_callback for (8, 0, 9) started
20:38:28 DISPATCHER: Trying to submit another job.
20:38:28 job_callback for (8, 0, 9) got condition
20:38:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:38:28 HBMASTER: Trying to run another job!
20:38:28 job_callback for (8, 0, 9) finished
20:38:28 start sampling a new configuration.
20:38:28 best_vector: [2, 1, 0.3907806286455814, 0.0678400374958319, 0.8158764544107999, 0, 0.622600520262736, 0.3667776610216744, 0, 0, 2, 0, 0.94241043426678, 0.9120029893738859, 0.3142798689924675, 0.5053146583328956], 9.426315028479538e-28, 1.0608599404737907e-05, -1.6358187546762092e-06
20:38:28 done sampling a new configuration.
20:38:28 HBMASTER: schedule new run for iteration 8
20:38:28 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
20:38:28 HBMASTER: submitting job (8, 0, 10) to dispatcher
20:38:28 DISPATCHER: trying to submit job (8, 0, 10)
20:38:28 DISPATCHER: trying to notify the job_runner thread.
20:38:28 HBMASTER: job (8, 0, 10) submitted to dispatcher
20:38:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:38:28 DISPATCHER: Trying to submit another job.
20:38:28 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:38:28 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:38:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:38:28 WORKER: start processing job (8, 0, 10)
20:38:28 WORKER: args: ()
20:38:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006047296425214046, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.030004661992393683, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 114, 'num_filters_3': 107, 'num_filters_4': 30, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:38:55 DISPATCHER: Starting worker discovery
20:38:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:55 DISPATCHER: Finished worker discovery
20:39:22 WORKER: done with job (8, 0, 10), trying to register it.
20:39:22 WORKER: registered result for job (8, 0, 10) with dispatcher
20:39:22 DISPATCHER: job (8, 0, 10) finished
20:39:22 DISPATCHER: register_result: lock acquired
20:39:22 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:39:22 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006047296425214046, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.030004661992393683, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 114, 'num_filters_3': 107, 'num_filters_4': 30, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006047296425214046, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.030004661992393683, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 114, 'num_filters_3': 107, 'num_filters_4': 30, 'num_filters_5': 45}"}}
exception: None

20:39:22 job_callback for (8, 0, 10) started
20:39:22 DISPATCHER: Trying to submit another job.
20:39:22 job_callback for (8, 0, 10) got condition
20:39:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:39:22 HBMASTER: Trying to run another job!
20:39:22 job_callback for (8, 0, 10) finished
20:39:22 start sampling a new configuration.
20:39:22 best_vector: [2, 1, 0.3596442864379586, 0.931045943521563, 0.8622265923003505, 0, 0.08156125109461942, 0.43170123500552393, 1, 0, 0, 1, 0.8531915404635254, 0.4591250654055944, 0.2332332533068427, 0.9352017284572776], 1.533686597277626e-25, 6.520236936118842e-08, -1.505062694319203e-08
20:39:22 done sampling a new configuration.
20:39:22 HBMASTER: schedule new run for iteration 8
20:39:22 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
20:39:22 HBMASTER: submitting job (8, 0, 11) to dispatcher
20:39:22 DISPATCHER: trying to submit job (8, 0, 11)
20:39:22 DISPATCHER: trying to notify the job_runner thread.
20:39:22 HBMASTER: job (8, 0, 11) submitted to dispatcher
20:39:22 DISPATCHER: Trying to submit another job.
20:39:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:39:22 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:39:22 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:39:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:39:22 WORKER: start processing job (8, 0, 11)
20:39:22 WORKER: args: ()
20:39:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005239484656315374, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.03644653583920299, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 94, 'num_filters_3': 41, 'num_filters_4': 25, 'num_filters_5': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:39:55 DISPATCHER: Starting worker discovery
20:39:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:55 DISPATCHER: Finished worker discovery
20:40:16 WORKER: done with job (8, 0, 11), trying to register it.
20:40:16 WORKER: registered result for job (8, 0, 11) with dispatcher
20:40:16 DISPATCHER: job (8, 0, 11) finished
20:40:16 DISPATCHER: register_result: lock acquired
20:40:16 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:40:16 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005239484656315374, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.03644653583920299, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 94, 'num_filters_3': 41, 'num_filters_4': 25, 'num_filters_5': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005239484656315374, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.03644653583920299, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 94, 'num_filters_3': 41, 'num_filters_4': 25, 'num_filters_5': 112}"}}
exception: None

20:40:16 job_callback for (8, 0, 11) started
20:40:16 job_callback for (8, 0, 11) got condition
20:40:16 DISPATCHER: Trying to submit another job.
20:40:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:40:16 HBMASTER: Trying to run another job!
20:40:16 job_callback for (8, 0, 11) finished
20:40:16 start sampling a new configuration.
20:40:16 done sampling a new configuration.
20:40:16 HBMASTER: schedule new run for iteration 8
20:40:16 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
20:40:16 HBMASTER: submitting job (8, 0, 12) to dispatcher
20:40:16 DISPATCHER: trying to submit job (8, 0, 12)
20:40:16 DISPATCHER: trying to notify the job_runner thread.
20:40:16 HBMASTER: job (8, 0, 12) submitted to dispatcher
20:40:16 DISPATCHER: Trying to submit another job.
20:40:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:40:16 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:40:16 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:40:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:40:16 WORKER: start processing job (8, 0, 12)
20:40:16 WORKER: args: ()
20:40:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05075826714689078, 'num_filters_1': 41, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.019138416275729268, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 66, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:40:55 DISPATCHER: Starting worker discovery
20:40:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:55 DISPATCHER: Finished worker discovery
20:41:10 WORKER: done with job (8, 0, 12), trying to register it.
20:41:10 WORKER: registered result for job (8, 0, 12) with dispatcher
20:41:10 DISPATCHER: job (8, 0, 12) finished
20:41:10 DISPATCHER: register_result: lock acquired
20:41:10 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:41:10 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05075826714689078, 'num_filters_1': 41, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.019138416275729268, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 66, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8032383662895007, 'info': {'number_mnist': 0.8032383662895007, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05075826714689078, 'num_filters_1': 41, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.019138416275729268, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 66, 'num_filters_3': 20}"}}
exception: None

20:41:10 job_callback for (8, 0, 12) started
20:41:10 DISPATCHER: Trying to submit another job.
20:41:10 job_callback for (8, 0, 12) got condition
20:41:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:41:10 HBMASTER: Trying to run another job!
20:41:10 job_callback for (8, 0, 12) finished
20:41:10 start sampling a new configuration.
20:41:11 best_vector: [0, 1, 0.5286258512923823, 0.5950593122287477, 0.21060846341319178, 0, 0.6702267685671137, 0.2443448608116671, 1, 0, 2, 1, 0.9298672288226736, 0.8874949940638529, 0.5163635743626867, 0.1745653062541954], 0.0004648237556795546, 0.004160376991276517, 1.933842058127956e-06
20:41:11 done sampling a new configuration.
20:41:11 HBMASTER: schedule new run for iteration 8
20:41:11 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
20:41:11 HBMASTER: submitting job (8, 0, 13) to dispatcher
20:41:11 DISPATCHER: trying to submit job (8, 0, 13)
20:41:11 DISPATCHER: trying to notify the job_runner thread.
20:41:11 HBMASTER: job (8, 0, 13) submitted to dispatcher
20:41:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:41:11 DISPATCHER: Trying to submit another job.
20:41:11 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:41:11 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:41:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:41:11 WORKER: start processing job (8, 0, 13)
20:41:11 WORKER: args: ()
20:41:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.011409108298164942, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.020792178418277844, 'kernel_size_2': 5, 'num_filters_2': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:41:55 DISPATCHER: Starting worker discovery
20:41:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:55 DISPATCHER: Finished worker discovery
20:42:05 WORKER: done with job (8, 0, 13), trying to register it.
20:42:05 WORKER: registered result for job (8, 0, 13) with dispatcher
20:42:05 DISPATCHER: job (8, 0, 13) finished
20:42:05 DISPATCHER: register_result: lock acquired
20:42:05 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:42:05 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.011409108298164942, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.020792178418277844, 'kernel_size_2': 5, 'num_filters_2': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6900824086368195, 'info': {'number_mnist': 0.6900824086368195, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.011409108298164942, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.020792178418277844, 'kernel_size_2': 5, 'num_filters_2': 111}"}}
exception: None

20:42:05 job_callback for (8, 0, 13) started
20:42:05 DISPATCHER: Trying to submit another job.
20:42:05 job_callback for (8, 0, 13) got condition
20:42:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:42:05 HBMASTER: Trying to run another job!
20:42:05 job_callback for (8, 0, 13) finished
20:42:05 start sampling a new configuration.
20:42:05 best_vector: [3, 2, 0.7943560146836269, 0.5779085764351113, 0.9276879411961847, 1, 0.7710203788608823, 0.22073068938279317, 0, 2, 2, 1, 0.44297242653448743, 0.3150661667925268, 0.8515366365712068, 0.5327874282840046], 7.443583364112467e-30, 0.0013434389743268963, -6.190967221922056e-05
20:42:05 done sampling a new configuration.
20:42:05 HBMASTER: schedule new run for iteration 8
20:42:05 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
20:42:05 HBMASTER: submitting job (8, 0, 14) to dispatcher
20:42:05 DISPATCHER: trying to submit job (8, 0, 14)
20:42:05 DISPATCHER: trying to notify the job_runner thread.
20:42:05 HBMASTER: job (8, 0, 14) submitted to dispatcher
20:42:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:42:05 DISPATCHER: Trying to submit another job.
20:42:05 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:42:05 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:42:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:42:05 WORKER: start processing job (8, 0, 14)
20:42:05 WORKER: args: ()
20:42:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03878930777649618, 'num_filters_1': 53, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.019372124337661608, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 30, 'num_filters_4': 94, 'num_filters_5': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:42:55 DISPATCHER: Starting worker discovery
20:42:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:55 DISPATCHER: Finished worker discovery
20:42:58 WORKER: done with job (8, 0, 14), trying to register it.
20:42:58 WORKER: registered result for job (8, 0, 14) with dispatcher
20:42:58 DISPATCHER: job (8, 0, 14) finished
20:42:58 DISPATCHER: register_result: lock acquired
20:42:58 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:42:58 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03878930777649618, 'num_filters_1': 53, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.019372124337661608, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 30, 'num_filters_4': 94, 'num_filters_5': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8242580244292607, 'info': {'number_mnist': 0.8242580244292607, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03878930777649618, 'num_filters_1': 53, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.019372124337661608, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 30, 'num_filters_4': 94, 'num_filters_5': 48}"}}
exception: None

20:42:58 job_callback for (8, 0, 14) started
20:42:58 DISPATCHER: Trying to submit another job.
20:42:58 job_callback for (8, 0, 14) got condition
20:42:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:42:58 HBMASTER: Trying to run another job!
20:42:58 job_callback for (8, 0, 14) finished
20:42:58 start sampling a new configuration.
20:42:59 best_vector: [1, 2, 0.3290916433144304, 0.8781044785331329, 0.09205498615878324, 1, 0.9602642063061019, 0.005004139480592085, 0, 2, 0, 0, 0.18839133188477697, 0.27035183131572893, 0.6504074723822416, 0.7099719112668368], 2.2576633730740176e-28, 4.4293582999418e-05, -4.1199853782900635e-06
20:42:59 done sampling a new configuration.
20:42:59 HBMASTER: schedule new run for iteration 8
20:42:59 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
20:42:59 HBMASTER: submitting job (8, 0, 15) to dispatcher
20:42:59 DISPATCHER: trying to submit job (8, 0, 15)
20:42:59 DISPATCHER: trying to notify the job_runner thread.
20:42:59 HBMASTER: job (8, 0, 15) submitted to dispatcher
20:42:59 DISPATCHER: Trying to submit another job.
20:42:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:42:59 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:42:59 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:42:59 WORKER: start processing job (8, 0, 15)
20:42:59 WORKER: args: ()
20:42:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004551801206781417, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.01015103991721236}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:43:52 WORKER: done with job (8, 0, 15), trying to register it.
20:43:52 WORKER: registered result for job (8, 0, 15) with dispatcher
20:43:52 DISPATCHER: job (8, 0, 15) finished
20:43:52 DISPATCHER: register_result: lock acquired
20:43:52 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:43:52 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004551801206781417, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.01015103991721236}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8244589549691355, 'info': {'number_mnist': 0.8244589549691355, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004551801206781417, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.01015103991721236}"}}
exception: None

20:43:52 job_callback for (8, 0, 15) started
20:43:52 job_callback for (8, 0, 15) got condition
20:43:52 DISPATCHER: Trying to submit another job.
20:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:43:52 HBMASTER: Trying to run another job!
20:43:52 job_callback for (8, 0, 15) finished
20:43:52 start sampling a new configuration.
20:43:52 best_vector: [0, 2, 0.39371821524080525, 0.2065781357703077, 0.22432168857431567, 0, 0.5998637033471756, 0.05172326921905612, 1, 2, 0, 0, 0.37644759169686237, 0.26505100751662974, 0.18240849466422177, 0.8533629283909198], 1.5660549312794382e-29, 0.0006385472054821336, -2.022805763144182e-06
20:43:52 done sampling a new configuration.
20:43:52 HBMASTER: schedule new run for iteration 8
20:43:52 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
20:43:52 HBMASTER: submitting job (8, 0, 16) to dispatcher
20:43:52 DISPATCHER: trying to submit job (8, 0, 16)
20:43:52 DISPATCHER: trying to notify the job_runner thread.
20:43:52 HBMASTER: job (8, 0, 16) submitted to dispatcher
20:43:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:43:52 DISPATCHER: Trying to submit another job.
20:43:52 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:43:52 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:43:52 WORKER: start processing job (8, 0, 16)
20:43:52 WORKER: args: ()
20:43:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006129660631502767, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01167598490172076, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:43:55 DISPATCHER: Starting worker discovery
20:43:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:55 DISPATCHER: Finished worker discovery
20:44:46 WORKER: done with job (8, 0, 16), trying to register it.
20:44:46 WORKER: registered result for job (8, 0, 16) with dispatcher
20:44:46 DISPATCHER: job (8, 0, 16) finished
20:44:46 DISPATCHER: register_result: lock acquired
20:44:46 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:44:46 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006129660631502767, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01167598490172076, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8688153573964057, 'info': {'number_mnist': 0.8688153573964057, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006129660631502767, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01167598490172076, 'kernel_size_2': 5, 'num_filters_2': 34}"}}
exception: None

20:44:46 job_callback for (8, 0, 16) started
20:44:46 DISPATCHER: Trying to submit another job.
20:44:46 job_callback for (8, 0, 16) got condition
20:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:44:46 HBMASTER: Trying to run another job!
20:44:46 job_callback for (8, 0, 16) finished
20:44:46 start sampling a new configuration.
20:44:46 best_vector: [1, 0, 0.14254505602728482, 0.9285168197373104, 0.48191888010983003, 0, 0.8191152866332737, 0.22599447550394386, 0, 0, 2, 2, 0.7389165474874033, 0.22026142468655863, 0.37307764729809617, 0.1071443585646463], 9.761090739642535e-06, 0.021657285267196628, 2.1139872666742973e-07
20:44:46 done sampling a new configuration.
20:44:46 HBMASTER: schedule new run for iteration 8
20:44:46 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
20:44:46 HBMASTER: submitting job (8, 0, 17) to dispatcher
20:44:46 DISPATCHER: trying to submit job (8, 0, 17)
20:44:46 DISPATCHER: trying to notify the job_runner thread.
20:44:46 HBMASTER: job (8, 0, 17) submitted to dispatcher
20:44:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:44:46 DISPATCHER: Trying to submit another job.
20:44:46 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:44:46 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:44:46 WORKER: start processing job (8, 0, 17)
20:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:44:46 WORKER: args: ()
20:44:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:44:55 DISPATCHER: Starting worker discovery
20:44:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:55 DISPATCHER: Finished worker discovery
20:45:40 WORKER: done with job (8, 0, 17), trying to register it.
20:45:40 WORKER: registered result for job (8, 0, 17) with dispatcher
20:45:40 DISPATCHER: job (8, 0, 17) finished
20:45:40 DISPATCHER: register_result: lock acquired
20:45:40 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:45:40 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9228285690574168, 'info': {'number_mnist': 0.9228285690574168, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}"}}
exception: None

20:45:40 job_callback for (8, 0, 17) started
20:45:40 DISPATCHER: Trying to submit another job.
20:45:40 job_callback for (8, 0, 17) got condition
20:45:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:45:40 HBMASTER: Trying to run another job!
20:45:40 job_callback for (8, 0, 17) finished
20:45:40 start sampling a new configuration.
20:45:40 done sampling a new configuration.
20:45:40 HBMASTER: schedule new run for iteration 8
20:45:40 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
20:45:40 HBMASTER: submitting job (8, 0, 18) to dispatcher
20:45:40 DISPATCHER: trying to submit job (8, 0, 18)
20:45:40 DISPATCHER: trying to notify the job_runner thread.
20:45:40 HBMASTER: job (8, 0, 18) submitted to dispatcher
20:45:40 DISPATCHER: Trying to submit another job.
20:45:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:45:40 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:45:40 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:45:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:45:40 WORKER: start processing job (8, 0, 18)
20:45:40 WORKER: args: ()
20:45:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.030737166777959728, 'num_filters_1': 87, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.19735368583157795, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 93, 'num_filters_3': 18, 'num_filters_4': 72, 'num_filters_5': 84}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:45:55 DISPATCHER: Starting worker discovery
20:45:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:55 DISPATCHER: Finished worker discovery
20:46:34 WORKER: done with job (8, 0, 18), trying to register it.
20:46:34 WORKER: registered result for job (8, 0, 18) with dispatcher
20:46:34 DISPATCHER: job (8, 0, 18) finished
20:46:34 DISPATCHER: register_result: lock acquired
20:46:34 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:46:34 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.030737166777959728, 'num_filters_1': 87, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.19735368583157795, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 93, 'num_filters_3': 18, 'num_filters_4': 72, 'num_filters_5': 84}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.030737166777959728, 'num_filters_1': 87, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.19735368583157795, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 93, 'num_filters_3': 18, 'num_filters_4': 72, 'num_filters_5': 84}"}}
exception: None

20:46:34 job_callback for (8, 0, 18) started
20:46:34 DISPATCHER: Trying to submit another job.
20:46:34 job_callback for (8, 0, 18) got condition
20:46:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:46:34 HBMASTER: Trying to run another job!
20:46:34 job_callback for (8, 0, 18) finished
20:46:34 start sampling a new configuration.
20:46:34 best_vector: [2, 1, 0.9521884422579006, 0.7450446792495679, 0.5715302377415586, 1, 0.48131366905897827, 0.1488449757486739, 0, 2, 2, 1, 0.818138126839468, 0.7796486339423407, 0.4369871103605985, 0.01969202838127429], 3.2034729968859022e-28, 3.1216120784289445e-05, -3.7458185888373274e-07
20:46:34 done sampling a new configuration.
20:46:34 HBMASTER: schedule new run for iteration 8
20:46:34 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
20:46:34 HBMASTER: submitting job (8, 0, 19) to dispatcher
20:46:34 DISPATCHER: trying to submit job (8, 0, 19)
20:46:34 DISPATCHER: trying to notify the job_runner thread.
20:46:34 HBMASTER: job (8, 0, 19) submitted to dispatcher
20:46:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:46:34 DISPATCHER: Trying to submit another job.
20:46:34 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:46:34 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:46:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:46:34 WORKER: start processing job (8, 0, 19)
20:46:34 WORKER: args: ()
20:46:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.08023740685158857, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.015618947968904385, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:46:55 DISPATCHER: Starting worker discovery
20:46:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:55 DISPATCHER: Finished worker discovery
20:47:28 WORKER: done with job (8, 0, 19), trying to register it.
20:47:28 WORKER: registered result for job (8, 0, 19) with dispatcher
20:47:28 DISPATCHER: job (8, 0, 19) finished
20:47:28 DISPATCHER: register_result: lock acquired
20:47:28 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:47:28 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.08023740685158857, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.015618947968904385, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9062600582711017, 'info': {'number_mnist': 0.9062600582711017, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.08023740685158857, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.015618947968904385, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 81}"}}
exception: None

20:47:28 job_callback for (8, 0, 19) started
20:47:28 DISPATCHER: Trying to submit another job.
20:47:28 job_callback for (8, 0, 19) got condition
20:47:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:47:28 HBMASTER: Trying to run another job!
20:47:28 job_callback for (8, 0, 19) finished
20:47:28 start sampling a new configuration.
20:47:28 best_vector: [0, 2, 0.38814326568399576, 0.8828910447590717, 0.6358452683965268, 1, 0.967441936612055, 0.20143046610468088, 1, 1, 2, 1, 0.7006757911351233, 0.6597782363822111, 0.3413658067498886, 0.402486073430422], 0.00019092429114472002, 0.0213392610516442, 4.074183289837302e-06
20:47:28 done sampling a new configuration.
20:47:28 HBMASTER: schedule new run for iteration 8
20:47:28 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
20:47:28 HBMASTER: submitting job (8, 0, 20) to dispatcher
20:47:28 DISPATCHER: trying to submit job (8, 0, 20)
20:47:28 DISPATCHER: trying to notify the job_runner thread.
20:47:28 HBMASTER: job (8, 0, 20) submitted to dispatcher
20:47:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:47:28 DISPATCHER: Trying to submit another job.
20:47:28 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:47:28 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:47:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:47:28 WORKER: start processing job (8, 0, 20)
20:47:28 WORKER: args: ()
20:47:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00597429318259451, 'num_filters_1': 100, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.018283825950154986, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 68, 'num_filters_3': 63, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:47:55 DISPATCHER: Starting worker discovery
20:47:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:55 DISPATCHER: Finished worker discovery
20:48:22 WORKER: done with job (8, 0, 20), trying to register it.
20:48:22 WORKER: registered result for job (8, 0, 20) with dispatcher
20:48:22 DISPATCHER: job (8, 0, 20) finished
20:48:22 DISPATCHER: register_result: lock acquired
20:48:22 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:48:22 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00597429318259451, 'num_filters_1': 100, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.018283825950154986, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 68, 'num_filters_3': 63, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8959850341612074, 'info': {'number_mnist': 0.8959850341612074, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00597429318259451, 'num_filters_1': 100, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.018283825950154986, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 68, 'num_filters_3': 63, 'num_filters_4': 32}"}}
exception: None

20:48:22 job_callback for (8, 0, 20) started
20:48:22 DISPATCHER: Trying to submit another job.
20:48:22 job_callback for (8, 0, 20) got condition
20:48:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:22 HBMASTER: Trying to run another job!
20:48:22 job_callback for (8, 0, 20) finished
20:48:22 start sampling a new configuration.
20:48:22 best_vector: [2, 2, 0.4700022635726616, 0.3202433654501171, 0.8079807645922931, 1, 0.789591653577323, 0.0814444233157568, 1, 0, 2, 0, 0.8239934578121191, 0.5566366851883224, 0.29783413800720565, 0.11297783065451236], 0.00023012910267804654, 0.0021686441159910136, 4.990681244410375e-07
20:48:22 done sampling a new configuration.
20:48:22 HBMASTER: schedule new run for iteration 8
20:48:22 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
20:48:22 HBMASTER: submitting job (8, 0, 21) to dispatcher
20:48:22 DISPATCHER: trying to submit job (8, 0, 21)
20:48:22 DISPATCHER: trying to notify the job_runner thread.
20:48:22 HBMASTER: job (8, 0, 21) submitted to dispatcher
20:48:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:48:22 DISPATCHER: Trying to submit another job.
20:48:22 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:48:22 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:48:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:48:22 WORKER: start processing job (8, 0, 21)
20:48:22 WORKER: args: ()
20:48:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008709726690474776, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01276326062850064, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 50, 'num_filters_4': 29, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:48:55 DISPATCHER: Starting worker discovery
20:48:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:55 DISPATCHER: Finished worker discovery
20:49:15 WORKER: done with job (8, 0, 21), trying to register it.
20:49:15 WORKER: registered result for job (8, 0, 21) with dispatcher
20:49:15 DISPATCHER: job (8, 0, 21) finished
20:49:15 DISPATCHER: register_result: lock acquired
20:49:15 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:49:15 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008709726690474776, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01276326062850064, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 50, 'num_filters_4': 29, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.927258897914707, 'info': {'number_mnist': 0.927258897914707, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008709726690474776, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01276326062850064, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 50, 'num_filters_4': 29, 'num_filters_5': 20}"}}
exception: None

20:49:15 job_callback for (8, 0, 21) started
20:49:15 DISPATCHER: Trying to submit another job.
20:49:15 job_callback for (8, 0, 21) got condition
20:49:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:49:15 HBMASTER: Trying to run another job!
20:49:15 job_callback for (8, 0, 21) finished
20:49:15 start sampling a new configuration.
20:49:15 best_vector: [0, 1, 0.13718937510298493, 0.5922889992609172, 0.17624121365949497, 0, 0.835798504342586, 0.19221437511021783, 0, 0, 1, 1, 0.004395273699918212, 0.9253560412018714, 0.6048748123809717, 0.7349589877197797], 0.0007368455010006741, 0.00010256523551031946, 7.557473234485347e-08
20:49:15 done sampling a new configuration.
20:49:15 HBMASTER: schedule new run for iteration 8
20:49:15 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
20:49:15 HBMASTER: submitting job (8, 0, 22) to dispatcher
20:49:15 DISPATCHER: trying to submit job (8, 0, 22)
20:49:15 DISPATCHER: trying to notify the job_runner thread.
20:49:15 HBMASTER: job (8, 0, 22) submitted to dispatcher
20:49:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:49:15 DISPATCHER: Trying to submit another job.
20:49:15 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:49:15 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:49:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:49:15 WORKER: start processing job (8, 0, 22)
20:49:15 WORKER: args: ()
20:49:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018809564924835663, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.017785933640118306}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:49:55 DISPATCHER: Starting worker discovery
20:49:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:55 DISPATCHER: Finished worker discovery
20:50:10 WORKER: done with job (8, 0, 22), trying to register it.
20:50:10 WORKER: registered result for job (8, 0, 22) with dispatcher
20:50:10 DISPATCHER: job (8, 0, 22) finished
20:50:10 DISPATCHER: register_result: lock acquired
20:50:10 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:50:10 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018809564924835663, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.017785933640118306}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9023689146427646, 'info': {'number_mnist': 0.9023689146427646, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018809564924835663, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.017785933640118306}"}}
exception: None

20:50:10 job_callback for (8, 0, 22) started
20:50:10 DISPATCHER: Trying to submit another job.
20:50:10 job_callback for (8, 0, 22) got condition
20:50:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:50:10 HBMASTER: Trying to run another job!
20:50:10 job_callback for (8, 0, 22) finished
20:50:10 start sampling a new configuration.
20:50:10 best_vector: [2, 1, 0.7576545346352206, 0.7473898840575351, 0.7291316327003419, 1, 0.08771596396130349, 0.1708888458516201, 1, 1, 0, 2, 0.13590910543208012, 0.6588624615580733, 0.1512106786460355, 0.0511386540399915], 2.305579438927905e-27, 4.337304467223217e-06, -3.132161776282262e-05
20:50:10 done sampling a new configuration.
20:50:10 HBMASTER: schedule new run for iteration 8
20:50:10 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
20:50:10 HBMASTER: submitting job (8, 0, 23) to dispatcher
20:50:10 DISPATCHER: trying to submit job (8, 0, 23)
20:50:10 DISPATCHER: trying to notify the job_runner thread.
20:50:10 HBMASTER: job (8, 0, 23) submitted to dispatcher
20:50:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:50:10 DISPATCHER: Trying to submit another job.
20:50:10 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:50:10 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:50:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:50:10 WORKER: start processing job (8, 0, 23)
20:50:10 WORKER: args: ()
20:50:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03275737325113279, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.016685203750101525, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 62, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:50:55 DISPATCHER: Starting worker discovery
20:50:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:55 DISPATCHER: Finished worker discovery
20:51:04 WORKER: done with job (8, 0, 23), trying to register it.
20:51:04 WORKER: registered result for job (8, 0, 23) with dispatcher
20:51:04 DISPATCHER: job (8, 0, 23) finished
20:51:04 DISPATCHER: register_result: lock acquired
20:51:04 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:51:04 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03275737325113279, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.016685203750101525, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 62, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6196272938217054, 'info': {'number_mnist': 0.6196272938217054, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03275737325113279, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.016685203750101525, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 62, 'num_filters_4': 21}"}}
exception: None

20:51:04 job_callback for (8, 0, 23) started
20:51:04 DISPATCHER: Trying to submit another job.
20:51:04 job_callback for (8, 0, 23) got condition
20:51:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:51:04 HBMASTER: Trying to run another job!
20:51:04 job_callback for (8, 0, 23) finished
20:51:04 start sampling a new configuration.
20:51:04 best_vector: [0, 1, 0.35224991552122425, 0.12367319196546045, 0.4549065926526821, 0, 0.2918189404863789, 0.1940147431859844, 0, 0, 2, 2, 0.09551514465248656, 0.04913494359920967, 0.6303743250431186, 0.7682078446826944], 5.892092435268394e-29, 0.0001697189938864984, -1.854450632888923e-05
20:51:04 done sampling a new configuration.
20:51:04 HBMASTER: schedule new run for iteration 8
20:51:04 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
20:51:04 HBMASTER: submitting job (8, 0, 24) to dispatcher
20:51:04 DISPATCHER: trying to submit job (8, 0, 24)
20:51:04 DISPATCHER: trying to notify the job_runner thread.
20:51:04 HBMASTER: job (8, 0, 24) submitted to dispatcher
20:51:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:51:04 DISPATCHER: Trying to submit another job.
20:51:04 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:51:04 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:51:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:51:04 WORKER: start processing job (8, 0, 24)
20:51:04 WORKER: args: ()
20:51:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005064071525116099, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.0178821198167479, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:51:55 DISPATCHER: Starting worker discovery
20:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:55 DISPATCHER: Finished worker discovery
20:51:59 WORKER: done with job (8, 0, 24), trying to register it.
20:51:59 WORKER: registered result for job (8, 0, 24) with dispatcher
20:51:59 DISPATCHER: job (8, 0, 24) finished
20:51:59 DISPATCHER: register_result: lock acquired
20:51:59 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:51:59 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005064071525116099, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.0178821198167479, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7630112813665981, 'info': {'number_mnist': 0.7630112813665981, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005064071525116099, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.0178821198167479, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 17}"}}
exception: None

20:51:59 job_callback for (8, 0, 24) started
20:51:59 job_callback for (8, 0, 24) got condition
20:51:59 DISPATCHER: Trying to submit another job.
20:51:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:51:59 HBMASTER: Trying to run another job!
20:51:59 job_callback for (8, 0, 24) finished
20:51:59 start sampling a new configuration.
20:51:59 done sampling a new configuration.
20:51:59 HBMASTER: schedule new run for iteration 8
20:51:59 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
20:51:59 HBMASTER: submitting job (8, 0, 25) to dispatcher
20:51:59 DISPATCHER: trying to submit job (8, 0, 25)
20:51:59 DISPATCHER: trying to notify the job_runner thread.
20:51:59 HBMASTER: job (8, 0, 25) submitted to dispatcher
20:51:59 DISPATCHER: Trying to submit another job.
20:51:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:51:59 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:51:59 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:51:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:51:59 WORKER: start processing job (8, 0, 25)
20:51:59 WORKER: args: ()
20:51:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008739123378806678, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.058521169290370004, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 99}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:52:54 WORKER: done with job (8, 0, 25), trying to register it.
20:52:54 WORKER: registered result for job (8, 0, 25) with dispatcher
20:52:54 DISPATCHER: job (8, 0, 25) finished
20:52:54 DISPATCHER: register_result: lock acquired
20:52:54 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:52:54 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008739123378806678, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.058521169290370004, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 99}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08504411251478836, 'info': {'number_mnist': 0.08504411251478836, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008739123378806678, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.058521169290370004, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 99}"}}
exception: None

20:52:54 job_callback for (8, 0, 25) started
20:52:54 job_callback for (8, 0, 25) got condition
20:52:54 DISPATCHER: Trying to submit another job.
20:52:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:52:54 HBMASTER: Trying to run another job!
20:52:54 job_callback for (8, 0, 25) finished
20:52:54 start sampling a new configuration.
20:52:54 best_vector: [0, 1, 0.3125307442464647, 0.42306389376468073, 0.2936834112959531, 0, 0.0023717650447874217, 0.10779793959714581, 2, 2, 2, 2, 0.1979342706748397, 0.044024964148182494, 0.9835983126592679, 0.9333530860094921], 1.230887662169329e-27, 8.124218242935263e-06, -2.9085807241960707e-06
20:52:54 done sampling a new configuration.
20:52:54 HBMASTER: schedule new run for iteration 8
20:52:54 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
20:52:54 HBMASTER: submitting job (8, 0, 26) to dispatcher
20:52:54 DISPATCHER: trying to submit job (8, 0, 26)
20:52:54 DISPATCHER: trying to notify the job_runner thread.
20:52:54 HBMASTER: job (8, 0, 26) submitted to dispatcher
20:52:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:52:54 DISPATCHER: Trying to submit another job.
20:52:54 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:52:54 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:52:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:52:54 WORKER: start processing job (8, 0, 26)
20:52:54 WORKER: args: ()
20:52:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004217562124951648, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.013811738681367041, 'kernel_size_2': 7, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:52:55 DISPATCHER: Starting worker discovery
20:52:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:55 DISPATCHER: Finished worker discovery
20:53:55 DISPATCHER: Starting worker discovery
20:53:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:55 DISPATCHER: Finished worker discovery
20:53:55 WORKER: done with job (8, 0, 26), trying to register it.
20:53:55 WORKER: registered result for job (8, 0, 26) with dispatcher
20:53:55 DISPATCHER: job (8, 0, 26) finished
20:53:55 DISPATCHER: register_result: lock acquired
20:53:55 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:53:55 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004217562124951648, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.013811738681367041, 'kernel_size_2': 7, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7325357832104583, 'info': {'number_mnist': 0.7325357832104583, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004217562124951648, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.013811738681367041, 'kernel_size_2': 7, 'num_filters_2': 24}"}}
exception: None

20:53:55 job_callback for (8, 0, 26) started
20:53:55 DISPATCHER: Trying to submit another job.
20:53:55 job_callback for (8, 0, 26) got condition
20:53:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:53:55 HBMASTER: Trying to run another job!
20:53:55 job_callback for (8, 0, 26) finished
20:53:55 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
20:53:55 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
20:53:55 HBMASTER: schedule new run for iteration 8
20:53:55 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
20:53:55 HBMASTER: submitting job (8, 0, 2) to dispatcher
20:53:55 DISPATCHER: trying to submit job (8, 0, 2)
20:53:55 DISPATCHER: trying to notify the job_runner thread.
20:53:55 HBMASTER: job (8, 0, 2) submitted to dispatcher
20:53:55 DISPATCHER: Trying to submit another job.
20:53:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:53:55 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:53:55 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:53:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:53:55 WORKER: start processing job (8, 0, 2)
20:53:55 WORKER: args: ()
20:53:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010311454435140005, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.019850462013068657}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:54:55 DISPATCHER: Starting worker discovery
20:54:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:55 DISPATCHER: Finished worker discovery
20:55:55 DISPATCHER: Starting worker discovery
20:55:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:55 DISPATCHER: Finished worker discovery
20:56:24 WORKER: done with job (8, 0, 2), trying to register it.
20:56:24 WORKER: registered result for job (8, 0, 2) with dispatcher
20:56:24 DISPATCHER: job (8, 0, 2) finished
20:56:24 DISPATCHER: register_result: lock acquired
20:56:24 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:56:24 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010311454435140005, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.019850462013068657}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8835829002072157, 'info': {'number_mnist': 0.8835829002072157, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010311454435140005, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.019850462013068657}"}}
exception: None

20:56:24 job_callback for (8, 0, 2) started
20:56:24 job_callback for (8, 0, 2) got condition
20:56:24 DISPATCHER: Trying to submit another job.
20:56:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:56:24 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.958936





20:56:24 HBMASTER: Trying to run another job!
20:56:24 job_callback for (8, 0, 2) finished
20:56:24 HBMASTER: schedule new run for iteration 8
20:56:24 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
20:56:24 HBMASTER: submitting job (8, 0, 6) to dispatcher
20:56:24 DISPATCHER: trying to submit job (8, 0, 6)
20:56:24 DISPATCHER: trying to notify the job_runner thread.
20:56:24 HBMASTER: job (8, 0, 6) submitted to dispatcher
20:56:24 DISPATCHER: Trying to submit another job.
20:56:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:56:24 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:56:24 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:56:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:56:24 WORKER: start processing job (8, 0, 6)
20:56:24 WORKER: args: ()
20:56:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:56:55 DISPATCHER: Starting worker discovery
20:56:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:55 DISPATCHER: Finished worker discovery
20:57:55 DISPATCHER: Starting worker discovery
20:57:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:55 DISPATCHER: Finished worker discovery
20:58:51 WORKER: done with job (8, 0, 6), trying to register it.
20:58:51 WORKER: registered result for job (8, 0, 6) with dispatcher
20:58:51 DISPATCHER: job (8, 0, 6) finished
20:58:51 DISPATCHER: register_result: lock acquired
20:58:51 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:58:51 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9133624797447754, 'info': {'number_mnist': 0.9133624797447754, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}"}}
exception: None

20:58:51 job_callback for (8, 0, 6) started
20:58:51 job_callback for (8, 0, 6) got condition
20:58:51 DISPATCHER: Trying to submit another job.
20:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:51 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.958936





20:58:51 HBMASTER: Trying to run another job!
20:58:51 job_callback for (8, 0, 6) finished
20:58:51 HBMASTER: schedule new run for iteration 8
20:58:51 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
20:58:51 HBMASTER: submitting job (8, 0, 8) to dispatcher
20:58:51 DISPATCHER: trying to submit job (8, 0, 8)
20:58:51 DISPATCHER: trying to notify the job_runner thread.
20:58:51 HBMASTER: job (8, 0, 8) submitted to dispatcher
20:58:51 DISPATCHER: Trying to submit another job.
20:58:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:51 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:58:51 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:51 WORKER: start processing job (8, 0, 8)
20:58:51 WORKER: args: ()
20:58:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:58:55 DISPATCHER: Starting worker discovery
20:58:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:55 DISPATCHER: Finished worker discovery
20:59:55 DISPATCHER: Starting worker discovery
20:59:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:55 DISPATCHER: Finished worker discovery
21:00:55 DISPATCHER: Starting worker discovery
21:00:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:55 DISPATCHER: Finished worker discovery
21:01:14 WORKER: done with job (8, 0, 8), trying to register it.
21:01:14 WORKER: registered result for job (8, 0, 8) with dispatcher
21:01:14 DISPATCHER: job (8, 0, 8) finished
21:01:14 DISPATCHER: register_result: lock acquired
21:01:14 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:01:14 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9472318863276835, 'info': {'number_mnist': 0.9472318863276835, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}"}}
exception: None

21:01:14 job_callback for (8, 0, 8) started
21:01:14 job_callback for (8, 0, 8) got condition
21:01:14 DISPATCHER: Trying to submit another job.
21:01:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:01:14 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.958936





21:01:14 HBMASTER: Trying to run another job!
21:01:14 job_callback for (8, 0, 8) finished
21:01:14 HBMASTER: schedule new run for iteration 8
21:01:14 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
21:01:14 HBMASTER: submitting job (8, 0, 16) to dispatcher
21:01:14 DISPATCHER: trying to submit job (8, 0, 16)
21:01:14 DISPATCHER: trying to notify the job_runner thread.
21:01:14 HBMASTER: job (8, 0, 16) submitted to dispatcher
21:01:14 DISPATCHER: Trying to submit another job.
21:01:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:01:14 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:01:14 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:01:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:01:14 WORKER: start processing job (8, 0, 16)
21:01:14 WORKER: args: ()
21:01:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006129660631502767, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01167598490172076, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:01:55 DISPATCHER: Starting worker discovery
21:01:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:55 DISPATCHER: Finished worker discovery
21:02:55 DISPATCHER: Starting worker discovery
21:02:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:55 DISPATCHER: Finished worker discovery
21:03:40 WORKER: done with job (8, 0, 16), trying to register it.
21:03:40 WORKER: registered result for job (8, 0, 16) with dispatcher
21:03:40 DISPATCHER: job (8, 0, 16) finished
21:03:40 DISPATCHER: register_result: lock acquired
21:03:40 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:03:40 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006129660631502767, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01167598490172076, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8478752864089409, 'info': {'number_mnist': 0.8478752864089409, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006129660631502767, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01167598490172076, 'kernel_size_2': 5, 'num_filters_2': 34}"}}
exception: None

21:03:40 job_callback for (8, 0, 16) started
21:03:40 job_callback for (8, 0, 16) got condition
21:03:40 DISPATCHER: Trying to submit another job.
21:03:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:40 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.958936





21:03:40 HBMASTER: Trying to run another job!
21:03:40 job_callback for (8, 0, 16) finished
21:03:40 HBMASTER: schedule new run for iteration 8
21:03:40 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
21:03:40 HBMASTER: submitting job (8, 0, 17) to dispatcher
21:03:40 DISPATCHER: trying to submit job (8, 0, 17)
21:03:40 DISPATCHER: trying to notify the job_runner thread.
21:03:40 HBMASTER: job (8, 0, 17) submitted to dispatcher
21:03:40 DISPATCHER: Trying to submit another job.
21:03:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:40 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:03:40 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:03:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:40 WORKER: start processing job (8, 0, 17)
21:03:40 WORKER: args: ()
21:03:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:03:55 DISPATCHER: Starting worker discovery
21:03:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:55 DISPATCHER: Finished worker discovery
21:04:55 DISPATCHER: Starting worker discovery
21:04:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:55 DISPATCHER: Finished worker discovery
21:05:55 DISPATCHER: Starting worker discovery
21:05:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:55 DISPATCHER: Finished worker discovery
21:06:04 WORKER: done with job (8, 0, 17), trying to register it.
21:06:04 WORKER: registered result for job (8, 0, 17) with dispatcher
21:06:04 DISPATCHER: job (8, 0, 17) finished
21:06:04 DISPATCHER: register_result: lock acquired
21:06:04 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:06:04 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9365149446814087, 'info': {'number_mnist': 0.9365149446814087, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}"}}
exception: None

21:06:04 job_callback for (8, 0, 17) started
21:06:04 job_callback for (8, 0, 17) got condition
21:06:04 DISPATCHER: Trying to submit another job.
21:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:06:04 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.958936





21:06:04 HBMASTER: Trying to run another job!
21:06:04 job_callback for (8, 0, 17) finished
21:06:04 HBMASTER: schedule new run for iteration 8
21:06:04 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
21:06:04 HBMASTER: submitting job (8, 0, 19) to dispatcher
21:06:04 DISPATCHER: trying to submit job (8, 0, 19)
21:06:04 DISPATCHER: trying to notify the job_runner thread.
21:06:04 HBMASTER: job (8, 0, 19) submitted to dispatcher
21:06:04 DISPATCHER: Trying to submit another job.
21:06:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:06:04 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:06:04 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:06:04 WORKER: start processing job (8, 0, 19)
21:06:04 WORKER: args: ()
21:06:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.08023740685158857, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.015618947968904385, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:06:55 DISPATCHER: Starting worker discovery
21:06:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:55 DISPATCHER: Finished worker discovery
21:07:55 DISPATCHER: Starting worker discovery
21:07:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:55 DISPATCHER: Finished worker discovery
21:08:29 WORKER: done with job (8, 0, 19), trying to register it.
21:08:29 WORKER: registered result for job (8, 0, 19) with dispatcher
21:08:29 DISPATCHER: job (8, 0, 19) finished
21:08:29 DISPATCHER: register_result: lock acquired
21:08:29 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:08:29 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.08023740685158857, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.015618947968904385, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8640596730908788, 'info': {'number_mnist': 0.8640596730908788, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.08023740685158857, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.015618947968904385, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 81}"}}
exception: None

21:08:29 job_callback for (8, 0, 19) started
21:08:29 job_callback for (8, 0, 19) got condition
21:08:29 DISPATCHER: Trying to submit another job.
21:08:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:08:29 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.958936





21:08:29 HBMASTER: Trying to run another job!
21:08:29 job_callback for (8, 0, 19) finished
21:08:29 HBMASTER: schedule new run for iteration 8
21:08:29 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
21:08:29 HBMASTER: submitting job (8, 0, 20) to dispatcher
21:08:29 DISPATCHER: trying to submit job (8, 0, 20)
21:08:29 DISPATCHER: trying to notify the job_runner thread.
21:08:29 HBMASTER: job (8, 0, 20) submitted to dispatcher
21:08:29 DISPATCHER: Trying to submit another job.
21:08:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:08:29 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:08:29 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:08:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:08:29 WORKER: start processing job (8, 0, 20)
21:08:29 WORKER: args: ()
21:08:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00597429318259451, 'num_filters_1': 100, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.018283825950154986, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 68, 'num_filters_3': 63, 'num_filters_4': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:08:55 DISPATCHER: Starting worker discovery
21:08:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:55 DISPATCHER: Finished worker discovery
21:09:55 DISPATCHER: Starting worker discovery
21:09:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:55 DISPATCHER: Finished worker discovery
21:10:54 WORKER: done with job (8, 0, 20), trying to register it.
21:10:54 WORKER: registered result for job (8, 0, 20) with dispatcher
21:10:54 DISPATCHER: job (8, 0, 20) finished
21:10:54 DISPATCHER: register_result: lock acquired
21:10:54 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:10:54 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00597429318259451, 'num_filters_1': 100, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.018283825950154986, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 68, 'num_filters_3': 63, 'num_filters_4': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8787790182064636, 'info': {'number_mnist': 0.8787790182064636, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00597429318259451, 'num_filters_1': 100, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.018283825950154986, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 68, 'num_filters_3': 63, 'num_filters_4': 32}"}}
exception: None

21:10:54 job_callback for (8, 0, 20) started
21:10:54 DISPATCHER: Trying to submit another job.
21:10:54 job_callback for (8, 0, 20) got condition
21:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:10:54 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.958936





21:10:54 HBMASTER: Trying to run another job!
21:10:54 job_callback for (8, 0, 20) finished
21:10:54 HBMASTER: schedule new run for iteration 8
21:10:54 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
21:10:54 HBMASTER: submitting job (8, 0, 21) to dispatcher
21:10:54 DISPATCHER: trying to submit job (8, 0, 21)
21:10:54 DISPATCHER: trying to notify the job_runner thread.
21:10:54 HBMASTER: job (8, 0, 21) submitted to dispatcher
21:10:54 DISPATCHER: Trying to submit another job.
21:10:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:10:54 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:10:54 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:10:54 WORKER: start processing job (8, 0, 21)
21:10:54 WORKER: args: ()
21:10:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008709726690474776, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01276326062850064, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 50, 'num_filters_4': 29, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:10:55 DISPATCHER: Starting worker discovery
21:10:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:55 DISPATCHER: Finished worker discovery
21:11:55 DISPATCHER: Starting worker discovery
21:11:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:55 DISPATCHER: Finished worker discovery
21:12:55 DISPATCHER: Starting worker discovery
21:12:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:55 DISPATCHER: Finished worker discovery
21:13:18 WORKER: done with job (8, 0, 21), trying to register it.
21:13:18 WORKER: registered result for job (8, 0, 21) with dispatcher
21:13:18 DISPATCHER: job (8, 0, 21) finished
21:13:18 DISPATCHER: register_result: lock acquired
21:13:18 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:13:18 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008709726690474776, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01276326062850064, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 50, 'num_filters_4': 29, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9031525632478714, 'info': {'number_mnist': 0.9031525632478714, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.008709726690474776, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01276326062850064, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 50, 'num_filters_4': 29, 'num_filters_5': 20}"}}
exception: None

21:13:18 job_callback for (8, 0, 21) started
21:13:18 DISPATCHER: Trying to submit another job.
21:13:18 job_callback for (8, 0, 21) got condition
21:13:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:13:18 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.958936





21:13:18 HBMASTER: Trying to run another job!
21:13:18 job_callback for (8, 0, 21) finished
21:13:18 HBMASTER: schedule new run for iteration 8
21:13:18 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
21:13:18 HBMASTER: submitting job (8, 0, 22) to dispatcher
21:13:18 DISPATCHER: trying to submit job (8, 0, 22)
21:13:18 DISPATCHER: trying to notify the job_runner thread.
21:13:18 HBMASTER: job (8, 0, 22) submitted to dispatcher
21:13:18 DISPATCHER: Trying to submit another job.
21:13:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:13:18 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:13:18 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:13:18 WORKER: start processing job (8, 0, 22)
21:13:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:13:18 WORKER: args: ()
21:13:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018809564924835663, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.017785933640118306}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:13:55 DISPATCHER: Starting worker discovery
21:13:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:55 DISPATCHER: Finished worker discovery
21:14:55 DISPATCHER: Starting worker discovery
21:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:55 DISPATCHER: Finished worker discovery
21:15:44 WORKER: done with job (8, 0, 22), trying to register it.
21:15:44 WORKER: registered result for job (8, 0, 22) with dispatcher
21:15:44 DISPATCHER: job (8, 0, 22) finished
21:15:44 DISPATCHER: register_result: lock acquired
21:15:44 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:15:44 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018809564924835663, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.017785933640118306}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9042081580396417, 'info': {'number_mnist': 0.9042081580396417, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018809564924835663, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.017785933640118306}"}}
exception: None

21:15:44 job_callback for (8, 0, 22) started
21:15:44 job_callback for (8, 0, 22) got condition
21:15:44 DISPATCHER: Trying to submit another job.
21:15:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:15:44 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.958936





21:15:44 HBMASTER: Trying to run another job!
21:15:44 job_callback for (8, 0, 22) finished
21:15:44 ITERATION: Advancing config (8, 0, 6) to next budget 400.000000
21:15:44 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
21:15:44 ITERATION: Advancing config (8, 0, 17) to next budget 400.000000
21:15:44 HBMASTER: schedule new run for iteration 8
21:15:44 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
21:15:44 HBMASTER: submitting job (8, 0, 6) to dispatcher
21:15:44 DISPATCHER: trying to submit job (8, 0, 6)
21:15:44 DISPATCHER: trying to notify the job_runner thread.
21:15:44 HBMASTER: job (8, 0, 6) submitted to dispatcher
21:15:44 DISPATCHER: Trying to submit another job.
21:15:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:15:44 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:15:44 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:15:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:15:44 WORKER: start processing job (8, 0, 6)
21:15:44 WORKER: args: ()
21:15:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}, 'budget': 400.0, 'working_directory': '.'}
21:15:55 DISPATCHER: Starting worker discovery
21:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:55 DISPATCHER: Finished worker discovery
21:16:55 DISPATCHER: Starting worker discovery
21:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:55 DISPATCHER: Finished worker discovery
21:17:55 DISPATCHER: Starting worker discovery
21:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:55 DISPATCHER: Finished worker discovery
21:18:55 DISPATCHER: Starting worker discovery
21:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:55 DISPATCHER: Finished worker discovery
21:19:55 DISPATCHER: Starting worker discovery
21:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:55 DISPATCHER: Finished worker discovery
21:20:55 DISPATCHER: Starting worker discovery
21:20:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:55 DISPATCHER: Finished worker discovery
21:21:55 DISPATCHER: Starting worker discovery
21:21:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:55 DISPATCHER: Finished worker discovery
21:22:47 WORKER: done with job (8, 0, 6), trying to register it.
21:22:47 WORKER: registered result for job (8, 0, 6) with dispatcher
21:22:47 DISPATCHER: job (8, 0, 6) finished
21:22:47 DISPATCHER: register_result: lock acquired
21:22:47 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:22:47 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9169905658402202, 'info': {'number_mnist': 0.9169905658402202, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04432847893166148, 'num_filters_1': 86, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010294734673873526}"}}
exception: None

21:22:47 job_callback for (8, 0, 6) started
21:22:47 DISPATCHER: Trying to submit another job.
21:22:47 job_callback for (8, 0, 6) got condition
21:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:22:47 HBMASTER: Trying to run another job!
21:22:47 job_callback for (8, 0, 6) finished
21:22:47 HBMASTER: schedule new run for iteration 8
21:22:47 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
21:22:47 HBMASTER: submitting job (8, 0, 8) to dispatcher
21:22:47 DISPATCHER: trying to submit job (8, 0, 8)
21:22:47 DISPATCHER: trying to notify the job_runner thread.
21:22:47 HBMASTER: job (8, 0, 8) submitted to dispatcher
21:22:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:22:47 DISPATCHER: Trying to submit another job.
21:22:47 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:22:47 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:22:47 WORKER: start processing job (8, 0, 8)
21:22:47 WORKER: args: ()
21:22:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 400.0, 'working_directory': '.'}
21:22:55 DISPATCHER: Starting worker discovery
21:22:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:55 DISPATCHER: Finished worker discovery
21:23:55 DISPATCHER: Starting worker discovery
21:23:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:55 DISPATCHER: Finished worker discovery
21:24:55 DISPATCHER: Starting worker discovery
21:24:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:55 DISPATCHER: Finished worker discovery
21:25:55 DISPATCHER: Starting worker discovery
21:25:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:55 DISPATCHER: Finished worker discovery
21:26:55 DISPATCHER: Starting worker discovery
21:26:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:55 DISPATCHER: Finished worker discovery
21:27:55 DISPATCHER: Starting worker discovery
21:27:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:55 DISPATCHER: Finished worker discovery
21:28:55 DISPATCHER: Starting worker discovery
21:28:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:55 DISPATCHER: Finished worker discovery
21:29:42 WORKER: done with job (8, 0, 8), trying to register it.
21:29:42 WORKER: registered result for job (8, 0, 8) with dispatcher
21:29:42 DISPATCHER: job (8, 0, 8) finished
21:29:42 DISPATCHER: register_result: lock acquired
21:29:42 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:29:42 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9515819242256114, 'info': {'number_mnist': 0.9515819242256114, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}"}}
exception: None

21:29:42 job_callback for (8, 0, 8) started
21:29:42 DISPATCHER: Trying to submit another job.
21:29:42 job_callback for (8, 0, 8) got condition
21:29:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:29:42 HBMASTER: Trying to run another job!
21:29:42 job_callback for (8, 0, 8) finished
21:29:42 HBMASTER: schedule new run for iteration 8
21:29:42 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
21:29:42 HBMASTER: submitting job (8, 0, 17) to dispatcher
21:29:42 DISPATCHER: trying to submit job (8, 0, 17)
21:29:42 DISPATCHER: trying to notify the job_runner thread.
21:29:42 HBMASTER: job (8, 0, 17) submitted to dispatcher
21:29:42 DISPATCHER: Trying to submit another job.
21:29:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:29:42 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:29:42 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:29:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:29:42 WORKER: start processing job (8, 0, 17)
21:29:42 WORKER: args: ()
21:29:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}, 'budget': 400.0, 'working_directory': '.'}
21:29:55 DISPATCHER: Starting worker discovery
21:29:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:55 DISPATCHER: Finished worker discovery
21:30:55 DISPATCHER: Starting worker discovery
21:30:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:55 DISPATCHER: Finished worker discovery
21:31:55 DISPATCHER: Starting worker discovery
21:31:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:55 DISPATCHER: Finished worker discovery
21:32:55 DISPATCHER: Starting worker discovery
21:32:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:55 DISPATCHER: Finished worker discovery
21:33:55 DISPATCHER: Starting worker discovery
21:33:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:55 DISPATCHER: Finished worker discovery
21:34:55 DISPATCHER: Starting worker discovery
21:34:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:55 DISPATCHER: Finished worker discovery
21:35:55 DISPATCHER: Starting worker discovery
21:35:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:55 DISPATCHER: Finished worker discovery
21:36:36 WORKER: done with job (8, 0, 17), trying to register it.
21:36:36 WORKER: registered result for job (8, 0, 17) with dispatcher
21:36:36 DISPATCHER: job (8, 0, 17) finished
21:36:36 DISPATCHER: register_result: lock acquired
21:36:36 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:36:36 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9284041989634156, 'info': {'number_mnist': 0.9284041989634156, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001927924898128598, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01968002253916287, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 25}"}}
exception: None

21:36:36 job_callback for (8, 0, 17) started
21:36:36 DISPATCHER: Trying to submit another job.
21:36:36 job_callback for (8, 0, 17) got condition
21:36:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:36:36 HBMASTER: Trying to run another job!
21:36:36 job_callback for (8, 0, 17) finished
21:36:36 ITERATION: Advancing config (8, 0, 8) to next budget 1200.000000
21:36:36 HBMASTER: schedule new run for iteration 8
21:36:36 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
21:36:36 HBMASTER: submitting job (8, 0, 8) to dispatcher
21:36:36 DISPATCHER: trying to submit job (8, 0, 8)
21:36:36 DISPATCHER: trying to notify the job_runner thread.
21:36:36 HBMASTER: job (8, 0, 8) submitted to dispatcher
21:36:36 DISPATCHER: Trying to submit another job.
21:36:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:36:36 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:36:36 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:36:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:36:36 WORKER: start processing job (8, 0, 8)
21:36:36 WORKER: args: ()
21:36:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 1200.0, 'working_directory': '.'}
21:36:55 DISPATCHER: Starting worker discovery
21:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:55 DISPATCHER: Finished worker discovery
21:37:55 DISPATCHER: Starting worker discovery
21:37:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:55 DISPATCHER: Finished worker discovery
21:38:55 DISPATCHER: Starting worker discovery
21:38:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:55 DISPATCHER: Finished worker discovery
21:39:55 DISPATCHER: Starting worker discovery
21:39:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:55 DISPATCHER: Finished worker discovery
21:40:55 DISPATCHER: Starting worker discovery
21:40:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:55 DISPATCHER: Finished worker discovery
21:41:55 DISPATCHER: Starting worker discovery
21:41:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:55 DISPATCHER: Finished worker discovery
21:42:55 DISPATCHER: Starting worker discovery
21:42:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:55 DISPATCHER: Finished worker discovery
21:43:55 DISPATCHER: Starting worker discovery
21:43:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:55 DISPATCHER: Finished worker discovery
21:44:55 DISPATCHER: Starting worker discovery
21:44:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:55 DISPATCHER: Finished worker discovery
21:45:55 DISPATCHER: Starting worker discovery
21:45:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:55 DISPATCHER: Finished worker discovery
21:46:55 DISPATCHER: Starting worker discovery
21:46:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:55 DISPATCHER: Finished worker discovery
21:47:55 DISPATCHER: Starting worker discovery
21:47:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:55 DISPATCHER: Finished worker discovery
21:48:55 DISPATCHER: Starting worker discovery
21:48:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:55 DISPATCHER: Finished worker discovery
21:49:55 DISPATCHER: Starting worker discovery
21:49:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:55 DISPATCHER: Finished worker discovery
21:50:55 DISPATCHER: Starting worker discovery
21:50:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:55 DISPATCHER: Finished worker discovery
21:51:55 DISPATCHER: Starting worker discovery
21:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:55 DISPATCHER: Finished worker discovery
21:52:55 DISPATCHER: Starting worker discovery
21:52:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:55 DISPATCHER: Finished worker discovery
21:53:55 DISPATCHER: Starting worker discovery
21:53:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:55 DISPATCHER: Finished worker discovery
21:54:55 DISPATCHER: Starting worker discovery
21:54:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:55 DISPATCHER: Finished worker discovery
21:55:55 DISPATCHER: Starting worker discovery
21:55:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:55 DISPATCHER: Finished worker discovery
21:56:55 DISPATCHER: Starting worker discovery
21:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:56 DISPATCHER: Finished worker discovery
21:57:04 WORKER: done with job (8, 0, 8), trying to register it.
21:57:04 WORKER: registered result for job (8, 0, 8) with dispatcher
21:57:04 DISPATCHER: job (8, 0, 8) finished
21:57:04 DISPATCHER: register_result: lock acquired
21:57:04 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:57:04 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9502920906273501, 'info': {'number_mnist': 0.9502920906273501, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014759568270277862, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.012891862064515517, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 60, 'num_filters_4': 21, 'num_filters_5': 117}"}}
exception: None

21:57:04 job_callback for (8, 0, 8) started
21:57:04 job_callback for (8, 0, 8) got condition
21:57:04 DISPATCHER: Trying to submit another job.
21:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:04 HBMASTER: Trying to run another job!
21:57:04 job_callback for (8, 0, 8) finished
21:57:04 start sampling a new configuration.
21:57:04 best_vector: [0, 2, 0.17760816446060246, 0.5687665253445041, 0.29739007900763936, 0, 0.08253083482335133, 0.3302115508467782, 0, 0, 2, 2, 0.9456755946806372, 0.8249509542204155, 0.09562944715060914, 0.031782746588866484], 8.970136171623777e-05, 0.0011975585274857066, 1.0742263065036045e-07
21:57:04 done sampling a new configuration.
21:57:04 HBMASTER: schedule new run for iteration 9
21:57:04 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
21:57:04 HBMASTER: submitting job (9, 0, 0) to dispatcher
21:57:04 DISPATCHER: trying to submit job (9, 0, 0)
21:57:04 DISPATCHER: trying to notify the job_runner thread.
21:57:04 HBMASTER: job (9, 0, 0) submitted to dispatcher
21:57:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:04 DISPATCHER: Trying to submit another job.
21:57:04 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:57:04 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:04 WORKER: start processing job (9, 0, 0)
21:57:04 WORKER: args: ()
21:57:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00226577264358653, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.02689150649220567, 'kernel_size_2': 3, 'num_filters_2': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:57:56 DISPATCHER: Starting worker discovery
21:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:56 DISPATCHER: Finished worker discovery
21:58:56 DISPATCHER: Starting worker discovery
21:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:56 DISPATCHER: Finished worker discovery
21:59:40 WORKER: done with job (9, 0, 0), trying to register it.
21:59:40 WORKER: registered result for job (9, 0, 0) with dispatcher
21:59:40 DISPATCHER: job (9, 0, 0) finished
21:59:40 DISPATCHER: register_result: lock acquired
21:59:40 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:59:40 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00226577264358653, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.02689150649220567, 'kernel_size_2': 3, 'num_filters_2': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7813001200846074, 'info': {'number_mnist': 0.7813001200846074, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00226577264358653, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.02689150649220567, 'kernel_size_2': 3, 'num_filters_2': 115}"}}
exception: None

21:59:40 job_callback for (9, 0, 0) started
21:59:40 DISPATCHER: Trying to submit another job.
21:59:40 job_callback for (9, 0, 0) got condition
21:59:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:59:40 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.958936





21:59:40 HBMASTER: Trying to run another job!
21:59:40 job_callback for (9, 0, 0) finished
21:59:40 start sampling a new configuration.
21:59:40 best_vector: [2, 1, 0.5916276269405765, 0.7109068733079134, 0.8731179634854368, 0, 0.1889405172106885, 0.0729195232965881, 0, 1, 2, 2, 0.07898002980245522, 0.6023924119241275, 0.03019827062335334, 0.7703543099088761], 0.0, inf, 1.294668607165798e-06
21:59:40 done sampling a new configuration.
21:59:40 HBMASTER: schedule new run for iteration 9
21:59:40 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
21:59:40 HBMASTER: submitting job (9, 0, 1) to dispatcher
21:59:40 DISPATCHER: trying to submit job (9, 0, 1)
21:59:40 DISPATCHER: trying to notify the job_runner thread.
21:59:40 HBMASTER: job (9, 0, 1) submitted to dispatcher
21:59:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:59:40 DISPATCHER: Trying to submit another job.
21:59:40 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:59:40 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:59:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:59:40 WORKER: start processing job (9, 0, 1)
21:59:40 WORKER: args: ()
21:59:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015249487696143448, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.012441435347735012, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 17, 'num_filters_5': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:59:56 DISPATCHER: Starting worker discovery
21:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:56 DISPATCHER: Finished worker discovery
22:00:56 DISPATCHER: Starting worker discovery
22:00:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:56 DISPATCHER: Finished worker discovery
22:01:56 DISPATCHER: Starting worker discovery
22:01:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:56 DISPATCHER: Finished worker discovery
22:02:05 WORKER: done with job (9, 0, 1), trying to register it.
22:02:05 WORKER: registered result for job (9, 0, 1) with dispatcher
22:02:05 DISPATCHER: job (9, 0, 1) finished
22:02:05 DISPATCHER: register_result: lock acquired
22:02:05 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:02:05 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015249487696143448, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.012441435347735012, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 17, 'num_filters_5': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015249487696143448, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.012441435347735012, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 17, 'num_filters_5': 79}"}}
exception: None

22:02:05 job_callback for (9, 0, 1) started
22:02:05 job_callback for (9, 0, 1) got condition
22:02:05 DISPATCHER: Trying to submit another job.
22:02:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:05 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.958936





22:02:05 HBMASTER: Trying to run another job!
22:02:05 job_callback for (9, 0, 1) finished
22:02:05 start sampling a new configuration.
22:02:06 best_vector: [0, 1, 0.06736140753019754, 0.6540701077656516, 0.27009602875260064, 0, 0.9925105096983671, 0.0643606451478759, 0, 0, 2, 0, 0.10445751581982018, 0.933178943430766, 0.25528838598342707, 0.4574991751155204], 0.0006562833965733906, 0.0010817083872725285, 7.099072545011396e-07
22:02:06 done sampling a new configuration.
22:02:06 HBMASTER: schedule new run for iteration 9
22:02:06 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
22:02:06 HBMASTER: submitting job (9, 0, 2) to dispatcher
22:02:06 DISPATCHER: trying to submit job (9, 0, 2)
22:02:06 DISPATCHER: trying to notify the job_runner thread.
22:02:06 HBMASTER: job (9, 0, 2) submitted to dispatcher
22:02:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:02:06 DISPATCHER: Trying to submit another job.
22:02:06 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:02:06 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:02:06 WORKER: start processing job (9, 0, 2)
22:02:06 WORKER: args: ()
22:02:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001363712480315778, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.012126490472190353, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:02:56 DISPATCHER: Starting worker discovery
22:02:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:56 DISPATCHER: Finished worker discovery
22:03:56 DISPATCHER: Starting worker discovery
22:03:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:56 DISPATCHER: Finished worker discovery
22:04:30 WORKER: done with job (9, 0, 2), trying to register it.
22:04:30 WORKER: registered result for job (9, 0, 2) with dispatcher
22:04:30 DISPATCHER: job (9, 0, 2) finished
22:04:30 DISPATCHER: register_result: lock acquired
22:04:30 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:04:30 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001363712480315778, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.012126490472190353, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9190623920217433, 'info': {'number_mnist': 0.9190623920217433, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001363712480315778, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.012126490472190353, 'kernel_size_2': 3, 'num_filters_2': 19}"}}
exception: None

22:04:30 job_callback for (9, 0, 2) started
22:04:30 DISPATCHER: Trying to submit another job.
22:04:30 job_callback for (9, 0, 2) got condition
22:04:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:30 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.958936





22:04:30 HBMASTER: Trying to run another job!
22:04:30 job_callback for (9, 0, 2) finished
22:04:30 start sampling a new configuration.
22:04:30 done sampling a new configuration.
22:04:30 HBMASTER: schedule new run for iteration 9
22:04:30 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
22:04:30 HBMASTER: submitting job (9, 0, 3) to dispatcher
22:04:30 DISPATCHER: trying to submit job (9, 0, 3)
22:04:30 DISPATCHER: trying to notify the job_runner thread.
22:04:30 HBMASTER: job (9, 0, 3) submitted to dispatcher
22:04:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:30 DISPATCHER: Trying to submit another job.
22:04:30 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:04:30 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:04:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:30 WORKER: start processing job (9, 0, 3)
22:04:30 WORKER: args: ()
22:04:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006829298018232003, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.032515841700097026, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 77, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:04:56 DISPATCHER: Starting worker discovery
22:04:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:56 DISPATCHER: Finished worker discovery
22:05:56 DISPATCHER: Starting worker discovery
22:05:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:56 DISPATCHER: Finished worker discovery
22:06:56 WORKER: done with job (9, 0, 3), trying to register it.
22:06:56 WORKER: registered result for job (9, 0, 3) with dispatcher
22:06:56 DISPATCHER: job (9, 0, 3) finished
22:06:56 DISPATCHER: register_result: lock acquired
22:06:56 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:06:56 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006829298018232003, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.032515841700097026, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 77, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5117341519971237, 'info': {'number_mnist': 0.5117341519971237, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006829298018232003, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.032515841700097026, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 77, 'num_filters_3': 19}"}}
exception: None

22:06:56 job_callback for (9, 0, 3) started
22:06:56 DISPATCHER: Trying to submit another job.
22:06:56 job_callback for (9, 0, 3) got condition
22:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:06:56 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.958936





22:06:56 HBMASTER: Trying to run another job!
22:06:56 job_callback for (9, 0, 3) finished
22:06:56 start sampling a new configuration.
22:06:56 best_vector: [0, 2, 0.16352175520395412, 0.10672702748325033, 0.3968688178584465, 1, 0.9809789102993287, 0.05605559047333972, 1, 0, 2, 2, 0.168751616782289, 0.1299270908605576, 0.7828782803106049, 0.5251178223050026], 2.6873860453790436e-30, 0.003721088013088029, -2.955280541938429e-07
22:06:56 done sampling a new configuration.
22:06:56 HBMASTER: schedule new run for iteration 9
22:06:56 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
22:06:56 HBMASTER: submitting job (9, 0, 4) to dispatcher
22:06:56 DISPATCHER: trying to submit job (9, 0, 4)
22:06:56 DISPATCHER: trying to notify the job_runner thread.
22:06:56 HBMASTER: job (9, 0, 4) submitted to dispatcher
22:06:56 DISPATCHER: Trying to submit another job.
22:06:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:06:56 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:06:56 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:06:56 WORKER: start processing job (9, 0, 4)
22:06:56 WORKER: args: ()
22:06:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002123457192910713, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011828508999337135, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:06:56 DISPATCHER: Starting worker discovery
22:06:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:56 DISPATCHER: Finished worker discovery
22:07:56 DISPATCHER: Starting worker discovery
22:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:56 DISPATCHER: Finished worker discovery
22:08:56 DISPATCHER: Starting worker discovery
22:08:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:56 DISPATCHER: Finished worker discovery
22:09:20 WORKER: done with job (9, 0, 4), trying to register it.
22:09:20 WORKER: registered result for job (9, 0, 4) with dispatcher
22:09:20 DISPATCHER: job (9, 0, 4) finished
22:09:20 DISPATCHER: register_result: lock acquired
22:09:20 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:09:20 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002123457192910713, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011828508999337135, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8611040210061461, 'info': {'number_mnist': 0.8611040210061461, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002123457192910713, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011828508999337135, 'kernel_size_2': 5, 'num_filters_2': 22}"}}
exception: None

22:09:20 job_callback for (9, 0, 4) started
22:09:20 job_callback for (9, 0, 4) got condition
22:09:20 DISPATCHER: Trying to submit another job.
22:09:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:09:20 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.958936





22:09:20 HBMASTER: Trying to run another job!
22:09:20 job_callback for (9, 0, 4) finished
22:09:20 start sampling a new configuration.
22:09:20 done sampling a new configuration.
22:09:20 HBMASTER: schedule new run for iteration 9
22:09:20 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
22:09:20 HBMASTER: submitting job (9, 0, 5) to dispatcher
22:09:20 DISPATCHER: trying to submit job (9, 0, 5)
22:09:20 DISPATCHER: trying to notify the job_runner thread.
22:09:20 HBMASTER: job (9, 0, 5) submitted to dispatcher
22:09:20 DISPATCHER: Trying to submit another job.
22:09:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:09:20 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:09:20 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:09:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:09:20 WORKER: start processing job (9, 0, 5)
22:09:20 WORKER: args: ()
22:09:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05989092788826279, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.03210694205188988, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 63, 'num_filters_4': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:09:56 DISPATCHER: Starting worker discovery
22:09:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:56 DISPATCHER: Finished worker discovery
22:10:56 DISPATCHER: Starting worker discovery
22:10:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:56 DISPATCHER: Finished worker discovery
22:11:45 WORKER: done with job (9, 0, 5), trying to register it.
22:11:45 WORKER: registered result for job (9, 0, 5) with dispatcher
22:11:45 DISPATCHER: job (9, 0, 5) finished
22:11:45 DISPATCHER: register_result: lock acquired
22:11:45 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:11:45 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05989092788826279, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.03210694205188988, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 63, 'num_filters_4': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05989092788826279, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.03210694205188988, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 36, 'num_filters_3': 63, 'num_filters_4': 30}"}}
exception: None

22:11:45 job_callback for (9, 0, 5) started
22:11:45 job_callback for (9, 0, 5) got condition
22:11:45 DISPATCHER: Trying to submit another job.
22:11:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:45 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.958936





22:11:45 HBMASTER: Trying to run another job!
22:11:45 job_callback for (9, 0, 5) finished
22:11:45 start sampling a new configuration.
22:11:45 best_vector: [2, 0, 0.18615252085755074, 0.8265325345078521, 0.6159604612554437, 0, 0.4650954035494108, 0.04128847553311063, 0, 0, 2, 0, 0.7115685449252415, 0.4665703580978272, 0.06254084422670664, 0.9239129689860525], 0.0020226953907823446, 0.02013070625342215, 4.07182867519903e-05
22:11:45 done sampling a new configuration.
22:11:45 HBMASTER: schedule new run for iteration 9
22:11:45 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
22:11:45 HBMASTER: submitting job (9, 0, 6) to dispatcher
22:11:45 DISPATCHER: trying to submit job (9, 0, 6)
22:11:45 DISPATCHER: trying to notify the job_runner thread.
22:11:45 HBMASTER: job (9, 0, 6) submitted to dispatcher
22:11:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:45 DISPATCHER: Trying to submit another job.
22:11:45 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:11:45 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:11:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:45 WORKER: start processing job (9, 0, 6)
22:11:45 WORKER: args: ()
22:11:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:11:56 DISPATCHER: Starting worker discovery
22:11:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:56 DISPATCHER: Finished worker discovery
22:12:56 DISPATCHER: Starting worker discovery
22:12:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:56 DISPATCHER: Finished worker discovery
22:13:56 DISPATCHER: Starting worker discovery
22:13:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:56 DISPATCHER: Finished worker discovery
22:14:10 WORKER: done with job (9, 0, 6), trying to register it.
22:14:10 WORKER: registered result for job (9, 0, 6) with dispatcher
22:14:10 DISPATCHER: job (9, 0, 6) finished
22:14:10 DISPATCHER: register_result: lock acquired
22:14:10 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:14:10 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9392713981636542, 'info': {'number_mnist': 0.9392713981636542, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}"}}
exception: None

22:14:10 job_callback for (9, 0, 6) started
22:14:10 DISPATCHER: Trying to submit another job.
22:14:10 job_callback for (9, 0, 6) got condition
22:14:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:14:10 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.958936





22:14:10 HBMASTER: Trying to run another job!
22:14:10 job_callback for (9, 0, 6) finished
22:14:10 start sampling a new configuration.
22:14:10 best_vector: [0, 2, 0.17007481394561524, 0.8910798543335875, 0.004868737064865417, 0, 0.7670716165894701, 0.05231787998465956, 2, 0, 2, 1, 0.7693334233345728, 0.652693777541287, 0.028325653253461203, 0.9079079250167723], 2.7579665267682083e-05, 0.0783456383870847, 2.1607464818986603e-06
22:14:10 done sampling a new configuration.
22:14:10 HBMASTER: schedule new run for iteration 9
22:14:10 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
22:14:10 HBMASTER: submitting job (9, 0, 7) to dispatcher
22:14:10 DISPATCHER: trying to submit job (9, 0, 7)
22:14:10 DISPATCHER: trying to notify the job_runner thread.
22:14:10 HBMASTER: job (9, 0, 7) submitted to dispatcher
22:14:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:14:10 DISPATCHER: Trying to submit another job.
22:14:10 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:14:10 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:14:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:14:10 WORKER: start processing job (9, 0, 7)
22:14:10 WORKER: args: ()
22:14:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00218851550540455, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.011696801806300979}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:14:56 DISPATCHER: Starting worker discovery
22:14:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:56 DISPATCHER: Finished worker discovery
22:15:56 DISPATCHER: Starting worker discovery
22:15:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:56 DISPATCHER: Finished worker discovery
22:16:35 WORKER: done with job (9, 0, 7), trying to register it.
22:16:35 WORKER: registered result for job (9, 0, 7) with dispatcher
22:16:35 DISPATCHER: job (9, 0, 7) finished
22:16:35 DISPATCHER: register_result: lock acquired
22:16:35 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:16:35 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00218851550540455, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.011696801806300979}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9201008330942235, 'info': {'number_mnist': 0.9201008330942235, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00218851550540455, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.011696801806300979}"}}
exception: None

22:16:35 job_callback for (9, 0, 7) started
22:16:35 job_callback for (9, 0, 7) got condition
22:16:35 DISPATCHER: Trying to submit another job.
22:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:36 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.958936





22:16:36 HBMASTER: Trying to run another job!
22:16:36 job_callback for (9, 0, 7) finished
22:16:36 start sampling a new configuration.
22:16:36 best_vector: [1, 0, 0.0006883427606568238, 0.848377150788618, 0.13006605078765143, 0, 0.8699311079593636, 0.09930967509162775, 1, 0, 2, 2, 0.6217661061046965, 0.748886079595315, 0.2435545814741535, 0.06127251352006949], 0.001130827166263116, 0.03135368850484014, 3.545560272382481e-05
22:16:36 done sampling a new configuration.
22:16:36 HBMASTER: schedule new run for iteration 9
22:16:36 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
22:16:36 HBMASTER: submitting job (9, 0, 8) to dispatcher
22:16:36 DISPATCHER: trying to submit job (9, 0, 8)
22:16:36 DISPATCHER: trying to notify the job_runner thread.
22:16:36 HBMASTER: job (9, 0, 8) submitted to dispatcher
22:16:36 DISPATCHER: Trying to submit another job.
22:16:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:36 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:16:36 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:16:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:36 WORKER: start processing job (9, 0, 8)
22:16:36 WORKER: args: ()
22:16:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010031749651178976, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013464953754249229}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:16:56 DISPATCHER: Starting worker discovery
22:16:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:56 DISPATCHER: Finished worker discovery
22:17:56 DISPATCHER: Starting worker discovery
22:17:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:56 DISPATCHER: Finished worker discovery
22:18:56 DISPATCHER: Starting worker discovery
22:18:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:56 DISPATCHER: Finished worker discovery
22:19:00 WORKER: done with job (9, 0, 8), trying to register it.
22:19:00 WORKER: registered result for job (9, 0, 8) with dispatcher
22:19:00 DISPATCHER: job (9, 0, 8) finished
22:19:00 DISPATCHER: register_result: lock acquired
22:19:00 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:19:00 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010031749651178976, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013464953754249229}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9373904116199682, 'info': {'number_mnist': 0.9373904116199682, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010031749651178976, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013464953754249229}"}}
exception: None

22:19:00 job_callback for (9, 0, 8) started
22:19:00 DISPATCHER: Trying to submit another job.
22:19:00 job_callback for (9, 0, 8) got condition
22:19:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:19:00 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.958936





22:19:00 HBMASTER: Trying to run another job!
22:19:00 job_callback for (9, 0, 8) finished
22:19:00 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
22:19:00 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
22:19:00 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
22:19:00 HBMASTER: schedule new run for iteration 9
22:19:00 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
22:19:00 HBMASTER: submitting job (9, 0, 6) to dispatcher
22:19:00 DISPATCHER: trying to submit job (9, 0, 6)
22:19:00 DISPATCHER: trying to notify the job_runner thread.
22:19:00 HBMASTER: job (9, 0, 6) submitted to dispatcher
22:19:00 DISPATCHER: Trying to submit another job.
22:19:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:19:00 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:19:00 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:19:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:19:00 WORKER: start processing job (9, 0, 6)
22:19:00 WORKER: args: ()
22:19:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}, 'budget': 400.0, 'working_directory': '.'}
22:19:56 DISPATCHER: Starting worker discovery
22:19:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:56 DISPATCHER: Finished worker discovery
22:20:56 DISPATCHER: Starting worker discovery
22:20:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:56 DISPATCHER: Finished worker discovery
22:21:56 DISPATCHER: Starting worker discovery
22:21:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:56 DISPATCHER: Finished worker discovery
22:22:56 DISPATCHER: Starting worker discovery
22:22:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:56 DISPATCHER: Finished worker discovery
22:23:56 DISPATCHER: Starting worker discovery
22:23:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:56 DISPATCHER: Finished worker discovery
22:24:56 DISPATCHER: Starting worker discovery
22:24:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:56 DISPATCHER: Finished worker discovery
22:25:55 WORKER: done with job (9, 0, 6), trying to register it.
22:25:55 WORKER: registered result for job (9, 0, 6) with dispatcher
22:25:55 DISPATCHER: job (9, 0, 6) finished
22:25:55 DISPATCHER: register_result: lock acquired
22:25:55 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:25:55 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9391106647507874, 'info': {'number_mnist': 0.9391106647507874, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}"}}
exception: None

22:25:55 job_callback for (9, 0, 6) started
22:25:55 DISPATCHER: Trying to submit another job.
22:25:55 job_callback for (9, 0, 6) got condition
22:25:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:25:55 HBMASTER: Trying to run another job!
22:25:55 job_callback for (9, 0, 6) finished
22:25:55 HBMASTER: schedule new run for iteration 9
22:25:55 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
22:25:55 HBMASTER: submitting job (9, 0, 7) to dispatcher
22:25:55 DISPATCHER: trying to submit job (9, 0, 7)
22:25:55 DISPATCHER: trying to notify the job_runner thread.
22:25:55 HBMASTER: job (9, 0, 7) submitted to dispatcher
22:25:55 DISPATCHER: Trying to submit another job.
22:25:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:55 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:25:55 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:25:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:55 WORKER: start processing job (9, 0, 7)
22:25:55 WORKER: args: ()
22:25:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00218851550540455, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.011696801806300979}, 'budget': 400.0, 'working_directory': '.'}
22:25:56 DISPATCHER: Starting worker discovery
22:25:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:56 DISPATCHER: Finished worker discovery
22:26:56 DISPATCHER: Starting worker discovery
22:26:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:56 DISPATCHER: Finished worker discovery
22:27:56 DISPATCHER: Starting worker discovery
22:27:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:56 DISPATCHER: Finished worker discovery
22:28:56 DISPATCHER: Starting worker discovery
22:28:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:56 DISPATCHER: Finished worker discovery
22:29:56 DISPATCHER: Starting worker discovery
22:29:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:56 DISPATCHER: Finished worker discovery
22:30:56 DISPATCHER: Starting worker discovery
22:30:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:56 DISPATCHER: Finished worker discovery
22:31:56 DISPATCHER: Starting worker discovery
22:31:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:56 DISPATCHER: Finished worker discovery
22:32:56 DISPATCHER: Starting worker discovery
22:32:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:56 DISPATCHER: Finished worker discovery
22:32:56 WORKER: done with job (9, 0, 7), trying to register it.
22:32:56 WORKER: registered result for job (9, 0, 7) with dispatcher
22:32:56 DISPATCHER: job (9, 0, 7) finished
22:32:56 DISPATCHER: register_result: lock acquired
22:32:56 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:32:56 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00218851550540455, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.011696801806300979}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9112169680565414, 'info': {'number_mnist': 0.9112169680565414, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00218851550540455, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.011696801806300979}"}}
exception: None

22:32:56 job_callback for (9, 0, 7) started
22:32:56 job_callback for (9, 0, 7) got condition
22:32:56 DISPATCHER: Trying to submit another job.
22:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:32:56 HBMASTER: Trying to run another job!
22:32:56 job_callback for (9, 0, 7) finished
22:32:56 HBMASTER: schedule new run for iteration 9
22:32:56 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
22:32:56 HBMASTER: submitting job (9, 0, 8) to dispatcher
22:32:56 DISPATCHER: trying to submit job (9, 0, 8)
22:32:56 DISPATCHER: trying to notify the job_runner thread.
22:32:56 HBMASTER: job (9, 0, 8) submitted to dispatcher
22:32:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:32:56 DISPATCHER: Trying to submit another job.
22:32:56 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:32:56 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:32:56 WORKER: start processing job (9, 0, 8)
22:32:56 WORKER: args: ()
22:32:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010031749651178976, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013464953754249229}, 'budget': 400.0, 'working_directory': '.'}
22:33:56 DISPATCHER: Starting worker discovery
22:33:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:56 DISPATCHER: Finished worker discovery
22:34:56 DISPATCHER: Starting worker discovery
22:34:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:56 DISPATCHER: Finished worker discovery
22:35:56 DISPATCHER: Starting worker discovery
22:35:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:56 DISPATCHER: Finished worker discovery
22:36:56 DISPATCHER: Starting worker discovery
22:36:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:56 DISPATCHER: Finished worker discovery
22:37:56 DISPATCHER: Starting worker discovery
22:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:56 DISPATCHER: Finished worker discovery
22:38:56 DISPATCHER: Starting worker discovery
22:38:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:56 DISPATCHER: Finished worker discovery
22:39:54 WORKER: done with job (9, 0, 8), trying to register it.
22:39:54 WORKER: registered result for job (9, 0, 8) with dispatcher
22:39:54 DISPATCHER: job (9, 0, 8) finished
22:39:54 DISPATCHER: register_result: lock acquired
22:39:54 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:39:54 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010031749651178976, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013464953754249229}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9278351306554263, 'info': {'number_mnist': 0.9278351306554263, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010031749651178976, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013464953754249229}"}}
exception: None

22:39:54 job_callback for (9, 0, 8) started
22:39:54 job_callback for (9, 0, 8) got condition
22:39:54 DISPATCHER: Trying to submit another job.
22:39:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:54 HBMASTER: Trying to run another job!
22:39:54 job_callback for (9, 0, 8) finished
22:39:54 ITERATION: Advancing config (9, 0, 6) to next budget 1200.000000
22:39:54 HBMASTER: schedule new run for iteration 9
22:39:54 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
22:39:54 HBMASTER: submitting job (9, 0, 6) to dispatcher
22:39:54 DISPATCHER: trying to submit job (9, 0, 6)
22:39:54 DISPATCHER: trying to notify the job_runner thread.
22:39:54 HBMASTER: job (9, 0, 6) submitted to dispatcher
22:39:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:54 DISPATCHER: Trying to submit another job.
22:39:54 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:39:54 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:39:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:54 WORKER: start processing job (9, 0, 6)
22:39:54 WORKER: args: ()
22:39:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}, 'budget': 1200.0, 'working_directory': '.'}
22:39:56 DISPATCHER: Starting worker discovery
22:39:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:56 DISPATCHER: Finished worker discovery
22:40:56 DISPATCHER: Starting worker discovery
22:40:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:56 DISPATCHER: Finished worker discovery
22:41:56 DISPATCHER: Starting worker discovery
22:41:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:56 DISPATCHER: Finished worker discovery
22:42:56 DISPATCHER: Starting worker discovery
22:42:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:56 DISPATCHER: Finished worker discovery
22:43:56 DISPATCHER: Starting worker discovery
22:43:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:56 DISPATCHER: Finished worker discovery
22:44:56 DISPATCHER: Starting worker discovery
22:44:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:56 DISPATCHER: Finished worker discovery
22:45:56 DISPATCHER: Starting worker discovery
22:45:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:56 DISPATCHER: Finished worker discovery
22:46:56 DISPATCHER: Starting worker discovery
22:46:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:56 DISPATCHER: Finished worker discovery
22:47:56 DISPATCHER: Starting worker discovery
22:47:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:56 DISPATCHER: Finished worker discovery
22:48:56 DISPATCHER: Starting worker discovery
22:48:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:56 DISPATCHER: Finished worker discovery
22:49:56 DISPATCHER: Starting worker discovery
22:49:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:56 DISPATCHER: Finished worker discovery
22:50:56 DISPATCHER: Starting worker discovery
22:50:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:56 DISPATCHER: Finished worker discovery
22:51:56 DISPATCHER: Starting worker discovery
22:51:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:56 DISPATCHER: Finished worker discovery
22:52:56 DISPATCHER: Starting worker discovery
22:52:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:56 DISPATCHER: Finished worker discovery
22:53:56 DISPATCHER: Starting worker discovery
22:53:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:56 DISPATCHER: Finished worker discovery
22:54:56 DISPATCHER: Starting worker discovery
22:54:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:56 DISPATCHER: Finished worker discovery
22:55:56 DISPATCHER: Starting worker discovery
22:55:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:56 DISPATCHER: Finished worker discovery
22:56:56 DISPATCHER: Starting worker discovery
22:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:56 DISPATCHER: Finished worker discovery
22:57:56 DISPATCHER: Starting worker discovery
22:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:56 DISPATCHER: Finished worker discovery
22:58:56 DISPATCHER: Starting worker discovery
22:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:56 DISPATCHER: Finished worker discovery
22:59:56 DISPATCHER: Starting worker discovery
22:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:56 DISPATCHER: Finished worker discovery
23:00:24 WORKER: done with job (9, 0, 6), trying to register it.
23:00:24 WORKER: registered result for job (9, 0, 6) with dispatcher
23:00:24 DISPATCHER: job (9, 0, 6) finished
23:00:24 DISPATCHER: register_result: lock acquired
23:00:24 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:00:24 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9478276788426169, 'info': {'number_mnist': 0.9478276788426169, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002356704015084474, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.011316641162751898, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 42, 'num_filters_4': 18}"}}
exception: None

23:00:24 job_callback for (9, 0, 6) started
23:00:24 DISPATCHER: Trying to submit another job.
23:00:24 job_callback for (9, 0, 6) got condition
23:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:24 HBMASTER: Trying to run another job!
23:00:24 job_callback for (9, 0, 6) finished
23:00:24 HBMASTER: shutdown initiated, shutdown_workers = True
23:00:24 WORKER: shutting down now!
23:00:24 DISPATCHER: Dispatcher shutting down
23:00:24 DISPATCHER: discover_workers shutting down
23:00:24 DISPATCHER: Trying to submit another job.
23:00:24 DISPATCHER: 'discover_worker' thread exited
23:00:24 DISPATCHER: job_runner shutting down
23:00:24 DISPATCHER: 'job_runner' thread exited
23:00:24 DISPATCHER: shut down complete
23:00:24 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f7d48156dd8; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:32463>
23:00:24 WORKER: No dispatcher found. Waiting for one to initiate contact.
23:00:24 WORKER: start listening for jobs
23:00:24 wait_for_workers trying to get the condition
23:00:24 DISPATCHER: started the 'discover_worker' thread
23:00:24 DISPATCHER: started the 'job_runner' thread
23:00:24 DISPATCHER: Pyro daemon running on localhost:41265
23:00:24 HBMASTER: only 0 worker(s) available, waiting for at least 1.
23:00:24 DISPATCHER: Starting worker discovery
23:00:24 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
23:00:24 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.29881140179544557376
23:00:24 HBMASTER: number of workers changed to 1
23:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:24 adjust_queue_size: lock accquired
23:00:24 HBMASTER: adjusted queue size to (0, 1)
23:00:24 DISPATCHER: Finished worker discovery
23:00:24 DISPATCHER: A new worker triggered discover_worker
23:00:24 DISPATCHER: Trying to submit another job.
23:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:24 Enough workers to start this run!
23:00:24 DISPATCHER: Starting worker discovery
23:00:24 HBMASTER: starting run at 1583877624.979882
23:00:24 start sampling a new configuration.
23:00:24 done sampling a new configuration.
23:00:24 HBMASTER: schedule new run for iteration 0
23:00:24 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
23:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:24 HBMASTER: submitting job (0, 0, 0) to dispatcher
23:00:24 DISPATCHER: trying to submit job (0, 0, 0)
23:00:24 DISPATCHER: Finished worker discovery
23:00:24 DISPATCHER: trying to notify the job_runner thread.
23:00:24 HBMASTER: job (0, 0, 0) submitted to dispatcher
23:00:24 DISPATCHER: Trying to submit another job.
23:00:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:24 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:00:24 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:24 WORKER: start processing job (0, 0, 0)
23:00:24 WORKER: args: ()
23:00:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.008949973957119986, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.016474472494806203}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:01:17 WORKER: done with job (0, 0, 0), trying to register it.
23:01:17 WORKER: registered result for job (0, 0, 0) with dispatcher
23:01:17 DISPATCHER: job (0, 0, 0) finished
23:01:17 DISPATCHER: register_result: lock acquired
23:01:17 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:01:17 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.008949973957119986, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.016474472494806203}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.008949973957119986, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.016474472494806203}"}}
exception: None

23:01:17 job_callback for (0, 0, 0) started
23:01:17 job_callback for (0, 0, 0) got condition
23:01:17 DISPATCHER: Trying to submit another job.
23:01:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:17 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:01:17 HBMASTER: Trying to run another job!
23:01:17 job_callback for (0, 0, 0) finished
23:01:17 start sampling a new configuration.
23:01:17 done sampling a new configuration.
23:01:17 HBMASTER: schedule new run for iteration 0
23:01:17 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
23:01:17 HBMASTER: submitting job (0, 0, 1) to dispatcher
23:01:17 DISPATCHER: trying to submit job (0, 0, 1)
23:01:17 DISPATCHER: trying to notify the job_runner thread.
23:01:17 HBMASTER: job (0, 0, 1) submitted to dispatcher
23:01:17 DISPATCHER: Trying to submit another job.
23:01:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:17 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:01:17 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:01:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:17 WORKER: start processing job (0, 0, 1)
23:01:17 WORKER: args: ()
23:01:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 70, 'last_n_outputs': 31, 'lr': 0.09340429847056232, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.09802432201356259}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:01:24 DISPATCHER: Starting worker discovery
23:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:02:10 WORKER: done with job (0, 0, 1), trying to register it.
23:02:10 WORKER: registered result for job (0, 0, 1) with dispatcher
23:02:10 DISPATCHER: job (0, 0, 1) finished
23:02:10 DISPATCHER: register_result: lock acquired
23:02:10 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:02:10 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 70, 'last_n_outputs': 31, 'lr': 0.09340429847056232, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.09802432201356259}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 70, 'last_n_outputs': 31, 'lr': 0.09340429847056232, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.09802432201356259}"}}
exception: None

23:02:10 job_callback for (0, 0, 1) started
23:02:10 DISPATCHER: Trying to submit another job.
23:02:10 job_callback for (0, 0, 1) got condition
23:02:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:10 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:02:10 HBMASTER: Trying to run another job!
23:02:10 job_callback for (0, 0, 1) finished
23:02:10 start sampling a new configuration.
23:02:10 done sampling a new configuration.
23:02:10 HBMASTER: schedule new run for iteration 0
23:02:10 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
23:02:10 HBMASTER: submitting job (0, 0, 2) to dispatcher
23:02:10 DISPATCHER: trying to submit job (0, 0, 2)
23:02:10 DISPATCHER: trying to notify the job_runner thread.
23:02:10 HBMASTER: job (0, 0, 2) submitted to dispatcher
23:02:10 DISPATCHER: Trying to submit another job.
23:02:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:10 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:02:10 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:02:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:10 WORKER: start processing job (0, 0, 2)
23:02:10 WORKER: args: ()
23:02:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 34, 'lr': 0.030305770989560055, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.1284617915456203}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:02:24 DISPATCHER: Starting worker discovery
23:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:25 DISPATCHER: Finished worker discovery
23:03:02 WORKER: done with job (0, 0, 2), trying to register it.
23:03:02 WORKER: registered result for job (0, 0, 2) with dispatcher
23:03:02 DISPATCHER: job (0, 0, 2) finished
23:03:02 DISPATCHER: register_result: lock acquired
23:03:02 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:03:02 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 34, 'lr': 0.030305770989560055, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.1284617915456203}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 34, 'lr': 0.030305770989560055, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.1284617915456203}"}}
exception: None

23:03:02 job_callback for (0, 0, 2) started
23:03:02 job_callback for (0, 0, 2) got condition
23:03:02 DISPATCHER: Trying to submit another job.
23:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:02 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:03:02 HBMASTER: Trying to run another job!
23:03:02 job_callback for (0, 0, 2) finished
23:03:02 start sampling a new configuration.
23:03:02 done sampling a new configuration.
23:03:02 HBMASTER: schedule new run for iteration 0
23:03:02 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
23:03:02 HBMASTER: submitting job (0, 0, 3) to dispatcher
23:03:02 DISPATCHER: trying to submit job (0, 0, 3)
23:03:02 DISPATCHER: trying to notify the job_runner thread.
23:03:02 HBMASTER: job (0, 0, 3) submitted to dispatcher
23:03:02 DISPATCHER: Trying to submit another job.
23:03:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:02 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:03:02 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:02 WORKER: start processing job (0, 0, 3)
23:03:02 WORKER: args: ()
23:03:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 13, 'lr': 0.004548681269356197, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.021357110971869122}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:03:25 DISPATCHER: Starting worker discovery
23:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:25 DISPATCHER: Finished worker discovery
23:03:54 WORKER: done with job (0, 0, 3), trying to register it.
23:03:54 WORKER: registered result for job (0, 0, 3) with dispatcher
23:03:54 DISPATCHER: job (0, 0, 3) finished
23:03:54 DISPATCHER: register_result: lock acquired
23:03:54 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:03:54 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 13, 'lr': 0.004548681269356197, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.021357110971869122}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 13, 'lr': 0.004548681269356197, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.021357110971869122}"}}
exception: None

23:03:54 job_callback for (0, 0, 3) started
23:03:54 job_callback for (0, 0, 3) got condition
23:03:54 DISPATCHER: Trying to submit another job.
23:03:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:54 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:03:54 HBMASTER: Trying to run another job!
23:03:54 job_callback for (0, 0, 3) finished
23:03:54 start sampling a new configuration.
23:03:54 done sampling a new configuration.
23:03:54 HBMASTER: schedule new run for iteration 0
23:03:54 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
23:03:54 HBMASTER: submitting job (0, 0, 4) to dispatcher
23:03:54 DISPATCHER: trying to submit job (0, 0, 4)
23:03:54 DISPATCHER: trying to notify the job_runner thread.
23:03:54 HBMASTER: job (0, 0, 4) submitted to dispatcher
23:03:54 DISPATCHER: Trying to submit another job.
23:03:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:54 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:03:54 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:03:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:54 WORKER: start processing job (0, 0, 4)
23:03:54 WORKER: args: ()
23:03:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 1, 'lr': 0.0028620713396998766, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.01108445120507487}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:04:25 DISPATCHER: Starting worker discovery
23:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:25 DISPATCHER: Finished worker discovery
23:04:47 WORKER: done with job (0, 0, 4), trying to register it.
23:04:47 WORKER: registered result for job (0, 0, 4) with dispatcher
23:04:47 DISPATCHER: job (0, 0, 4) finished
23:04:47 DISPATCHER: register_result: lock acquired
23:04:47 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:04:47 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 1, 'lr': 0.0028620713396998766, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.01108445120507487}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 1, 'lr': 0.0028620713396998766, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.01108445120507487}"}}
exception: None

23:04:47 job_callback for (0, 0, 4) started
23:04:47 DISPATCHER: Trying to submit another job.
23:04:47 job_callback for (0, 0, 4) got condition
23:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:47 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:04:47 HBMASTER: Trying to run another job!
23:04:47 job_callback for (0, 0, 4) finished
23:04:47 start sampling a new configuration.
23:04:47 done sampling a new configuration.
23:04:47 HBMASTER: schedule new run for iteration 0
23:04:47 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
23:04:47 HBMASTER: submitting job (0, 0, 5) to dispatcher
23:04:47 DISPATCHER: trying to submit job (0, 0, 5)
23:04:47 DISPATCHER: trying to notify the job_runner thread.
23:04:47 HBMASTER: job (0, 0, 5) submitted to dispatcher
23:04:47 DISPATCHER: Trying to submit another job.
23:04:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:47 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:04:47 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:47 WORKER: start processing job (0, 0, 5)
23:04:47 WORKER: args: ()
23:04:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.08131832475528855, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.02569683132631687}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:05:25 DISPATCHER: Starting worker discovery
23:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:25 DISPATCHER: Finished worker discovery
23:05:39 WORKER: done with job (0, 0, 5), trying to register it.
23:05:39 WORKER: registered result for job (0, 0, 5) with dispatcher
23:05:39 DISPATCHER: job (0, 0, 5) finished
23:05:39 DISPATCHER: register_result: lock acquired
23:05:39 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:05:39 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.08131832475528855, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.02569683132631687}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.050679700810154465, 'info': {'number_mnist': 0.050679700810154465, 'config': "{'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.08131832475528855, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.02569683132631687}"}}
exception: None

23:05:39 job_callback for (0, 0, 5) started
23:05:39 job_callback for (0, 0, 5) got condition
23:05:39 DISPATCHER: Trying to submit another job.
23:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:39 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:05:39 HBMASTER: Trying to run another job!
23:05:39 job_callback for (0, 0, 5) finished
23:05:39 start sampling a new configuration.
23:05:39 done sampling a new configuration.
23:05:40 HBMASTER: schedule new run for iteration 0
23:05:40 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
23:05:40 HBMASTER: submitting job (0, 0, 6) to dispatcher
23:05:40 DISPATCHER: trying to submit job (0, 0, 6)
23:05:40 DISPATCHER: trying to notify the job_runner thread.
23:05:40 HBMASTER: job (0, 0, 6) submitted to dispatcher
23:05:40 DISPATCHER: Trying to submit another job.
23:05:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:40 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:05:40 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:40 WORKER: start processing job (0, 0, 6)
23:05:40 WORKER: args: ()
23:05:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 35, 'lr': 0.009207321969643408, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.04139602392699695}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:06:25 DISPATCHER: Starting worker discovery
23:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:25 DISPATCHER: Finished worker discovery
23:06:32 WORKER: done with job (0, 0, 6), trying to register it.
23:06:32 WORKER: registered result for job (0, 0, 6) with dispatcher
23:06:32 DISPATCHER: job (0, 0, 6) finished
23:06:32 DISPATCHER: register_result: lock acquired
23:06:32 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:06:32 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 35, 'lr': 0.009207321969643408, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.04139602392699695}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06539958800253841, 'info': {'number_mnist': 0.06539958800253841, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 35, 'lr': 0.009207321969643408, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.04139602392699695}"}}
exception: None

23:06:32 job_callback for (0, 0, 6) started
23:06:32 DISPATCHER: Trying to submit another job.
23:06:32 job_callback for (0, 0, 6) got condition
23:06:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:32 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:06:32 HBMASTER: Trying to run another job!
23:06:32 job_callback for (0, 0, 6) finished
23:06:32 start sampling a new configuration.
23:06:32 done sampling a new configuration.
23:06:32 HBMASTER: schedule new run for iteration 0
23:06:32 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
23:06:32 HBMASTER: submitting job (0, 0, 7) to dispatcher
23:06:32 DISPATCHER: trying to submit job (0, 0, 7)
23:06:32 DISPATCHER: trying to notify the job_runner thread.
23:06:32 HBMASTER: job (0, 0, 7) submitted to dispatcher
23:06:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:32 DISPATCHER: Trying to submit another job.
23:06:32 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:06:32 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:06:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:32 WORKER: start processing job (0, 0, 7)
23:06:32 WORKER: args: ()
23:06:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 57, 'last_n_outputs': 15, 'lr': 0.05070685855651157, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.13533622132385173}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:07:24 WORKER: done with job (0, 0, 7), trying to register it.
23:07:24 WORKER: registered result for job (0, 0, 7) with dispatcher
23:07:24 DISPATCHER: job (0, 0, 7) finished
23:07:24 DISPATCHER: register_result: lock acquired
23:07:24 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:07:24 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 57, 'last_n_outputs': 15, 'lr': 0.05070685855651157, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.13533622132385173}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006742374306898868, 'info': {'number_mnist': 0.006742374306898868, 'config': "{'batch_size': 32, 'hidden_dim': 57, 'last_n_outputs': 15, 'lr': 0.05070685855651157, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.13533622132385173}"}}
exception: None

23:07:24 job_callback for (0, 0, 7) started
23:07:24 DISPATCHER: Trying to submit another job.
23:07:24 job_callback for (0, 0, 7) got condition
23:07:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:24 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
23:07:24 HBMASTER: Trying to run another job!
23:07:24 job_callback for (0, 0, 7) finished
23:07:24 start sampling a new configuration.
23:07:24 done sampling a new configuration.
23:07:24 HBMASTER: schedule new run for iteration 0
23:07:24 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
23:07:24 HBMASTER: submitting job (0, 0, 8) to dispatcher
23:07:24 DISPATCHER: trying to submit job (0, 0, 8)
23:07:24 DISPATCHER: trying to notify the job_runner thread.
23:07:24 HBMASTER: job (0, 0, 8) submitted to dispatcher
23:07:24 DISPATCHER: Trying to submit another job.
23:07:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:24 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:07:24 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:07:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:24 WORKER: start processing job (0, 0, 8)
23:07:24 WORKER: args: ()
23:07:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.09721956187360196, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.11401201476789323}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:07:25 DISPATCHER: Starting worker discovery
23:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:08:16 WORKER: done with job (0, 0, 8), trying to register it.
23:08:16 WORKER: registered result for job (0, 0, 8) with dispatcher
23:08:16 DISPATCHER: job (0, 0, 8) finished
23:08:16 DISPATCHER: register_result: lock acquired
23:08:16 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:08:16 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.09721956187360196, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.11401201476789323}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.017688857269054756, 'info': {'number_mnist': 0.017688857269054756, 'config': "{'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.09721956187360196, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.11401201476789323}"}}
exception: None

23:08:16 job_callback for (0, 0, 8) started
23:08:16 job_callback for (0, 0, 8) got condition
23:08:16 DISPATCHER: Trying to submit another job.
23:08:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:08:16 HBMASTER: Trying to run another job!
23:08:16 job_callback for (0, 0, 8) finished
23:08:16 start sampling a new configuration.
23:08:16 done sampling a new configuration.
23:08:16 HBMASTER: schedule new run for iteration 0
23:08:16 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
23:08:16 HBMASTER: submitting job (0, 0, 9) to dispatcher
23:08:16 DISPATCHER: trying to submit job (0, 0, 9)
23:08:16 DISPATCHER: trying to notify the job_runner thread.
23:08:16 HBMASTER: job (0, 0, 9) submitted to dispatcher
23:08:16 DISPATCHER: Trying to submit another job.
23:08:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:08:16 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:08:16 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:08:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:08:16 WORKER: start processing job (0, 0, 9)
23:08:16 WORKER: args: ()
23:08:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 4, 'lr': 0.06337904900255562, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.19826770606355637}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:08:25 DISPATCHER: Starting worker discovery
23:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:09:09 WORKER: done with job (0, 0, 9), trying to register it.
23:09:09 WORKER: registered result for job (0, 0, 9) with dispatcher
23:09:09 DISPATCHER: job (0, 0, 9) finished
23:09:09 DISPATCHER: register_result: lock acquired
23:09:09 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:09:09 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 4, 'lr': 0.06337904900255562, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.19826770606355637}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 4, 'lr': 0.06337904900255562, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.19826770606355637}"}}
exception: None

23:09:09 job_callback for (0, 0, 9) started
23:09:09 job_callback for (0, 0, 9) got condition
23:09:09 DISPATCHER: Trying to submit another job.
23:09:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:09 HBMASTER: Trying to run another job!
23:09:09 job_callback for (0, 0, 9) finished
23:09:09 start sampling a new configuration.
23:09:09 done sampling a new configuration.
23:09:09 HBMASTER: schedule new run for iteration 0
23:09:09 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
23:09:09 HBMASTER: submitting job (0, 0, 10) to dispatcher
23:09:09 DISPATCHER: trying to submit job (0, 0, 10)
23:09:09 DISPATCHER: trying to notify the job_runner thread.
23:09:09 HBMASTER: job (0, 0, 10) submitted to dispatcher
23:09:09 DISPATCHER: Trying to submit another job.
23:09:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:09 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:09:09 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:09:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:09 WORKER: start processing job (0, 0, 10)
23:09:09 WORKER: args: ()
23:09:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 11, 'lr': 0.027360225704280476, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.013406980912887237}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:09:25 DISPATCHER: Starting worker discovery
23:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:25 DISPATCHER: Finished worker discovery
23:10:02 WORKER: done with job (0, 0, 10), trying to register it.
23:10:02 WORKER: registered result for job (0, 0, 10) with dispatcher
23:10:02 DISPATCHER: job (0, 0, 10) finished
23:10:02 DISPATCHER: register_result: lock acquired
23:10:02 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:10:02 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 11, 'lr': 0.027360225704280476, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.013406980912887237}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 11, 'lr': 0.027360225704280476, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.013406980912887237}"}}
exception: None

23:10:02 job_callback for (0, 0, 10) started
23:10:02 job_callback for (0, 0, 10) got condition
23:10:02 DISPATCHER: Trying to submit another job.
23:10:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:10:02 HBMASTER: Trying to run another job!
23:10:02 job_callback for (0, 0, 10) finished
23:10:02 start sampling a new configuration.
23:10:02 done sampling a new configuration.
23:10:02 HBMASTER: schedule new run for iteration 0
23:10:02 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:10:02 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:10:02 DISPATCHER: trying to submit job (0, 0, 11)
23:10:02 DISPATCHER: trying to notify the job_runner thread.
23:10:02 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:10:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:10:02 DISPATCHER: Trying to submit another job.
23:10:02 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:10:02 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:10:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:10:02 WORKER: start processing job (0, 0, 11)
23:10:02 WORKER: args: ()
23:10:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:10:25 DISPATCHER: Starting worker discovery
23:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:25 DISPATCHER: Finished worker discovery
23:10:54 WORKER: done with job (0, 0, 11), trying to register it.
23:10:54 WORKER: registered result for job (0, 0, 11) with dispatcher
23:10:54 DISPATCHER: job (0, 0, 11) finished
23:10:54 DISPATCHER: register_result: lock acquired
23:10:54 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:10:54 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15812895464496074, 'info': {'number_mnist': 0.15812895464496074, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}"}}
exception: None

23:10:54 job_callback for (0, 0, 11) started
23:10:54 DISPATCHER: Trying to submit another job.
23:10:54 job_callback for (0, 0, 11) got condition
23:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:10:54 HBMASTER: Trying to run another job!
23:10:54 job_callback for (0, 0, 11) finished
23:10:54 start sampling a new configuration.
23:10:54 done sampling a new configuration.
23:10:54 HBMASTER: schedule new run for iteration 0
23:10:54 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
23:10:54 HBMASTER: submitting job (0, 0, 12) to dispatcher
23:10:54 DISPATCHER: trying to submit job (0, 0, 12)
23:10:54 DISPATCHER: trying to notify the job_runner thread.
23:10:54 HBMASTER: job (0, 0, 12) submitted to dispatcher
23:10:54 DISPATCHER: Trying to submit another job.
23:10:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:10:54 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:10:54 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:10:54 WORKER: start processing job (0, 0, 12)
23:10:54 WORKER: args: ()
23:10:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 1, 'lr': 0.0190265456424416, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.028463689115218575}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:11:25 DISPATCHER: Starting worker discovery
23:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:25 DISPATCHER: Finished worker discovery
23:11:47 WORKER: done with job (0, 0, 12), trying to register it.
23:11:47 WORKER: registered result for job (0, 0, 12) with dispatcher
23:11:47 DISPATCHER: job (0, 0, 12) finished
23:11:47 DISPATCHER: register_result: lock acquired
23:11:47 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:11:47 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 1, 'lr': 0.0190265456424416, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.028463689115218575}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 1, 'lr': 0.0190265456424416, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.028463689115218575}"}}
exception: None

23:11:47 job_callback for (0, 0, 12) started
23:11:47 job_callback for (0, 0, 12) got condition
23:11:47 DISPATCHER: Trying to submit another job.
23:11:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:11:47 HBMASTER: Trying to run another job!
23:11:47 job_callback for (0, 0, 12) finished
23:11:47 start sampling a new configuration.
23:11:47 done sampling a new configuration.
23:11:47 HBMASTER: schedule new run for iteration 0
23:11:47 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
23:11:47 HBMASTER: submitting job (0, 0, 13) to dispatcher
23:11:47 DISPATCHER: trying to submit job (0, 0, 13)
23:11:47 DISPATCHER: trying to notify the job_runner thread.
23:11:47 HBMASTER: job (0, 0, 13) submitted to dispatcher
23:11:47 DISPATCHER: Trying to submit another job.
23:11:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:11:47 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:11:47 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:11:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:11:47 WORKER: start processing job (0, 0, 13)
23:11:47 WORKER: args: ()
23:11:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 36, 'lr': 0.01766892699893537, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.01933915492447275}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:12:25 DISPATCHER: Starting worker discovery
23:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:25 DISPATCHER: Finished worker discovery
23:12:39 WORKER: done with job (0, 0, 13), trying to register it.
23:12:39 WORKER: registered result for job (0, 0, 13) with dispatcher
23:12:39 DISPATCHER: job (0, 0, 13) finished
23:12:39 DISPATCHER: register_result: lock acquired
23:12:39 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:12:39 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 36, 'lr': 0.01766892699893537, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.01933915492447275}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 3.1487231430657605e-06, 'info': {'number_mnist': -3.1487231430657605e-06, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 36, 'lr': 0.01766892699893537, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.01933915492447275}"}}
exception: None

23:12:39 job_callback for (0, 0, 13) started
23:12:39 job_callback for (0, 0, 13) got condition
23:12:39 DISPATCHER: Trying to submit another job.
23:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:12:39 HBMASTER: Trying to run another job!
23:12:39 job_callback for (0, 0, 13) finished
23:12:39 start sampling a new configuration.
23:12:39 done sampling a new configuration.
23:12:39 HBMASTER: schedule new run for iteration 0
23:12:39 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
23:12:39 HBMASTER: submitting job (0, 0, 14) to dispatcher
23:12:39 DISPATCHER: trying to submit job (0, 0, 14)
23:12:39 DISPATCHER: trying to notify the job_runner thread.
23:12:39 HBMASTER: job (0, 0, 14) submitted to dispatcher
23:12:39 DISPATCHER: Trying to submit another job.
23:12:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:12:39 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:12:39 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:12:39 WORKER: start processing job (0, 0, 14)
23:12:39 WORKER: args: ()
23:12:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.013973837887275601, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.015533446532950924}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:13:25 DISPATCHER: Starting worker discovery
23:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:25 DISPATCHER: Finished worker discovery
23:13:32 WORKER: done with job (0, 0, 14), trying to register it.
23:13:32 WORKER: registered result for job (0, 0, 14) with dispatcher
23:13:32 DISPATCHER: job (0, 0, 14) finished
23:13:32 DISPATCHER: register_result: lock acquired
23:13:32 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:13:32 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.013973837887275601, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.015533446532950924}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.013973837887275601, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.015533446532950924}"}}
exception: None

23:13:32 job_callback for (0, 0, 14) started
23:13:32 DISPATCHER: Trying to submit another job.
23:13:32 job_callback for (0, 0, 14) got condition
23:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:13:32 HBMASTER: Trying to run another job!
23:13:32 job_callback for (0, 0, 14) finished
23:13:32 start sampling a new configuration.
23:13:32 done sampling a new configuration.
23:13:32 HBMASTER: schedule new run for iteration 0
23:13:32 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
23:13:32 HBMASTER: submitting job (0, 0, 15) to dispatcher
23:13:32 DISPATCHER: trying to submit job (0, 0, 15)
23:13:32 DISPATCHER: trying to notify the job_runner thread.
23:13:32 HBMASTER: job (0, 0, 15) submitted to dispatcher
23:13:32 DISPATCHER: Trying to submit another job.
23:13:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:13:32 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:13:32 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:13:32 WORKER: start processing job (0, 0, 15)
23:13:32 WORKER: args: ()
23:13:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 22, 'lr': 0.01761972420881618, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.02166066580544794}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:14:25 DISPATCHER: Starting worker discovery
23:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:25 DISPATCHER: Finished worker discovery
23:14:25 WORKER: done with job (0, 0, 15), trying to register it.
23:14:25 WORKER: registered result for job (0, 0, 15) with dispatcher
23:14:25 DISPATCHER: job (0, 0, 15) finished
23:14:25 DISPATCHER: register_result: lock acquired
23:14:25 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:14:25 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 22, 'lr': 0.01761972420881618, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.02166066580544794}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 22, 'lr': 0.01761972420881618, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.02166066580544794}"}}
exception: None

23:14:25 job_callback for (0, 0, 15) started
23:14:25 job_callback for (0, 0, 15) got condition
23:14:25 DISPATCHER: Trying to submit another job.
23:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:14:25 HBMASTER: Trying to run another job!
23:14:25 job_callback for (0, 0, 15) finished
23:14:25 start sampling a new configuration.
23:14:25 done sampling a new configuration.
23:14:25 HBMASTER: schedule new run for iteration 0
23:14:25 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
23:14:25 HBMASTER: submitting job (0, 0, 16) to dispatcher
23:14:25 DISPATCHER: trying to submit job (0, 0, 16)
23:14:25 DISPATCHER: trying to notify the job_runner thread.
23:14:25 HBMASTER: job (0, 0, 16) submitted to dispatcher
23:14:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:14:25 DISPATCHER: Trying to submit another job.
23:14:25 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:14:25 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:14:25 WORKER: start processing job (0, 0, 16)
23:14:25 WORKER: args: ()
23:14:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 38, 'lr': 0.015793043528030973, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.04874352958682455}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:15:17 WORKER: done with job (0, 0, 16), trying to register it.
23:15:17 WORKER: registered result for job (0, 0, 16) with dispatcher
23:15:17 DISPATCHER: job (0, 0, 16) finished
23:15:17 DISPATCHER: register_result: lock acquired
23:15:17 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:15:17 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 38, 'lr': 0.015793043528030973, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.04874352958682455}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16840764400572558, 'info': {'number_mnist': 0.16840764400572558, 'config': "{'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 38, 'lr': 0.015793043528030973, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.04874352958682455}"}}
exception: None

23:15:17 job_callback for (0, 0, 16) started
23:15:17 job_callback for (0, 0, 16) got condition
23:15:17 DISPATCHER: Trying to submit another job.
23:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:17 HBMASTER: Trying to run another job!
23:15:17 job_callback for (0, 0, 16) finished
23:15:17 start sampling a new configuration.
23:15:17 done sampling a new configuration.
23:15:17 HBMASTER: schedule new run for iteration 0
23:15:17 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
23:15:17 HBMASTER: submitting job (0, 0, 17) to dispatcher
23:15:17 DISPATCHER: trying to submit job (0, 0, 17)
23:15:17 DISPATCHER: trying to notify the job_runner thread.
23:15:17 HBMASTER: job (0, 0, 17) submitted to dispatcher
23:15:17 DISPATCHER: Trying to submit another job.
23:15:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:17 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:15:17 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:17 WORKER: start processing job (0, 0, 17)
23:15:17 WORKER: args: ()
23:15:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 5, 'lr': 0.025744766603312333, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.018985997882251235}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:15:25 DISPATCHER: Starting worker discovery
23:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:16:10 WORKER: done with job (0, 0, 17), trying to register it.
23:16:10 WORKER: registered result for job (0, 0, 17) with dispatcher
23:16:10 DISPATCHER: job (0, 0, 17) finished
23:16:10 DISPATCHER: register_result: lock acquired
23:16:10 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:16:10 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 5, 'lr': 0.025744766603312333, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.018985997882251235}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 5, 'lr': 0.025744766603312333, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.018985997882251235}"}}
exception: None

23:16:10 job_callback for (0, 0, 17) started
23:16:10 job_callback for (0, 0, 17) got condition
23:16:10 DISPATCHER: Trying to submit another job.
23:16:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:16:10 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.168408





23:16:10 HBMASTER: Trying to run another job!
23:16:10 job_callback for (0, 0, 17) finished
23:16:10 start sampling a new configuration.
23:16:10 best_vector: [1, 0.91943646673705, 0.8406389442614757, 0.14506229820732697, 0.006180644649433353, 1, 0.50348022286296, 0.5842482480710514], 0.00011689359178339058, 0.009700973138721106, 1.1339815939793021e-06
23:16:10 done sampling a new configuration.
23:16:10 HBMASTER: schedule new run for iteration 0
23:16:10 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
23:16:10 HBMASTER: submitting job (0, 0, 18) to dispatcher
23:16:10 DISPATCHER: trying to submit job (0, 0, 18)
23:16:10 DISPATCHER: trying to notify the job_runner thread.
23:16:10 HBMASTER: job (0, 0, 18) submitted to dispatcher
23:16:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:16:10 DISPATCHER: Trying to submit another job.
23:16:10 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:16:10 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:16:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:16:10 WORKER: start processing job (0, 0, 18)
23:16:10 WORKER: args: ()
23:16:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 43, 'lr': 0.0019504040784280238, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.0575604917653106}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:16:25 DISPATCHER: Starting worker discovery
23:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:25 DISPATCHER: Finished worker discovery
23:17:02 WORKER: done with job (0, 0, 18), trying to register it.
23:17:02 WORKER: registered result for job (0, 0, 18) with dispatcher
23:17:02 DISPATCHER: job (0, 0, 18) finished
23:17:02 DISPATCHER: register_result: lock acquired
23:17:02 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:17:02 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 43, 'lr': 0.0019504040784280238, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.0575604917653106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.030491889768417837, 'info': {'number_mnist': 0.030491889768417837, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 43, 'lr': 0.0019504040784280238, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.0575604917653106}"}}
exception: None

23:17:02 job_callback for (0, 0, 18) started
23:17:02 DISPATCHER: Trying to submit another job.
23:17:02 job_callback for (0, 0, 18) got condition
23:17:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:17:02 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.168408





23:17:02 HBMASTER: Trying to run another job!
23:17:02 job_callback for (0, 0, 18) finished
23:17:02 start sampling a new configuration.
23:17:02 best_vector: [0, 0.6103382839455015, 0.24655974179907864, 0.7034912539475466, 0.06277022215398878, 1, 0.09972843689147151, 0.49733232340699596], 0.0024118792976415043, 0.09534080171597421, 0.0002299505058793018
23:17:02 done sampling a new configuration.
23:17:02 HBMASTER: schedule new run for iteration 0
23:17:02 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:17:02 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:17:02 DISPATCHER: trying to submit job (0, 0, 19)
23:17:02 DISPATCHER: trying to notify the job_runner thread.
23:17:02 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:17:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:17:02 DISPATCHER: Trying to submit another job.
23:17:02 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:17:02 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:17:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:17:02 WORKER: start processing job (0, 0, 19)
23:17:02 WORKER: args: ()
23:17:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 13, 'lr': 0.025525984894282313, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.0443653866257421}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:17:25 DISPATCHER: Starting worker discovery
23:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:25 DISPATCHER: Finished worker discovery
23:17:55 WORKER: done with job (0, 0, 19), trying to register it.
23:17:55 WORKER: registered result for job (0, 0, 19) with dispatcher
23:17:55 DISPATCHER: job (0, 0, 19) finished
23:17:55 DISPATCHER: register_result: lock acquired
23:17:55 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:17:55 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 13, 'lr': 0.025525984894282313, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.0443653866257421}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.017887494053926194, 'info': {'number_mnist': 0.017887494053926194, 'config': "{'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 13, 'lr': 0.025525984894282313, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.0443653866257421}"}}
exception: None

23:17:55 job_callback for (0, 0, 19) started
23:17:55 DISPATCHER: Trying to submit another job.
23:17:55 job_callback for (0, 0, 19) got condition
23:17:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:17:55 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.168408





23:17:55 HBMASTER: Trying to run another job!
23:17:55 job_callback for (0, 0, 19) finished
23:17:55 start sampling a new configuration.
23:17:55 done sampling a new configuration.
23:17:55 HBMASTER: schedule new run for iteration 0
23:17:55 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:17:55 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:17:55 DISPATCHER: trying to submit job (0, 0, 20)
23:17:55 DISPATCHER: trying to notify the job_runner thread.
23:17:55 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:17:55 DISPATCHER: Trying to submit another job.
23:17:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:17:55 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:17:55 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:17:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:17:55 WORKER: start processing job (0, 0, 20)
23:17:55 WORKER: args: ()
23:17:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:18:25 DISPATCHER: Starting worker discovery
23:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:25 DISPATCHER: Finished worker discovery
23:18:47 WORKER: done with job (0, 0, 20), trying to register it.
23:18:47 WORKER: registered result for job (0, 0, 20) with dispatcher
23:18:47 DISPATCHER: job (0, 0, 20) finished
23:18:47 DISPATCHER: register_result: lock acquired
23:18:47 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:18:47 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1729771967383002, 'info': {'number_mnist': 0.1729771967383002, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}"}}
exception: None

23:18:47 job_callback for (0, 0, 20) started
23:18:47 job_callback for (0, 0, 20) got condition
23:18:47 DISPATCHER: Trying to submit another job.
23:18:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:47 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.172977





23:18:47 HBMASTER: Trying to run another job!
23:18:47 job_callback for (0, 0, 20) finished
23:18:47 start sampling a new configuration.
23:18:47 done sampling a new configuration.
23:18:47 HBMASTER: schedule new run for iteration 0
23:18:47 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
23:18:47 HBMASTER: submitting job (0, 0, 21) to dispatcher
23:18:47 DISPATCHER: trying to submit job (0, 0, 21)
23:18:47 DISPATCHER: trying to notify the job_runner thread.
23:18:47 HBMASTER: job (0, 0, 21) submitted to dispatcher
23:18:47 DISPATCHER: Trying to submit another job.
23:18:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:18:47 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:18:47 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:18:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:18:47 WORKER: start processing job (0, 0, 21)
23:18:47 WORKER: args: ()
23:18:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 42, 'lr': 0.05871377640100891, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1163362735849785}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:19:25 DISPATCHER: Starting worker discovery
23:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:25 DISPATCHER: Finished worker discovery
23:19:40 WORKER: done with job (0, 0, 21), trying to register it.
23:19:40 WORKER: registered result for job (0, 0, 21) with dispatcher
23:19:40 DISPATCHER: job (0, 0, 21) finished
23:19:40 DISPATCHER: register_result: lock acquired
23:19:40 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:19:40 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 42, 'lr': 0.05871377640100891, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1163362735849785}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 42, 'lr': 0.05871377640100891, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1163362735849785}"}}
exception: None

23:19:40 job_callback for (0, 0, 21) started
23:19:40 DISPATCHER: Trying to submit another job.
23:19:40 job_callback for (0, 0, 21) got condition
23:19:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:19:40 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.172977





23:19:40 HBMASTER: Trying to run another job!
23:19:40 job_callback for (0, 0, 21) finished
23:19:40 start sampling a new configuration.
23:19:40 done sampling a new configuration.
23:19:40 HBMASTER: schedule new run for iteration 0
23:19:40 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:19:40 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:19:40 DISPATCHER: trying to submit job (0, 0, 22)
23:19:40 DISPATCHER: trying to notify the job_runner thread.
23:19:40 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:19:40 DISPATCHER: Trying to submit another job.
23:19:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:19:40 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:19:40 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:19:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:19:40 WORKER: start processing job (0, 0, 22)
23:19:40 WORKER: args: ()
23:19:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 29, 'lr': 0.002732916414727765, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.04103420533610236}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:20:25 DISPATCHER: Starting worker discovery
23:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:25 DISPATCHER: Finished worker discovery
23:20:32 WORKER: done with job (0, 0, 22), trying to register it.
23:20:32 WORKER: registered result for job (0, 0, 22) with dispatcher
23:20:32 DISPATCHER: job (0, 0, 22) finished
23:20:32 DISPATCHER: register_result: lock acquired
23:20:32 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:20:32 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 29, 'lr': 0.002732916414727765, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.04103420533610236}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.008990586991097543, 'info': {'number_mnist': 0.008990586991097543, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 29, 'lr': 0.002732916414727765, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.04103420533610236}"}}
exception: None

23:20:32 job_callback for (0, 0, 22) started
23:20:32 job_callback for (0, 0, 22) got condition
23:20:32 DISPATCHER: Trying to submit another job.
23:20:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:32 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.172977





23:20:32 HBMASTER: Trying to run another job!
23:20:32 job_callback for (0, 0, 22) finished
23:20:32 start sampling a new configuration.
23:20:32 done sampling a new configuration.
23:20:32 HBMASTER: schedule new run for iteration 0
23:20:32 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
23:20:32 HBMASTER: submitting job (0, 0, 23) to dispatcher
23:20:32 DISPATCHER: trying to submit job (0, 0, 23)
23:20:32 DISPATCHER: trying to notify the job_runner thread.
23:20:32 HBMASTER: job (0, 0, 23) submitted to dispatcher
23:20:32 DISPATCHER: Trying to submit another job.
23:20:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:32 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:20:32 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:20:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:32 WORKER: start processing job (0, 0, 23)
23:20:32 WORKER: args: ()
23:20:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 21, 'lr': 0.0029951573604565613, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.1012373328726629}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:21:25 DISPATCHER: Starting worker discovery
23:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:25 DISPATCHER: Finished worker discovery
23:21:25 WORKER: done with job (0, 0, 23), trying to register it.
23:21:25 WORKER: registered result for job (0, 0, 23) with dispatcher
23:21:25 DISPATCHER: job (0, 0, 23) finished
23:21:25 DISPATCHER: register_result: lock acquired
23:21:25 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:21:25 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 21, 'lr': 0.0029951573604565613, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.1012373328726629}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 21, 'lr': 0.0029951573604565613, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.1012373328726629}"}}
exception: None

23:21:25 job_callback for (0, 0, 23) started
23:21:25 DISPATCHER: Trying to submit another job.
23:21:25 job_callback for (0, 0, 23) got condition
23:21:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:21:25 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.172977





23:21:25 HBMASTER: Trying to run another job!
23:21:25 job_callback for (0, 0, 23) finished
23:21:25 start sampling a new configuration.
23:21:25 best_vector: [1, 0.6621905722005079, 0.554751036807775, 0.33466275351505625, 0.055301392356797194, 1, 0.9044141100200217, 0.021779005070928753], 0.0011515064212176626, 0.2258924900530522, 0.0002601166528009366
23:21:25 done sampling a new configuration.
23:21:25 HBMASTER: schedule new run for iteration 0
23:21:25 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:21:25 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:21:25 DISPATCHER: trying to submit job (0, 0, 24)
23:21:25 DISPATCHER: trying to notify the job_runner thread.
23:21:25 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:21:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:21:25 DISPATCHER: Trying to submit another job.
23:21:25 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:21:25 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:21:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:21:25 WORKER: start processing job (0, 0, 24)
23:21:25 WORKER: args: ()
23:21:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 28, 'lr': 0.004670092761913089, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.010674195159427274}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:22:17 WORKER: done with job (0, 0, 24), trying to register it.
23:22:17 WORKER: registered result for job (0, 0, 24) with dispatcher
23:22:17 DISPATCHER: job (0, 0, 24) finished
23:22:17 DISPATCHER: register_result: lock acquired
23:22:17 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:22:17 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 28, 'lr': 0.004670092761913089, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.010674195159427274}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.005654712559366551, 'info': {'number_mnist': -0.005654712559366551, 'config': "{'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 28, 'lr': 0.004670092761913089, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.010674195159427274}"}}
exception: None

23:22:17 job_callback for (0, 0, 24) started
23:22:17 DISPATCHER: Trying to submit another job.
23:22:17 job_callback for (0, 0, 24) got condition
23:22:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:17 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.172977





23:22:17 HBMASTER: Trying to run another job!
23:22:17 job_callback for (0, 0, 24) finished
23:22:17 start sampling a new configuration.
23:22:17 best_vector: [0, 0.954476661864283, 0.9372307539032851, 0.20122983059146815, 0.10067532932231564, 0, 0.1259372593549769, 0.5497031735033582], 5.366305196665991e-05, 0.16769508117289408, 8.999029855534267e-06
23:22:17 done sampling a new configuration.
23:22:17 HBMASTER: schedule new run for iteration 0
23:22:17 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:22:17 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:22:17 DISPATCHER: trying to submit job (0, 0, 25)
23:22:17 DISPATCHER: trying to notify the job_runner thread.
23:22:17 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:22:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:17 DISPATCHER: Trying to submit another job.
23:22:17 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:22:17 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:22:17 WORKER: start processing job (0, 0, 25)
23:22:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:17 WORKER: args: ()
23:22:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:22:25 DISPATCHER: Starting worker discovery
23:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:23:10 WORKER: done with job (0, 0, 25), trying to register it.
23:23:10 WORKER: registered result for job (0, 0, 25) with dispatcher
23:23:10 DISPATCHER: job (0, 0, 25) finished
23:23:10 DISPATCHER: register_result: lock acquired
23:23:10 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:23:10 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20350234231222022, 'info': {'number_mnist': 0.20350234231222022, 'config': "{'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}"}}
exception: None

23:23:10 job_callback for (0, 0, 25) started
23:23:10 DISPATCHER: Trying to submit another job.
23:23:10 job_callback for (0, 0, 25) got condition
23:23:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:23:10 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.203502





23:23:10 HBMASTER: Trying to run another job!
23:23:10 job_callback for (0, 0, 25) finished
23:23:10 start sampling a new configuration.
23:23:10 done sampling a new configuration.
23:23:10 HBMASTER: schedule new run for iteration 0
23:23:10 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
23:23:10 HBMASTER: submitting job (0, 0, 26) to dispatcher
23:23:10 DISPATCHER: trying to submit job (0, 0, 26)
23:23:10 DISPATCHER: trying to notify the job_runner thread.
23:23:10 HBMASTER: job (0, 0, 26) submitted to dispatcher
23:23:10 DISPATCHER: Trying to submit another job.
23:23:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:23:10 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:23:10 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:23:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:23:10 WORKER: start processing job (0, 0, 26)
23:23:10 WORKER: args: ()
23:23:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 37, 'lr': 0.002459030692639928, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.11264893999502733}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:23:25 DISPATCHER: Starting worker discovery
23:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:25 DISPATCHER: Finished worker discovery
23:24:02 WORKER: done with job (0, 0, 26), trying to register it.
23:24:02 WORKER: registered result for job (0, 0, 26) with dispatcher
23:24:02 DISPATCHER: job (0, 0, 26) finished
23:24:02 DISPATCHER: register_result: lock acquired
23:24:02 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:24:02 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 37, 'lr': 0.002459030692639928, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.11264893999502733}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004638208921647003, 'info': {'number_mnist': 0.004638208921647003, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 37, 'lr': 0.002459030692639928, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.11264893999502733}"}}
exception: None

23:24:02 job_callback for (0, 0, 26) started
23:24:02 DISPATCHER: Trying to submit another job.
23:24:02 job_callback for (0, 0, 26) got condition
23:24:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:02 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.203502





23:24:02 HBMASTER: Trying to run another job!
23:24:02 job_callback for (0, 0, 26) finished
23:24:02 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
23:24:02 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
23:24:02 HBMASTER: schedule new run for iteration 0
23:24:02 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
23:24:02 HBMASTER: submitting job (0, 0, 5) to dispatcher
23:24:02 DISPATCHER: trying to submit job (0, 0, 5)
23:24:02 DISPATCHER: trying to notify the job_runner thread.
23:24:02 HBMASTER: job (0, 0, 5) submitted to dispatcher
23:24:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:02 DISPATCHER: Trying to submit another job.
23:24:02 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:24:02 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:24:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:02 WORKER: start processing job (0, 0, 5)
23:24:02 WORKER: args: ()
23:24:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.08131832475528855, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.02569683132631687}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:24:25 DISPATCHER: Starting worker discovery
23:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:25 DISPATCHER: Finished worker discovery
23:25:25 DISPATCHER: Starting worker discovery
23:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:25 DISPATCHER: Finished worker discovery
23:26:24 WORKER: done with job (0, 0, 5), trying to register it.
23:26:24 WORKER: registered result for job (0, 0, 5) with dispatcher
23:26:24 DISPATCHER: job (0, 0, 5) finished
23:26:24 DISPATCHER: register_result: lock acquired
23:26:24 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:26:24 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.08131832475528855, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.02569683132631687}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.08131832475528855, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.02569683132631687}"}}
exception: None

23:26:24 job_callback for (0, 0, 5) started
23:26:24 DISPATCHER: Trying to submit another job.
23:26:24 job_callback for (0, 0, 5) got condition
23:26:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:26:24 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:26:24 HBMASTER: Trying to run another job!
23:26:24 job_callback for (0, 0, 5) finished
23:26:24 HBMASTER: schedule new run for iteration 0
23:26:24 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
23:26:24 HBMASTER: submitting job (0, 0, 6) to dispatcher
23:26:24 DISPATCHER: trying to submit job (0, 0, 6)
23:26:24 DISPATCHER: trying to notify the job_runner thread.
23:26:24 HBMASTER: job (0, 0, 6) submitted to dispatcher
23:26:24 DISPATCHER: Trying to submit another job.
23:26:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:26:24 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:26:24 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:26:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:26:24 WORKER: start processing job (0, 0, 6)
23:26:24 WORKER: args: ()
23:26:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 35, 'lr': 0.009207321969643408, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.04139602392699695}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:26:25 DISPATCHER: Starting worker discovery
23:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:27:25 DISPATCHER: Starting worker discovery
23:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:25 DISPATCHER: Finished worker discovery
23:28:25 DISPATCHER: Starting worker discovery
23:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:25 DISPATCHER: Finished worker discovery
23:28:45 WORKER: done with job (0, 0, 6), trying to register it.
23:28:45 WORKER: registered result for job (0, 0, 6) with dispatcher
23:28:45 DISPATCHER: job (0, 0, 6) finished
23:28:45 DISPATCHER: register_result: lock acquired
23:28:45 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:28:45 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 35, 'lr': 0.009207321969643408, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.04139602392699695}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.06255223164907012, 'info': {'number_mnist': 0.06255223164907012, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 35, 'lr': 0.009207321969643408, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.04139602392699695}"}}
exception: None

23:28:45 job_callback for (0, 0, 6) started
23:28:45 job_callback for (0, 0, 6) got condition
23:28:45 DISPATCHER: Trying to submit another job.
23:28:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:28:45 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:28:45 HBMASTER: Trying to run another job!
23:28:45 job_callback for (0, 0, 6) finished
23:28:45 HBMASTER: schedule new run for iteration 0
23:28:45 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
23:28:45 HBMASTER: submitting job (0, 0, 8) to dispatcher
23:28:45 DISPATCHER: trying to submit job (0, 0, 8)
23:28:45 DISPATCHER: trying to notify the job_runner thread.
23:28:45 HBMASTER: job (0, 0, 8) submitted to dispatcher
23:28:45 DISPATCHER: Trying to submit another job.
23:28:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:28:45 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:28:45 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:28:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:28:45 WORKER: start processing job (0, 0, 8)
23:28:45 WORKER: args: ()
23:28:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.09721956187360196, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.11401201476789323}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:29:25 DISPATCHER: Starting worker discovery
23:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:25 DISPATCHER: Finished worker discovery
23:30:25 DISPATCHER: Starting worker discovery
23:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:25 DISPATCHER: Finished worker discovery
23:31:06 WORKER: done with job (0, 0, 8), trying to register it.
23:31:06 WORKER: registered result for job (0, 0, 8) with dispatcher
23:31:06 DISPATCHER: job (0, 0, 8) finished
23:31:06 DISPATCHER: register_result: lock acquired
23:31:06 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:31:06 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.09721956187360196, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.11401201476789323}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.09721956187360196, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.11401201476789323}"}}
exception: None

23:31:06 job_callback for (0, 0, 8) started
23:31:06 job_callback for (0, 0, 8) got condition
23:31:06 DISPATCHER: Trying to submit another job.
23:31:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:06 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:31:06 HBMASTER: Trying to run another job!
23:31:06 job_callback for (0, 0, 8) finished
23:31:06 HBMASTER: schedule new run for iteration 0
23:31:06 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:31:06 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:31:06 DISPATCHER: trying to submit job (0, 0, 11)
23:31:06 DISPATCHER: trying to notify the job_runner thread.
23:31:06 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:31:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:06 DISPATCHER: Trying to submit another job.
23:31:06 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:31:06 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:31:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:06 WORKER: start processing job (0, 0, 11)
23:31:06 WORKER: args: ()
23:31:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:31:25 DISPATCHER: Starting worker discovery
23:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:25 DISPATCHER: Finished worker discovery
23:32:25 DISPATCHER: Starting worker discovery
23:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:25 DISPATCHER: Finished worker discovery
23:33:25 DISPATCHER: Starting worker discovery
23:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:25 DISPATCHER: Finished worker discovery
23:33:28 WORKER: done with job (0, 0, 11), trying to register it.
23:33:28 WORKER: registered result for job (0, 0, 11) with dispatcher
23:33:28 DISPATCHER: job (0, 0, 11) finished
23:33:28 DISPATCHER: register_result: lock acquired
23:33:28 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:33:28 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22949792164484026, 'info': {'number_mnist': 0.22949792164484026, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}"}}
exception: None

23:33:28 job_callback for (0, 0, 11) started
23:33:28 job_callback for (0, 0, 11) got condition
23:33:28 DISPATCHER: Trying to submit another job.
23:33:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:28 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:33:28 HBMASTER: Trying to run another job!
23:33:28 job_callback for (0, 0, 11) finished
23:33:28 HBMASTER: schedule new run for iteration 0
23:33:28 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
23:33:28 HBMASTER: submitting job (0, 0, 16) to dispatcher
23:33:28 DISPATCHER: trying to submit job (0, 0, 16)
23:33:28 DISPATCHER: trying to notify the job_runner thread.
23:33:28 HBMASTER: job (0, 0, 16) submitted to dispatcher
23:33:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:28 DISPATCHER: Trying to submit another job.
23:33:28 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:33:28 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:33:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:28 WORKER: start processing job (0, 0, 16)
23:33:28 WORKER: args: ()
23:33:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 38, 'lr': 0.015793043528030973, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.04874352958682455}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:34:25 DISPATCHER: Starting worker discovery
23:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:25 DISPATCHER: Finished worker discovery
23:35:25 DISPATCHER: Starting worker discovery
23:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:25 DISPATCHER: Finished worker discovery
23:35:50 WORKER: done with job (0, 0, 16), trying to register it.
23:35:50 WORKER: registered result for job (0, 0, 16) with dispatcher
23:35:50 DISPATCHER: job (0, 0, 16) finished
23:35:50 DISPATCHER: register_result: lock acquired
23:35:50 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:35:50 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 38, 'lr': 0.015793043528030973, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.04874352958682455}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08123760859446887, 'info': {'number_mnist': 0.08123760859446887, 'config': "{'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 38, 'lr': 0.015793043528030973, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.04874352958682455}"}}
exception: None

23:35:50 job_callback for (0, 0, 16) started
23:35:50 job_callback for (0, 0, 16) got condition
23:35:50 DISPATCHER: Trying to submit another job.
23:35:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:35:50 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:35:50 HBMASTER: Trying to run another job!
23:35:50 job_callback for (0, 0, 16) finished
23:35:50 HBMASTER: schedule new run for iteration 0
23:35:50 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
23:35:50 HBMASTER: submitting job (0, 0, 18) to dispatcher
23:35:50 DISPATCHER: trying to submit job (0, 0, 18)
23:35:50 DISPATCHER: trying to notify the job_runner thread.
23:35:50 HBMASTER: job (0, 0, 18) submitted to dispatcher
23:35:50 DISPATCHER: Trying to submit another job.
23:35:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:35:50 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:35:50 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:35:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:35:50 WORKER: start processing job (0, 0, 18)
23:35:50 WORKER: args: ()
23:35:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 43, 'lr': 0.0019504040784280238, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.0575604917653106}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:36:25 DISPATCHER: Starting worker discovery
23:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:25 DISPATCHER: Finished worker discovery
23:37:25 DISPATCHER: Starting worker discovery
23:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:25 DISPATCHER: Finished worker discovery
23:38:12 WORKER: done with job (0, 0, 18), trying to register it.
23:38:12 WORKER: registered result for job (0, 0, 18) with dispatcher
23:38:12 DISPATCHER: job (0, 0, 18) finished
23:38:12 DISPATCHER: register_result: lock acquired
23:38:12 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:38:12 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 43, 'lr': 0.0019504040784280238, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.0575604917653106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04141720131554006, 'info': {'number_mnist': 0.04141720131554006, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 43, 'lr': 0.0019504040784280238, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.0575604917653106}"}}
exception: None

23:38:12 job_callback for (0, 0, 18) started
23:38:12 job_callback for (0, 0, 18) got condition
23:38:12 DISPATCHER: Trying to submit another job.
23:38:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:12 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:38:12 HBMASTER: Trying to run another job!
23:38:12 job_callback for (0, 0, 18) finished
23:38:12 HBMASTER: schedule new run for iteration 0
23:38:12 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:38:12 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:38:12 DISPATCHER: trying to submit job (0, 0, 19)
23:38:12 DISPATCHER: trying to notify the job_runner thread.
23:38:12 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:38:12 DISPATCHER: Trying to submit another job.
23:38:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:12 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:38:12 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:38:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:12 WORKER: start processing job (0, 0, 19)
23:38:12 WORKER: args: ()
23:38:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 13, 'lr': 0.025525984894282313, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.0443653866257421}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:38:25 DISPATCHER: Starting worker discovery
23:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:25 DISPATCHER: Finished worker discovery
23:39:25 DISPATCHER: Starting worker discovery
23:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:25 DISPATCHER: Finished worker discovery
23:40:25 DISPATCHER: Starting worker discovery
23:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:25 DISPATCHER: Finished worker discovery
23:40:33 WORKER: done with job (0, 0, 19), trying to register it.
23:40:33 WORKER: registered result for job (0, 0, 19) with dispatcher
23:40:33 DISPATCHER: job (0, 0, 19) finished
23:40:33 DISPATCHER: register_result: lock acquired
23:40:33 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:40:33 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 13, 'lr': 0.025525984894282313, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.0443653866257421}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07297986803556844, 'info': {'number_mnist': 0.07297986803556844, 'config': "{'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 13, 'lr': 0.025525984894282313, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.0443653866257421}"}}
exception: None

23:40:33 job_callback for (0, 0, 19) started
23:40:33 DISPATCHER: Trying to submit another job.
23:40:33 job_callback for (0, 0, 19) got condition
23:40:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:33 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:40:33 HBMASTER: Trying to run another job!
23:40:33 job_callback for (0, 0, 19) finished
23:40:33 HBMASTER: schedule new run for iteration 0
23:40:33 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:40:33 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:40:33 DISPATCHER: trying to submit job (0, 0, 20)
23:40:33 DISPATCHER: trying to notify the job_runner thread.
23:40:33 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:40:33 DISPATCHER: Trying to submit another job.
23:40:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:33 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:40:33 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:40:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:33 WORKER: start processing job (0, 0, 20)
23:40:33 WORKER: args: ()
23:40:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:41:25 DISPATCHER: Starting worker discovery
23:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:25 DISPATCHER: Finished worker discovery
23:42:25 DISPATCHER: Starting worker discovery
23:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:25 DISPATCHER: Finished worker discovery
23:42:54 WORKER: done with job (0, 0, 20), trying to register it.
23:42:54 WORKER: registered result for job (0, 0, 20) with dispatcher
23:42:54 DISPATCHER: job (0, 0, 20) finished
23:42:54 DISPATCHER: register_result: lock acquired
23:42:54 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:42:54 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14206740167676996, 'info': {'number_mnist': 0.14206740167676996, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}"}}
exception: None

23:42:54 job_callback for (0, 0, 20) started
23:42:54 job_callback for (0, 0, 20) got condition
23:42:54 DISPATCHER: Trying to submit another job.
23:42:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:42:54 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
23:42:54 HBMASTER: Trying to run another job!
23:42:54 job_callback for (0, 0, 20) finished
23:42:54 HBMASTER: schedule new run for iteration 0
23:42:54 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:42:54 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:42:54 DISPATCHER: trying to submit job (0, 0, 25)
23:42:54 DISPATCHER: trying to notify the job_runner thread.
23:42:54 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:42:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:42:54 DISPATCHER: Trying to submit another job.
23:42:54 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:42:54 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:42:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:42:54 WORKER: start processing job (0, 0, 25)
23:42:54 WORKER: args: ()
23:42:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:43:25 DISPATCHER: Starting worker discovery
23:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:25 DISPATCHER: Finished worker discovery
23:44:25 DISPATCHER: Starting worker discovery
23:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:25 DISPATCHER: Finished worker discovery
23:45:16 WORKER: done with job (0, 0, 25), trying to register it.
23:45:16 WORKER: registered result for job (0, 0, 25) with dispatcher
23:45:16 DISPATCHER: job (0, 0, 25) finished
23:45:16 DISPATCHER: register_result: lock acquired
23:45:16 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:45:16 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2785558898790436, 'info': {'number_mnist': 0.2785558898790436, 'config': "{'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}"}}
exception: None

23:45:16 job_callback for (0, 0, 25) started
23:45:16 DISPATCHER: Trying to submit another job.
23:45:16 job_callback for (0, 0, 25) got condition
23:45:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:45:16 HBMASTER: Trying to run another job!
23:45:16 job_callback for (0, 0, 25) finished
23:45:16 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
23:45:16 ITERATION: Advancing config (0, 0, 20) to next budget 400.000000
23:45:16 ITERATION: Advancing config (0, 0, 25) to next budget 400.000000
23:45:16 HBMASTER: schedule new run for iteration 0
23:45:16 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:45:16 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:45:16 DISPATCHER: trying to submit job (0, 0, 11)
23:45:16 DISPATCHER: trying to notify the job_runner thread.
23:45:16 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:45:16 DISPATCHER: Trying to submit another job.
23:45:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:45:16 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:45:16 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:45:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:45:16 WORKER: start processing job (0, 0, 11)
23:45:16 WORKER: args: ()
23:45:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:45:25 DISPATCHER: Starting worker discovery
23:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:25 DISPATCHER: Finished worker discovery
23:46:25 DISPATCHER: Starting worker discovery
23:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:25 DISPATCHER: Finished worker discovery
23:47:25 DISPATCHER: Starting worker discovery
23:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:25 DISPATCHER: Finished worker discovery
23:48:25 DISPATCHER: Starting worker discovery
23:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:25 DISPATCHER: Finished worker discovery
23:49:25 DISPATCHER: Starting worker discovery
23:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:25 DISPATCHER: Finished worker discovery
23:50:25 DISPATCHER: Starting worker discovery
23:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:25 DISPATCHER: Finished worker discovery
23:51:25 DISPATCHER: Starting worker discovery
23:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:25 DISPATCHER: Finished worker discovery
23:52:04 WORKER: done with job (0, 0, 11), trying to register it.
23:52:04 WORKER: registered result for job (0, 0, 11) with dispatcher
23:52:04 DISPATCHER: job (0, 0, 11) finished
23:52:04 DISPATCHER: register_result: lock acquired
23:52:04 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:52:04 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.21538671679943275, 'info': {'number_mnist': 0.21538671679943275, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 8, 'lr': 0.06199320933964138, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.015098440452977242}"}}
exception: None

23:52:04 job_callback for (0, 0, 11) started
23:52:04 job_callback for (0, 0, 11) got condition
23:52:04 DISPATCHER: Trying to submit another job.
23:52:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:52:04 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
23:52:04 HBMASTER: Trying to run another job!
23:52:04 job_callback for (0, 0, 11) finished
23:52:04 HBMASTER: schedule new run for iteration 0
23:52:04 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:52:04 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:52:04 DISPATCHER: trying to submit job (0, 0, 20)
23:52:04 DISPATCHER: trying to notify the job_runner thread.
23:52:04 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:52:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:52:04 DISPATCHER: Trying to submit another job.
23:52:04 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:52:04 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:52:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:52:04 WORKER: start processing job (0, 0, 20)
23:52:04 WORKER: args: ()
23:52:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:52:25 DISPATCHER: Starting worker discovery
23:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:25 DISPATCHER: Finished worker discovery
23:53:25 DISPATCHER: Starting worker discovery
23:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:25 DISPATCHER: Finished worker discovery
23:54:25 DISPATCHER: Starting worker discovery
23:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:25 DISPATCHER: Finished worker discovery
23:55:25 DISPATCHER: Starting worker discovery
23:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:25 DISPATCHER: Finished worker discovery
23:56:25 DISPATCHER: Starting worker discovery
23:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:25 DISPATCHER: Finished worker discovery
23:57:25 DISPATCHER: Starting worker discovery
23:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:25 DISPATCHER: Finished worker discovery
23:58:25 DISPATCHER: Starting worker discovery
23:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:25 DISPATCHER: Finished worker discovery
23:58:51 WORKER: done with job (0, 0, 20), trying to register it.
23:58:51 WORKER: registered result for job (0, 0, 20) with dispatcher
23:58:51 DISPATCHER: job (0, 0, 20) finished
23:58:51 DISPATCHER: register_result: lock acquired
23:58:51 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:58:51 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13812092927966294, 'info': {'number_mnist': 0.13812092927966294, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 21, 'lr': 0.007804607856820018, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.012065063551844116}"}}
exception: None

23:58:51 job_callback for (0, 0, 20) started
23:58:51 job_callback for (0, 0, 20) got condition
23:58:51 DISPATCHER: Trying to submit another job.
23:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:58:51 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
23:58:51 HBMASTER: Trying to run another job!
23:58:51 job_callback for (0, 0, 20) finished
23:58:51 HBMASTER: schedule new run for iteration 0
23:58:51 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:58:51 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:58:51 DISPATCHER: trying to submit job (0, 0, 25)
23:58:51 DISPATCHER: trying to notify the job_runner thread.
23:58:51 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:58:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:58:51 DISPATCHER: Trying to submit another job.
23:58:51 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:58:51 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:58:51 WORKER: start processing job (0, 0, 25)
23:58:51 WORKER: args: ()
23:58:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:59:25 DISPATCHER: Starting worker discovery
23:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:25 DISPATCHER: Finished worker discovery
00:00:25 DISPATCHER: Starting worker discovery
00:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:25 DISPATCHER: Finished worker discovery
00:01:25 DISPATCHER: Starting worker discovery
00:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:25 DISPATCHER: Finished worker discovery
00:02:25 DISPATCHER: Starting worker discovery
00:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:25 DISPATCHER: Finished worker discovery
00:03:25 DISPATCHER: Starting worker discovery
00:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:25 DISPATCHER: Finished worker discovery
00:04:25 DISPATCHER: Starting worker discovery
00:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:25 DISPATCHER: Finished worker discovery
00:05:25 DISPATCHER: Starting worker discovery
00:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:25 DISPATCHER: Finished worker discovery
00:05:39 WORKER: done with job (0, 0, 25), trying to register it.
00:05:39 WORKER: registered result for job (0, 0, 25) with dispatcher
00:05:39 DISPATCHER: job (0, 0, 25) finished
00:05:39 DISPATCHER: register_result: lock acquired
00:05:39 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:05:39 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3001523446093022, 'info': {'number_mnist': 0.3001523446093022, 'config': "{'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}"}}
exception: None

00:05:39 job_callback for (0, 0, 25) started
00:05:39 DISPATCHER: Trying to submit another job.
00:05:39 job_callback for (0, 0, 25) got condition
00:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:05:39 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
00:05:39 HBMASTER: Trying to run another job!
00:05:39 job_callback for (0, 0, 25) finished
00:05:39 ITERATION: Advancing config (0, 0, 25) to next budget 1200.000000
00:05:39 HBMASTER: schedule new run for iteration 0
00:05:39 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
00:05:39 HBMASTER: submitting job (0, 0, 25) to dispatcher
00:05:39 DISPATCHER: trying to submit job (0, 0, 25)
00:05:39 DISPATCHER: trying to notify the job_runner thread.
00:05:39 HBMASTER: job (0, 0, 25) submitted to dispatcher
00:05:39 DISPATCHER: Trying to submit another job.
00:05:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:05:39 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:05:39 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:05:39 WORKER: start processing job (0, 0, 25)
00:05:39 WORKER: args: ()
00:05:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:06:25 DISPATCHER: Starting worker discovery
00:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:25 DISPATCHER: Finished worker discovery
00:07:25 DISPATCHER: Starting worker discovery
00:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:25 DISPATCHER: Finished worker discovery
00:08:25 DISPATCHER: Starting worker discovery
00:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:25 DISPATCHER: Finished worker discovery
00:09:25 DISPATCHER: Starting worker discovery
00:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:25 DISPATCHER: Finished worker discovery
00:10:25 DISPATCHER: Starting worker discovery
00:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:25 DISPATCHER: Finished worker discovery
00:11:25 DISPATCHER: Starting worker discovery
00:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:25 DISPATCHER: Finished worker discovery
00:12:25 DISPATCHER: Starting worker discovery
00:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:25 DISPATCHER: Finished worker discovery
00:13:25 DISPATCHER: Starting worker discovery
00:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:25 DISPATCHER: Finished worker discovery
00:14:25 DISPATCHER: Starting worker discovery
00:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:25 DISPATCHER: Finished worker discovery
00:15:25 DISPATCHER: Starting worker discovery
00:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:25 DISPATCHER: Finished worker discovery
00:16:25 DISPATCHER: Starting worker discovery
00:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:25 DISPATCHER: Finished worker discovery
00:17:25 DISPATCHER: Starting worker discovery
00:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:25 DISPATCHER: Finished worker discovery
00:18:25 DISPATCHER: Starting worker discovery
00:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:25 DISPATCHER: Finished worker discovery
00:19:25 DISPATCHER: Starting worker discovery
00:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:25 DISPATCHER: Finished worker discovery
00:20:25 DISPATCHER: Starting worker discovery
00:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:25 DISPATCHER: Finished worker discovery
00:21:25 DISPATCHER: Starting worker discovery
00:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:25 DISPATCHER: Finished worker discovery
00:22:25 DISPATCHER: Starting worker discovery
00:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:25 DISPATCHER: Finished worker discovery
00:23:25 DISPATCHER: Starting worker discovery
00:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:25 DISPATCHER: Finished worker discovery
00:24:25 DISPATCHER: Starting worker discovery
00:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:25 DISPATCHER: Finished worker discovery
00:25:25 DISPATCHER: Starting worker discovery
00:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:25 DISPATCHER: Finished worker discovery
00:25:47 WORKER: done with job (0, 0, 25), trying to register it.
00:25:47 WORKER: registered result for job (0, 0, 25) with dispatcher
00:25:47 DISPATCHER: job (0, 0, 25) finished
00:25:47 DISPATCHER: register_result: lock acquired
00:25:47 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:25:47 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.38225749970550027, 'info': {'number_mnist': 0.38225749970550027, 'config': "{'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 47, 'lr': 0.002526153061148055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.05190154874823713}"}}
exception: None

00:25:47 job_callback for (0, 0, 25) started
00:25:47 DISPATCHER: Trying to submit another job.
00:25:47 job_callback for (0, 0, 25) got condition
00:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:25:47 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
00:25:47 HBMASTER: Trying to run another job!
00:25:47 job_callback for (0, 0, 25) finished
00:25:47 start sampling a new configuration.
00:25:47 done sampling a new configuration.
00:25:47 HBMASTER: schedule new run for iteration 1
00:25:47 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:25:47 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:25:47 DISPATCHER: trying to submit job (1, 0, 0)
00:25:47 DISPATCHER: trying to notify the job_runner thread.
00:25:47 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:25:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:25:47 DISPATCHER: Trying to submit another job.
00:25:47 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:25:47 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:25:47 WORKER: start processing job (1, 0, 0)
00:25:47 WORKER: args: ()
00:25:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 14, 'lr': 0.0018605956830144604, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.05833087013966807}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:26:25 DISPATCHER: Starting worker discovery
00:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:25 DISPATCHER: Finished worker discovery
00:27:25 DISPATCHER: Starting worker discovery
00:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:25 DISPATCHER: Finished worker discovery
00:28:09 WORKER: done with job (1, 0, 0), trying to register it.
00:28:09 WORKER: registered result for job (1, 0, 0) with dispatcher
00:28:09 DISPATCHER: job (1, 0, 0) finished
00:28:09 DISPATCHER: register_result: lock acquired
00:28:09 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:28:09 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 14, 'lr': 0.0018605956830144604, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.05833087013966807}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.005306279896397567, 'info': {'number_mnist': 0.005306279896397567, 'config': "{'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 14, 'lr': 0.0018605956830144604, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.05833087013966807}"}}
exception: None

00:28:09 job_callback for (1, 0, 0) started
00:28:09 DISPATCHER: Trying to submit another job.
00:28:09 job_callback for (1, 0, 0) got condition
00:28:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:09 HBMASTER: Trying to run another job!
00:28:09 job_callback for (1, 0, 0) finished
00:28:09 start sampling a new configuration.
00:28:09 best_vector: [1, 0.5851053262047127, 0.5058535883974254, 0.7361754090143354, 0.06782380637168545, 0, 0.09615458695176515, 0.39789396641494246], 0.0006408974596028816, 0.9733327080600147, 0.0006238064599440566
00:28:09 done sampling a new configuration.
00:28:09 HBMASTER: schedule new run for iteration 1
00:28:09 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
00:28:09 HBMASTER: submitting job (1, 0, 1) to dispatcher
00:28:09 DISPATCHER: trying to submit job (1, 0, 1)
00:28:09 DISPATCHER: trying to notify the job_runner thread.
00:28:09 HBMASTER: job (1, 0, 1) submitted to dispatcher
00:28:09 DISPATCHER: Trying to submit another job.
00:28:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:09 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:28:09 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:28:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:09 WORKER: start processing job (1, 0, 1)
00:28:09 WORKER: args: ()
00:28:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 26, 'lr': 0.02967227313388992, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.032936085803928095}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:28:25 DISPATCHER: Starting worker discovery
00:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:25 DISPATCHER: Finished worker discovery
00:29:25 DISPATCHER: Starting worker discovery
00:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:25 DISPATCHER: Finished worker discovery
00:30:25 DISPATCHER: Starting worker discovery
00:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:25 DISPATCHER: Finished worker discovery
00:30:31 WORKER: done with job (1, 0, 1), trying to register it.
00:30:31 WORKER: registered result for job (1, 0, 1) with dispatcher
00:30:31 DISPATCHER: job (1, 0, 1) finished
00:30:31 DISPATCHER: register_result: lock acquired
00:30:31 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:30:31 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 26, 'lr': 0.02967227313388992, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.032936085803928095}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.011257533502801264, 'info': {'number_mnist': 0.011257533502801264, 'config': "{'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 26, 'lr': 0.02967227313388992, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.032936085803928095}"}}
exception: None

00:30:31 job_callback for (1, 0, 1) started
00:30:31 job_callback for (1, 0, 1) got condition
00:30:31 DISPATCHER: Trying to submit another job.
00:30:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:30:31 HBMASTER: Trying to run another job!
00:30:31 job_callback for (1, 0, 1) finished
00:30:31 start sampling a new configuration.
00:30:31 best_vector: [3, 0.9213653139466031, 0.6635077411826587, 0.4055963980967653, 0.11542070846251826, 1, 0.20790171692206783, 0.6665470572488355], 0.0006269697953953879, 0.7239743290786301, 0.00045391003697394194
00:30:31 done sampling a new configuration.
00:30:31 HBMASTER: schedule new run for iteration 1
00:30:31 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:30:31 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:30:31 DISPATCHER: trying to submit job (1, 0, 2)
00:30:31 DISPATCHER: trying to notify the job_runner thread.
00:30:31 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:30:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:30:31 DISPATCHER: Trying to submit another job.
00:30:31 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:30:31 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:30:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:30:31 WORKER: start processing job (1, 0, 2)
00:30:31 WORKER: args: ()
00:30:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 34, 'lr': 0.0064742996531457955, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.07365423362149658}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:31:25 DISPATCHER: Starting worker discovery
00:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:25 DISPATCHER: Finished worker discovery
00:32:25 DISPATCHER: Starting worker discovery
00:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:25 DISPATCHER: Finished worker discovery
00:32:52 WORKER: done with job (1, 0, 2), trying to register it.
00:32:52 WORKER: registered result for job (1, 0, 2) with dispatcher
00:32:52 DISPATCHER: job (1, 0, 2) finished
00:32:52 DISPATCHER: register_result: lock acquired
00:32:52 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:32:52 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 34, 'lr': 0.0064742996531457955, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.07365423362149658}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.051644906343396225, 'info': {'number_mnist': 0.051644906343396225, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 34, 'lr': 0.0064742996531457955, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.07365423362149658}"}}
exception: None

00:32:52 job_callback for (1, 0, 2) started
00:32:52 DISPATCHER: Trying to submit another job.
00:32:52 job_callback for (1, 0, 2) got condition
00:32:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:32:52 HBMASTER: Trying to run another job!
00:32:52 job_callback for (1, 0, 2) finished
00:32:52 start sampling a new configuration.
00:32:52 done sampling a new configuration.
00:32:52 HBMASTER: schedule new run for iteration 1
00:32:52 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:32:52 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:32:52 DISPATCHER: trying to submit job (1, 0, 3)
00:32:52 DISPATCHER: trying to notify the job_runner thread.
00:32:52 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:32:52 DISPATCHER: Trying to submit another job.
00:32:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:32:52 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:32:52 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:32:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:32:52 WORKER: start processing job (1, 0, 3)
00:32:52 WORKER: args: ()
00:32:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 11, 'lr': 0.00848678084880452, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.15187856118659965}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:33:25 DISPATCHER: Starting worker discovery
00:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:25 DISPATCHER: Finished worker discovery
00:34:25 DISPATCHER: Starting worker discovery
00:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:25 DISPATCHER: Finished worker discovery
00:35:14 WORKER: done with job (1, 0, 3), trying to register it.
00:35:14 WORKER: registered result for job (1, 0, 3) with dispatcher
00:35:14 DISPATCHER: job (1, 0, 3) finished
00:35:14 DISPATCHER: register_result: lock acquired
00:35:14 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:35:14 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 11, 'lr': 0.00848678084880452, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.15187856118659965}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 11, 'lr': 0.00848678084880452, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.15187856118659965}"}}
exception: None

00:35:14 job_callback for (1, 0, 3) started
00:35:14 DISPATCHER: Trying to submit another job.
00:35:14 job_callback for (1, 0, 3) got condition
00:35:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:35:14 HBMASTER: Trying to run another job!
00:35:14 job_callback for (1, 0, 3) finished
00:35:14 start sampling a new configuration.
00:35:14 done sampling a new configuration.
00:35:14 HBMASTER: schedule new run for iteration 1
00:35:14 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:35:14 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:35:14 DISPATCHER: trying to submit job (1, 0, 4)
00:35:14 DISPATCHER: trying to notify the job_runner thread.
00:35:14 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:35:14 DISPATCHER: Trying to submit another job.
00:35:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:35:14 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:35:14 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:35:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:35:14 WORKER: start processing job (1, 0, 4)
00:35:14 WORKER: args: ()
00:35:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 12, 'lr': 0.05978539674832851, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.10886909953126019}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:35:25 DISPATCHER: Starting worker discovery
00:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:25 DISPATCHER: Finished worker discovery
00:36:25 DISPATCHER: Starting worker discovery
00:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:25 DISPATCHER: Finished worker discovery
00:37:25 DISPATCHER: Starting worker discovery
00:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:25 DISPATCHER: Finished worker discovery
00:37:36 WORKER: done with job (1, 0, 4), trying to register it.
00:37:36 WORKER: registered result for job (1, 0, 4) with dispatcher
00:37:36 DISPATCHER: job (1, 0, 4) finished
00:37:36 DISPATCHER: register_result: lock acquired
00:37:36 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:37:36 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 12, 'lr': 0.05978539674832851, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.10886909953126019}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.040234271237215846, 'info': {'number_mnist': 0.040234271237215846, 'config': "{'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 12, 'lr': 0.05978539674832851, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.10886909953126019}"}}
exception: None

00:37:36 job_callback for (1, 0, 4) started
00:37:36 DISPATCHER: Trying to submit another job.
00:37:36 job_callback for (1, 0, 4) got condition
00:37:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:36 HBMASTER: Trying to run another job!
00:37:36 job_callback for (1, 0, 4) finished
00:37:36 start sampling a new configuration.
00:37:36 best_vector: [0, 0.19954908587861064, 0.9599021763528609, 0.12379366085365724, 0.12376286543054632, 1, 0.01754057932723896, 0.9987821406592889], 0.0006579061196998193, 0.008254000231886839, 5.430357264562079e-06
00:37:36 done sampling a new configuration.
00:37:36 HBMASTER: schedule new run for iteration 1
00:37:36 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
00:37:36 HBMASTER: submitting job (1, 0, 5) to dispatcher
00:37:36 DISPATCHER: trying to submit job (1, 0, 5)
00:37:36 DISPATCHER: trying to notify the job_runner thread.
00:37:36 HBMASTER: job (1, 0, 5) submitted to dispatcher
00:37:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:36 DISPATCHER: Trying to submit another job.
00:37:36 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:37:36 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:37:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:36 WORKER: start processing job (1, 0, 5)
00:37:36 WORKER: args: ()
00:37:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 48, 'lr': 0.0017684277520861364, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.19927165334445462}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:38:25 DISPATCHER: Starting worker discovery
00:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:25 DISPATCHER: Finished worker discovery
00:39:25 DISPATCHER: Starting worker discovery
00:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:25 DISPATCHER: Finished worker discovery
00:39:57 WORKER: done with job (1, 0, 5), trying to register it.
00:39:57 WORKER: registered result for job (1, 0, 5) with dispatcher
00:39:57 DISPATCHER: job (1, 0, 5) finished
00:39:57 DISPATCHER: register_result: lock acquired
00:39:57 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:39:57 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 48, 'lr': 0.0017684277520861364, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.19927165334445462}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.015612086606012921, 'info': {'number_mnist': 0.015612086606012921, 'config': "{'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 48, 'lr': 0.0017684277520861364, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.19927165334445462}"}}
exception: None

00:39:57 job_callback for (1, 0, 5) started
00:39:57 job_callback for (1, 0, 5) got condition
00:39:57 DISPATCHER: Trying to submit another job.
00:39:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:39:57 HBMASTER: Trying to run another job!
00:39:57 job_callback for (1, 0, 5) finished
00:39:57 start sampling a new configuration.
00:39:57 best_vector: [0, 0.9897520196954606, 0.7813543388050466, 0.3671629319852877, 0.14416415791380272, 1, 0.05990480902925863, 0.5899114603160815], 0.00022157770592815164, 0.33049410329097856, 7.323012522999662e-05
00:39:57 done sampling a new configuration.
00:39:57 HBMASTER: schedule new run for iteration 1
00:39:57 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
00:39:57 HBMASTER: submitting job (1, 0, 6) to dispatcher
00:39:57 DISPATCHER: trying to submit job (1, 0, 6)
00:39:57 DISPATCHER: trying to notify the job_runner thread.
00:39:57 HBMASTER: job (1, 0, 6) submitted to dispatcher
00:39:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:39:57 DISPATCHER: Trying to submit another job.
00:39:57 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:39:57 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:39:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:39:57 WORKER: start processing job (1, 0, 6)
00:39:57 WORKER: args: ()
00:39:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:40:25 DISPATCHER: Starting worker discovery
00:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:25 DISPATCHER: Finished worker discovery
00:41:25 DISPATCHER: Starting worker discovery
00:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:25 DISPATCHER: Finished worker discovery
00:42:18 WORKER: done with job (1, 0, 6), trying to register it.
00:42:18 WORKER: registered result for job (1, 0, 6) with dispatcher
00:42:18 DISPATCHER: job (1, 0, 6) finished
00:42:18 DISPATCHER: register_result: lock acquired
00:42:18 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:42:18 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.023834149026048218, 'info': {'number_mnist': 0.023834149026048218, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}"}}
exception: None

00:42:18 job_callback for (1, 0, 6) started
00:42:18 DISPATCHER: Trying to submit another job.
00:42:18 job_callback for (1, 0, 6) got condition
00:42:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:42:18 HBMASTER: Trying to run another job!
00:42:18 job_callback for (1, 0, 6) finished
00:42:18 start sampling a new configuration.
00:42:18 done sampling a new configuration.
00:42:18 HBMASTER: schedule new run for iteration 1
00:42:18 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
00:42:18 HBMASTER: submitting job (1, 0, 7) to dispatcher
00:42:18 DISPATCHER: trying to submit job (1, 0, 7)
00:42:18 DISPATCHER: trying to notify the job_runner thread.
00:42:18 HBMASTER: job (1, 0, 7) submitted to dispatcher
00:42:18 DISPATCHER: Trying to submit another job.
00:42:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:42:18 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:42:18 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:42:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:42:18 WORKER: start processing job (1, 0, 7)
00:42:18 WORKER: args: ()
00:42:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 11, 'lr': 0.0039004151071757964, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.025274520199720374}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:42:25 DISPATCHER: Starting worker discovery
00:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:43:25 DISPATCHER: Starting worker discovery
00:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:25 DISPATCHER: Finished worker discovery
00:44:25 DISPATCHER: Starting worker discovery
00:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:25 DISPATCHER: Finished worker discovery
00:44:40 WORKER: done with job (1, 0, 7), trying to register it.
00:44:40 WORKER: registered result for job (1, 0, 7) with dispatcher
00:44:40 DISPATCHER: job (1, 0, 7) finished
00:44:40 DISPATCHER: register_result: lock acquired
00:44:40 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:44:40 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 11, 'lr': 0.0039004151071757964, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.025274520199720374}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.009571735876567905, 'info': {'number_mnist': 0.009571735876567905, 'config': "{'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 11, 'lr': 0.0039004151071757964, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.025274520199720374}"}}
exception: None

00:44:40 job_callback for (1, 0, 7) started
00:44:40 job_callback for (1, 0, 7) got condition
00:44:40 DISPATCHER: Trying to submit another job.
00:44:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:44:40 HBMASTER: Trying to run another job!
00:44:40 job_callback for (1, 0, 7) finished
00:44:40 start sampling a new configuration.
00:44:40 done sampling a new configuration.
00:44:40 HBMASTER: schedule new run for iteration 1
00:44:40 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:44:40 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:44:40 DISPATCHER: trying to submit job (1, 0, 8)
00:44:40 DISPATCHER: trying to notify the job_runner thread.
00:44:40 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:44:40 DISPATCHER: Trying to submit another job.
00:44:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:44:40 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:44:40 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:44:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:44:40 WORKER: start processing job (1, 0, 8)
00:44:40 WORKER: args: ()
00:44:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 16, 'lr': 0.002412465577649427, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0432771188873626}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:45:25 DISPATCHER: Starting worker discovery
00:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:25 DISPATCHER: Finished worker discovery
00:46:25 DISPATCHER: Starting worker discovery
00:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:25 DISPATCHER: Finished worker discovery
00:47:01 WORKER: done with job (1, 0, 8), trying to register it.
00:47:01 WORKER: registered result for job (1, 0, 8) with dispatcher
00:47:01 DISPATCHER: job (1, 0, 8) finished
00:47:01 DISPATCHER: register_result: lock acquired
00:47:01 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:47:01 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 16, 'lr': 0.002412465577649427, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0432771188873626}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.01188382857644181, 'info': {'number_mnist': -0.01188382857644181, 'config': "{'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 16, 'lr': 0.002412465577649427, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0432771188873626}"}}
exception: None

00:47:01 job_callback for (1, 0, 8) started
00:47:01 job_callback for (1, 0, 8) got condition
00:47:01 DISPATCHER: Trying to submit another job.
00:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:47:01 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.278556





00:47:01 HBMASTER: Trying to run another job!
00:47:01 job_callback for (1, 0, 8) finished
00:47:01 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
00:47:01 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
00:47:01 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
00:47:01 HBMASTER: schedule new run for iteration 1
00:47:01 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:47:01 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:47:01 DISPATCHER: trying to submit job (1, 0, 2)
00:47:01 DISPATCHER: trying to notify the job_runner thread.
00:47:01 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:47:01 DISPATCHER: Trying to submit another job.
00:47:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:47:01 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:47:01 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:47:01 WORKER: start processing job (1, 0, 2)
00:47:01 WORKER: args: ()
00:47:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 34, 'lr': 0.0064742996531457955, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.07365423362149658}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:47:25 DISPATCHER: Starting worker discovery
00:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:25 DISPATCHER: Finished worker discovery
00:48:25 DISPATCHER: Starting worker discovery
00:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:25 DISPATCHER: Finished worker discovery
00:49:25 DISPATCHER: Starting worker discovery
00:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:25 DISPATCHER: Finished worker discovery
00:50:25 DISPATCHER: Starting worker discovery
00:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:25 DISPATCHER: Finished worker discovery
00:51:25 DISPATCHER: Starting worker discovery
00:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:25 DISPATCHER: Finished worker discovery
00:52:25 DISPATCHER: Starting worker discovery
00:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:25 DISPATCHER: Finished worker discovery
00:53:25 DISPATCHER: Starting worker discovery
00:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:25 DISPATCHER: Finished worker discovery
00:53:49 WORKER: done with job (1, 0, 2), trying to register it.
00:53:49 WORKER: registered result for job (1, 0, 2) with dispatcher
00:53:49 DISPATCHER: job (1, 0, 2) finished
00:53:49 DISPATCHER: register_result: lock acquired
00:53:49 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:53:49 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 34, 'lr': 0.0064742996531457955, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.07365423362149658}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03315020836018461, 'info': {'number_mnist': 0.03315020836018461, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 34, 'lr': 0.0064742996531457955, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.07365423362149658}"}}
exception: None

00:53:49 job_callback for (1, 0, 2) started
00:53:49 DISPATCHER: Trying to submit another job.
00:53:49 job_callback for (1, 0, 2) got condition
00:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:49 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
00:53:49 HBMASTER: Trying to run another job!
00:53:49 job_callback for (1, 0, 2) finished
00:53:49 HBMASTER: schedule new run for iteration 1
00:53:49 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:53:49 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:53:49 DISPATCHER: trying to submit job (1, 0, 4)
00:53:49 DISPATCHER: trying to notify the job_runner thread.
00:53:49 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:53:49 DISPATCHER: Trying to submit another job.
00:53:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:49 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:53:49 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:49 WORKER: start processing job (1, 0, 4)
00:53:49 WORKER: args: ()
00:53:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 12, 'lr': 0.05978539674832851, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.10886909953126019}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:54:25 DISPATCHER: Starting worker discovery
00:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:25 DISPATCHER: Finished worker discovery
00:55:25 DISPATCHER: Starting worker discovery
00:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:25 DISPATCHER: Finished worker discovery
00:56:25 DISPATCHER: Starting worker discovery
00:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:25 DISPATCHER: Finished worker discovery
00:57:25 DISPATCHER: Starting worker discovery
00:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:25 DISPATCHER: Finished worker discovery
00:58:25 DISPATCHER: Starting worker discovery
00:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:26 DISPATCHER: Finished worker discovery
00:59:26 DISPATCHER: Starting worker discovery
00:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:26 DISPATCHER: Finished worker discovery
01:00:26 DISPATCHER: Starting worker discovery
01:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:26 DISPATCHER: Finished worker discovery
01:00:37 WORKER: done with job (1, 0, 4), trying to register it.
01:00:37 WORKER: registered result for job (1, 0, 4) with dispatcher
01:00:37 DISPATCHER: job (1, 0, 4) finished
01:00:37 DISPATCHER: register_result: lock acquired
01:00:37 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:00:37 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 12, 'lr': 0.05978539674832851, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.10886909953126019}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 12, 'lr': 0.05978539674832851, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.10886909953126019}"}}
exception: None

01:00:37 job_callback for (1, 0, 4) started
01:00:37 job_callback for (1, 0, 4) got condition
01:00:37 DISPATCHER: Trying to submit another job.
01:00:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:00:37 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:00:37 HBMASTER: Trying to run another job!
01:00:37 job_callback for (1, 0, 4) finished
01:00:37 HBMASTER: schedule new run for iteration 1
01:00:37 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
01:00:37 HBMASTER: submitting job (1, 0, 6) to dispatcher
01:00:37 DISPATCHER: trying to submit job (1, 0, 6)
01:00:37 DISPATCHER: trying to notify the job_runner thread.
01:00:37 HBMASTER: job (1, 0, 6) submitted to dispatcher
01:00:37 DISPATCHER: Trying to submit another job.
01:00:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:00:37 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:00:37 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:00:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:00:37 WORKER: start processing job (1, 0, 6)
01:00:37 WORKER: args: ()
01:00:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:01:26 DISPATCHER: Starting worker discovery
01:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:26 DISPATCHER: Finished worker discovery
01:02:26 DISPATCHER: Starting worker discovery
01:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:26 DISPATCHER: Finished worker discovery
01:03:26 DISPATCHER: Starting worker discovery
01:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:26 DISPATCHER: Finished worker discovery
01:04:26 DISPATCHER: Starting worker discovery
01:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:26 DISPATCHER: Finished worker discovery
01:05:26 DISPATCHER: Starting worker discovery
01:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:26 DISPATCHER: Finished worker discovery
01:06:26 DISPATCHER: Starting worker discovery
01:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:26 DISPATCHER: Finished worker discovery
01:07:25 WORKER: done with job (1, 0, 6), trying to register it.
01:07:25 WORKER: registered result for job (1, 0, 6) with dispatcher
01:07:25 DISPATCHER: job (1, 0, 6) finished
01:07:25 DISPATCHER: register_result: lock acquired
01:07:25 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:07:25 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.047412301374755196, 'info': {'number_mnist': 0.047412301374755196, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}"}}
exception: None

01:07:25 job_callback for (1, 0, 6) started
01:07:25 DISPATCHER: Trying to submit another job.
01:07:25 job_callback for (1, 0, 6) got condition
01:07:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:25 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:07:25 HBMASTER: Trying to run another job!
01:07:25 job_callback for (1, 0, 6) finished
01:07:25 ITERATION: Advancing config (1, 0, 6) to next budget 1200.000000
01:07:25 HBMASTER: schedule new run for iteration 1
01:07:25 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
01:07:25 HBMASTER: submitting job (1, 0, 6) to dispatcher
01:07:25 DISPATCHER: trying to submit job (1, 0, 6)
01:07:25 DISPATCHER: trying to notify the job_runner thread.
01:07:25 HBMASTER: job (1, 0, 6) submitted to dispatcher
01:07:25 DISPATCHER: Trying to submit another job.
01:07:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:25 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:07:25 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:07:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:25 WORKER: start processing job (1, 0, 6)
01:07:25 WORKER: args: ()
01:07:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}, 'budget': 1200.0, 'working_directory': '.'}
01:07:26 DISPATCHER: Starting worker discovery
01:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:26 DISPATCHER: Finished worker discovery
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:08:26 DISPATCHER: Starting worker discovery
01:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:26 DISPATCHER: Finished worker discovery
01:09:26 DISPATCHER: Starting worker discovery
01:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:26 DISPATCHER: Finished worker discovery
01:10:26 DISPATCHER: Starting worker discovery
01:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:26 DISPATCHER: Finished worker discovery
01:11:26 DISPATCHER: Starting worker discovery
01:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:26 DISPATCHER: Finished worker discovery
01:12:26 DISPATCHER: Starting worker discovery
01:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:26 DISPATCHER: Finished worker discovery
01:13:26 DISPATCHER: Starting worker discovery
01:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:26 DISPATCHER: Finished worker discovery
01:14:26 DISPATCHER: Starting worker discovery
01:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:26 DISPATCHER: Finished worker discovery
01:15:26 DISPATCHER: Starting worker discovery
01:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:26 DISPATCHER: Finished worker discovery
01:16:26 DISPATCHER: Starting worker discovery
01:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:26 DISPATCHER: Finished worker discovery
01:17:26 DISPATCHER: Starting worker discovery
01:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:26 DISPATCHER: Finished worker discovery
01:18:26 DISPATCHER: Starting worker discovery
01:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:26 DISPATCHER: Finished worker discovery
01:19:26 DISPATCHER: Starting worker discovery
01:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:26 DISPATCHER: Finished worker discovery
01:20:26 DISPATCHER: Starting worker discovery
01:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:26 DISPATCHER: Finished worker discovery
01:21:26 DISPATCHER: Starting worker discovery
01:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:26 DISPATCHER: Finished worker discovery
01:22:26 DISPATCHER: Starting worker discovery
01:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:26 DISPATCHER: Finished worker discovery
01:23:26 DISPATCHER: Starting worker discovery
01:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:26 DISPATCHER: Finished worker discovery
01:24:26 DISPATCHER: Starting worker discovery
01:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:26 DISPATCHER: Finished worker discovery
01:25:26 DISPATCHER: Starting worker discovery
01:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:26 DISPATCHER: Finished worker discovery
01:26:26 DISPATCHER: Starting worker discovery
01:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:26 DISPATCHER: Finished worker discovery
01:27:26 DISPATCHER: Starting worker discovery
01:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:26 DISPATCHER: Finished worker discovery
01:27:33 WORKER: done with job (1, 0, 6), trying to register it.
01:27:33 WORKER: registered result for job (1, 0, 6) with dispatcher
01:27:33 DISPATCHER: job (1, 0, 6) finished
01:27:33 DISPATCHER: register_result: lock acquired
01:27:33 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:27:33 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0.01353102207685022, 'info': {'number_mnist': -0.01353102207685022, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.005424077222799931, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.05854536320854627}"}}
exception: None

01:27:33 job_callback for (1, 0, 6) started
01:27:33 job_callback for (1, 0, 6) got condition
01:27:33 DISPATCHER: Trying to submit another job.
01:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:33 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
01:27:33 HBMASTER: Trying to run another job!
01:27:33 job_callback for (1, 0, 6) finished
01:27:33 start sampling a new configuration.
01:27:33 done sampling a new configuration.
01:27:33 HBMASTER: schedule new run for iteration 2
01:27:33 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
01:27:33 HBMASTER: submitting job (2, 0, 0) to dispatcher
01:27:33 DISPATCHER: trying to submit job (2, 0, 0)
01:27:33 DISPATCHER: trying to notify the job_runner thread.
01:27:33 HBMASTER: job (2, 0, 0) submitted to dispatcher
01:27:33 DISPATCHER: Trying to submit another job.
01:27:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:33 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:27:33 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:33 WORKER: start processing job (2, 0, 0)
01:27:33 WORKER: args: ()
01:27:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 43, 'lr': 0.042658897340465025, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.02242680556031745}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:28:26 DISPATCHER: Starting worker discovery
01:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:26 DISPATCHER: Finished worker discovery
01:29:26 DISPATCHER: Starting worker discovery
01:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:26 DISPATCHER: Finished worker discovery
01:30:26 DISPATCHER: Starting worker discovery
01:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:26 DISPATCHER: Finished worker discovery
01:31:26 DISPATCHER: Starting worker discovery
01:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:26 DISPATCHER: Finished worker discovery
01:32:26 DISPATCHER: Starting worker discovery
01:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:26 DISPATCHER: Finished worker discovery
01:33:26 DISPATCHER: Starting worker discovery
01:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:26 DISPATCHER: Finished worker discovery
01:34:22 WORKER: done with job (2, 0, 0), trying to register it.
01:34:22 WORKER: registered result for job (2, 0, 0) with dispatcher
01:34:22 DISPATCHER: job (2, 0, 0) finished
01:34:22 DISPATCHER: register_result: lock acquired
01:34:22 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:34:22 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 43, 'lr': 0.042658897340465025, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.02242680556031745}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 43, 'lr': 0.042658897340465025, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.02242680556031745}"}}
exception: None

01:34:22 job_callback for (2, 0, 0) started
01:34:22 job_callback for (2, 0, 0) got condition
01:34:22 DISPATCHER: Trying to submit another job.
01:34:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:34:22 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:34:22 HBMASTER: Trying to run another job!
01:34:22 job_callback for (2, 0, 0) finished
01:34:22 start sampling a new configuration.
01:34:22 done sampling a new configuration.
01:34:22 HBMASTER: schedule new run for iteration 2
01:34:22 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
01:34:22 HBMASTER: submitting job (2, 0, 1) to dispatcher
01:34:22 DISPATCHER: trying to submit job (2, 0, 1)
01:34:22 DISPATCHER: trying to notify the job_runner thread.
01:34:22 HBMASTER: job (2, 0, 1) submitted to dispatcher
01:34:22 DISPATCHER: Trying to submit another job.
01:34:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:34:22 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:34:22 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:34:22 WORKER: start processing job (2, 0, 1)
01:34:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:34:22 WORKER: args: ()
01:34:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 19, 'lr': 0.0050233175129015374, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.017862990222830874}, 'budget': 400.0, 'working_directory': '.'}
01:34:26 DISPATCHER: Starting worker discovery
01:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:26 DISPATCHER: Finished worker discovery
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:35:26 DISPATCHER: Starting worker discovery
01:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:26 DISPATCHER: Finished worker discovery
01:36:26 DISPATCHER: Starting worker discovery
01:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:26 DISPATCHER: Finished worker discovery
01:37:26 DISPATCHER: Starting worker discovery
01:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:26 DISPATCHER: Finished worker discovery
01:38:26 DISPATCHER: Starting worker discovery
01:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:26 DISPATCHER: Finished worker discovery
01:39:26 DISPATCHER: Starting worker discovery
01:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:26 DISPATCHER: Finished worker discovery
01:40:26 DISPATCHER: Starting worker discovery
01:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:26 DISPATCHER: Finished worker discovery
01:41:10 WORKER: done with job (2, 0, 1), trying to register it.
01:41:10 WORKER: registered result for job (2, 0, 1) with dispatcher
01:41:10 DISPATCHER: job (2, 0, 1) finished
01:41:10 DISPATCHER: register_result: lock acquired
01:41:10 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:41:10 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 19, 'lr': 0.0050233175129015374, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.017862990222830874}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 19, 'lr': 0.0050233175129015374, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.017862990222830874}"}}
exception: None

01:41:10 job_callback for (2, 0, 1) started
01:41:10 DISPATCHER: Trying to submit another job.
01:41:10 job_callback for (2, 0, 1) got condition
01:41:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:41:10 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
01:41:10 HBMASTER: Trying to run another job!
01:41:10 job_callback for (2, 0, 1) finished
01:41:10 start sampling a new configuration.
01:41:10 done sampling a new configuration.
01:41:10 HBMASTER: schedule new run for iteration 2
01:41:10 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
01:41:10 HBMASTER: submitting job (2, 0, 2) to dispatcher
01:41:10 DISPATCHER: trying to submit job (2, 0, 2)
01:41:10 DISPATCHER: trying to notify the job_runner thread.
01:41:10 HBMASTER: job (2, 0, 2) submitted to dispatcher
01:41:10 DISPATCHER: Trying to submit another job.
01:41:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:41:10 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:41:10 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:41:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:41:10 WORKER: start processing job (2, 0, 2)
01:41:10 WORKER: args: ()
01:41:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 43, 'lr': 0.0038396411437296315, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.039298494290211164}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:41:26 DISPATCHER: Starting worker discovery
01:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:26 DISPATCHER: Finished worker discovery
01:42:26 DISPATCHER: Starting worker discovery
01:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:26 DISPATCHER: Finished worker discovery
01:43:26 DISPATCHER: Starting worker discovery
01:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:26 DISPATCHER: Finished worker discovery
01:44:26 DISPATCHER: Starting worker discovery
01:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:26 DISPATCHER: Finished worker discovery
01:45:26 DISPATCHER: Starting worker discovery
01:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:26 DISPATCHER: Finished worker discovery
01:46:26 DISPATCHER: Starting worker discovery
01:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:26 DISPATCHER: Finished worker discovery
01:47:26 DISPATCHER: Starting worker discovery
01:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:26 DISPATCHER: Finished worker discovery
01:47:58 WORKER: done with job (2, 0, 2), trying to register it.
01:47:58 WORKER: registered result for job (2, 0, 2) with dispatcher
01:47:58 DISPATCHER: job (2, 0, 2) finished
01:47:58 DISPATCHER: register_result: lock acquired
01:47:58 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:47:58 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 43, 'lr': 0.0038396411437296315, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.039298494290211164}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.020676215405983037, 'info': {'number_mnist': -0.020676215405983037, 'config': "{'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 43, 'lr': 0.0038396411437296315, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.039298494290211164}"}}
exception: None

01:47:58 job_callback for (2, 0, 2) started
01:47:58 job_callback for (2, 0, 2) got condition
01:47:58 DISPATCHER: Trying to submit another job.
01:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:47:58 HBMASTER: Trying to run another job!
01:47:58 job_callback for (2, 0, 2) finished
01:47:58 start sampling a new configuration.
01:47:58 best_vector: [1, 0.9497054349238426, 0.8680820491509054, 0.5008595215698544, 0.17158950434985265, 0, 0.9197892844331591, 0.2266407879847105], 0.01689360461577483, 0.0715348855901396, 0.0012084820733945067
01:47:58 done sampling a new configuration.
01:47:58 HBMASTER: schedule new run for iteration 2
01:47:58 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
01:47:58 HBMASTER: submitting job (2, 0, 3) to dispatcher
01:47:58 DISPATCHER: trying to submit job (2, 0, 3)
01:47:58 DISPATCHER: trying to notify the job_runner thread.
01:47:58 HBMASTER: job (2, 0, 3) submitted to dispatcher
01:47:58 DISPATCHER: Trying to submit another job.
01:47:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:47:58 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:47:58 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:47:58 WORKER: start processing job (2, 0, 3)
01:47:58 WORKER: args: ()
01:47:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.010039660872982796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01971816350057307}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:48:26 DISPATCHER: Starting worker discovery
01:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:26 DISPATCHER: Finished worker discovery
01:49:26 DISPATCHER: Starting worker discovery
01:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:26 DISPATCHER: Finished worker discovery
01:50:26 DISPATCHER: Starting worker discovery
01:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:26 DISPATCHER: Finished worker discovery
01:51:26 DISPATCHER: Starting worker discovery
01:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:26 DISPATCHER: Finished worker discovery
01:52:26 DISPATCHER: Starting worker discovery
01:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:26 DISPATCHER: Finished worker discovery
01:53:26 DISPATCHER: Starting worker discovery
01:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:26 DISPATCHER: Finished worker discovery
01:54:26 DISPATCHER: Starting worker discovery
01:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:26 DISPATCHER: Finished worker discovery
01:54:46 WORKER: done with job (2, 0, 3), trying to register it.
01:54:46 WORKER: registered result for job (2, 0, 3) with dispatcher
01:54:46 DISPATCHER: job (2, 0, 3) finished
01:54:46 DISPATCHER: register_result: lock acquired
01:54:46 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
01:54:46 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.010039660872982796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01971816350057307}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5762864678834164, 'info': {'number_mnist': 0.5762864678834164, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.010039660872982796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01971816350057307}"}}
exception: None

01:54:46 job_callback for (2, 0, 3) started
01:54:46 DISPATCHER: Trying to submit another job.
01:54:46 job_callback for (2, 0, 3) got condition
01:54:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:54:46 HBMASTER: Trying to run another job!
01:54:46 job_callback for (2, 0, 3) finished
01:54:46 start sampling a new configuration.
01:54:46 best_vector: [3, 0.1904490272226731, 0.017746871800699587, 0.9660075541500234, 0.6120613958715804, 1, 0.8634421046356844, 0.9075921197828082], 0.004071611735312794, 0.3040621622887746, 0.0012380230682395579
01:54:46 done sampling a new configuration.
01:54:46 HBMASTER: schedule new run for iteration 2
01:54:46 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
01:54:46 HBMASTER: submitting job (2, 0, 4) to dispatcher
01:54:46 DISPATCHER: trying to submit job (2, 0, 4)
01:54:46 DISPATCHER: trying to notify the job_runner thread.
01:54:46 HBMASTER: job (2, 0, 4) submitted to dispatcher
01:54:46 DISPATCHER: Trying to submit another job.
01:54:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:54:46 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
01:54:46 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
01:54:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:54:46 WORKER: start processing job (2, 0, 4)
01:54:46 WORKER: args: ()
01:54:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 1, 'lr': 0.08550964595881448, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.15163678629759303}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:55:26 DISPATCHER: Starting worker discovery
01:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:26 DISPATCHER: Finished worker discovery
01:56:26 DISPATCHER: Starting worker discovery
01:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:26 DISPATCHER: Finished worker discovery
01:57:26 DISPATCHER: Starting worker discovery
01:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:26 DISPATCHER: Finished worker discovery
01:58:26 DISPATCHER: Starting worker discovery
01:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:26 DISPATCHER: Finished worker discovery
01:59:26 DISPATCHER: Starting worker discovery
01:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:26 DISPATCHER: Finished worker discovery
02:00:26 DISPATCHER: Starting worker discovery
02:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:26 DISPATCHER: Finished worker discovery
02:01:26 DISPATCHER: Starting worker discovery
02:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:26 DISPATCHER: Finished worker discovery
02:01:34 WORKER: done with job (2, 0, 4), trying to register it.
02:01:34 WORKER: registered result for job (2, 0, 4) with dispatcher
02:01:34 DISPATCHER: job (2, 0, 4) finished
02:01:34 DISPATCHER: register_result: lock acquired
02:01:34 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:01:34 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 1, 'lr': 0.08550964595881448, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.15163678629759303}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 1, 'lr': 0.08550964595881448, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.15163678629759303}"}}
exception: None

02:01:34 job_callback for (2, 0, 4) started
02:01:34 DISPATCHER: Trying to submit another job.
02:01:34 job_callback for (2, 0, 4) got condition
02:01:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:01:34 HBMASTER: Trying to run another job!
02:01:34 job_callback for (2, 0, 4) finished
02:01:34 start sampling a new configuration.
02:01:34 best_vector: [1, 0.5648344734956182, 0.8456104671051693, 0.684402429002477, 0.15707674113848838, 0, 0.9135162564113033, 0.05984827830733713], 0.023036231283786943, 0.03871016350538867, 0.000891736279543342
02:01:34 done sampling a new configuration.
02:01:34 HBMASTER: schedule new run for iteration 2
02:01:34 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
02:01:34 HBMASTER: submitting job (2, 0, 5) to dispatcher
02:01:34 DISPATCHER: trying to submit job (2, 0, 5)
02:01:34 DISPATCHER: trying to notify the job_runner thread.
02:01:34 HBMASTER: job (2, 0, 5) submitted to dispatcher
02:01:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:01:34 DISPATCHER: Trying to submit another job.
02:01:34 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:01:34 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:01:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:01:34 WORKER: start processing job (2, 0, 5)
02:01:34 WORKER: args: ()
02:01:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 43, 'lr': 0.023377865625382934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01196366945202721}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:02:26 DISPATCHER: Starting worker discovery
02:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:26 DISPATCHER: Finished worker discovery
02:03:26 DISPATCHER: Starting worker discovery
02:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:26 DISPATCHER: Finished worker discovery
02:04:26 DISPATCHER: Starting worker discovery
02:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:26 DISPATCHER: Finished worker discovery
02:05:26 DISPATCHER: Starting worker discovery
02:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:26 DISPATCHER: Finished worker discovery
02:06:26 DISPATCHER: Starting worker discovery
02:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:26 DISPATCHER: Finished worker discovery
02:07:26 DISPATCHER: Starting worker discovery
02:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:26 DISPATCHER: Finished worker discovery
02:08:23 WORKER: done with job (2, 0, 5), trying to register it.
02:08:23 WORKER: registered result for job (2, 0, 5) with dispatcher
02:08:23 DISPATCHER: job (2, 0, 5) finished
02:08:23 DISPATCHER: register_result: lock acquired
02:08:23 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:08:23 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 43, 'lr': 0.023377865625382934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01196366945202721}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.39227134186908585, 'info': {'number_mnist': 0.39227134186908585, 'config': "{'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 43, 'lr': 0.023377865625382934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01196366945202721}"}}
exception: None

02:08:23 job_callback for (2, 0, 5) started
02:08:23 DISPATCHER: Trying to submit another job.
02:08:23 job_callback for (2, 0, 5) got condition
02:08:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:23 HBMASTER: Trying to run another job!
02:08:23 job_callback for (2, 0, 5) finished
02:08:23 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
02:08:23 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
02:08:23 HBMASTER: schedule new run for iteration 2
02:08:23 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
02:08:23 HBMASTER: submitting job (2, 0, 3) to dispatcher
02:08:23 DISPATCHER: trying to submit job (2, 0, 3)
02:08:23 DISPATCHER: trying to notify the job_runner thread.
02:08:23 HBMASTER: job (2, 0, 3) submitted to dispatcher
02:08:23 DISPATCHER: Trying to submit another job.
02:08:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:23 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:08:23 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:08:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:23 WORKER: start processing job (2, 0, 3)
02:08:23 WORKER: args: ()
02:08:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.010039660872982796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01971816350057307}, 'budget': 1200.0, 'working_directory': '.'}
02:08:26 DISPATCHER: Starting worker discovery
02:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:26 DISPATCHER: Finished worker discovery
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:09:26 DISPATCHER: Starting worker discovery
02:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:26 DISPATCHER: Finished worker discovery
02:10:26 DISPATCHER: Starting worker discovery
02:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:26 DISPATCHER: Finished worker discovery
02:11:26 DISPATCHER: Starting worker discovery
02:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:26 DISPATCHER: Finished worker discovery
02:12:26 DISPATCHER: Starting worker discovery
02:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:26 DISPATCHER: Finished worker discovery
02:13:26 DISPATCHER: Starting worker discovery
02:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:26 DISPATCHER: Finished worker discovery
02:14:26 DISPATCHER: Starting worker discovery
02:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:26 DISPATCHER: Finished worker discovery
02:15:26 DISPATCHER: Starting worker discovery
02:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:26 DISPATCHER: Finished worker discovery
02:16:26 DISPATCHER: Starting worker discovery
02:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:26 DISPATCHER: Finished worker discovery
02:17:26 DISPATCHER: Starting worker discovery
02:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:26 DISPATCHER: Finished worker discovery
02:18:26 DISPATCHER: Starting worker discovery
02:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:26 DISPATCHER: Finished worker discovery
02:19:26 DISPATCHER: Starting worker discovery
02:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:26 DISPATCHER: Finished worker discovery
02:20:26 DISPATCHER: Starting worker discovery
02:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:26 DISPATCHER: Finished worker discovery
02:21:26 DISPATCHER: Starting worker discovery
02:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:26 DISPATCHER: Finished worker discovery
02:22:26 DISPATCHER: Starting worker discovery
02:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:26 DISPATCHER: Finished worker discovery
02:23:26 DISPATCHER: Starting worker discovery
02:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:26 DISPATCHER: Finished worker discovery
02:24:26 DISPATCHER: Starting worker discovery
02:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:26 DISPATCHER: Finished worker discovery
02:25:26 DISPATCHER: Starting worker discovery
02:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:26 DISPATCHER: Finished worker discovery
02:26:26 DISPATCHER: Starting worker discovery
02:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:26 DISPATCHER: Finished worker discovery
02:27:26 DISPATCHER: Starting worker discovery
02:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:26 DISPATCHER: Finished worker discovery
02:28:26 DISPATCHER: Starting worker discovery
02:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:26 DISPATCHER: Finished worker discovery
02:28:31 WORKER: done with job (2, 0, 3), trying to register it.
02:28:31 WORKER: registered result for job (2, 0, 3) with dispatcher
02:28:31 DISPATCHER: job (2, 0, 3) finished
02:28:31 DISPATCHER: register_result: lock acquired
02:28:31 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:28:31 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.010039660872982796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01971816350057307}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6999867305359196, 'info': {'number_mnist': 0.6999867305359196, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.010039660872982796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01971816350057307}"}}
exception: None

02:28:31 job_callback for (2, 0, 3) started
02:28:31 job_callback for (2, 0, 3) got condition
02:28:31 DISPATCHER: Trying to submit another job.
02:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:28:31 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
02:28:31 HBMASTER: Trying to run another job!
02:28:31 job_callback for (2, 0, 3) finished
02:28:31 HBMASTER: schedule new run for iteration 2
02:28:31 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
02:28:31 HBMASTER: submitting job (2, 0, 5) to dispatcher
02:28:31 DISPATCHER: trying to submit job (2, 0, 5)
02:28:31 DISPATCHER: trying to notify the job_runner thread.
02:28:31 HBMASTER: job (2, 0, 5) submitted to dispatcher
02:28:31 DISPATCHER: Trying to submit another job.
02:28:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:28:31 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:28:31 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:28:31 WORKER: start processing job (2, 0, 5)
02:28:31 WORKER: args: ()
02:28:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 43, 'lr': 0.023377865625382934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01196366945202721}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:29:26 DISPATCHER: Starting worker discovery
02:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:26 DISPATCHER: Finished worker discovery
02:30:26 DISPATCHER: Starting worker discovery
02:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:26 DISPATCHER: Finished worker discovery
02:31:26 DISPATCHER: Starting worker discovery
02:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:26 DISPATCHER: Finished worker discovery
02:32:26 DISPATCHER: Starting worker discovery
02:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:26 DISPATCHER: Finished worker discovery
02:33:26 DISPATCHER: Starting worker discovery
02:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:26 DISPATCHER: Finished worker discovery
02:34:26 DISPATCHER: Starting worker discovery
02:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:26 DISPATCHER: Finished worker discovery
02:35:26 DISPATCHER: Starting worker discovery
02:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:26 DISPATCHER: Finished worker discovery
02:36:26 DISPATCHER: Starting worker discovery
02:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:26 DISPATCHER: Finished worker discovery
02:37:26 DISPATCHER: Starting worker discovery
02:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:26 DISPATCHER: Finished worker discovery
02:38:26 DISPATCHER: Starting worker discovery
02:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:26 DISPATCHER: Finished worker discovery
02:39:26 DISPATCHER: Starting worker discovery
02:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:26 DISPATCHER: Finished worker discovery
02:40:26 DISPATCHER: Starting worker discovery
02:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:26 DISPATCHER: Finished worker discovery
02:41:26 DISPATCHER: Starting worker discovery
02:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:26 DISPATCHER: Finished worker discovery
02:42:26 DISPATCHER: Starting worker discovery
02:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:26 DISPATCHER: Finished worker discovery
02:43:26 DISPATCHER: Starting worker discovery
02:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:26 DISPATCHER: Finished worker discovery
02:44:26 DISPATCHER: Starting worker discovery
02:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:26 DISPATCHER: Finished worker discovery
02:45:26 DISPATCHER: Starting worker discovery
02:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:26 DISPATCHER: Finished worker discovery
02:46:26 DISPATCHER: Starting worker discovery
02:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:26 DISPATCHER: Finished worker discovery
02:47:26 DISPATCHER: Starting worker discovery
02:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:26 DISPATCHER: Finished worker discovery
02:48:26 DISPATCHER: Starting worker discovery
02:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:26 DISPATCHER: Finished worker discovery
02:48:39 WORKER: done with job (2, 0, 5), trying to register it.
02:48:39 WORKER: registered result for job (2, 0, 5) with dispatcher
02:48:39 DISPATCHER: job (2, 0, 5) finished
02:48:39 DISPATCHER: register_result: lock acquired
02:48:39 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
02:48:39 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 43, 'lr': 0.023377865625382934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01196366945202721}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.33199648008933136, 'info': {'number_mnist': 0.33199648008933136, 'config': "{'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 43, 'lr': 0.023377865625382934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.01196366945202721}"}}
exception: None

02:48:39 job_callback for (2, 0, 5) started
02:48:39 job_callback for (2, 0, 5) got condition
02:48:39 DISPATCHER: Trying to submit another job.
02:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:48:39 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
02:48:39 HBMASTER: Trying to run another job!
02:48:39 job_callback for (2, 0, 5) finished
02:48:39 start sampling a new configuration.
02:48:39 best_vector: [0, 0.3702373330434258, 0.8536272171317334, 0.5751387188725067, 0.056488449406607556, 1, 0.984728568693765, 0.06151427389075268], 0.02316030490672901, 0.03009615715343271, 0.000697036176194335
02:48:39 done sampling a new configuration.
02:48:39 HBMASTER: schedule new run for iteration 3
02:48:39 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
02:48:39 HBMASTER: submitting job (3, 0, 0) to dispatcher
02:48:39 DISPATCHER: trying to submit job (3, 0, 0)
02:48:39 DISPATCHER: trying to notify the job_runner thread.
02:48:39 HBMASTER: job (3, 0, 0) submitted to dispatcher
02:48:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:48:39 DISPATCHER: Trying to submit another job.
02:48:39 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
02:48:39 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
02:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:48:39 WORKER: start processing job (3, 0, 0)
02:48:39 WORKER: args: ()
02:48:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 49, 'last_n_outputs': 43, 'lr': 0.014134401958165555, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.0120235279004009}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:49:26 DISPATCHER: Starting worker discovery
02:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:26 DISPATCHER: Finished worker discovery
02:50:26 DISPATCHER: Starting worker discovery
02:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:26 DISPATCHER: Finished worker discovery
02:51:26 DISPATCHER: Starting worker discovery
02:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:26 DISPATCHER: Finished worker discovery
02:52:26 DISPATCHER: Starting worker discovery
02:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:26 DISPATCHER: Finished worker discovery
02:53:26 DISPATCHER: Starting worker discovery
02:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:26 DISPATCHER: Finished worker discovery
02:54:26 DISPATCHER: Starting worker discovery
02:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:26 DISPATCHER: Finished worker discovery
02:55:26 DISPATCHER: Starting worker discovery
02:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:26 DISPATCHER: Finished worker discovery
02:56:26 DISPATCHER: Starting worker discovery
02:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:26 DISPATCHER: Finished worker discovery
02:57:26 DISPATCHER: Starting worker discovery
02:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:26 DISPATCHER: Finished worker discovery
02:58:26 DISPATCHER: Starting worker discovery
02:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:26 DISPATCHER: Finished worker discovery
02:59:26 DISPATCHER: Starting worker discovery
02:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:26 DISPATCHER: Finished worker discovery
03:00:26 DISPATCHER: Starting worker discovery
03:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:26 DISPATCHER: Finished worker discovery
03:01:26 DISPATCHER: Starting worker discovery
03:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:26 DISPATCHER: Finished worker discovery
03:02:26 DISPATCHER: Starting worker discovery
03:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:26 DISPATCHER: Finished worker discovery
03:03:26 DISPATCHER: Starting worker discovery
03:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:26 DISPATCHER: Finished worker discovery
03:04:26 DISPATCHER: Starting worker discovery
03:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:26 DISPATCHER: Finished worker discovery
03:05:26 DISPATCHER: Starting worker discovery
03:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:26 DISPATCHER: Finished worker discovery
03:06:26 DISPATCHER: Starting worker discovery
03:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:26 DISPATCHER: Finished worker discovery
03:07:26 DISPATCHER: Starting worker discovery
03:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:26 DISPATCHER: Finished worker discovery
03:08:26 DISPATCHER: Starting worker discovery
03:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:26 DISPATCHER: Finished worker discovery
03:08:47 WORKER: done with job (3, 0, 0), trying to register it.
03:08:47 WORKER: registered result for job (3, 0, 0) with dispatcher
03:08:47 DISPATCHER: job (3, 0, 0) finished
03:08:47 DISPATCHER: register_result: lock acquired
03:08:47 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:08:47 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 49, 'last_n_outputs': 43, 'lr': 0.014134401958165555, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.0120235279004009}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.07629093338860585, 'info': {'number_mnist': 0.07629093338860585, 'config': "{'batch_size': 16, 'hidden_dim': 49, 'last_n_outputs': 43, 'lr': 0.014134401958165555, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.0120235279004009}"}}
exception: None

03:08:47 job_callback for (3, 0, 0) started
03:08:47 job_callback for (3, 0, 0) got condition
03:08:47 DISPATCHER: Trying to submit another job.
03:08:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:08:47 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:08:47 HBMASTER: Trying to run another job!
03:08:47 job_callback for (3, 0, 0) finished
03:08:47 start sampling a new configuration.
03:08:47 best_vector: [0, 0.8371537984624389, 0.8483130823407746, 0.4026787956615144, 0.3194387893437086, 0, 0.9087893154560092, 0.6919376910654161], 0.017737525721084963, 0.05651704832049383, 0.001002472598264561
03:08:47 done sampling a new configuration.
03:08:47 HBMASTER: schedule new run for iteration 3
03:08:47 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
03:08:47 HBMASTER: submitting job (3, 0, 1) to dispatcher
03:08:47 DISPATCHER: trying to submit job (3, 0, 1)
03:08:47 DISPATCHER: trying to notify the job_runner thread.
03:08:47 HBMASTER: job (3, 0, 1) submitted to dispatcher
03:08:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:08:47 DISPATCHER: Trying to submit another job.
03:08:47 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:08:47 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:08:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:08:47 WORKER: start processing job (3, 0, 1)
03:08:47 WORKER: args: ()
03:08:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 43, 'lr': 0.0063878923883852095, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.07947521129333267}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:09:26 DISPATCHER: Starting worker discovery
03:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:26 DISPATCHER: Finished worker discovery
03:10:26 DISPATCHER: Starting worker discovery
03:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:26 DISPATCHER: Finished worker discovery
03:11:26 DISPATCHER: Starting worker discovery
03:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:26 DISPATCHER: Finished worker discovery
03:12:26 DISPATCHER: Starting worker discovery
03:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:26 DISPATCHER: Finished worker discovery
03:13:26 DISPATCHER: Starting worker discovery
03:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:26 DISPATCHER: Finished worker discovery
03:14:26 DISPATCHER: Starting worker discovery
03:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:26 DISPATCHER: Finished worker discovery
03:15:26 DISPATCHER: Starting worker discovery
03:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:26 DISPATCHER: Finished worker discovery
03:16:26 DISPATCHER: Starting worker discovery
03:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:26 DISPATCHER: Finished worker discovery
03:17:26 DISPATCHER: Starting worker discovery
03:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:26 DISPATCHER: Finished worker discovery
03:18:26 DISPATCHER: Starting worker discovery
03:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:26 DISPATCHER: Finished worker discovery
03:19:26 DISPATCHER: Starting worker discovery
03:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:26 DISPATCHER: Finished worker discovery
03:20:26 DISPATCHER: Starting worker discovery
03:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:26 DISPATCHER: Finished worker discovery
03:21:26 DISPATCHER: Starting worker discovery
03:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:26 DISPATCHER: Finished worker discovery
03:22:26 DISPATCHER: Starting worker discovery
03:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:26 DISPATCHER: Finished worker discovery
03:23:26 DISPATCHER: Starting worker discovery
03:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:26 DISPATCHER: Finished worker discovery
03:24:26 DISPATCHER: Starting worker discovery
03:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:26 DISPATCHER: Finished worker discovery
03:25:26 DISPATCHER: Starting worker discovery
03:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:26 DISPATCHER: Finished worker discovery
03:26:26 DISPATCHER: Starting worker discovery
03:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:26 DISPATCHER: Finished worker discovery
03:27:26 DISPATCHER: Starting worker discovery
03:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:26 DISPATCHER: Finished worker discovery
03:28:26 DISPATCHER: Starting worker discovery
03:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:26 DISPATCHER: Finished worker discovery
03:28:55 WORKER: done with job (3, 0, 1), trying to register it.
03:28:55 WORKER: registered result for job (3, 0, 1) with dispatcher
03:28:55 DISPATCHER: job (3, 0, 1) finished
03:28:55 DISPATCHER: register_result: lock acquired
03:28:55 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:28:55 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 43, 'lr': 0.0063878923883852095, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.07947521129333267}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.03879932532734689, 'info': {'number_mnist': 0.03879932532734689, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 43, 'lr': 0.0063878923883852095, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.07947521129333267}"}}
exception: None

03:28:55 job_callback for (3, 0, 1) started
03:28:55 DISPATCHER: Trying to submit another job.
03:28:55 job_callback for (3, 0, 1) got condition
03:28:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:28:55 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:28:55 HBMASTER: Trying to run another job!
03:28:55 job_callback for (3, 0, 1) finished
03:28:55 start sampling a new configuration.
03:28:55 best_vector: [0, 0.7678570305760354, 0.9944212648503592, 0.5049590582472782, 0.19013613839176866, 1, 0.9355151552462262, 0.33314484977259196], 0.012481849537448709, 0.04482332935865099, 0.000559478052822189
03:28:55 done sampling a new configuration.
03:28:55 HBMASTER: schedule new run for iteration 3
03:28:55 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
03:28:55 HBMASTER: submitting job (3, 0, 2) to dispatcher
03:28:55 DISPATCHER: trying to submit job (3, 0, 2)
03:28:55 DISPATCHER: trying to notify the job_runner thread.
03:28:55 HBMASTER: job (3, 0, 2) submitted to dispatcher
03:28:55 DISPATCHER: Trying to submit another job.
03:28:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:28:55 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:28:55 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:28:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:28:55 WORKER: start processing job (3, 0, 2)
03:28:55 WORKER: args: ()
03:28:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 50, 'lr': 0.010231000749811469, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.02712885363400435}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:29:26 DISPATCHER: Starting worker discovery
03:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:26 DISPATCHER: Finished worker discovery
03:30:26 DISPATCHER: Starting worker discovery
03:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:26 DISPATCHER: Finished worker discovery
03:31:26 DISPATCHER: Starting worker discovery
03:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:26 DISPATCHER: Finished worker discovery
03:32:26 DISPATCHER: Starting worker discovery
03:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:27 DISPATCHER: Finished worker discovery
03:33:27 DISPATCHER: Starting worker discovery
03:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:27 DISPATCHER: Finished worker discovery
03:34:27 DISPATCHER: Starting worker discovery
03:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:27 DISPATCHER: Finished worker discovery
03:35:27 DISPATCHER: Starting worker discovery
03:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:27 DISPATCHER: Finished worker discovery
03:36:27 DISPATCHER: Starting worker discovery
03:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:27 DISPATCHER: Finished worker discovery
03:37:27 DISPATCHER: Starting worker discovery
03:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:27 DISPATCHER: Finished worker discovery
03:38:27 DISPATCHER: Starting worker discovery
03:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:27 DISPATCHER: Finished worker discovery
03:39:27 DISPATCHER: Starting worker discovery
03:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:27 DISPATCHER: Finished worker discovery
03:40:27 DISPATCHER: Starting worker discovery
03:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:27 DISPATCHER: Finished worker discovery
03:41:27 DISPATCHER: Starting worker discovery
03:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:27 DISPATCHER: Finished worker discovery
03:42:27 DISPATCHER: Starting worker discovery
03:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:27 DISPATCHER: Finished worker discovery
03:43:27 DISPATCHER: Starting worker discovery
03:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:27 DISPATCHER: Finished worker discovery
03:44:27 DISPATCHER: Starting worker discovery
03:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:27 DISPATCHER: Finished worker discovery
03:45:27 DISPATCHER: Starting worker discovery
03:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:27 DISPATCHER: Finished worker discovery
03:46:27 DISPATCHER: Starting worker discovery
03:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:27 DISPATCHER: Finished worker discovery
03:47:27 DISPATCHER: Starting worker discovery
03:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:27 DISPATCHER: Finished worker discovery
03:48:27 DISPATCHER: Starting worker discovery
03:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:27 DISPATCHER: Finished worker discovery
03:49:04 WORKER: done with job (3, 0, 2), trying to register it.
03:49:04 WORKER: registered result for job (3, 0, 2) with dispatcher
03:49:04 DISPATCHER: job (3, 0, 2) finished
03:49:04 DISPATCHER: register_result: lock acquired
03:49:04 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
03:49:04 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 50, 'lr': 0.010231000749811469, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.02712885363400435}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08134246837899323, 'info': {'number_mnist': 0.08134246837899323, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 50, 'lr': 0.010231000749811469, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.02712885363400435}"}}
exception: None

03:49:04 job_callback for (3, 0, 2) started
03:49:04 DISPATCHER: Trying to submit another job.
03:49:04 job_callback for (3, 0, 2) got condition
03:49:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:04 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:49:04 HBMASTER: Trying to run another job!
03:49:04 job_callback for (3, 0, 2) finished
03:49:04 start sampling a new configuration.
03:49:04 best_vector: [2, 0.9926160098628304, 0.933225553764236, 0.08992728293266228, 0.21667927122122982, 0, 0.7513230669790474, 0.5079103639587067], 0.018438058588118388, 0.26515093514467947, 0.004888868476891979
03:49:04 done sampling a new configuration.
03:49:04 HBMASTER: schedule new run for iteration 3
03:49:04 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
03:49:04 HBMASTER: submitting job (3, 0, 3) to dispatcher
03:49:04 DISPATCHER: trying to submit job (3, 0, 3)
03:49:04 DISPATCHER: trying to notify the job_runner thread.
03:49:04 HBMASTER: job (3, 0, 3) submitted to dispatcher
03:49:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:04 DISPATCHER: Trying to submit another job.
03:49:04 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
03:49:04 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
03:49:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:04 WORKER: start processing job (3, 0, 3)
03:49:04 WORKER: args: ()
03:49:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 47, 'lr': 0.0015130544802711412, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.04579379320420529}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:49:27 DISPATCHER: Starting worker discovery
03:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:27 DISPATCHER: Finished worker discovery
03:50:27 DISPATCHER: Starting worker discovery
03:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:27 DISPATCHER: Finished worker discovery
03:51:27 DISPATCHER: Starting worker discovery
03:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:27 DISPATCHER: Finished worker discovery
03:52:27 DISPATCHER: Starting worker discovery
03:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:27 DISPATCHER: Finished worker discovery
03:53:27 DISPATCHER: Starting worker discovery
03:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:27 DISPATCHER: Finished worker discovery
03:54:27 DISPATCHER: Starting worker discovery
03:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:27 DISPATCHER: Finished worker discovery
03:55:27 DISPATCHER: Starting worker discovery
03:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:27 DISPATCHER: Finished worker discovery
03:56:27 DISPATCHER: Starting worker discovery
03:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:27 DISPATCHER: Finished worker discovery
03:57:27 DISPATCHER: Starting worker discovery
03:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:27 DISPATCHER: Finished worker discovery
03:58:27 DISPATCHER: Starting worker discovery
03:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:27 DISPATCHER: Finished worker discovery
03:59:27 DISPATCHER: Starting worker discovery
03:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:27 DISPATCHER: Finished worker discovery
04:00:27 DISPATCHER: Starting worker discovery
04:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:27 DISPATCHER: Finished worker discovery
04:01:27 DISPATCHER: Starting worker discovery
04:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:27 DISPATCHER: Finished worker discovery
04:02:27 DISPATCHER: Starting worker discovery
04:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:27 DISPATCHER: Finished worker discovery
04:03:27 DISPATCHER: Starting worker discovery
04:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:27 DISPATCHER: Finished worker discovery
04:04:27 DISPATCHER: Starting worker discovery
04:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:27 DISPATCHER: Finished worker discovery
04:05:27 DISPATCHER: Starting worker discovery
04:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:27 DISPATCHER: Finished worker discovery
04:06:27 DISPATCHER: Starting worker discovery
04:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:27 DISPATCHER: Finished worker discovery
04:07:27 DISPATCHER: Starting worker discovery
04:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:27 DISPATCHER: Finished worker discovery
04:08:27 DISPATCHER: Starting worker discovery
04:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:27 DISPATCHER: Finished worker discovery
04:09:12 WORKER: done with job (3, 0, 3), trying to register it.
04:09:12 WORKER: registered result for job (3, 0, 3) with dispatcher
04:09:12 DISPATCHER: job (3, 0, 3) finished
04:09:12 DISPATCHER: register_result: lock acquired
04:09:12 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:09:12 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 47, 'lr': 0.0015130544802711412, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.04579379320420529}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.06264233130770015, 'info': {'number_mnist': 0.06264233130770015, 'config': "{'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 47, 'lr': 0.0015130544802711412, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.04579379320420529}"}}
exception: None

04:09:12 job_callback for (3, 0, 3) started
04:09:12 job_callback for (3, 0, 3) got condition
04:09:12 DISPATCHER: Trying to submit another job.
04:09:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:09:12 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:09:12 HBMASTER: Trying to run another job!
04:09:12 job_callback for (3, 0, 3) finished
04:09:12 start sampling a new configuration.
04:09:12 best_vector: [0, 0.8577264458443667, 0.6588350562431556, 0.2137365307700168, 0.28428455271278125, 0, 0.8652756513651771, 0.9117713884253791], 0.02344566616275517, 0.02240226056196845, 0.0005252359224269683
04:09:12 done sampling a new configuration.
04:09:12 HBMASTER: schedule new run for iteration 4
04:09:12 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
04:09:12 HBMASTER: submitting job (4, 0, 0) to dispatcher
04:09:12 DISPATCHER: trying to submit job (4, 0, 0)
04:09:12 DISPATCHER: trying to notify the job_runner thread.
04:09:12 HBMASTER: job (4, 0, 0) submitted to dispatcher
04:09:12 DISPATCHER: Trying to submit another job.
04:09:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:09:12 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:09:12 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:09:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:09:12 WORKER: start processing job (4, 0, 0)
04:09:12 WORKER: args: ()
04:09:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 33, 'lr': 0.0026759196058523177, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15354720856564433}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:09:27 DISPATCHER: Starting worker discovery
04:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:27 DISPATCHER: Finished worker discovery
04:10:04 WORKER: done with job (4, 0, 0), trying to register it.
04:10:04 WORKER: registered result for job (4, 0, 0) with dispatcher
04:10:04 DISPATCHER: job (4, 0, 0) finished
04:10:04 DISPATCHER: register_result: lock acquired
04:10:04 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:10:04 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 33, 'lr': 0.0026759196058523177, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15354720856564433}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04602646117375726, 'info': {'number_mnist': 0.04602646117375726, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 33, 'lr': 0.0026759196058523177, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15354720856564433}"}}
exception: None

04:10:04 job_callback for (4, 0, 0) started
04:10:04 DISPATCHER: Trying to submit another job.
04:10:04 job_callback for (4, 0, 0) got condition
04:10:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:04 HBMASTER: Trying to run another job!
04:10:04 job_callback for (4, 0, 0) finished
04:10:04 start sampling a new configuration.
04:10:04 best_vector: [1, 0.9269048976581589, 0.778124449680353, 0.4706127436061187, 0.18022315474876083, 0, 0.7146382233074899, 0.0578851996820528], 0.030245375620437123, 0.12014738243794668, 0.003633902711648008
04:10:04 done sampling a new configuration.
04:10:04 HBMASTER: schedule new run for iteration 4
04:10:04 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:10:04 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:10:04 DISPATCHER: trying to submit job (4, 0, 1)
04:10:04 DISPATCHER: trying to notify the job_runner thread.
04:10:04 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:10:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:04 DISPATCHER: Trying to submit another job.
04:10:04 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:10:04 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:10:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:04 WORKER: start processing job (4, 0, 1)
04:10:04 WORKER: args: ()
04:10:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:10:27 DISPATCHER: Starting worker discovery
04:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:27 DISPATCHER: Finished worker discovery
04:10:57 WORKER: done with job (4, 0, 1), trying to register it.
04:10:57 WORKER: registered result for job (4, 0, 1) with dispatcher
04:10:57 DISPATCHER: job (4, 0, 1) finished
04:10:57 DISPATCHER: register_result: lock acquired
04:10:57 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:10:57 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6706099661665105, 'info': {'number_mnist': 0.6706099661665105, 'config': "{'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}"}}
exception: None

04:10:57 job_callback for (4, 0, 1) started
04:10:57 DISPATCHER: Trying to submit another job.
04:10:57 job_callback for (4, 0, 1) got condition
04:10:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:57 HBMASTER: Trying to run another job!
04:10:57 job_callback for (4, 0, 1) finished
04:10:57 start sampling a new configuration.
04:10:57 best_vector: [3, 0.8792620249770848, 0.8474998647167498, 0.06445255473809203, 0.07011550026581148, 1, 0.8062880583807733, 0.8037073756036747], 0.011010027166638065, 0.25060033829615885, 0.0027591165326093983
04:10:57 done sampling a new configuration.
04:10:57 HBMASTER: schedule new run for iteration 4
04:10:57 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:10:57 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:10:57 DISPATCHER: trying to submit job (4, 0, 2)
04:10:57 DISPATCHER: trying to notify the job_runner thread.
04:10:57 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:10:57 DISPATCHER: Trying to submit another job.
04:10:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:57 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:10:57 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:10:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:57 WORKER: start processing job (4, 0, 2)
04:10:57 WORKER: args: ()
04:10:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0013455663244320878, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.11108294967356219}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:11:27 DISPATCHER: Starting worker discovery
04:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:27 DISPATCHER: Finished worker discovery
04:11:49 WORKER: done with job (4, 0, 2), trying to register it.
04:11:49 WORKER: registered result for job (4, 0, 2) with dispatcher
04:11:49 DISPATCHER: job (4, 0, 2) finished
04:11:49 DISPATCHER: register_result: lock acquired
04:11:49 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:11:49 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0013455663244320878, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.11108294967356219}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04460173329250585, 'info': {'number_mnist': 0.04460173329250585, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0013455663244320878, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.11108294967356219}"}}
exception: None

04:11:49 job_callback for (4, 0, 2) started
04:11:49 job_callback for (4, 0, 2) got condition
04:11:49 DISPATCHER: Trying to submit another job.
04:11:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:11:49 HBMASTER: Trying to run another job!
04:11:49 job_callback for (4, 0, 2) finished
04:11:49 start sampling a new configuration.
04:11:49 done sampling a new configuration.
04:11:49 HBMASTER: schedule new run for iteration 4
04:11:49 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
04:11:49 HBMASTER: submitting job (4, 0, 3) to dispatcher
04:11:49 DISPATCHER: trying to submit job (4, 0, 3)
04:11:49 DISPATCHER: trying to notify the job_runner thread.
04:11:49 HBMASTER: job (4, 0, 3) submitted to dispatcher
04:11:49 DISPATCHER: Trying to submit another job.
04:11:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:11:49 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:11:49 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:11:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:11:49 WORKER: start processing job (4, 0, 3)
04:11:49 WORKER: args: ()
04:11:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.03479427343596437, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.022428466719354972}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:12:27 DISPATCHER: Starting worker discovery
04:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:27 DISPATCHER: Finished worker discovery
04:12:41 WORKER: done with job (4, 0, 3), trying to register it.
04:12:41 WORKER: registered result for job (4, 0, 3) with dispatcher
04:12:41 DISPATCHER: job (4, 0, 3) finished
04:12:41 DISPATCHER: register_result: lock acquired
04:12:41 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:12:41 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.03479427343596437, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.022428466719354972}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.03479427343596437, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.022428466719354972}"}}
exception: None

04:12:41 job_callback for (4, 0, 3) started
04:12:41 job_callback for (4, 0, 3) got condition
04:12:41 DISPATCHER: Trying to submit another job.
04:12:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:12:41 HBMASTER: Trying to run another job!
04:12:41 job_callback for (4, 0, 3) finished
04:12:41 start sampling a new configuration.
04:12:41 done sampling a new configuration.
04:12:41 HBMASTER: schedule new run for iteration 4
04:12:41 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:12:41 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:12:41 DISPATCHER: trying to submit job (4, 0, 4)
04:12:41 DISPATCHER: trying to notify the job_runner thread.
04:12:41 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:12:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:12:41 DISPATCHER: Trying to submit another job.
04:12:41 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:12:41 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:12:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:12:41 WORKER: start processing job (4, 0, 4)
04:12:41 WORKER: args: ()
04:12:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 9, 'lr': 0.009584838373370133, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.06792835339398484}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:13:27 DISPATCHER: Starting worker discovery
04:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:27 DISPATCHER: Finished worker discovery
04:13:34 WORKER: done with job (4, 0, 4), trying to register it.
04:13:34 WORKER: registered result for job (4, 0, 4) with dispatcher
04:13:34 DISPATCHER: job (4, 0, 4) finished
04:13:34 DISPATCHER: register_result: lock acquired
04:13:34 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:13:34 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 9, 'lr': 0.009584838373370133, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.06792835339398484}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.023916637336792352, 'info': {'number_mnist': 0.023916637336792352, 'config': "{'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 9, 'lr': 0.009584838373370133, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.06792835339398484}"}}
exception: None

04:13:34 job_callback for (4, 0, 4) started
04:13:34 DISPATCHER: Trying to submit another job.
04:13:34 job_callback for (4, 0, 4) got condition
04:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:34 HBMASTER: Trying to run another job!
04:13:34 job_callback for (4, 0, 4) finished
04:13:34 start sampling a new configuration.
04:13:34 done sampling a new configuration.
04:13:34 HBMASTER: schedule new run for iteration 4
04:13:34 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:13:34 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:13:34 DISPATCHER: trying to submit job (4, 0, 5)
04:13:34 DISPATCHER: trying to notify the job_runner thread.
04:13:34 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:13:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:34 DISPATCHER: Trying to submit another job.
04:13:34 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:13:34 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:34 WORKER: start processing job (4, 0, 5)
04:13:34 WORKER: args: ()
04:13:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 38, 'last_n_outputs': 19, 'lr': 0.0099435247803932, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.014251954352906625}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:14:26 WORKER: done with job (4, 0, 5), trying to register it.
04:14:26 WORKER: registered result for job (4, 0, 5) with dispatcher
04:14:26 DISPATCHER: job (4, 0, 5) finished
04:14:26 DISPATCHER: register_result: lock acquired
04:14:26 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:14:26 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 38, 'last_n_outputs': 19, 'lr': 0.0099435247803932, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.014251954352906625}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 38, 'last_n_outputs': 19, 'lr': 0.0099435247803932, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.014251954352906625}"}}
exception: None

04:14:26 job_callback for (4, 0, 5) started
04:14:26 job_callback for (4, 0, 5) got condition
04:14:26 DISPATCHER: Trying to submit another job.
04:14:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:14:26 HBMASTER: Trying to run another job!
04:14:26 job_callback for (4, 0, 5) finished
04:14:26 start sampling a new configuration.
04:14:26 best_vector: [1, 0.6697589078231918, 0.10581384160460183, 0.6313888340305611, 0.09744802932744002, 0, 0.08646920639908506, 0.6885615175829924], 0.051988874016523086, 0.32837684569091485, 0.017071942460568215
04:14:26 done sampling a new configuration.
04:14:26 HBMASTER: schedule new run for iteration 4
04:14:26 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
04:14:26 HBMASTER: submitting job (4, 0, 6) to dispatcher
04:14:26 DISPATCHER: trying to submit job (4, 0, 6)
04:14:26 DISPATCHER: trying to notify the job_runner thread.
04:14:26 HBMASTER: job (4, 0, 6) submitted to dispatcher
04:14:26 DISPATCHER: Trying to submit another job.
04:14:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:14:26 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:14:26 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:14:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:14:26 WORKER: start processing job (4, 0, 6)
04:14:26 WORKER: args: ()
04:14:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 6, 'lr': 0.01831376630675226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.07867544141474167}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:14:27 DISPATCHER: Starting worker discovery
04:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:15:19 WORKER: done with job (4, 0, 6), trying to register it.
04:15:19 WORKER: registered result for job (4, 0, 6) with dispatcher
04:15:19 DISPATCHER: job (4, 0, 6) finished
04:15:19 DISPATCHER: register_result: lock acquired
04:15:19 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:15:19 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 6, 'lr': 0.01831376630675226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.07867544141474167}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.002949329354732633, 'info': {'number_mnist': 0.002949329354732633, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 6, 'lr': 0.01831376630675226, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.07867544141474167}"}}
exception: None

04:15:19 job_callback for (4, 0, 6) started
04:15:19 DISPATCHER: Trying to submit another job.
04:15:19 job_callback for (4, 0, 6) got condition
04:15:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:15:19 HBMASTER: Trying to run another job!
04:15:19 job_callback for (4, 0, 6) finished
04:15:19 start sampling a new configuration.
04:15:19 done sampling a new configuration.
04:15:19 HBMASTER: schedule new run for iteration 4
04:15:19 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:15:19 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:15:19 DISPATCHER: trying to submit job (4, 0, 7)
04:15:19 DISPATCHER: trying to notify the job_runner thread.
04:15:19 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:15:19 DISPATCHER: Trying to submit another job.
04:15:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:15:19 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:15:19 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:15:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:15:19 WORKER: start processing job (4, 0, 7)
04:15:19 WORKER: args: ()
04:15:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 37, 'lr': 0.00661199005323089, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.024638526126352478}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:15:27 DISPATCHER: Starting worker discovery
04:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:16:12 WORKER: done with job (4, 0, 7), trying to register it.
04:16:12 WORKER: registered result for job (4, 0, 7) with dispatcher
04:16:12 DISPATCHER: job (4, 0, 7) finished
04:16:12 DISPATCHER: register_result: lock acquired
04:16:12 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:16:12 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 37, 'lr': 0.00661199005323089, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.024638526126352478}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 37, 'lr': 0.00661199005323089, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.024638526126352478}"}}
exception: None

04:16:12 job_callback for (4, 0, 7) started
04:16:12 DISPATCHER: Trying to submit another job.
04:16:12 job_callback for (4, 0, 7) got condition
04:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:16:12 HBMASTER: Trying to run another job!
04:16:12 job_callback for (4, 0, 7) finished
04:16:12 start sampling a new configuration.
04:16:12 done sampling a new configuration.
04:16:12 HBMASTER: schedule new run for iteration 4
04:16:12 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
04:16:12 HBMASTER: submitting job (4, 0, 8) to dispatcher
04:16:12 DISPATCHER: trying to submit job (4, 0, 8)
04:16:12 DISPATCHER: trying to notify the job_runner thread.
04:16:12 HBMASTER: job (4, 0, 8) submitted to dispatcher
04:16:12 DISPATCHER: Trying to submit another job.
04:16:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:16:12 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:16:12 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:16:12 WORKER: start processing job (4, 0, 8)
04:16:12 WORKER: args: ()
04:16:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 8, 'lr': 0.00380607842696538, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.013197819898406123}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:16:27 DISPATCHER: Starting worker discovery
04:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:27 DISPATCHER: Finished worker discovery
04:17:04 WORKER: done with job (4, 0, 8), trying to register it.
04:17:04 WORKER: registered result for job (4, 0, 8) with dispatcher
04:17:04 DISPATCHER: job (4, 0, 8) finished
04:17:04 DISPATCHER: register_result: lock acquired
04:17:04 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:17:04 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 8, 'lr': 0.00380607842696538, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.013197819898406123}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 8, 'lr': 0.00380607842696538, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.013197819898406123}"}}
exception: None

04:17:04 job_callback for (4, 0, 8) started
04:17:04 DISPATCHER: Trying to submit another job.
04:17:04 job_callback for (4, 0, 8) got condition
04:17:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:17:04 HBMASTER: Trying to run another job!
04:17:04 job_callback for (4, 0, 8) finished
04:17:04 start sampling a new configuration.
04:17:04 best_vector: [0, 0.9720488988367294, 0.731974961017525, 0.49629475840886556, 0.2259673217821106, 0, 0.8720843890708045, 0.27213775186223366], 0.03346354850985378, 0.12770852214800463, 0.004273580326021488
04:17:04 done sampling a new configuration.
04:17:04 HBMASTER: schedule new run for iteration 4
04:17:04 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:17:04 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:17:04 DISPATCHER: trying to submit job (4, 0, 9)
04:17:04 DISPATCHER: trying to notify the job_runner thread.
04:17:04 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:17:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:17:04 DISPATCHER: Trying to submit another job.
04:17:04 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:17:04 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:17:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:17:04 WORKER: start processing job (4, 0, 9)
04:17:04 WORKER: args: ()
04:17:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 37, 'lr': 0.009830814849623533, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.022597447085976014}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:17:27 DISPATCHER: Starting worker discovery
04:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:27 DISPATCHER: Finished worker discovery
04:17:56 WORKER: done with job (4, 0, 9), trying to register it.
04:17:56 WORKER: registered result for job (4, 0, 9) with dispatcher
04:17:56 DISPATCHER: job (4, 0, 9) finished
04:17:56 DISPATCHER: register_result: lock acquired
04:17:56 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:17:56 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 37, 'lr': 0.009830814849623533, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.022597447085976014}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 37, 'lr': 0.009830814849623533, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.022597447085976014}"}}
exception: None

04:17:56 job_callback for (4, 0, 9) started
04:17:56 DISPATCHER: Trying to submit another job.
04:17:56 job_callback for (4, 0, 9) got condition
04:17:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:17:56 HBMASTER: Trying to run another job!
04:17:56 job_callback for (4, 0, 9) finished
04:17:56 start sampling a new configuration.
04:17:57 best_vector: [2, 0.7962088713611604, 0.954773824061534, 0.19240548010108782, 0.012515401774136944, 1, 0.9267787463401338, 0.19932544297755228], 0.011993224617584335, 0.04960706219462066, 0.0005949486395185617
04:17:57 done sampling a new configuration.
04:17:57 HBMASTER: schedule new run for iteration 4
04:17:57 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:17:57 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:17:57 DISPATCHER: trying to submit job (4, 0, 10)
04:17:57 DISPATCHER: trying to notify the job_runner thread.
04:17:57 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:17:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:17:57 DISPATCHER: Trying to submit another job.
04:17:57 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:17:57 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:17:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:17:57 WORKER: start processing job (4, 0, 10)
04:17:57 WORKER: args: ()
04:17:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 48, 'lr': 0.0024255540695554616, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.018168889357341445}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:18:27 DISPATCHER: Starting worker discovery
04:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:27 DISPATCHER: Finished worker discovery
04:18:49 WORKER: done with job (4, 0, 10), trying to register it.
04:18:49 WORKER: registered result for job (4, 0, 10) with dispatcher
04:18:49 DISPATCHER: job (4, 0, 10) finished
04:18:49 DISPATCHER: register_result: lock acquired
04:18:49 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:18:49 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 48, 'lr': 0.0024255540695554616, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.018168889357341445}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04867966400627884, 'info': {'number_mnist': 0.04867966400627884, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 48, 'lr': 0.0024255540695554616, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.018168889357341445}"}}
exception: None

04:18:49 job_callback for (4, 0, 10) started
04:18:49 job_callback for (4, 0, 10) got condition
04:18:49 DISPATCHER: Trying to submit another job.
04:18:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:18:49 HBMASTER: Trying to run another job!
04:18:49 job_callback for (4, 0, 10) finished
04:18:49 start sampling a new configuration.
04:18:49 best_vector: [0, 0.6409730918391148, 0.7260293515352217, 0.127216997548612, 0.0012328693945875546, 0, 0.953606963876556, 0.9724984636417123], 0.027483447763464956, 0.010654281524263917, 0.0002928163897293571
04:18:49 done sampling a new configuration.
04:18:49 HBMASTER: schedule new run for iteration 4
04:18:49 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:18:49 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:18:49 DISPATCHER: trying to submit job (4, 0, 11)
04:18:49 DISPATCHER: trying to notify the job_runner thread.
04:18:49 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:18:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:18:49 DISPATCHER: Trying to submit another job.
04:18:49 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:18:49 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:18:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:18:49 WORKER: start processing job (4, 0, 11)
04:18:49 WORKER: args: ()
04:18:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 37, 'lr': 0.0017965280196727245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.1841830548742242}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:19:27 DISPATCHER: Starting worker discovery
04:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:27 DISPATCHER: Finished worker discovery
04:19:41 WORKER: done with job (4, 0, 11), trying to register it.
04:19:41 WORKER: registered result for job (4, 0, 11) with dispatcher
04:19:41 DISPATCHER: job (4, 0, 11) finished
04:19:41 DISPATCHER: register_result: lock acquired
04:19:41 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:19:41 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 37, 'lr': 0.0017965280196727245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.1841830548742242}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43889473624951225, 'info': {'number_mnist': 0.43889473624951225, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 37, 'lr': 0.0017965280196727245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.1841830548742242}"}}
exception: None

04:19:41 job_callback for (4, 0, 11) started
04:19:41 DISPATCHER: Trying to submit another job.
04:19:41 job_callback for (4, 0, 11) got condition
04:19:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:19:41 HBMASTER: Trying to run another job!
04:19:41 job_callback for (4, 0, 11) finished
04:19:41 start sampling a new configuration.
04:19:41 best_vector: [2, 0.7977679733118417, 0.7326353082408829, 0.3374871024760416, 0.20484846001244694, 1, 0.7139033112586081, 0.5429294231585515], 0.0648665965353616, 0.35503004097296303, 0.02302959042572609
04:19:41 done sampling a new configuration.
04:19:41 HBMASTER: schedule new run for iteration 4
04:19:41 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:19:41 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:19:41 DISPATCHER: trying to submit job (4, 0, 12)
04:19:41 DISPATCHER: trying to notify the job_runner thread.
04:19:41 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:19:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:19:41 DISPATCHER: Trying to submit another job.
04:19:41 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:19:41 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:19:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:19:41 WORKER: start processing job (4, 0, 12)
04:19:41 WORKER: args: ()
04:19:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 37, 'lr': 0.0047312315683848815, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05085895881583496}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:20:27 DISPATCHER: Starting worker discovery
04:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:27 DISPATCHER: Finished worker discovery
04:20:34 WORKER: done with job (4, 0, 12), trying to register it.
04:20:34 WORKER: registered result for job (4, 0, 12) with dispatcher
04:20:34 DISPATCHER: job (4, 0, 12) finished
04:20:34 DISPATCHER: register_result: lock acquired
04:20:34 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:20:34 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 37, 'lr': 0.0047312315683848815, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05085895881583496}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.010751026624718635, 'info': {'number_mnist': 0.010751026624718635, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 37, 'lr': 0.0047312315683848815, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05085895881583496}"}}
exception: None

04:20:34 job_callback for (4, 0, 12) started
04:20:34 job_callback for (4, 0, 12) got condition
04:20:34 DISPATCHER: Trying to submit another job.
04:20:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:20:34 HBMASTER: Trying to run another job!
04:20:34 job_callback for (4, 0, 12) finished
04:20:34 start sampling a new configuration.
04:20:34 best_vector: [1, 0.9387473629562001, 0.7673441654130644, 0.3754945135127489, 0.3391002044907135, 0, 0.9027091513940626, 0.2714790803715592], 0.05066518321414647, 0.05143791424720043, 0.0026061113494879645
04:20:34 done sampling a new configuration.
04:20:34 HBMASTER: schedule new run for iteration 4
04:20:34 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
04:20:34 HBMASTER: submitting job (4, 0, 13) to dispatcher
04:20:34 DISPATCHER: trying to submit job (4, 0, 13)
04:20:34 DISPATCHER: trying to notify the job_runner thread.
04:20:34 HBMASTER: job (4, 0, 13) submitted to dispatcher
04:20:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:20:34 DISPATCHER: Trying to submit another job.
04:20:34 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:20:34 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:20:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:20:34 WORKER: start processing job (4, 0, 13)
04:20:34 WORKER: args: ()
04:20:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 39, 'lr': 0.005636234150198856, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.02255290168861809}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:21:26 WORKER: done with job (4, 0, 13), trying to register it.
04:21:26 WORKER: registered result for job (4, 0, 13) with dispatcher
04:21:26 DISPATCHER: job (4, 0, 13) finished
04:21:26 DISPATCHER: register_result: lock acquired
04:21:26 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:21:26 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 39, 'lr': 0.005636234150198856, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.02255290168861809}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.030423666356588018, 'info': {'number_mnist': 0.030423666356588018, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 39, 'lr': 0.005636234150198856, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.02255290168861809}"}}
exception: None

04:21:26 job_callback for (4, 0, 13) started
04:21:26 job_callback for (4, 0, 13) got condition
04:21:26 DISPATCHER: Trying to submit another job.
04:21:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:21:26 HBMASTER: Trying to run another job!
04:21:26 job_callback for (4, 0, 13) finished
04:21:26 start sampling a new configuration.
04:21:26 best_vector: [0, 0.7807151915389082, 0.8386328414170318, 0.24807423965302955, 0.05279405514095979, 0, 0.5445694811653456, 0.7910503218945082], 0.020325578507031584, 0.39234348342740527, 0.007974608274125971
04:21:26 done sampling a new configuration.
04:21:26 HBMASTER: schedule new run for iteration 4
04:21:26 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:21:26 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:21:26 DISPATCHER: trying to submit job (4, 0, 14)
04:21:26 DISPATCHER: trying to notify the job_runner thread.
04:21:26 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:21:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:21:26 DISPATCHER: Trying to submit another job.
04:21:26 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:21:26 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:21:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:21:26 WORKER: start processing job (4, 0, 14)
04:21:26 WORKER: args: ()
04:21:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 42, 'lr': 0.0031343571347203342, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.10694985420268112}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:21:27 DISPATCHER: Starting worker discovery
04:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:22:18 WORKER: done with job (4, 0, 14), trying to register it.
04:22:18 WORKER: registered result for job (4, 0, 14) with dispatcher
04:22:18 DISPATCHER: job (4, 0, 14) finished
04:22:18 DISPATCHER: register_result: lock acquired
04:22:18 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:22:18 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 42, 'lr': 0.0031343571347203342, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.10694985420268112}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4824076359388485, 'info': {'number_mnist': 0.4824076359388485, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 42, 'lr': 0.0031343571347203342, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.10694985420268112}"}}
exception: None

04:22:18 job_callback for (4, 0, 14) started
04:22:18 DISPATCHER: Trying to submit another job.
04:22:18 job_callback for (4, 0, 14) got condition
04:22:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:18 HBMASTER: Trying to run another job!
04:22:18 job_callback for (4, 0, 14) finished
04:22:18 start sampling a new configuration.
04:22:19 best_vector: [3, 0.6795238403656054, 0.9993499836893133, 0.24334725584911254, 0.026777045877618436, 1, 0.6338364078569956, 0.781531191054173], 0.041036969505807, 0.23674087382762407, 0.009715128020042312
04:22:19 done sampling a new configuration.
04:22:19 HBMASTER: schedule new run for iteration 4
04:22:19 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
04:22:19 HBMASTER: submitting job (4, 0, 15) to dispatcher
04:22:19 DISPATCHER: trying to submit job (4, 0, 15)
04:22:19 DISPATCHER: trying to notify the job_runner thread.
04:22:19 HBMASTER: job (4, 0, 15) submitted to dispatcher
04:22:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:19 DISPATCHER: Trying to submit another job.
04:22:19 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:22:19 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:19 WORKER: start processing job (4, 0, 15)
04:22:19 WORKER: args: ()
04:22:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 50, 'lr': 0.0030668639580931746, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.10394306578085606}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:22:27 DISPATCHER: Starting worker discovery
04:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:23:11 WORKER: done with job (4, 0, 15), trying to register it.
04:23:11 WORKER: registered result for job (4, 0, 15) with dispatcher
04:23:11 DISPATCHER: job (4, 0, 15) finished
04:23:11 DISPATCHER: register_result: lock acquired
04:23:11 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:23:11 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 50, 'lr': 0.0030668639580931746, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.10394306578085606}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06674504274889877, 'info': {'number_mnist': 0.06674504274889877, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 50, 'lr': 0.0030668639580931746, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.10394306578085606}"}}
exception: None

04:23:11 job_callback for (4, 0, 15) started
04:23:11 job_callback for (4, 0, 15) got condition
04:23:11 DISPATCHER: Trying to submit another job.
04:23:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:23:11 HBMASTER: Trying to run another job!
04:23:11 job_callback for (4, 0, 15) finished
04:23:11 start sampling a new configuration.
04:23:11 best_vector: [3, 0.9392873550159717, 0.865312154521749, 0.10973391825182546, 0.043662476810527255, 0, 0.9515886188638439, 0.5007807859349368], 0.0062224841686644855, 0.15501783025633548, 0.000964595994630766
04:23:11 done sampling a new configuration.
04:23:11 HBMASTER: schedule new run for iteration 4
04:23:11 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:23:11 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:23:11 DISPATCHER: trying to submit job (4, 0, 16)
04:23:11 DISPATCHER: trying to notify the job_runner thread.
04:23:11 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:23:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:23:11 DISPATCHER: Trying to submit another job.
04:23:11 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:23:11 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:23:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:23:11 WORKER: start processing job (4, 0, 16)
04:23:11 WORKER: args: ()
04:23:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:23:27 DISPATCHER: Starting worker discovery
04:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:27 DISPATCHER: Finished worker discovery
04:24:03 WORKER: done with job (4, 0, 16), trying to register it.
04:24:03 WORKER: registered result for job (4, 0, 16) with dispatcher
04:24:03 DISPATCHER: job (4, 0, 16) finished
04:24:03 DISPATCHER: register_result: lock acquired
04:24:03 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:24:03 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9128318622735658, 'info': {'number_mnist': 0.9128318622735658, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}"}}
exception: None

04:24:03 job_callback for (4, 0, 16) started
04:24:03 DISPATCHER: Trying to submit another job.
04:24:03 job_callback for (4, 0, 16) got condition
04:24:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:03 HBMASTER: Trying to run another job!
04:24:03 job_callback for (4, 0, 16) finished
04:24:03 start sampling a new configuration.
04:24:03 done sampling a new configuration.
04:24:03 HBMASTER: schedule new run for iteration 4
04:24:03 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:24:03 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:24:03 DISPATCHER: trying to submit job (4, 0, 17)
04:24:03 DISPATCHER: trying to notify the job_runner thread.
04:24:03 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:24:03 DISPATCHER: Trying to submit another job.
04:24:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:03 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:24:03 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:24:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:03 WORKER: start processing job (4, 0, 17)
04:24:03 WORKER: args: ()
04:24:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 4, 'lr': 0.0073437208392958045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.13098213908217787}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:24:27 DISPATCHER: Starting worker discovery
04:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:27 DISPATCHER: Finished worker discovery
04:24:56 WORKER: done with job (4, 0, 17), trying to register it.
04:24:56 WORKER: registered result for job (4, 0, 17) with dispatcher
04:24:56 DISPATCHER: job (4, 0, 17) finished
04:24:56 DISPATCHER: register_result: lock acquired
04:24:56 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:24:56 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 4, 'lr': 0.0073437208392958045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.13098213908217787}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07800786200355822, 'info': {'number_mnist': 0.07800786200355822, 'config': "{'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 4, 'lr': 0.0073437208392958045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.13098213908217787}"}}
exception: None

04:24:56 job_callback for (4, 0, 17) started
04:24:56 DISPATCHER: Trying to submit another job.
04:24:56 job_callback for (4, 0, 17) got condition
04:24:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:56 HBMASTER: Trying to run another job!
04:24:56 job_callback for (4, 0, 17) finished
04:24:56 start sampling a new configuration.
04:24:56 best_vector: [0, 0.8779044272897812, 0.7349626185098834, 0.18158446927931854, 0.24302616956340647, 1, 0.7687122001406936, 0.2468414334743123], 0.057586420066513655, 0.12769192817967034, 0.007353321015257589
04:24:56 done sampling a new configuration.
04:24:56 HBMASTER: schedule new run for iteration 4
04:24:56 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
04:24:56 HBMASTER: submitting job (4, 0, 18) to dispatcher
04:24:56 DISPATCHER: trying to submit job (4, 0, 18)
04:24:56 DISPATCHER: trying to notify the job_runner thread.
04:24:56 HBMASTER: job (4, 0, 18) submitted to dispatcher
04:24:56 DISPATCHER: Trying to submit another job.
04:24:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:56 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:24:56 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:24:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:56 WORKER: start processing job (4, 0, 18)
04:24:56 WORKER: args: ()
04:24:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 37, 'lr': 0.0023076446773291704, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.020948267408920675}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:25:27 DISPATCHER: Starting worker discovery
04:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:27 DISPATCHER: Finished worker discovery
04:25:48 WORKER: done with job (4, 0, 18), trying to register it.
04:25:48 WORKER: registered result for job (4, 0, 18) with dispatcher
04:25:48 DISPATCHER: job (4, 0, 18) finished
04:25:48 DISPATCHER: register_result: lock acquired
04:25:48 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:25:48 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 37, 'lr': 0.0023076446773291704, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.020948267408920675}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015391157011832003, 'info': {'number_mnist': 0.015391157011832003, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 37, 'lr': 0.0023076446773291704, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.020948267408920675}"}}
exception: None

04:25:48 job_callback for (4, 0, 18) started
04:25:48 job_callback for (4, 0, 18) got condition
04:25:48 DISPATCHER: Trying to submit another job.
04:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:48 HBMASTER: Trying to run another job!
04:25:48 job_callback for (4, 0, 18) finished
04:25:48 start sampling a new configuration.
04:25:48 best_vector: [2, 0.07285087330264885, 0.15527084172671085, 0.8244533604772535, 0.37037377223671997, 1, 0.9854301058568612, 0.8539331188680339], 0.018936915819591938, 0.38571586356220394, 0.007304268838558665
04:25:48 done sampling a new configuration.
04:25:48 HBMASTER: schedule new run for iteration 4
04:25:48 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
04:25:48 HBMASTER: submitting job (4, 0, 19) to dispatcher
04:25:48 DISPATCHER: trying to submit job (4, 0, 19)
04:25:48 DISPATCHER: trying to notify the job_runner thread.
04:25:48 HBMASTER: job (4, 0, 19) submitted to dispatcher
04:25:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:48 DISPATCHER: Trying to submit another job.
04:25:48 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:25:48 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:48 WORKER: start processing job (4, 0, 19)
04:25:48 WORKER: args: ()
04:25:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 8, 'lr': 0.04455605393171102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.12911972783107856}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:26:27 DISPATCHER: Starting worker discovery
04:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:27 DISPATCHER: Finished worker discovery
04:26:41 WORKER: done with job (4, 0, 19), trying to register it.
04:26:41 WORKER: registered result for job (4, 0, 19) with dispatcher
04:26:41 DISPATCHER: job (4, 0, 19) finished
04:26:41 DISPATCHER: register_result: lock acquired
04:26:41 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:26:41 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 8, 'lr': 0.04455605393171102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.12911972783107856}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.007622073326738141, 'info': {'number_mnist': 0.007622073326738141, 'config': "{'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 8, 'lr': 0.04455605393171102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.12911972783107856}"}}
exception: None

04:26:41 job_callback for (4, 0, 19) started
04:26:41 job_callback for (4, 0, 19) got condition
04:26:41 DISPATCHER: Trying to submit another job.
04:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:41 HBMASTER: Trying to run another job!
04:26:41 job_callback for (4, 0, 19) finished
04:26:41 start sampling a new configuration.
04:26:41 done sampling a new configuration.
04:26:41 HBMASTER: schedule new run for iteration 4
04:26:41 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:26:41 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:26:41 DISPATCHER: trying to submit job (4, 0, 20)
04:26:41 DISPATCHER: trying to notify the job_runner thread.
04:26:41 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:26:41 DISPATCHER: Trying to submit another job.
04:26:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:41 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:26:41 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:41 WORKER: start processing job (4, 0, 20)
04:26:41 WORKER: args: ()
04:26:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 32, 'lr': 0.001409505748666999, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.19813131839764256}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:27:27 DISPATCHER: Starting worker discovery
04:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:27 DISPATCHER: Finished worker discovery
04:27:34 WORKER: done with job (4, 0, 20), trying to register it.
04:27:34 WORKER: registered result for job (4, 0, 20) with dispatcher
04:27:34 DISPATCHER: job (4, 0, 20) finished
04:27:34 DISPATCHER: register_result: lock acquired
04:27:34 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:27:34 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 32, 'lr': 0.001409505748666999, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.19813131839764256}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02822393572927066, 'info': {'number_mnist': 0.02822393572927066, 'config': "{'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 32, 'lr': 0.001409505748666999, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.19813131839764256}"}}
exception: None

04:27:34 job_callback for (4, 0, 20) started
04:27:34 job_callback for (4, 0, 20) got condition
04:27:34 DISPATCHER: Trying to submit another job.
04:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:27:34 HBMASTER: Trying to run another job!
04:27:34 job_callback for (4, 0, 20) finished
04:27:34 start sampling a new configuration.
04:27:34 best_vector: [2, 0.9646734362914546, 0.7131738977357117, 0.08087276173405855, 0.11506222014401028, 1, 0.952785011986828, 0.49625928070192304], 0.015327223120015443, 0.2022813121658186, 0.003100410804574996
04:27:34 done sampling a new configuration.
04:27:34 HBMASTER: schedule new run for iteration 4
04:27:34 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
04:27:34 HBMASTER: submitting job (4, 0, 21) to dispatcher
04:27:34 DISPATCHER: trying to submit job (4, 0, 21)
04:27:34 DISPATCHER: trying to notify the job_runner thread.
04:27:34 HBMASTER: job (4, 0, 21) submitted to dispatcher
04:27:34 DISPATCHER: Trying to submit another job.
04:27:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:27:34 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:27:34 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:27:34 WORKER: start processing job (4, 0, 21)
04:27:34 WORKER: args: ()
04:27:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 36, 'lr': 0.0014512609964041682, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.04422300090702414}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:28:27 WORKER: done with job (4, 0, 21), trying to register it.
04:28:27 WORKER: registered result for job (4, 0, 21) with dispatcher
04:28:27 DISPATCHER: job (4, 0, 21) finished
04:28:27 DISPATCHER: register_result: lock acquired
04:28:27 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:28:27 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 36, 'lr': 0.0014512609964041682, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.04422300090702414}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07084483064499374, 'info': {'number_mnist': 0.07084483064499374, 'config': "{'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 36, 'lr': 0.0014512609964041682, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.04422300090702414}"}}
exception: None

04:28:27 job_callback for (4, 0, 21) started
04:28:27 job_callback for (4, 0, 21) got condition
04:28:27 DISPATCHER: Trying to submit another job.
04:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:28:27 HBMASTER: Trying to run another job!
04:28:27 job_callback for (4, 0, 21) finished
04:28:27 start sampling a new configuration.
04:28:27 best_vector: [1, 0.7854985363193921, 0.7730694823815928, 0.597087976746666, 0.06673087922544188, 1, 0.9509887902565182, 0.3755203924989181], 0.05689206823116163, 0.07083433020495572, 0.004029911547128974
04:28:27 done sampling a new configuration.
04:28:27 HBMASTER: schedule new run for iteration 4
04:28:27 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
04:28:27 HBMASTER: submitting job (4, 0, 22) to dispatcher
04:28:27 DISPATCHER: trying to submit job (4, 0, 22)
04:28:27 DISPATCHER: trying to notify the job_runner thread.
04:28:27 HBMASTER: job (4, 0, 22) submitted to dispatcher
04:28:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:28:27 DISPATCHER: Trying to submit another job.
04:28:27 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:28:27 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:28:27 WORKER: start processing job (4, 0, 22)
04:28:27 WORKER: args: ()
04:28:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 39, 'lr': 0.01563781076920006, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.030800892048714376}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:28:27 DISPATCHER: Starting worker discovery
04:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:29:19 WORKER: done with job (4, 0, 22), trying to register it.
04:29:19 WORKER: registered result for job (4, 0, 22) with dispatcher
04:29:19 DISPATCHER: job (4, 0, 22) finished
04:29:19 DISPATCHER: register_result: lock acquired
04:29:19 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:29:19 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 39, 'lr': 0.01563781076920006, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.030800892048714376}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2739974883620886, 'info': {'number_mnist': 0.2739974883620886, 'config': "{'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 39, 'lr': 0.01563781076920006, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.030800892048714376}"}}
exception: None

04:29:19 job_callback for (4, 0, 22) started
04:29:19 DISPATCHER: Trying to submit another job.
04:29:19 job_callback for (4, 0, 22) got condition
04:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:19 HBMASTER: Trying to run another job!
04:29:19 job_callback for (4, 0, 22) finished
04:29:19 start sampling a new configuration.
04:29:19 best_vector: [3, 0.6892070248813454, 0.00023030346028546367, 0.9556346589795494, 0.13180209167194956, 1, 0.004105759281122334, 0.8986576117196281], 0.042268488351013524, 0.029970148783150043, 0.0012667928847187198
04:29:19 done sampling a new configuration.
04:29:19 HBMASTER: schedule new run for iteration 4
04:29:19 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
04:29:19 HBMASTER: submitting job (4, 0, 23) to dispatcher
04:29:19 DISPATCHER: trying to submit job (4, 0, 23)
04:29:19 DISPATCHER: trying to notify the job_runner thread.
04:29:19 HBMASTER: job (4, 0, 23) submitted to dispatcher
04:29:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:19 DISPATCHER: Trying to submit another job.
04:29:19 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:29:19 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:19 WORKER: start processing job (4, 0, 23)
04:29:19 WORKER: args: ()
04:29:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 1, 'lr': 0.08152096612492768, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.14763200183968467}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:29:27 DISPATCHER: Starting worker discovery
04:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:30:12 WORKER: done with job (4, 0, 23), trying to register it.
04:30:12 WORKER: registered result for job (4, 0, 23) with dispatcher
04:30:12 DISPATCHER: job (4, 0, 23) finished
04:30:12 DISPATCHER: register_result: lock acquired
04:30:12 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:30:12 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 1, 'lr': 0.08152096612492768, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.14763200183968467}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07675621396433414, 'info': {'number_mnist': 0.07675621396433414, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 1, 'lr': 0.08152096612492768, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.14763200183968467}"}}
exception: None

04:30:12 job_callback for (4, 0, 23) started
04:30:12 DISPATCHER: Trying to submit another job.
04:30:12 job_callback for (4, 0, 23) got condition
04:30:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:30:12 HBMASTER: Trying to run another job!
04:30:12 job_callback for (4, 0, 23) finished
04:30:12 start sampling a new configuration.
04:30:12 best_vector: [2, 0.9240033496365894, 0.3457177799550133, 0.916553455841108, 0.20132900685072502, 0, 0.9900504128879148, 0.10015140671427748], 0.036407726711148294, 0.06428602680016131, 0.002340508095085828
04:30:12 done sampling a new configuration.
04:30:12 HBMASTER: schedule new run for iteration 4
04:30:12 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
04:30:12 HBMASTER: submitting job (4, 0, 24) to dispatcher
04:30:12 DISPATCHER: trying to submit job (4, 0, 24)
04:30:12 DISPATCHER: trying to notify the job_runner thread.
04:30:12 HBMASTER: job (4, 0, 24) submitted to dispatcher
04:30:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:30:12 DISPATCHER: Trying to submit another job.
04:30:12 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:30:12 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:30:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:30:12 WORKER: start processing job (4, 0, 24)
04:30:12 WORKER: args: ()
04:30:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 18, 'lr': 0.06809369665258058, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.01349894986079993}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:30:27 DISPATCHER: Starting worker discovery
04:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:27 DISPATCHER: Finished worker discovery
04:31:05 WORKER: done with job (4, 0, 24), trying to register it.
04:31:05 WORKER: registered result for job (4, 0, 24) with dispatcher
04:31:05 DISPATCHER: job (4, 0, 24) finished
04:31:05 DISPATCHER: register_result: lock acquired
04:31:05 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:31:05 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 18, 'lr': 0.06809369665258058, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.01349894986079993}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004616419775685943, 'info': {'number_mnist': 0.004616419775685943, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 18, 'lr': 0.06809369665258058, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.01349894986079993}"}}
exception: None

04:31:05 job_callback for (4, 0, 24) started
04:31:05 job_callback for (4, 0, 24) got condition
04:31:05 DISPATCHER: Trying to submit another job.
04:31:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:05 HBMASTER: Trying to run another job!
04:31:05 job_callback for (4, 0, 24) finished
04:31:05 start sampling a new configuration.
04:31:05 best_vector: [3, 0.9325688948345344, 0.9957097382766408, 0.04090742313496046, 0.1720264378130098, 0, 0.3581295232502426, 0.3462315856190087], 0.051316300483583384, 0.416623514005569, 0.02137957743323619
04:31:05 done sampling a new configuration.
04:31:05 HBMASTER: schedule new run for iteration 4
04:31:05 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:31:05 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:31:05 DISPATCHER: trying to submit job (4, 0, 25)
04:31:05 DISPATCHER: trying to notify the job_runner thread.
04:31:05 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:31:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:05 DISPATCHER: Trying to submit another job.
04:31:05 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:31:05 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:31:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:05 WORKER: start processing job (4, 0, 25)
04:31:05 WORKER: args: ()
04:31:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 50, 'lr': 0.0012072990149045886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.028213546308544134}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:31:27 DISPATCHER: Starting worker discovery
04:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:27 DISPATCHER: Finished worker discovery
04:31:57 WORKER: done with job (4, 0, 25), trying to register it.
04:31:57 WORKER: registered result for job (4, 0, 25) with dispatcher
04:31:57 DISPATCHER: job (4, 0, 25) finished
04:31:57 DISPATCHER: register_result: lock acquired
04:31:57 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:31:57 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 50, 'lr': 0.0012072990149045886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.028213546308544134}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7414996752824465, 'info': {'number_mnist': 0.7414996752824465, 'config': "{'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 50, 'lr': 0.0012072990149045886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.028213546308544134}"}}
exception: None

04:31:57 job_callback for (4, 0, 25) started
04:31:57 DISPATCHER: Trying to submit another job.
04:31:57 job_callback for (4, 0, 25) got condition
04:31:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:57 HBMASTER: Trying to run another job!
04:31:57 job_callback for (4, 0, 25) finished
04:31:57 start sampling a new configuration.
04:31:57 best_vector: [2, 0.9886967198231102, 0.6881901140472141, 0.27004527489989716, 0.1725117000810622, 0, 0.5569160270699665, 0.5954231268118295], 0.06807012972129275, 0.6488732317059047, 0.044168885054895385
04:31:57 done sampling a new configuration.
04:31:57 HBMASTER: schedule new run for iteration 4
04:31:57 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:31:57 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:31:57 DISPATCHER: trying to submit job (4, 0, 26)
04:31:57 DISPATCHER: trying to notify the job_runner thread.
04:31:57 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:31:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:57 DISPATCHER: Trying to submit another job.
04:31:57 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:31:57 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:31:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:57 WORKER: start processing job (4, 0, 26)
04:31:57 WORKER: args: ()
04:31:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:32:27 DISPATCHER: Starting worker discovery
04:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:27 DISPATCHER: Finished worker discovery
04:32:50 WORKER: done with job (4, 0, 26), trying to register it.
04:32:50 WORKER: registered result for job (4, 0, 26) with dispatcher
04:32:50 DISPATCHER: job (4, 0, 26) finished
04:32:50 DISPATCHER: register_result: lock acquired
04:32:50 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:32:50 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7239045464430693, 'info': {'number_mnist': 0.7239045464430693, 'config': "{'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}"}}
exception: None

04:32:50 job_callback for (4, 0, 26) started
04:32:50 DISPATCHER: Trying to submit another job.
04:32:50 job_callback for (4, 0, 26) got condition
04:32:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:32:50 HBMASTER: Trying to run another job!
04:32:50 job_callback for (4, 0, 26) finished
04:32:50 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
04:32:50 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
04:32:50 HBMASTER: schedule new run for iteration 4
04:32:50 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:32:50 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:32:50 DISPATCHER: trying to submit job (4, 0, 1)
04:32:50 DISPATCHER: trying to notify the job_runner thread.
04:32:50 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:32:50 DISPATCHER: Trying to submit another job.
04:32:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:32:50 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:32:50 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:32:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:32:50 WORKER: start processing job (4, 0, 1)
04:32:50 WORKER: args: ()
04:32:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:33:27 DISPATCHER: Starting worker discovery
04:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:27 DISPATCHER: Finished worker discovery
04:34:27 DISPATCHER: Starting worker discovery
04:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:27 DISPATCHER: Finished worker discovery
04:35:11 WORKER: done with job (4, 0, 1), trying to register it.
04:35:11 WORKER: registered result for job (4, 0, 1) with dispatcher
04:35:11 DISPATCHER: job (4, 0, 1) finished
04:35:11 DISPATCHER: register_result: lock acquired
04:35:11 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:35:11 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7017701205163785, 'info': {'number_mnist': 0.7017701205163785, 'config': "{'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}"}}
exception: None

04:35:11 job_callback for (4, 0, 1) started
04:35:11 job_callback for (4, 0, 1) got condition
04:35:11 DISPATCHER: Trying to submit another job.
04:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:35:11 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.701770





04:35:11 HBMASTER: Trying to run another job!
04:35:11 job_callback for (4, 0, 1) finished
04:35:11 HBMASTER: schedule new run for iteration 4
04:35:11 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:35:11 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:35:11 DISPATCHER: trying to submit job (4, 0, 11)
04:35:11 DISPATCHER: trying to notify the job_runner thread.
04:35:11 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:35:11 DISPATCHER: Trying to submit another job.
04:35:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:35:11 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:35:11 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:35:11 WORKER: start processing job (4, 0, 11)
04:35:11 WORKER: args: ()
04:35:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 37, 'lr': 0.0017965280196727245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.1841830548742242}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:35:27 DISPATCHER: Starting worker discovery
04:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:27 DISPATCHER: Finished worker discovery
04:36:27 DISPATCHER: Starting worker discovery
04:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:27 DISPATCHER: Finished worker discovery
04:37:27 DISPATCHER: Starting worker discovery
04:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:27 DISPATCHER: Finished worker discovery
04:37:33 WORKER: done with job (4, 0, 11), trying to register it.
04:37:33 WORKER: registered result for job (4, 0, 11) with dispatcher
04:37:33 DISPATCHER: job (4, 0, 11) finished
04:37:33 DISPATCHER: register_result: lock acquired
04:37:33 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:37:33 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 37, 'lr': 0.0017965280196727245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.1841830548742242}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3407565945796034, 'info': {'number_mnist': 0.3407565945796034, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 37, 'lr': 0.0017965280196727245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.1841830548742242}"}}
exception: None

04:37:33 job_callback for (4, 0, 11) started
04:37:33 DISPATCHER: Trying to submit another job.
04:37:33 job_callback for (4, 0, 11) got condition
04:37:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:37:33 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.701770





04:37:33 HBMASTER: Trying to run another job!
04:37:33 job_callback for (4, 0, 11) finished
04:37:33 HBMASTER: schedule new run for iteration 4
04:37:33 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:37:33 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:37:33 DISPATCHER: trying to submit job (4, 0, 14)
04:37:33 DISPATCHER: trying to notify the job_runner thread.
04:37:33 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:37:33 DISPATCHER: Trying to submit another job.
04:37:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:37:33 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:37:33 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:37:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:37:33 WORKER: start processing job (4, 0, 14)
04:37:33 WORKER: args: ()
04:37:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 42, 'lr': 0.0031343571347203342, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.10694985420268112}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:38:27 DISPATCHER: Starting worker discovery
04:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:27 DISPATCHER: Finished worker discovery
04:39:27 DISPATCHER: Starting worker discovery
04:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:27 DISPATCHER: Finished worker discovery
04:39:54 WORKER: done with job (4, 0, 14), trying to register it.
04:39:54 WORKER: registered result for job (4, 0, 14) with dispatcher
04:39:54 DISPATCHER: job (4, 0, 14) finished
04:39:54 DISPATCHER: register_result: lock acquired
04:39:54 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:39:54 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 42, 'lr': 0.0031343571347203342, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.10694985420268112}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49575100748474926, 'info': {'number_mnist': 0.49575100748474926, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 42, 'lr': 0.0031343571347203342, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.10694985420268112}"}}
exception: None

04:39:54 job_callback for (4, 0, 14) started
04:39:54 job_callback for (4, 0, 14) got condition
04:39:54 DISPATCHER: Trying to submit another job.
04:39:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:39:54 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.701770





04:39:54 HBMASTER: Trying to run another job!
04:39:54 job_callback for (4, 0, 14) finished
04:39:54 HBMASTER: schedule new run for iteration 4
04:39:54 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:39:54 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:39:54 DISPATCHER: trying to submit job (4, 0, 16)
04:39:54 DISPATCHER: trying to notify the job_runner thread.
04:39:54 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:39:54 DISPATCHER: Trying to submit another job.
04:39:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:39:54 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:39:54 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:39:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:39:54 WORKER: start processing job (4, 0, 16)
04:39:54 WORKER: args: ()
04:39:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:40:27 DISPATCHER: Starting worker discovery
04:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:27 DISPATCHER: Finished worker discovery
04:41:27 DISPATCHER: Starting worker discovery
04:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:27 DISPATCHER: Finished worker discovery
04:42:15 WORKER: done with job (4, 0, 16), trying to register it.
04:42:15 WORKER: registered result for job (4, 0, 16) with dispatcher
04:42:15 DISPATCHER: job (4, 0, 16) finished
04:42:15 DISPATCHER: register_result: lock acquired
04:42:15 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:42:15 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9303635079176729, 'info': {'number_mnist': 0.9303635079176729, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}"}}
exception: None

04:42:15 job_callback for (4, 0, 16) started
04:42:15 DISPATCHER: Trying to submit another job.
04:42:15 job_callback for (4, 0, 16) got condition
04:42:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:42:15 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.930364





04:42:15 HBMASTER: Trying to run another job!
04:42:15 job_callback for (4, 0, 16) finished
04:42:15 HBMASTER: schedule new run for iteration 4
04:42:15 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:42:15 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:42:15 DISPATCHER: trying to submit job (4, 0, 17)
04:42:15 DISPATCHER: trying to notify the job_runner thread.
04:42:15 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:42:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:42:15 DISPATCHER: Trying to submit another job.
04:42:15 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:42:15 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:42:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:42:15 WORKER: start processing job (4, 0, 17)
04:42:15 WORKER: args: ()
04:42:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 4, 'lr': 0.0073437208392958045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.13098213908217787}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:42:27 DISPATCHER: Starting worker discovery
04:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:27 DISPATCHER: Finished worker discovery
04:43:27 DISPATCHER: Starting worker discovery
04:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:27 DISPATCHER: Finished worker discovery
04:44:27 DISPATCHER: Starting worker discovery
04:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:27 DISPATCHER: Finished worker discovery
04:44:37 WORKER: done with job (4, 0, 17), trying to register it.
04:44:37 WORKER: registered result for job (4, 0, 17) with dispatcher
04:44:37 DISPATCHER: job (4, 0, 17) finished
04:44:37 DISPATCHER: register_result: lock acquired
04:44:37 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:44:37 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 4, 'lr': 0.0073437208392958045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.13098213908217787}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16217603580917583, 'info': {'number_mnist': 0.16217603580917583, 'config': "{'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 4, 'lr': 0.0073437208392958045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.13098213908217787}"}}
exception: None

04:44:37 job_callback for (4, 0, 17) started
04:44:37 DISPATCHER: Trying to submit another job.
04:44:37 job_callback for (4, 0, 17) got condition
04:44:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:44:37 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.930364





04:44:37 HBMASTER: Trying to run another job!
04:44:37 job_callback for (4, 0, 17) finished
04:44:37 HBMASTER: schedule new run for iteration 4
04:44:37 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
04:44:37 HBMASTER: submitting job (4, 0, 22) to dispatcher
04:44:37 DISPATCHER: trying to submit job (4, 0, 22)
04:44:37 DISPATCHER: trying to notify the job_runner thread.
04:44:37 HBMASTER: job (4, 0, 22) submitted to dispatcher
04:44:37 DISPATCHER: Trying to submit another job.
04:44:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:44:37 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:44:37 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:44:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:44:37 WORKER: start processing job (4, 0, 22)
04:44:37 WORKER: args: ()
04:44:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 39, 'lr': 0.01563781076920006, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.030800892048714376}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:45:27 DISPATCHER: Starting worker discovery
04:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:27 DISPATCHER: Finished worker discovery
04:46:27 DISPATCHER: Starting worker discovery
04:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:27 DISPATCHER: Finished worker discovery
04:46:58 WORKER: done with job (4, 0, 22), trying to register it.
04:46:58 WORKER: registered result for job (4, 0, 22) with dispatcher
04:46:58 DISPATCHER: job (4, 0, 22) finished
04:46:58 DISPATCHER: register_result: lock acquired
04:46:58 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:46:58 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 39, 'lr': 0.01563781076920006, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.030800892048714376}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2120904837588023, 'info': {'number_mnist': 0.2120904837588023, 'config': "{'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 39, 'lr': 0.01563781076920006, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.030800892048714376}"}}
exception: None

04:46:58 job_callback for (4, 0, 22) started
04:46:58 DISPATCHER: Trying to submit another job.
04:46:58 job_callback for (4, 0, 22) got condition
04:46:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:46:58 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.930364





04:46:58 HBMASTER: Trying to run another job!
04:46:58 job_callback for (4, 0, 22) finished
04:46:58 HBMASTER: schedule new run for iteration 4
04:46:58 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
04:46:58 HBMASTER: submitting job (4, 0, 23) to dispatcher
04:46:58 DISPATCHER: trying to submit job (4, 0, 23)
04:46:58 DISPATCHER: trying to notify the job_runner thread.
04:46:58 HBMASTER: job (4, 0, 23) submitted to dispatcher
04:46:58 DISPATCHER: Trying to submit another job.
04:46:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:46:58 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:46:58 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:46:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:46:58 WORKER: start processing job (4, 0, 23)
04:46:58 WORKER: args: ()
04:46:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 1, 'lr': 0.08152096612492768, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.14763200183968467}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:47:27 DISPATCHER: Starting worker discovery
04:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:27 DISPATCHER: Finished worker discovery
04:48:27 DISPATCHER: Starting worker discovery
04:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:27 DISPATCHER: Finished worker discovery
04:49:19 WORKER: done with job (4, 0, 23), trying to register it.
04:49:19 WORKER: registered result for job (4, 0, 23) with dispatcher
04:49:19 DISPATCHER: job (4, 0, 23) finished
04:49:19 DISPATCHER: register_result: lock acquired
04:49:19 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:49:19 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 1, 'lr': 0.08152096612492768, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.14763200183968467}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.003211227843785638, 'info': {'number_mnist': 0.003211227843785638, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 1, 'lr': 0.08152096612492768, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.14763200183968467}"}}
exception: None

04:49:19 job_callback for (4, 0, 23) started
04:49:19 DISPATCHER: Trying to submit another job.
04:49:19 job_callback for (4, 0, 23) got condition
04:49:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:49:19 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.930364





04:49:19 HBMASTER: Trying to run another job!
04:49:19 job_callback for (4, 0, 23) finished
04:49:19 HBMASTER: schedule new run for iteration 4
04:49:19 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:49:19 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:49:19 DISPATCHER: trying to submit job (4, 0, 25)
04:49:19 DISPATCHER: trying to notify the job_runner thread.
04:49:19 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:49:19 DISPATCHER: Trying to submit another job.
04:49:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:49:19 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:49:19 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:49:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:49:19 WORKER: start processing job (4, 0, 25)
04:49:19 WORKER: args: ()
04:49:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 50, 'lr': 0.0012072990149045886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.028213546308544134}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:49:27 DISPATCHER: Starting worker discovery
04:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:27 DISPATCHER: Finished worker discovery
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:50:27 DISPATCHER: Starting worker discovery
04:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:27 DISPATCHER: Finished worker discovery
04:51:27 DISPATCHER: Starting worker discovery
04:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:27 DISPATCHER: Finished worker discovery
04:51:41 WORKER: done with job (4, 0, 25), trying to register it.
04:51:41 WORKER: registered result for job (4, 0, 25) with dispatcher
04:51:41 DISPATCHER: job (4, 0, 25) finished
04:51:41 DISPATCHER: register_result: lock acquired
04:51:41 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:51:41 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 50, 'lr': 0.0012072990149045886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.028213546308544134}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6973817969496794, 'info': {'number_mnist': 0.6973817969496794, 'config': "{'batch_size': 128, 'hidden_dim': 95, 'last_n_outputs': 50, 'lr': 0.0012072990149045886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.028213546308544134}"}}
exception: None

04:51:41 job_callback for (4, 0, 25) started
04:51:41 job_callback for (4, 0, 25) got condition
04:51:41 DISPATCHER: Trying to submit another job.
04:51:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:51:41 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.930364





04:51:41 HBMASTER: Trying to run another job!
04:51:41 job_callback for (4, 0, 25) finished
04:51:41 HBMASTER: schedule new run for iteration 4
04:51:41 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:51:41 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:51:41 DISPATCHER: trying to submit job (4, 0, 26)
04:51:41 DISPATCHER: trying to notify the job_runner thread.
04:51:41 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:51:41 DISPATCHER: Trying to submit another job.
04:51:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:51:41 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:51:41 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:51:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:51:41 WORKER: start processing job (4, 0, 26)
04:51:41 WORKER: args: ()
04:51:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:52:27 DISPATCHER: Starting worker discovery
04:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:27 DISPATCHER: Finished worker discovery
04:53:27 DISPATCHER: Starting worker discovery
04:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:27 DISPATCHER: Finished worker discovery
04:54:02 WORKER: done with job (4, 0, 26), trying to register it.
04:54:02 WORKER: registered result for job (4, 0, 26) with dispatcher
04:54:02 DISPATCHER: job (4, 0, 26) finished
04:54:02 DISPATCHER: register_result: lock acquired
04:54:02 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
04:54:02 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8447148182009024, 'info': {'number_mnist': 0.8447148182009024, 'config': "{'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}"}}
exception: None

04:54:02 job_callback for (4, 0, 26) started
04:54:02 DISPATCHER: Trying to submit another job.
04:54:02 job_callback for (4, 0, 26) got condition
04:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:54:02 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.930364





04:54:02 HBMASTER: Trying to run another job!
04:54:02 job_callback for (4, 0, 26) finished
04:54:02 ITERATION: Advancing config (4, 0, 1) to next budget 400.000000
04:54:02 ITERATION: Advancing config (4, 0, 16) to next budget 400.000000
04:54:02 ITERATION: Advancing config (4, 0, 26) to next budget 400.000000
04:54:02 HBMASTER: schedule new run for iteration 4
04:54:02 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:54:02 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:54:02 DISPATCHER: trying to submit job (4, 0, 1)
04:54:02 DISPATCHER: trying to notify the job_runner thread.
04:54:02 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:54:02 DISPATCHER: Trying to submit another job.
04:54:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:54:02 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
04:54:02 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
04:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:54:02 WORKER: start processing job (4, 0, 1)
04:54:02 WORKER: args: ()
04:54:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:54:27 DISPATCHER: Starting worker discovery
04:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:27 DISPATCHER: Finished worker discovery
04:55:27 DISPATCHER: Starting worker discovery
04:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:27 DISPATCHER: Finished worker discovery
04:56:27 DISPATCHER: Starting worker discovery
04:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:27 DISPATCHER: Finished worker discovery
04:57:27 DISPATCHER: Starting worker discovery
04:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:27 DISPATCHER: Finished worker discovery
04:58:27 DISPATCHER: Starting worker discovery
04:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:27 DISPATCHER: Finished worker discovery
04:59:27 DISPATCHER: Starting worker discovery
04:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:27 DISPATCHER: Finished worker discovery
05:00:27 DISPATCHER: Starting worker discovery
05:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:28 DISPATCHER: Finished worker discovery
05:00:50 WORKER: done with job (4, 0, 1), trying to register it.
05:00:50 WORKER: registered result for job (4, 0, 1) with dispatcher
05:00:50 DISPATCHER: job (4, 0, 1) finished
05:00:50 DISPATCHER: register_result: lock acquired
05:00:50 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:00:50 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.822714505290815, 'info': {'number_mnist': 0.822714505290815, 'config': "{'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 39, 'lr': 0.008734247358571584, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.011893519284662969}"}}
exception: None

05:00:50 job_callback for (4, 0, 1) started
05:00:50 DISPATCHER: Trying to submit another job.
05:00:50 job_callback for (4, 0, 1) got condition
05:00:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:00:50 HBMASTER: Trying to run another job!
05:00:50 job_callback for (4, 0, 1) finished
05:00:50 HBMASTER: schedule new run for iteration 4
05:00:50 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
05:00:50 HBMASTER: submitting job (4, 0, 16) to dispatcher
05:00:50 DISPATCHER: trying to submit job (4, 0, 16)
05:00:50 DISPATCHER: trying to notify the job_runner thread.
05:00:50 HBMASTER: job (4, 0, 16) submitted to dispatcher
05:00:50 DISPATCHER: Trying to submit another job.
05:00:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:00:50 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:00:50 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:00:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:00:50 WORKER: start processing job (4, 0, 16)
05:00:50 WORKER: args: ()
05:00:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:01:28 DISPATCHER: Starting worker discovery
05:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:28 DISPATCHER: Finished worker discovery
05:02:28 DISPATCHER: Starting worker discovery
05:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:28 DISPATCHER: Finished worker discovery
05:03:28 DISPATCHER: Starting worker discovery
05:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:28 DISPATCHER: Finished worker discovery
05:04:28 DISPATCHER: Starting worker discovery
05:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:28 DISPATCHER: Finished worker discovery
05:05:28 DISPATCHER: Starting worker discovery
05:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:28 DISPATCHER: Finished worker discovery
05:06:28 DISPATCHER: Starting worker discovery
05:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:28 DISPATCHER: Finished worker discovery
05:07:28 DISPATCHER: Starting worker discovery
05:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:28 DISPATCHER: Finished worker discovery
05:07:38 WORKER: done with job (4, 0, 16), trying to register it.
05:07:38 WORKER: registered result for job (4, 0, 16) with dispatcher
05:07:38 DISPATCHER: job (4, 0, 16) finished
05:07:38 DISPATCHER: register_result: lock acquired
05:07:38 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:07:38 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9268370034660249, 'info': {'number_mnist': 0.9268370034660249, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}"}}
exception: None

05:07:38 job_callback for (4, 0, 16) started
05:07:38 job_callback for (4, 0, 16) got condition
05:07:38 DISPATCHER: Trying to submit another job.
05:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:07:38 HBMASTER: Trying to run another job!
05:07:38 job_callback for (4, 0, 16) finished
05:07:38 HBMASTER: schedule new run for iteration 4
05:07:38 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
05:07:38 HBMASTER: submitting job (4, 0, 26) to dispatcher
05:07:38 DISPATCHER: trying to submit job (4, 0, 26)
05:07:38 DISPATCHER: trying to notify the job_runner thread.
05:07:38 HBMASTER: job (4, 0, 26) submitted to dispatcher
05:07:38 DISPATCHER: Trying to submit another job.
05:07:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:07:38 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:07:38 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:07:38 WORKER: start processing job (4, 0, 26)
05:07:38 WORKER: args: ()
05:07:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:08:28 DISPATCHER: Starting worker discovery
05:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:28 DISPATCHER: Finished worker discovery
05:09:28 DISPATCHER: Starting worker discovery
05:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:28 DISPATCHER: Finished worker discovery
05:10:28 DISPATCHER: Starting worker discovery
05:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:28 DISPATCHER: Finished worker discovery
05:11:28 DISPATCHER: Starting worker discovery
05:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:28 DISPATCHER: Finished worker discovery
05:12:28 DISPATCHER: Starting worker discovery
05:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:28 DISPATCHER: Finished worker discovery
05:13:28 DISPATCHER: Starting worker discovery
05:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:28 DISPATCHER: Finished worker discovery
05:14:26 WORKER: done with job (4, 0, 26), trying to register it.
05:14:26 WORKER: registered result for job (4, 0, 26) with dispatcher
05:14:26 DISPATCHER: job (4, 0, 26) finished
05:14:26 DISPATCHER: register_result: lock acquired
05:14:26 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:14:26 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7725097657214866, 'info': {'number_mnist': 0.7725097657214866, 'config': "{'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.003468091521442096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.059520058322476505}"}}
exception: None

05:14:26 job_callback for (4, 0, 26) started
05:14:26 job_callback for (4, 0, 26) got condition
05:14:26 DISPATCHER: Trying to submit another job.
05:14:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:14:26 HBMASTER: Trying to run another job!
05:14:26 job_callback for (4, 0, 26) finished
05:14:26 ITERATION: Advancing config (4, 0, 16) to next budget 1200.000000
05:14:26 HBMASTER: schedule new run for iteration 4
05:14:26 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
05:14:26 HBMASTER: submitting job (4, 0, 16) to dispatcher
05:14:26 DISPATCHER: trying to submit job (4, 0, 16)
05:14:26 DISPATCHER: trying to notify the job_runner thread.
05:14:26 HBMASTER: job (4, 0, 16) submitted to dispatcher
05:14:26 DISPATCHER: Trying to submit another job.
05:14:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:14:26 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:14:26 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:14:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:14:26 WORKER: start processing job (4, 0, 16)
05:14:26 WORKER: args: ()
05:14:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 1200.0, 'working_directory': '.'}
05:14:28 DISPATCHER: Starting worker discovery
05:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:28 DISPATCHER: Finished worker discovery
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:15:28 DISPATCHER: Starting worker discovery
05:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:28 DISPATCHER: Finished worker discovery
05:16:28 DISPATCHER: Starting worker discovery
05:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:28 DISPATCHER: Finished worker discovery
05:17:28 DISPATCHER: Starting worker discovery
05:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:28 DISPATCHER: Finished worker discovery
05:18:28 DISPATCHER: Starting worker discovery
05:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:28 DISPATCHER: Finished worker discovery
05:19:28 DISPATCHER: Starting worker discovery
05:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:28 DISPATCHER: Finished worker discovery
05:20:28 DISPATCHER: Starting worker discovery
05:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:28 DISPATCHER: Finished worker discovery
05:21:28 DISPATCHER: Starting worker discovery
05:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:28 DISPATCHER: Finished worker discovery
05:22:28 DISPATCHER: Starting worker discovery
05:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:28 DISPATCHER: Finished worker discovery
05:23:28 DISPATCHER: Starting worker discovery
05:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:28 DISPATCHER: Finished worker discovery
05:24:28 DISPATCHER: Starting worker discovery
05:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:28 DISPATCHER: Finished worker discovery
05:25:28 DISPATCHER: Starting worker discovery
05:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:28 DISPATCHER: Finished worker discovery
05:26:28 DISPATCHER: Starting worker discovery
05:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:28 DISPATCHER: Finished worker discovery
05:27:28 DISPATCHER: Starting worker discovery
05:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:28 DISPATCHER: Finished worker discovery
05:28:28 DISPATCHER: Starting worker discovery
05:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:28 DISPATCHER: Finished worker discovery
05:29:28 DISPATCHER: Starting worker discovery
05:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:28 DISPATCHER: Finished worker discovery
05:30:28 DISPATCHER: Starting worker discovery
05:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:28 DISPATCHER: Finished worker discovery
05:31:28 DISPATCHER: Starting worker discovery
05:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:28 DISPATCHER: Finished worker discovery
05:32:28 DISPATCHER: Starting worker discovery
05:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:28 DISPATCHER: Finished worker discovery
05:33:28 DISPATCHER: Starting worker discovery
05:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:28 DISPATCHER: Finished worker discovery
05:34:28 DISPATCHER: Starting worker discovery
05:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:28 DISPATCHER: Finished worker discovery
05:34:34 WORKER: done with job (4, 0, 16), trying to register it.
05:34:34 WORKER: registered result for job (4, 0, 16) with dispatcher
05:34:34 DISPATCHER: job (4, 0, 16) finished
05:34:34 DISPATCHER: register_result: lock acquired
05:34:34 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:34:34 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9298095377479305, 'info': {'number_mnist': 0.9298095377479305, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 44, 'lr': 0.0016575545751584934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04482608638755581}"}}
exception: None

05:34:34 job_callback for (4, 0, 16) started
05:34:34 job_callback for (4, 0, 16) got condition
05:34:34 DISPATCHER: Trying to submit another job.
05:34:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:34:34 HBMASTER: Trying to run another job!
05:34:34 job_callback for (4, 0, 16) finished
05:34:34 start sampling a new configuration.
05:34:34 done sampling a new configuration.
05:34:34 HBMASTER: schedule new run for iteration 5
05:34:34 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
05:34:34 HBMASTER: submitting job (5, 0, 0) to dispatcher
05:34:34 DISPATCHER: trying to submit job (5, 0, 0)
05:34:34 DISPATCHER: trying to notify the job_runner thread.
05:34:34 HBMASTER: job (5, 0, 0) submitted to dispatcher
05:34:34 DISPATCHER: Trying to submit another job.
05:34:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:34:34 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:34:34 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:34:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:34:34 WORKER: start processing job (5, 0, 0)
05:34:34 WORKER: args: ()
05:34:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 28, 'lr': 0.03588338636777915, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.016739126366345614}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:35:28 DISPATCHER: Starting worker discovery
05:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:28 DISPATCHER: Finished worker discovery
05:36:28 DISPATCHER: Starting worker discovery
05:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:28 DISPATCHER: Finished worker discovery
05:36:55 WORKER: done with job (5, 0, 0), trying to register it.
05:36:55 WORKER: registered result for job (5, 0, 0) with dispatcher
05:36:55 DISPATCHER: job (5, 0, 0) finished
05:36:55 DISPATCHER: register_result: lock acquired
05:36:55 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:36:55 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 28, 'lr': 0.03588338636777915, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.016739126366345614}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.017311096344077674, 'info': {'number_mnist': 0.017311096344077674, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 28, 'lr': 0.03588338636777915, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.016739126366345614}"}}
exception: None

05:36:55 job_callback for (5, 0, 0) started
05:36:55 DISPATCHER: Trying to submit another job.
05:36:55 job_callback for (5, 0, 0) got condition
05:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:36:55 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.930364





05:36:55 HBMASTER: Trying to run another job!
05:36:55 job_callback for (5, 0, 0) finished
05:36:55 start sampling a new configuration.
05:36:55 best_vector: [0, 0.9124453973338812, 0.8338684953602337, 0.13768070007669964, 0.1000245996053035, 1, 0.9994520432896676, 0.36713044912808873], 0.00016671975128629206, 222.73440579698524, 0.03713422473737343
05:36:55 done sampling a new configuration.
05:36:55 HBMASTER: schedule new run for iteration 5
05:36:55 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
05:36:55 HBMASTER: submitting job (5, 0, 1) to dispatcher
05:36:55 DISPATCHER: trying to submit job (5, 0, 1)
05:36:55 DISPATCHER: trying to notify the job_runner thread.
05:36:55 HBMASTER: job (5, 0, 1) submitted to dispatcher
05:36:55 DISPATCHER: Trying to submit another job.
05:36:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:36:55 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:36:55 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:36:55 WORKER: start processing job (5, 0, 1)
05:36:55 WORKER: args: ()
05:36:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 42, 'lr': 0.0018852172291321954, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.03003638944370788}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:37:28 DISPATCHER: Starting worker discovery
05:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:28 DISPATCHER: Finished worker discovery
05:38:28 DISPATCHER: Starting worker discovery
05:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:28 DISPATCHER: Finished worker discovery
05:39:17 WORKER: done with job (5, 0, 1), trying to register it.
05:39:17 WORKER: registered result for job (5, 0, 1) with dispatcher
05:39:17 DISPATCHER: job (5, 0, 1) finished
05:39:17 DISPATCHER: register_result: lock acquired
05:39:17 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:39:17 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 42, 'lr': 0.0018852172291321954, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.03003638944370788}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05734632927742143, 'info': {'number_mnist': 0.05734632927742143, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 42, 'lr': 0.0018852172291321954, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.03003638944370788}"}}
exception: None

05:39:17 job_callback for (5, 0, 1) started
05:39:17 job_callback for (5, 0, 1) got condition
05:39:17 DISPATCHER: Trying to submit another job.
05:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:39:17 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.930364





05:39:17 HBMASTER: Trying to run another job!
05:39:17 job_callback for (5, 0, 1) finished
05:39:17 start sampling a new configuration.
05:39:17 done sampling a new configuration.
05:39:17 HBMASTER: schedule new run for iteration 5
05:39:17 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
05:39:17 HBMASTER: submitting job (5, 0, 2) to dispatcher
05:39:17 DISPATCHER: trying to submit job (5, 0, 2)
05:39:17 DISPATCHER: trying to notify the job_runner thread.
05:39:17 HBMASTER: job (5, 0, 2) submitted to dispatcher
05:39:17 DISPATCHER: Trying to submit another job.
05:39:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:39:17 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:39:17 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:39:17 WORKER: start processing job (5, 0, 2)
05:39:17 WORKER: args: ()
05:39:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 36, 'lr': 0.08076856180528157, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.033481823479284814}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:39:28 DISPATCHER: Starting worker discovery
05:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:28 DISPATCHER: Finished worker discovery
05:40:28 DISPATCHER: Starting worker discovery
05:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:28 DISPATCHER: Finished worker discovery
05:41:28 DISPATCHER: Starting worker discovery
05:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:28 DISPATCHER: Finished worker discovery
05:41:38 WORKER: done with job (5, 0, 2), trying to register it.
05:41:38 WORKER: registered result for job (5, 0, 2) with dispatcher
05:41:38 DISPATCHER: job (5, 0, 2) finished
05:41:38 DISPATCHER: register_result: lock acquired
05:41:38 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:41:38 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 36, 'lr': 0.08076856180528157, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.033481823479284814}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 36, 'lr': 0.08076856180528157, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.033481823479284814}"}}
exception: None

05:41:38 job_callback for (5, 0, 2) started
05:41:38 DISPATCHER: Trying to submit another job.
05:41:38 job_callback for (5, 0, 2) got condition
05:41:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:41:38 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.930364





05:41:38 HBMASTER: Trying to run another job!
05:41:38 job_callback for (5, 0, 2) finished
05:41:38 start sampling a new configuration.
05:41:38 done sampling a new configuration.
05:41:38 HBMASTER: schedule new run for iteration 5
05:41:38 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
05:41:38 HBMASTER: submitting job (5, 0, 3) to dispatcher
05:41:38 DISPATCHER: trying to submit job (5, 0, 3)
05:41:38 DISPATCHER: trying to notify the job_runner thread.
05:41:38 HBMASTER: job (5, 0, 3) submitted to dispatcher
05:41:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:41:38 DISPATCHER: Trying to submit another job.
05:41:38 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:41:38 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:41:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:41:38 WORKER: start processing job (5, 0, 3)
05:41:38 WORKER: args: ()
05:41:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 2, 'lr': 0.04322431969899902, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.0777022972433825}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:42:28 DISPATCHER: Starting worker discovery
05:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:28 DISPATCHER: Finished worker discovery
05:43:28 DISPATCHER: Starting worker discovery
05:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:28 DISPATCHER: Finished worker discovery
05:43:59 WORKER: done with job (5, 0, 3), trying to register it.
05:43:59 WORKER: registered result for job (5, 0, 3) with dispatcher
05:43:59 DISPATCHER: job (5, 0, 3) finished
05:43:59 DISPATCHER: register_result: lock acquired
05:43:59 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:43:59 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 2, 'lr': 0.04322431969899902, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.0777022972433825}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 2, 'lr': 0.04322431969899902, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.0777022972433825}"}}
exception: None

05:43:59 job_callback for (5, 0, 3) started
05:43:59 DISPATCHER: Trying to submit another job.
05:43:59 job_callback for (5, 0, 3) got condition
05:43:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:43:59 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.930364





05:43:59 HBMASTER: Trying to run another job!
05:43:59 job_callback for (5, 0, 3) finished
05:43:59 start sampling a new configuration.
05:43:59 done sampling a new configuration.
05:43:59 HBMASTER: schedule new run for iteration 5
05:43:59 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
05:43:59 HBMASTER: submitting job (5, 0, 4) to dispatcher
05:43:59 DISPATCHER: trying to submit job (5, 0, 4)
05:43:59 DISPATCHER: trying to notify the job_runner thread.
05:43:59 HBMASTER: job (5, 0, 4) submitted to dispatcher
05:43:59 DISPATCHER: Trying to submit another job.
05:43:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:43:59 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:43:59 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:43:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:43:59 WORKER: start processing job (5, 0, 4)
05:43:59 WORKER: args: ()
05:43:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 30, 'lr': 0.015355703707320695, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.024461067907286454}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:44:28 DISPATCHER: Starting worker discovery
05:44:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:28 DISPATCHER: Finished worker discovery
05:45:28 DISPATCHER: Starting worker discovery
05:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:28 DISPATCHER: Finished worker discovery
05:46:21 WORKER: done with job (5, 0, 4), trying to register it.
05:46:21 WORKER: registered result for job (5, 0, 4) with dispatcher
05:46:21 DISPATCHER: job (5, 0, 4) finished
05:46:21 DISPATCHER: register_result: lock acquired
05:46:21 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:46:21 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 30, 'lr': 0.015355703707320695, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.024461067907286454}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.01088246150608074, 'info': {'number_mnist': -0.01088246150608074, 'config': "{'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 30, 'lr': 0.015355703707320695, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.024461067907286454}"}}
exception: None

05:46:21 job_callback for (5, 0, 4) started
05:46:21 job_callback for (5, 0, 4) got condition
05:46:21 DISPATCHER: Trying to submit another job.
05:46:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:46:21 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.930364





05:46:21 HBMASTER: Trying to run another job!
05:46:21 job_callback for (5, 0, 4) finished
05:46:21 start sampling a new configuration.
05:46:21 best_vector: [2, 0.9870239194456963, 0.9542625160109084, 0.535771242346145, 0.10042512711157589, 1, 0.8247151784324374, 0.002094249540690707], 0.0001452021175638495, 106.09108826243036, 0.015404650670358148
05:46:21 done sampling a new configuration.
05:46:21 HBMASTER: schedule new run for iteration 5
05:46:21 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
05:46:21 HBMASTER: submitting job (5, 0, 5) to dispatcher
05:46:21 DISPATCHER: trying to submit job (5, 0, 5)
05:46:21 DISPATCHER: trying to notify the job_runner thread.
05:46:21 HBMASTER: job (5, 0, 5) submitted to dispatcher
05:46:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:46:21 DISPATCHER: Trying to submit another job.
05:46:21 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:46:21 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:46:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:46:21 WORKER: start processing job (5, 0, 5)
05:46:21 WORKER: args: ()
05:46:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 99, 'last_n_outputs': 48, 'lr': 0.011790778604449288, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.010062935325113345}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:46:28 DISPATCHER: Starting worker discovery
05:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:28 DISPATCHER: Finished worker discovery
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:47:28 DISPATCHER: Starting worker discovery
05:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:28 DISPATCHER: Finished worker discovery
05:48:28 DISPATCHER: Starting worker discovery
05:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:28 DISPATCHER: Finished worker discovery
05:48:42 WORKER: done with job (5, 0, 5), trying to register it.
05:48:42 WORKER: registered result for job (5, 0, 5) with dispatcher
05:48:42 DISPATCHER: job (5, 0, 5) finished
05:48:42 DISPATCHER: register_result: lock acquired
05:48:42 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:48:42 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 99, 'last_n_outputs': 48, 'lr': 0.011790778604449288, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.010062935325113345}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2241470278886411, 'info': {'number_mnist': 0.2241470278886411, 'config': "{'batch_size': 64, 'hidden_dim': 99, 'last_n_outputs': 48, 'lr': 0.011790778604449288, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.010062935325113345}"}}
exception: None

05:48:42 job_callback for (5, 0, 5) started
05:48:42 DISPATCHER: Trying to submit another job.
05:48:42 job_callback for (5, 0, 5) got condition
05:48:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:48:42 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.930364





05:48:42 HBMASTER: Trying to run another job!
05:48:42 job_callback for (5, 0, 5) finished
05:48:42 start sampling a new configuration.
05:48:42 best_vector: [0, 0.865170946756101, 0.9408303919161192, 0.565176912007536, 0.10091147414650226, 0, 0.4783049807588637, 0.009769141977821971], 0.00016193340813663629, 98.31088956230616, 0.0159198174037687
05:48:42 done sampling a new configuration.
05:48:42 HBMASTER: schedule new run for iteration 5
05:48:42 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:48:42 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:48:42 DISPATCHER: trying to submit job (5, 0, 6)
05:48:42 DISPATCHER: trying to notify the job_runner thread.
05:48:42 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:48:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:48:42 DISPATCHER: Trying to submit another job.
05:48:42 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:48:42 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:48:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:48:42 WORKER: start processing job (5, 0, 6)
05:48:42 WORKER: args: ()
05:48:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 48, 'lr': 0.01350062343820568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.01029698183844878}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:49:28 DISPATCHER: Starting worker discovery
05:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:28 DISPATCHER: Finished worker discovery
05:50:28 DISPATCHER: Starting worker discovery
05:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:28 DISPATCHER: Finished worker discovery
05:51:04 WORKER: done with job (5, 0, 6), trying to register it.
05:51:04 WORKER: registered result for job (5, 0, 6) with dispatcher
05:51:04 DISPATCHER: job (5, 0, 6) finished
05:51:04 DISPATCHER: register_result: lock acquired
05:51:04 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:51:04 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 48, 'lr': 0.01350062343820568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.01029698183844878}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4076328827273453, 'info': {'number_mnist': 0.4076328827273453, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 48, 'lr': 0.01350062343820568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.01029698183844878}"}}
exception: None

05:51:04 job_callback for (5, 0, 6) started
05:51:04 job_callback for (5, 0, 6) got condition
05:51:04 DISPATCHER: Trying to submit another job.
05:51:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:51:04 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.930364





05:51:04 HBMASTER: Trying to run another job!
05:51:04 job_callback for (5, 0, 6) finished
05:51:04 start sampling a new configuration.
05:51:04 best_vector: [0, 0.9987452274586377, 0.39933592887643626, 0.20405099780849723, 0.09897877338125256, 0, 0.99244851659813, 0.9111411246543508], 0.00015842843884283366, 13.873200697981217, 0.0021979095283344743
05:51:04 done sampling a new configuration.
05:51:04 HBMASTER: schedule new run for iteration 5
05:51:04 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
05:51:04 HBMASTER: submitting job (5, 0, 7) to dispatcher
05:51:04 DISPATCHER: trying to submit job (5, 0, 7)
05:51:04 DISPATCHER: trying to notify the job_runner thread.
05:51:04 HBMASTER: job (5, 0, 7) submitted to dispatcher
05:51:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:51:04 DISPATCHER: Trying to submit another job.
05:51:04 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:51:04 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:51:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:51:04 WORKER: start processing job (5, 0, 7)
05:51:04 WORKER: args: ()
05:51:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 20, 'lr': 0.002559186850545925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.15325756936795248}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:51:28 DISPATCHER: Starting worker discovery
05:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:28 DISPATCHER: Finished worker discovery
05:52:28 DISPATCHER: Starting worker discovery
05:52:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:28 DISPATCHER: Finished worker discovery
05:53:25 WORKER: done with job (5, 0, 7), trying to register it.
05:53:25 WORKER: registered result for job (5, 0, 7) with dispatcher
05:53:25 DISPATCHER: job (5, 0, 7) finished
05:53:25 DISPATCHER: register_result: lock acquired
05:53:25 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:53:25 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 20, 'lr': 0.002559186850545925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.15325756936795248}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2660876516948795, 'info': {'number_mnist': 0.2660876516948795, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 20, 'lr': 0.002559186850545925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.15325756936795248}"}}
exception: None

05:53:25 job_callback for (5, 0, 7) started
05:53:25 job_callback for (5, 0, 7) got condition
05:53:25 DISPATCHER: Trying to submit another job.
05:53:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:53:25 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.930364





05:53:25 HBMASTER: Trying to run another job!
05:53:25 job_callback for (5, 0, 7) finished
05:53:25 start sampling a new configuration.
05:53:26 best_vector: [2, 0.8549859226318219, 0.20106452524437313, 0.04947441598745038, 0.09827718521215137, 0, 0.8878426655426728, 0.9177832545278621], 5.143486469294446e-05, 21.060793140618088, 0.0010832590455137842
05:53:26 done sampling a new configuration.
05:53:26 HBMASTER: schedule new run for iteration 5
05:53:26 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
05:53:26 HBMASTER: submitting job (5, 0, 8) to dispatcher
05:53:26 DISPATCHER: trying to submit job (5, 0, 8)
05:53:26 DISPATCHER: trying to notify the job_runner thread.
05:53:26 HBMASTER: job (5, 0, 8) submitted to dispatcher
05:53:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:53:26 DISPATCHER: Trying to submit another job.
05:53:26 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:53:26 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:53:26 WORKER: start processing job (5, 0, 8)
05:53:26 WORKER: args: ()
05:53:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:53:28 DISPATCHER: Starting worker discovery
05:53:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:28 DISPATCHER: Finished worker discovery
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:54:28 DISPATCHER: Starting worker discovery
05:54:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:28 DISPATCHER: Finished worker discovery
05:55:28 DISPATCHER: Starting worker discovery
05:55:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:28 DISPATCHER: Finished worker discovery
05:55:47 WORKER: done with job (5, 0, 8), trying to register it.
05:55:47 WORKER: registered result for job (5, 0, 8) with dispatcher
05:55:47 DISPATCHER: job (5, 0, 8) finished
05:55:47 DISPATCHER: register_result: lock acquired
05:55:47 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
05:55:47 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4043161261899961, 'info': {'number_mnist': 0.4043161261899961, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}"}}
exception: None

05:55:47 job_callback for (5, 0, 8) started
05:55:47 DISPATCHER: Trying to submit another job.
05:55:47 job_callback for (5, 0, 8) got condition
05:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:55:47 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.930364





05:55:47 HBMASTER: Trying to run another job!
05:55:47 job_callback for (5, 0, 8) finished
05:55:47 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
05:55:47 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
05:55:47 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
05:55:47 HBMASTER: schedule new run for iteration 5
05:55:47 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:55:47 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:55:47 DISPATCHER: trying to submit job (5, 0, 6)
05:55:47 DISPATCHER: trying to notify the job_runner thread.
05:55:47 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:55:47 DISPATCHER: Trying to submit another job.
05:55:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:55:47 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
05:55:47 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
05:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:55:47 WORKER: start processing job (5, 0, 6)
05:55:47 WORKER: args: ()
05:55:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 48, 'lr': 0.01350062343820568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.01029698183844878}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:56:28 DISPATCHER: Starting worker discovery
05:56:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:28 DISPATCHER: Finished worker discovery
05:57:28 DISPATCHER: Starting worker discovery
05:57:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:28 DISPATCHER: Finished worker discovery
05:58:28 DISPATCHER: Starting worker discovery
05:58:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:28 DISPATCHER: Finished worker discovery
05:59:28 DISPATCHER: Starting worker discovery
05:59:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:28 DISPATCHER: Finished worker discovery
06:00:28 DISPATCHER: Starting worker discovery
06:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:28 DISPATCHER: Finished worker discovery
06:01:28 DISPATCHER: Starting worker discovery
06:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:28 DISPATCHER: Finished worker discovery
06:02:28 DISPATCHER: Starting worker discovery
06:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:28 DISPATCHER: Finished worker discovery
06:02:35 WORKER: done with job (5, 0, 6), trying to register it.
06:02:35 WORKER: registered result for job (5, 0, 6) with dispatcher
06:02:35 DISPATCHER: job (5, 0, 6) finished
06:02:35 DISPATCHER: register_result: lock acquired
06:02:35 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:02:35 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 48, 'lr': 0.01350062343820568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.01029698183844878}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12229509820629775, 'info': {'number_mnist': 0.12229509820629775, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 48, 'lr': 0.01350062343820568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.01029698183844878}"}}
exception: None

06:02:35 job_callback for (5, 0, 6) started
06:02:35 DISPATCHER: Trying to submit another job.
06:02:35 job_callback for (5, 0, 6) got condition
06:02:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:02:35 HBMASTER: Trying to run another job!
06:02:35 job_callback for (5, 0, 6) finished
06:02:35 HBMASTER: schedule new run for iteration 5
06:02:35 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
06:02:35 HBMASTER: submitting job (5, 0, 7) to dispatcher
06:02:35 DISPATCHER: trying to submit job (5, 0, 7)
06:02:35 DISPATCHER: trying to notify the job_runner thread.
06:02:35 HBMASTER: job (5, 0, 7) submitted to dispatcher
06:02:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:02:35 DISPATCHER: Trying to submit another job.
06:02:35 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:02:35 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:02:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:02:35 WORKER: start processing job (5, 0, 7)
06:02:35 WORKER: args: ()
06:02:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 20, 'lr': 0.002559186850545925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.15325756936795248}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:03:28 DISPATCHER: Starting worker discovery
06:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:28 DISPATCHER: Finished worker discovery
06:04:28 DISPATCHER: Starting worker discovery
06:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:28 DISPATCHER: Finished worker discovery
06:05:28 DISPATCHER: Starting worker discovery
06:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:28 DISPATCHER: Finished worker discovery
06:06:28 DISPATCHER: Starting worker discovery
06:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:28 DISPATCHER: Finished worker discovery
06:07:28 DISPATCHER: Starting worker discovery
06:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:28 DISPATCHER: Finished worker discovery
06:08:28 DISPATCHER: Starting worker discovery
06:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:28 DISPATCHER: Finished worker discovery
06:09:23 WORKER: done with job (5, 0, 7), trying to register it.
06:09:23 WORKER: registered result for job (5, 0, 7) with dispatcher
06:09:23 DISPATCHER: job (5, 0, 7) finished
06:09:23 DISPATCHER: register_result: lock acquired
06:09:23 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:09:23 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 20, 'lr': 0.002559186850545925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.15325756936795248}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.24434489774411378, 'info': {'number_mnist': 0.24434489774411378, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 20, 'lr': 0.002559186850545925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.15325756936795248}"}}
exception: None

06:09:23 job_callback for (5, 0, 7) started
06:09:23 job_callback for (5, 0, 7) got condition
06:09:23 DISPATCHER: Trying to submit another job.
06:09:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:09:23 HBMASTER: Trying to run another job!
06:09:23 job_callback for (5, 0, 7) finished
06:09:23 HBMASTER: schedule new run for iteration 5
06:09:23 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:09:23 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:09:23 DISPATCHER: trying to submit job (5, 0, 8)
06:09:23 DISPATCHER: trying to notify the job_runner thread.
06:09:23 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:09:23 DISPATCHER: Trying to submit another job.
06:09:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:09:23 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:09:23 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:09:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:09:23 WORKER: start processing job (5, 0, 8)
06:09:23 WORKER: args: ()
06:09:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}, 'budget': 400.0, 'working_directory': '.'}
06:09:28 DISPATCHER: Starting worker discovery
06:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:28 DISPATCHER: Finished worker discovery
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:10:28 DISPATCHER: Starting worker discovery
06:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:28 DISPATCHER: Finished worker discovery
06:11:28 DISPATCHER: Starting worker discovery
06:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:28 DISPATCHER: Finished worker discovery
06:12:28 DISPATCHER: Starting worker discovery
06:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:28 DISPATCHER: Finished worker discovery
06:13:28 DISPATCHER: Starting worker discovery
06:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:28 DISPATCHER: Finished worker discovery
06:14:28 DISPATCHER: Starting worker discovery
06:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:28 DISPATCHER: Finished worker discovery
06:15:28 DISPATCHER: Starting worker discovery
06:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:28 DISPATCHER: Finished worker discovery
06:16:11 WORKER: done with job (5, 0, 8), trying to register it.
06:16:11 WORKER: registered result for job (5, 0, 8) with dispatcher
06:16:11 DISPATCHER: job (5, 0, 8) finished
06:16:11 DISPATCHER: register_result: lock acquired
06:16:11 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:16:11 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6517971414648513, 'info': {'number_mnist': 0.6517971414648513, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}"}}
exception: None

06:16:11 job_callback for (5, 0, 8) started
06:16:11 DISPATCHER: Trying to submit another job.
06:16:11 job_callback for (5, 0, 8) got condition
06:16:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:16:11 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.926837





06:16:11 HBMASTER: Trying to run another job!
06:16:11 job_callback for (5, 0, 8) finished
06:16:11 ITERATION: Advancing config (5, 0, 8) to next budget 1200.000000
06:16:11 HBMASTER: schedule new run for iteration 5
06:16:11 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:16:11 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:16:11 DISPATCHER: trying to submit job (5, 0, 8)
06:16:11 DISPATCHER: trying to notify the job_runner thread.
06:16:11 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:16:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:16:11 DISPATCHER: Trying to submit another job.
06:16:11 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:16:11 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:16:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:16:11 WORKER: start processing job (5, 0, 8)
06:16:11 WORKER: args: ()
06:16:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:16:28 DISPATCHER: Starting worker discovery
06:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:28 DISPATCHER: Finished worker discovery
06:17:28 DISPATCHER: Starting worker discovery
06:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:28 DISPATCHER: Finished worker discovery
06:18:28 DISPATCHER: Starting worker discovery
06:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:28 DISPATCHER: Finished worker discovery
06:19:28 DISPATCHER: Starting worker discovery
06:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:28 DISPATCHER: Finished worker discovery
06:20:28 DISPATCHER: Starting worker discovery
06:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:28 DISPATCHER: Finished worker discovery
06:21:28 DISPATCHER: Starting worker discovery
06:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:28 DISPATCHER: Finished worker discovery
06:22:28 DISPATCHER: Starting worker discovery
06:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:28 DISPATCHER: Finished worker discovery
06:23:28 DISPATCHER: Starting worker discovery
06:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:28 DISPATCHER: Finished worker discovery
06:24:28 DISPATCHER: Starting worker discovery
06:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:28 DISPATCHER: Finished worker discovery
06:25:28 DISPATCHER: Starting worker discovery
06:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:28 DISPATCHER: Finished worker discovery
06:26:28 DISPATCHER: Starting worker discovery
06:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:28 DISPATCHER: Finished worker discovery
06:27:28 DISPATCHER: Starting worker discovery
06:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:28 DISPATCHER: Finished worker discovery
06:28:28 DISPATCHER: Starting worker discovery
06:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:28 DISPATCHER: Finished worker discovery
06:29:28 DISPATCHER: Starting worker discovery
06:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:28 DISPATCHER: Finished worker discovery
06:30:28 DISPATCHER: Starting worker discovery
06:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:28 DISPATCHER: Finished worker discovery
06:31:28 DISPATCHER: Starting worker discovery
06:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:28 DISPATCHER: Finished worker discovery
06:32:28 DISPATCHER: Starting worker discovery
06:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:28 DISPATCHER: Finished worker discovery
06:33:28 DISPATCHER: Starting worker discovery
06:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:28 DISPATCHER: Finished worker discovery
06:34:28 DISPATCHER: Starting worker discovery
06:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:28 DISPATCHER: Finished worker discovery
06:35:28 DISPATCHER: Starting worker discovery
06:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:28 DISPATCHER: Finished worker discovery
06:36:19 WORKER: done with job (5, 0, 8), trying to register it.
06:36:19 WORKER: registered result for job (5, 0, 8) with dispatcher
06:36:19 DISPATCHER: job (5, 0, 8) finished
06:36:19 DISPATCHER: register_result: lock acquired
06:36:19 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:36:19 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6983645130413466, 'info': {'number_mnist': 0.6983645130413466, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 11, 'lr': 0.0012558819885547037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.15633763708233853}"}}
exception: None

06:36:19 job_callback for (5, 0, 8) started
06:36:19 job_callback for (5, 0, 8) got condition
06:36:19 DISPATCHER: Trying to submit another job.
06:36:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:36:19 HBMASTER: Trying to run another job!
06:36:19 job_callback for (5, 0, 8) finished
06:36:19 start sampling a new configuration.
06:36:19 best_vector: [0, 0.6498790412252474, 0.8548230992656892, 0.5610948818186625, 0.0987045510868996, 0, 0.48522167198451466, 0.058354497507595054], 5.853280497955763e-34, 17.084436673575553, -0.11715993379457851
06:36:19 done sampling a new configuration.
06:36:19 HBMASTER: schedule new run for iteration 6
06:36:19 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
06:36:19 HBMASTER: submitting job (6, 0, 0) to dispatcher
06:36:19 DISPATCHER: trying to submit job (6, 0, 0)
06:36:19 DISPATCHER: trying to notify the job_runner thread.
06:36:19 HBMASTER: job (6, 0, 0) submitted to dispatcher
06:36:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:36:19 DISPATCHER: Trying to submit another job.
06:36:19 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:36:19 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:36:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:36:19 WORKER: start processing job (6, 0, 0)
06:36:19 WORKER: args: ()
06:36:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.013249203285945919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.01191025203157445}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:36:28 DISPATCHER: Starting worker discovery
06:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:28 DISPATCHER: Finished worker discovery
06:37:28 DISPATCHER: Starting worker discovery
06:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:28 DISPATCHER: Finished worker discovery
06:38:28 DISPATCHER: Starting worker discovery
06:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:28 DISPATCHER: Finished worker discovery
06:39:28 DISPATCHER: Starting worker discovery
06:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:28 DISPATCHER: Finished worker discovery
06:40:28 DISPATCHER: Starting worker discovery
06:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:28 DISPATCHER: Finished worker discovery
06:41:28 DISPATCHER: Starting worker discovery
06:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:28 DISPATCHER: Finished worker discovery
06:42:28 DISPATCHER: Starting worker discovery
06:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:28 DISPATCHER: Finished worker discovery
06:43:08 WORKER: done with job (6, 0, 0), trying to register it.
06:43:08 WORKER: registered result for job (6, 0, 0) with dispatcher
06:43:08 DISPATCHER: job (6, 0, 0) finished
06:43:08 DISPATCHER: register_result: lock acquired
06:43:08 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:43:08 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.013249203285945919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.01191025203157445}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3381513993105605, 'info': {'number_mnist': 0.3381513993105605, 'config': "{'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.013249203285945919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.01191025203157445}"}}
exception: None

06:43:08 job_callback for (6, 0, 0) started
06:43:08 DISPATCHER: Trying to submit another job.
06:43:08 job_callback for (6, 0, 0) got condition
06:43:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:43:08 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.926837





06:43:08 HBMASTER: Trying to run another job!
06:43:08 job_callback for (6, 0, 0) finished
06:43:08 start sampling a new configuration.
06:43:08 best_vector: [0, 0.9091264021742796, 0.9678450239436331, 0.6732871427993148, 0.09814912822518614, 0, 0.6307477436434682, 0.04120173691854914], 2.479847401698773e-34, 40.325061909654956, -0.13069234562311224
06:43:08 done sampling a new configuration.
06:43:08 HBMASTER: schedule new run for iteration 6
06:43:08 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
06:43:08 HBMASTER: submitting job (6, 0, 1) to dispatcher
06:43:08 DISPATCHER: trying to submit job (6, 0, 1)
06:43:08 DISPATCHER: trying to notify the job_runner thread.
06:43:08 HBMASTER: job (6, 0, 1) submitted to dispatcher
06:43:08 DISPATCHER: Trying to submit another job.
06:43:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:43:08 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:43:08 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:43:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:43:08 WORKER: start processing job (6, 0, 1)
06:43:08 WORKER: args: ()
06:43:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 49, 'lr': 0.022211315730990243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01131370096459612}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:43:28 DISPATCHER: Starting worker discovery
06:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:28 DISPATCHER: Finished worker discovery
06:44:28 DISPATCHER: Starting worker discovery
06:44:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:28 DISPATCHER: Finished worker discovery
06:45:28 DISPATCHER: Starting worker discovery
06:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:28 DISPATCHER: Finished worker discovery
06:46:28 DISPATCHER: Starting worker discovery
06:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:28 DISPATCHER: Finished worker discovery
06:47:28 DISPATCHER: Starting worker discovery
06:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:28 DISPATCHER: Finished worker discovery
06:48:28 DISPATCHER: Starting worker discovery
06:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:28 DISPATCHER: Finished worker discovery
06:49:28 DISPATCHER: Starting worker discovery
06:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:28 DISPATCHER: Finished worker discovery
06:49:56 WORKER: done with job (6, 0, 1), trying to register it.
06:49:56 WORKER: registered result for job (6, 0, 1) with dispatcher
06:49:56 DISPATCHER: job (6, 0, 1) finished
06:49:56 DISPATCHER: register_result: lock acquired
06:49:56 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:49:56 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 49, 'lr': 0.022211315730990243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01131370096459612}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.21961047949125534, 'info': {'number_mnist': 0.21961047949125534, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 49, 'lr': 0.022211315730990243, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01131370096459612}"}}
exception: None

06:49:56 job_callback for (6, 0, 1) started
06:49:56 DISPATCHER: Trying to submit another job.
06:49:56 job_callback for (6, 0, 1) got condition
06:49:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:49:56 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.926837





06:49:56 HBMASTER: Trying to run another job!
06:49:56 job_callback for (6, 0, 1) finished
06:49:56 start sampling a new configuration.
06:49:56 best_vector: [0, 0.5097323138420702, 0.7754965044009864, 0.793797466983255, 0.1026111698727351, 0, 0.3762065085466699, 0.12183003352620875], 5.562002104411565e-33, 1.7979137390236488, -0.03659971817010233
06:49:56 done sampling a new configuration.
06:49:56 HBMASTER: schedule new run for iteration 6
06:49:56 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
06:49:56 HBMASTER: submitting job (6, 0, 2) to dispatcher
06:49:56 DISPATCHER: trying to submit job (6, 0, 2)
06:49:56 DISPATCHER: trying to notify the job_runner thread.
06:49:56 HBMASTER: job (6, 0, 2) submitted to dispatcher
06:49:56 DISPATCHER: Trying to submit another job.
06:49:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:49:56 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:49:56 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:49:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:49:56 WORKER: start processing job (6, 0, 2)
06:49:56 WORKER: args: ()
06:49:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 61, 'last_n_outputs': 39, 'lr': 0.03868966184901022, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.014404710286386926}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:50:28 DISPATCHER: Starting worker discovery
06:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:28 DISPATCHER: Finished worker discovery
06:51:28 DISPATCHER: Starting worker discovery
06:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:28 DISPATCHER: Finished worker discovery
06:52:28 DISPATCHER: Starting worker discovery
06:52:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:28 DISPATCHER: Finished worker discovery
06:53:28 DISPATCHER: Starting worker discovery
06:53:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:28 DISPATCHER: Finished worker discovery
06:54:28 DISPATCHER: Starting worker discovery
06:54:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:28 DISPATCHER: Finished worker discovery
06:55:28 DISPATCHER: Starting worker discovery
06:55:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:28 DISPATCHER: Finished worker discovery
06:56:28 DISPATCHER: Starting worker discovery
06:56:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:28 DISPATCHER: Finished worker discovery
06:56:44 WORKER: done with job (6, 0, 2), trying to register it.
06:56:44 WORKER: registered result for job (6, 0, 2) with dispatcher
06:56:44 DISPATCHER: job (6, 0, 2) finished
06:56:44 DISPATCHER: register_result: lock acquired
06:56:44 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
06:56:44 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 61, 'last_n_outputs': 39, 'lr': 0.03868966184901022, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.014404710286386926}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03198915655433534, 'info': {'number_mnist': 0.03198915655433534, 'config': "{'batch_size': 16, 'hidden_dim': 61, 'last_n_outputs': 39, 'lr': 0.03868966184901022, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.014404710286386926}"}}
exception: None

06:56:44 job_callback for (6, 0, 2) started
06:56:44 DISPATCHER: Trying to submit another job.
06:56:44 job_callback for (6, 0, 2) got condition
06:56:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:56:44 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.926837





06:56:44 HBMASTER: Trying to run another job!
06:56:44 job_callback for (6, 0, 2) finished
06:56:44 start sampling a new configuration.
06:56:44 best_vector: [3, 0.6421050263877441, 0.07144612137198825, 0.295834151262504, 0.09870733313856866, 0, 0.3042903160749676, 0.8179390023366411], 1.3575420845170924e-32, 0.7366254139780293, -0.0025062408113392465
06:56:44 done sampling a new configuration.
06:56:44 HBMASTER: schedule new run for iteration 6
06:56:44 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
06:56:44 HBMASTER: submitting job (6, 0, 3) to dispatcher
06:56:44 DISPATCHER: trying to submit job (6, 0, 3)
06:56:44 DISPATCHER: trying to notify the job_runner thread.
06:56:44 HBMASTER: job (6, 0, 3) submitted to dispatcher
06:56:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:56:44 DISPATCHER: Trying to submit another job.
06:56:44 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
06:56:44 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
06:56:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:56:44 WORKER: start processing job (6, 0, 3)
06:56:44 WORKER: args: ()
06:56:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 4, 'lr': 0.003905425004664879, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.11592128232341167}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:57:28 DISPATCHER: Starting worker discovery
06:57:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:28 DISPATCHER: Finished worker discovery
06:58:28 DISPATCHER: Starting worker discovery
06:58:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:28 DISPATCHER: Finished worker discovery
06:59:28 DISPATCHER: Starting worker discovery
06:59:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:28 DISPATCHER: Finished worker discovery
07:00:28 DISPATCHER: Starting worker discovery
07:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:28 DISPATCHER: Finished worker discovery
07:01:28 DISPATCHER: Starting worker discovery
07:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:28 DISPATCHER: Finished worker discovery
07:02:28 DISPATCHER: Starting worker discovery
07:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:28 DISPATCHER: Finished worker discovery
07:03:28 DISPATCHER: Starting worker discovery
07:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:28 DISPATCHER: Finished worker discovery
07:03:32 WORKER: done with job (6, 0, 3), trying to register it.
07:03:32 WORKER: registered result for job (6, 0, 3) with dispatcher
07:03:32 DISPATCHER: job (6, 0, 3) finished
07:03:32 DISPATCHER: register_result: lock acquired
07:03:32 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:03:32 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 4, 'lr': 0.003905425004664879, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.11592128232341167}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.33659691997352165, 'info': {'number_mnist': 0.33659691997352165, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 4, 'lr': 0.003905425004664879, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.11592128232341167}"}}
exception: None

07:03:32 job_callback for (6, 0, 3) started
07:03:32 DISPATCHER: Trying to submit another job.
07:03:32 job_callback for (6, 0, 3) got condition
07:03:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:03:32 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.926837





07:03:32 HBMASTER: Trying to run another job!
07:03:32 job_callback for (6, 0, 3) finished
07:03:32 start sampling a new configuration.
07:03:32 done sampling a new configuration.
07:03:32 HBMASTER: schedule new run for iteration 6
07:03:32 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
07:03:32 HBMASTER: submitting job (6, 0, 4) to dispatcher
07:03:32 DISPATCHER: trying to submit job (6, 0, 4)
07:03:32 DISPATCHER: trying to notify the job_runner thread.
07:03:32 HBMASTER: job (6, 0, 4) submitted to dispatcher
07:03:32 DISPATCHER: Trying to submit another job.
07:03:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:03:32 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:03:32 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:03:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:03:32 WORKER: start processing job (6, 0, 4)
07:03:32 WORKER: args: ()
07:03:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 50, 'lr': 0.0011081343539970272, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.037661400319115905}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:04:28 DISPATCHER: Starting worker discovery
07:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:28 DISPATCHER: Finished worker discovery
07:05:28 DISPATCHER: Starting worker discovery
07:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:28 DISPATCHER: Finished worker discovery
07:06:28 DISPATCHER: Starting worker discovery
07:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:28 DISPATCHER: Finished worker discovery
07:07:28 DISPATCHER: Starting worker discovery
07:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:28 DISPATCHER: Finished worker discovery
07:08:28 DISPATCHER: Starting worker discovery
07:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:28 DISPATCHER: Finished worker discovery
07:09:28 DISPATCHER: Starting worker discovery
07:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:28 DISPATCHER: Finished worker discovery
07:10:20 WORKER: done with job (6, 0, 4), trying to register it.
07:10:20 WORKER: registered result for job (6, 0, 4) with dispatcher
07:10:20 DISPATCHER: job (6, 0, 4) finished
07:10:20 DISPATCHER: register_result: lock acquired
07:10:20 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:10:20 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 50, 'lr': 0.0011081343539970272, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.037661400319115905}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 50, 'lr': 0.0011081343539970272, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.037661400319115905}"}}
exception: None

07:10:20 job_callback for (6, 0, 4) started
07:10:20 DISPATCHER: Trying to submit another job.
07:10:20 job_callback for (6, 0, 4) got condition
07:10:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:10:20 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.926837





07:10:20 HBMASTER: Trying to run another job!
07:10:20 job_callback for (6, 0, 4) finished
07:10:20 start sampling a new configuration.
07:10:20 best_vector: [3, 0.9461412907299058, 0.5080198383720145, 0.5225069996787377, 0.09910800431238198, 0, 0.9788059991913479, 0.3572634912375036], 8.217129342109668e-35, 121.69700127213281, -0.0012936442204040963
07:10:20 done sampling a new configuration.
07:10:20 HBMASTER: schedule new run for iteration 6
07:10:20 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:10:20 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:10:20 DISPATCHER: trying to submit job (6, 0, 5)
07:10:20 DISPATCHER: trying to notify the job_runner thread.
07:10:20 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:10:20 DISPATCHER: Trying to submit another job.
07:10:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:10:20 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:10:20 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:10:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:10:20 WORKER: start processing job (6, 0, 5)
07:10:20 WORKER: args: ()
07:10:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.011092105697692107, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02916154425873789}, 'budget': 400.0, 'working_directory': '.'}
07:10:28 DISPATCHER: Starting worker discovery
07:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:28 DISPATCHER: Finished worker discovery
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:11:29 DISPATCHER: Starting worker discovery
07:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:29 DISPATCHER: Finished worker discovery
07:12:29 DISPATCHER: Starting worker discovery
07:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:29 DISPATCHER: Finished worker discovery
07:13:29 DISPATCHER: Starting worker discovery
07:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:29 DISPATCHER: Finished worker discovery
07:14:29 DISPATCHER: Starting worker discovery
07:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:29 DISPATCHER: Finished worker discovery
07:15:29 DISPATCHER: Starting worker discovery
07:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:29 DISPATCHER: Finished worker discovery
07:16:29 DISPATCHER: Starting worker discovery
07:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:29 DISPATCHER: Finished worker discovery
07:17:08 WORKER: done with job (6, 0, 5), trying to register it.
07:17:08 WORKER: registered result for job (6, 0, 5) with dispatcher
07:17:08 DISPATCHER: job (6, 0, 5) finished
07:17:08 DISPATCHER: register_result: lock acquired
07:17:08 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:17:08 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.011092105697692107, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02916154425873789}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7448154266469443, 'info': {'number_mnist': 0.7448154266469443, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.011092105697692107, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02916154425873789}"}}
exception: None

07:17:08 job_callback for (6, 0, 5) started
07:17:08 job_callback for (6, 0, 5) got condition
07:17:08 DISPATCHER: Trying to submit another job.
07:17:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:17:08 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.926837





07:17:08 HBMASTER: Trying to run another job!
07:17:08 job_callback for (6, 0, 5) finished
07:17:08 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
07:17:08 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
07:17:08 HBMASTER: schedule new run for iteration 6
07:17:08 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
07:17:08 HBMASTER: submitting job (6, 0, 0) to dispatcher
07:17:08 DISPATCHER: trying to submit job (6, 0, 0)
07:17:08 DISPATCHER: trying to notify the job_runner thread.
07:17:08 HBMASTER: job (6, 0, 0) submitted to dispatcher
07:17:08 DISPATCHER: Trying to submit another job.
07:17:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:17:08 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:17:08 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:17:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:17:08 WORKER: start processing job (6, 0, 0)
07:17:08 WORKER: args: ()
07:17:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.013249203285945919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.01191025203157445}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:17:29 DISPATCHER: Starting worker discovery
07:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:29 DISPATCHER: Finished worker discovery
07:18:29 DISPATCHER: Starting worker discovery
07:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:29 DISPATCHER: Finished worker discovery
07:19:29 DISPATCHER: Starting worker discovery
07:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:29 DISPATCHER: Finished worker discovery
07:20:29 DISPATCHER: Starting worker discovery
07:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:29 DISPATCHER: Finished worker discovery
07:21:29 DISPATCHER: Starting worker discovery
07:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:29 DISPATCHER: Finished worker discovery
07:22:29 DISPATCHER: Starting worker discovery
07:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:29 DISPATCHER: Finished worker discovery
07:23:29 DISPATCHER: Starting worker discovery
07:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:29 DISPATCHER: Finished worker discovery
07:24:29 DISPATCHER: Starting worker discovery
07:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:29 DISPATCHER: Finished worker discovery
07:25:29 DISPATCHER: Starting worker discovery
07:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:29 DISPATCHER: Finished worker discovery
07:26:29 DISPATCHER: Starting worker discovery
07:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:29 DISPATCHER: Finished worker discovery
07:27:29 DISPATCHER: Starting worker discovery
07:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:29 DISPATCHER: Finished worker discovery
07:28:29 DISPATCHER: Starting worker discovery
07:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:29 DISPATCHER: Finished worker discovery
07:29:29 DISPATCHER: Starting worker discovery
07:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:29 DISPATCHER: Finished worker discovery
07:30:29 DISPATCHER: Starting worker discovery
07:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:29 DISPATCHER: Finished worker discovery
07:31:29 DISPATCHER: Starting worker discovery
07:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:29 DISPATCHER: Finished worker discovery
07:32:29 DISPATCHER: Starting worker discovery
07:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:29 DISPATCHER: Finished worker discovery
07:33:29 DISPATCHER: Starting worker discovery
07:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:29 DISPATCHER: Finished worker discovery
07:34:29 DISPATCHER: Starting worker discovery
07:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:29 DISPATCHER: Finished worker discovery
07:35:29 DISPATCHER: Starting worker discovery
07:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:29 DISPATCHER: Finished worker discovery
07:36:29 DISPATCHER: Starting worker discovery
07:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:29 DISPATCHER: Finished worker discovery
07:37:16 WORKER: done with job (6, 0, 0), trying to register it.
07:37:16 WORKER: registered result for job (6, 0, 0) with dispatcher
07:37:16 DISPATCHER: job (6, 0, 0) finished
07:37:16 DISPATCHER: register_result: lock acquired
07:37:16 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:37:16 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.013249203285945919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.01191025203157445}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3127344054406459, 'info': {'number_mnist': 0.3127344054406459, 'config': "{'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.013249203285945919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.01191025203157445}"}}
exception: None

07:37:16 job_callback for (6, 0, 0) started
07:37:16 DISPATCHER: Trying to submit another job.
07:37:16 job_callback for (6, 0, 0) got condition
07:37:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:37:16 HBMASTER: Trying to run another job!
07:37:16 job_callback for (6, 0, 0) finished
07:37:16 HBMASTER: schedule new run for iteration 6
07:37:16 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:37:16 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:37:16 DISPATCHER: trying to submit job (6, 0, 5)
07:37:16 DISPATCHER: trying to notify the job_runner thread.
07:37:16 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:37:16 DISPATCHER: Trying to submit another job.
07:37:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:37:16 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:37:16 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:37:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:37:16 WORKER: start processing job (6, 0, 5)
07:37:16 WORKER: args: ()
07:37:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.011092105697692107, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02916154425873789}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:37:29 DISPATCHER: Starting worker discovery
07:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:29 DISPATCHER: Finished worker discovery
07:38:29 DISPATCHER: Starting worker discovery
07:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:29 DISPATCHER: Finished worker discovery
07:39:29 DISPATCHER: Starting worker discovery
07:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:29 DISPATCHER: Finished worker discovery
07:40:29 DISPATCHER: Starting worker discovery
07:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:29 DISPATCHER: Finished worker discovery
07:41:29 DISPATCHER: Starting worker discovery
07:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:29 DISPATCHER: Finished worker discovery
07:42:29 DISPATCHER: Starting worker discovery
07:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:29 DISPATCHER: Finished worker discovery
07:43:29 DISPATCHER: Starting worker discovery
07:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:29 DISPATCHER: Finished worker discovery
07:44:29 DISPATCHER: Starting worker discovery
07:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:29 DISPATCHER: Finished worker discovery
07:45:29 DISPATCHER: Starting worker discovery
07:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:29 DISPATCHER: Finished worker discovery
07:46:29 DISPATCHER: Starting worker discovery
07:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:29 DISPATCHER: Finished worker discovery
07:47:29 DISPATCHER: Starting worker discovery
07:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:29 DISPATCHER: Finished worker discovery
07:48:29 DISPATCHER: Starting worker discovery
07:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:29 DISPATCHER: Finished worker discovery
07:49:29 DISPATCHER: Starting worker discovery
07:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:29 DISPATCHER: Finished worker discovery
07:50:29 DISPATCHER: Starting worker discovery
07:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:29 DISPATCHER: Finished worker discovery
07:51:29 DISPATCHER: Starting worker discovery
07:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:29 DISPATCHER: Finished worker discovery
07:52:29 DISPATCHER: Starting worker discovery
07:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:29 DISPATCHER: Finished worker discovery
07:53:29 DISPATCHER: Starting worker discovery
07:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:29 DISPATCHER: Finished worker discovery
07:54:29 DISPATCHER: Starting worker discovery
07:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:29 DISPATCHER: Finished worker discovery
07:55:29 DISPATCHER: Starting worker discovery
07:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:29 DISPATCHER: Finished worker discovery
07:56:29 DISPATCHER: Starting worker discovery
07:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:29 DISPATCHER: Finished worker discovery
07:57:24 WORKER: done with job (6, 0, 5), trying to register it.
07:57:24 WORKER: registered result for job (6, 0, 5) with dispatcher
07:57:24 DISPATCHER: job (6, 0, 5) finished
07:57:24 DISPATCHER: register_result: lock acquired
07:57:24 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
07:57:24 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.011092105697692107, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02916154425873789}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8306173564708637, 'info': {'number_mnist': 0.8306173564708637, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.011092105697692107, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02916154425873789}"}}
exception: None

07:57:24 job_callback for (6, 0, 5) started
07:57:24 job_callback for (6, 0, 5) got condition
07:57:24 DISPATCHER: Trying to submit another job.
07:57:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:57:24 HBMASTER: Trying to run another job!
07:57:24 job_callback for (6, 0, 5) finished
07:57:24 start sampling a new configuration.
07:57:24 done sampling a new configuration.
07:57:24 HBMASTER: schedule new run for iteration 7
07:57:24 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
07:57:24 HBMASTER: submitting job (7, 0, 0) to dispatcher
07:57:24 DISPATCHER: trying to submit job (7, 0, 0)
07:57:24 DISPATCHER: trying to notify the job_runner thread.
07:57:24 HBMASTER: job (7, 0, 0) submitted to dispatcher
07:57:24 DISPATCHER: Trying to submit another job.
07:57:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:57:24 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
07:57:24 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
07:57:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:57:24 WORKER: start processing job (7, 0, 0)
07:57:24 WORKER: args: ()
07:57:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 68, 'last_n_outputs': 28, 'lr': 0.0027679510110069122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.130308762667339}, 'budget': 1200.0, 'working_directory': '.'}
07:57:29 DISPATCHER: Starting worker discovery
07:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:29 DISPATCHER: Finished worker discovery
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:58:29 DISPATCHER: Starting worker discovery
07:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:29 DISPATCHER: Finished worker discovery
07:59:29 DISPATCHER: Starting worker discovery
07:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:29 DISPATCHER: Finished worker discovery
08:00:29 DISPATCHER: Starting worker discovery
08:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:29 DISPATCHER: Finished worker discovery
08:01:29 DISPATCHER: Starting worker discovery
08:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:29 DISPATCHER: Finished worker discovery
08:02:29 DISPATCHER: Starting worker discovery
08:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:29 DISPATCHER: Finished worker discovery
08:03:29 DISPATCHER: Starting worker discovery
08:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:29 DISPATCHER: Finished worker discovery
08:04:29 DISPATCHER: Starting worker discovery
08:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:29 DISPATCHER: Finished worker discovery
08:05:29 DISPATCHER: Starting worker discovery
08:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:29 DISPATCHER: Finished worker discovery
08:06:29 DISPATCHER: Starting worker discovery
08:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:29 DISPATCHER: Finished worker discovery
08:07:29 DISPATCHER: Starting worker discovery
08:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:29 DISPATCHER: Finished worker discovery
08:08:29 DISPATCHER: Starting worker discovery
08:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:29 DISPATCHER: Finished worker discovery
08:09:29 DISPATCHER: Starting worker discovery
08:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:29 DISPATCHER: Finished worker discovery
08:10:29 DISPATCHER: Starting worker discovery
08:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:29 DISPATCHER: Finished worker discovery
08:11:29 DISPATCHER: Starting worker discovery
08:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:29 DISPATCHER: Finished worker discovery
08:12:29 DISPATCHER: Starting worker discovery
08:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:29 DISPATCHER: Finished worker discovery
08:13:29 DISPATCHER: Starting worker discovery
08:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:29 DISPATCHER: Finished worker discovery
08:14:29 DISPATCHER: Starting worker discovery
08:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:29 DISPATCHER: Finished worker discovery
08:15:29 DISPATCHER: Starting worker discovery
08:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:29 DISPATCHER: Finished worker discovery
08:16:29 DISPATCHER: Starting worker discovery
08:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:29 DISPATCHER: Finished worker discovery
08:17:29 DISPATCHER: Starting worker discovery
08:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:29 DISPATCHER: Finished worker discovery
08:17:32 WORKER: done with job (7, 0, 0), trying to register it.
08:17:32 WORKER: registered result for job (7, 0, 0) with dispatcher
08:17:32 DISPATCHER: job (7, 0, 0) finished
08:17:32 DISPATCHER: register_result: lock acquired
08:17:32 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:17:32 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 68, 'last_n_outputs': 28, 'lr': 0.0027679510110069122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.130308762667339}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.05502777665415533, 'info': {'number_mnist': 0.05502777665415533, 'config': "{'batch_size': 128, 'hidden_dim': 68, 'last_n_outputs': 28, 'lr': 0.0027679510110069122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.130308762667339}"}}
exception: None

08:17:32 job_callback for (7, 0, 0) started
08:17:32 DISPATCHER: Trying to submit another job.
08:17:32 job_callback for (7, 0, 0) got condition
08:17:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:17:32 HBMASTER: Trying to run another job!
08:17:32 job_callback for (7, 0, 0) finished
08:17:32 start sampling a new configuration.
08:17:32 best_vector: [0, 0.3446266730624211, 0.6604110088839155, 0.9195268932983348, 0.09835198602041739, 0, 0.5952506375624812, 0.14383753163062798], 3.719788359485118e-33, 2.6883249888400025, -0.03202760035691362
08:17:32 done sampling a new configuration.
08:17:32 HBMASTER: schedule new run for iteration 7
08:17:32 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
08:17:32 HBMASTER: submitting job (7, 0, 1) to dispatcher
08:17:32 DISPATCHER: trying to submit job (7, 0, 1)
08:17:32 DISPATCHER: trying to notify the job_runner thread.
08:17:32 HBMASTER: job (7, 0, 1) submitted to dispatcher
08:17:32 DISPATCHER: Trying to submit another job.
08:17:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:17:32 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:17:32 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:17:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:17:32 WORKER: start processing job (7, 0, 1)
08:17:32 WORKER: args: ()
08:17:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 34, 'lr': 0.06903252941021482, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.015386397327217007}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:18:29 DISPATCHER: Starting worker discovery
08:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:29 DISPATCHER: Finished worker discovery
08:19:29 DISPATCHER: Starting worker discovery
08:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:29 DISPATCHER: Finished worker discovery
08:20:29 DISPATCHER: Starting worker discovery
08:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:29 DISPATCHER: Finished worker discovery
08:21:29 DISPATCHER: Starting worker discovery
08:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:29 DISPATCHER: Finished worker discovery
08:22:29 DISPATCHER: Starting worker discovery
08:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:29 DISPATCHER: Finished worker discovery
08:23:29 DISPATCHER: Starting worker discovery
08:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:29 DISPATCHER: Finished worker discovery
08:24:29 DISPATCHER: Starting worker discovery
08:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:29 DISPATCHER: Finished worker discovery
08:25:29 DISPATCHER: Starting worker discovery
08:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:29 DISPATCHER: Finished worker discovery
08:26:29 DISPATCHER: Starting worker discovery
08:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:29 DISPATCHER: Finished worker discovery
08:27:29 DISPATCHER: Starting worker discovery
08:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:29 DISPATCHER: Finished worker discovery
08:28:29 DISPATCHER: Starting worker discovery
08:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:29 DISPATCHER: Finished worker discovery
08:29:29 DISPATCHER: Starting worker discovery
08:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:29 DISPATCHER: Finished worker discovery
08:30:29 DISPATCHER: Starting worker discovery
08:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:29 DISPATCHER: Finished worker discovery
08:31:29 DISPATCHER: Starting worker discovery
08:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:29 DISPATCHER: Finished worker discovery
08:32:29 DISPATCHER: Starting worker discovery
08:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:29 DISPATCHER: Finished worker discovery
08:33:29 DISPATCHER: Starting worker discovery
08:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:29 DISPATCHER: Finished worker discovery
08:34:29 DISPATCHER: Starting worker discovery
08:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:29 DISPATCHER: Finished worker discovery
08:35:29 DISPATCHER: Starting worker discovery
08:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:29 DISPATCHER: Finished worker discovery
08:36:29 DISPATCHER: Starting worker discovery
08:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:29 DISPATCHER: Finished worker discovery
08:37:29 DISPATCHER: Starting worker discovery
08:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:29 DISPATCHER: Finished worker discovery
08:37:40 WORKER: done with job (7, 0, 1), trying to register it.
08:37:40 WORKER: registered result for job (7, 0, 1) with dispatcher
08:37:40 DISPATCHER: job (7, 0, 1) finished
08:37:40 DISPATCHER: register_result: lock acquired
08:37:40 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:37:40 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 34, 'lr': 0.06903252941021482, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.015386397327217007}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.02858663217140152, 'info': {'number_mnist': 0.02858663217140152, 'config': "{'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 34, 'lr': 0.06903252941021482, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.015386397327217007}"}}
exception: None

08:37:40 job_callback for (7, 0, 1) started
08:37:40 job_callback for (7, 0, 1) got condition
08:37:40 DISPATCHER: Trying to submit another job.
08:37:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:37:40 HBMASTER: Trying to run another job!
08:37:40 job_callback for (7, 0, 1) finished
08:37:40 start sampling a new configuration.
08:37:40 done sampling a new configuration.
08:37:40 HBMASTER: schedule new run for iteration 7
08:37:40 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
08:37:40 HBMASTER: submitting job (7, 0, 2) to dispatcher
08:37:40 DISPATCHER: trying to submit job (7, 0, 2)
08:37:40 DISPATCHER: trying to notify the job_runner thread.
08:37:40 HBMASTER: job (7, 0, 2) submitted to dispatcher
08:37:40 DISPATCHER: Trying to submit another job.
08:37:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:37:40 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:37:40 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:37:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:37:40 WORKER: start processing job (7, 0, 2)
08:37:40 WORKER: args: ()
08:37:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 33, 'lr': 0.013257652652560199, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.04639405816802041}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:38:29 DISPATCHER: Starting worker discovery
08:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:29 DISPATCHER: Finished worker discovery
08:39:29 DISPATCHER: Starting worker discovery
08:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:29 DISPATCHER: Finished worker discovery
08:40:29 DISPATCHER: Starting worker discovery
08:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:29 DISPATCHER: Finished worker discovery
08:41:29 DISPATCHER: Starting worker discovery
08:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:29 DISPATCHER: Finished worker discovery
08:42:29 DISPATCHER: Starting worker discovery
08:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:29 DISPATCHER: Finished worker discovery
08:43:29 DISPATCHER: Starting worker discovery
08:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:29 DISPATCHER: Finished worker discovery
08:44:29 DISPATCHER: Starting worker discovery
08:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:29 DISPATCHER: Finished worker discovery
08:45:29 DISPATCHER: Starting worker discovery
08:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:29 DISPATCHER: Finished worker discovery
08:46:29 DISPATCHER: Starting worker discovery
08:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:29 DISPATCHER: Finished worker discovery
08:47:29 DISPATCHER: Starting worker discovery
08:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:29 DISPATCHER: Finished worker discovery
08:48:29 DISPATCHER: Starting worker discovery
08:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:29 DISPATCHER: Finished worker discovery
08:49:29 DISPATCHER: Starting worker discovery
08:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:29 DISPATCHER: Finished worker discovery
08:50:29 DISPATCHER: Starting worker discovery
08:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:29 DISPATCHER: Finished worker discovery
08:51:29 DISPATCHER: Starting worker discovery
08:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:29 DISPATCHER: Finished worker discovery
08:52:29 DISPATCHER: Starting worker discovery
08:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:29 DISPATCHER: Finished worker discovery
08:53:29 DISPATCHER: Starting worker discovery
08:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:29 DISPATCHER: Finished worker discovery
08:54:29 DISPATCHER: Starting worker discovery
08:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:29 DISPATCHER: Finished worker discovery
08:55:29 DISPATCHER: Starting worker discovery
08:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:29 DISPATCHER: Finished worker discovery
08:56:29 DISPATCHER: Starting worker discovery
08:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:29 DISPATCHER: Finished worker discovery
08:57:29 DISPATCHER: Starting worker discovery
08:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:29 DISPATCHER: Finished worker discovery
08:57:48 WORKER: done with job (7, 0, 2), trying to register it.
08:57:48 WORKER: registered result for job (7, 0, 2) with dispatcher
08:57:48 DISPATCHER: job (7, 0, 2) finished
08:57:48 DISPATCHER: register_result: lock acquired
08:57:48 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
08:57:48 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 33, 'lr': 0.013257652652560199, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.04639405816802041}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18418012138447995, 'info': {'number_mnist': 0.18418012138447995, 'config': "{'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 33, 'lr': 0.013257652652560199, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.04639405816802041}"}}
exception: None

08:57:48 job_callback for (7, 0, 2) started
08:57:48 job_callback for (7, 0, 2) got condition
08:57:48 DISPATCHER: Trying to submit another job.
08:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:48 HBMASTER: Trying to run another job!
08:57:48 job_callback for (7, 0, 2) finished
08:57:48 start sampling a new configuration.
08:57:48 done sampling a new configuration.
08:57:48 HBMASTER: schedule new run for iteration 7
08:57:48 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
08:57:48 HBMASTER: submitting job (7, 0, 3) to dispatcher
08:57:48 DISPATCHER: trying to submit job (7, 0, 3)
08:57:48 DISPATCHER: trying to notify the job_runner thread.
08:57:48 HBMASTER: job (7, 0, 3) submitted to dispatcher
08:57:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:48 DISPATCHER: Trying to submit another job.
08:57:48 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
08:57:48 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
08:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:48 WORKER: start processing job (7, 0, 3)
08:57:48 WORKER: args: ()
08:57:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 39, 'lr': 0.0011494972771542951, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.07448413060277939}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:58:29 DISPATCHER: Starting worker discovery
08:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:29 DISPATCHER: Finished worker discovery
08:59:29 DISPATCHER: Starting worker discovery
08:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:29 DISPATCHER: Finished worker discovery
09:00:29 DISPATCHER: Starting worker discovery
09:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:29 DISPATCHER: Finished worker discovery
09:01:29 DISPATCHER: Starting worker discovery
09:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:29 DISPATCHER: Finished worker discovery
09:02:29 DISPATCHER: Starting worker discovery
09:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:29 DISPATCHER: Finished worker discovery
09:03:29 DISPATCHER: Starting worker discovery
09:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:29 DISPATCHER: Finished worker discovery
09:04:29 DISPATCHER: Starting worker discovery
09:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:29 DISPATCHER: Finished worker discovery
09:05:29 DISPATCHER: Starting worker discovery
09:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:29 DISPATCHER: Finished worker discovery
09:06:29 DISPATCHER: Starting worker discovery
09:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:29 DISPATCHER: Finished worker discovery
09:07:29 DISPATCHER: Starting worker discovery
09:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:29 DISPATCHER: Finished worker discovery
09:08:29 DISPATCHER: Starting worker discovery
09:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:29 DISPATCHER: Finished worker discovery
09:09:29 DISPATCHER: Starting worker discovery
09:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:29 DISPATCHER: Finished worker discovery
09:10:29 DISPATCHER: Starting worker discovery
09:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:29 DISPATCHER: Finished worker discovery
09:11:29 DISPATCHER: Starting worker discovery
09:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:29 DISPATCHER: Finished worker discovery
09:12:29 DISPATCHER: Starting worker discovery
09:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:29 DISPATCHER: Finished worker discovery
09:13:29 DISPATCHER: Starting worker discovery
09:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:29 DISPATCHER: Finished worker discovery
09:14:29 DISPATCHER: Starting worker discovery
09:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:29 DISPATCHER: Finished worker discovery
09:15:29 DISPATCHER: Starting worker discovery
09:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:29 DISPATCHER: Finished worker discovery
09:16:29 DISPATCHER: Starting worker discovery
09:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:29 DISPATCHER: Finished worker discovery
09:17:29 DISPATCHER: Starting worker discovery
09:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:29 DISPATCHER: Finished worker discovery
09:17:56 WORKER: done with job (7, 0, 3), trying to register it.
09:17:56 WORKER: registered result for job (7, 0, 3) with dispatcher
09:17:56 DISPATCHER: job (7, 0, 3) finished
09:17:56 DISPATCHER: register_result: lock acquired
09:17:56 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:17:56 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 39, 'lr': 0.0011494972771542951, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.07448413060277939}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0.0005761303595168689, 'info': {'number_mnist': -0.0005761303595168689, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 39, 'lr': 0.0011494972771542951, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.07448413060277939}"}}
exception: None

09:17:56 job_callback for (7, 0, 3) started
09:17:56 DISPATCHER: Trying to submit another job.
09:17:56 job_callback for (7, 0, 3) got condition
09:17:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:17:56 HBMASTER: Trying to run another job!
09:17:56 job_callback for (7, 0, 3) finished
09:17:56 start sampling a new configuration.
09:17:56 done sampling a new configuration.
09:17:56 HBMASTER: schedule new run for iteration 8
09:17:56 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
09:17:56 HBMASTER: submitting job (8, 0, 0) to dispatcher
09:17:56 DISPATCHER: trying to submit job (8, 0, 0)
09:17:56 DISPATCHER: trying to notify the job_runner thread.
09:17:56 HBMASTER: job (8, 0, 0) submitted to dispatcher
09:17:56 DISPATCHER: Trying to submit another job.
09:17:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:17:56 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:17:56 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:17:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:17:56 WORKER: start processing job (8, 0, 0)
09:17:56 WORKER: args: ()
09:17:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 13, 'lr': 0.001128887926055392, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.04460351374539541}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:18:29 DISPATCHER: Starting worker discovery
09:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:29 DISPATCHER: Finished worker discovery
09:18:49 WORKER: done with job (8, 0, 0), trying to register it.
09:18:49 WORKER: registered result for job (8, 0, 0) with dispatcher
09:18:49 DISPATCHER: job (8, 0, 0) finished
09:18:49 DISPATCHER: register_result: lock acquired
09:18:49 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:18:49 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 13, 'lr': 0.001128887926055392, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.04460351374539541}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 13, 'lr': 0.001128887926055392, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.04460351374539541}"}}
exception: None

09:18:49 job_callback for (8, 0, 0) started
09:18:49 DISPATCHER: Trying to submit another job.
09:18:49 job_callback for (8, 0, 0) got condition
09:18:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:18:49 HBMASTER: Trying to run another job!
09:18:49 job_callback for (8, 0, 0) finished
09:18:49 start sampling a new configuration.
09:18:49 best_vector: [3, 0.8277875889833639, 0.09328449166808706, 0.02549011239113924, 0.09907878750586437, 0, 0.9518455363369589, 0.2534077906606277], 8.116734115572413e-34, 12.320226161917063, -0.0010561194648494464
09:18:49 done sampling a new configuration.
09:18:49 HBMASTER: schedule new run for iteration 8
09:18:49 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
09:18:49 HBMASTER: submitting job (8, 0, 1) to dispatcher
09:18:49 DISPATCHER: trying to submit job (8, 0, 1)
09:18:49 DISPATCHER: trying to notify the job_runner thread.
09:18:49 HBMASTER: job (8, 0, 1) submitted to dispatcher
09:18:49 DISPATCHER: Trying to submit another job.
09:18:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:18:49 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:18:49 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:18:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:18:49 WORKER: start processing job (8, 0, 1)
09:18:49 WORKER: args: ()
09:18:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:19:29 DISPATCHER: Starting worker discovery
09:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:29 DISPATCHER: Finished worker discovery
09:19:42 WORKER: done with job (8, 0, 1), trying to register it.
09:19:42 WORKER: registered result for job (8, 0, 1) with dispatcher
09:19:42 DISPATCHER: job (8, 0, 1) finished
09:19:42 DISPATCHER: register_result: lock acquired
09:19:42 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:19:42 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7784369776753447, 'info': {'number_mnist': 0.7784369776753447, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}"}}
exception: None

09:19:42 job_callback for (8, 0, 1) started
09:19:42 job_callback for (8, 0, 1) got condition
09:19:42 DISPATCHER: Trying to submit another job.
09:19:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:19:42 HBMASTER: Trying to run another job!
09:19:42 job_callback for (8, 0, 1) finished
09:19:42 start sampling a new configuration.
09:19:42 best_vector: [3, 0.7727403584706614, 0.12565510744099384, 0.3436066185666429, 0.09907628831588118, 0, 0.6400992919749666, 0.3042032675085471], 8.253387967353382e-34, 12.116236434728883, -0.004523690054710048
09:19:42 done sampling a new configuration.
09:19:42 HBMASTER: schedule new run for iteration 8
09:19:42 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
09:19:42 HBMASTER: submitting job (8, 0, 2) to dispatcher
09:19:42 DISPATCHER: trying to submit job (8, 0, 2)
09:19:42 DISPATCHER: trying to notify the job_runner thread.
09:19:42 HBMASTER: job (8, 0, 2) submitted to dispatcher
09:19:42 DISPATCHER: Trying to submit another job.
09:19:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:19:42 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:19:42 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:19:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:19:42 WORKER: start processing job (8, 0, 2)
09:19:42 WORKER: args: ()
09:19:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:20:29 DISPATCHER: Starting worker discovery
09:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:29 DISPATCHER: Finished worker discovery
09:20:34 WORKER: done with job (8, 0, 2), trying to register it.
09:20:34 WORKER: registered result for job (8, 0, 2) with dispatcher
09:20:34 DISPATCHER: job (8, 0, 2) finished
09:20:34 DISPATCHER: register_result: lock acquired
09:20:34 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:20:34 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7876429933452177, 'info': {'number_mnist': 0.7876429933452177, 'config': "{'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}"}}
exception: None

09:20:34 job_callback for (8, 0, 2) started
09:20:34 job_callback for (8, 0, 2) got condition
09:20:34 DISPATCHER: Trying to submit another job.
09:20:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:20:34 HBMASTER: Trying to run another job!
09:20:34 job_callback for (8, 0, 2) finished
09:20:34 start sampling a new configuration.
09:20:34 best_vector: [0, 0.9964502685114923, 0.04493922536145395, 0.6799950433137196, 0.1005913753476427, 0, 0.8831560620418375, 0.7801170157086799], 9.008570791869255e-34, 11.10053995360237, -0.0024258828390155483
09:20:34 done sampling a new configuration.
09:20:34 HBMASTER: schedule new run for iteration 8
09:20:34 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
09:20:34 HBMASTER: submitting job (8, 0, 3) to dispatcher
09:20:34 DISPATCHER: trying to submit job (8, 0, 3)
09:20:34 DISPATCHER: trying to notify the job_runner thread.
09:20:34 HBMASTER: job (8, 0, 3) submitted to dispatcher
09:20:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:20:34 DISPATCHER: Trying to submit another job.
09:20:34 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:20:34 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:20:34 WORKER: start processing job (8, 0, 3)
09:20:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:20:34 WORKER: args: ()
09:20:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.02290815361140132, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.10350364340858524}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:21:26 WORKER: done with job (8, 0, 3), trying to register it.
09:21:26 WORKER: registered result for job (8, 0, 3) with dispatcher
09:21:26 DISPATCHER: job (8, 0, 3) finished
09:21:26 DISPATCHER: register_result: lock acquired
09:21:26 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:21:26 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.02290815361140132, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.10350364340858524}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.02290815361140132, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.10350364340858524}"}}
exception: None

09:21:26 job_callback for (8, 0, 3) started
09:21:26 job_callback for (8, 0, 3) got condition
09:21:26 DISPATCHER: Trying to submit another job.
09:21:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:21:26 HBMASTER: Trying to run another job!
09:21:26 job_callback for (8, 0, 3) finished
09:21:26 start sampling a new configuration.
09:21:26 best_vector: [3, 0.6778598119937995, 0.14324313645190223, 0.4650160708322867, 0.10025135486521268, 0, 0.5658136419142266, 0.1331646434447492], 9.067516326762385e-34, 11.028378267691044, -0.004271875881026402
09:21:26 done sampling a new configuration.
09:21:26 HBMASTER: schedule new run for iteration 8
09:21:26 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
09:21:26 HBMASTER: submitting job (8, 0, 4) to dispatcher
09:21:26 DISPATCHER: trying to submit job (8, 0, 4)
09:21:26 DISPATCHER: trying to notify the job_runner thread.
09:21:26 HBMASTER: job (8, 0, 4) submitted to dispatcher
09:21:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:21:26 DISPATCHER: Trying to submit another job.
09:21:26 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:21:26 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:21:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:21:26 WORKER: start processing job (8, 0, 4)
09:21:26 WORKER: args: ()
09:21:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:21:29 DISPATCHER: Starting worker discovery
09:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:29 DISPATCHER: Finished worker discovery
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:22:19 WORKER: done with job (8, 0, 4), trying to register it.
09:22:19 WORKER: registered result for job (8, 0, 4) with dispatcher
09:22:19 DISPATCHER: job (8, 0, 4) finished
09:22:19 DISPATCHER: register_result: lock acquired
09:22:19 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:22:19 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8082104676888553, 'info': {'number_mnist': 0.8082104676888553, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}"}}
exception: None

09:22:19 job_callback for (8, 0, 4) started
09:22:19 job_callback for (8, 0, 4) got condition
09:22:19 DISPATCHER: Trying to submit another job.
09:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:22:19 HBMASTER: Trying to run another job!
09:22:19 job_callback for (8, 0, 4) finished
09:22:19 start sampling a new configuration.
09:22:19 best_vector: [0, 0.9094195846862423, 0.06067734042328399, 0.38285808896565776, 0.10172210282250614, 0, 0.7590237451532177, 0.9278787687425097], 7.850856244764898e-34, 12.737464154522245, -0.018896407474200128
09:22:19 done sampling a new configuration.
09:22:19 HBMASTER: schedule new run for iteration 8
09:22:19 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
09:22:19 HBMASTER: submitting job (8, 0, 5) to dispatcher
09:22:19 DISPATCHER: trying to submit job (8, 0, 5)
09:22:19 DISPATCHER: trying to notify the job_runner thread.
09:22:19 HBMASTER: job (8, 0, 5) submitted to dispatcher
09:22:19 DISPATCHER: Trying to submit another job.
09:22:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:22:19 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:22:19 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:22:19 WORKER: start processing job (8, 0, 5)
09:22:19 WORKER: args: ()
09:22:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 4, 'lr': 0.005830639331903391, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.16113805249185245}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:22:29 DISPATCHER: Starting worker discovery
09:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:29 DISPATCHER: Finished worker discovery
09:23:11 WORKER: done with job (8, 0, 5), trying to register it.
09:23:11 WORKER: registered result for job (8, 0, 5) with dispatcher
09:23:11 DISPATCHER: job (8, 0, 5) finished
09:23:11 DISPATCHER: register_result: lock acquired
09:23:11 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:23:11 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 4, 'lr': 0.005830639331903391, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.16113805249185245}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 4, 'lr': 0.005830639331903391, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.16113805249185245}"}}
exception: None

09:23:11 job_callback for (8, 0, 5) started
09:23:11 job_callback for (8, 0, 5) got condition
09:23:11 DISPATCHER: Trying to submit another job.
09:23:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:23:11 HBMASTER: Trying to run another job!
09:23:11 job_callback for (8, 0, 5) finished
09:23:11 start sampling a new configuration.
09:23:11 best_vector: [3, 0.7245724656939452, 0.1606700305769868, 0.49502585167953755, 0.0967217447633972, 0, 0.1551231612700409, 0.8476185973744883], 5.490206651297506e-32, 0.18214250637791005, -0.0005035414050429082
09:23:11 done sampling a new configuration.
09:23:11 HBMASTER: schedule new run for iteration 8
09:23:11 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
09:23:11 HBMASTER: submitting job (8, 0, 6) to dispatcher
09:23:11 DISPATCHER: trying to submit job (8, 0, 6)
09:23:11 DISPATCHER: trying to notify the job_runner thread.
09:23:11 HBMASTER: job (8, 0, 6) submitted to dispatcher
09:23:11 DISPATCHER: Trying to submit another job.
09:23:11 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:23:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:23:11 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:23:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:23:11 WORKER: start processing job (8, 0, 6)
09:23:11 WORKER: args: ()
09:23:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.009773535693249092, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.12670017655483382}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:23:29 DISPATCHER: Starting worker discovery
09:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:29 DISPATCHER: Finished worker discovery
09:24:04 WORKER: done with job (8, 0, 6), trying to register it.
09:24:04 WORKER: registered result for job (8, 0, 6) with dispatcher
09:24:04 DISPATCHER: job (8, 0, 6) finished
09:24:04 DISPATCHER: register_result: lock acquired
09:24:04 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:24:04 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.009773535693249092, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.12670017655483382}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3104764639472586, 'info': {'number_mnist': 0.3104764639472586, 'config': "{'batch_size': 128, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.009773535693249092, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.12670017655483382}"}}
exception: None

09:24:04 job_callback for (8, 0, 6) started
09:24:04 job_callback for (8, 0, 6) got condition
09:24:04 DISPATCHER: Trying to submit another job.
09:24:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:24:04 HBMASTER: Trying to run another job!
09:24:04 job_callback for (8, 0, 6) finished
09:24:04 start sampling a new configuration.
09:24:04 done sampling a new configuration.
09:24:04 HBMASTER: schedule new run for iteration 8
09:24:04 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
09:24:04 HBMASTER: submitting job (8, 0, 7) to dispatcher
09:24:04 DISPATCHER: trying to submit job (8, 0, 7)
09:24:04 DISPATCHER: trying to notify the job_runner thread.
09:24:04 HBMASTER: job (8, 0, 7) submitted to dispatcher
09:24:04 DISPATCHER: Trying to submit another job.
09:24:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:24:04 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:24:04 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:24:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:24:04 WORKER: start processing job (8, 0, 7)
09:24:04 WORKER: args: ()
09:24:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 49, 'lr': 0.01544761961382268, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02859280925939572}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:24:29 DISPATCHER: Starting worker discovery
09:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:29 DISPATCHER: Finished worker discovery
09:24:57 WORKER: done with job (8, 0, 7), trying to register it.
09:24:57 WORKER: registered result for job (8, 0, 7) with dispatcher
09:24:57 DISPATCHER: job (8, 0, 7) finished
09:24:57 DISPATCHER: register_result: lock acquired
09:24:57 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:24:57 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 49, 'lr': 0.01544761961382268, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02859280925939572}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 49, 'lr': 0.01544761961382268, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02859280925939572}"}}
exception: None

09:24:57 job_callback for (8, 0, 7) started
09:24:57 DISPATCHER: Trying to submit another job.
09:24:57 job_callback for (8, 0, 7) got condition
09:24:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:24:57 HBMASTER: Trying to run another job!
09:24:57 job_callback for (8, 0, 7) finished
09:24:57 start sampling a new configuration.
09:24:57 done sampling a new configuration.
09:24:57 HBMASTER: schedule new run for iteration 8
09:24:57 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
09:24:57 HBMASTER: submitting job (8, 0, 8) to dispatcher
09:24:57 DISPATCHER: trying to submit job (8, 0, 8)
09:24:57 DISPATCHER: trying to notify the job_runner thread.
09:24:57 HBMASTER: job (8, 0, 8) submitted to dispatcher
09:24:57 DISPATCHER: Trying to submit another job.
09:24:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:24:57 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:24:57 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:24:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:24:57 WORKER: start processing job (8, 0, 8)
09:24:57 WORKER: args: ()
09:24:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 49, 'last_n_outputs': 17, 'lr': 0.040543802763578454, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.02123069627472903}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:25:29 DISPATCHER: Starting worker discovery
09:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:29 DISPATCHER: Finished worker discovery
09:25:49 WORKER: done with job (8, 0, 8), trying to register it.
09:25:49 WORKER: registered result for job (8, 0, 8) with dispatcher
09:25:49 DISPATCHER: job (8, 0, 8) finished
09:25:49 DISPATCHER: register_result: lock acquired
09:25:49 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:25:49 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 49, 'last_n_outputs': 17, 'lr': 0.040543802763578454, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.02123069627472903}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03566998276407564, 'info': {'number_mnist': 0.03566998276407564, 'config': "{'batch_size': 16, 'hidden_dim': 49, 'last_n_outputs': 17, 'lr': 0.040543802763578454, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.02123069627472903}"}}
exception: None

09:25:49 job_callback for (8, 0, 8) started
09:25:49 job_callback for (8, 0, 8) got condition
09:25:49 DISPATCHER: Trying to submit another job.
09:25:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:25:49 HBMASTER: Trying to run another job!
09:25:49 job_callback for (8, 0, 8) finished
09:25:49 start sampling a new configuration.
09:25:49 done sampling a new configuration.
09:25:49 HBMASTER: schedule new run for iteration 8
09:25:49 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
09:25:49 HBMASTER: submitting job (8, 0, 9) to dispatcher
09:25:49 DISPATCHER: trying to submit job (8, 0, 9)
09:25:49 DISPATCHER: trying to notify the job_runner thread.
09:25:49 HBMASTER: job (8, 0, 9) submitted to dispatcher
09:25:49 DISPATCHER: Trying to submit another job.
09:25:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:25:49 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:25:49 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:25:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:25:49 WORKER: start processing job (8, 0, 9)
09:25:49 WORKER: args: ()
09:25:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 15, 'lr': 0.001096720612189866, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.011537466147377974}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:26:29 DISPATCHER: Starting worker discovery
09:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:29 DISPATCHER: Finished worker discovery
09:26:41 WORKER: done with job (8, 0, 9), trying to register it.
09:26:41 WORKER: registered result for job (8, 0, 9) with dispatcher
09:26:41 DISPATCHER: job (8, 0, 9) finished
09:26:41 DISPATCHER: register_result: lock acquired
09:26:41 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:26:41 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 15, 'lr': 0.001096720612189866, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.011537466147377974}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.017871968328592128, 'info': {'number_mnist': 0.017871968328592128, 'config': "{'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 15, 'lr': 0.001096720612189866, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.011537466147377974}"}}
exception: None

09:26:41 job_callback for (8, 0, 9) started
09:26:41 job_callback for (8, 0, 9) got condition
09:26:41 DISPATCHER: Trying to submit another job.
09:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:26:41 HBMASTER: Trying to run another job!
09:26:41 job_callback for (8, 0, 9) finished
09:26:41 start sampling a new configuration.
09:26:41 best_vector: [0, 0.7178664672513551, 0.9956009787012093, 0.4563620666860735, 0.10204718837184144, 0, 0.4867846076471206, 0.35462563721920615], 9.389650622834439e-34, 10.650023522367562, -0.04683616342332873
09:26:41 done sampling a new configuration.
09:26:41 HBMASTER: schedule new run for iteration 8
09:26:41 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
09:26:41 HBMASTER: submitting job (8, 0, 10) to dispatcher
09:26:41 DISPATCHER: trying to submit job (8, 0, 10)
09:26:41 DISPATCHER: trying to notify the job_runner thread.
09:26:41 HBMASTER: job (8, 0, 10) submitted to dispatcher
09:26:41 DISPATCHER: Trying to submit another job.
09:26:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:26:41 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:26:41 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:26:41 WORKER: start processing job (8, 0, 10)
09:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:26:41 WORKER: args: ()
09:26:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 50, 'lr': 0.00817945059160568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02893200898206338}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:27:29 DISPATCHER: Starting worker discovery
09:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:29 DISPATCHER: Finished worker discovery
09:27:34 WORKER: done with job (8, 0, 10), trying to register it.
09:27:34 WORKER: registered result for job (8, 0, 10) with dispatcher
09:27:34 DISPATCHER: job (8, 0, 10) finished
09:27:34 DISPATCHER: register_result: lock acquired
09:27:34 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:27:34 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 50, 'lr': 0.00817945059160568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02893200898206338}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38346186278762745, 'info': {'number_mnist': 0.38346186278762745, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 50, 'lr': 0.00817945059160568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02893200898206338}"}}
exception: None

09:27:34 job_callback for (8, 0, 10) started
09:27:34 DISPATCHER: Trying to submit another job.
09:27:34 job_callback for (8, 0, 10) got condition
09:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:34 HBMASTER: Trying to run another job!
09:27:34 job_callback for (8, 0, 10) finished
09:27:34 start sampling a new configuration.
09:27:34 best_vector: [3, 0.5715069276894177, 0.06154751075129919, 0.8138396393171089, 0.09787080647415236, 0, 0.9513018193532721, 0.1928805970575198], 4.207444354047964e-32, 0.2376739692440387, -0.002870730714575142
09:27:34 done sampling a new configuration.
09:27:34 HBMASTER: schedule new run for iteration 8
09:27:34 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
09:27:34 HBMASTER: submitting job (8, 0, 11) to dispatcher
09:27:34 DISPATCHER: trying to submit job (8, 0, 11)
09:27:34 DISPATCHER: trying to notify the job_runner thread.
09:27:34 HBMASTER: job (8, 0, 11) submitted to dispatcher
09:27:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:34 DISPATCHER: Trying to submit another job.
09:27:34 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:27:34 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:34 WORKER: start processing job (8, 0, 11)
09:27:34 WORKER: args: ()
09:27:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 66, 'last_n_outputs': 4, 'lr': 0.04243061031514255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017821466655243826}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:28:26 WORKER: done with job (8, 0, 11), trying to register it.
09:28:26 WORKER: registered result for job (8, 0, 11) with dispatcher
09:28:26 DISPATCHER: job (8, 0, 11) finished
09:28:26 DISPATCHER: register_result: lock acquired
09:28:26 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:28:26 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 66, 'last_n_outputs': 4, 'lr': 0.04243061031514255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017821466655243826}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 3.2797083820718315e-05, 'info': {'number_mnist': -3.2797083820718315e-05, 'config': "{'batch_size': 128, 'hidden_dim': 66, 'last_n_outputs': 4, 'lr': 0.04243061031514255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017821466655243826}"}}
exception: None

09:28:26 job_callback for (8, 0, 11) started
09:28:26 DISPATCHER: Trying to submit another job.
09:28:26 job_callback for (8, 0, 11) got condition
09:28:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:26 HBMASTER: Trying to run another job!
09:28:26 job_callback for (8, 0, 11) finished
09:28:26 start sampling a new configuration.
09:28:26 best_vector: [0, 0.5028833286898617, 0.8007801156568938, 0.6225896682243037, 0.10157579115140992, 0, 0.6091378548695443, 0.3210319710480955], 3.430586168558252e-34, 29.149537451212396, -0.036314641463503036
09:28:26 done sampling a new configuration.
09:28:26 HBMASTER: schedule new run for iteration 8
09:28:26 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
09:28:26 HBMASTER: submitting job (8, 0, 12) to dispatcher
09:28:26 DISPATCHER: trying to submit job (8, 0, 12)
09:28:26 DISPATCHER: trying to notify the job_runner thread.
09:28:26 HBMASTER: job (8, 0, 12) submitted to dispatcher
09:28:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:26 DISPATCHER: Trying to submit another job.
09:28:26 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:28:26 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:28:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:26 WORKER: start processing job (8, 0, 12)
09:28:26 WORKER: args: ()
09:28:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 60, 'last_n_outputs': 41, 'lr': 0.01758649676322439, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.026162077262764333}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:28:29 DISPATCHER: Starting worker discovery
09:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:29 DISPATCHER: Finished worker discovery
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:29:19 WORKER: done with job (8, 0, 12), trying to register it.
09:29:19 WORKER: registered result for job (8, 0, 12) with dispatcher
09:29:19 DISPATCHER: job (8, 0, 12) finished
09:29:19 DISPATCHER: register_result: lock acquired
09:29:19 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:29:19 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 60, 'last_n_outputs': 41, 'lr': 0.01758649676322439, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.026162077262764333}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17239865821441924, 'info': {'number_mnist': 0.17239865821441924, 'config': "{'batch_size': 16, 'hidden_dim': 60, 'last_n_outputs': 41, 'lr': 0.01758649676322439, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.026162077262764333}"}}
exception: None

09:29:19 job_callback for (8, 0, 12) started
09:29:19 job_callback for (8, 0, 12) got condition
09:29:19 DISPATCHER: Trying to submit another job.
09:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:19 HBMASTER: Trying to run another job!
09:29:19 job_callback for (8, 0, 12) finished
09:29:19 start sampling a new configuration.
09:29:19 best_vector: [0, 0.7633677754470727, 0.19581210818370948, 0.017159644375756344, 0.09775840789025425, 0, 0.48245902865514945, 0.8306763786394804], 1.3221807435958852e-33, 7.56326247257495, -0.0005849916900312173
09:29:19 done sampling a new configuration.
09:29:19 HBMASTER: schedule new run for iteration 8
09:29:19 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
09:29:19 HBMASTER: submitting job (8, 0, 13) to dispatcher
09:29:19 DISPATCHER: trying to submit job (8, 0, 13)
09:29:19 DISPATCHER: trying to notify the job_runner thread.
09:29:19 HBMASTER: job (8, 0, 13) submitted to dispatcher
09:29:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:19 DISPATCHER: Trying to submit another job.
09:29:19 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:29:19 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:19 WORKER: start processing job (8, 0, 13)
09:29:19 WORKER: args: ()
09:29:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 10, 'lr': 0.0010822293025361891, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.12043005516790016}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:29:29 DISPATCHER: Starting worker discovery
09:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:29 DISPATCHER: Finished worker discovery
09:30:11 WORKER: done with job (8, 0, 13), trying to register it.
09:30:11 WORKER: registered result for job (8, 0, 13) with dispatcher
09:30:11 DISPATCHER: job (8, 0, 13) finished
09:30:11 DISPATCHER: register_result: lock acquired
09:30:11 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:30:11 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 10, 'lr': 0.0010822293025361891, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.12043005516790016}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32804868963471734, 'info': {'number_mnist': 0.32804868963471734, 'config': "{'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 10, 'lr': 0.0010822293025361891, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.12043005516790016}"}}
exception: None

09:30:11 job_callback for (8, 0, 13) started
09:30:11 job_callback for (8, 0, 13) got condition
09:30:11 DISPATCHER: Trying to submit another job.
09:30:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:30:11 HBMASTER: Trying to run another job!
09:30:11 job_callback for (8, 0, 13) finished
09:30:11 start sampling a new configuration.
09:30:11 done sampling a new configuration.
09:30:11 HBMASTER: schedule new run for iteration 8
09:30:11 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
09:30:11 HBMASTER: submitting job (8, 0, 14) to dispatcher
09:30:11 DISPATCHER: trying to submit job (8, 0, 14)
09:30:11 DISPATCHER: trying to notify the job_runner thread.
09:30:11 HBMASTER: job (8, 0, 14) submitted to dispatcher
09:30:11 DISPATCHER: Trying to submit another job.
09:30:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:30:11 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:30:11 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:30:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:30:11 WORKER: start processing job (8, 0, 14)
09:30:11 WORKER: args: ()
09:30:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 3, 'lr': 0.002769201556966291, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.025576454186381922}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:30:29 DISPATCHER: Starting worker discovery
09:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:29 DISPATCHER: Finished worker discovery
09:31:03 WORKER: done with job (8, 0, 14), trying to register it.
09:31:03 WORKER: registered result for job (8, 0, 14) with dispatcher
09:31:03 DISPATCHER: job (8, 0, 14) finished
09:31:03 DISPATCHER: register_result: lock acquired
09:31:03 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:31:03 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 3, 'lr': 0.002769201556966291, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.025576454186381922}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 3, 'lr': 0.002769201556966291, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.025576454186381922}"}}
exception: None

09:31:03 job_callback for (8, 0, 14) started
09:31:03 DISPATCHER: Trying to submit another job.
09:31:03 job_callback for (8, 0, 14) got condition
09:31:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:03 HBMASTER: Trying to run another job!
09:31:03 job_callback for (8, 0, 14) finished
09:31:03 start sampling a new configuration.
09:31:03 done sampling a new configuration.
09:31:03 HBMASTER: schedule new run for iteration 8
09:31:03 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
09:31:03 HBMASTER: submitting job (8, 0, 15) to dispatcher
09:31:03 DISPATCHER: trying to submit job (8, 0, 15)
09:31:03 DISPATCHER: trying to notify the job_runner thread.
09:31:03 HBMASTER: job (8, 0, 15) submitted to dispatcher
09:31:03 DISPATCHER: Trying to submit another job.
09:31:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:03 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:31:03 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:31:03 WORKER: start processing job (8, 0, 15)
09:31:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:03 WORKER: args: ()
09:31:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 47, 'last_n_outputs': 48, 'lr': 0.011493662637411386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015690194405165073}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:31:29 DISPATCHER: Starting worker discovery
09:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:29 DISPATCHER: Finished worker discovery
09:31:55 WORKER: done with job (8, 0, 15), trying to register it.
09:31:55 WORKER: registered result for job (8, 0, 15) with dispatcher
09:31:55 DISPATCHER: job (8, 0, 15) finished
09:31:55 DISPATCHER: register_result: lock acquired
09:31:55 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:31:55 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 47, 'last_n_outputs': 48, 'lr': 0.011493662637411386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015690194405165073}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7967434899665881, 'info': {'number_mnist': 0.7967434899665881, 'config': "{'batch_size': 128, 'hidden_dim': 47, 'last_n_outputs': 48, 'lr': 0.011493662637411386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015690194405165073}"}}
exception: None

09:31:55 job_callback for (8, 0, 15) started
09:31:55 DISPATCHER: Trying to submit another job.
09:31:55 job_callback for (8, 0, 15) got condition
09:31:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:55 HBMASTER: Trying to run another job!
09:31:55 job_callback for (8, 0, 15) finished
09:31:55 start sampling a new configuration.
09:31:55 done sampling a new configuration.
09:31:55 HBMASTER: schedule new run for iteration 8
09:31:55 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
09:31:55 HBMASTER: submitting job (8, 0, 16) to dispatcher
09:31:55 DISPATCHER: trying to submit job (8, 0, 16)
09:31:55 DISPATCHER: trying to notify the job_runner thread.
09:31:55 HBMASTER: job (8, 0, 16) submitted to dispatcher
09:31:55 DISPATCHER: Trying to submit another job.
09:31:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:55 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:31:55 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:31:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:55 WORKER: start processing job (8, 0, 16)
09:31:55 WORKER: args: ()
09:31:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 8, 'lr': 0.00406789493789853, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.15265687165328007}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:32:29 DISPATCHER: Starting worker discovery
09:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:29 DISPATCHER: Finished worker discovery
09:32:48 WORKER: done with job (8, 0, 16), trying to register it.
09:32:48 WORKER: registered result for job (8, 0, 16) with dispatcher
09:32:48 DISPATCHER: job (8, 0, 16) finished
09:32:48 DISPATCHER: register_result: lock acquired
09:32:48 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:32:48 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 8, 'lr': 0.00406789493789853, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.15265687165328007}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0029968277510605823, 'info': {'number_mnist': 0.0029968277510605823, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 8, 'lr': 0.00406789493789853, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.15265687165328007}"}}
exception: None

09:32:48 job_callback for (8, 0, 16) started
09:32:48 DISPATCHER: Trying to submit another job.
09:32:48 job_callback for (8, 0, 16) got condition
09:32:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:48 HBMASTER: Trying to run another job!
09:32:48 job_callback for (8, 0, 16) finished
09:32:48 start sampling a new configuration.
09:32:48 best_vector: [0, 0.860489008595313, 0.8252219068610472, 0.7313073664827056, 0.10092157521540876, 0, 0.6930892553181194, 0.28714520855952735], 7.370475444893775e-35, 135.67645770976614, -0.06035826654720411
09:32:48 done sampling a new configuration.
09:32:48 HBMASTER: schedule new run for iteration 8
09:32:48 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
09:32:48 HBMASTER: submitting job (8, 0, 17) to dispatcher
09:32:48 DISPATCHER: trying to submit job (8, 0, 17)
09:32:48 DISPATCHER: trying to notify the job_runner thread.
09:32:48 HBMASTER: job (8, 0, 17) submitted to dispatcher
09:32:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:48 DISPATCHER: Trying to submit another job.
09:32:48 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:32:48 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:32:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:48 WORKER: start processing job (8, 0, 17)
09:32:48 WORKER: args: ()
09:32:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.029014476088913724, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.02363657407787451}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:33:29 DISPATCHER: Starting worker discovery
09:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:29 DISPATCHER: Finished worker discovery
09:33:40 WORKER: done with job (8, 0, 17), trying to register it.
09:33:40 WORKER: registered result for job (8, 0, 17) with dispatcher
09:33:40 DISPATCHER: job (8, 0, 17) finished
09:33:40 DISPATCHER: register_result: lock acquired
09:33:40 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:33:40 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.029014476088913724, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.02363657407787451}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04404110036412653, 'info': {'number_mnist': 0.04404110036412653, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 42, 'lr': 0.029014476088913724, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.02363657407787451}"}}
exception: None

09:33:40 job_callback for (8, 0, 17) started
09:33:40 DISPATCHER: Trying to submit another job.
09:33:40 job_callback for (8, 0, 17) got condition
09:33:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:40 HBMASTER: Trying to run another job!
09:33:40 job_callback for (8, 0, 17) finished
09:33:40 start sampling a new configuration.
09:33:40 done sampling a new configuration.
09:33:40 HBMASTER: schedule new run for iteration 8
09:33:40 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
09:33:40 HBMASTER: submitting job (8, 0, 18) to dispatcher
09:33:40 DISPATCHER: trying to submit job (8, 0, 18)
09:33:40 DISPATCHER: trying to notify the job_runner thread.
09:33:40 HBMASTER: job (8, 0, 18) submitted to dispatcher
09:33:40 DISPATCHER: Trying to submit another job.
09:33:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:40 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:33:40 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:33:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:40 WORKER: start processing job (8, 0, 18)
09:33:40 WORKER: args: ()
09:33:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 45, 'lr': 0.008143243778644603, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.13647617794830738}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:34:29 DISPATCHER: Starting worker discovery
09:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:30 DISPATCHER: Finished worker discovery
09:34:32 WORKER: done with job (8, 0, 18), trying to register it.
09:34:32 WORKER: registered result for job (8, 0, 18) with dispatcher
09:34:32 DISPATCHER: job (8, 0, 18) finished
09:34:32 DISPATCHER: register_result: lock acquired
09:34:32 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:34:32 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 45, 'lr': 0.008143243778644603, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.13647617794830738}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.017385163797134666, 'info': {'number_mnist': -0.017385163797134666, 'config': "{'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 45, 'lr': 0.008143243778644603, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.13647617794830738}"}}
exception: None

09:34:32 job_callback for (8, 0, 18) started
09:34:32 job_callback for (8, 0, 18) got condition
09:34:32 DISPATCHER: Trying to submit another job.
09:34:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:34:32 HBMASTER: Trying to run another job!
09:34:32 job_callback for (8, 0, 18) finished
09:34:32 start sampling a new configuration.
09:34:32 best_vector: [0, 0.6313823477807425, 0.9068755490784767, 0.4720956217891167, 0.09615187097338285, 0, 0.9088542250288695, 0.13928159384924796], 7.319269275325623e-32, 0.13662566062040551, -0.004893472197976599
09:34:32 done sampling a new configuration.
09:34:32 HBMASTER: schedule new run for iteration 8
09:34:32 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
09:34:32 HBMASTER: submitting job (8, 0, 19) to dispatcher
09:34:32 DISPATCHER: trying to submit job (8, 0, 19)
09:34:32 DISPATCHER: trying to notify the job_runner thread.
09:34:32 HBMASTER: job (8, 0, 19) submitted to dispatcher
09:34:32 DISPATCHER: Trying to submit another job.
09:34:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:34:32 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:34:32 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:34:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:34:32 WORKER: start processing job (8, 0, 19)
09:34:32 WORKER: args: ()
09:34:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.008794096836896493, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.01517782466200281}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:35:24 WORKER: done with job (8, 0, 19), trying to register it.
09:35:24 WORKER: registered result for job (8, 0, 19) with dispatcher
09:35:24 DISPATCHER: job (8, 0, 19) finished
09:35:24 DISPATCHER: register_result: lock acquired
09:35:24 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:35:24 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.008794096836896493, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.01517782466200281}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7244075829883296, 'info': {'number_mnist': 0.7244075829883296, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.008794096836896493, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.01517782466200281}"}}
exception: None

09:35:24 job_callback for (8, 0, 19) started
09:35:24 job_callback for (8, 0, 19) got condition
09:35:24 DISPATCHER: Trying to submit another job.
09:35:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:24 HBMASTER: Trying to run another job!
09:35:24 job_callback for (8, 0, 19) finished
09:35:24 start sampling a new configuration.
09:35:25 best_vector: [0, 0.742124383322521, 0.839761598210092, 0.8174212435659733, 0.09804387790781677, 0, 0.7236522355142954, 0.5498210283077035], 1.776370150391685e-33, 5.629457350313517, -0.004884971921460541
09:35:25 done sampling a new configuration.
09:35:25 HBMASTER: schedule new run for iteration 8
09:35:25 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
09:35:25 HBMASTER: submitting job (8, 0, 20) to dispatcher
09:35:25 DISPATCHER: trying to submit job (8, 0, 20)
09:35:25 DISPATCHER: trying to notify the job_runner thread.
09:35:25 HBMASTER: job (8, 0, 20) submitted to dispatcher
09:35:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:25 DISPATCHER: Trying to submit another job.
09:35:25 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:35:25 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:35:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:25 WORKER: start processing job (8, 0, 20)
09:35:25 WORKER: args: ()
09:35:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 42, 'lr': 0.04313625989403935, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.05191987641903336}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:35:30 DISPATCHER: Starting worker discovery
09:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:30 DISPATCHER: Finished worker discovery
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:36:17 WORKER: done with job (8, 0, 20), trying to register it.
09:36:17 WORKER: registered result for job (8, 0, 20) with dispatcher
09:36:17 DISPATCHER: job (8, 0, 20) finished
09:36:17 DISPATCHER: register_result: lock acquired
09:36:17 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:36:17 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 42, 'lr': 0.04313625989403935, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.05191987641903336}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05410751291176226, 'info': {'number_mnist': 0.05410751291176226, 'config': "{'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 42, 'lr': 0.04313625989403935, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.05191987641903336}"}}
exception: None

09:36:17 job_callback for (8, 0, 20) started
09:36:17 job_callback for (8, 0, 20) got condition
09:36:17 DISPATCHER: Trying to submit another job.
09:36:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:17 HBMASTER: Trying to run another job!
09:36:17 job_callback for (8, 0, 20) finished
09:36:17 start sampling a new configuration.
09:36:17 best_vector: [0, 0.729997831902941, 0.5906805560363462, 0.19330801517528612, 0.10015202388682765, 0, 0.9248093735372351, 0.5665759726631686], 8.85145833607749e-35, 112.97573371882903, -0.00037464198872710783
09:36:17 done sampling a new configuration.
09:36:17 HBMASTER: schedule new run for iteration 8
09:36:17 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
09:36:17 HBMASTER: submitting job (8, 0, 21) to dispatcher
09:36:17 DISPATCHER: trying to submit job (8, 0, 21)
09:36:17 DISPATCHER: trying to notify the job_runner thread.
09:36:17 HBMASTER: job (8, 0, 21) submitted to dispatcher
09:36:17 DISPATCHER: Trying to submit another job.
09:36:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:17 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:36:17 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:36:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:17 WORKER: start processing job (8, 0, 21)
09:36:17 WORKER: args: ()
09:36:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 30, 'lr': 0.002435656446769097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.054592418604988355}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:36:30 DISPATCHER: Starting worker discovery
09:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:30 DISPATCHER: Finished worker discovery
09:37:09 WORKER: done with job (8, 0, 21), trying to register it.
09:37:09 WORKER: registered result for job (8, 0, 21) with dispatcher
09:37:09 DISPATCHER: job (8, 0, 21) finished
09:37:09 DISPATCHER: register_result: lock acquired
09:37:09 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:37:09 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 30, 'lr': 0.002435656446769097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.054592418604988355}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.567869984406841, 'info': {'number_mnist': 0.567869984406841, 'config': "{'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 30, 'lr': 0.002435656446769097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.054592418604988355}"}}
exception: None

09:37:09 job_callback for (8, 0, 21) started
09:37:09 DISPATCHER: Trying to submit another job.
09:37:09 job_callback for (8, 0, 21) got condition
09:37:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:37:09 HBMASTER: Trying to run another job!
09:37:09 job_callback for (8, 0, 21) finished
09:37:09 start sampling a new configuration.
09:37:09 best_vector: [0, 0.46294510093883023, 0.8485674960068355, 0.5827138532098259, 0.10069919749606025, 0, 0.5956249985219675, 0.46221684611757036], 3.2475905265872427e-34, 30.792059276353978, -0.01184470525311934
09:37:09 done sampling a new configuration.
09:37:09 HBMASTER: schedule new run for iteration 8
09:37:09 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
09:37:09 HBMASTER: submitting job (8, 0, 22) to dispatcher
09:37:09 DISPATCHER: trying to submit job (8, 0, 22)
09:37:09 DISPATCHER: trying to notify the job_runner thread.
09:37:09 HBMASTER: job (8, 0, 22) submitted to dispatcher
09:37:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:37:09 DISPATCHER: Trying to submit another job.
09:37:09 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:37:09 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:37:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:37:09 WORKER: start processing job (8, 0, 22)
09:37:09 WORKER: args: ()
09:37:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.014636178803354749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03993539471627341}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:37:30 DISPATCHER: Starting worker discovery
09:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:30 DISPATCHER: Finished worker discovery
09:38:02 WORKER: done with job (8, 0, 22), trying to register it.
09:38:02 WORKER: registered result for job (8, 0, 22) with dispatcher
09:38:02 DISPATCHER: job (8, 0, 22) finished
09:38:02 DISPATCHER: register_result: lock acquired
09:38:02 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:38:02 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.014636178803354749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03993539471627341}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39092676333569065, 'info': {'number_mnist': 0.39092676333569065, 'config': "{'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.014636178803354749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03993539471627341}"}}
exception: None

09:38:02 job_callback for (8, 0, 22) started
09:38:02 DISPATCHER: Trying to submit another job.
09:38:02 job_callback for (8, 0, 22) got condition
09:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:02 HBMASTER: Trying to run another job!
09:38:02 job_callback for (8, 0, 22) finished
09:38:02 start sampling a new configuration.
09:38:02 best_vector: [0, 0.9076475352767653, 0.6368441686942392, 0.8088206606709236, 0.09827440080328435, 0, 0.9563578980543912, 0.8640935424837637], 2.0613792704011087e-33, 4.8511208701803685, -0.0008369580671310264
09:38:02 done sampling a new configuration.
09:38:02 HBMASTER: schedule new run for iteration 8
09:38:02 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
09:38:02 HBMASTER: submitting job (8, 0, 23) to dispatcher
09:38:02 DISPATCHER: trying to submit job (8, 0, 23)
09:38:02 DISPATCHER: trying to notify the job_runner thread.
09:38:02 HBMASTER: job (8, 0, 23) submitted to dispatcher
09:38:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:02 DISPATCHER: Trying to submit another job.
09:38:02 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:38:02 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:38:02 WORKER: start processing job (8, 0, 23)
09:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:02 WORKER: args: ()
09:38:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 32, 'lr': 0.04146114784947597, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.13311028638957792}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:38:30 DISPATCHER: Starting worker discovery
09:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:30 DISPATCHER: Finished worker discovery
09:38:54 WORKER: done with job (8, 0, 23), trying to register it.
09:38:54 WORKER: registered result for job (8, 0, 23) with dispatcher
09:38:54 DISPATCHER: job (8, 0, 23) finished
09:38:54 DISPATCHER: register_result: lock acquired
09:38:54 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:38:54 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 32, 'lr': 0.04146114784947597, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.13311028638957792}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04111624884711077, 'info': {'number_mnist': 0.04111624884711077, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 32, 'lr': 0.04146114784947597, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.13311028638957792}"}}
exception: None

09:38:54 job_callback for (8, 0, 23) started
09:38:54 DISPATCHER: Trying to submit another job.
09:38:54 job_callback for (8, 0, 23) got condition
09:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:54 HBMASTER: Trying to run another job!
09:38:54 job_callback for (8, 0, 23) finished
09:38:54 start sampling a new configuration.
09:38:54 best_vector: [0, 0.8740550969706355, 0.8288067886202701, 0.590700494265375, 0.09838699099830822, 0, 0.8379545813930642, 0.9743623330114595], 1.430303392762348e-33, 6.991523651976368, -0.0009633636665937192
09:38:54 done sampling a new configuration.
09:38:54 HBMASTER: schedule new run for iteration 8
09:38:54 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
09:38:54 HBMASTER: submitting job (8, 0, 24) to dispatcher
09:38:54 DISPATCHER: trying to submit job (8, 0, 24)
09:38:54 DISPATCHER: trying to notify the job_runner thread.
09:38:54 HBMASTER: job (8, 0, 24) submitted to dispatcher
09:38:54 DISPATCHER: Trying to submit another job.
09:38:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:54 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:38:54 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:54 WORKER: start processing job (8, 0, 24)
09:38:54 WORKER: args: ()
09:38:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 42, 'lr': 0.015184517224009137, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.1852143457623283}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:39:30 DISPATCHER: Starting worker discovery
09:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:30 DISPATCHER: Finished worker discovery
09:39:46 WORKER: done with job (8, 0, 24), trying to register it.
09:39:46 WORKER: registered result for job (8, 0, 24) with dispatcher
09:39:46 DISPATCHER: job (8, 0, 24) finished
09:39:46 DISPATCHER: register_result: lock acquired
09:39:46 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:39:46 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 42, 'lr': 0.015184517224009137, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.1852143457623283}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06008925911742655, 'info': {'number_mnist': 0.06008925911742655, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 42, 'lr': 0.015184517224009137, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.1852143457623283}"}}
exception: None

09:39:46 job_callback for (8, 0, 24) started
09:39:46 job_callback for (8, 0, 24) got condition
09:39:46 DISPATCHER: Trying to submit another job.
09:39:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:46 HBMASTER: Trying to run another job!
09:39:46 job_callback for (8, 0, 24) finished
09:39:46 start sampling a new configuration.
09:39:46 best_vector: [0, 0.9934469032431615, 0.9936328485856374, 0.07993551053577569, 0.09976131188383924, 0, 0.7067919409511013, 0.6078480869728127], 4.344235509251705e-35, 230.19009855021653, -0.0039273300200561734
09:39:46 done sampling a new configuration.
09:39:46 HBMASTER: schedule new run for iteration 8
09:39:46 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
09:39:46 HBMASTER: submitting job (8, 0, 25) to dispatcher
09:39:46 DISPATCHER: trying to submit job (8, 0, 25)
09:39:46 DISPATCHER: trying to notify the job_runner thread.
09:39:46 HBMASTER: job (8, 0, 25) submitted to dispatcher
09:39:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:46 DISPATCHER: Trying to submit another job.
09:39:46 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:39:46 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:39:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:46 WORKER: start processing job (8, 0, 25)
09:39:46 WORKER: args: ()
09:39:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.0014450105606140155, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06177725314101195}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:40:30 DISPATCHER: Starting worker discovery
09:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:30 DISPATCHER: Finished worker discovery
09:40:39 WORKER: done with job (8, 0, 25), trying to register it.
09:40:39 WORKER: registered result for job (8, 0, 25) with dispatcher
09:40:39 DISPATCHER: job (8, 0, 25) finished
09:40:39 DISPATCHER: register_result: lock acquired
09:40:39 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:40:39 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.0014450105606140155, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06177725314101195}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6436302683734766, 'info': {'number_mnist': 0.6436302683734766, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.0014450105606140155, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06177725314101195}"}}
exception: None

09:40:39 job_callback for (8, 0, 25) started
09:40:39 DISPATCHER: Trying to submit another job.
09:40:39 job_callback for (8, 0, 25) got condition
09:40:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:39 HBMASTER: Trying to run another job!
09:40:39 job_callback for (8, 0, 25) finished
09:40:39 start sampling a new configuration.
09:40:39 best_vector: [0, 0.7844347233068112, 0.9173324986963929, 0.4629982801401693, 0.09908224720771269, 0, 0.41705778907975344, 0.23819066514450776], 1.247644194582388e-34, 80.15105623400272, -0.08357031348072362
09:40:39 done sampling a new configuration.
09:40:39 HBMASTER: schedule new run for iteration 8
09:40:39 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
09:40:39 HBMASTER: submitting job (8, 0, 26) to dispatcher
09:40:39 DISPATCHER: trying to submit job (8, 0, 26)
09:40:39 DISPATCHER: trying to notify the job_runner thread.
09:40:39 HBMASTER: job (8, 0, 26) submitted to dispatcher
09:40:39 DISPATCHER: Trying to submit another job.
09:40:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:39 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:40:39 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:40:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:39 WORKER: start processing job (8, 0, 26)
09:40:39 WORKER: args: ()
09:40:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 46, 'lr': 0.008433280783709592, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.02041235910382058}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:41:30 DISPATCHER: Starting worker discovery
09:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:30 DISPATCHER: Finished worker discovery
09:41:31 WORKER: done with job (8, 0, 26), trying to register it.
09:41:31 WORKER: registered result for job (8, 0, 26) with dispatcher
09:41:31 DISPATCHER: job (8, 0, 26) finished
09:41:31 DISPATCHER: register_result: lock acquired
09:41:31 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:41:31 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 46, 'lr': 0.008433280783709592, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.02041235910382058}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3374121194476442, 'info': {'number_mnist': 0.3374121194476442, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 46, 'lr': 0.008433280783709592, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.02041235910382058}"}}
exception: None

09:41:31 job_callback for (8, 0, 26) started
09:41:31 DISPATCHER: Trying to submit another job.
09:41:31 job_callback for (8, 0, 26) got condition
09:41:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:31 HBMASTER: Trying to run another job!
09:41:31 job_callback for (8, 0, 26) finished
09:41:31 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
09:41:31 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
09:41:31 HBMASTER: schedule new run for iteration 8
09:41:31 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
09:41:31 HBMASTER: submitting job (8, 0, 1) to dispatcher
09:41:31 DISPATCHER: trying to submit job (8, 0, 1)
09:41:31 DISPATCHER: trying to notify the job_runner thread.
09:41:31 HBMASTER: job (8, 0, 1) submitted to dispatcher
09:41:31 DISPATCHER: Trying to submit another job.
09:41:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:31 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:41:31 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:41:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:31 WORKER: start processing job (8, 0, 1)
09:41:31 WORKER: args: ()
09:41:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:42:30 DISPATCHER: Starting worker discovery
09:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:30 DISPATCHER: Finished worker discovery
09:43:30 DISPATCHER: Starting worker discovery
09:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:30 DISPATCHER: Finished worker discovery
09:43:52 WORKER: done with job (8, 0, 1), trying to register it.
09:43:52 WORKER: registered result for job (8, 0, 1) with dispatcher
09:43:52 DISPATCHER: job (8, 0, 1) finished
09:43:52 DISPATCHER: register_result: lock acquired
09:43:52 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:43:52 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8276698276219111, 'info': {'number_mnist': 0.8276698276219111, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}"}}
exception: None

09:43:52 job_callback for (8, 0, 1) started
09:43:52 DISPATCHER: Trying to submit another job.
09:43:52 job_callback for (8, 0, 1) got condition
09:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:52 HBMASTER: Trying to run another job!
09:43:52 job_callback for (8, 0, 1) finished
09:43:52 HBMASTER: schedule new run for iteration 8
09:43:52 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
09:43:52 HBMASTER: submitting job (8, 0, 2) to dispatcher
09:43:52 DISPATCHER: trying to submit job (8, 0, 2)
09:43:52 DISPATCHER: trying to notify the job_runner thread.
09:43:52 HBMASTER: job (8, 0, 2) submitted to dispatcher
09:43:52 DISPATCHER: Trying to submit another job.
09:43:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:52 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:43:52 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:52 WORKER: start processing job (8, 0, 2)
09:43:52 WORKER: args: ()
09:43:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:44:30 DISPATCHER: Starting worker discovery
09:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:30 DISPATCHER: Finished worker discovery
09:45:30 DISPATCHER: Starting worker discovery
09:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:30 DISPATCHER: Finished worker discovery
09:46:14 WORKER: done with job (8, 0, 2), trying to register it.
09:46:14 WORKER: registered result for job (8, 0, 2) with dispatcher
09:46:14 DISPATCHER: job (8, 0, 2) finished
09:46:14 DISPATCHER: register_result: lock acquired
09:46:14 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:46:14 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8401271049671368, 'info': {'number_mnist': 0.8401271049671368, 'config': "{'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}"}}
exception: None

09:46:14 job_callback for (8, 0, 2) started
09:46:14 job_callback for (8, 0, 2) got condition
09:46:14 DISPATCHER: Trying to submit another job.
09:46:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:46:14 HBMASTER: Trying to run another job!
09:46:14 job_callback for (8, 0, 2) finished
09:46:14 HBMASTER: schedule new run for iteration 8
09:46:14 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
09:46:14 HBMASTER: submitting job (8, 0, 4) to dispatcher
09:46:14 DISPATCHER: trying to submit job (8, 0, 4)
09:46:14 DISPATCHER: trying to notify the job_runner thread.
09:46:14 HBMASTER: job (8, 0, 4) submitted to dispatcher
09:46:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:46:14 DISPATCHER: Trying to submit another job.
09:46:14 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:46:14 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:46:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:46:14 WORKER: start processing job (8, 0, 4)
09:46:14 WORKER: args: ()
09:46:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:46:30 DISPATCHER: Starting worker discovery
09:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:30 DISPATCHER: Finished worker discovery
09:47:30 DISPATCHER: Starting worker discovery
09:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:30 DISPATCHER: Finished worker discovery
09:48:30 DISPATCHER: Starting worker discovery
09:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:30 DISPATCHER: Finished worker discovery
09:48:35 WORKER: done with job (8, 0, 4), trying to register it.
09:48:35 WORKER: registered result for job (8, 0, 4) with dispatcher
09:48:35 DISPATCHER: job (8, 0, 4) finished
09:48:35 DISPATCHER: register_result: lock acquired
09:48:35 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:48:35 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8168474352881318, 'info': {'number_mnist': 0.8168474352881318, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}"}}
exception: None

09:48:35 job_callback for (8, 0, 4) started
09:48:35 DISPATCHER: Trying to submit another job.
09:48:35 job_callback for (8, 0, 4) got condition
09:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:35 HBMASTER: Trying to run another job!
09:48:35 job_callback for (8, 0, 4) finished
09:48:35 HBMASTER: schedule new run for iteration 8
09:48:35 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
09:48:35 HBMASTER: submitting job (8, 0, 10) to dispatcher
09:48:35 DISPATCHER: trying to submit job (8, 0, 10)
09:48:35 DISPATCHER: trying to notify the job_runner thread.
09:48:35 HBMASTER: job (8, 0, 10) submitted to dispatcher
09:48:35 DISPATCHER: Trying to submit another job.
09:48:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:35 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:48:35 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:35 WORKER: start processing job (8, 0, 10)
09:48:35 WORKER: args: ()
09:48:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 50, 'lr': 0.00817945059160568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02893200898206338}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:49:30 DISPATCHER: Starting worker discovery
09:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:30 DISPATCHER: Finished worker discovery
09:50:30 DISPATCHER: Starting worker discovery
09:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:30 DISPATCHER: Finished worker discovery
09:50:56 WORKER: done with job (8, 0, 10), trying to register it.
09:50:56 WORKER: registered result for job (8, 0, 10) with dispatcher
09:50:56 DISPATCHER: job (8, 0, 10) finished
09:50:56 DISPATCHER: register_result: lock acquired
09:50:56 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:50:56 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 50, 'lr': 0.00817945059160568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02893200898206338}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29764765694983303, 'info': {'number_mnist': 0.29764765694983303, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 50, 'lr': 0.00817945059160568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02893200898206338}"}}
exception: None

09:50:56 job_callback for (8, 0, 10) started
09:50:56 DISPATCHER: Trying to submit another job.
09:50:56 job_callback for (8, 0, 10) got condition
09:50:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:50:56 HBMASTER: Trying to run another job!
09:50:56 job_callback for (8, 0, 10) finished
09:50:56 HBMASTER: schedule new run for iteration 8
09:50:56 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
09:50:56 HBMASTER: submitting job (8, 0, 15) to dispatcher
09:50:56 DISPATCHER: trying to submit job (8, 0, 15)
09:50:56 DISPATCHER: trying to notify the job_runner thread.
09:50:56 HBMASTER: job (8, 0, 15) submitted to dispatcher
09:50:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:50:56 DISPATCHER: Trying to submit another job.
09:50:56 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:50:56 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:50:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:50:56 WORKER: start processing job (8, 0, 15)
09:50:56 WORKER: args: ()
09:50:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 47, 'last_n_outputs': 48, 'lr': 0.011493662637411386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015690194405165073}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:51:30 DISPATCHER: Starting worker discovery
09:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:30 DISPATCHER: Finished worker discovery
09:52:30 DISPATCHER: Starting worker discovery
09:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:30 DISPATCHER: Finished worker discovery
09:53:18 WORKER: done with job (8, 0, 15), trying to register it.
09:53:18 WORKER: registered result for job (8, 0, 15) with dispatcher
09:53:18 DISPATCHER: job (8, 0, 15) finished
09:53:18 DISPATCHER: register_result: lock acquired
09:53:18 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:53:18 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 47, 'last_n_outputs': 48, 'lr': 0.011493662637411386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015690194405165073}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8133904946650388, 'info': {'number_mnist': 0.8133904946650388, 'config': "{'batch_size': 128, 'hidden_dim': 47, 'last_n_outputs': 48, 'lr': 0.011493662637411386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015690194405165073}"}}
exception: None

09:53:18 job_callback for (8, 0, 15) started
09:53:18 DISPATCHER: Trying to submit another job.
09:53:18 job_callback for (8, 0, 15) got condition
09:53:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:53:18 HBMASTER: Trying to run another job!
09:53:18 job_callback for (8, 0, 15) finished
09:53:18 HBMASTER: schedule new run for iteration 8
09:53:18 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
09:53:18 HBMASTER: submitting job (8, 0, 19) to dispatcher
09:53:18 DISPATCHER: trying to submit job (8, 0, 19)
09:53:18 DISPATCHER: trying to notify the job_runner thread.
09:53:18 HBMASTER: job (8, 0, 19) submitted to dispatcher
09:53:18 DISPATCHER: Trying to submit another job.
09:53:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:53:18 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:53:18 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:53:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:53:18 WORKER: start processing job (8, 0, 19)
09:53:18 WORKER: args: ()
09:53:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.008794096836896493, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.01517782466200281}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:53:30 DISPATCHER: Starting worker discovery
09:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:30 DISPATCHER: Finished worker discovery
09:54:30 DISPATCHER: Starting worker discovery
09:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:30 DISPATCHER: Finished worker discovery
09:55:30 DISPATCHER: Starting worker discovery
09:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:30 DISPATCHER: Finished worker discovery
09:55:39 WORKER: done with job (8, 0, 19), trying to register it.
09:55:39 WORKER: registered result for job (8, 0, 19) with dispatcher
09:55:39 DISPATCHER: job (8, 0, 19) finished
09:55:39 DISPATCHER: register_result: lock acquired
09:55:39 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:55:39 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.008794096836896493, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.01517782466200281}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5797287048113665, 'info': {'number_mnist': 0.5797287048113665, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 46, 'lr': 0.008794096836896493, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.01517782466200281}"}}
exception: None

09:55:39 job_callback for (8, 0, 19) started
09:55:39 DISPATCHER: Trying to submit another job.
09:55:39 job_callback for (8, 0, 19) got condition
09:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:39 HBMASTER: Trying to run another job!
09:55:39 job_callback for (8, 0, 19) finished
09:55:39 HBMASTER: schedule new run for iteration 8
09:55:39 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
09:55:39 HBMASTER: submitting job (8, 0, 21) to dispatcher
09:55:39 DISPATCHER: trying to submit job (8, 0, 21)
09:55:39 DISPATCHER: trying to notify the job_runner thread.
09:55:39 HBMASTER: job (8, 0, 21) submitted to dispatcher
09:55:39 DISPATCHER: Trying to submit another job.
09:55:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:39 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:55:39 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:39 WORKER: start processing job (8, 0, 21)
09:55:39 WORKER: args: ()
09:55:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 30, 'lr': 0.002435656446769097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.054592418604988355}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:56:30 DISPATCHER: Starting worker discovery
09:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:30 DISPATCHER: Finished worker discovery
09:57:30 DISPATCHER: Starting worker discovery
09:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:30 DISPATCHER: Finished worker discovery
09:58:01 WORKER: done with job (8, 0, 21), trying to register it.
09:58:01 WORKER: registered result for job (8, 0, 21) with dispatcher
09:58:01 DISPATCHER: job (8, 0, 21) finished
09:58:01 DISPATCHER: register_result: lock acquired
09:58:01 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
09:58:01 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 30, 'lr': 0.002435656446769097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.054592418604988355}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5396830638137451, 'info': {'number_mnist': 0.5396830638137451, 'config': "{'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 30, 'lr': 0.002435656446769097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.054592418604988355}"}}
exception: None

09:58:01 job_callback for (8, 0, 21) started
09:58:01 job_callback for (8, 0, 21) got condition
09:58:01 DISPATCHER: Trying to submit another job.
09:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:58:01 HBMASTER: Trying to run another job!
09:58:01 job_callback for (8, 0, 21) finished
09:58:01 HBMASTER: schedule new run for iteration 8
09:58:01 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
09:58:01 HBMASTER: submitting job (8, 0, 22) to dispatcher
09:58:01 DISPATCHER: trying to submit job (8, 0, 22)
09:58:01 DISPATCHER: trying to notify the job_runner thread.
09:58:01 HBMASTER: job (8, 0, 22) submitted to dispatcher
09:58:01 DISPATCHER: Trying to submit another job.
09:58:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:58:01 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
09:58:01 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
09:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:58:01 WORKER: start processing job (8, 0, 22)
09:58:01 WORKER: args: ()
09:58:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.014636178803354749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03993539471627341}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:58:30 DISPATCHER: Starting worker discovery
09:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:30 DISPATCHER: Finished worker discovery
09:59:30 DISPATCHER: Starting worker discovery
09:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:30 DISPATCHER: Finished worker discovery
10:00:22 WORKER: done with job (8, 0, 22), trying to register it.
10:00:22 WORKER: registered result for job (8, 0, 22) with dispatcher
10:00:22 DISPATCHER: job (8, 0, 22) finished
10:00:22 DISPATCHER: register_result: lock acquired
10:00:22 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:00:22 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.014636178803354749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03993539471627341}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3668865648664866, 'info': {'number_mnist': 0.3668865648664866, 'config': "{'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.014636178803354749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03993539471627341}"}}
exception: None

10:00:22 job_callback for (8, 0, 22) started
10:00:22 DISPATCHER: Trying to submit another job.
10:00:22 job_callback for (8, 0, 22) got condition
10:00:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:00:22 HBMASTER: Trying to run another job!
10:00:22 job_callback for (8, 0, 22) finished
10:00:22 HBMASTER: schedule new run for iteration 8
10:00:22 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
10:00:22 HBMASTER: submitting job (8, 0, 25) to dispatcher
10:00:22 DISPATCHER: trying to submit job (8, 0, 25)
10:00:22 DISPATCHER: trying to notify the job_runner thread.
10:00:22 HBMASTER: job (8, 0, 25) submitted to dispatcher
10:00:22 DISPATCHER: Trying to submit another job.
10:00:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:00:22 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:00:22 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:00:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:00:22 WORKER: start processing job (8, 0, 25)
10:00:22 WORKER: args: ()
10:00:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.0014450105606140155, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06177725314101195}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:00:30 DISPATCHER: Starting worker discovery
10:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:30 DISPATCHER: Finished worker discovery
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:01:30 DISPATCHER: Starting worker discovery
10:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:30 DISPATCHER: Finished worker discovery
10:02:30 DISPATCHER: Starting worker discovery
10:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:30 DISPATCHER: Finished worker discovery
10:02:43 WORKER: done with job (8, 0, 25), trying to register it.
10:02:43 WORKER: registered result for job (8, 0, 25) with dispatcher
10:02:43 DISPATCHER: job (8, 0, 25) finished
10:02:43 DISPATCHER: register_result: lock acquired
10:02:43 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:02:43 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.0014450105606140155, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06177725314101195}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6760401780038314, 'info': {'number_mnist': 0.6760401780038314, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.0014450105606140155, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06177725314101195}"}}
exception: None

10:02:43 job_callback for (8, 0, 25) started
10:02:43 job_callback for (8, 0, 25) got condition
10:02:43 DISPATCHER: Trying to submit another job.
10:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:43 HBMASTER: Trying to run another job!
10:02:43 job_callback for (8, 0, 25) finished
10:02:43 ITERATION: Advancing config (8, 0, 1) to next budget 400.000000
10:02:43 ITERATION: Advancing config (8, 0, 2) to next budget 400.000000
10:02:43 ITERATION: Advancing config (8, 0, 4) to next budget 400.000000
10:02:43 HBMASTER: schedule new run for iteration 8
10:02:43 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
10:02:43 HBMASTER: submitting job (8, 0, 1) to dispatcher
10:02:43 DISPATCHER: trying to submit job (8, 0, 1)
10:02:43 DISPATCHER: trying to notify the job_runner thread.
10:02:43 HBMASTER: job (8, 0, 1) submitted to dispatcher
10:02:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:43 DISPATCHER: Trying to submit another job.
10:02:43 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:02:43 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:43 WORKER: start processing job (8, 0, 1)
10:02:43 WORKER: args: ()
10:02:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:03:30 DISPATCHER: Starting worker discovery
10:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:30 DISPATCHER: Finished worker discovery
10:04:30 DISPATCHER: Starting worker discovery
10:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:30 DISPATCHER: Finished worker discovery
10:05:30 DISPATCHER: Starting worker discovery
10:05:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:30 DISPATCHER: Finished worker discovery
10:06:30 DISPATCHER: Starting worker discovery
10:06:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:30 DISPATCHER: Finished worker discovery
10:07:30 DISPATCHER: Starting worker discovery
10:07:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:30 DISPATCHER: Finished worker discovery
10:08:30 DISPATCHER: Starting worker discovery
10:08:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:30 DISPATCHER: Finished worker discovery
10:09:30 DISPATCHER: Starting worker discovery
10:09:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:30 DISPATCHER: Finished worker discovery
10:09:31 WORKER: done with job (8, 0, 1), trying to register it.
10:09:31 WORKER: registered result for job (8, 0, 1) with dispatcher
10:09:31 DISPATCHER: job (8, 0, 1) finished
10:09:31 DISPATCHER: register_result: lock acquired
10:09:31 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:09:31 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8181964031986076, 'info': {'number_mnist': 0.8181964031986076, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 5, 'lr': 0.0011245537672331977, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021364421459659434}"}}
exception: None

10:09:31 job_callback for (8, 0, 1) started
10:09:31 DISPATCHER: Trying to submit another job.
10:09:31 job_callback for (8, 0, 1) got condition
10:09:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:09:31 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.926837





10:09:31 HBMASTER: Trying to run another job!
10:09:31 job_callback for (8, 0, 1) finished
10:09:31 HBMASTER: schedule new run for iteration 8
10:09:31 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
10:09:31 HBMASTER: submitting job (8, 0, 2) to dispatcher
10:09:31 DISPATCHER: trying to submit job (8, 0, 2)
10:09:31 DISPATCHER: trying to notify the job_runner thread.
10:09:31 HBMASTER: job (8, 0, 2) submitted to dispatcher
10:09:31 DISPATCHER: Trying to submit another job.
10:09:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:09:31 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:09:31 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:09:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:09:31 WORKER: start processing job (8, 0, 2)
10:09:31 WORKER: args: ()
10:09:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:10:30 DISPATCHER: Starting worker discovery
10:10:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:30 DISPATCHER: Finished worker discovery
10:11:30 DISPATCHER: Starting worker discovery
10:11:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:30 DISPATCHER: Finished worker discovery
10:12:30 DISPATCHER: Starting worker discovery
10:12:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:30 DISPATCHER: Finished worker discovery
10:13:30 DISPATCHER: Starting worker discovery
10:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:30 DISPATCHER: Finished worker discovery
10:14:30 DISPATCHER: Starting worker discovery
10:14:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:30 DISPATCHER: Finished worker discovery
10:15:30 DISPATCHER: Starting worker discovery
10:15:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:30 DISPATCHER: Finished worker discovery
10:16:19 WORKER: done with job (8, 0, 2), trying to register it.
10:16:19 WORKER: registered result for job (8, 0, 2) with dispatcher
10:16:19 DISPATCHER: job (8, 0, 2) finished
10:16:19 DISPATCHER: register_result: lock acquired
10:16:19 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:16:19 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8162143418809209, 'info': {'number_mnist': 0.8162143418809209, 'config': "{'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 7, 'lr': 0.004866460886378205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.024875829747953406}"}}
exception: None

10:16:19 job_callback for (8, 0, 2) started
10:16:19 DISPATCHER: Trying to submit another job.
10:16:19 job_callback for (8, 0, 2) got condition
10:16:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:16:19 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.926837





10:16:19 HBMASTER: Trying to run another job!
10:16:19 job_callback for (8, 0, 2) finished
10:16:19 HBMASTER: schedule new run for iteration 8
10:16:19 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
10:16:19 HBMASTER: submitting job (8, 0, 4) to dispatcher
10:16:19 DISPATCHER: trying to submit job (8, 0, 4)
10:16:19 DISPATCHER: trying to notify the job_runner thread.
10:16:19 HBMASTER: job (8, 0, 4) submitted to dispatcher
10:16:19 DISPATCHER: Trying to submit another job.
10:16:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:16:19 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:16:19 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:16:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:16:19 WORKER: start processing job (8, 0, 4)
10:16:19 WORKER: args: ()
10:16:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:16:30 DISPATCHER: Starting worker discovery
10:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:30 DISPATCHER: Finished worker discovery
10:17:30 DISPATCHER: Starting worker discovery
10:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:30 DISPATCHER: Finished worker discovery
10:18:30 DISPATCHER: Starting worker discovery
10:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:30 DISPATCHER: Finished worker discovery
10:19:30 DISPATCHER: Starting worker discovery
10:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:30 DISPATCHER: Finished worker discovery
10:20:30 DISPATCHER: Starting worker discovery
10:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:30 DISPATCHER: Finished worker discovery
10:21:30 DISPATCHER: Starting worker discovery
10:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:30 DISPATCHER: Finished worker discovery
10:22:30 DISPATCHER: Starting worker discovery
10:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:30 DISPATCHER: Finished worker discovery
10:23:07 WORKER: done with job (8, 0, 4), trying to register it.
10:23:07 WORKER: registered result for job (8, 0, 4) with dispatcher
10:23:07 DISPATCHER: job (8, 0, 4) finished
10:23:07 DISPATCHER: register_result: lock acquired
10:23:07 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:23:07 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8418350394096471, 'info': {'number_mnist': 0.8418350394096471, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}"}}
exception: None

10:23:07 job_callback for (8, 0, 4) started
10:23:07 job_callback for (8, 0, 4) got condition
10:23:07 DISPATCHER: Trying to submit another job.
10:23:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:23:07 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.926837





10:23:07 HBMASTER: Trying to run another job!
10:23:07 job_callback for (8, 0, 4) finished
10:23:07 ITERATION: Advancing config (8, 0, 4) to next budget 1200.000000
10:23:07 HBMASTER: schedule new run for iteration 8
10:23:07 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
10:23:07 HBMASTER: submitting job (8, 0, 4) to dispatcher
10:23:07 DISPATCHER: trying to submit job (8, 0, 4)
10:23:07 DISPATCHER: trying to notify the job_runner thread.
10:23:07 HBMASTER: job (8, 0, 4) submitted to dispatcher
10:23:07 DISPATCHER: Trying to submit another job.
10:23:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:23:07 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:23:07 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:23:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:23:07 WORKER: start processing job (8, 0, 4)
10:23:07 WORKER: args: ()
10:23:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:23:30 DISPATCHER: Starting worker discovery
10:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:30 DISPATCHER: Finished worker discovery
10:24:30 DISPATCHER: Starting worker discovery
10:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:30 DISPATCHER: Finished worker discovery
10:25:30 DISPATCHER: Starting worker discovery
10:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:30 DISPATCHER: Finished worker discovery
10:26:30 DISPATCHER: Starting worker discovery
10:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:30 DISPATCHER: Finished worker discovery
10:27:30 DISPATCHER: Starting worker discovery
10:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:30 DISPATCHER: Finished worker discovery
10:28:30 DISPATCHER: Starting worker discovery
10:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:30 DISPATCHER: Finished worker discovery
10:29:30 DISPATCHER: Starting worker discovery
10:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:30 DISPATCHER: Finished worker discovery
10:30:30 DISPATCHER: Starting worker discovery
10:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:30 DISPATCHER: Finished worker discovery
10:31:30 DISPATCHER: Starting worker discovery
10:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:30 DISPATCHER: Finished worker discovery
10:32:30 DISPATCHER: Starting worker discovery
10:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:30 DISPATCHER: Finished worker discovery
10:33:30 DISPATCHER: Starting worker discovery
10:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:30 DISPATCHER: Finished worker discovery
10:34:30 DISPATCHER: Starting worker discovery
10:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:30 DISPATCHER: Finished worker discovery
10:35:30 DISPATCHER: Starting worker discovery
10:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:30 DISPATCHER: Finished worker discovery
10:36:30 DISPATCHER: Starting worker discovery
10:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:30 DISPATCHER: Finished worker discovery
10:37:30 DISPATCHER: Starting worker discovery
10:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:30 DISPATCHER: Finished worker discovery
10:38:30 DISPATCHER: Starting worker discovery
10:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:30 DISPATCHER: Finished worker discovery
10:39:30 DISPATCHER: Starting worker discovery
10:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:30 DISPATCHER: Finished worker discovery
10:40:30 DISPATCHER: Starting worker discovery
10:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:30 DISPATCHER: Finished worker discovery
10:41:30 DISPATCHER: Starting worker discovery
10:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:30 DISPATCHER: Finished worker discovery
10:42:30 DISPATCHER: Starting worker discovery
10:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:30 DISPATCHER: Finished worker discovery
10:43:15 WORKER: done with job (8, 0, 4), trying to register it.
10:43:15 WORKER: registered result for job (8, 0, 4) with dispatcher
10:43:15 DISPATCHER: job (8, 0, 4) finished
10:43:15 DISPATCHER: register_result: lock acquired
10:43:15 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:43:15 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7786897146738336, 'info': {'number_mnist': 0.7786897146738336, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 8, 'lr': 0.008512010323384415, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.014902227718102932}"}}
exception: None

10:43:15 job_callback for (8, 0, 4) started
10:43:15 job_callback for (8, 0, 4) got condition
10:43:15 DISPATCHER: Trying to submit another job.
10:43:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:43:15 HBMASTER: Trying to run another job!
10:43:15 job_callback for (8, 0, 4) finished
10:43:15 start sampling a new configuration.
10:43:15 done sampling a new configuration.
10:43:15 HBMASTER: schedule new run for iteration 9
10:43:15 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
10:43:15 HBMASTER: submitting job (9, 0, 0) to dispatcher
10:43:15 DISPATCHER: trying to submit job (9, 0, 0)
10:43:15 DISPATCHER: trying to notify the job_runner thread.
10:43:15 HBMASTER: job (9, 0, 0) submitted to dispatcher
10:43:15 DISPATCHER: Trying to submit another job.
10:43:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:43:15 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:43:15 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:43:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:43:15 WORKER: start processing job (9, 0, 0)
10:43:15 WORKER: args: ()
10:43:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 42, 'lr': 0.004581786016325363, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.050428179701418635}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:43:30 DISPATCHER: Starting worker discovery
10:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:30 DISPATCHER: Finished worker discovery
10:44:30 DISPATCHER: Starting worker discovery
10:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:30 DISPATCHER: Finished worker discovery
10:45:30 DISPATCHER: Starting worker discovery
10:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:30 DISPATCHER: Finished worker discovery
10:45:36 WORKER: done with job (9, 0, 0), trying to register it.
10:45:36 WORKER: registered result for job (9, 0, 0) with dispatcher
10:45:36 DISPATCHER: job (9, 0, 0) finished
10:45:36 DISPATCHER: register_result: lock acquired
10:45:36 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:45:36 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 42, 'lr': 0.004581786016325363, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.050428179701418635}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6951226608945789, 'info': {'number_mnist': 0.6951226608945789, 'config': "{'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 42, 'lr': 0.004581786016325363, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.050428179701418635}"}}
exception: None

10:45:36 job_callback for (9, 0, 0) started
10:45:36 job_callback for (9, 0, 0) got condition
10:45:36 DISPATCHER: Trying to submit another job.
10:45:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:45:36 HBMASTER: Trying to run another job!
10:45:36 job_callback for (9, 0, 0) finished
10:45:36 start sampling a new configuration.
10:45:36 best_vector: [3, 0.8615386305046201, 0.05094413063846241, 0.46484141970558945, 0.09852095492144781, 0, 0.9648754920121971, 0.3737732892187955], 1.3597302939507995e-34, 73.54399651525188, -0.002795950603566383
10:45:36 done sampling a new configuration.
10:45:36 HBMASTER: schedule new run for iteration 9
10:45:36 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
10:45:36 HBMASTER: submitting job (9, 0, 1) to dispatcher
10:45:36 DISPATCHER: trying to submit job (9, 0, 1)
10:45:36 DISPATCHER: trying to notify the job_runner thread.
10:45:36 HBMASTER: job (9, 0, 1) submitted to dispatcher
10:45:36 DISPATCHER: Trying to submit another job.
10:45:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:45:36 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:45:36 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:45:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:45:36 WORKER: start processing job (9, 0, 1)
10:45:36 WORKER: args: ()
10:45:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.008505166881582416, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.03064010581930883}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:46:30 DISPATCHER: Starting worker discovery
10:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:30 DISPATCHER: Finished worker discovery
10:47:30 DISPATCHER: Starting worker discovery
10:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:30 DISPATCHER: Finished worker discovery
10:47:58 WORKER: done with job (9, 0, 1), trying to register it.
10:47:58 WORKER: registered result for job (9, 0, 1) with dispatcher
10:47:58 DISPATCHER: job (9, 0, 1) finished
10:47:58 DISPATCHER: register_result: lock acquired
10:47:58 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:47:58 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.008505166881582416, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.03064010581930883}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7238510124407903, 'info': {'number_mnist': 0.7238510124407903, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.008505166881582416, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.03064010581930883}"}}
exception: None

10:47:58 job_callback for (9, 0, 1) started
10:47:58 job_callback for (9, 0, 1) got condition
10:47:58 DISPATCHER: Trying to submit another job.
10:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:47:58 HBMASTER: Trying to run another job!
10:47:58 job_callback for (9, 0, 1) finished
10:47:58 start sampling a new configuration.
10:47:58 best_vector: [0, 0.8640757813726746, 0.8101991363802049, 0.6419476060517237, 0.0989679758868345, 0, 0.6347538041342042, 0.05908472035497814], 3.1817038962556053e-35, 314.2970033059494, -0.06979201721451356
10:47:58 done sampling a new configuration.
10:47:58 HBMASTER: schedule new run for iteration 9
10:47:58 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
10:47:58 HBMASTER: submitting job (9, 0, 2) to dispatcher
10:47:58 DISPATCHER: trying to submit job (9, 0, 2)
10:47:58 DISPATCHER: trying to notify the job_runner thread.
10:47:58 HBMASTER: job (9, 0, 2) submitted to dispatcher
10:47:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:47:58 DISPATCHER: Trying to submit another job.
10:47:58 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:47:58 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:47:58 WORKER: start processing job (9, 0, 2)
10:47:58 WORKER: args: ()
10:47:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 41, 'lr': 0.019226277754495123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.011936334847381144}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:48:30 DISPATCHER: Starting worker discovery
10:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:30 DISPATCHER: Finished worker discovery
10:49:30 DISPATCHER: Starting worker discovery
10:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:30 DISPATCHER: Finished worker discovery
10:50:19 WORKER: done with job (9, 0, 2), trying to register it.
10:50:19 WORKER: registered result for job (9, 0, 2) with dispatcher
10:50:19 DISPATCHER: job (9, 0, 2) finished
10:50:19 DISPATCHER: register_result: lock acquired
10:50:19 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:50:19 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 41, 'lr': 0.019226277754495123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.011936334847381144}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05906996278218924, 'info': {'number_mnist': 0.05906996278218924, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 41, 'lr': 0.019226277754495123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.011936334847381144}"}}
exception: None

10:50:19 job_callback for (9, 0, 2) started
10:50:19 job_callback for (9, 0, 2) got condition
10:50:19 DISPATCHER: Trying to submit another job.
10:50:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:19 HBMASTER: Trying to run another job!
10:50:19 job_callback for (9, 0, 2) finished
10:50:19 start sampling a new configuration.
10:50:19 best_vector: [3, 0.6273700214296241, 0.05342776765074402, 0.4850460747865068, 0.10383250082766889, 0, 0.7856350599964204, 0.15129463696768752], 4.6719411034596605e-32, 0.21404379418642097, -0.004012566866312917
10:50:19 done sampling a new configuration.
10:50:19 HBMASTER: schedule new run for iteration 9
10:50:19 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
10:50:19 HBMASTER: submitting job (9, 0, 3) to dispatcher
10:50:19 DISPATCHER: trying to submit job (9, 0, 3)
10:50:19 DISPATCHER: trying to notify the job_runner thread.
10:50:19 HBMASTER: job (9, 0, 3) submitted to dispatcher
10:50:19 DISPATCHER: Trying to submit another job.
10:50:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:19 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:50:19 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:50:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:19 WORKER: start processing job (9, 0, 3)
10:50:19 WORKER: args: ()
10:50:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 70, 'last_n_outputs': 3, 'lr': 0.00933452341788275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.015733989676402542}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:50:30 DISPATCHER: Starting worker discovery
10:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:30 DISPATCHER: Finished worker discovery
10:51:30 DISPATCHER: Starting worker discovery
10:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:30 DISPATCHER: Finished worker discovery
10:52:30 DISPATCHER: Starting worker discovery
10:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:30 DISPATCHER: Finished worker discovery
10:52:40 WORKER: done with job (9, 0, 3), trying to register it.
10:52:40 WORKER: registered result for job (9, 0, 3) with dispatcher
10:52:40 DISPATCHER: job (9, 0, 3) finished
10:52:40 DISPATCHER: register_result: lock acquired
10:52:40 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:52:40 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 70, 'last_n_outputs': 3, 'lr': 0.00933452341788275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.015733989676402542}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6587919085177656, 'info': {'number_mnist': 0.6587919085177656, 'config': "{'batch_size': 128, 'hidden_dim': 70, 'last_n_outputs': 3, 'lr': 0.00933452341788275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.015733989676402542}"}}
exception: None

10:52:40 job_callback for (9, 0, 3) started
10:52:40 DISPATCHER: Trying to submit another job.
10:52:40 job_callback for (9, 0, 3) got condition
10:52:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:52:40 HBMASTER: Trying to run another job!
10:52:40 job_callback for (9, 0, 3) finished
10:52:40 start sampling a new configuration.
10:52:40 best_vector: [3, 0.9045461609559788, 0.22472277656868844, 0.5355676148968174, 0.09920927242286266, 0, 0.7173355859816304, 0.06552070811215166], 4.4186368270339897e-35, 226.31414147499652, -0.0014751112940027556
10:52:40 done sampling a new configuration.
10:52:40 HBMASTER: schedule new run for iteration 9
10:52:40 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
10:52:40 HBMASTER: submitting job (9, 0, 4) to dispatcher
10:52:40 DISPATCHER: trying to submit job (9, 0, 4)
10:52:40 DISPATCHER: trying to notify the job_runner thread.
10:52:40 HBMASTER: job (9, 0, 4) submitted to dispatcher
10:52:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:52:40 DISPATCHER: Trying to submit another job.
10:52:40 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:52:40 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:52:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:52:40 WORKER: start processing job (9, 0, 4)
10:52:40 WORKER: args: ()
10:52:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:53:30 DISPATCHER: Starting worker discovery
10:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:30 DISPATCHER: Finished worker discovery
10:54:30 DISPATCHER: Starting worker discovery
10:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:30 DISPATCHER: Finished worker discovery
10:55:02 WORKER: done with job (9, 0, 4), trying to register it.
10:55:02 WORKER: registered result for job (9, 0, 4) with dispatcher
10:55:02 DISPATCHER: job (9, 0, 4) finished
10:55:02 DISPATCHER: register_result: lock acquired
10:55:02 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:55:02 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7459679621153458, 'info': {'number_mnist': 0.7459679621153458, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}"}}
exception: None

10:55:02 job_callback for (9, 0, 4) started
10:55:02 job_callback for (9, 0, 4) got condition
10:55:02 DISPATCHER: Trying to submit another job.
10:55:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:55:02 HBMASTER: Trying to run another job!
10:55:02 job_callback for (9, 0, 4) finished
10:55:02 start sampling a new configuration.
10:55:02 done sampling a new configuration.
10:55:02 HBMASTER: schedule new run for iteration 9
10:55:02 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
10:55:02 HBMASTER: submitting job (9, 0, 5) to dispatcher
10:55:02 DISPATCHER: trying to submit job (9, 0, 5)
10:55:02 DISPATCHER: trying to notify the job_runner thread.
10:55:02 HBMASTER: job (9, 0, 5) submitted to dispatcher
10:55:02 DISPATCHER: Trying to submit another job.
10:55:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:55:02 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:55:02 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:55:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:55:02 WORKER: start processing job (9, 0, 5)
10:55:02 WORKER: args: ()
10:55:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 77, 'last_n_outputs': 27, 'lr': 0.001443900117650316, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.012198616803411064}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:55:30 DISPATCHER: Starting worker discovery
10:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:30 DISPATCHER: Finished worker discovery
10:56:30 DISPATCHER: Starting worker discovery
10:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:30 DISPATCHER: Finished worker discovery
10:57:23 WORKER: done with job (9, 0, 5), trying to register it.
10:57:23 WORKER: registered result for job (9, 0, 5) with dispatcher
10:57:23 DISPATCHER: job (9, 0, 5) finished
10:57:23 DISPATCHER: register_result: lock acquired
10:57:23 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:57:23 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 77, 'last_n_outputs': 27, 'lr': 0.001443900117650316, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.012198616803411064}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 77, 'last_n_outputs': 27, 'lr': 0.001443900117650316, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.012198616803411064}"}}
exception: None

10:57:23 job_callback for (9, 0, 5) started
10:57:23 job_callback for (9, 0, 5) got condition
10:57:23 DISPATCHER: Trying to submit another job.
10:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:57:23 HBMASTER: Trying to run another job!
10:57:23 job_callback for (9, 0, 5) finished
10:57:23 start sampling a new configuration.
10:57:23 best_vector: [3, 0.9168917033241333, 0.016694531399016374, 0.6158596709698043, 0.10092839242526055, 0, 0.6058140339507048, 0.03853927567142518], 2.839270653191587e-34, 35.22031261359015, -0.012306990094095123
10:57:23 done sampling a new configuration.
10:57:23 HBMASTER: schedule new run for iteration 9
10:57:23 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
10:57:23 HBMASTER: submitting job (9, 0, 6) to dispatcher
10:57:23 DISPATCHER: trying to submit job (9, 0, 6)
10:57:23 DISPATCHER: trying to notify the job_runner thread.
10:57:23 HBMASTER: job (9, 0, 6) submitted to dispatcher
10:57:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:57:23 DISPATCHER: Trying to submit another job.
10:57:23 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:57:23 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:57:23 WORKER: start processing job (9, 0, 6)
10:57:23 WORKER: args: ()
10:57:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 1, 'lr': 0.017049802080879306, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.011223821563637607}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:57:30 DISPATCHER: Starting worker discovery
10:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:30 DISPATCHER: Finished worker discovery
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:58:30 DISPATCHER: Starting worker discovery
10:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:30 DISPATCHER: Finished worker discovery
10:59:30 DISPATCHER: Starting worker discovery
10:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:30 DISPATCHER: Finished worker discovery
10:59:45 WORKER: done with job (9, 0, 6), trying to register it.
10:59:45 WORKER: registered result for job (9, 0, 6) with dispatcher
10:59:45 DISPATCHER: job (9, 0, 6) finished
10:59:45 DISPATCHER: register_result: lock acquired
10:59:45 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
10:59:45 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 1, 'lr': 0.017049802080879306, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.011223821563637607}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31412811944537405, 'info': {'number_mnist': 0.31412811944537405, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 1, 'lr': 0.017049802080879306, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.011223821563637607}"}}
exception: None

10:59:45 job_callback for (9, 0, 6) started
10:59:45 DISPATCHER: Trying to submit another job.
10:59:45 job_callback for (9, 0, 6) got condition
10:59:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:59:45 HBMASTER: Trying to run another job!
10:59:45 job_callback for (9, 0, 6) finished
10:59:45 start sampling a new configuration.
10:59:45 best_vector: [3, 0.8760610596861652, 0.11750347900226113, 0.2798299974993449, 0.10041815848071253, 0, 0.7161739339125229, 0.3065287234718769], 2.077132614984357e-35, 481.4329103428628, -0.0019353317998246206
10:59:45 done sampling a new configuration.
10:59:45 HBMASTER: schedule new run for iteration 9
10:59:45 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
10:59:45 HBMASTER: submitting job (9, 0, 7) to dispatcher
10:59:45 DISPATCHER: trying to submit job (9, 0, 7)
10:59:45 DISPATCHER: trying to notify the job_runner thread.
10:59:45 HBMASTER: job (9, 0, 7) submitted to dispatcher
10:59:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:59:45 DISPATCHER: Trying to submit another job.
10:59:45 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
10:59:45 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
10:59:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:59:45 WORKER: start processing job (9, 0, 7)
10:59:45 WORKER: args: ()
10:59:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 6, 'lr': 0.0036279391566871014, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.0250497308426825}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:00:30 DISPATCHER: Starting worker discovery
11:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:30 DISPATCHER: Finished worker discovery
11:01:30 DISPATCHER: Starting worker discovery
11:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:30 DISPATCHER: Finished worker discovery
11:02:06 WORKER: done with job (9, 0, 7), trying to register it.
11:02:06 WORKER: registered result for job (9, 0, 7) with dispatcher
11:02:06 DISPATCHER: job (9, 0, 7) finished
11:02:06 DISPATCHER: register_result: lock acquired
11:02:06 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:02:06 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 6, 'lr': 0.0036279391566871014, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.0250497308426825}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8755285624763077, 'info': {'number_mnist': 0.8755285624763077, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 6, 'lr': 0.0036279391566871014, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.0250497308426825}"}}
exception: None

11:02:06 job_callback for (9, 0, 7) started
11:02:06 job_callback for (9, 0, 7) got condition
11:02:06 DISPATCHER: Trying to submit another job.
11:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:06 HBMASTER: Trying to run another job!
11:02:06 job_callback for (9, 0, 7) finished
11:02:06 start sampling a new configuration.
11:02:06 best_vector: [3, 0.8405025867324393, 0.245946139103004, 0.7962111823154823, 0.09786837578926705, 0, 0.5955078342872543, 0.5455246226590672], 6.290124230752427e-33, 1.5897937199888654, -0.00040846721478224335
11:02:06 done sampling a new configuration.
11:02:06 HBMASTER: schedule new run for iteration 9
11:02:06 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
11:02:06 HBMASTER: submitting job (9, 0, 8) to dispatcher
11:02:06 DISPATCHER: trying to submit job (9, 0, 8)
11:02:06 DISPATCHER: trying to notify the job_runner thread.
11:02:06 HBMASTER: job (9, 0, 8) submitted to dispatcher
11:02:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:06 DISPATCHER: Trying to submit another job.
11:02:06 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:02:06 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:06 WORKER: start processing job (9, 0, 8)
11:02:06 WORKER: args: ()
11:02:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 13, 'lr': 0.03912211853770432, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.0512559039860927}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:02:30 DISPATCHER: Starting worker discovery
11:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:30 DISPATCHER: Finished worker discovery
11:03:30 DISPATCHER: Starting worker discovery
11:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:30 DISPATCHER: Finished worker discovery
11:04:28 WORKER: done with job (9, 0, 8), trying to register it.
11:04:28 WORKER: registered result for job (9, 0, 8) with dispatcher
11:04:28 DISPATCHER: job (9, 0, 8) finished
11:04:28 DISPATCHER: register_result: lock acquired
11:04:28 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:04:28 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 13, 'lr': 0.03912211853770432, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.0512559039860927}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.012897171101721509, 'info': {'number_mnist': 0.012897171101721509, 'config': "{'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 13, 'lr': 0.03912211853770432, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.0512559039860927}"}}
exception: None

11:04:28 job_callback for (9, 0, 8) started
11:04:28 job_callback for (9, 0, 8) got condition
11:04:28 DISPATCHER: Trying to submit another job.
11:04:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:04:28 HBMASTER: Trying to run another job!
11:04:28 job_callback for (9, 0, 8) finished
11:04:28 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
11:04:28 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
11:04:28 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
11:04:28 HBMASTER: schedule new run for iteration 9
11:04:28 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
11:04:28 HBMASTER: submitting job (9, 0, 1) to dispatcher
11:04:28 DISPATCHER: trying to submit job (9, 0, 1)
11:04:28 DISPATCHER: trying to notify the job_runner thread.
11:04:28 HBMASTER: job (9, 0, 1) submitted to dispatcher
11:04:28 DISPATCHER: Trying to submit another job.
11:04:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:04:28 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:04:28 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:04:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:04:28 WORKER: start processing job (9, 0, 1)
11:04:28 WORKER: args: ()
11:04:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.008505166881582416, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.03064010581930883}, 'budget': 400.0, 'working_directory': '.'}
11:04:30 DISPATCHER: Starting worker discovery
11:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:30 DISPATCHER: Finished worker discovery
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:05:30 DISPATCHER: Starting worker discovery
11:05:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:30 DISPATCHER: Finished worker discovery
11:06:30 DISPATCHER: Starting worker discovery
11:06:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:30 DISPATCHER: Finished worker discovery
11:07:30 DISPATCHER: Starting worker discovery
11:07:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:30 DISPATCHER: Finished worker discovery
11:08:30 DISPATCHER: Starting worker discovery
11:08:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:30 DISPATCHER: Finished worker discovery
11:09:30 DISPATCHER: Starting worker discovery
11:09:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:30 DISPATCHER: Finished worker discovery
11:10:30 DISPATCHER: Starting worker discovery
11:10:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:30 DISPATCHER: Finished worker discovery
11:11:15 WORKER: done with job (9, 0, 1), trying to register it.
11:11:15 WORKER: registered result for job (9, 0, 1) with dispatcher
11:11:15 DISPATCHER: job (9, 0, 1) finished
11:11:15 DISPATCHER: register_result: lock acquired
11:11:15 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:11:15 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.008505166881582416, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.03064010581930883}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5829184305457893, 'info': {'number_mnist': 0.5829184305457893, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.008505166881582416, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.03064010581930883}"}}
exception: None

11:11:15 job_callback for (9, 0, 1) started
11:11:15 job_callback for (9, 0, 1) got condition
11:11:15 DISPATCHER: Trying to submit another job.
11:11:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:11:15 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.926837





11:11:15 HBMASTER: Trying to run another job!
11:11:15 job_callback for (9, 0, 1) finished
11:11:15 HBMASTER: schedule new run for iteration 9
11:11:15 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
11:11:15 HBMASTER: submitting job (9, 0, 4) to dispatcher
11:11:15 DISPATCHER: trying to submit job (9, 0, 4)
11:11:15 DISPATCHER: trying to notify the job_runner thread.
11:11:15 HBMASTER: job (9, 0, 4) submitted to dispatcher
11:11:15 DISPATCHER: Trying to submit another job.
11:11:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:11:15 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:11:15 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:11:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:11:15 WORKER: start processing job (9, 0, 4)
11:11:15 WORKER: args: ()
11:11:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:11:30 DISPATCHER: Starting worker discovery
11:11:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:30 DISPATCHER: Finished worker discovery
11:12:30 DISPATCHER: Starting worker discovery
11:12:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:30 DISPATCHER: Finished worker discovery
11:13:30 DISPATCHER: Starting worker discovery
11:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:30 DISPATCHER: Finished worker discovery
11:14:30 DISPATCHER: Starting worker discovery
11:14:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:30 DISPATCHER: Finished worker discovery
11:15:30 DISPATCHER: Starting worker discovery
11:15:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:30 DISPATCHER: Finished worker discovery
11:16:30 DISPATCHER: Starting worker discovery
11:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:30 DISPATCHER: Finished worker discovery
11:17:30 DISPATCHER: Starting worker discovery
11:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:30 DISPATCHER: Finished worker discovery
11:18:04 WORKER: done with job (9, 0, 4), trying to register it.
11:18:04 WORKER: registered result for job (9, 0, 4) with dispatcher
11:18:04 DISPATCHER: job (9, 0, 4) finished
11:18:04 DISPATCHER: register_result: lock acquired
11:18:04 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:18:04 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8804868864543575, 'info': {'number_mnist': 0.8804868864543575, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}"}}
exception: None

11:18:04 job_callback for (9, 0, 4) started
11:18:04 DISPATCHER: Trying to submit another job.
11:18:04 job_callback for (9, 0, 4) got condition
11:18:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:18:04 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.926837





11:18:04 HBMASTER: Trying to run another job!
11:18:04 job_callback for (9, 0, 4) finished
11:18:04 HBMASTER: schedule new run for iteration 9
11:18:04 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
11:18:04 HBMASTER: submitting job (9, 0, 7) to dispatcher
11:18:04 DISPATCHER: trying to submit job (9, 0, 7)
11:18:04 DISPATCHER: trying to notify the job_runner thread.
11:18:04 HBMASTER: job (9, 0, 7) submitted to dispatcher
11:18:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:18:04 DISPATCHER: Trying to submit another job.
11:18:04 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:18:04 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:18:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:18:04 WORKER: start processing job (9, 0, 7)
11:18:04 WORKER: args: ()
11:18:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 6, 'lr': 0.0036279391566871014, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.0250497308426825}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:18:30 DISPATCHER: Starting worker discovery
11:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:30 DISPATCHER: Finished worker discovery
11:19:30 DISPATCHER: Starting worker discovery
11:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:30 DISPATCHER: Finished worker discovery
11:20:30 DISPATCHER: Starting worker discovery
11:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:30 DISPATCHER: Finished worker discovery
11:21:30 DISPATCHER: Starting worker discovery
11:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:30 DISPATCHER: Finished worker discovery
11:22:30 DISPATCHER: Starting worker discovery
11:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:30 DISPATCHER: Finished worker discovery
11:23:30 DISPATCHER: Starting worker discovery
11:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:30 DISPATCHER: Finished worker discovery
11:24:30 DISPATCHER: Starting worker discovery
11:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:30 DISPATCHER: Finished worker discovery
11:24:52 WORKER: done with job (9, 0, 7), trying to register it.
11:24:52 WORKER: registered result for job (9, 0, 7) with dispatcher
11:24:52 DISPATCHER: job (9, 0, 7) finished
11:24:52 DISPATCHER: register_result: lock acquired
11:24:52 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:24:52 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 6, 'lr': 0.0036279391566871014, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.0250497308426825}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8611877851419982, 'info': {'number_mnist': 0.8611877851419982, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 6, 'lr': 0.0036279391566871014, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.0250497308426825}"}}
exception: None

11:24:52 job_callback for (9, 0, 7) started
11:24:52 job_callback for (9, 0, 7) got condition
11:24:52 DISPATCHER: Trying to submit another job.
11:24:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:24:52 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.926837





11:24:52 HBMASTER: Trying to run another job!
11:24:52 job_callback for (9, 0, 7) finished
11:24:52 ITERATION: Advancing config (9, 0, 4) to next budget 1200.000000
11:24:52 HBMASTER: schedule new run for iteration 9
11:24:52 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
11:24:52 HBMASTER: submitting job (9, 0, 4) to dispatcher
11:24:52 DISPATCHER: trying to submit job (9, 0, 4)
11:24:52 DISPATCHER: trying to notify the job_runner thread.
11:24:52 HBMASTER: job (9, 0, 4) submitted to dispatcher
11:24:52 DISPATCHER: Trying to submit another job.
11:24:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:24:52 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:24:52 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:24:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:24:52 WORKER: start processing job (9, 0, 4)
11:24:52 WORKER: args: ()
11:24:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:25:30 DISPATCHER: Starting worker discovery
11:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:30 DISPATCHER: Finished worker discovery
11:26:30 DISPATCHER: Starting worker discovery
11:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:30 DISPATCHER: Finished worker discovery
11:27:30 DISPATCHER: Starting worker discovery
11:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:30 DISPATCHER: Finished worker discovery
11:28:30 DISPATCHER: Starting worker discovery
11:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:30 DISPATCHER: Finished worker discovery
11:29:30 DISPATCHER: Starting worker discovery
11:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:30 DISPATCHER: Finished worker discovery
11:30:30 DISPATCHER: Starting worker discovery
11:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:30 DISPATCHER: Finished worker discovery
11:31:30 DISPATCHER: Starting worker discovery
11:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:30 DISPATCHER: Finished worker discovery
11:32:30 DISPATCHER: Starting worker discovery
11:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:30 DISPATCHER: Finished worker discovery
11:33:30 DISPATCHER: Starting worker discovery
11:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:30 DISPATCHER: Finished worker discovery
11:34:30 DISPATCHER: Starting worker discovery
11:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:30 DISPATCHER: Finished worker discovery
11:35:30 DISPATCHER: Starting worker discovery
11:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:30 DISPATCHER: Finished worker discovery
11:36:30 DISPATCHER: Starting worker discovery
11:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:30 DISPATCHER: Finished worker discovery
11:37:30 DISPATCHER: Starting worker discovery
11:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:30 DISPATCHER: Finished worker discovery
11:38:30 DISPATCHER: Starting worker discovery
11:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:30 DISPATCHER: Finished worker discovery
11:39:30 DISPATCHER: Starting worker discovery
11:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:30 DISPATCHER: Finished worker discovery
11:40:30 DISPATCHER: Starting worker discovery
11:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:30 DISPATCHER: Finished worker discovery
11:41:30 DISPATCHER: Starting worker discovery
11:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:30 DISPATCHER: Finished worker discovery
11:42:30 DISPATCHER: Starting worker discovery
11:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:30 DISPATCHER: Finished worker discovery
11:43:30 DISPATCHER: Starting worker discovery
11:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:30 DISPATCHER: Finished worker discovery
11:44:30 DISPATCHER: Starting worker discovery
11:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:30 DISPATCHER: Finished worker discovery
11:45:00 WORKER: done with job (9, 0, 4), trying to register it.
11:45:00 WORKER: registered result for job (9, 0, 4) with dispatcher
11:45:00 DISPATCHER: job (9, 0, 4) finished
11:45:00 DISPATCHER: register_result: lock acquired
11:45:00 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:45:00 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8883039440077347, 'info': {'number_mnist': 0.8883039440077347, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.01177972711333678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012168706225840268}"}}
exception: None

11:45:00 job_callback for (9, 0, 4) started
11:45:00 job_callback for (9, 0, 4) got condition
11:45:00 DISPATCHER: Trying to submit another job.
11:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:45:00 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.929810





11:45:00 HBMASTER: Trying to run another job!
11:45:00 job_callback for (9, 0, 4) finished
11:45:00 HBMASTER: shutdown initiated, shutdown_workers = True
11:45:00 WORKER: shutting down now!
11:45:00 DISPATCHER: Dispatcher shutting down
11:45:00 DISPATCHER: discover_workers shutting down
11:45:00 DISPATCHER: Trying to submit another job.
11:45:00 DISPATCHER: 'discover_worker' thread exited
11:45:00 DISPATCHER: job_runner shutting down
11:45:00 DISPATCHER: 'job_runner' thread exited
11:45:00 DISPATCHER: shut down complete
11:45:00 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f7d481f1470; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:30525>
11:45:00 WORKER: No dispatcher found. Waiting for one to initiate contact.
11:45:00 WORKER: start listening for jobs
11:45:00 wait_for_workers trying to get the condition
11:45:00 DISPATCHER: started the 'discover_worker' thread
11:45:00 DISPATCHER: started the 'job_runner' thread
11:45:00 DISPATCHER: Pyro daemon running on localhost:37191
11:45:00 DISPATCHER: Starting worker discovery
11:45:00 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
11:45:00 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.29881140179544557376
11:45:00 HBMASTER: number of workers changed to 1
11:45:00 Enough workers to start this run!
11:45:00 adjust_queue_size: lock accquired
11:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:45:00 HBMASTER: starting run at 1583923500.6044962
11:45:00 HBMASTER: adjusted queue size to (0, 1)
11:45:00 DISPATCHER: Finished worker discovery
11:45:00 start sampling a new configuration.
11:45:00 DISPATCHER: Trying to submit another job.
11:45:00 done sampling a new configuration.
11:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:45:00 HBMASTER: schedule new run for iteration 0
11:45:00 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
11:45:00 HBMASTER: submitting job (0, 0, 0) to dispatcher
11:45:00 DISPATCHER: trying to submit job (0, 0, 0)
11:45:00 DISPATCHER: trying to notify the job_runner thread.
11:45:00 HBMASTER: job (0, 0, 0) submitted to dispatcher
11:45:00 DISPATCHER: Trying to submit another job.
11:45:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:45:00 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:45:00 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:45:00 WORKER: start processing job (0, 0, 0)
11:45:00 WORKER: args: ()
11:45:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:45:54 WORKER: done with job (0, 0, 0), trying to register it.
11:45:54 WORKER: registered result for job (0, 0, 0) with dispatcher
11:45:54 DISPATCHER: job (0, 0, 0) finished
11:45:54 DISPATCHER: register_result: lock acquired
11:45:54 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:45:54 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9467035718352351, 'info': {'number_mnist': 0.9467035718352351, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}"}}
exception: None

11:45:54 job_callback for (0, 0, 0) started
11:45:54 DISPATCHER: Trying to submit another job.
11:45:54 job_callback for (0, 0, 0) got condition
11:45:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:45:54 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:45:54 HBMASTER: Trying to run another job!
11:45:54 job_callback for (0, 0, 0) finished
11:45:54 start sampling a new configuration.
11:45:54 done sampling a new configuration.
11:45:54 HBMASTER: schedule new run for iteration 0
11:45:54 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
11:45:54 HBMASTER: submitting job (0, 0, 1) to dispatcher
11:45:54 DISPATCHER: trying to submit job (0, 0, 1)
11:45:54 DISPATCHER: trying to notify the job_runner thread.
11:45:54 HBMASTER: job (0, 0, 1) submitted to dispatcher
11:45:54 DISPATCHER: Trying to submit another job.
11:45:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:45:54 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:45:54 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:45:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:45:54 WORKER: start processing job (0, 0, 1)
11:45:54 WORKER: args: ()
11:45:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029895840294533495, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01803386381537953, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 64, 'num_filters_4': 22, 'num_filters_5': 123}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:46:00 DISPATCHER: Starting worker discovery
11:46:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:00 DISPATCHER: Finished worker discovery
11:46:48 WORKER: done with job (0, 0, 1), trying to register it.
11:46:48 WORKER: registered result for job (0, 0, 1) with dispatcher
11:46:48 DISPATCHER: job (0, 0, 1) finished
11:46:48 DISPATCHER: register_result: lock acquired
11:46:48 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:46:48 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029895840294533495, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01803386381537953, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 64, 'num_filters_4': 22, 'num_filters_5': 123}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029895840294533495, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01803386381537953, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 64, 'num_filters_4': 22, 'num_filters_5': 123}"}}
exception: None

11:46:48 job_callback for (0, 0, 1) started
11:46:48 job_callback for (0, 0, 1) got condition
11:46:48 DISPATCHER: Trying to submit another job.
11:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:46:48 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:46:48 HBMASTER: Trying to run another job!
11:46:48 job_callback for (0, 0, 1) finished
11:46:48 start sampling a new configuration.
11:46:48 done sampling a new configuration.
11:46:48 HBMASTER: schedule new run for iteration 0
11:46:48 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
11:46:48 HBMASTER: submitting job (0, 0, 2) to dispatcher
11:46:48 DISPATCHER: trying to submit job (0, 0, 2)
11:46:48 DISPATCHER: trying to notify the job_runner thread.
11:46:48 HBMASTER: job (0, 0, 2) submitted to dispatcher
11:46:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:46:48 DISPATCHER: Trying to submit another job.
11:46:48 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:46:48 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:46:48 WORKER: start processing job (0, 0, 2)
11:46:48 WORKER: args: ()
11:46:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005845429138500955, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.054270984473526414, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:47:00 DISPATCHER: Starting worker discovery
11:47:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:00 DISPATCHER: Finished worker discovery
11:47:45 WORKER: done with job (0, 0, 2), trying to register it.
11:47:45 WORKER: registered result for job (0, 0, 2) with dispatcher
11:47:45 DISPATCHER: job (0, 0, 2) finished
11:47:45 DISPATCHER: register_result: lock acquired
11:47:45 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:47:45 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005845429138500955, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.054270984473526414, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7629430631101686, 'info': {'number_mnist': 0.7629430631101686, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005845429138500955, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.054270984473526414, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 51}"}}
exception: None

11:47:45 job_callback for (0, 0, 2) started
11:47:45 DISPATCHER: Trying to submit another job.
11:47:45 job_callback for (0, 0, 2) got condition
11:47:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:47:45 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:47:45 HBMASTER: Trying to run another job!
11:47:45 job_callback for (0, 0, 2) finished
11:47:45 start sampling a new configuration.
11:47:45 done sampling a new configuration.
11:47:45 HBMASTER: schedule new run for iteration 0
11:47:45 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
11:47:45 HBMASTER: submitting job (0, 0, 3) to dispatcher
11:47:45 DISPATCHER: trying to submit job (0, 0, 3)
11:47:45 DISPATCHER: trying to notify the job_runner thread.
11:47:45 HBMASTER: job (0, 0, 3) submitted to dispatcher
11:47:45 DISPATCHER: Trying to submit another job.
11:47:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:47:45 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:47:45 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:47:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:47:45 WORKER: start processing job (0, 0, 3)
11:47:45 WORKER: args: ()
11:47:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0018589138943675486, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.025733189232398968, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:48:00 DISPATCHER: Starting worker discovery
11:48:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:00 DISPATCHER: Finished worker discovery
11:48:39 WORKER: done with job (0, 0, 3), trying to register it.
11:48:39 WORKER: registered result for job (0, 0, 3) with dispatcher
11:48:39 DISPATCHER: job (0, 0, 3) finished
11:48:39 DISPATCHER: register_result: lock acquired
11:48:39 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:48:39 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0018589138943675486, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.025733189232398968, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7896794433129976, 'info': {'number_mnist': 0.7896794433129976, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0018589138943675486, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.025733189232398968, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 19}"}}
exception: None

11:48:39 job_callback for (0, 0, 3) started
11:48:39 DISPATCHER: Trying to submit another job.
11:48:39 job_callback for (0, 0, 3) got condition
11:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:48:39 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:48:39 HBMASTER: Trying to run another job!
11:48:39 job_callback for (0, 0, 3) finished
11:48:39 start sampling a new configuration.
11:48:39 done sampling a new configuration.
11:48:39 HBMASTER: schedule new run for iteration 0
11:48:39 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
11:48:39 HBMASTER: submitting job (0, 0, 4) to dispatcher
11:48:39 DISPATCHER: trying to submit job (0, 0, 4)
11:48:39 DISPATCHER: trying to notify the job_runner thread.
11:48:39 HBMASTER: job (0, 0, 4) submitted to dispatcher
11:48:39 DISPATCHER: Trying to submit another job.
11:48:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:48:39 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:48:39 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:48:39 WORKER: start processing job (0, 0, 4)
11:48:39 WORKER: args: ()
11:48:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002491458607183327, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.0712934142005935, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 127, 'num_filters_3': 83, 'num_filters_4': 46, 'num_filters_5': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:49:00 DISPATCHER: Starting worker discovery
11:49:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:00 DISPATCHER: Finished worker discovery
11:49:34 WORKER: done with job (0, 0, 4), trying to register it.
11:49:34 WORKER: registered result for job (0, 0, 4) with dispatcher
11:49:34 DISPATCHER: job (0, 0, 4) finished
11:49:34 DISPATCHER: register_result: lock acquired
11:49:34 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:49:34 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002491458607183327, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.0712934142005935, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 127, 'num_filters_3': 83, 'num_filters_4': 46, 'num_filters_5': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002491458607183327, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.0712934142005935, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 127, 'num_filters_3': 83, 'num_filters_4': 46, 'num_filters_5': 46}"}}
exception: None

11:49:34 job_callback for (0, 0, 4) started
11:49:34 job_callback for (0, 0, 4) got condition
11:49:34 DISPATCHER: Trying to submit another job.
11:49:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:49:34 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:49:34 HBMASTER: Trying to run another job!
11:49:34 job_callback for (0, 0, 4) finished
11:49:34 start sampling a new configuration.
11:49:34 done sampling a new configuration.
11:49:34 HBMASTER: schedule new run for iteration 0
11:49:34 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
11:49:34 HBMASTER: submitting job (0, 0, 5) to dispatcher
11:49:34 DISPATCHER: trying to submit job (0, 0, 5)
11:49:34 DISPATCHER: trying to notify the job_runner thread.
11:49:34 HBMASTER: job (0, 0, 5) submitted to dispatcher
11:49:34 DISPATCHER: Trying to submit another job.
11:49:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:49:34 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:49:34 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:49:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:49:34 WORKER: start processing job (0, 0, 5)
11:49:34 WORKER: args: ()
11:49:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002786239315420906, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.14635776830980726, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 21, 'num_filters_3': 30, 'num_filters_4': 84, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:50:00 DISPATCHER: Starting worker discovery
11:50:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:00 DISPATCHER: Finished worker discovery
11:50:31 WORKER: done with job (0, 0, 5), trying to register it.
11:50:31 WORKER: registered result for job (0, 0, 5) with dispatcher
11:50:31 DISPATCHER: job (0, 0, 5) finished
11:50:31 DISPATCHER: register_result: lock acquired
11:50:31 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:50:31 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002786239315420906, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.14635776830980726, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 21, 'num_filters_3': 30, 'num_filters_4': 84, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002786239315420906, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.14635776830980726, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 21, 'num_filters_3': 30, 'num_filters_4': 84, 'num_filters_5': 39}"}}
exception: None

11:50:31 job_callback for (0, 0, 5) started
11:50:31 job_callback for (0, 0, 5) got condition
11:50:31 DISPATCHER: Trying to submit another job.
11:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:50:31 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:50:31 HBMASTER: Trying to run another job!
11:50:31 job_callback for (0, 0, 5) finished
11:50:31 start sampling a new configuration.
11:50:31 done sampling a new configuration.
11:50:31 HBMASTER: schedule new run for iteration 0
11:50:31 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
11:50:31 HBMASTER: submitting job (0, 0, 6) to dispatcher
11:50:31 DISPATCHER: trying to submit job (0, 0, 6)
11:50:31 DISPATCHER: trying to notify the job_runner thread.
11:50:31 HBMASTER: job (0, 0, 6) submitted to dispatcher
11:50:31 DISPATCHER: Trying to submit another job.
11:50:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:50:31 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:50:31 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:50:31 WORKER: start processing job (0, 0, 6)
11:50:31 WORKER: args: ()
11:50:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012435409933020468, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.05840938694424292}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:51:00 DISPATCHER: Starting worker discovery
11:51:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:00 DISPATCHER: Finished worker discovery
11:51:24 WORKER: done with job (0, 0, 6), trying to register it.
11:51:24 WORKER: registered result for job (0, 0, 6) with dispatcher
11:51:24 DISPATCHER: job (0, 0, 6) finished
11:51:24 DISPATCHER: register_result: lock acquired
11:51:24 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:51:24 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012435409933020468, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.05840938694424292}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5955785191567903, 'info': {'number_mnist': 0.5955785191567903, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012435409933020468, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.05840938694424292}"}}
exception: None

11:51:24 job_callback for (0, 0, 6) started
11:51:24 job_callback for (0, 0, 6) got condition
11:51:24 DISPATCHER: Trying to submit another job.
11:51:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:51:24 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:51:24 HBMASTER: Trying to run another job!
11:51:24 job_callback for (0, 0, 6) finished
11:51:24 start sampling a new configuration.
11:51:24 done sampling a new configuration.
11:51:24 HBMASTER: schedule new run for iteration 0
11:51:24 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
11:51:24 HBMASTER: submitting job (0, 0, 7) to dispatcher
11:51:24 DISPATCHER: trying to submit job (0, 0, 7)
11:51:24 DISPATCHER: trying to notify the job_runner thread.
11:51:24 HBMASTER: job (0, 0, 7) submitted to dispatcher
11:51:24 DISPATCHER: Trying to submit another job.
11:51:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:51:24 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:51:24 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:51:24 WORKER: start processing job (0, 0, 7)
11:51:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:51:24 WORKER: args: ()
11:51:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005581416978910914, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013259064845283677}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:52:00 DISPATCHER: Starting worker discovery
11:52:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:00 DISPATCHER: Finished worker discovery
11:52:18 WORKER: done with job (0, 0, 7), trying to register it.
11:52:18 WORKER: registered result for job (0, 0, 7) with dispatcher
11:52:18 DISPATCHER: job (0, 0, 7) finished
11:52:18 DISPATCHER: register_result: lock acquired
11:52:18 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:52:18 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005581416978910914, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013259064845283677}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8826626594157384, 'info': {'number_mnist': 0.8826626594157384, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005581416978910914, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013259064845283677}"}}
exception: None

11:52:18 job_callback for (0, 0, 7) started
11:52:18 job_callback for (0, 0, 7) got condition
11:52:18 DISPATCHER: Trying to submit another job.
11:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:52:18 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:52:18 HBMASTER: Trying to run another job!
11:52:18 job_callback for (0, 0, 7) finished
11:52:18 start sampling a new configuration.
11:52:18 done sampling a new configuration.
11:52:18 HBMASTER: schedule new run for iteration 0
11:52:18 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
11:52:18 HBMASTER: submitting job (0, 0, 8) to dispatcher
11:52:18 DISPATCHER: trying to submit job (0, 0, 8)
11:52:18 DISPATCHER: trying to notify the job_runner thread.
11:52:18 HBMASTER: job (0, 0, 8) submitted to dispatcher
11:52:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:52:18 DISPATCHER: Trying to submit another job.
11:52:18 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:52:18 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:52:18 WORKER: start processing job (0, 0, 8)
11:52:18 WORKER: args: ()
11:52:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00770557680450912, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0201320206958422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:53:00 DISPATCHER: Starting worker discovery
11:53:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:00 DISPATCHER: Finished worker discovery
11:53:12 WORKER: done with job (0, 0, 8), trying to register it.
11:53:12 WORKER: registered result for job (0, 0, 8) with dispatcher
11:53:12 DISPATCHER: job (0, 0, 8) finished
11:53:12 DISPATCHER: register_result: lock acquired
11:53:12 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:53:12 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00770557680450912, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0201320206958422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9292022795605771, 'info': {'number_mnist': 0.9292022795605771, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00770557680450912, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0201320206958422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 44, 'num_filters_4': 46}"}}
exception: None

11:53:12 job_callback for (0, 0, 8) started
11:53:12 DISPATCHER: Trying to submit another job.
11:53:12 job_callback for (0, 0, 8) got condition
11:53:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:53:12 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:53:12 HBMASTER: Trying to run another job!
11:53:12 job_callback for (0, 0, 8) finished
11:53:12 start sampling a new configuration.
11:53:12 done sampling a new configuration.
11:53:12 HBMASTER: schedule new run for iteration 0
11:53:12 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
11:53:12 HBMASTER: submitting job (0, 0, 9) to dispatcher
11:53:12 DISPATCHER: trying to submit job (0, 0, 9)
11:53:12 DISPATCHER: trying to notify the job_runner thread.
11:53:12 HBMASTER: job (0, 0, 9) submitted to dispatcher
11:53:12 DISPATCHER: Trying to submit another job.
11:53:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:53:12 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:53:12 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:53:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:53:12 WORKER: start processing job (0, 0, 9)
11:53:12 WORKER: args: ()
11:53:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028691869998732127, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01095693923194258}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:54:00 DISPATCHER: Starting worker discovery
11:54:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:00 DISPATCHER: Finished worker discovery
11:54:10 WORKER: done with job (0, 0, 9), trying to register it.
11:54:10 WORKER: registered result for job (0, 0, 9) with dispatcher
11:54:10 DISPATCHER: job (0, 0, 9) finished
11:54:10 DISPATCHER: register_result: lock acquired
11:54:10 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:54:10 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028691869998732127, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01095693923194258}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9132843634922649, 'info': {'number_mnist': 0.9132843634922649, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028691869998732127, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01095693923194258}"}}
exception: None

11:54:10 job_callback for (0, 0, 9) started
11:54:10 DISPATCHER: Trying to submit another job.
11:54:10 job_callback for (0, 0, 9) got condition
11:54:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:54:10 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:54:10 HBMASTER: Trying to run another job!
11:54:10 job_callback for (0, 0, 9) finished
11:54:10 start sampling a new configuration.
11:54:10 done sampling a new configuration.
11:54:10 HBMASTER: schedule new run for iteration 0
11:54:10 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
11:54:10 HBMASTER: submitting job (0, 0, 10) to dispatcher
11:54:10 DISPATCHER: trying to submit job (0, 0, 10)
11:54:10 DISPATCHER: trying to notify the job_runner thread.
11:54:10 HBMASTER: job (0, 0, 10) submitted to dispatcher
11:54:10 DISPATCHER: Trying to submit another job.
11:54:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:54:10 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:54:10 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:54:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:54:10 WORKER: start processing job (0, 0, 10)
11:54:10 WORKER: args: ()
11:54:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03415325124402012, 'num_filters_1': 101, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.11846869433134403, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:55:00 DISPATCHER: Starting worker discovery
11:55:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:00 DISPATCHER: Finished worker discovery
11:55:07 WORKER: done with job (0, 0, 10), trying to register it.
11:55:07 WORKER: registered result for job (0, 0, 10) with dispatcher
11:55:07 DISPATCHER: job (0, 0, 10) finished
11:55:07 DISPATCHER: register_result: lock acquired
11:55:07 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:55:07 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03415325124402012, 'num_filters_1': 101, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.11846869433134403, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05790102555728473, 'info': {'number_mnist': 0.05790102555728473, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03415325124402012, 'num_filters_1': 101, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.11846869433134403, 'kernel_size_2': 3, 'num_filters_2': 18}"}}
exception: None

11:55:07 job_callback for (0, 0, 10) started
11:55:07 DISPATCHER: Trying to submit another job.
11:55:07 job_callback for (0, 0, 10) got condition
11:55:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:55:07 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:55:07 HBMASTER: Trying to run another job!
11:55:07 job_callback for (0, 0, 10) finished
11:55:07 start sampling a new configuration.
11:55:07 done sampling a new configuration.
11:55:07 HBMASTER: schedule new run for iteration 0
11:55:07 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
11:55:07 HBMASTER: submitting job (0, 0, 11) to dispatcher
11:55:07 DISPATCHER: trying to submit job (0, 0, 11)
11:55:07 DISPATCHER: trying to notify the job_runner thread.
11:55:07 HBMASTER: job (0, 0, 11) submitted to dispatcher
11:55:07 DISPATCHER: Trying to submit another job.
11:55:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:55:07 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:55:07 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:55:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:55:07 WORKER: start processing job (0, 0, 11)
11:55:07 WORKER: args: ()
11:55:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00911980048518861, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.0481469634680757}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:56:00 DISPATCHER: Starting worker discovery
11:56:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:00 DISPATCHER: Finished worker discovery
11:56:01 WORKER: done with job (0, 0, 11), trying to register it.
11:56:01 WORKER: registered result for job (0, 0, 11) with dispatcher
11:56:01 DISPATCHER: job (0, 0, 11) finished
11:56:01 DISPATCHER: register_result: lock acquired
11:56:01 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:56:01 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00911980048518861, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.0481469634680757}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7617852052505829, 'info': {'number_mnist': 0.7617852052505829, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00911980048518861, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.0481469634680757}"}}
exception: None

11:56:01 job_callback for (0, 0, 11) started
11:56:01 DISPATCHER: Trying to submit another job.
11:56:01 job_callback for (0, 0, 11) got condition
11:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:02 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:56:02 HBMASTER: Trying to run another job!
11:56:02 job_callback for (0, 0, 11) finished
11:56:02 start sampling a new configuration.
11:56:02 done sampling a new configuration.
11:56:02 HBMASTER: schedule new run for iteration 0
11:56:02 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
11:56:02 HBMASTER: submitting job (0, 0, 12) to dispatcher
11:56:02 DISPATCHER: trying to submit job (0, 0, 12)
11:56:02 DISPATCHER: trying to notify the job_runner thread.
11:56:02 HBMASTER: job (0, 0, 12) submitted to dispatcher
11:56:02 DISPATCHER: Trying to submit another job.
11:56:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:02 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:56:02 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:56:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:02 WORKER: start processing job (0, 0, 12)
11:56:02 WORKER: args: ()
11:56:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01874299750351994, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.04171589411299923}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:56:55 WORKER: done with job (0, 0, 12), trying to register it.
11:56:55 WORKER: registered result for job (0, 0, 12) with dispatcher
11:56:55 DISPATCHER: job (0, 0, 12) finished
11:56:55 DISPATCHER: register_result: lock acquired
11:56:55 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:56:55 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01874299750351994, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.04171589411299923}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5882452794141465, 'info': {'number_mnist': 0.5882452794141465, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01874299750351994, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.04171589411299923}"}}
exception: None

11:56:55 job_callback for (0, 0, 12) started
11:56:55 job_callback for (0, 0, 12) got condition
11:56:55 DISPATCHER: Trying to submit another job.
11:56:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:55 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:56:55 HBMASTER: Trying to run another job!
11:56:55 job_callback for (0, 0, 12) finished
11:56:55 start sampling a new configuration.
11:56:55 done sampling a new configuration.
11:56:55 HBMASTER: schedule new run for iteration 0
11:56:55 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
11:56:55 HBMASTER: submitting job (0, 0, 13) to dispatcher
11:56:55 DISPATCHER: trying to submit job (0, 0, 13)
11:56:55 DISPATCHER: trying to notify the job_runner thread.
11:56:55 HBMASTER: job (0, 0, 13) submitted to dispatcher
11:56:55 DISPATCHER: Trying to submit another job.
11:56:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:55 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:56:55 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:56:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:55 WORKER: start processing job (0, 0, 13)
11:56:55 WORKER: args: ()
11:56:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02649177479655138, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.029063473671610215, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:57:00 DISPATCHER: Starting worker discovery
11:57:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:00 DISPATCHER: Finished worker discovery
11:57:52 WORKER: done with job (0, 0, 13), trying to register it.
11:57:52 WORKER: registered result for job (0, 0, 13) with dispatcher
11:57:52 DISPATCHER: job (0, 0, 13) finished
11:57:52 DISPATCHER: register_result: lock acquired
11:57:52 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:57:52 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02649177479655138, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.029063473671610215, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.513902446652025, 'info': {'number_mnist': 0.513902446652025, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02649177479655138, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.029063473671610215, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 27}"}}
exception: None

11:57:52 job_callback for (0, 0, 13) started
11:57:52 DISPATCHER: Trying to submit another job.
11:57:52 job_callback for (0, 0, 13) got condition
11:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:57:52 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:57:52 HBMASTER: Trying to run another job!
11:57:52 job_callback for (0, 0, 13) finished
11:57:52 start sampling a new configuration.
11:57:52 done sampling a new configuration.
11:57:52 HBMASTER: schedule new run for iteration 0
11:57:52 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
11:57:52 HBMASTER: submitting job (0, 0, 14) to dispatcher
11:57:52 DISPATCHER: trying to submit job (0, 0, 14)
11:57:52 DISPATCHER: trying to notify the job_runner thread.
11:57:52 HBMASTER: job (0, 0, 14) submitted to dispatcher
11:57:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:57:52 DISPATCHER: Trying to submit another job.
11:57:52 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:57:52 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:57:52 WORKER: start processing job (0, 0, 14)
11:57:52 WORKER: args: ()
11:57:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.049763744069986904, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.03205701765219546, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 118, 'num_filters_3': 88, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:58:00 DISPATCHER: Starting worker discovery
11:58:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:00 DISPATCHER: Finished worker discovery
11:58:47 WORKER: done with job (0, 0, 14), trying to register it.
11:58:47 WORKER: registered result for job (0, 0, 14) with dispatcher
11:58:47 DISPATCHER: job (0, 0, 14) finished
11:58:47 DISPATCHER: register_result: lock acquired
11:58:47 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:58:47 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.049763744069986904, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.03205701765219546, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 118, 'num_filters_3': 88, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.049763744069986904, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.03205701765219546, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 118, 'num_filters_3': 88, 'num_filters_4': 77}"}}
exception: None

11:58:47 job_callback for (0, 0, 14) started
11:58:47 DISPATCHER: Trying to submit another job.
11:58:47 job_callback for (0, 0, 14) got condition
11:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:58:47 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:58:47 HBMASTER: Trying to run another job!
11:58:47 job_callback for (0, 0, 14) finished
11:58:47 start sampling a new configuration.
11:58:47 done sampling a new configuration.
11:58:47 HBMASTER: schedule new run for iteration 0
11:58:47 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
11:58:47 HBMASTER: submitting job (0, 0, 15) to dispatcher
11:58:47 DISPATCHER: trying to submit job (0, 0, 15)
11:58:47 DISPATCHER: trying to notify the job_runner thread.
11:58:47 HBMASTER: job (0, 0, 15) submitted to dispatcher
11:58:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:58:47 DISPATCHER: Trying to submit another job.
11:58:47 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:58:47 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:58:47 WORKER: start processing job (0, 0, 15)
11:58:47 WORKER: args: ()
11:58:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012908850017585556, 'num_filters_1': 107, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.030552083518681848}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:59:00 DISPATCHER: Starting worker discovery
11:59:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:00 DISPATCHER: Finished worker discovery
11:59:49 WORKER: done with job (0, 0, 15), trying to register it.
11:59:49 WORKER: registered result for job (0, 0, 15) with dispatcher
11:59:49 DISPATCHER: job (0, 0, 15) finished
11:59:49 DISPATCHER: register_result: lock acquired
11:59:49 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
11:59:49 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012908850017585556, 'num_filters_1': 107, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.030552083518681848}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8238875659248598, 'info': {'number_mnist': 0.8238875659248598, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012908850017585556, 'num_filters_1': 107, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.030552083518681848}"}}
exception: None

11:59:49 job_callback for (0, 0, 15) started
11:59:49 job_callback for (0, 0, 15) got condition
11:59:49 DISPATCHER: Trying to submit another job.
11:59:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:59:49 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:59:49 HBMASTER: Trying to run another job!
11:59:49 job_callback for (0, 0, 15) finished
11:59:49 start sampling a new configuration.
11:59:49 done sampling a new configuration.
11:59:49 HBMASTER: schedule new run for iteration 0
11:59:49 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:59:49 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:59:49 DISPATCHER: trying to submit job (0, 0, 16)
11:59:49 DISPATCHER: trying to notify the job_runner thread.
11:59:49 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:59:49 DISPATCHER: Trying to submit another job.
11:59:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:59:49 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
11:59:49 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
11:59:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:59:49 WORKER: start processing job (0, 0, 16)
11:59:49 WORKER: args: ()
11:59:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0036080992506406294, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.10577786214302684}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:00:00 DISPATCHER: Starting worker discovery
12:00:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:00 DISPATCHER: Finished worker discovery
12:00:43 WORKER: done with job (0, 0, 16), trying to register it.
12:00:43 WORKER: registered result for job (0, 0, 16) with dispatcher
12:00:43 DISPATCHER: job (0, 0, 16) finished
12:00:43 DISPATCHER: register_result: lock acquired
12:00:43 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:00:43 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0036080992506406294, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.10577786214302684}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7350594956920359, 'info': {'number_mnist': 0.7350594956920359, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0036080992506406294, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.10577786214302684}"}}
exception: None

12:00:43 job_callback for (0, 0, 16) started
12:00:43 job_callback for (0, 0, 16) got condition
12:00:43 DISPATCHER: Trying to submit another job.
12:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:00:43 HBMASTER: Trying to run another job!
12:00:43 job_callback for (0, 0, 16) finished
12:00:43 start sampling a new configuration.
12:00:43 done sampling a new configuration.
12:00:43 HBMASTER: schedule new run for iteration 0
12:00:43 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
12:00:43 HBMASTER: submitting job (0, 0, 17) to dispatcher
12:00:43 DISPATCHER: trying to submit job (0, 0, 17)
12:00:43 DISPATCHER: trying to notify the job_runner thread.
12:00:43 HBMASTER: job (0, 0, 17) submitted to dispatcher
12:00:43 DISPATCHER: Trying to submit another job.
12:00:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:00:43 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:00:43 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:00:43 WORKER: start processing job (0, 0, 17)
12:00:43 WORKER: args: ()
12:00:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08183426629421486, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012765645539865434, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 36, 'num_filters_3': 25, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:01:00 DISPATCHER: Starting worker discovery
12:01:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:00 DISPATCHER: Finished worker discovery
12:01:37 WORKER: done with job (0, 0, 17), trying to register it.
12:01:37 WORKER: registered result for job (0, 0, 17) with dispatcher
12:01:37 DISPATCHER: job (0, 0, 17) finished
12:01:37 DISPATCHER: register_result: lock acquired
12:01:37 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:01:37 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08183426629421486, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012765645539865434, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 36, 'num_filters_3': 25, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00014778402990041616, 'info': {'number_mnist': 0.00014778402990041616, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08183426629421486, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.012765645539865434, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 36, 'num_filters_3': 25, 'num_filters_4': 18}"}}
exception: None

12:01:37 job_callback for (0, 0, 17) started
12:01:37 job_callback for (0, 0, 17) got condition
12:01:37 DISPATCHER: Trying to submit another job.
12:01:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:37 HBMASTER: Trying to run another job!
12:01:37 job_callback for (0, 0, 17) finished
12:01:37 start sampling a new configuration.
12:01:37 done sampling a new configuration.
12:01:37 HBMASTER: schedule new run for iteration 0
12:01:37 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:01:37 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:01:37 DISPATCHER: trying to submit job (0, 0, 18)
12:01:37 DISPATCHER: trying to notify the job_runner thread.
12:01:37 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:01:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:37 DISPATCHER: Trying to submit another job.
12:01:37 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:01:37 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:01:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:37 WORKER: start processing job (0, 0, 18)
12:01:37 WORKER: args: ()
12:01:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:02:00 DISPATCHER: Starting worker discovery
12:02:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:00 DISPATCHER: Finished worker discovery
12:02:31 WORKER: done with job (0, 0, 18), trying to register it.
12:02:31 WORKER: registered result for job (0, 0, 18) with dispatcher
12:02:31 DISPATCHER: job (0, 0, 18) finished
12:02:31 DISPATCHER: register_result: lock acquired
12:02:31 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:02:31 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9593635052413217, 'info': {'number_mnist': 0.9593635052413217, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}"}}
exception: None

12:02:31 job_callback for (0, 0, 18) started
12:02:31 DISPATCHER: Trying to submit another job.
12:02:31 job_callback for (0, 0, 18) got condition
12:02:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:02:31 HBMASTER: Trying to run another job!
12:02:31 job_callback for (0, 0, 18) finished
12:02:31 start sampling a new configuration.
12:02:31 done sampling a new configuration.
12:02:31 HBMASTER: schedule new run for iteration 0
12:02:31 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:02:31 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:02:31 DISPATCHER: trying to submit job (0, 0, 19)
12:02:31 DISPATCHER: trying to notify the job_runner thread.
12:02:31 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:02:31 DISPATCHER: Trying to submit another job.
12:02:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:02:31 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:02:31 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:02:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:02:31 WORKER: start processing job (0, 0, 19)
12:02:31 WORKER: args: ()
12:02:31 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004522080139367764, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.022552267160942274}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:03:00 DISPATCHER: Starting worker discovery
12:03:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:00 DISPATCHER: Finished worker discovery
12:03:25 WORKER: done with job (0, 0, 19), trying to register it.
12:03:25 WORKER: registered result for job (0, 0, 19) with dispatcher
12:03:25 DISPATCHER: job (0, 0, 19) finished
12:03:25 DISPATCHER: register_result: lock acquired
12:03:25 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:03:25 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004522080139367764, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.022552267160942274}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8767594643500854, 'info': {'number_mnist': 0.8767594643500854, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004522080139367764, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.022552267160942274}"}}
exception: None

12:03:25 job_callback for (0, 0, 19) started
12:03:25 DISPATCHER: Trying to submit another job.
12:03:25 job_callback for (0, 0, 19) got condition
12:03:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:03:25 HBMASTER: Trying to run another job!
12:03:25 job_callback for (0, 0, 19) finished
12:03:25 start sampling a new configuration.
12:03:25 done sampling a new configuration.
12:03:25 HBMASTER: schedule new run for iteration 0
12:03:25 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
12:03:25 HBMASTER: submitting job (0, 0, 20) to dispatcher
12:03:25 DISPATCHER: trying to submit job (0, 0, 20)
12:03:25 DISPATCHER: trying to notify the job_runner thread.
12:03:25 HBMASTER: job (0, 0, 20) submitted to dispatcher
12:03:25 DISPATCHER: Trying to submit another job.
12:03:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:03:25 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:03:25 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:03:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:03:25 WORKER: start processing job (0, 0, 20)
12:03:25 WORKER: args: ()
12:03:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005861898122143219, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.016693636526980433, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 90, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:04:00 DISPATCHER: Starting worker discovery
12:04:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:00 DISPATCHER: Finished worker discovery
12:04:24 WORKER: done with job (0, 0, 20), trying to register it.
12:04:24 WORKER: registered result for job (0, 0, 20) with dispatcher
12:04:24 DISPATCHER: job (0, 0, 20) finished
12:04:24 DISPATCHER: register_result: lock acquired
12:04:24 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:04:24 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005861898122143219, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.016693636526980433, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 90, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8735114607042646, 'info': {'number_mnist': 0.8735114607042646, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005861898122143219, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.016693636526980433, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 90, 'num_filters_3': 26}"}}
exception: None

12:04:24 job_callback for (0, 0, 20) started
12:04:24 job_callback for (0, 0, 20) got condition
12:04:24 DISPATCHER: Trying to submit another job.
12:04:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:24 HBMASTER: Trying to run another job!
12:04:24 job_callback for (0, 0, 20) finished
12:04:24 start sampling a new configuration.
12:04:24 done sampling a new configuration.
12:04:24 HBMASTER: schedule new run for iteration 0
12:04:24 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:04:24 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:04:24 DISPATCHER: trying to submit job (0, 0, 21)
12:04:24 DISPATCHER: trying to notify the job_runner thread.
12:04:24 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:04:24 DISPATCHER: Trying to submit another job.
12:04:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:24 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:04:24 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:04:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:24 WORKER: start processing job (0, 0, 21)
12:04:24 WORKER: args: ()
12:04:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:05:00 DISPATCHER: Starting worker discovery
12:05:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:00 DISPATCHER: Finished worker discovery
12:05:20 WORKER: done with job (0, 0, 21), trying to register it.
12:05:20 WORKER: registered result for job (0, 0, 21) with dispatcher
12:05:20 DISPATCHER: job (0, 0, 21) finished
12:05:20 DISPATCHER: register_result: lock acquired
12:05:20 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:05:20 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.92639350217087, 'info': {'number_mnist': 0.92639350217087, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}"}}
exception: None

12:05:20 job_callback for (0, 0, 21) started
12:05:20 job_callback for (0, 0, 21) got condition
12:05:20 DISPATCHER: Trying to submit another job.
12:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:05:20 HBMASTER: Trying to run another job!
12:05:20 job_callback for (0, 0, 21) finished
12:05:20 start sampling a new configuration.
12:05:20 done sampling a new configuration.
12:05:20 HBMASTER: schedule new run for iteration 0
12:05:20 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
12:05:20 HBMASTER: submitting job (0, 0, 22) to dispatcher
12:05:20 DISPATCHER: trying to submit job (0, 0, 22)
12:05:20 DISPATCHER: trying to notify the job_runner thread.
12:05:20 HBMASTER: job (0, 0, 22) submitted to dispatcher
12:05:20 DISPATCHER: Trying to submit another job.
12:05:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:05:20 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:05:20 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:05:20 WORKER: start processing job (0, 0, 22)
12:05:20 WORKER: args: ()
12:05:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03900330029132936, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.03972969971870288, 'kernel_size_2': 5, 'num_filters_2': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:06:00 DISPATCHER: Starting worker discovery
12:06:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:00 DISPATCHER: Finished worker discovery
12:06:14 WORKER: done with job (0, 0, 22), trying to register it.
12:06:14 WORKER: registered result for job (0, 0, 22) with dispatcher
12:06:14 DISPATCHER: job (0, 0, 22) finished
12:06:14 DISPATCHER: register_result: lock acquired
12:06:14 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:06:14 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03900330029132936, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.03972969971870288, 'kernel_size_2': 5, 'num_filters_2': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6930621880475882, 'info': {'number_mnist': 0.6930621880475882, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03900330029132936, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.03972969971870288, 'kernel_size_2': 5, 'num_filters_2': 23}"}}
exception: None

12:06:14 job_callback for (0, 0, 22) started
12:06:14 DISPATCHER: Trying to submit another job.
12:06:14 job_callback for (0, 0, 22) got condition
12:06:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:14 HBMASTER: Trying to run another job!
12:06:14 job_callback for (0, 0, 22) finished
12:06:14 start sampling a new configuration.
12:06:14 done sampling a new configuration.
12:06:14 HBMASTER: schedule new run for iteration 0
12:06:14 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
12:06:14 HBMASTER: submitting job (0, 0, 23) to dispatcher
12:06:14 DISPATCHER: trying to submit job (0, 0, 23)
12:06:14 DISPATCHER: trying to notify the job_runner thread.
12:06:14 HBMASTER: job (0, 0, 23) submitted to dispatcher
12:06:14 DISPATCHER: Trying to submit another job.
12:06:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:14 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:06:14 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:06:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:14 WORKER: start processing job (0, 0, 23)
12:06:14 WORKER: args: ()
12:06:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007646759813656101, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.0566240730444655, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 110, 'num_filters_3': 16, 'num_filters_4': 36, 'num_filters_5': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:07:00 DISPATCHER: Starting worker discovery
12:07:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:00 DISPATCHER: Finished worker discovery
12:07:08 WORKER: done with job (0, 0, 23), trying to register it.
12:07:08 WORKER: registered result for job (0, 0, 23) with dispatcher
12:07:08 DISPATCHER: job (0, 0, 23) finished
12:07:08 DISPATCHER: register_result: lock acquired
12:07:08 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:07:08 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007646759813656101, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.0566240730444655, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 110, 'num_filters_3': 16, 'num_filters_4': 36, 'num_filters_5': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007646759813656101, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.0566240730444655, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 110, 'num_filters_3': 16, 'num_filters_4': 36, 'num_filters_5': 104}"}}
exception: None

12:07:08 job_callback for (0, 0, 23) started
12:07:08 job_callback for (0, 0, 23) got condition
12:07:08 DISPATCHER: Trying to submit another job.
12:07:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:08 HBMASTER: Trying to run another job!
12:07:08 job_callback for (0, 0, 23) finished
12:07:08 start sampling a new configuration.
12:07:08 done sampling a new configuration.
12:07:08 HBMASTER: schedule new run for iteration 0
12:07:08 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
12:07:08 HBMASTER: submitting job (0, 0, 24) to dispatcher
12:07:08 DISPATCHER: trying to submit job (0, 0, 24)
12:07:08 DISPATCHER: trying to notify the job_runner thread.
12:07:08 HBMASTER: job (0, 0, 24) submitted to dispatcher
12:07:08 DISPATCHER: Trying to submit another job.
12:07:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:08 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:07:08 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:07:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:08 WORKER: start processing job (0, 0, 24)
12:07:08 WORKER: args: ()
12:07:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012110667349678381, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.12585842770912792, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 50, 'num_filters_3': 56, 'num_filters_4': 42, 'num_filters_5': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:08:00 DISPATCHER: Starting worker discovery
12:08:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:00 DISPATCHER: Finished worker discovery
12:08:02 WORKER: done with job (0, 0, 24), trying to register it.
12:08:02 WORKER: registered result for job (0, 0, 24) with dispatcher
12:08:02 DISPATCHER: job (0, 0, 24) finished
12:08:02 DISPATCHER: register_result: lock acquired
12:08:02 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:08:02 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012110667349678381, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.12585842770912792, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 50, 'num_filters_3': 56, 'num_filters_4': 42, 'num_filters_5': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7870126448017266, 'info': {'number_mnist': 0.7870126448017266, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012110667349678381, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.12585842770912792, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 50, 'num_filters_3': 56, 'num_filters_4': 42, 'num_filters_5': 55}"}}
exception: None

12:08:02 job_callback for (0, 0, 24) started
12:08:02 job_callback for (0, 0, 24) got condition
12:08:02 DISPATCHER: Trying to submit another job.
12:08:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:08:02 HBMASTER: Trying to run another job!
12:08:02 job_callback for (0, 0, 24) finished
12:08:02 start sampling a new configuration.
12:08:02 done sampling a new configuration.
12:08:02 HBMASTER: schedule new run for iteration 0
12:08:02 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:08:02 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:08:02 DISPATCHER: trying to submit job (0, 0, 25)
12:08:02 DISPATCHER: trying to notify the job_runner thread.
12:08:02 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:08:02 DISPATCHER: Trying to submit another job.
12:08:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:08:02 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:08:02 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:08:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:08:02 WORKER: start processing job (0, 0, 25)
12:08:02 WORKER: args: ()
12:08:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004606529758792696, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.01246668597873527, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:08:56 WORKER: done with job (0, 0, 25), trying to register it.
12:08:56 WORKER: registered result for job (0, 0, 25) with dispatcher
12:08:56 DISPATCHER: job (0, 0, 25) finished
12:08:56 DISPATCHER: register_result: lock acquired
12:08:56 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:08:56 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004606529758792696, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.01246668597873527, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9173719690603409, 'info': {'number_mnist': 0.9173719690603409, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004606529758792696, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.01246668597873527, 'kernel_size_2': 3, 'num_filters_2': 33}"}}
exception: None

12:08:56 job_callback for (0, 0, 25) started
12:08:56 DISPATCHER: Trying to submit another job.
12:08:56 job_callback for (0, 0, 25) got condition
12:08:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:08:56 HBMASTER: Trying to run another job!
12:08:56 job_callback for (0, 0, 25) finished
12:08:56 start sampling a new configuration.
12:08:56 done sampling a new configuration.
12:08:56 HBMASTER: schedule new run for iteration 0
12:08:56 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:08:56 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:08:56 DISPATCHER: trying to submit job (0, 0, 26)
12:08:56 DISPATCHER: trying to notify the job_runner thread.
12:08:56 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:08:56 DISPATCHER: Trying to submit another job.
12:08:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:08:56 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:08:56 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:08:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:08:56 WORKER: start processing job (0, 0, 26)
12:08:56 WORKER: args: ()
12:08:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002554536450795536, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.037757912740047674, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:09:00 DISPATCHER: Starting worker discovery
12:09:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:00 DISPATCHER: Finished worker discovery
12:09:52 WORKER: done with job (0, 0, 26), trying to register it.
12:09:52 WORKER: registered result for job (0, 0, 26) with dispatcher
12:09:52 DISPATCHER: job (0, 0, 26) finished
12:09:52 DISPATCHER: register_result: lock acquired
12:09:52 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:09:52 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002554536450795536, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.037757912740047674, 'kernel_size_2': 7, 'num_filters_2': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8374321327171944, 'info': {'number_mnist': 0.8374321327171944, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002554536450795536, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.037757912740047674, 'kernel_size_2': 7, 'num_filters_2': 55}"}}
exception: None

12:09:52 job_callback for (0, 0, 26) started
12:09:52 DISPATCHER: Trying to submit another job.
12:09:52 job_callback for (0, 0, 26) got condition
12:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:09:52 HBMASTER: Trying to run another job!
12:09:52 job_callback for (0, 0, 26) finished
12:09:52 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 21) to next budget 133.333333
12:09:52 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
12:09:52 HBMASTER: schedule new run for iteration 0
12:09:52 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
12:09:52 HBMASTER: submitting job (0, 0, 0) to dispatcher
12:09:52 DISPATCHER: trying to submit job (0, 0, 0)
12:09:52 DISPATCHER: trying to notify the job_runner thread.
12:09:52 HBMASTER: job (0, 0, 0) submitted to dispatcher
12:09:52 DISPATCHER: Trying to submit another job.
12:09:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:09:52 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:09:52 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:09:52 WORKER: start processing job (0, 0, 0)
12:09:52 WORKER: args: ()
12:09:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:10:00 DISPATCHER: Starting worker discovery
12:10:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:00 DISPATCHER: Finished worker discovery
12:11:00 DISPATCHER: Starting worker discovery
12:11:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:00 DISPATCHER: Finished worker discovery
12:12:00 DISPATCHER: Starting worker discovery
12:12:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:00 DISPATCHER: Finished worker discovery
12:12:17 WORKER: done with job (0, 0, 0), trying to register it.
12:12:17 WORKER: registered result for job (0, 0, 0) with dispatcher
12:12:17 DISPATCHER: job (0, 0, 0) finished
12:12:17 DISPATCHER: register_result: lock acquired
12:12:17 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:12:17 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9498284895853953, 'info': {'number_mnist': 0.9498284895853953, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}"}}
exception: None

12:12:17 job_callback for (0, 0, 0) started
12:12:17 job_callback for (0, 0, 0) got condition
12:12:17 DISPATCHER: Trying to submit another job.
12:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:12:17 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:12:17 HBMASTER: Trying to run another job!
12:12:17 job_callback for (0, 0, 0) finished
12:12:17 HBMASTER: schedule new run for iteration 0
12:12:17 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
12:12:17 HBMASTER: submitting job (0, 0, 7) to dispatcher
12:12:17 DISPATCHER: trying to submit job (0, 0, 7)
12:12:17 DISPATCHER: trying to notify the job_runner thread.
12:12:17 HBMASTER: job (0, 0, 7) submitted to dispatcher
12:12:17 DISPATCHER: Trying to submit another job.
12:12:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:12:17 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:12:17 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:12:17 WORKER: start processing job (0, 0, 7)
12:12:17 WORKER: args: ()
12:12:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005581416978910914, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013259064845283677}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:13:00 DISPATCHER: Starting worker discovery
12:13:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:00 DISPATCHER: Finished worker discovery
12:14:00 DISPATCHER: Starting worker discovery
12:14:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:00 DISPATCHER: Finished worker discovery
12:14:42 WORKER: done with job (0, 0, 7), trying to register it.
12:14:42 WORKER: registered result for job (0, 0, 7) with dispatcher
12:14:42 DISPATCHER: job (0, 0, 7) finished
12:14:42 DISPATCHER: register_result: lock acquired
12:14:42 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:14:42 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005581416978910914, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013259064845283677}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8942635137704646, 'info': {'number_mnist': 0.8942635137704646, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005581416978910914, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013259064845283677}"}}
exception: None

12:14:42 job_callback for (0, 0, 7) started
12:14:42 DISPATCHER: Trying to submit another job.
12:14:42 job_callback for (0, 0, 7) got condition
12:14:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:42 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:14:42 HBMASTER: Trying to run another job!
12:14:42 job_callback for (0, 0, 7) finished
12:14:42 HBMASTER: schedule new run for iteration 0
12:14:42 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
12:14:42 HBMASTER: submitting job (0, 0, 8) to dispatcher
12:14:42 DISPATCHER: trying to submit job (0, 0, 8)
12:14:42 DISPATCHER: trying to notify the job_runner thread.
12:14:42 HBMASTER: job (0, 0, 8) submitted to dispatcher
12:14:42 DISPATCHER: Trying to submit another job.
12:14:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:42 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:14:42 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:14:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:42 WORKER: start processing job (0, 0, 8)
12:14:42 WORKER: args: ()
12:14:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00770557680450912, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0201320206958422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:15:00 DISPATCHER: Starting worker discovery
12:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:00 DISPATCHER: Finished worker discovery
12:16:00 DISPATCHER: Starting worker discovery
12:16:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:00 DISPATCHER: Finished worker discovery
12:17:00 DISPATCHER: Starting worker discovery
12:17:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:00 DISPATCHER: Finished worker discovery
12:17:09 WORKER: done with job (0, 0, 8), trying to register it.
12:17:09 WORKER: registered result for job (0, 0, 8) with dispatcher
12:17:09 DISPATCHER: job (0, 0, 8) finished
12:17:09 DISPATCHER: register_result: lock acquired
12:17:09 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:17:09 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00770557680450912, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0201320206958422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7313872878834452, 'info': {'number_mnist': 0.7313872878834452, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00770557680450912, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0201320206958422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 44, 'num_filters_4': 46}"}}
exception: None

12:17:09 job_callback for (0, 0, 8) started
12:17:09 job_callback for (0, 0, 8) got condition
12:17:09 DISPATCHER: Trying to submit another job.
12:17:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:17:09 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:17:09 HBMASTER: Trying to run another job!
12:17:09 job_callback for (0, 0, 8) finished
12:17:09 HBMASTER: schedule new run for iteration 0
12:17:09 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
12:17:09 HBMASTER: submitting job (0, 0, 9) to dispatcher
12:17:09 DISPATCHER: trying to submit job (0, 0, 9)
12:17:09 DISPATCHER: trying to notify the job_runner thread.
12:17:09 HBMASTER: job (0, 0, 9) submitted to dispatcher
12:17:09 DISPATCHER: Trying to submit another job.
12:17:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:17:09 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:17:09 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:17:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:17:09 WORKER: start processing job (0, 0, 9)
12:17:09 WORKER: args: ()
12:17:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028691869998732127, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01095693923194258}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:18:00 DISPATCHER: Starting worker discovery
12:18:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:00 DISPATCHER: Finished worker discovery
12:19:00 DISPATCHER: Starting worker discovery
12:19:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:01 DISPATCHER: Finished worker discovery
12:19:47 WORKER: done with job (0, 0, 9), trying to register it.
12:19:47 WORKER: registered result for job (0, 0, 9) with dispatcher
12:19:47 DISPATCHER: job (0, 0, 9) finished
12:19:47 DISPATCHER: register_result: lock acquired
12:19:47 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:19:47 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028691869998732127, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01095693923194258}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8960133261235536, 'info': {'number_mnist': 0.8960133261235536, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028691869998732127, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01095693923194258}"}}
exception: None

12:19:47 job_callback for (0, 0, 9) started
12:19:47 DISPATCHER: Trying to submit another job.
12:19:47 job_callback for (0, 0, 9) got condition
12:19:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:19:47 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:19:47 HBMASTER: Trying to run another job!
12:19:47 job_callback for (0, 0, 9) finished
12:19:47 HBMASTER: schedule new run for iteration 0
12:19:47 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:19:47 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:19:47 DISPATCHER: trying to submit job (0, 0, 18)
12:19:47 DISPATCHER: trying to notify the job_runner thread.
12:19:47 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:19:47 DISPATCHER: Trying to submit another job.
12:19:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:19:47 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:19:47 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:19:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:19:47 WORKER: start processing job (0, 0, 18)
12:19:47 WORKER: args: ()
12:19:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:20:01 DISPATCHER: Starting worker discovery
12:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:01 DISPATCHER: Finished worker discovery
12:21:01 DISPATCHER: Starting worker discovery
12:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:01 DISPATCHER: Finished worker discovery
12:22:01 DISPATCHER: Starting worker discovery
12:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:01 DISPATCHER: Finished worker discovery
12:22:12 WORKER: done with job (0, 0, 18), trying to register it.
12:22:12 WORKER: registered result for job (0, 0, 18) with dispatcher
12:22:12 DISPATCHER: job (0, 0, 18) finished
12:22:12 DISPATCHER: register_result: lock acquired
12:22:12 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:22:12 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9532291499588131, 'info': {'number_mnist': 0.9532291499588131, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}"}}
exception: None

12:22:12 job_callback for (0, 0, 18) started
12:22:12 job_callback for (0, 0, 18) got condition
12:22:12 DISPATCHER: Trying to submit another job.
12:22:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:22:12 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:22:12 HBMASTER: Trying to run another job!
12:22:12 job_callback for (0, 0, 18) finished
12:22:12 HBMASTER: schedule new run for iteration 0
12:22:12 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:22:12 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:22:12 DISPATCHER: trying to submit job (0, 0, 19)
12:22:12 DISPATCHER: trying to notify the job_runner thread.
12:22:12 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:22:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:22:12 DISPATCHER: Trying to submit another job.
12:22:12 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:22:12 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:22:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:22:12 WORKER: start processing job (0, 0, 19)
12:22:12 WORKER: args: ()
12:22:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004522080139367764, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.022552267160942274}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:23:01 DISPATCHER: Starting worker discovery
12:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:01 DISPATCHER: Finished worker discovery
12:24:01 DISPATCHER: Starting worker discovery
12:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:01 DISPATCHER: Finished worker discovery
12:24:38 WORKER: done with job (0, 0, 19), trying to register it.
12:24:38 WORKER: registered result for job (0, 0, 19) with dispatcher
12:24:38 DISPATCHER: job (0, 0, 19) finished
12:24:38 DISPATCHER: register_result: lock acquired
12:24:38 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:24:38 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004522080139367764, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.022552267160942274}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8775204048344662, 'info': {'number_mnist': 0.8775204048344662, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004522080139367764, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.022552267160942274}"}}
exception: None

12:24:38 job_callback for (0, 0, 19) started
12:24:38 DISPATCHER: Trying to submit another job.
12:24:38 job_callback for (0, 0, 19) got condition
12:24:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:24:38 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:24:38 HBMASTER: Trying to run another job!
12:24:38 job_callback for (0, 0, 19) finished
12:24:38 HBMASTER: schedule new run for iteration 0
12:24:38 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
12:24:38 HBMASTER: submitting job (0, 0, 20) to dispatcher
12:24:38 DISPATCHER: trying to submit job (0, 0, 20)
12:24:38 DISPATCHER: trying to notify the job_runner thread.
12:24:38 HBMASTER: job (0, 0, 20) submitted to dispatcher
12:24:38 DISPATCHER: Trying to submit another job.
12:24:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:24:38 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:24:38 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:24:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:24:38 WORKER: start processing job (0, 0, 20)
12:24:38 WORKER: args: ()
12:24:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005861898122143219, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.016693636526980433, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 90, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:25:01 DISPATCHER: Starting worker discovery
12:25:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:01 DISPATCHER: Finished worker discovery
12:26:01 DISPATCHER: Starting worker discovery
12:26:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:01 DISPATCHER: Finished worker discovery
12:27:01 DISPATCHER: Starting worker discovery
12:27:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:01 DISPATCHER: Finished worker discovery
12:27:19 WORKER: done with job (0, 0, 20), trying to register it.
12:27:19 WORKER: registered result for job (0, 0, 20) with dispatcher
12:27:19 DISPATCHER: job (0, 0, 20) finished
12:27:19 DISPATCHER: register_result: lock acquired
12:27:19 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:27:19 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005861898122143219, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.016693636526980433, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 90, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8705377638305931, 'info': {'number_mnist': 0.8705377638305931, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005861898122143219, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.016693636526980433, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 90, 'num_filters_3': 26}"}}
exception: None

12:27:19 job_callback for (0, 0, 20) started
12:27:19 DISPATCHER: Trying to submit another job.
12:27:19 job_callback for (0, 0, 20) got condition
12:27:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:27:19 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:27:19 HBMASTER: Trying to run another job!
12:27:19 job_callback for (0, 0, 20) finished
12:27:19 HBMASTER: schedule new run for iteration 0
12:27:19 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:27:19 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:27:19 DISPATCHER: trying to submit job (0, 0, 21)
12:27:19 DISPATCHER: trying to notify the job_runner thread.
12:27:19 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:27:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:27:19 DISPATCHER: Trying to submit another job.
12:27:19 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:27:19 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:27:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:27:19 WORKER: start processing job (0, 0, 21)
12:27:19 WORKER: args: ()
12:27:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:28:01 DISPATCHER: Starting worker discovery
12:28:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:01 DISPATCHER: Finished worker discovery
12:29:01 DISPATCHER: Starting worker discovery
12:29:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:01 DISPATCHER: Finished worker discovery
12:29:50 WORKER: done with job (0, 0, 21), trying to register it.
12:29:50 WORKER: registered result for job (0, 0, 21) with dispatcher
12:29:50 DISPATCHER: job (0, 0, 21) finished
12:29:50 DISPATCHER: register_result: lock acquired
12:29:50 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:29:50 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9475796566370107, 'info': {'number_mnist': 0.9475796566370107, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}"}}
exception: None

12:29:50 job_callback for (0, 0, 21) started
12:29:50 job_callback for (0, 0, 21) got condition
12:29:50 DISPATCHER: Trying to submit another job.
12:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:29:50 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:29:50 HBMASTER: Trying to run another job!
12:29:50 job_callback for (0, 0, 21) finished
12:29:50 HBMASTER: schedule new run for iteration 0
12:29:50 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:29:50 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:29:50 DISPATCHER: trying to submit job (0, 0, 25)
12:29:50 DISPATCHER: trying to notify the job_runner thread.
12:29:50 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:29:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:29:50 DISPATCHER: Trying to submit another job.
12:29:50 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:29:50 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:29:50 WORKER: start processing job (0, 0, 25)
12:29:50 WORKER: args: ()
12:29:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004606529758792696, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.01246668597873527, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:30:01 DISPATCHER: Starting worker discovery
12:30:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:01 DISPATCHER: Finished worker discovery
12:31:01 DISPATCHER: Starting worker discovery
12:31:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:01 DISPATCHER: Finished worker discovery
12:32:01 DISPATCHER: Starting worker discovery
12:32:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:01 DISPATCHER: Finished worker discovery
12:32:16 WORKER: done with job (0, 0, 25), trying to register it.
12:32:16 WORKER: registered result for job (0, 0, 25) with dispatcher
12:32:16 DISPATCHER: job (0, 0, 25) finished
12:32:16 DISPATCHER: register_result: lock acquired
12:32:16 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:32:16 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004606529758792696, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.01246668597873527, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9216887352492459, 'info': {'number_mnist': 0.9216887352492459, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004606529758792696, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.01246668597873527, 'kernel_size_2': 3, 'num_filters_2': 33}"}}
exception: None

12:32:16 job_callback for (0, 0, 25) started
12:32:16 DISPATCHER: Trying to submit another job.
12:32:16 job_callback for (0, 0, 25) got condition
12:32:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:32:16 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:32:16 HBMASTER: Trying to run another job!
12:32:16 job_callback for (0, 0, 25) finished
12:32:16 ITERATION: Advancing config (0, 0, 0) to next budget 400.000000
12:32:16 ITERATION: Advancing config (0, 0, 18) to next budget 400.000000
12:32:16 ITERATION: Advancing config (0, 0, 21) to next budget 400.000000
12:32:16 HBMASTER: schedule new run for iteration 0
12:32:16 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
12:32:16 HBMASTER: submitting job (0, 0, 0) to dispatcher
12:32:16 DISPATCHER: trying to submit job (0, 0, 0)
12:32:16 DISPATCHER: trying to notify the job_runner thread.
12:32:16 HBMASTER: job (0, 0, 0) submitted to dispatcher
12:32:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:32:16 DISPATCHER: Trying to submit another job.
12:32:16 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:32:16 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:32:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:32:16 WORKER: start processing job (0, 0, 0)
12:32:16 WORKER: args: ()
12:32:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}, 'budget': 400.0, 'working_directory': '.'}
12:33:01 DISPATCHER: Starting worker discovery
12:33:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:01 DISPATCHER: Finished worker discovery
12:34:01 DISPATCHER: Starting worker discovery
12:34:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:01 DISPATCHER: Finished worker discovery
12:35:01 DISPATCHER: Starting worker discovery
12:35:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:01 DISPATCHER: Finished worker discovery
12:36:01 DISPATCHER: Starting worker discovery
12:36:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:01 DISPATCHER: Finished worker discovery
12:37:01 DISPATCHER: Starting worker discovery
12:37:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:01 DISPATCHER: Finished worker discovery
12:38:01 DISPATCHER: Starting worker discovery
12:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:01 DISPATCHER: Finished worker discovery
12:39:01 DISPATCHER: Starting worker discovery
12:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:01 DISPATCHER: Finished worker discovery
12:39:15 WORKER: done with job (0, 0, 0), trying to register it.
12:39:15 WORKER: registered result for job (0, 0, 0) with dispatcher
12:39:15 DISPATCHER: job (0, 0, 0) finished
12:39:15 DISPATCHER: register_result: lock acquired
12:39:15 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:39:15 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9394979266038057, 'info': {'number_mnist': 0.9394979266038057, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00261070471973841, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010080191572354968}"}}
exception: None

12:39:15 job_callback for (0, 0, 0) started
12:39:15 DISPATCHER: Trying to submit another job.
12:39:15 job_callback for (0, 0, 0) got condition
12:39:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:39:15 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:39:15 HBMASTER: Trying to run another job!
12:39:15 job_callback for (0, 0, 0) finished
12:39:15 HBMASTER: schedule new run for iteration 0
12:39:15 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:39:15 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:39:15 DISPATCHER: trying to submit job (0, 0, 18)
12:39:15 DISPATCHER: trying to notify the job_runner thread.
12:39:15 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:39:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:39:15 DISPATCHER: Trying to submit another job.
12:39:15 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:39:15 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:39:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:39:15 WORKER: start processing job (0, 0, 18)
12:39:15 WORKER: args: ()
12:39:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
12:40:01 DISPATCHER: Starting worker discovery
12:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:01 DISPATCHER: Finished worker discovery
12:41:01 DISPATCHER: Starting worker discovery
12:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:01 DISPATCHER: Finished worker discovery
12:42:01 DISPATCHER: Starting worker discovery
12:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:01 DISPATCHER: Finished worker discovery
12:43:01 DISPATCHER: Starting worker discovery
12:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:01 DISPATCHER: Finished worker discovery
12:44:01 DISPATCHER: Starting worker discovery
12:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:01 DISPATCHER: Finished worker discovery
12:45:01 DISPATCHER: Starting worker discovery
12:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:01 DISPATCHER: Finished worker discovery
12:46:01 DISPATCHER: Starting worker discovery
12:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:01 DISPATCHER: Finished worker discovery
12:46:09 WORKER: done with job (0, 0, 18), trying to register it.
12:46:09 WORKER: registered result for job (0, 0, 18) with dispatcher
12:46:09 DISPATCHER: job (0, 0, 18) finished
12:46:09 DISPATCHER: register_result: lock acquired
12:46:09 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:46:09 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9392212469470865, 'info': {'number_mnist': 0.9392212469470865, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0038136087041088763, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.016479291919619957, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 86, 'num_filters_4': 22, 'num_filters_5': 26}"}}
exception: None

12:46:09 job_callback for (0, 0, 18) started
12:46:09 DISPATCHER: Trying to submit another job.
12:46:09 job_callback for (0, 0, 18) got condition
12:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:46:09 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:46:09 HBMASTER: Trying to run another job!
12:46:09 job_callback for (0, 0, 18) finished
12:46:09 HBMASTER: schedule new run for iteration 0
12:46:09 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:46:09 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:46:09 DISPATCHER: trying to submit job (0, 0, 21)
12:46:09 DISPATCHER: trying to notify the job_runner thread.
12:46:09 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:46:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:46:09 DISPATCHER: Trying to submit another job.
12:46:09 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:46:09 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:46:09 WORKER: start processing job (0, 0, 21)
12:46:09 WORKER: args: ()
12:46:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 400.0, 'working_directory': '.'}
12:47:01 DISPATCHER: Starting worker discovery
12:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:01 DISPATCHER: Finished worker discovery
12:48:01 DISPATCHER: Starting worker discovery
12:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:01 DISPATCHER: Finished worker discovery
12:49:01 DISPATCHER: Starting worker discovery
12:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:01 DISPATCHER: Finished worker discovery
12:50:01 DISPATCHER: Starting worker discovery
12:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:01 DISPATCHER: Finished worker discovery
12:51:01 DISPATCHER: Starting worker discovery
12:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:01 DISPATCHER: Finished worker discovery
12:52:01 DISPATCHER: Starting worker discovery
12:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:01 DISPATCHER: Finished worker discovery
12:53:01 DISPATCHER: Starting worker discovery
12:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:01 DISPATCHER: Finished worker discovery
12:53:27 WORKER: done with job (0, 0, 21), trying to register it.
12:53:27 WORKER: registered result for job (0, 0, 21) with dispatcher
12:53:27 DISPATCHER: job (0, 0, 21) finished
12:53:27 DISPATCHER: register_result: lock acquired
12:53:27 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
12:53:27 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.946100245711946, 'info': {'number_mnist': 0.946100245711946, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}"}}
exception: None

12:53:27 job_callback for (0, 0, 21) started
12:53:27 DISPATCHER: Trying to submit another job.
12:53:27 job_callback for (0, 0, 21) got condition
12:53:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:53:27 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:53:27 HBMASTER: Trying to run another job!
12:53:27 job_callback for (0, 0, 21) finished
12:53:27 ITERATION: Advancing config (0, 0, 21) to next budget 1200.000000
12:53:27 HBMASTER: schedule new run for iteration 0
12:53:27 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:53:27 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:53:27 DISPATCHER: trying to submit job (0, 0, 21)
12:53:27 DISPATCHER: trying to notify the job_runner thread.
12:53:27 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:53:27 DISPATCHER: Trying to submit another job.
12:53:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:53:27 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
12:53:27 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
12:53:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:53:27 WORKER: start processing job (0, 0, 21)
12:53:27 WORKER: args: ()
12:53:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 1200.0, 'working_directory': '.'}
12:54:01 DISPATCHER: Starting worker discovery
12:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:01 DISPATCHER: Finished worker discovery
12:55:01 DISPATCHER: Starting worker discovery
12:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:01 DISPATCHER: Finished worker discovery
12:56:01 DISPATCHER: Starting worker discovery
12:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:01 DISPATCHER: Finished worker discovery
12:57:01 DISPATCHER: Starting worker discovery
12:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:01 DISPATCHER: Finished worker discovery
12:58:01 DISPATCHER: Starting worker discovery
12:58:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:01 DISPATCHER: Finished worker discovery
12:59:01 DISPATCHER: Starting worker discovery
12:59:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:01 DISPATCHER: Finished worker discovery
13:00:01 DISPATCHER: Starting worker discovery
13:00:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:01 DISPATCHER: Finished worker discovery
13:01:01 DISPATCHER: Starting worker discovery
13:01:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:01 DISPATCHER: Finished worker discovery
13:02:01 DISPATCHER: Starting worker discovery
13:02:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:01 DISPATCHER: Finished worker discovery
13:03:01 DISPATCHER: Starting worker discovery
13:03:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:01 DISPATCHER: Finished worker discovery
13:04:01 DISPATCHER: Starting worker discovery
13:04:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:01 DISPATCHER: Finished worker discovery
13:05:01 DISPATCHER: Starting worker discovery
13:05:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:01 DISPATCHER: Finished worker discovery
13:06:01 DISPATCHER: Starting worker discovery
13:06:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:01 DISPATCHER: Finished worker discovery
13:07:01 DISPATCHER: Starting worker discovery
13:07:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:01 DISPATCHER: Finished worker discovery
13:08:01 DISPATCHER: Starting worker discovery
13:08:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:01 DISPATCHER: Finished worker discovery
13:09:01 DISPATCHER: Starting worker discovery
13:09:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:01 DISPATCHER: Finished worker discovery
13:10:01 DISPATCHER: Starting worker discovery
13:10:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:01 DISPATCHER: Finished worker discovery
13:11:01 DISPATCHER: Starting worker discovery
13:11:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:01 DISPATCHER: Finished worker discovery
13:12:01 DISPATCHER: Starting worker discovery
13:12:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:01 DISPATCHER: Finished worker discovery
13:13:01 DISPATCHER: Starting worker discovery
13:13:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:01 DISPATCHER: Finished worker discovery
13:14:01 DISPATCHER: Starting worker discovery
13:14:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:01 DISPATCHER: Finished worker discovery
13:15:01 DISPATCHER: Starting worker discovery
13:15:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:01 DISPATCHER: Finished worker discovery
13:15:13 WORKER: done with job (0, 0, 21), trying to register it.
13:15:13 WORKER: registered result for job (0, 0, 21) with dispatcher
13:15:13 DISPATCHER: job (0, 0, 21) finished
13:15:13 DISPATCHER: register_result: lock acquired
13:15:13 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:15:13 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.943958030373186, 'info': {'number_mnist': 0.943958030373186, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012286344051542396, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.011577176592184843, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 44, 'num_filters_3': 64}"}}
exception: None

13:15:13 job_callback for (0, 0, 21) started
13:15:13 DISPATCHER: Trying to submit another job.
13:15:13 job_callback for (0, 0, 21) got condition
13:15:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:15:13 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:15:13 HBMASTER: Trying to run another job!
13:15:13 job_callback for (0, 0, 21) finished
13:15:13 start sampling a new configuration.
13:15:13 done sampling a new configuration.
13:15:13 HBMASTER: schedule new run for iteration 1
13:15:13 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
13:15:13 HBMASTER: submitting job (1, 0, 0) to dispatcher
13:15:13 DISPATCHER: trying to submit job (1, 0, 0)
13:15:13 DISPATCHER: trying to notify the job_runner thread.
13:15:13 HBMASTER: job (1, 0, 0) submitted to dispatcher
13:15:13 DISPATCHER: Trying to submit another job.
13:15:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:15:13 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:15:13 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:15:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:15:13 WORKER: start processing job (1, 0, 0)
13:15:13 WORKER: args: ()
13:15:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02093457892593924, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.011766793500011603}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:16:01 DISPATCHER: Starting worker discovery
13:16:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:01 DISPATCHER: Finished worker discovery
13:17:01 DISPATCHER: Starting worker discovery
13:17:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:01 DISPATCHER: Finished worker discovery
13:17:43 WORKER: done with job (1, 0, 0), trying to register it.
13:17:43 WORKER: registered result for job (1, 0, 0) with dispatcher
13:17:43 DISPATCHER: job (1, 0, 0) finished
13:17:43 DISPATCHER: register_result: lock acquired
13:17:43 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:17:43 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02093457892593924, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.011766793500011603}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9114579567500853, 'info': {'number_mnist': 0.9114579567500853, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02093457892593924, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.011766793500011603}"}}
exception: None

13:17:43 job_callback for (1, 0, 0) started
13:17:43 DISPATCHER: Trying to submit another job.
13:17:43 job_callback for (1, 0, 0) got condition
13:17:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:17:43 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:17:43 HBMASTER: Trying to run another job!
13:17:43 job_callback for (1, 0, 0) finished
13:17:43 start sampling a new configuration.
13:17:43 done sampling a new configuration.
13:17:43 HBMASTER: schedule new run for iteration 1
13:17:43 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
13:17:43 HBMASTER: submitting job (1, 0, 1) to dispatcher
13:17:43 DISPATCHER: trying to submit job (1, 0, 1)
13:17:43 DISPATCHER: trying to notify the job_runner thread.
13:17:43 HBMASTER: job (1, 0, 1) submitted to dispatcher
13:17:43 DISPATCHER: Trying to submit another job.
13:17:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:17:43 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:17:43 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:17:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:17:43 WORKER: start processing job (1, 0, 1)
13:17:43 WORKER: args: ()
13:17:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0015848692939901996, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.0737080217956936, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:18:01 DISPATCHER: Starting worker discovery
13:18:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:01 DISPATCHER: Finished worker discovery
13:19:01 DISPATCHER: Starting worker discovery
13:19:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:01 DISPATCHER: Finished worker discovery
13:20:01 DISPATCHER: Starting worker discovery
13:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:01 DISPATCHER: Finished worker discovery
13:20:08 WORKER: done with job (1, 0, 1), trying to register it.
13:20:08 WORKER: registered result for job (1, 0, 1) with dispatcher
13:20:08 DISPATCHER: job (1, 0, 1) finished
13:20:08 DISPATCHER: register_result: lock acquired
13:20:08 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:20:08 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0015848692939901996, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.0737080217956936, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8521193319784895, 'info': {'number_mnist': 0.8521193319784895, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0015848692939901996, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.0737080217956936, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 28}"}}
exception: None

13:20:08 job_callback for (1, 0, 1) started
13:20:08 job_callback for (1, 0, 1) got condition
13:20:08 DISPATCHER: Trying to submit another job.
13:20:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:20:08 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:20:08 HBMASTER: Trying to run another job!
13:20:08 job_callback for (1, 0, 1) finished
13:20:08 start sampling a new configuration.
13:20:08 done sampling a new configuration.
13:20:08 HBMASTER: schedule new run for iteration 1
13:20:08 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
13:20:08 HBMASTER: submitting job (1, 0, 2) to dispatcher
13:20:08 DISPATCHER: trying to submit job (1, 0, 2)
13:20:08 DISPATCHER: trying to notify the job_runner thread.
13:20:08 HBMASTER: job (1, 0, 2) submitted to dispatcher
13:20:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:20:08 DISPATCHER: Trying to submit another job.
13:20:08 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:20:08 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:20:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:20:08 WORKER: start processing job (1, 0, 2)
13:20:08 WORKER: args: ()
13:20:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002197972339071118, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.030226751896200083, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 112, 'num_filters_4': 52, 'num_filters_5': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:21:01 DISPATCHER: Starting worker discovery
13:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:01 DISPATCHER: Finished worker discovery
13:22:01 DISPATCHER: Starting worker discovery
13:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:01 DISPATCHER: Finished worker discovery
13:22:34 WORKER: done with job (1, 0, 2), trying to register it.
13:22:34 WORKER: registered result for job (1, 0, 2) with dispatcher
13:22:34 DISPATCHER: job (1, 0, 2) finished
13:22:34 DISPATCHER: register_result: lock acquired
13:22:34 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:22:34 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002197972339071118, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.030226751896200083, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 112, 'num_filters_4': 52, 'num_filters_5': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9069907661706128, 'info': {'number_mnist': 0.9069907661706128, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002197972339071118, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.030226751896200083, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 112, 'num_filters_4': 52, 'num_filters_5': 22}"}}
exception: None

13:22:34 job_callback for (1, 0, 2) started
13:22:34 DISPATCHER: Trying to submit another job.
13:22:34 job_callback for (1, 0, 2) got condition
13:22:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:22:34 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:22:34 HBMASTER: Trying to run another job!
13:22:34 job_callback for (1, 0, 2) finished
13:22:34 start sampling a new configuration.
13:22:34 done sampling a new configuration.
13:22:34 HBMASTER: schedule new run for iteration 1
13:22:34 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
13:22:34 HBMASTER: submitting job (1, 0, 3) to dispatcher
13:22:34 DISPATCHER: trying to submit job (1, 0, 3)
13:22:34 DISPATCHER: trying to notify the job_runner thread.
13:22:34 HBMASTER: job (1, 0, 3) submitted to dispatcher
13:22:34 DISPATCHER: Trying to submit another job.
13:22:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:22:34 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:22:34 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:22:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:22:34 WORKER: start processing job (1, 0, 3)
13:22:34 WORKER: args: ()
13:22:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004852214304326983, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.011445762977914636}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:23:01 DISPATCHER: Starting worker discovery
13:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:01 DISPATCHER: Finished worker discovery
13:24:01 DISPATCHER: Starting worker discovery
13:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:01 DISPATCHER: Finished worker discovery
13:25:02 DISPATCHER: Starting worker discovery
13:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:02 DISPATCHER: Finished worker discovery
13:25:09 WORKER: done with job (1, 0, 3), trying to register it.
13:25:09 WORKER: registered result for job (1, 0, 3) with dispatcher
13:25:09 DISPATCHER: job (1, 0, 3) finished
13:25:09 DISPATCHER: register_result: lock acquired
13:25:09 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:25:09 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004852214304326983, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.011445762977914636}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.908140416261449, 'info': {'number_mnist': 0.908140416261449, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004852214304326983, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.011445762977914636}"}}
exception: None

13:25:09 job_callback for (1, 0, 3) started
13:25:09 DISPATCHER: Trying to submit another job.
13:25:09 job_callback for (1, 0, 3) got condition
13:25:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:25:09 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:25:09 HBMASTER: Trying to run another job!
13:25:09 job_callback for (1, 0, 3) finished
13:25:09 start sampling a new configuration.
13:25:09 done sampling a new configuration.
13:25:09 HBMASTER: schedule new run for iteration 1
13:25:09 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
13:25:09 HBMASTER: submitting job (1, 0, 4) to dispatcher
13:25:09 DISPATCHER: trying to submit job (1, 0, 4)
13:25:09 DISPATCHER: trying to notify the job_runner thread.
13:25:09 HBMASTER: job (1, 0, 4) submitted to dispatcher
13:25:09 DISPATCHER: Trying to submit another job.
13:25:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:25:09 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:25:09 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:25:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:25:09 WORKER: start processing job (1, 0, 4)
13:25:09 WORKER: args: ()
13:25:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:26:02 DISPATCHER: Starting worker discovery
13:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:02 DISPATCHER: Finished worker discovery
13:27:02 DISPATCHER: Starting worker discovery
13:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:02 DISPATCHER: Finished worker discovery
13:27:35 WORKER: done with job (1, 0, 4), trying to register it.
13:27:35 WORKER: registered result for job (1, 0, 4) with dispatcher
13:27:35 DISPATCHER: job (1, 0, 4) finished
13:27:35 DISPATCHER: register_result: lock acquired
13:27:35 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:27:35 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9152827311873827, 'info': {'number_mnist': 0.9152827311873827, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}"}}
exception: None

13:27:35 job_callback for (1, 0, 4) started
13:27:35 job_callback for (1, 0, 4) got condition
13:27:35 DISPATCHER: Trying to submit another job.
13:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:27:35 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:27:35 HBMASTER: Trying to run another job!
13:27:35 job_callback for (1, 0, 4) finished
13:27:35 start sampling a new configuration.
13:27:35 done sampling a new configuration.
13:27:35 HBMASTER: schedule new run for iteration 1
13:27:35 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
13:27:35 HBMASTER: submitting job (1, 0, 5) to dispatcher
13:27:35 DISPATCHER: trying to submit job (1, 0, 5)
13:27:35 DISPATCHER: trying to notify the job_runner thread.
13:27:35 HBMASTER: job (1, 0, 5) submitted to dispatcher
13:27:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:27:35 DISPATCHER: Trying to submit another job.
13:27:35 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:27:35 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:27:35 WORKER: start processing job (1, 0, 5)
13:27:35 WORKER: args: ()
13:27:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014739142675252528, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.016616747442545765}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:28:02 DISPATCHER: Starting worker discovery
13:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:02 DISPATCHER: Finished worker discovery
13:29:02 DISPATCHER: Starting worker discovery
13:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:02 DISPATCHER: Finished worker discovery
13:29:59 WORKER: done with job (1, 0, 5), trying to register it.
13:29:59 WORKER: registered result for job (1, 0, 5) with dispatcher
13:29:59 DISPATCHER: job (1, 0, 5) finished
13:29:59 DISPATCHER: register_result: lock acquired
13:29:59 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:29:59 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014739142675252528, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.016616747442545765}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7557674818877537, 'info': {'number_mnist': 0.7557674818877537, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014739142675252528, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.016616747442545765}"}}
exception: None

13:29:59 job_callback for (1, 0, 5) started
13:29:59 DISPATCHER: Trying to submit another job.
13:29:59 job_callback for (1, 0, 5) got condition
13:29:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:29:59 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:29:59 HBMASTER: Trying to run another job!
13:29:59 job_callback for (1, 0, 5) finished
13:29:59 start sampling a new configuration.
13:29:59 done sampling a new configuration.
13:29:59 HBMASTER: schedule new run for iteration 1
13:29:59 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
13:29:59 HBMASTER: submitting job (1, 0, 6) to dispatcher
13:29:59 DISPATCHER: trying to submit job (1, 0, 6)
13:29:59 DISPATCHER: trying to notify the job_runner thread.
13:29:59 HBMASTER: job (1, 0, 6) submitted to dispatcher
13:29:59 DISPATCHER: Trying to submit another job.
13:29:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:29:59 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:29:59 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:29:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:29:59 WORKER: start processing job (1, 0, 6)
13:29:59 WORKER: args: ()
13:29:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.010261673337855343, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02255037881941998, 'kernel_size_2': 5, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:30:02 DISPATCHER: Starting worker discovery
13:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:02 DISPATCHER: Finished worker discovery
13:31:02 DISPATCHER: Starting worker discovery
13:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:02 DISPATCHER: Finished worker discovery
13:32:02 DISPATCHER: Starting worker discovery
13:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:02 DISPATCHER: Finished worker discovery
13:32:29 WORKER: done with job (1, 0, 6), trying to register it.
13:32:29 WORKER: registered result for job (1, 0, 6) with dispatcher
13:32:29 DISPATCHER: job (1, 0, 6) finished
13:32:29 DISPATCHER: register_result: lock acquired
13:32:29 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:32:29 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.010261673337855343, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02255037881941998, 'kernel_size_2': 5, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8980725775250429, 'info': {'number_mnist': 0.8980725775250429, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.010261673337855343, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02255037881941998, 'kernel_size_2': 5, 'num_filters_2': 26}"}}
exception: None

13:32:29 job_callback for (1, 0, 6) started
13:32:29 DISPATCHER: Trying to submit another job.
13:32:29 job_callback for (1, 0, 6) got condition
13:32:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:32:29 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:32:29 HBMASTER: Trying to run another job!
13:32:29 job_callback for (1, 0, 6) finished
13:32:29 start sampling a new configuration.
13:32:29 done sampling a new configuration.
13:32:29 HBMASTER: schedule new run for iteration 1
13:32:29 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
13:32:29 HBMASTER: submitting job (1, 0, 7) to dispatcher
13:32:29 DISPATCHER: trying to submit job (1, 0, 7)
13:32:29 DISPATCHER: trying to notify the job_runner thread.
13:32:29 HBMASTER: job (1, 0, 7) submitted to dispatcher
13:32:29 DISPATCHER: Trying to submit another job.
13:32:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:32:29 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:32:29 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:32:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:32:29 WORKER: start processing job (1, 0, 7)
13:32:29 WORKER: args: ()
13:32:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02906157519657727, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01807915016880889, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:33:02 DISPATCHER: Starting worker discovery
13:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:02 DISPATCHER: Finished worker discovery
13:34:02 DISPATCHER: Starting worker discovery
13:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:02 DISPATCHER: Finished worker discovery
13:34:55 WORKER: done with job (1, 0, 7), trying to register it.
13:34:55 WORKER: registered result for job (1, 0, 7) with dispatcher
13:34:55 DISPATCHER: job (1, 0, 7) finished
13:34:55 DISPATCHER: register_result: lock acquired
13:34:55 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:34:55 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02906157519657727, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01807915016880889, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9258035386903961, 'info': {'number_mnist': 0.9258035386903961, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02906157519657727, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01807915016880889, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 68}"}}
exception: None

13:34:55 job_callback for (1, 0, 7) started
13:34:55 DISPATCHER: Trying to submit another job.
13:34:55 job_callback for (1, 0, 7) got condition
13:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:34:55 HBMASTER: Trying to run another job!
13:34:55 job_callback for (1, 0, 7) finished
13:34:55 start sampling a new configuration.
13:34:55 done sampling a new configuration.
13:34:55 HBMASTER: schedule new run for iteration 1
13:34:55 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
13:34:55 HBMASTER: submitting job (1, 0, 8) to dispatcher
13:34:55 DISPATCHER: trying to submit job (1, 0, 8)
13:34:55 DISPATCHER: trying to notify the job_runner thread.
13:34:55 HBMASTER: job (1, 0, 8) submitted to dispatcher
13:34:55 DISPATCHER: Trying to submit another job.
13:34:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:34:55 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:34:55 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:34:55 WORKER: start processing job (1, 0, 8)
13:34:55 WORKER: args: ()
13:34:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01400680465748013, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.02079506722139743, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:35:02 DISPATCHER: Starting worker discovery
13:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:02 DISPATCHER: Finished worker discovery
13:36:02 DISPATCHER: Starting worker discovery
13:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:02 DISPATCHER: Finished worker discovery
13:37:02 DISPATCHER: Starting worker discovery
13:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:02 DISPATCHER: Finished worker discovery
13:37:27 WORKER: done with job (1, 0, 8), trying to register it.
13:37:27 WORKER: registered result for job (1, 0, 8) with dispatcher
13:37:27 DISPATCHER: job (1, 0, 8) finished
13:37:27 DISPATCHER: register_result: lock acquired
13:37:27 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:37:27 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01400680465748013, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.02079506722139743, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8315118533046837, 'info': {'number_mnist': 0.8315118533046837, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.01400680465748013, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.02079506722139743, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

13:37:27 job_callback for (1, 0, 8) started
13:37:27 job_callback for (1, 0, 8) got condition
13:37:27 DISPATCHER: Trying to submit another job.
13:37:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:37:27 HBMASTER: Trying to run another job!
13:37:27 job_callback for (1, 0, 8) finished
13:37:27 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
13:37:27 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
13:37:27 ITERATION: Advancing config (1, 0, 7) to next budget 400.000000
13:37:27 HBMASTER: schedule new run for iteration 1
13:37:27 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
13:37:27 HBMASTER: submitting job (1, 0, 0) to dispatcher
13:37:27 DISPATCHER: trying to submit job (1, 0, 0)
13:37:27 DISPATCHER: trying to notify the job_runner thread.
13:37:27 HBMASTER: job (1, 0, 0) submitted to dispatcher
13:37:27 DISPATCHER: Trying to submit another job.
13:37:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:37:27 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:37:27 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:37:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:37:27 WORKER: start processing job (1, 0, 0)
13:37:27 WORKER: args: ()
13:37:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02093457892593924, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.011766793500011603}, 'budget': 400.0, 'working_directory': '.'}
13:38:02 DISPATCHER: Starting worker discovery
13:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:02 DISPATCHER: Finished worker discovery
13:39:02 DISPATCHER: Starting worker discovery
13:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:02 DISPATCHER: Finished worker discovery
13:40:02 DISPATCHER: Starting worker discovery
13:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:02 DISPATCHER: Finished worker discovery
13:41:02 DISPATCHER: Starting worker discovery
13:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:02 DISPATCHER: Finished worker discovery
13:42:02 DISPATCHER: Starting worker discovery
13:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:02 DISPATCHER: Finished worker discovery
13:43:02 DISPATCHER: Starting worker discovery
13:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:02 DISPATCHER: Finished worker discovery
13:44:02 DISPATCHER: Starting worker discovery
13:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:02 DISPATCHER: Finished worker discovery
13:44:39 WORKER: done with job (1, 0, 0), trying to register it.
13:44:39 WORKER: registered result for job (1, 0, 0) with dispatcher
13:44:39 DISPATCHER: job (1, 0, 0) finished
13:44:39 DISPATCHER: register_result: lock acquired
13:44:39 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:44:39 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02093457892593924, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.011766793500011603}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9200277774733249, 'info': {'number_mnist': 0.9200277774733249, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02093457892593924, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.011766793500011603}"}}
exception: None

13:44:39 job_callback for (1, 0, 0) started
13:44:39 DISPATCHER: Trying to submit another job.
13:44:39 job_callback for (1, 0, 0) got condition
13:44:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:44:39 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:44:39 HBMASTER: Trying to run another job!
13:44:39 job_callback for (1, 0, 0) finished
13:44:39 HBMASTER: schedule new run for iteration 1
13:44:39 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
13:44:39 HBMASTER: submitting job (1, 0, 4) to dispatcher
13:44:39 DISPATCHER: trying to submit job (1, 0, 4)
13:44:39 DISPATCHER: trying to notify the job_runner thread.
13:44:39 HBMASTER: job (1, 0, 4) submitted to dispatcher
13:44:39 DISPATCHER: Trying to submit another job.
13:44:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:44:39 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:44:39 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:44:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:44:39 WORKER: start processing job (1, 0, 4)
13:44:39 WORKER: args: ()
13:44:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}, 'budget': 400.0, 'working_directory': '.'}
13:45:02 DISPATCHER: Starting worker discovery
13:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:02 DISPATCHER: Finished worker discovery
13:46:02 DISPATCHER: Starting worker discovery
13:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:02 DISPATCHER: Finished worker discovery
13:47:02 DISPATCHER: Starting worker discovery
13:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:02 DISPATCHER: Finished worker discovery
13:48:02 DISPATCHER: Starting worker discovery
13:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:02 DISPATCHER: Finished worker discovery
13:49:02 DISPATCHER: Starting worker discovery
13:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:02 DISPATCHER: Finished worker discovery
13:50:02 DISPATCHER: Starting worker discovery
13:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:02 DISPATCHER: Finished worker discovery
13:51:02 DISPATCHER: Starting worker discovery
13:51:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:02 DISPATCHER: Finished worker discovery
13:51:40 WORKER: done with job (1, 0, 4), trying to register it.
13:51:40 WORKER: registered result for job (1, 0, 4) with dispatcher
13:51:40 DISPATCHER: job (1, 0, 4) finished
13:51:40 DISPATCHER: register_result: lock acquired
13:51:40 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:51:40 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9361208736494002, 'info': {'number_mnist': 0.9361208736494002, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}"}}
exception: None

13:51:40 job_callback for (1, 0, 4) started
13:51:40 job_callback for (1, 0, 4) got condition
13:51:40 DISPATCHER: Trying to submit another job.
13:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:40 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:51:40 HBMASTER: Trying to run another job!
13:51:40 job_callback for (1, 0, 4) finished
13:51:40 HBMASTER: schedule new run for iteration 1
13:51:40 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
13:51:40 HBMASTER: submitting job (1, 0, 7) to dispatcher
13:51:40 DISPATCHER: trying to submit job (1, 0, 7)
13:51:40 DISPATCHER: trying to notify the job_runner thread.
13:51:40 HBMASTER: job (1, 0, 7) submitted to dispatcher
13:51:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:40 DISPATCHER: Trying to submit another job.
13:51:40 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:51:40 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:40 WORKER: start processing job (1, 0, 7)
13:51:40 WORKER: args: ()
13:51:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02906157519657727, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01807915016880889, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 68}, 'budget': 400.0, 'working_directory': '.'}
13:52:02 DISPATCHER: Starting worker discovery
13:52:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:02 DISPATCHER: Finished worker discovery
13:53:02 DISPATCHER: Starting worker discovery
13:53:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:02 DISPATCHER: Finished worker discovery
13:54:02 DISPATCHER: Starting worker discovery
13:54:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:02 DISPATCHER: Finished worker discovery
13:55:02 DISPATCHER: Starting worker discovery
13:55:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:02 DISPATCHER: Finished worker discovery
13:56:02 DISPATCHER: Starting worker discovery
13:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:02 DISPATCHER: Finished worker discovery
13:57:02 DISPATCHER: Starting worker discovery
13:57:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:02 DISPATCHER: Finished worker discovery
13:58:02 DISPATCHER: Starting worker discovery
13:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:02 DISPATCHER: Finished worker discovery
13:58:41 WORKER: done with job (1, 0, 7), trying to register it.
13:58:41 WORKER: registered result for job (1, 0, 7) with dispatcher
13:58:41 DISPATCHER: job (1, 0, 7) finished
13:58:41 DISPATCHER: register_result: lock acquired
13:58:41 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
13:58:41 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02906157519657727, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01807915016880889, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 68}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.889453705159258, 'info': {'number_mnist': 0.889453705159258, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02906157519657727, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01807915016880889, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 68}"}}
exception: None

13:58:41 job_callback for (1, 0, 7) started
13:58:41 DISPATCHER: Trying to submit another job.
13:58:41 job_callback for (1, 0, 7) got condition
13:58:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:58:41 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:58:41 HBMASTER: Trying to run another job!
13:58:41 job_callback for (1, 0, 7) finished
13:58:41 ITERATION: Advancing config (1, 0, 4) to next budget 1200.000000
13:58:41 HBMASTER: schedule new run for iteration 1
13:58:41 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
13:58:41 HBMASTER: submitting job (1, 0, 4) to dispatcher
13:58:41 DISPATCHER: trying to submit job (1, 0, 4)
13:58:41 DISPATCHER: trying to notify the job_runner thread.
13:58:41 HBMASTER: job (1, 0, 4) submitted to dispatcher
13:58:41 DISPATCHER: Trying to submit another job.
13:58:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:58:41 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
13:58:41 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
13:58:41 WORKER: start processing job (1, 0, 4)
13:58:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:58:41 WORKER: args: ()
13:58:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}, 'budget': 1200.0, 'working_directory': '.'}
13:59:02 DISPATCHER: Starting worker discovery
13:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:02 DISPATCHER: Finished worker discovery
14:00:02 DISPATCHER: Starting worker discovery
14:00:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:02 DISPATCHER: Finished worker discovery
14:01:02 DISPATCHER: Starting worker discovery
14:01:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:02 DISPATCHER: Finished worker discovery
14:02:02 DISPATCHER: Starting worker discovery
14:02:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:02 DISPATCHER: Finished worker discovery
14:03:02 DISPATCHER: Starting worker discovery
14:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:02 DISPATCHER: Finished worker discovery
14:04:02 DISPATCHER: Starting worker discovery
14:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:02 DISPATCHER: Finished worker discovery
14:05:02 DISPATCHER: Starting worker discovery
14:05:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:02 DISPATCHER: Finished worker discovery
14:06:02 DISPATCHER: Starting worker discovery
14:06:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:02 DISPATCHER: Finished worker discovery
14:07:02 DISPATCHER: Starting worker discovery
14:07:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:02 DISPATCHER: Finished worker discovery
14:08:02 DISPATCHER: Starting worker discovery
14:08:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:02 DISPATCHER: Finished worker discovery
14:09:02 DISPATCHER: Starting worker discovery
14:09:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:02 DISPATCHER: Finished worker discovery
14:10:02 DISPATCHER: Starting worker discovery
14:10:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:02 DISPATCHER: Finished worker discovery
14:11:02 DISPATCHER: Starting worker discovery
14:11:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:02 DISPATCHER: Finished worker discovery
14:12:02 DISPATCHER: Starting worker discovery
14:12:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:02 DISPATCHER: Finished worker discovery
14:13:02 DISPATCHER: Starting worker discovery
14:13:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:02 DISPATCHER: Finished worker discovery
14:14:02 DISPATCHER: Starting worker discovery
14:14:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:02 DISPATCHER: Finished worker discovery
14:15:02 DISPATCHER: Starting worker discovery
14:15:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:02 DISPATCHER: Finished worker discovery
14:16:02 DISPATCHER: Starting worker discovery
14:16:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:02 DISPATCHER: Finished worker discovery
14:17:02 DISPATCHER: Starting worker discovery
14:17:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:02 DISPATCHER: Finished worker discovery
14:18:02 DISPATCHER: Starting worker discovery
14:18:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:02 DISPATCHER: Finished worker discovery
14:19:02 DISPATCHER: Starting worker discovery
14:19:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:02 DISPATCHER: Finished worker discovery
14:19:24 WORKER: done with job (1, 0, 4), trying to register it.
14:19:24 WORKER: registered result for job (1, 0, 4) with dispatcher
14:19:24 DISPATCHER: job (1, 0, 4) finished
14:19:24 DISPATCHER: register_result: lock acquired
14:19:24 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:19:24 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9335949745858956, 'info': {'number_mnist': 0.9335949745858956, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0109128828048092, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.015157992049331345, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 30}"}}
exception: None

14:19:24 job_callback for (1, 0, 4) started
14:19:24 job_callback for (1, 0, 4) got condition
14:19:24 DISPATCHER: Trying to submit another job.
14:19:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:19:24 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:19:24 HBMASTER: Trying to run another job!
14:19:24 job_callback for (1, 0, 4) finished
14:19:24 start sampling a new configuration.
14:19:24 done sampling a new configuration.
14:19:24 HBMASTER: schedule new run for iteration 2
14:19:24 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
14:19:24 HBMASTER: submitting job (2, 0, 0) to dispatcher
14:19:24 DISPATCHER: trying to submit job (2, 0, 0)
14:19:24 DISPATCHER: trying to notify the job_runner thread.
14:19:24 HBMASTER: job (2, 0, 0) submitted to dispatcher
14:19:24 DISPATCHER: Trying to submit another job.
14:19:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:19:24 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:19:24 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:19:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:19:24 WORKER: start processing job (2, 0, 0)
14:19:24 WORKER: args: ()
14:19:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0014032920258349587, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.15485726245757753, 'kernel_size_2': 5, 'num_filters_2': 52}, 'budget': 400.0, 'working_directory': '.'}
14:20:02 DISPATCHER: Starting worker discovery
14:20:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:02 DISPATCHER: Finished worker discovery
14:21:02 DISPATCHER: Starting worker discovery
14:21:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:02 DISPATCHER: Finished worker discovery
14:22:02 DISPATCHER: Starting worker discovery
14:22:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:02 DISPATCHER: Finished worker discovery
14:23:02 DISPATCHER: Starting worker discovery
14:23:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:02 DISPATCHER: Finished worker discovery
14:24:02 DISPATCHER: Starting worker discovery
14:24:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:02 DISPATCHER: Finished worker discovery
14:25:02 DISPATCHER: Starting worker discovery
14:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:02 DISPATCHER: Finished worker discovery
14:26:02 DISPATCHER: Starting worker discovery
14:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:02 DISPATCHER: Finished worker discovery
14:26:26 WORKER: done with job (2, 0, 0), trying to register it.
14:26:26 WORKER: registered result for job (2, 0, 0) with dispatcher
14:26:26 DISPATCHER: job (2, 0, 0) finished
14:26:26 DISPATCHER: register_result: lock acquired
14:26:26 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:26:26 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0014032920258349587, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.15485726245757753, 'kernel_size_2': 5, 'num_filters_2': 52}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5103726032027937, 'info': {'number_mnist': 0.5103726032027937, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0014032920258349587, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.15485726245757753, 'kernel_size_2': 5, 'num_filters_2': 52}"}}
exception: None

14:26:26 job_callback for (2, 0, 0) started
14:26:26 DISPATCHER: Trying to submit another job.
14:26:26 job_callback for (2, 0, 0) got condition
14:26:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:26:26 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:26:26 HBMASTER: Trying to run another job!
14:26:26 job_callback for (2, 0, 0) finished
14:26:26 start sampling a new configuration.
14:26:26 done sampling a new configuration.
14:26:26 HBMASTER: schedule new run for iteration 2
14:26:26 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
14:26:26 HBMASTER: submitting job (2, 0, 1) to dispatcher
14:26:26 DISPATCHER: trying to submit job (2, 0, 1)
14:26:26 DISPATCHER: trying to notify the job_runner thread.
14:26:26 HBMASTER: job (2, 0, 1) submitted to dispatcher
14:26:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:26:26 DISPATCHER: Trying to submit another job.
14:26:26 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:26:26 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:26:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:26:26 WORKER: start processing job (2, 0, 1)
14:26:26 WORKER: args: ()
14:26:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.059450339957095324, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.12310944481975886, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 90, 'num_filters_3': 21, 'num_filters_4': 18}, 'budget': 400.0, 'working_directory': '.'}
14:27:02 DISPATCHER: Starting worker discovery
14:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:02 DISPATCHER: Finished worker discovery
14:28:02 DISPATCHER: Starting worker discovery
14:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:02 DISPATCHER: Finished worker discovery
14:29:02 DISPATCHER: Starting worker discovery
14:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:02 DISPATCHER: Finished worker discovery
14:30:02 DISPATCHER: Starting worker discovery
14:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:02 DISPATCHER: Finished worker discovery
14:31:02 DISPATCHER: Starting worker discovery
14:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:02 DISPATCHER: Finished worker discovery
14:32:02 DISPATCHER: Starting worker discovery
14:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:02 DISPATCHER: Finished worker discovery
14:33:02 DISPATCHER: Starting worker discovery
14:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:02 DISPATCHER: Finished worker discovery
14:33:37 WORKER: done with job (2, 0, 1), trying to register it.
14:33:37 WORKER: registered result for job (2, 0, 1) with dispatcher
14:33:37 DISPATCHER: job (2, 0, 1) finished
14:33:37 DISPATCHER: register_result: lock acquired
14:33:37 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:33:37 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.059450339957095324, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.12310944481975886, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 90, 'num_filters_3': 21, 'num_filters_4': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.059450339957095324, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.12310944481975886, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 90, 'num_filters_3': 21, 'num_filters_4': 18}"}}
exception: None

14:33:37 job_callback for (2, 0, 1) started
14:33:37 DISPATCHER: Trying to submit another job.
14:33:37 job_callback for (2, 0, 1) got condition
14:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:37 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:33:37 HBMASTER: Trying to run another job!
14:33:37 job_callback for (2, 0, 1) finished
14:33:37 start sampling a new configuration.
14:33:37 done sampling a new configuration.
14:33:37 HBMASTER: schedule new run for iteration 2
14:33:37 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
14:33:37 HBMASTER: submitting job (2, 0, 2) to dispatcher
14:33:37 DISPATCHER: trying to submit job (2, 0, 2)
14:33:37 DISPATCHER: trying to notify the job_runner thread.
14:33:37 HBMASTER: job (2, 0, 2) submitted to dispatcher
14:33:37 DISPATCHER: Trying to submit another job.
14:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:37 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:33:37 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:37 WORKER: start processing job (2, 0, 2)
14:33:37 WORKER: args: ()
14:33:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003460119040853581, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.056204614741474056, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 101, 'num_filters_3': 87, 'num_filters_4': 47, 'num_filters_5': 62}, 'budget': 400.0, 'working_directory': '.'}
14:34:02 DISPATCHER: Starting worker discovery
14:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:02 DISPATCHER: Finished worker discovery
14:35:02 DISPATCHER: Starting worker discovery
14:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:02 DISPATCHER: Finished worker discovery
14:36:02 DISPATCHER: Starting worker discovery
14:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:02 DISPATCHER: Finished worker discovery
14:37:02 DISPATCHER: Starting worker discovery
14:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:02 DISPATCHER: Finished worker discovery
14:38:02 DISPATCHER: Starting worker discovery
14:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:02 DISPATCHER: Finished worker discovery
14:39:02 DISPATCHER: Starting worker discovery
14:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:02 DISPATCHER: Finished worker discovery
14:40:02 DISPATCHER: Starting worker discovery
14:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:02 DISPATCHER: Finished worker discovery
14:40:33 WORKER: done with job (2, 0, 2), trying to register it.
14:40:33 WORKER: registered result for job (2, 0, 2) with dispatcher
14:40:33 DISPATCHER: job (2, 0, 2) finished
14:40:33 DISPATCHER: register_result: lock acquired
14:40:33 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:40:33 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003460119040853581, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.056204614741474056, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 101, 'num_filters_3': 87, 'num_filters_4': 47, 'num_filters_5': 62}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8399620075933125, 'info': {'number_mnist': 0.8399620075933125, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003460119040853581, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.056204614741474056, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 101, 'num_filters_3': 87, 'num_filters_4': 47, 'num_filters_5': 62}"}}
exception: None

14:40:33 job_callback for (2, 0, 2) started
14:40:33 DISPATCHER: Trying to submit another job.
14:40:33 job_callback for (2, 0, 2) got condition
14:40:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:40:33 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:40:33 HBMASTER: Trying to run another job!
14:40:33 job_callback for (2, 0, 2) finished
14:40:33 start sampling a new configuration.
14:40:33 done sampling a new configuration.
14:40:33 HBMASTER: schedule new run for iteration 2
14:40:33 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
14:40:33 HBMASTER: submitting job (2, 0, 3) to dispatcher
14:40:33 DISPATCHER: trying to submit job (2, 0, 3)
14:40:33 DISPATCHER: trying to notify the job_runner thread.
14:40:33 HBMASTER: job (2, 0, 3) submitted to dispatcher
14:40:33 DISPATCHER: Trying to submit another job.
14:40:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:40:33 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:40:33 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:40:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:40:33 WORKER: start processing job (2, 0, 3)
14:40:33 WORKER: args: ()
14:40:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06592309639557858, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.012148273380119824}, 'budget': 400.0, 'working_directory': '.'}
14:41:02 DISPATCHER: Starting worker discovery
14:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:02 DISPATCHER: Finished worker discovery
14:42:02 DISPATCHER: Starting worker discovery
14:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:02 DISPATCHER: Finished worker discovery
14:43:02 DISPATCHER: Starting worker discovery
14:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:02 DISPATCHER: Finished worker discovery
14:44:02 DISPATCHER: Starting worker discovery
14:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:02 DISPATCHER: Finished worker discovery
14:45:02 DISPATCHER: Starting worker discovery
14:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:02 DISPATCHER: Finished worker discovery
14:46:02 DISPATCHER: Starting worker discovery
14:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:02 DISPATCHER: Finished worker discovery
14:47:02 DISPATCHER: Starting worker discovery
14:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:02 DISPATCHER: Finished worker discovery
14:47:28 WORKER: done with job (2, 0, 3), trying to register it.
14:47:28 WORKER: registered result for job (2, 0, 3) with dispatcher
14:47:28 DISPATCHER: job (2, 0, 3) finished
14:47:28 DISPATCHER: register_result: lock acquired
14:47:28 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:47:28 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06592309639557858, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.012148273380119824}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9043504819408439, 'info': {'number_mnist': 0.9043504819408439, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06592309639557858, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.012148273380119824}"}}
exception: None

14:47:28 job_callback for (2, 0, 3) started
14:47:28 job_callback for (2, 0, 3) got condition
14:47:28 DISPATCHER: Trying to submit another job.
14:47:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:47:28 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:47:28 HBMASTER: Trying to run another job!
14:47:28 job_callback for (2, 0, 3) finished
14:47:28 start sampling a new configuration.
14:47:28 done sampling a new configuration.
14:47:28 HBMASTER: schedule new run for iteration 2
14:47:28 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
14:47:28 HBMASTER: submitting job (2, 0, 4) to dispatcher
14:47:28 DISPATCHER: trying to submit job (2, 0, 4)
14:47:28 DISPATCHER: trying to notify the job_runner thread.
14:47:28 HBMASTER: job (2, 0, 4) submitted to dispatcher
14:47:28 DISPATCHER: Trying to submit another job.
14:47:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:47:28 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:47:28 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:47:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:47:28 WORKER: start processing job (2, 0, 4)
14:47:28 WORKER: args: ()
14:47:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003293216080617641, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.015582217799644733, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 107, 'num_filters_3': 48, 'num_filters_4': 59}, 'budget': 400.0, 'working_directory': '.'}
14:48:02 DISPATCHER: Starting worker discovery
14:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:02 DISPATCHER: Finished worker discovery
14:49:02 DISPATCHER: Starting worker discovery
14:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:02 DISPATCHER: Finished worker discovery
14:50:02 DISPATCHER: Starting worker discovery
14:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:02 DISPATCHER: Finished worker discovery
14:51:02 DISPATCHER: Starting worker discovery
14:51:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:02 DISPATCHER: Finished worker discovery
14:52:02 DISPATCHER: Starting worker discovery
14:52:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:02 DISPATCHER: Finished worker discovery
14:53:02 DISPATCHER: Starting worker discovery
14:53:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:02 DISPATCHER: Finished worker discovery
14:54:02 DISPATCHER: Starting worker discovery
14:54:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:02 DISPATCHER: Finished worker discovery
14:54:26 WORKER: done with job (2, 0, 4), trying to register it.
14:54:26 WORKER: registered result for job (2, 0, 4) with dispatcher
14:54:26 DISPATCHER: job (2, 0, 4) finished
14:54:26 DISPATCHER: register_result: lock acquired
14:54:26 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
14:54:26 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003293216080617641, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.015582217799644733, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 107, 'num_filters_3': 48, 'num_filters_4': 59}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9296392309920346, 'info': {'number_mnist': 0.9296392309920346, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003293216080617641, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.015582217799644733, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 107, 'num_filters_3': 48, 'num_filters_4': 59}"}}
exception: None

14:54:26 job_callback for (2, 0, 4) started
14:54:26 DISPATCHER: Trying to submit another job.
14:54:26 job_callback for (2, 0, 4) got condition
14:54:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:54:26 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:54:26 HBMASTER: Trying to run another job!
14:54:26 job_callback for (2, 0, 4) finished
14:54:26 start sampling a new configuration.
14:54:26 done sampling a new configuration.
14:54:26 HBMASTER: schedule new run for iteration 2
14:54:26 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
14:54:26 HBMASTER: submitting job (2, 0, 5) to dispatcher
14:54:26 DISPATCHER: trying to submit job (2, 0, 5)
14:54:26 DISPATCHER: trying to notify the job_runner thread.
14:54:26 HBMASTER: job (2, 0, 5) submitted to dispatcher
14:54:26 DISPATCHER: Trying to submit another job.
14:54:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:54:26 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
14:54:26 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
14:54:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:54:26 WORKER: start processing job (2, 0, 5)
14:54:26 WORKER: args: ()
14:54:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025455490330083454, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.12644520925930522, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 45}, 'budget': 400.0, 'working_directory': '.'}
14:55:02 DISPATCHER: Starting worker discovery
14:55:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:02 DISPATCHER: Finished worker discovery
14:56:02 DISPATCHER: Starting worker discovery
14:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:02 DISPATCHER: Finished worker discovery
14:57:02 DISPATCHER: Starting worker discovery
14:57:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:02 DISPATCHER: Finished worker discovery
14:58:02 DISPATCHER: Starting worker discovery
14:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:02 DISPATCHER: Finished worker discovery
14:59:02 DISPATCHER: Starting worker discovery
14:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:02 DISPATCHER: Finished worker discovery
15:00:02 DISPATCHER: Starting worker discovery
15:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:03 DISPATCHER: Finished worker discovery
15:01:03 DISPATCHER: Starting worker discovery
15:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:03 DISPATCHER: Finished worker discovery
15:01:22 WORKER: done with job (2, 0, 5), trying to register it.
15:01:22 WORKER: registered result for job (2, 0, 5) with dispatcher
15:01:22 DISPATCHER: job (2, 0, 5) finished
15:01:22 DISPATCHER: register_result: lock acquired
15:01:22 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:01:22 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025455490330083454, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.12644520925930522, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7399153515142036, 'info': {'number_mnist': 0.7399153515142036, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025455490330083454, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.12644520925930522, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 45}"}}
exception: None

15:01:22 job_callback for (2, 0, 5) started
15:01:22 job_callback for (2, 0, 5) got condition
15:01:22 DISPATCHER: Trying to submit another job.
15:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:01:22 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:01:22 HBMASTER: Trying to run another job!
15:01:22 job_callback for (2, 0, 5) finished
15:01:22 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
15:01:22 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
15:01:22 HBMASTER: schedule new run for iteration 2
15:01:22 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
15:01:22 HBMASTER: submitting job (2, 0, 3) to dispatcher
15:01:22 DISPATCHER: trying to submit job (2, 0, 3)
15:01:22 DISPATCHER: trying to notify the job_runner thread.
15:01:22 HBMASTER: job (2, 0, 3) submitted to dispatcher
15:01:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:01:22 DISPATCHER: Trying to submit another job.
15:01:22 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:01:22 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:01:22 WORKER: start processing job (2, 0, 3)
15:01:22 WORKER: args: ()
15:01:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06592309639557858, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.012148273380119824}, 'budget': 1200.0, 'working_directory': '.'}
15:02:03 DISPATCHER: Starting worker discovery
15:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:03 DISPATCHER: Finished worker discovery
15:03:03 DISPATCHER: Starting worker discovery
15:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:03 DISPATCHER: Finished worker discovery
15:04:03 DISPATCHER: Starting worker discovery
15:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:03 DISPATCHER: Finished worker discovery
15:05:03 DISPATCHER: Starting worker discovery
15:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:03 DISPATCHER: Finished worker discovery
15:06:03 DISPATCHER: Starting worker discovery
15:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:03 DISPATCHER: Finished worker discovery
15:07:03 DISPATCHER: Starting worker discovery
15:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:03 DISPATCHER: Finished worker discovery
15:08:03 DISPATCHER: Starting worker discovery
15:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:03 DISPATCHER: Finished worker discovery
15:09:03 DISPATCHER: Starting worker discovery
15:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:03 DISPATCHER: Finished worker discovery
15:10:03 DISPATCHER: Starting worker discovery
15:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:03 DISPATCHER: Finished worker discovery
15:11:03 DISPATCHER: Starting worker discovery
15:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:03 DISPATCHER: Finished worker discovery
15:12:03 DISPATCHER: Starting worker discovery
15:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:03 DISPATCHER: Finished worker discovery
15:13:03 DISPATCHER: Starting worker discovery
15:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:03 DISPATCHER: Finished worker discovery
15:14:03 DISPATCHER: Starting worker discovery
15:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:03 DISPATCHER: Finished worker discovery
15:15:03 DISPATCHER: Starting worker discovery
15:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:03 DISPATCHER: Finished worker discovery
15:16:03 DISPATCHER: Starting worker discovery
15:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:03 DISPATCHER: Finished worker discovery
15:17:03 DISPATCHER: Starting worker discovery
15:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:03 DISPATCHER: Finished worker discovery
15:18:03 DISPATCHER: Starting worker discovery
15:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:03 DISPATCHER: Finished worker discovery
15:19:03 DISPATCHER: Starting worker discovery
15:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:03 DISPATCHER: Finished worker discovery
15:20:03 DISPATCHER: Starting worker discovery
15:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:03 DISPATCHER: Finished worker discovery
15:21:03 DISPATCHER: Starting worker discovery
15:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:03 DISPATCHER: Finished worker discovery
15:21:49 WORKER: done with job (2, 0, 3), trying to register it.
15:21:49 WORKER: registered result for job (2, 0, 3) with dispatcher
15:21:49 DISPATCHER: job (2, 0, 3) finished
15:21:49 DISPATCHER: register_result: lock acquired
15:21:49 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:21:49 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06592309639557858, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.012148273380119824}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8835927269552587, 'info': {'number_mnist': 0.8835927269552587, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06592309639557858, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.012148273380119824}"}}
exception: None

15:21:49 job_callback for (2, 0, 3) started
15:21:49 job_callback for (2, 0, 3) got condition
15:21:49 DISPATCHER: Trying to submit another job.
15:21:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:21:49 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:21:49 HBMASTER: Trying to run another job!
15:21:49 job_callback for (2, 0, 3) finished
15:21:49 HBMASTER: schedule new run for iteration 2
15:21:49 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
15:21:49 HBMASTER: submitting job (2, 0, 4) to dispatcher
15:21:49 DISPATCHER: trying to submit job (2, 0, 4)
15:21:49 DISPATCHER: trying to notify the job_runner thread.
15:21:49 HBMASTER: job (2, 0, 4) submitted to dispatcher
15:21:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:21:49 DISPATCHER: Trying to submit another job.
15:21:49 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:21:49 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:21:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:21:49 WORKER: start processing job (2, 0, 4)
15:21:49 WORKER: args: ()
15:21:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003293216080617641, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.015582217799644733, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 107, 'num_filters_3': 48, 'num_filters_4': 59}, 'budget': 1200.0, 'working_directory': '.'}
15:22:03 DISPATCHER: Starting worker discovery
15:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:03 DISPATCHER: Finished worker discovery
15:23:03 DISPATCHER: Starting worker discovery
15:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:03 DISPATCHER: Finished worker discovery
15:24:03 DISPATCHER: Starting worker discovery
15:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:03 DISPATCHER: Finished worker discovery
15:25:03 DISPATCHER: Starting worker discovery
15:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:03 DISPATCHER: Finished worker discovery
15:26:03 DISPATCHER: Starting worker discovery
15:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:03 DISPATCHER: Finished worker discovery
15:27:03 DISPATCHER: Starting worker discovery
15:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:03 DISPATCHER: Finished worker discovery
15:28:03 DISPATCHER: Starting worker discovery
15:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:03 DISPATCHER: Finished worker discovery
15:29:03 DISPATCHER: Starting worker discovery
15:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:03 DISPATCHER: Finished worker discovery
15:30:03 DISPATCHER: Starting worker discovery
15:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:03 DISPATCHER: Finished worker discovery
15:31:03 DISPATCHER: Starting worker discovery
15:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:03 DISPATCHER: Finished worker discovery
15:32:03 DISPATCHER: Starting worker discovery
15:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:03 DISPATCHER: Finished worker discovery
15:33:03 DISPATCHER: Starting worker discovery
15:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:03 DISPATCHER: Finished worker discovery
15:34:03 DISPATCHER: Starting worker discovery
15:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:03 DISPATCHER: Finished worker discovery
15:35:03 DISPATCHER: Starting worker discovery
15:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:03 DISPATCHER: Finished worker discovery
15:36:03 DISPATCHER: Starting worker discovery
15:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:03 DISPATCHER: Finished worker discovery
15:37:03 DISPATCHER: Starting worker discovery
15:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:03 DISPATCHER: Finished worker discovery
15:38:03 DISPATCHER: Starting worker discovery
15:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:03 DISPATCHER: Finished worker discovery
15:39:03 DISPATCHER: Starting worker discovery
15:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:03 DISPATCHER: Finished worker discovery
15:40:03 DISPATCHER: Starting worker discovery
15:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:03 DISPATCHER: Finished worker discovery
15:41:03 DISPATCHER: Starting worker discovery
15:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:03 DISPATCHER: Finished worker discovery
15:42:03 DISPATCHER: Starting worker discovery
15:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:03 DISPATCHER: Finished worker discovery
15:42:29 WORKER: done with job (2, 0, 4), trying to register it.
15:42:29 WORKER: registered result for job (2, 0, 4) with dispatcher
15:42:29 DISPATCHER: job (2, 0, 4) finished
15:42:29 DISPATCHER: register_result: lock acquired
15:42:29 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
15:42:29 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003293216080617641, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.015582217799644733, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 107, 'num_filters_3': 48, 'num_filters_4': 59}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9367359697135325, 'info': {'number_mnist': 0.9367359697135325, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003293216080617641, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.015582217799644733, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 107, 'num_filters_3': 48, 'num_filters_4': 59}"}}
exception: None

15:42:29 job_callback for (2, 0, 4) started
15:42:29 job_callback for (2, 0, 4) got condition
15:42:29 DISPATCHER: Trying to submit another job.
15:42:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:42:29 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:42:29 HBMASTER: Trying to run another job!
15:42:29 job_callback for (2, 0, 4) finished
15:42:29 start sampling a new configuration.
15:42:29 done sampling a new configuration.
15:42:29 HBMASTER: schedule new run for iteration 3
15:42:29 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
15:42:29 HBMASTER: submitting job (3, 0, 0) to dispatcher
15:42:29 DISPATCHER: trying to submit job (3, 0, 0)
15:42:29 DISPATCHER: trying to notify the job_runner thread.
15:42:29 HBMASTER: job (3, 0, 0) submitted to dispatcher
15:42:29 DISPATCHER: Trying to submit another job.
15:42:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:42:29 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
15:42:29 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
15:42:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:42:29 WORKER: start processing job (3, 0, 0)
15:42:29 WORKER: args: ()
15:42:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.021996217029091634, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.19087657716591863, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 83, 'num_filters_4': 24, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
15:43:03 DISPATCHER: Starting worker discovery
15:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:03 DISPATCHER: Finished worker discovery
15:44:03 DISPATCHER: Starting worker discovery
15:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:03 DISPATCHER: Finished worker discovery
15:45:03 DISPATCHER: Starting worker discovery
15:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:03 DISPATCHER: Finished worker discovery
15:46:03 DISPATCHER: Starting worker discovery
15:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:03 DISPATCHER: Finished worker discovery
15:47:03 DISPATCHER: Starting worker discovery
15:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:03 DISPATCHER: Finished worker discovery
15:48:03 DISPATCHER: Starting worker discovery
15:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:03 DISPATCHER: Finished worker discovery
15:49:03 DISPATCHER: Starting worker discovery
15:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:03 DISPATCHER: Finished worker discovery
15:50:03 DISPATCHER: Starting worker discovery
15:50:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:03 DISPATCHER: Finished worker discovery
15:51:03 DISPATCHER: Starting worker discovery
15:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:03 DISPATCHER: Finished worker discovery
15:52:03 DISPATCHER: Starting worker discovery
15:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:03 DISPATCHER: Finished worker discovery
15:53:03 DISPATCHER: Starting worker discovery
15:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:03 DISPATCHER: Finished worker discovery
15:54:03 DISPATCHER: Starting worker discovery
15:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:03 DISPATCHER: Finished worker discovery
15:55:03 DISPATCHER: Starting worker discovery
15:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:03 DISPATCHER: Finished worker discovery
15:56:03 DISPATCHER: Starting worker discovery
15:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:03 DISPATCHER: Finished worker discovery
15:57:03 DISPATCHER: Starting worker discovery
15:57:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:03 DISPATCHER: Finished worker discovery
15:58:03 DISPATCHER: Starting worker discovery
15:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:03 DISPATCHER: Finished worker discovery
15:59:03 DISPATCHER: Starting worker discovery
15:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:03 DISPATCHER: Finished worker discovery
16:00:03 DISPATCHER: Starting worker discovery
16:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:03 DISPATCHER: Finished worker discovery
16:01:03 DISPATCHER: Starting worker discovery
16:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:03 DISPATCHER: Finished worker discovery
16:02:03 DISPATCHER: Starting worker discovery
16:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:03 DISPATCHER: Finished worker discovery
16:02:57 WORKER: done with job (3, 0, 0), trying to register it.
16:02:57 WORKER: registered result for job (3, 0, 0) with dispatcher
16:02:57 DISPATCHER: job (3, 0, 0) finished
16:02:57 DISPATCHER: register_result: lock acquired
16:02:57 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:02:57 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.021996217029091634, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.19087657716591863, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 83, 'num_filters_4': 24, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.021996217029091634, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.19087657716591863, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 83, 'num_filters_4': 24, 'num_filters_5': 24}"}}
exception: None

16:02:57 job_callback for (3, 0, 0) started
16:02:57 DISPATCHER: Trying to submit another job.
16:02:57 job_callback for (3, 0, 0) got condition
16:02:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:02:57 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:02:57 HBMASTER: Trying to run another job!
16:02:57 job_callback for (3, 0, 0) finished
16:02:57 start sampling a new configuration.
16:02:57 done sampling a new configuration.
16:02:57 HBMASTER: schedule new run for iteration 3
16:02:57 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
16:02:57 HBMASTER: submitting job (3, 0, 1) to dispatcher
16:02:57 DISPATCHER: trying to submit job (3, 0, 1)
16:02:57 DISPATCHER: trying to notify the job_runner thread.
16:02:57 HBMASTER: job (3, 0, 1) submitted to dispatcher
16:02:57 DISPATCHER: Trying to submit another job.
16:02:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:02:57 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:02:57 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:02:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:02:57 WORKER: start processing job (3, 0, 1)
16:02:57 WORKER: args: ()
16:02:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.012799952565085766, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01212601065352811, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 109, 'num_filters_3': 123, 'num_filters_4': 16, 'num_filters_5': 44}, 'budget': 1200.0, 'working_directory': '.'}
16:03:03 DISPATCHER: Starting worker discovery
16:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:03 DISPATCHER: Finished worker discovery
16:04:03 DISPATCHER: Starting worker discovery
16:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:03 DISPATCHER: Finished worker discovery
16:05:03 DISPATCHER: Starting worker discovery
16:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:03 DISPATCHER: Finished worker discovery
16:06:03 DISPATCHER: Starting worker discovery
16:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:03 DISPATCHER: Finished worker discovery
16:07:03 DISPATCHER: Starting worker discovery
16:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:03 DISPATCHER: Finished worker discovery
16:08:03 DISPATCHER: Starting worker discovery
16:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:03 DISPATCHER: Finished worker discovery
16:09:03 DISPATCHER: Starting worker discovery
16:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:03 DISPATCHER: Finished worker discovery
16:10:03 DISPATCHER: Starting worker discovery
16:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:03 DISPATCHER: Finished worker discovery
16:11:03 DISPATCHER: Starting worker discovery
16:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:03 DISPATCHER: Finished worker discovery
16:12:03 DISPATCHER: Starting worker discovery
16:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:03 DISPATCHER: Finished worker discovery
16:13:03 DISPATCHER: Starting worker discovery
16:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:03 DISPATCHER: Finished worker discovery
16:14:03 DISPATCHER: Starting worker discovery
16:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:03 DISPATCHER: Finished worker discovery
16:15:03 DISPATCHER: Starting worker discovery
16:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:03 DISPATCHER: Finished worker discovery
16:16:03 DISPATCHER: Starting worker discovery
16:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:03 DISPATCHER: Finished worker discovery
16:17:03 DISPATCHER: Starting worker discovery
16:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:03 DISPATCHER: Finished worker discovery
16:18:03 DISPATCHER: Starting worker discovery
16:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:03 DISPATCHER: Finished worker discovery
16:19:03 DISPATCHER: Starting worker discovery
16:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:03 DISPATCHER: Finished worker discovery
16:20:03 DISPATCHER: Starting worker discovery
16:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:03 DISPATCHER: Finished worker discovery
16:21:03 DISPATCHER: Starting worker discovery
16:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:03 DISPATCHER: Finished worker discovery
16:22:03 DISPATCHER: Starting worker discovery
16:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:03 DISPATCHER: Finished worker discovery
16:23:03 DISPATCHER: Starting worker discovery
16:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:03 DISPATCHER: Finished worker discovery
16:23:49 WORKER: done with job (3, 0, 1), trying to register it.
16:23:49 WORKER: registered result for job (3, 0, 1) with dispatcher
16:23:49 DISPATCHER: job (3, 0, 1) finished
16:23:49 DISPATCHER: register_result: lock acquired
16:23:49 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:23:49 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.012799952565085766, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01212601065352811, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 109, 'num_filters_3': 123, 'num_filters_4': 16, 'num_filters_5': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9383645938226202, 'info': {'number_mnist': 0.9383645938226202, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.012799952565085766, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01212601065352811, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 109, 'num_filters_3': 123, 'num_filters_4': 16, 'num_filters_5': 44}"}}
exception: None

16:23:49 job_callback for (3, 0, 1) started
16:23:49 job_callback for (3, 0, 1) got condition
16:23:49 DISPATCHER: Trying to submit another job.
16:23:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:23:49 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:23:49 HBMASTER: Trying to run another job!
16:23:49 job_callback for (3, 0, 1) finished
16:23:49 start sampling a new configuration.
16:23:49 done sampling a new configuration.
16:23:49 HBMASTER: schedule new run for iteration 3
16:23:49 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
16:23:49 HBMASTER: submitting job (3, 0, 2) to dispatcher
16:23:49 DISPATCHER: trying to submit job (3, 0, 2)
16:23:49 DISPATCHER: trying to notify the job_runner thread.
16:23:49 HBMASTER: job (3, 0, 2) submitted to dispatcher
16:23:49 DISPATCHER: Trying to submit another job.
16:23:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:23:49 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:23:49 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:23:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:23:49 WORKER: start processing job (3, 0, 2)
16:23:49 WORKER: args: ()
16:23:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.059514752767679896, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.021583604278198984, 'kernel_size_2': 7, 'num_filters_2': 61}, 'budget': 1200.0, 'working_directory': '.'}
16:24:03 DISPATCHER: Starting worker discovery
16:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:03 DISPATCHER: Finished worker discovery
16:25:03 DISPATCHER: Starting worker discovery
16:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:03 DISPATCHER: Finished worker discovery
16:26:03 DISPATCHER: Starting worker discovery
16:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:03 DISPATCHER: Finished worker discovery
16:27:03 DISPATCHER: Starting worker discovery
16:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:03 DISPATCHER: Finished worker discovery
16:28:03 DISPATCHER: Starting worker discovery
16:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:03 DISPATCHER: Finished worker discovery
16:29:03 DISPATCHER: Starting worker discovery
16:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:03 DISPATCHER: Finished worker discovery
16:30:03 DISPATCHER: Starting worker discovery
16:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:03 DISPATCHER: Finished worker discovery
16:31:03 DISPATCHER: Starting worker discovery
16:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:03 DISPATCHER: Finished worker discovery
16:32:03 DISPATCHER: Starting worker discovery
16:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:03 DISPATCHER: Finished worker discovery
16:33:03 DISPATCHER: Starting worker discovery
16:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:03 DISPATCHER: Finished worker discovery
16:34:03 DISPATCHER: Starting worker discovery
16:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:03 DISPATCHER: Finished worker discovery
16:35:03 DISPATCHER: Starting worker discovery
16:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:03 DISPATCHER: Finished worker discovery
16:36:03 DISPATCHER: Starting worker discovery
16:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:03 DISPATCHER: Finished worker discovery
16:37:03 DISPATCHER: Starting worker discovery
16:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:03 DISPATCHER: Finished worker discovery
16:38:03 DISPATCHER: Starting worker discovery
16:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:03 DISPATCHER: Finished worker discovery
16:39:03 DISPATCHER: Starting worker discovery
16:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:03 DISPATCHER: Finished worker discovery
16:40:03 DISPATCHER: Starting worker discovery
16:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:03 DISPATCHER: Finished worker discovery
16:41:03 DISPATCHER: Starting worker discovery
16:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:03 DISPATCHER: Finished worker discovery
16:42:03 DISPATCHER: Starting worker discovery
16:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:03 DISPATCHER: Finished worker discovery
16:43:03 DISPATCHER: Starting worker discovery
16:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:03 DISPATCHER: Finished worker discovery
16:44:03 DISPATCHER: Starting worker discovery
16:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:04 DISPATCHER: Finished worker discovery
16:45:04 DISPATCHER: Starting worker discovery
16:45:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:04 DISPATCHER: Finished worker discovery
16:45:56 WORKER: done with job (3, 0, 2), trying to register it.
16:45:56 WORKER: registered result for job (3, 0, 2) with dispatcher
16:45:56 DISPATCHER: job (3, 0, 2) finished
16:45:56 DISPATCHER: register_result: lock acquired
16:45:56 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
16:45:56 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.059514752767679896, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.021583604278198984, 'kernel_size_2': 7, 'num_filters_2': 61}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.838724881529066, 'info': {'number_mnist': 0.838724881529066, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.059514752767679896, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.021583604278198984, 'kernel_size_2': 7, 'num_filters_2': 61}"}}
exception: None

16:45:56 job_callback for (3, 0, 2) started
16:45:56 job_callback for (3, 0, 2) got condition
16:45:56 DISPATCHER: Trying to submit another job.
16:45:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:45:56 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:45:56 HBMASTER: Trying to run another job!
16:45:56 job_callback for (3, 0, 2) finished
16:45:56 start sampling a new configuration.
16:45:56 done sampling a new configuration.
16:45:56 HBMASTER: schedule new run for iteration 3
16:45:56 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
16:45:56 HBMASTER: submitting job (3, 0, 3) to dispatcher
16:45:56 DISPATCHER: trying to submit job (3, 0, 3)
16:45:56 DISPATCHER: trying to notify the job_runner thread.
16:45:56 HBMASTER: job (3, 0, 3) submitted to dispatcher
16:45:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:45:56 DISPATCHER: Trying to submit another job.
16:45:56 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
16:45:56 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
16:45:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:45:56 WORKER: start processing job (3, 0, 3)
16:45:56 WORKER: args: ()
16:45:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03839944523064525, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.023423400275654278, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 38, 'num_filters_4': 27}, 'budget': 1200.0, 'working_directory': '.'}
16:46:04 DISPATCHER: Starting worker discovery
16:46:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:04 DISPATCHER: Finished worker discovery
16:47:04 DISPATCHER: Starting worker discovery
16:47:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:04 DISPATCHER: Finished worker discovery
16:48:04 DISPATCHER: Starting worker discovery
16:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:04 DISPATCHER: Finished worker discovery
16:49:04 DISPATCHER: Starting worker discovery
16:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:04 DISPATCHER: Finished worker discovery
16:50:04 DISPATCHER: Starting worker discovery
16:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:04 DISPATCHER: Finished worker discovery
16:51:04 DISPATCHER: Starting worker discovery
16:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:04 DISPATCHER: Finished worker discovery
16:52:04 DISPATCHER: Starting worker discovery
16:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:04 DISPATCHER: Finished worker discovery
16:53:04 DISPATCHER: Starting worker discovery
16:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:04 DISPATCHER: Finished worker discovery
16:54:04 DISPATCHER: Starting worker discovery
16:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:04 DISPATCHER: Finished worker discovery
16:55:04 DISPATCHER: Starting worker discovery
16:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:04 DISPATCHER: Finished worker discovery
16:56:04 DISPATCHER: Starting worker discovery
16:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:04 DISPATCHER: Finished worker discovery
16:57:04 DISPATCHER: Starting worker discovery
16:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:04 DISPATCHER: Finished worker discovery
16:58:04 DISPATCHER: Starting worker discovery
16:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:04 DISPATCHER: Finished worker discovery
16:59:04 DISPATCHER: Starting worker discovery
16:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:04 DISPATCHER: Finished worker discovery
17:00:04 DISPATCHER: Starting worker discovery
17:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:04 DISPATCHER: Finished worker discovery
17:01:04 DISPATCHER: Starting worker discovery
17:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:04 DISPATCHER: Finished worker discovery
17:02:04 DISPATCHER: Starting worker discovery
17:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:04 DISPATCHER: Finished worker discovery
17:03:04 DISPATCHER: Starting worker discovery
17:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:04 DISPATCHER: Finished worker discovery
17:04:04 DISPATCHER: Starting worker discovery
17:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:04 DISPATCHER: Finished worker discovery
17:05:04 DISPATCHER: Starting worker discovery
17:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:04 DISPATCHER: Finished worker discovery
17:06:04 DISPATCHER: Starting worker discovery
17:06:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:04 DISPATCHER: Finished worker discovery
17:07:04 DISPATCHER: Starting worker discovery
17:07:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:04 DISPATCHER: Finished worker discovery
17:07:48 WORKER: done with job (3, 0, 3), trying to register it.
17:07:48 WORKER: registered result for job (3, 0, 3) with dispatcher
17:07:48 DISPATCHER: job (3, 0, 3) finished
17:07:48 DISPATCHER: register_result: lock acquired
17:07:48 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:07:48 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03839944523064525, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.023423400275654278, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 38, 'num_filters_4': 27}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7619976694644401, 'info': {'number_mnist': 0.7619976694644401, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03839944523064525, 'num_filters_1': 84, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.023423400275654278, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 38, 'num_filters_4': 27}"}}
exception: None

17:07:48 job_callback for (3, 0, 3) started
17:07:48 DISPATCHER: Trying to submit another job.
17:07:48 job_callback for (3, 0, 3) got condition
17:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:48 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:07:48 HBMASTER: Trying to run another job!
17:07:48 job_callback for (3, 0, 3) finished
17:07:48 start sampling a new configuration.
17:07:48 done sampling a new configuration.
17:07:48 HBMASTER: schedule new run for iteration 4
17:07:48 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
17:07:48 HBMASTER: submitting job (4, 0, 0) to dispatcher
17:07:48 DISPATCHER: trying to submit job (4, 0, 0)
17:07:48 DISPATCHER: trying to notify the job_runner thread.
17:07:48 HBMASTER: job (4, 0, 0) submitted to dispatcher
17:07:48 DISPATCHER: Trying to submit another job.
17:07:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:48 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:07:48 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:48 WORKER: start processing job (4, 0, 0)
17:07:48 WORKER: args: ()
17:07:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004454173996353296, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011668441061159752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 75, 'num_filters_3': 23, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:08:04 DISPATCHER: Starting worker discovery
17:08:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:04 DISPATCHER: Finished worker discovery
17:08:44 WORKER: done with job (4, 0, 0), trying to register it.
17:08:44 WORKER: registered result for job (4, 0, 0) with dispatcher
17:08:44 DISPATCHER: job (4, 0, 0) finished
17:08:44 DISPATCHER: register_result: lock acquired
17:08:44 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:08:44 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004454173996353296, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011668441061159752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 75, 'num_filters_3': 23, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8242524003500796, 'info': {'number_mnist': 0.8242524003500796, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004454173996353296, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011668441061159752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 75, 'num_filters_3': 23, 'num_filters_4': 47}"}}
exception: None

17:08:44 job_callback for (4, 0, 0) started
17:08:44 DISPATCHER: Trying to submit another job.
17:08:44 job_callback for (4, 0, 0) got condition
17:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:08:44 HBMASTER: Trying to run another job!
17:08:44 job_callback for (4, 0, 0) finished
17:08:44 start sampling a new configuration.
17:08:44 done sampling a new configuration.
17:08:44 HBMASTER: schedule new run for iteration 4
17:08:44 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
17:08:44 HBMASTER: submitting job (4, 0, 1) to dispatcher
17:08:44 DISPATCHER: trying to submit job (4, 0, 1)
17:08:44 DISPATCHER: trying to notify the job_runner thread.
17:08:44 HBMASTER: job (4, 0, 1) submitted to dispatcher
17:08:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:08:44 DISPATCHER: Trying to submit another job.
17:08:44 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:08:44 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:08:44 WORKER: start processing job (4, 0, 1)
17:08:44 WORKER: args: ()
17:08:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.023191326773313113, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.029199301588665075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 82, 'num_filters_3': 36, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:09:04 DISPATCHER: Starting worker discovery
17:09:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:04 DISPATCHER: Finished worker discovery
17:09:38 WORKER: done with job (4, 0, 1), trying to register it.
17:09:38 WORKER: registered result for job (4, 0, 1) with dispatcher
17:09:38 DISPATCHER: job (4, 0, 1) finished
17:09:38 DISPATCHER: register_result: lock acquired
17:09:38 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:09:38 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.023191326773313113, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.029199301588665075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 82, 'num_filters_3': 36, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7892609484568693, 'info': {'number_mnist': 0.7892609484568693, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.023191326773313113, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.029199301588665075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 82, 'num_filters_3': 36, 'num_filters_4': 16}"}}
exception: None

17:09:38 job_callback for (4, 0, 1) started
17:09:38 DISPATCHER: Trying to submit another job.
17:09:38 job_callback for (4, 0, 1) got condition
17:09:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:09:38 HBMASTER: Trying to run another job!
17:09:38 job_callback for (4, 0, 1) finished
17:09:38 start sampling a new configuration.
17:09:38 done sampling a new configuration.
17:09:38 HBMASTER: schedule new run for iteration 4
17:09:38 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
17:09:38 HBMASTER: submitting job (4, 0, 2) to dispatcher
17:09:38 DISPATCHER: trying to submit job (4, 0, 2)
17:09:38 DISPATCHER: trying to notify the job_runner thread.
17:09:38 HBMASTER: job (4, 0, 2) submitted to dispatcher
17:09:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:09:38 DISPATCHER: Trying to submit another job.
17:09:38 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:09:38 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:09:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:09:38 WORKER: start processing job (4, 0, 2)
17:09:38 WORKER: args: ()
17:09:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001064775404019217, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.029162414770016448, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 124, 'num_filters_4': 39, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:10:04 DISPATCHER: Starting worker discovery
17:10:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:04 DISPATCHER: Finished worker discovery
17:10:32 WORKER: done with job (4, 0, 2), trying to register it.
17:10:32 WORKER: registered result for job (4, 0, 2) with dispatcher
17:10:32 DISPATCHER: job (4, 0, 2) finished
17:10:32 DISPATCHER: register_result: lock acquired
17:10:32 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:10:32 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001064775404019217, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.029162414770016448, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 124, 'num_filters_4': 39, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8232588004366279, 'info': {'number_mnist': 0.8232588004366279, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001064775404019217, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.029162414770016448, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 124, 'num_filters_4': 39, 'num_filters_5': 16}"}}
exception: None

17:10:32 job_callback for (4, 0, 2) started
17:10:32 DISPATCHER: Trying to submit another job.
17:10:32 job_callback for (4, 0, 2) got condition
17:10:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:10:32 HBMASTER: Trying to run another job!
17:10:32 job_callback for (4, 0, 2) finished
17:10:32 start sampling a new configuration.
17:10:32 done sampling a new configuration.
17:10:32 HBMASTER: schedule new run for iteration 4
17:10:32 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
17:10:32 HBMASTER: submitting job (4, 0, 3) to dispatcher
17:10:32 DISPATCHER: trying to submit job (4, 0, 3)
17:10:32 DISPATCHER: trying to notify the job_runner thread.
17:10:32 HBMASTER: job (4, 0, 3) submitted to dispatcher
17:10:32 DISPATCHER: Trying to submit another job.
17:10:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:10:32 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:10:32 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:10:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:10:32 WORKER: start processing job (4, 0, 3)
17:10:32 WORKER: args: ()
17:10:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:11:04 DISPATCHER: Starting worker discovery
17:11:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:04 DISPATCHER: Finished worker discovery
17:11:26 WORKER: done with job (4, 0, 3), trying to register it.
17:11:26 WORKER: registered result for job (4, 0, 3) with dispatcher
17:11:26 DISPATCHER: job (4, 0, 3) finished
17:11:26 DISPATCHER: register_result: lock acquired
17:11:26 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:11:26 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9338821139810307, 'info': {'number_mnist': 0.9338821139810307, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

17:11:26 job_callback for (4, 0, 3) started
17:11:26 DISPATCHER: Trying to submit another job.
17:11:26 job_callback for (4, 0, 3) got condition
17:11:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:11:26 HBMASTER: Trying to run another job!
17:11:26 job_callback for (4, 0, 3) finished
17:11:26 start sampling a new configuration.
17:11:26 done sampling a new configuration.
17:11:26 HBMASTER: schedule new run for iteration 4
17:11:26 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
17:11:26 HBMASTER: submitting job (4, 0, 4) to dispatcher
17:11:26 DISPATCHER: trying to submit job (4, 0, 4)
17:11:26 DISPATCHER: trying to notify the job_runner thread.
17:11:26 HBMASTER: job (4, 0, 4) submitted to dispatcher
17:11:26 DISPATCHER: Trying to submit another job.
17:11:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:11:26 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:11:26 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:11:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:11:26 WORKER: start processing job (4, 0, 4)
17:11:26 WORKER: args: ()
17:11:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07137883610505093, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.013071350563764421, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 93, 'num_filters_3': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:12:04 DISPATCHER: Starting worker discovery
17:12:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:04 DISPATCHER: Finished worker discovery
17:12:20 WORKER: done with job (4, 0, 4), trying to register it.
17:12:20 WORKER: registered result for job (4, 0, 4) with dispatcher
17:12:20 DISPATCHER: job (4, 0, 4) finished
17:12:20 DISPATCHER: register_result: lock acquired
17:12:20 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:12:20 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07137883610505093, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.013071350563764421, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 93, 'num_filters_3': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07137883610505093, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.013071350563764421, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 93, 'num_filters_3': 67}"}}
exception: None

17:12:20 job_callback for (4, 0, 4) started
17:12:20 job_callback for (4, 0, 4) got condition
17:12:20 DISPATCHER: Trying to submit another job.
17:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:12:20 HBMASTER: Trying to run another job!
17:12:20 job_callback for (4, 0, 4) finished
17:12:20 start sampling a new configuration.
17:12:20 done sampling a new configuration.
17:12:20 HBMASTER: schedule new run for iteration 4
17:12:20 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
17:12:20 HBMASTER: submitting job (4, 0, 5) to dispatcher
17:12:20 DISPATCHER: trying to submit job (4, 0, 5)
17:12:20 DISPATCHER: trying to notify the job_runner thread.
17:12:20 HBMASTER: job (4, 0, 5) submitted to dispatcher
17:12:20 DISPATCHER: Trying to submit another job.
17:12:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:12:20 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:12:20 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:12:20 WORKER: start processing job (4, 0, 5)
17:12:20 WORKER: args: ()
17:12:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0019500402812139693, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.016373466016552655}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:13:04 DISPATCHER: Starting worker discovery
17:13:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:04 DISPATCHER: Finished worker discovery
17:13:14 WORKER: done with job (4, 0, 5), trying to register it.
17:13:14 WORKER: registered result for job (4, 0, 5) with dispatcher
17:13:14 DISPATCHER: job (4, 0, 5) finished
17:13:14 DISPATCHER: register_result: lock acquired
17:13:14 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:13:14 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0019500402812139693, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.016373466016552655}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.537782443128951, 'info': {'number_mnist': 0.537782443128951, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0019500402812139693, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.016373466016552655}"}}
exception: None

17:13:14 job_callback for (4, 0, 5) started
17:13:14 DISPATCHER: Trying to submit another job.
17:13:14 job_callback for (4, 0, 5) got condition
17:13:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:14 HBMASTER: Trying to run another job!
17:13:14 job_callback for (4, 0, 5) finished
17:13:14 start sampling a new configuration.
17:13:14 done sampling a new configuration.
17:13:14 HBMASTER: schedule new run for iteration 4
17:13:14 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
17:13:14 HBMASTER: submitting job (4, 0, 6) to dispatcher
17:13:14 DISPATCHER: trying to submit job (4, 0, 6)
17:13:14 DISPATCHER: trying to notify the job_runner thread.
17:13:14 HBMASTER: job (4, 0, 6) submitted to dispatcher
17:13:14 DISPATCHER: Trying to submit another job.
17:13:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:14 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:13:14 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:13:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:14 WORKER: start processing job (4, 0, 6)
17:13:14 WORKER: args: ()
17:13:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002085177601306467, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011637713858141717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 78, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:14:04 DISPATCHER: Starting worker discovery
17:14:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:04 DISPATCHER: Finished worker discovery
17:14:07 WORKER: done with job (4, 0, 6), trying to register it.
17:14:07 WORKER: registered result for job (4, 0, 6) with dispatcher
17:14:07 DISPATCHER: job (4, 0, 6) finished
17:14:07 DISPATCHER: register_result: lock acquired
17:14:07 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:14:07 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002085177601306467, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011637713858141717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 78, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8258596844782942, 'info': {'number_mnist': 0.8258596844782942, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002085177601306467, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011637713858141717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 78, 'num_filters_3': 19}"}}
exception: None

17:14:07 job_callback for (4, 0, 6) started
17:14:07 DISPATCHER: Trying to submit another job.
17:14:07 job_callback for (4, 0, 6) got condition
17:14:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:14:07 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.959364





17:14:07 HBMASTER: Trying to run another job!
17:14:07 job_callback for (4, 0, 6) finished
17:14:07 start sampling a new configuration.
17:14:07 done sampling a new configuration.
17:14:07 HBMASTER: schedule new run for iteration 4
17:14:07 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
17:14:07 HBMASTER: submitting job (4, 0, 7) to dispatcher
17:14:07 DISPATCHER: trying to submit job (4, 0, 7)
17:14:07 DISPATCHER: trying to notify the job_runner thread.
17:14:07 HBMASTER: job (4, 0, 7) submitted to dispatcher
17:14:07 DISPATCHER: Trying to submit another job.
17:14:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:14:07 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:14:07 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:14:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:14:08 WORKER: start processing job (4, 0, 7)
17:14:08 WORKER: args: ()
17:14:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07991560163950744, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.060418749365899735}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:15:03 WORKER: done with job (4, 0, 7), trying to register it.
17:15:03 WORKER: registered result for job (4, 0, 7) with dispatcher
17:15:03 DISPATCHER: job (4, 0, 7) finished
17:15:03 DISPATCHER: register_result: lock acquired
17:15:03 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:15:03 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07991560163950744, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.060418749365899735}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4939251480805976, 'info': {'number_mnist': 0.4939251480805976, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07991560163950744, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.060418749365899735}"}}
exception: None

17:15:03 job_callback for (4, 0, 7) started
17:15:03 job_callback for (4, 0, 7) got condition
17:15:03 DISPATCHER: Trying to submit another job.
17:15:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:03 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.959364





17:15:03 HBMASTER: Trying to run another job!
17:15:03 job_callback for (4, 0, 7) finished
17:15:03 start sampling a new configuration.
17:15:03 best_vector: [3, 1, 0.2242143248879812, 0.521555976317684, 0.7249276873867492, 1, 0.05729723200687708, 0.1639962698283732, 1, 0, 2, 2, 0.5464629638132505, 0.28614802199192874, 0.5245436283969317, 0.11545401741632932], 6.951985920909914e-05, 0.0192544897591797, 1.338569417201214e-06
17:15:03 done sampling a new configuration.
17:15:03 HBMASTER: schedule new run for iteration 4
17:15:03 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
17:15:03 HBMASTER: submitting job (4, 0, 8) to dispatcher
17:15:03 DISPATCHER: trying to submit job (4, 0, 8)
17:15:03 DISPATCHER: trying to notify the job_runner thread.
17:15:03 HBMASTER: job (4, 0, 8) submitted to dispatcher
17:15:03 DISPATCHER: Trying to submit another job.
17:15:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:03 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:15:03 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:15:03 WORKER: start processing job (4, 0, 8)
17:15:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:03 WORKER: args: ()
17:15:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0028082039751423887, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.0163442149862394, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 49, 'num_filters_3': 28, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:15:04 DISPATCHER: Starting worker discovery
17:15:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:04 DISPATCHER: Finished worker discovery
17:16:01 WORKER: done with job (4, 0, 8), trying to register it.
17:16:01 WORKER: registered result for job (4, 0, 8) with dispatcher
17:16:01 DISPATCHER: job (4, 0, 8) finished
17:16:01 DISPATCHER: register_result: lock acquired
17:16:01 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:16:01 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0028082039751423887, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.0163442149862394, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 49, 'num_filters_3': 28, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7468884969663597, 'info': {'number_mnist': 0.7468884969663597, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0028082039751423887, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.0163442149862394, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 49, 'num_filters_3': 28, 'num_filters_4': 47}"}}
exception: None

17:16:01 job_callback for (4, 0, 8) started
17:16:01 DISPATCHER: Trying to submit another job.
17:16:01 job_callback for (4, 0, 8) got condition
17:16:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:16:01 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.959364





17:16:01 HBMASTER: Trying to run another job!
17:16:01 job_callback for (4, 0, 8) finished
17:16:01 start sampling a new configuration.
17:16:01 best_vector: [2, 2, 0.07108430908166563, 0.6674311886455325, 0.3672909891966363, 1, 0.019362236764639884, 0.31401542171325164, 0, 1, 0, 0, 0.693752632292159, 0.9063674200619394, 0.2878236983149594, 0.029892045635769273], 3.065869913302158e-05, 0.023184087717397665, 7.10793970001276e-07
17:16:01 done sampling a new configuration.
17:16:01 HBMASTER: schedule new run for iteration 4
17:16:01 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
17:16:01 HBMASTER: submitting job (4, 0, 9) to dispatcher
17:16:01 DISPATCHER: trying to submit job (4, 0, 9)
17:16:01 DISPATCHER: trying to notify the job_runner thread.
17:16:01 HBMASTER: job (4, 0, 9) submitted to dispatcher
17:16:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:16:01 DISPATCHER: Trying to submit another job.
17:16:01 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:16:01 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:16:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:16:01 WORKER: start processing job (4, 0, 9)
17:16:01 WORKER: args: ()
17:16:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001387294351993989, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.02561789744635977, 'kernel_size_2': 3, 'num_filters_2': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:16:04 DISPATCHER: Starting worker discovery
17:16:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:04 DISPATCHER: Finished worker discovery
17:16:59 WORKER: done with job (4, 0, 9), trying to register it.
17:16:59 WORKER: registered result for job (4, 0, 9) with dispatcher
17:16:59 DISPATCHER: job (4, 0, 9) finished
17:16:59 DISPATCHER: register_result: lock acquired
17:16:59 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:16:59 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001387294351993989, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.02561789744635977, 'kernel_size_2': 3, 'num_filters_2': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6365237062540368, 'info': {'number_mnist': 0.6365237062540368, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001387294351993989, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.02561789744635977, 'kernel_size_2': 3, 'num_filters_2': 67}"}}
exception: None

17:16:59 job_callback for (4, 0, 9) started
17:16:59 DISPATCHER: Trying to submit another job.
17:16:59 job_callback for (4, 0, 9) got condition
17:16:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:16:59 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.959364





17:16:59 HBMASTER: Trying to run another job!
17:16:59 job_callback for (4, 0, 9) finished
17:16:59 start sampling a new configuration.
17:16:59 best_vector: [0, 0, 0.00833215991179298, 0.642941378113291, 0.7554200003470753, 0, 0.8424279600005333, 0.1616387253759825, 1, 1, 0, 2, 0.8283687155931712, 0.09086122621640381, 0.15154935754558058, 0.05030054001578337], 4.750934016019671e-05, 0.0009326347195098628, 4.430886013440372e-08
17:16:59 done sampling a new configuration.
17:16:59 HBMASTER: schedule new run for iteration 4
17:16:59 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:16:59 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:16:59 DISPATCHER: trying to submit job (4, 0, 10)
17:16:59 DISPATCHER: trying to notify the job_runner thread.
17:16:59 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:16:59 DISPATCHER: Trying to submit another job.
17:16:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:16:59 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:16:59 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:16:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:16:59 WORKER: start processing job (4, 0, 10)
17:16:59 WORKER: args: ()
17:16:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001039116688635112, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.016229189457238936, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 19, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:17:04 DISPATCHER: Starting worker discovery
17:17:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:04 DISPATCHER: Finished worker discovery
17:17:52 WORKER: done with job (4, 0, 10), trying to register it.
17:17:52 WORKER: registered result for job (4, 0, 10) with dispatcher
17:17:52 DISPATCHER: job (4, 0, 10) finished
17:17:52 DISPATCHER: register_result: lock acquired
17:17:52 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:17:52 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001039116688635112, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.016229189457238936, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 19, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8940584900686834, 'info': {'number_mnist': 0.8940584900686834, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001039116688635112, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.016229189457238936, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 19, 'num_filters_4': 21}"}}
exception: None

17:17:52 job_callback for (4, 0, 10) started
17:17:52 job_callback for (4, 0, 10) got condition
17:17:52 DISPATCHER: Trying to submit another job.
17:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:17:52 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.959364





17:17:52 HBMASTER: Trying to run another job!
17:17:52 job_callback for (4, 0, 10) finished
17:17:52 start sampling a new configuration.
17:17:53 best_vector: [2, 2, 0.1525752836999207, 0.7315062585438291, 0.25898596277939634, 1, 0.015972686091148325, 0.3597642920293287, 0, 0, 2, 1, 0.8045878042310355, 0.1647812199515195, 0.33727700269473126, 0.07947337341312385], 4.22819533991195e-05, 0.004162617540225177, 1.7600360085415837e-07
17:17:53 done sampling a new configuration.
17:17:53 HBMASTER: schedule new run for iteration 4
17:17:53 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
17:17:53 HBMASTER: submitting job (4, 0, 11) to dispatcher
17:17:53 DISPATCHER: trying to submit job (4, 0, 11)
17:17:53 DISPATCHER: trying to notify the job_runner thread.
17:17:53 HBMASTER: job (4, 0, 11) submitted to dispatcher
17:17:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:17:53 DISPATCHER: Trying to submit another job.
17:17:53 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:17:53 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:17:53 WORKER: start processing job (4, 0, 11)
17:17:53 WORKER: args: ()
17:17:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020190662410096943, 'num_filters_1': 73, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.029380835072347004, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:18:04 DISPATCHER: Starting worker discovery
17:18:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:04 DISPATCHER: Finished worker discovery
17:18:50 WORKER: done with job (4, 0, 11), trying to register it.
17:18:50 WORKER: registered result for job (4, 0, 11) with dispatcher
17:18:50 DISPATCHER: job (4, 0, 11) finished
17:18:50 DISPATCHER: register_result: lock acquired
17:18:50 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:18:50 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020190662410096943, 'num_filters_1': 73, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.029380835072347004, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7643060878390425, 'info': {'number_mnist': 0.7643060878390425, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020190662410096943, 'num_filters_1': 73, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.029380835072347004, 'kernel_size_2': 3, 'num_filters_2': 85}"}}
exception: None

17:18:50 job_callback for (4, 0, 11) started
17:18:50 job_callback for (4, 0, 11) got condition
17:18:50 DISPATCHER: Trying to submit another job.
17:18:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:18:50 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.959364





17:18:50 HBMASTER: Trying to run another job!
17:18:50 job_callback for (4, 0, 11) finished
17:18:50 start sampling a new configuration.
17:18:50 done sampling a new configuration.
17:18:50 HBMASTER: schedule new run for iteration 4
17:18:50 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
17:18:50 HBMASTER: submitting job (4, 0, 12) to dispatcher
17:18:50 DISPATCHER: trying to submit job (4, 0, 12)
17:18:50 DISPATCHER: trying to notify the job_runner thread.
17:18:50 HBMASTER: job (4, 0, 12) submitted to dispatcher
17:18:50 DISPATCHER: Trying to submit another job.
17:18:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:18:50 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:18:50 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:18:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:18:50 WORKER: start processing job (4, 0, 12)
17:18:50 WORKER: args: ()
17:18:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016383242299037976, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.05302249692663548, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:19:04 DISPATCHER: Starting worker discovery
17:19:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:04 DISPATCHER: Finished worker discovery
17:19:45 WORKER: done with job (4, 0, 12), trying to register it.
17:19:45 WORKER: registered result for job (4, 0, 12) with dispatcher
17:19:45 DISPATCHER: job (4, 0, 12) finished
17:19:45 DISPATCHER: register_result: lock acquired
17:19:45 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:19:45 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016383242299037976, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.05302249692663548, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7373744996484363, 'info': {'number_mnist': 0.7373744996484363, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016383242299037976, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.05302249692663548, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 68}"}}
exception: None

17:19:45 job_callback for (4, 0, 12) started
17:19:45 job_callback for (4, 0, 12) got condition
17:19:45 DISPATCHER: Trying to submit another job.
17:19:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:19:45 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.959364





17:19:45 HBMASTER: Trying to run another job!
17:19:45 job_callback for (4, 0, 12) finished
17:19:45 start sampling a new configuration.
17:19:45 best_vector: [2, 0, 0.20422962409378057, 0.825598842342015, 0.8952941805117419, 0, 0.34353814138362226, 0.283696571688514, 0, 0, 0, 1, 0.2704263970175636, 0.9290764108698045, 0.1436026766769311, 0.08289172175257621], 0.0004163741585587341, 0.00043368031134000915, 1.8057327471768612e-07
17:19:45 done sampling a new configuration.
17:19:45 HBMASTER: schedule new run for iteration 4
17:19:45 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
17:19:45 HBMASTER: submitting job (4, 0, 13) to dispatcher
17:19:45 DISPATCHER: trying to submit job (4, 0, 13)
17:19:45 DISPATCHER: trying to notify the job_runner thread.
17:19:45 HBMASTER: job (4, 0, 13) submitted to dispatcher
17:19:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:19:45 DISPATCHER: Trying to submit another job.
17:19:45 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:19:45 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:19:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:19:45 WORKER: start processing job (4, 0, 13)
17:19:45 WORKER: args: ()
17:19:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002561292915131009, 'num_filters_1': 89, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.023393637149461986, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 111, 'num_filters_4': 21, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:20:04 DISPATCHER: Starting worker discovery
17:20:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:04 DISPATCHER: Finished worker discovery
17:20:38 WORKER: done with job (4, 0, 13), trying to register it.
17:20:38 WORKER: registered result for job (4, 0, 13) with dispatcher
17:20:38 DISPATCHER: job (4, 0, 13) finished
17:20:38 DISPATCHER: register_result: lock acquired
17:20:38 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:20:39 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002561292915131009, 'num_filters_1': 89, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.023393637149461986, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 111, 'num_filters_4': 21, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.784658289318478, 'info': {'number_mnist': 0.784658289318478, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002561292915131009, 'num_filters_1': 89, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.023393637149461986, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 111, 'num_filters_4': 21, 'num_filters_5': 18}"}}
exception: None

17:20:39 job_callback for (4, 0, 13) started
17:20:39 job_callback for (4, 0, 13) got condition
17:20:39 DISPATCHER: Trying to submit another job.
17:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:39 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.959364





17:20:39 HBMASTER: Trying to run another job!
17:20:39 job_callback for (4, 0, 13) finished
17:20:39 start sampling a new configuration.
17:20:39 best_vector: [2, 0, 0.22325579221683356, 0.862142095214607, 0.22052334898991804, 1, 0.7431941470593951, 0.015577375280727127, 1, 0, 2, 0, 0.2687020336454461, 0.8471689178858643, 0.5200984623382383, 0.23307719374354807], 0.0005588681108999304, 0.0025735976291281996, 1.4383016452074168e-06
17:20:39 done sampling a new configuration.
17:20:39 HBMASTER: schedule new run for iteration 4
17:20:39 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
17:20:39 HBMASTER: submitting job (4, 0, 14) to dispatcher
17:20:39 DISPATCHER: trying to submit job (4, 0, 14)
17:20:39 DISPATCHER: trying to notify the job_runner thread.
17:20:39 HBMASTER: job (4, 0, 14) submitted to dispatcher
17:20:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:39 DISPATCHER: Trying to submit another job.
17:20:39 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:20:39 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:39 WORKER: start processing job (4, 0, 14)
17:20:39 WORKER: args: ()
17:20:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002795835303100447, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010477716237323662, 'kernel_size_2': 5, 'num_filters_2': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:21:04 DISPATCHER: Starting worker discovery
17:21:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:04 DISPATCHER: Finished worker discovery
17:21:33 WORKER: done with job (4, 0, 14), trying to register it.
17:21:33 WORKER: registered result for job (4, 0, 14) with dispatcher
17:21:33 DISPATCHER: job (4, 0, 14) finished
17:21:33 DISPATCHER: register_result: lock acquired
17:21:33 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:21:33 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002795835303100447, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010477716237323662, 'kernel_size_2': 5, 'num_filters_2': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8507334496150406, 'info': {'number_mnist': 0.8507334496150406, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002795835303100447, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010477716237323662, 'kernel_size_2': 5, 'num_filters_2': 27}"}}
exception: None

17:21:33 job_callback for (4, 0, 14) started
17:21:33 job_callback for (4, 0, 14) got condition
17:21:33 DISPATCHER: Trying to submit another job.
17:21:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:21:33 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.959364





17:21:33 HBMASTER: Trying to run another job!
17:21:33 job_callback for (4, 0, 14) finished
17:21:33 start sampling a new configuration.
17:21:33 done sampling a new configuration.
17:21:33 HBMASTER: schedule new run for iteration 4
17:21:33 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
17:21:33 HBMASTER: submitting job (4, 0, 15) to dispatcher
17:21:33 DISPATCHER: trying to submit job (4, 0, 15)
17:21:33 DISPATCHER: trying to notify the job_runner thread.
17:21:33 HBMASTER: job (4, 0, 15) submitted to dispatcher
17:21:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:21:33 DISPATCHER: Trying to submit another job.
17:21:33 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:21:33 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:21:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:21:33 WORKER: start processing job (4, 0, 15)
17:21:33 WORKER: args: ()
17:21:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.018401860338302625, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.0818307143504094, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:22:04 DISPATCHER: Starting worker discovery
17:22:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:04 DISPATCHER: Finished worker discovery
17:22:26 WORKER: done with job (4, 0, 15), trying to register it.
17:22:26 WORKER: registered result for job (4, 0, 15) with dispatcher
17:22:26 DISPATCHER: job (4, 0, 15) finished
17:22:26 DISPATCHER: register_result: lock acquired
17:22:26 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:22:26 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.018401860338302625, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.0818307143504094, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.057421698101095986, 'info': {'number_mnist': 0.057421698101095986, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.018401860338302625, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.0818307143504094, 'kernel_size_2': 3, 'num_filters_2': 107}"}}
exception: None

17:22:26 job_callback for (4, 0, 15) started
17:22:26 job_callback for (4, 0, 15) got condition
17:22:26 DISPATCHER: Trying to submit another job.
17:22:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:22:26 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.959364





17:22:26 HBMASTER: Trying to run another job!
17:22:26 job_callback for (4, 0, 15) finished
17:22:26 start sampling a new configuration.
17:22:26 best_vector: [3, 1, 0.3831624070251305, 0.8933976620750147, 0.014687553368507245, 1, 0.3239357584277012, 0.005647949844896638, 1, 2, 1, 0, 0.8155713920757299, 0.3746466512408631, 0.439973729983587, 0.15081338818404327], 0.0021161486264587187, 0.008080659315528115, 1.7099876111435668e-05
17:22:26 done sampling a new configuration.
17:22:26 HBMASTER: schedule new run for iteration 4
17:22:26 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
17:22:26 HBMASTER: submitting job (4, 0, 16) to dispatcher
17:22:26 DISPATCHER: trying to submit job (4, 0, 16)
17:22:26 DISPATCHER: trying to notify the job_runner thread.
17:22:26 HBMASTER: job (4, 0, 16) submitted to dispatcher
17:22:26 DISPATCHER: Trying to submit another job.
17:22:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:22:26 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:22:26 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:22:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:22:26 WORKER: start processing job (4, 0, 16)
17:22:26 WORKER: args: ()
17:22:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005838816330850292, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.010170636952434755}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:23:04 DISPATCHER: Starting worker discovery
17:23:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:04 DISPATCHER: Finished worker discovery
17:23:22 WORKER: done with job (4, 0, 16), trying to register it.
17:23:22 WORKER: registered result for job (4, 0, 16) with dispatcher
17:23:22 DISPATCHER: job (4, 0, 16) finished
17:23:22 DISPATCHER: register_result: lock acquired
17:23:22 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:23:22 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005838816330850292, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.010170636952434755}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9080608096737156, 'info': {'number_mnist': 0.9080608096737156, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005838816330850292, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.010170636952434755}"}}
exception: None

17:23:22 job_callback for (4, 0, 16) started
17:23:22 job_callback for (4, 0, 16) got condition
17:23:22 DISPATCHER: Trying to submit another job.
17:23:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:23:22 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.959364





17:23:22 HBMASTER: Trying to run another job!
17:23:22 job_callback for (4, 0, 16) finished
17:23:22 start sampling a new configuration.
17:23:22 done sampling a new configuration.
17:23:22 HBMASTER: schedule new run for iteration 4
17:23:22 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
17:23:22 HBMASTER: submitting job (4, 0, 17) to dispatcher
17:23:22 DISPATCHER: trying to submit job (4, 0, 17)
17:23:22 DISPATCHER: trying to notify the job_runner thread.
17:23:22 HBMASTER: job (4, 0, 17) submitted to dispatcher
17:23:22 DISPATCHER: Trying to submit another job.
17:23:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:23:22 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:23:22 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:23:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:23:22 WORKER: start processing job (4, 0, 17)
17:23:22 WORKER: args: ()
17:23:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.030567685324209667, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05518545282745106, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:24:04 DISPATCHER: Starting worker discovery
17:24:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:04 DISPATCHER: Finished worker discovery
17:24:16 WORKER: done with job (4, 0, 17), trying to register it.
17:24:16 WORKER: registered result for job (4, 0, 17) with dispatcher
17:24:16 DISPATCHER: job (4, 0, 17) finished
17:24:16 DISPATCHER: register_result: lock acquired
17:24:16 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:24:16 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.030567685324209667, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05518545282745106, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5156250751939151, 'info': {'number_mnist': 0.5156250751939151, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.030567685324209667, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05518545282745106, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 88}"}}
exception: None

17:24:16 job_callback for (4, 0, 17) started
17:24:16 DISPATCHER: Trying to submit another job.
17:24:16 job_callback for (4, 0, 17) got condition
17:24:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:24:16 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.959364





17:24:16 HBMASTER: Trying to run another job!
17:24:16 job_callback for (4, 0, 17) finished
17:24:16 start sampling a new configuration.
17:24:16 done sampling a new configuration.
17:24:16 HBMASTER: schedule new run for iteration 4
17:24:16 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:24:16 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:24:16 DISPATCHER: trying to submit job (4, 0, 18)
17:24:16 DISPATCHER: trying to notify the job_runner thread.
17:24:16 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:24:16 DISPATCHER: Trying to submit another job.
17:24:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:24:16 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:24:16 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:24:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:24:16 WORKER: start processing job (4, 0, 18)
17:24:16 WORKER: args: ()
17:24:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.015212868850710843, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.08824081964692279, 'kernel_size_2': 3, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:25:04 DISPATCHER: Starting worker discovery
17:25:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:04 DISPATCHER: Finished worker discovery
17:25:09 WORKER: done with job (4, 0, 18), trying to register it.
17:25:09 WORKER: registered result for job (4, 0, 18) with dispatcher
17:25:09 DISPATCHER: job (4, 0, 18) finished
17:25:09 DISPATCHER: register_result: lock acquired
17:25:09 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:25:09 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.015212868850710843, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.08824081964692279, 'kernel_size_2': 3, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7392539924465028, 'info': {'number_mnist': 0.7392539924465028, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.015212868850710843, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.08824081964692279, 'kernel_size_2': 3, 'num_filters_2': 80}"}}
exception: None

17:25:09 job_callback for (4, 0, 18) started
17:25:09 DISPATCHER: Trying to submit another job.
17:25:09 job_callback for (4, 0, 18) got condition
17:25:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:25:09 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.959364





17:25:09 HBMASTER: Trying to run another job!
17:25:09 job_callback for (4, 0, 18) finished
17:25:09 start sampling a new configuration.
17:25:09 done sampling a new configuration.
17:25:09 HBMASTER: schedule new run for iteration 4
17:25:09 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
17:25:09 HBMASTER: submitting job (4, 0, 19) to dispatcher
17:25:09 DISPATCHER: trying to submit job (4, 0, 19)
17:25:09 DISPATCHER: trying to notify the job_runner thread.
17:25:09 HBMASTER: job (4, 0, 19) submitted to dispatcher
17:25:09 DISPATCHER: Trying to submit another job.
17:25:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:25:09 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:25:09 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:25:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:25:09 WORKER: start processing job (4, 0, 19)
17:25:09 WORKER: args: ()
17:25:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.022827524547831435, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.058627918781951706, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:26:02 WORKER: done with job (4, 0, 19), trying to register it.
17:26:02 WORKER: registered result for job (4, 0, 19) with dispatcher
17:26:02 DISPATCHER: job (4, 0, 19) finished
17:26:02 DISPATCHER: register_result: lock acquired
17:26:02 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:26:02 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.022827524547831435, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.058627918781951706, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7048598526473266, 'info': {'number_mnist': 0.7048598526473266, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.022827524547831435, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.058627918781951706, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 28}"}}
exception: None

17:26:02 job_callback for (4, 0, 19) started
17:26:02 DISPATCHER: Trying to submit another job.
17:26:02 job_callback for (4, 0, 19) got condition
17:26:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:26:02 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.959364





17:26:02 HBMASTER: Trying to run another job!
17:26:02 job_callback for (4, 0, 19) finished
17:26:02 start sampling a new configuration.
17:26:03 best_vector: [1, 2, 0.4509574400434134, 0.5005687608594084, 0.2364612061067048, 1, 0.4885033844343895, 0.05893678690506987, 1, 1, 0, 1, 0.6509811580674855, 0.20857799003961536, 0.5343555825218511, 0.24380825229778472], 1.4494214846135083e-05, 3.5200462349836688, 5.102030639818219e-05
17:26:03 done sampling a new configuration.
17:26:03 HBMASTER: schedule new run for iteration 4
17:26:03 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
17:26:03 HBMASTER: submitting job (4, 0, 20) to dispatcher
17:26:03 DISPATCHER: trying to submit job (4, 0, 20)
17:26:03 DISPATCHER: trying to notify the job_runner thread.
17:26:03 HBMASTER: job (4, 0, 20) submitted to dispatcher
17:26:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:26:03 DISPATCHER: Trying to submit another job.
17:26:03 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:26:03 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:26:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:26:03 WORKER: start processing job (4, 0, 20)
17:26:03 WORKER: args: ()
17:26:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:26:04 DISPATCHER: Starting worker discovery
17:26:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:04 DISPATCHER: Finished worker discovery
17:26:57 WORKER: done with job (4, 0, 20), trying to register it.
17:26:57 WORKER: registered result for job (4, 0, 20) with dispatcher
17:26:57 DISPATCHER: job (4, 0, 20) finished
17:26:57 DISPATCHER: register_result: lock acquired
17:26:57 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:26:57 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9193303713354385, 'info': {'number_mnist': 0.9193303713354385, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}"}}
exception: None

17:26:57 job_callback for (4, 0, 20) started
17:26:57 job_callback for (4, 0, 20) got condition
17:26:57 DISPATCHER: Trying to submit another job.
17:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:26:57 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.959364





17:26:57 HBMASTER: Trying to run another job!
17:26:57 job_callback for (4, 0, 20) finished
17:26:57 start sampling a new configuration.
17:26:57 done sampling a new configuration.
17:26:57 HBMASTER: schedule new run for iteration 4
17:26:57 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
17:26:57 HBMASTER: submitting job (4, 0, 21) to dispatcher
17:26:57 DISPATCHER: trying to submit job (4, 0, 21)
17:26:57 DISPATCHER: trying to notify the job_runner thread.
17:26:57 HBMASTER: job (4, 0, 21) submitted to dispatcher
17:26:57 DISPATCHER: Trying to submit another job.
17:26:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:26:57 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:26:57 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:26:57 WORKER: start processing job (4, 0, 21)
17:26:57 WORKER: args: ()
17:26:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013325619782472676, 'num_filters_1': 116, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.16917329987435134, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 78, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:27:04 DISPATCHER: Starting worker discovery
17:27:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:04 DISPATCHER: Finished worker discovery
17:27:51 WORKER: done with job (4, 0, 21), trying to register it.
17:27:51 WORKER: registered result for job (4, 0, 21) with dispatcher
17:27:51 DISPATCHER: job (4, 0, 21) finished
17:27:51 DISPATCHER: register_result: lock acquired
17:27:51 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:27:51 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013325619782472676, 'num_filters_1': 116, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.16917329987435134, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 78, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5461953120433043, 'info': {'number_mnist': 0.5461953120433043, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013325619782472676, 'num_filters_1': 116, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.16917329987435134, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 78, 'num_filters_3': 109}"}}
exception: None

17:27:51 job_callback for (4, 0, 21) started
17:27:51 job_callback for (4, 0, 21) got condition
17:27:51 DISPATCHER: Trying to submit another job.
17:27:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:27:51 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.959364





17:27:51 HBMASTER: Trying to run another job!
17:27:51 job_callback for (4, 0, 21) finished
17:27:51 start sampling a new configuration.
17:27:51 best_vector: [1, 2, 0.2512124223231579, 0.8806320588194915, 0.07807686493882737, 1, 0.8683008647150107, 0.2915700009705801, 0, 2, 2, 1, 0.39686970815720357, 0.43755004629209526, 0.39068351730962286, 0.2454107599863123], 8.608213335753126e-07, 27.15200092994494, 2.337302164975333e-05
17:27:51 done sampling a new configuration.
17:27:51 HBMASTER: schedule new run for iteration 4
17:27:51 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
17:27:51 HBMASTER: submitting job (4, 0, 22) to dispatcher
17:27:51 DISPATCHER: trying to submit job (4, 0, 22)
17:27:51 DISPATCHER: trying to notify the job_runner thread.
17:27:51 HBMASTER: job (4, 0, 22) submitted to dispatcher
17:27:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:27:51 DISPATCHER: Trying to submit another job.
17:27:51 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:27:51 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:27:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:27:51 WORKER: start processing job (4, 0, 22)
17:27:51 WORKER: args: ()
17:27:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031799833395160237, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.023951974304895218}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:28:04 DISPATCHER: Starting worker discovery
17:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:04 DISPATCHER: Finished worker discovery
17:28:46 WORKER: done with job (4, 0, 22), trying to register it.
17:28:46 WORKER: registered result for job (4, 0, 22) with dispatcher
17:28:46 DISPATCHER: job (4, 0, 22) finished
17:28:46 DISPATCHER: register_result: lock acquired
17:28:46 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:28:46 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031799833395160237, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.023951974304895218}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.826888777298137, 'info': {'number_mnist': 0.826888777298137, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031799833395160237, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.023951974304895218}"}}
exception: None

17:28:46 job_callback for (4, 0, 22) started
17:28:46 job_callback for (4, 0, 22) got condition
17:28:46 DISPATCHER: Trying to submit another job.
17:28:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:28:46 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.959364





17:28:46 HBMASTER: Trying to run another job!
17:28:46 job_callback for (4, 0, 22) finished
17:28:46 start sampling a new configuration.
17:28:46 best_vector: [2, 2, 0.11890305209473773, 0.892203157584172, 0.10527001159213363, 1, 0.743671835663767, 0.18185565962697067, 0, 2, 1, 1, 0.8945779181546372, 0.5548177481605991, 0.580817700356178, 0.2455191148169246], 3.3623114667063855e-06, 3.8029365183192985, 1.2786657062701436e-05
17:28:46 done sampling a new configuration.
17:28:46 HBMASTER: schedule new run for iteration 4
17:28:46 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:28:46 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:28:46 DISPATCHER: trying to submit job (4, 0, 23)
17:28:46 DISPATCHER: trying to notify the job_runner thread.
17:28:46 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:28:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:28:46 DISPATCHER: Trying to submit another job.
17:28:46 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:28:46 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:28:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:28:46 WORKER: start processing job (4, 0, 23)
17:28:46 WORKER: args: ()
17:28:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017290442350053632, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01724247750447846}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:29:04 DISPATCHER: Starting worker discovery
17:29:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:04 DISPATCHER: Finished worker discovery
17:29:39 WORKER: done with job (4, 0, 23), trying to register it.
17:29:39 WORKER: registered result for job (4, 0, 23) with dispatcher
17:29:39 DISPATCHER: job (4, 0, 23) finished
17:29:39 DISPATCHER: register_result: lock acquired
17:29:39 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:29:39 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017290442350053632, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01724247750447846}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7876972993198134, 'info': {'number_mnist': 0.7876972993198134, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017290442350053632, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01724247750447846}"}}
exception: None

17:29:39 job_callback for (4, 0, 23) started
17:29:39 job_callback for (4, 0, 23) got condition
17:29:39 DISPATCHER: Trying to submit another job.
17:29:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:29:39 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.959364





17:29:39 HBMASTER: Trying to run another job!
17:29:39 job_callback for (4, 0, 23) finished
17:29:39 start sampling a new configuration.
17:29:39 done sampling a new configuration.
17:29:39 HBMASTER: schedule new run for iteration 4
17:29:39 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:29:39 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:29:39 DISPATCHER: trying to submit job (4, 0, 24)
17:29:39 DISPATCHER: trying to notify the job_runner thread.
17:29:39 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:29:39 DISPATCHER: Trying to submit another job.
17:29:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:29:39 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:29:39 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:29:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:29:39 WORKER: start processing job (4, 0, 24)
17:29:39 WORKER: args: ()
17:29:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.028080015800713624, 'num_filters_1': 68, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.09754649408572535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 96, 'num_filters_3': 25, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:30:04 DISPATCHER: Starting worker discovery
17:30:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:04 DISPATCHER: Finished worker discovery
17:30:33 WORKER: done with job (4, 0, 24), trying to register it.
17:30:33 WORKER: registered result for job (4, 0, 24) with dispatcher
17:30:33 DISPATCHER: job (4, 0, 24) finished
17:30:33 DISPATCHER: register_result: lock acquired
17:30:33 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:30:33 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.028080015800713624, 'num_filters_1': 68, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.09754649408572535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 96, 'num_filters_3': 25, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.028080015800713624, 'num_filters_1': 68, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.09754649408572535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 96, 'num_filters_3': 25, 'num_filters_4': 27}"}}
exception: None

17:30:33 job_callback for (4, 0, 24) started
17:30:33 DISPATCHER: Trying to submit another job.
17:30:33 job_callback for (4, 0, 24) got condition
17:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:30:33 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.959364





17:30:33 HBMASTER: Trying to run another job!
17:30:33 job_callback for (4, 0, 24) finished
17:30:33 start sampling a new configuration.
17:30:33 best_vector: [2, 0, 0.228100669985683, 0.6724094638475129, 0.41047766390869755, 1, 0.7853192438119432, 0.012249880843807653, 1, 1, 1, 1, 0.2008777988785308, 0.6990155260826316, 0.16419774340617996, 0.24392750964886473], 9.090310026412077e-07, 12.154536388589428, 1.104885039995849e-05
17:30:33 done sampling a new configuration.
17:30:33 HBMASTER: schedule new run for iteration 4
17:30:33 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:30:33 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:30:33 DISPATCHER: trying to submit job (4, 0, 25)
17:30:33 DISPATCHER: trying to notify the job_runner thread.
17:30:33 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:30:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:30:33 DISPATCHER: Trying to submit another job.
17:30:33 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:30:33 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:30:33 WORKER: start processing job (4, 0, 25)
17:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:30:33 WORKER: args: ()
17:30:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:31:04 DISPATCHER: Starting worker discovery
17:31:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:04 DISPATCHER: Finished worker discovery
17:31:27 WORKER: done with job (4, 0, 25), trying to register it.
17:31:27 WORKER: registered result for job (4, 0, 25) with dispatcher
17:31:27 DISPATCHER: job (4, 0, 25) finished
17:31:27 DISPATCHER: register_result: lock acquired
17:31:27 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:31:27 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.922884696589568, 'info': {'number_mnist': 0.922884696589568, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}"}}
exception: None

17:31:27 job_callback for (4, 0, 25) started
17:31:27 DISPATCHER: Trying to submit another job.
17:31:27 job_callback for (4, 0, 25) got condition
17:31:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:31:27 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.959364





17:31:27 HBMASTER: Trying to run another job!
17:31:27 job_callback for (4, 0, 25) finished
17:31:27 start sampling a new configuration.
17:31:27 done sampling a new configuration.
17:31:27 HBMASTER: schedule new run for iteration 4
17:31:27 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
17:31:27 HBMASTER: submitting job (4, 0, 26) to dispatcher
17:31:27 DISPATCHER: trying to submit job (4, 0, 26)
17:31:27 DISPATCHER: trying to notify the job_runner thread.
17:31:27 HBMASTER: job (4, 0, 26) submitted to dispatcher
17:31:27 DISPATCHER: Trying to submit another job.
17:31:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:31:27 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:31:27 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:31:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:31:27 WORKER: start processing job (4, 0, 26)
17:31:27 WORKER: args: ()
17:31:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0012424754735925168, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.14994526933742464}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:32:04 DISPATCHER: Starting worker discovery
17:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:04 DISPATCHER: Finished worker discovery
17:32:21 WORKER: done with job (4, 0, 26), trying to register it.
17:32:21 WORKER: registered result for job (4, 0, 26) with dispatcher
17:32:21 DISPATCHER: job (4, 0, 26) finished
17:32:21 DISPATCHER: register_result: lock acquired
17:32:21 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:32:21 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0012424754735925168, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.14994526933742464}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6922411372948242, 'info': {'number_mnist': 0.6922411372948242, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0012424754735925168, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.14994526933742464}"}}
exception: None

17:32:21 job_callback for (4, 0, 26) started
17:32:21 job_callback for (4, 0, 26) got condition
17:32:21 DISPATCHER: Trying to submit another job.
17:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:21 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.959364





17:32:21 HBMASTER: Trying to run another job!
17:32:21 job_callback for (4, 0, 26) finished
17:32:21 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
17:32:21 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
17:32:21 HBMASTER: schedule new run for iteration 4
17:32:21 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
17:32:21 HBMASTER: submitting job (4, 0, 0) to dispatcher
17:32:21 DISPATCHER: trying to submit job (4, 0, 0)
17:32:21 DISPATCHER: trying to notify the job_runner thread.
17:32:21 HBMASTER: job (4, 0, 0) submitted to dispatcher
17:32:21 DISPATCHER: Trying to submit another job.
17:32:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:21 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:32:21 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:21 WORKER: start processing job (4, 0, 0)
17:32:21 WORKER: args: ()
17:32:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004454173996353296, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011668441061159752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 75, 'num_filters_3': 23, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:33:04 DISPATCHER: Starting worker discovery
17:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:04 DISPATCHER: Finished worker discovery
17:34:04 DISPATCHER: Starting worker discovery
17:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:04 DISPATCHER: Finished worker discovery
17:34:53 WORKER: done with job (4, 0, 0), trying to register it.
17:34:53 WORKER: registered result for job (4, 0, 0) with dispatcher
17:34:53 DISPATCHER: job (4, 0, 0) finished
17:34:53 DISPATCHER: register_result: lock acquired
17:34:53 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:34:53 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004454173996353296, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011668441061159752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 75, 'num_filters_3': 23, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9320088550808785, 'info': {'number_mnist': 0.9320088550808785, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004454173996353296, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011668441061159752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 75, 'num_filters_3': 23, 'num_filters_4': 47}"}}
exception: None

17:34:53 job_callback for (4, 0, 0) started
17:34:53 job_callback for (4, 0, 0) got condition
17:34:53 DISPATCHER: Trying to submit another job.
17:34:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:34:53 HBMASTER: Trying to run another job!
17:34:53 job_callback for (4, 0, 0) finished
17:34:53 HBMASTER: schedule new run for iteration 4
17:34:53 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
17:34:53 HBMASTER: submitting job (4, 0, 3) to dispatcher
17:34:53 DISPATCHER: trying to submit job (4, 0, 3)
17:34:53 DISPATCHER: trying to notify the job_runner thread.
17:34:53 HBMASTER: job (4, 0, 3) submitted to dispatcher
17:34:53 DISPATCHER: Trying to submit another job.
17:34:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:34:53 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:34:53 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:34:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:34:53 WORKER: start processing job (4, 0, 3)
17:34:53 WORKER: args: ()
17:34:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:35:04 DISPATCHER: Starting worker discovery
17:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:04 DISPATCHER: Finished worker discovery
17:36:04 DISPATCHER: Starting worker discovery
17:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:04 DISPATCHER: Finished worker discovery
17:37:04 DISPATCHER: Starting worker discovery
17:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:04 DISPATCHER: Finished worker discovery
17:37:17 WORKER: done with job (4, 0, 3), trying to register it.
17:37:17 WORKER: registered result for job (4, 0, 3) with dispatcher
17:37:17 DISPATCHER: job (4, 0, 3) finished
17:37:17 DISPATCHER: register_result: lock acquired
17:37:17 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:37:17 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9502777411426054, 'info': {'number_mnist': 0.9502777411426054, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

17:37:17 job_callback for (4, 0, 3) started
17:37:17 DISPATCHER: Trying to submit another job.
17:37:17 job_callback for (4, 0, 3) got condition
17:37:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:37:17 HBMASTER: Trying to run another job!
17:37:17 job_callback for (4, 0, 3) finished
17:37:17 HBMASTER: schedule new run for iteration 4
17:37:17 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
17:37:17 HBMASTER: submitting job (4, 0, 6) to dispatcher
17:37:17 DISPATCHER: trying to submit job (4, 0, 6)
17:37:17 DISPATCHER: trying to notify the job_runner thread.
17:37:17 HBMASTER: job (4, 0, 6) submitted to dispatcher
17:37:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:37:17 DISPATCHER: Trying to submit another job.
17:37:17 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:37:17 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:37:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:37:17 WORKER: start processing job (4, 0, 6)
17:37:17 WORKER: args: ()
17:37:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002085177601306467, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011637713858141717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 78, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:38:04 DISPATCHER: Starting worker discovery
17:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:04 DISPATCHER: Finished worker discovery
17:39:04 DISPATCHER: Starting worker discovery
17:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:04 DISPATCHER: Finished worker discovery
17:39:42 WORKER: done with job (4, 0, 6), trying to register it.
17:39:42 WORKER: registered result for job (4, 0, 6) with dispatcher
17:39:42 DISPATCHER: job (4, 0, 6) finished
17:39:42 DISPATCHER: register_result: lock acquired
17:39:42 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:39:42 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002085177601306467, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011637713858141717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 78, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9161022094052581, 'info': {'number_mnist': 0.9161022094052581, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002085177601306467, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011637713858141717, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 78, 'num_filters_3': 19}"}}
exception: None

17:39:42 job_callback for (4, 0, 6) started
17:39:42 DISPATCHER: Trying to submit another job.
17:39:42 job_callback for (4, 0, 6) got condition
17:39:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:39:42 HBMASTER: Trying to run another job!
17:39:42 job_callback for (4, 0, 6) finished
17:39:42 HBMASTER: schedule new run for iteration 4
17:39:42 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:39:42 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:39:42 DISPATCHER: trying to submit job (4, 0, 10)
17:39:42 DISPATCHER: trying to notify the job_runner thread.
17:39:42 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:39:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:39:42 DISPATCHER: Trying to submit another job.
17:39:42 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:39:42 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:39:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:39:42 WORKER: start processing job (4, 0, 10)
17:39:42 WORKER: args: ()
17:39:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001039116688635112, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.016229189457238936, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 19, 'num_filters_4': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:40:04 DISPATCHER: Starting worker discovery
17:40:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:04 DISPATCHER: Finished worker discovery
17:41:04 DISPATCHER: Starting worker discovery
17:41:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:04 DISPATCHER: Finished worker discovery
17:42:04 DISPATCHER: Starting worker discovery
17:42:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:04 DISPATCHER: Finished worker discovery
17:42:06 WORKER: done with job (4, 0, 10), trying to register it.
17:42:06 WORKER: registered result for job (4, 0, 10) with dispatcher
17:42:06 DISPATCHER: job (4, 0, 10) finished
17:42:06 DISPATCHER: register_result: lock acquired
17:42:06 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:42:06 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001039116688635112, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.016229189457238936, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 19, 'num_filters_4': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9066063120565292, 'info': {'number_mnist': 0.9066063120565292, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001039116688635112, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.016229189457238936, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 19, 'num_filters_4': 21}"}}
exception: None

17:42:06 job_callback for (4, 0, 10) started
17:42:06 job_callback for (4, 0, 10) got condition
17:42:06 DISPATCHER: Trying to submit another job.
17:42:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:42:06 HBMASTER: Trying to run another job!
17:42:06 job_callback for (4, 0, 10) finished
17:42:06 HBMASTER: schedule new run for iteration 4
17:42:06 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
17:42:06 HBMASTER: submitting job (4, 0, 14) to dispatcher
17:42:06 DISPATCHER: trying to submit job (4, 0, 14)
17:42:06 DISPATCHER: trying to notify the job_runner thread.
17:42:06 HBMASTER: job (4, 0, 14) submitted to dispatcher
17:42:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:42:06 DISPATCHER: Trying to submit another job.
17:42:06 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:42:06 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:42:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:42:06 WORKER: start processing job (4, 0, 14)
17:42:06 WORKER: args: ()
17:42:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002795835303100447, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010477716237323662, 'kernel_size_2': 5, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:43:04 DISPATCHER: Starting worker discovery
17:43:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:04 DISPATCHER: Finished worker discovery
17:44:04 DISPATCHER: Starting worker discovery
17:44:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:04 DISPATCHER: Finished worker discovery
17:44:30 WORKER: done with job (4, 0, 14), trying to register it.
17:44:30 WORKER: registered result for job (4, 0, 14) with dispatcher
17:44:30 DISPATCHER: job (4, 0, 14) finished
17:44:30 DISPATCHER: register_result: lock acquired
17:44:30 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:44:30 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002795835303100447, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010477716237323662, 'kernel_size_2': 5, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9002833555537963, 'info': {'number_mnist': 0.9002833555537963, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002795835303100447, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010477716237323662, 'kernel_size_2': 5, 'num_filters_2': 27}"}}
exception: None

17:44:30 job_callback for (4, 0, 14) started
17:44:30 DISPATCHER: Trying to submit another job.
17:44:30 job_callback for (4, 0, 14) got condition
17:44:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:44:30 HBMASTER: Trying to run another job!
17:44:30 job_callback for (4, 0, 14) finished
17:44:30 HBMASTER: schedule new run for iteration 4
17:44:30 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
17:44:30 HBMASTER: submitting job (4, 0, 16) to dispatcher
17:44:30 DISPATCHER: trying to submit job (4, 0, 16)
17:44:30 DISPATCHER: trying to notify the job_runner thread.
17:44:30 HBMASTER: job (4, 0, 16) submitted to dispatcher
17:44:30 DISPATCHER: Trying to submit another job.
17:44:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:44:30 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:44:30 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:44:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:44:30 WORKER: start processing job (4, 0, 16)
17:44:30 WORKER: args: ()
17:44:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005838816330850292, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.010170636952434755}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:45:04 DISPATCHER: Starting worker discovery
17:45:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:04 DISPATCHER: Finished worker discovery
17:46:04 DISPATCHER: Starting worker discovery
17:46:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:04 DISPATCHER: Finished worker discovery
17:47:01 WORKER: done with job (4, 0, 16), trying to register it.
17:47:01 WORKER: registered result for job (4, 0, 16) with dispatcher
17:47:01 DISPATCHER: job (4, 0, 16) finished
17:47:01 DISPATCHER: register_result: lock acquired
17:47:01 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:47:01 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005838816330850292, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.010170636952434755}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.909858298230608, 'info': {'number_mnist': 0.909858298230608, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005838816330850292, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.010170636952434755}"}}
exception: None

17:47:01 job_callback for (4, 0, 16) started
17:47:01 DISPATCHER: Trying to submit another job.
17:47:01 job_callback for (4, 0, 16) got condition
17:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:47:01 HBMASTER: Trying to run another job!
17:47:01 job_callback for (4, 0, 16) finished
17:47:01 HBMASTER: schedule new run for iteration 4
17:47:01 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
17:47:01 HBMASTER: submitting job (4, 0, 20) to dispatcher
17:47:01 DISPATCHER: trying to submit job (4, 0, 20)
17:47:01 DISPATCHER: trying to notify the job_runner thread.
17:47:01 HBMASTER: job (4, 0, 20) submitted to dispatcher
17:47:01 DISPATCHER: Trying to submit another job.
17:47:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:47:01 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:47:01 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:47:01 WORKER: start processing job (4, 0, 20)
17:47:01 WORKER: args: ()
17:47:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:47:04 DISPATCHER: Starting worker discovery
17:47:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:04 DISPATCHER: Finished worker discovery
17:48:04 DISPATCHER: Starting worker discovery
17:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:04 DISPATCHER: Finished worker discovery
17:49:04 DISPATCHER: Starting worker discovery
17:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:04 DISPATCHER: Finished worker discovery
17:49:27 WORKER: done with job (4, 0, 20), trying to register it.
17:49:27 WORKER: registered result for job (4, 0, 20) with dispatcher
17:49:27 DISPATCHER: job (4, 0, 20) finished
17:49:27 DISPATCHER: register_result: lock acquired
17:49:27 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:49:27 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9330308055962409, 'info': {'number_mnist': 0.9330308055962409, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}"}}
exception: None

17:49:27 job_callback for (4, 0, 20) started
17:49:27 DISPATCHER: Trying to submit another job.
17:49:27 job_callback for (4, 0, 20) got condition
17:49:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:49:27 HBMASTER: Trying to run another job!
17:49:27 job_callback for (4, 0, 20) finished
17:49:27 HBMASTER: schedule new run for iteration 4
17:49:27 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
17:49:27 HBMASTER: submitting job (4, 0, 22) to dispatcher
17:49:27 DISPATCHER: trying to submit job (4, 0, 22)
17:49:27 DISPATCHER: trying to notify the job_runner thread.
17:49:27 HBMASTER: job (4, 0, 22) submitted to dispatcher
17:49:27 DISPATCHER: Trying to submit another job.
17:49:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:49:27 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:49:27 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:49:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:49:27 WORKER: start processing job (4, 0, 22)
17:49:27 WORKER: args: ()
17:49:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031799833395160237, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.023951974304895218}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:50:04 DISPATCHER: Starting worker discovery
17:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:04 DISPATCHER: Finished worker discovery
17:51:04 DISPATCHER: Starting worker discovery
17:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:04 DISPATCHER: Finished worker discovery
17:51:52 WORKER: done with job (4, 0, 22), trying to register it.
17:51:52 WORKER: registered result for job (4, 0, 22) with dispatcher
17:51:52 DISPATCHER: job (4, 0, 22) finished
17:51:52 DISPATCHER: register_result: lock acquired
17:51:52 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:51:52 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031799833395160237, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.023951974304895218}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8770448815779769, 'info': {'number_mnist': 0.8770448815779769, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031799833395160237, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.023951974304895218}"}}
exception: None

17:51:52 job_callback for (4, 0, 22) started
17:51:52 DISPATCHER: Trying to submit another job.
17:51:52 job_callback for (4, 0, 22) got condition
17:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:51:52 HBMASTER: Trying to run another job!
17:51:52 job_callback for (4, 0, 22) finished
17:51:52 HBMASTER: schedule new run for iteration 4
17:51:52 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:51:52 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:51:52 DISPATCHER: trying to submit job (4, 0, 25)
17:51:52 DISPATCHER: trying to notify the job_runner thread.
17:51:52 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:51:52 DISPATCHER: Trying to submit another job.
17:51:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:51:52 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:51:52 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:51:52 WORKER: start processing job (4, 0, 25)
17:51:52 WORKER: args: ()
17:51:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:52:04 DISPATCHER: Starting worker discovery
17:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:04 DISPATCHER: Finished worker discovery
17:53:04 DISPATCHER: Starting worker discovery
17:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:04 DISPATCHER: Finished worker discovery
17:54:04 DISPATCHER: Starting worker discovery
17:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:04 DISPATCHER: Finished worker discovery
17:54:15 WORKER: done with job (4, 0, 25), trying to register it.
17:54:15 WORKER: registered result for job (4, 0, 25) with dispatcher
17:54:15 DISPATCHER: job (4, 0, 25) finished
17:54:15 DISPATCHER: register_result: lock acquired
17:54:15 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
17:54:15 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9367373912173445, 'info': {'number_mnist': 0.9367373912173445, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}"}}
exception: None

17:54:15 job_callback for (4, 0, 25) started
17:54:15 DISPATCHER: Trying to submit another job.
17:54:15 job_callback for (4, 0, 25) got condition
17:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:54:15 HBMASTER: Trying to run another job!
17:54:15 job_callback for (4, 0, 25) finished
17:54:15 ITERATION: Advancing config (4, 0, 3) to next budget 400.000000
17:54:15 ITERATION: Advancing config (4, 0, 20) to next budget 400.000000
17:54:15 ITERATION: Advancing config (4, 0, 25) to next budget 400.000000
17:54:15 HBMASTER: schedule new run for iteration 4
17:54:15 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
17:54:15 HBMASTER: submitting job (4, 0, 3) to dispatcher
17:54:15 DISPATCHER: trying to submit job (4, 0, 3)
17:54:15 DISPATCHER: trying to notify the job_runner thread.
17:54:15 HBMASTER: job (4, 0, 3) submitted to dispatcher
17:54:15 DISPATCHER: Trying to submit another job.
17:54:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:54:15 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
17:54:15 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
17:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:54:15 WORKER: start processing job (4, 0, 3)
17:54:15 WORKER: args: ()
17:54:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
17:55:04 DISPATCHER: Starting worker discovery
17:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:04 DISPATCHER: Finished worker discovery
17:56:04 DISPATCHER: Starting worker discovery
17:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:04 DISPATCHER: Finished worker discovery
17:57:04 DISPATCHER: Starting worker discovery
17:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:04 DISPATCHER: Finished worker discovery
17:58:04 DISPATCHER: Starting worker discovery
17:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:04 DISPATCHER: Finished worker discovery
17:59:04 DISPATCHER: Starting worker discovery
17:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:04 DISPATCHER: Finished worker discovery
18:00:04 DISPATCHER: Starting worker discovery
18:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:04 DISPATCHER: Finished worker discovery
18:01:04 DISPATCHER: Starting worker discovery
18:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:05 DISPATCHER: Finished worker discovery
18:01:11 WORKER: done with job (4, 0, 3), trying to register it.
18:01:11 WORKER: registered result for job (4, 0, 3) with dispatcher
18:01:11 DISPATCHER: job (4, 0, 3) finished
18:01:11 DISPATCHER: register_result: lock acquired
18:01:11 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:01:11 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9465032785486858, 'info': {'number_mnist': 0.9465032785486858, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

18:01:11 job_callback for (4, 0, 3) started
18:01:11 DISPATCHER: Trying to submit another job.
18:01:11 job_callback for (4, 0, 3) got condition
18:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:01:11 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:01:11 HBMASTER: Trying to run another job!
18:01:11 job_callback for (4, 0, 3) finished
18:01:11 HBMASTER: schedule new run for iteration 4
18:01:11 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
18:01:11 HBMASTER: submitting job (4, 0, 20) to dispatcher
18:01:11 DISPATCHER: trying to submit job (4, 0, 20)
18:01:11 DISPATCHER: trying to notify the job_runner thread.
18:01:11 HBMASTER: job (4, 0, 20) submitted to dispatcher
18:01:11 DISPATCHER: Trying to submit another job.
18:01:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:01:11 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:01:11 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:01:11 WORKER: start processing job (4, 0, 20)
18:01:11 WORKER: args: ()
18:01:11 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}, 'budget': 400.0, 'working_directory': '.'}
18:02:05 DISPATCHER: Starting worker discovery
18:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:05 DISPATCHER: Finished worker discovery
18:03:05 DISPATCHER: Starting worker discovery
18:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:05 DISPATCHER: Finished worker discovery
18:04:05 DISPATCHER: Starting worker discovery
18:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:05 DISPATCHER: Finished worker discovery
18:05:05 DISPATCHER: Starting worker discovery
18:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:05 DISPATCHER: Finished worker discovery
18:06:05 DISPATCHER: Starting worker discovery
18:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:05 DISPATCHER: Finished worker discovery
18:07:05 DISPATCHER: Starting worker discovery
18:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:05 DISPATCHER: Finished worker discovery
18:08:05 DISPATCHER: Starting worker discovery
18:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:05 DISPATCHER: Finished worker discovery
18:08:11 WORKER: done with job (4, 0, 20), trying to register it.
18:08:11 WORKER: registered result for job (4, 0, 20) with dispatcher
18:08:11 DISPATCHER: job (4, 0, 20) finished
18:08:11 DISPATCHER: register_result: lock acquired
18:08:11 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:08:11 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9365263512365297, 'info': {'number_mnist': 0.9365263512365297, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007978382989526158, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.0119310462056487, 'kernel_size_2': 5, 'num_filters_2': 61}"}}
exception: None

18:08:11 job_callback for (4, 0, 20) started
18:08:11 DISPATCHER: Trying to submit another job.
18:08:11 job_callback for (4, 0, 20) got condition
18:08:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:08:12 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:08:12 HBMASTER: Trying to run another job!
18:08:12 job_callback for (4, 0, 20) finished
18:08:12 HBMASTER: schedule new run for iteration 4
18:08:12 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
18:08:12 HBMASTER: submitting job (4, 0, 25) to dispatcher
18:08:12 DISPATCHER: trying to submit job (4, 0, 25)
18:08:12 DISPATCHER: trying to notify the job_runner thread.
18:08:12 HBMASTER: job (4, 0, 25) submitted to dispatcher
18:08:12 DISPATCHER: Trying to submit another job.
18:08:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:08:12 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:08:12 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:08:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:08:12 WORKER: start processing job (4, 0, 25)
18:08:12 WORKER: args: ()
18:08:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}, 'budget': 400.0, 'working_directory': '.'}
18:09:05 DISPATCHER: Starting worker discovery
18:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:05 DISPATCHER: Finished worker discovery
18:10:05 DISPATCHER: Starting worker discovery
18:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:05 DISPATCHER: Finished worker discovery
18:11:05 DISPATCHER: Starting worker discovery
18:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:05 DISPATCHER: Finished worker discovery
18:12:05 DISPATCHER: Starting worker discovery
18:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:05 DISPATCHER: Finished worker discovery
18:13:05 DISPATCHER: Starting worker discovery
18:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:05 DISPATCHER: Finished worker discovery
18:14:05 DISPATCHER: Starting worker discovery
18:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:05 DISPATCHER: Finished worker discovery
18:15:05 DISPATCHER: Starting worker discovery
18:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:05 DISPATCHER: Finished worker discovery
18:15:07 WORKER: done with job (4, 0, 25), trying to register it.
18:15:07 WORKER: registered result for job (4, 0, 25) with dispatcher
18:15:07 DISPATCHER: job (4, 0, 25) finished
18:15:07 DISPATCHER: register_result: lock acquired
18:15:07 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:15:07 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9447995361930099, 'info': {'number_mnist': 0.9447995361930099, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0028589156363912, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010373790244569293, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 68}"}}
exception: None

18:15:07 job_callback for (4, 0, 25) started
18:15:07 job_callback for (4, 0, 25) got condition
18:15:07 DISPATCHER: Trying to submit another job.
18:15:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:15:07 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:15:07 HBMASTER: Trying to run another job!
18:15:07 job_callback for (4, 0, 25) finished
18:15:07 ITERATION: Advancing config (4, 0, 3) to next budget 1200.000000
18:15:07 HBMASTER: schedule new run for iteration 4
18:15:07 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
18:15:07 HBMASTER: submitting job (4, 0, 3) to dispatcher
18:15:07 DISPATCHER: trying to submit job (4, 0, 3)
18:15:07 DISPATCHER: trying to notify the job_runner thread.
18:15:07 HBMASTER: job (4, 0, 3) submitted to dispatcher
18:15:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:15:07 DISPATCHER: Trying to submit another job.
18:15:07 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:15:07 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:15:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:15:07 WORKER: start processing job (4, 0, 3)
18:15:07 WORKER: args: ()
18:15:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
18:16:05 DISPATCHER: Starting worker discovery
18:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:05 DISPATCHER: Finished worker discovery
18:17:05 DISPATCHER: Starting worker discovery
18:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:05 DISPATCHER: Finished worker discovery
18:18:05 DISPATCHER: Starting worker discovery
18:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:05 DISPATCHER: Finished worker discovery
18:19:05 DISPATCHER: Starting worker discovery
18:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:05 DISPATCHER: Finished worker discovery
18:20:05 DISPATCHER: Starting worker discovery
18:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:05 DISPATCHER: Finished worker discovery
18:21:05 DISPATCHER: Starting worker discovery
18:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:05 DISPATCHER: Finished worker discovery
18:22:05 DISPATCHER: Starting worker discovery
18:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:05 DISPATCHER: Finished worker discovery
18:23:05 DISPATCHER: Starting worker discovery
18:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:05 DISPATCHER: Finished worker discovery
18:24:05 DISPATCHER: Starting worker discovery
18:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:05 DISPATCHER: Finished worker discovery
18:25:05 DISPATCHER: Starting worker discovery
18:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:05 DISPATCHER: Finished worker discovery
18:26:05 DISPATCHER: Starting worker discovery
18:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:05 DISPATCHER: Finished worker discovery
18:27:05 DISPATCHER: Starting worker discovery
18:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:05 DISPATCHER: Finished worker discovery
18:28:05 DISPATCHER: Starting worker discovery
18:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:05 DISPATCHER: Finished worker discovery
18:29:05 DISPATCHER: Starting worker discovery
18:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:05 DISPATCHER: Finished worker discovery
18:30:05 DISPATCHER: Starting worker discovery
18:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:05 DISPATCHER: Finished worker discovery
18:31:05 DISPATCHER: Starting worker discovery
18:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:05 DISPATCHER: Finished worker discovery
18:32:05 DISPATCHER: Starting worker discovery
18:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:05 DISPATCHER: Finished worker discovery
18:33:05 DISPATCHER: Starting worker discovery
18:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:05 DISPATCHER: Finished worker discovery
18:34:05 DISPATCHER: Starting worker discovery
18:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:05 DISPATCHER: Finished worker discovery
18:35:05 DISPATCHER: Starting worker discovery
18:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:05 DISPATCHER: Finished worker discovery
18:35:32 WORKER: done with job (4, 0, 3), trying to register it.
18:35:32 WORKER: registered result for job (4, 0, 3) with dispatcher
18:35:32 DISPATCHER: job (4, 0, 3) finished
18:35:32 DISPATCHER: register_result: lock acquired
18:35:32 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:35:32 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9407236384957508, 'info': {'number_mnist': 0.9407236384957508, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002930096114683582, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011615041510510512, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

18:35:32 job_callback for (4, 0, 3) started
18:35:32 job_callback for (4, 0, 3) got condition
18:35:32 DISPATCHER: Trying to submit another job.
18:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:35:32 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:35:32 HBMASTER: Trying to run another job!
18:35:32 job_callback for (4, 0, 3) finished
18:35:32 start sampling a new configuration.
18:35:32 done sampling a new configuration.
18:35:32 HBMASTER: schedule new run for iteration 5
18:35:32 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
18:35:32 HBMASTER: submitting job (5, 0, 0) to dispatcher
18:35:32 DISPATCHER: trying to submit job (5, 0, 0)
18:35:32 DISPATCHER: trying to notify the job_runner thread.
18:35:32 HBMASTER: job (5, 0, 0) submitted to dispatcher
18:35:32 DISPATCHER: Trying to submit another job.
18:35:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:35:32 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:35:32 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:35:32 WORKER: start processing job (5, 0, 0)
18:35:32 WORKER: args: ()
18:35:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.014680749696284152, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.09490814951275192}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:36:05 DISPATCHER: Starting worker discovery
18:36:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:05 DISPATCHER: Finished worker discovery
18:37:05 DISPATCHER: Starting worker discovery
18:37:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:05 DISPATCHER: Finished worker discovery
18:37:58 WORKER: done with job (5, 0, 0), trying to register it.
18:37:58 WORKER: registered result for job (5, 0, 0) with dispatcher
18:37:58 DISPATCHER: job (5, 0, 0) finished
18:37:58 DISPATCHER: register_result: lock acquired
18:37:58 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:37:58 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.014680749696284152, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.09490814951275192}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.48684453506472763, 'info': {'number_mnist': 0.48684453506472763, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.014680749696284152, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.09490814951275192}"}}
exception: None

18:37:58 job_callback for (5, 0, 0) started
18:37:58 DISPATCHER: Trying to submit another job.
18:37:58 job_callback for (5, 0, 0) got condition
18:37:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:37:58 HBMASTER: Trying to run another job!
18:37:58 job_callback for (5, 0, 0) finished
18:37:58 start sampling a new configuration.
18:37:58 best_vector: [0, 0, 0.3379397687746656, 0.4846533316709839, 0.2869576639712448, 1, 0.6342334802207104, 0.03432036311574097, 2, 1, 0, 1, 0.5164446397775269, 0.3266548576745368, 0.06789892361796013, 0.24349867152300583], 6.022912789072491e-06, 7.1987859749969125, 4.3357660114604585e-05
18:37:58 done sampling a new configuration.
18:37:58 HBMASTER: schedule new run for iteration 5
18:37:58 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
18:37:58 HBMASTER: submitting job (5, 0, 1) to dispatcher
18:37:58 DISPATCHER: trying to submit job (5, 0, 1)
18:37:58 DISPATCHER: trying to notify the job_runner thread.
18:37:58 HBMASTER: job (5, 0, 1) submitted to dispatcher
18:37:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:37:58 DISPATCHER: Trying to submit another job.
18:37:58 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:37:58 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:37:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:37:58 WORKER: start processing job (5, 0, 1)
18:37:58 WORKER: args: ()
18:37:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004741104606107786, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.011082859353482346, 'kernel_size_2': 7, 'num_filters_2': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:38:05 DISPATCHER: Starting worker discovery
18:38:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:06 DISPATCHER: Finished worker discovery
18:39:06 DISPATCHER: Starting worker discovery
18:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:06 DISPATCHER: Finished worker discovery
18:40:06 DISPATCHER: Starting worker discovery
18:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:06 DISPATCHER: Finished worker discovery
18:40:23 WORKER: done with job (5, 0, 1), trying to register it.
18:40:23 WORKER: registered result for job (5, 0, 1) with dispatcher
18:40:23 DISPATCHER: job (5, 0, 1) finished
18:40:23 DISPATCHER: register_result: lock acquired
18:40:23 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:40:23 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004741104606107786, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.011082859353482346, 'kernel_size_2': 7, 'num_filters_2': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9166339434434401, 'info': {'number_mnist': 0.9166339434434401, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004741104606107786, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.011082859353482346, 'kernel_size_2': 7, 'num_filters_2': 46}"}}
exception: None

18:40:23 job_callback for (5, 0, 1) started
18:40:23 job_callback for (5, 0, 1) got condition
18:40:23 DISPATCHER: Trying to submit another job.
18:40:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:40:23 HBMASTER: Trying to run another job!
18:40:23 job_callback for (5, 0, 1) finished
18:40:23 start sampling a new configuration.
18:40:23 best_vector: [0, 0, 0.17167285583847583, 0.5528577491589097, 0.6007540418355319, 1, 0.882497774863247, 0.1442830324966719, 2, 1, 0, 1, 0.05452849140587576, 0.6616561152123561, 0.38034805410172723, 0.2443658070422396], 1.0198600846633306e-05, 2.7424535938933206, 2.7969189544532972e-05
18:40:23 done sampling a new configuration.
18:40:23 HBMASTER: schedule new run for iteration 5
18:40:23 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:40:23 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:40:23 DISPATCHER: trying to submit job (5, 0, 2)
18:40:23 DISPATCHER: trying to notify the job_runner thread.
18:40:23 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:40:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:40:23 DISPATCHER: Trying to submit another job.
18:40:23 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:40:23 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:40:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:40:23 WORKER: start processing job (5, 0, 2)
18:40:23 WORKER: args: ()
18:40:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002204680757969412, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.01540694574235641, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 63, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:41:06 DISPATCHER: Starting worker discovery
18:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:06 DISPATCHER: Finished worker discovery
18:42:06 DISPATCHER: Starting worker discovery
18:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:06 DISPATCHER: Finished worker discovery
18:42:47 WORKER: done with job (5, 0, 2), trying to register it.
18:42:47 WORKER: registered result for job (5, 0, 2) with dispatcher
18:42:47 DISPATCHER: job (5, 0, 2) finished
18:42:47 DISPATCHER: register_result: lock acquired
18:42:47 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:42:47 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002204680757969412, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.01540694574235641, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 63, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9133065093299282, 'info': {'number_mnist': 0.9133065093299282, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002204680757969412, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.01540694574235641, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 63, 'num_filters_4': 35}"}}
exception: None

18:42:47 job_callback for (5, 0, 2) started
18:42:47 job_callback for (5, 0, 2) got condition
18:42:47 DISPATCHER: Trying to submit another job.
18:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:42:47 HBMASTER: Trying to run another job!
18:42:47 job_callback for (5, 0, 2) finished
18:42:47 start sampling a new configuration.
18:42:47 sampled vector: [2, 1, 0.3781977233464242, 0.032055275712835285, 0.6333930430712119, 0, 0.5146281711604741, 0.42457826965968715, 0, 0, 2, 2, 0.3414919832590179, 0.18093009565488183, 0.6641301975019908, 0.2417874381147917] has EI value nan
18:42:47 data in the KDEs:
[[3.00000000e+00 2.00000000e+00 2.90668065e-01 9.59697093e-01
  9.00001600e-01 1.00000000e+00 8.84615469e-01 1.66743694e-01
  1.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  5.44175724e-01 8.10134850e-01 1.65573138e-01 2.44555229e-01]
 [3.00000000e+00 0.00000000e+00 2.08378877e-01 8.26346502e-01
  9.99984000e-02 0.00000000e+00 8.73626456e-01 2.66618440e-03
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.57274419e-01 2.44555229e-01 5.14305148e-01 2.44555229e-01]
 [3.00000000e+00 1.00000000e+00 2.33440933e-01 9.67643389e-01
  2.99999200e-01 0.00000000e+00 8.62637442e-01 4.99763775e-02
  2.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  4.93288642e-01 2.44555229e-01 5.14305148e-01 2.44555229e-01]
 [0.00000000e+00 1.00000000e+00 4.43402577e-01 6.23899452e-01
  7.00000800e-01 1.00000000e+00 5.65934080e-01 2.33574452e-01
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  4.11366893e-01 4.93288642e-01 5.14305148e-01 2.44555229e-01]
 [0.00000000e+00 2.00000000e+00 5.44711336e-01 6.47742833e-01
  5.00000000e-01 1.00000000e+00 2.14285651e-01 4.88863885e-02
  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  4.93288642e-01 6.70441281e-01 5.14305148e-01 2.44555229e-01]
 [2.00000000e+00 0.00000000e+00 2.28100670e-01 6.70441281e-01
  5.00000000e-01 1.00000000e+00 7.85714349e-01 1.22498808e-02
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  2.06711555e-01 6.99104210e-01 1.43578776e-01 2.44555229e-01]
 [1.00000000e+00 2.00000000e+00 4.50957440e-01 5.03913663e-01
  2.99999200e-01 1.00000000e+00 4.89010987e-01 5.89367869e-02
  1.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  6.47742833e-01 8.10134850e-01 1.65573138e-01 2.44555229e-01]
 [3.00000000e+00 0.00000000e+00 3.31686941e-01 6.39927886e-01
  2.99999200e-01 1.00000000e+00 7.74725335e-01 7.35963203e-02
  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  3.57274419e-01 9.62599641e-02 1.43578776e-01 2.44555229e-01]
 [3.00000000e+00 0.00000000e+00 7.28879427e-01 5.44175724e-01
  9.99984000e-02 1.00000000e+00 1.15384531e-01 3.05060246e-02
  2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00
  4.93288642e-01 2.44555229e-01 1.43578776e-01 2.44555229e-01]
 [3.00000000e+00 1.00000000e+00 3.83162407e-01 8.95418147e-01
  9.99984000e-02 1.00000000e+00 3.24175786e-01 5.64794984e-03
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  2.62398612e-01 6.99104210e-01 1.43578776e-01 2.44555229e-01]
 [0.00000000e+00 0.00000000e+00 8.33215991e-03 6.39927886e-01
  7.00000800e-01 0.00000000e+00 8.40659416e-01 1.61638725e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  8.26346502e-01 9.62599641e-02 1.43578776e-01 2.44555229e-01]
 [2.00000000e+00 1.00000000e+00 3.73372235e-01 6.84989922e-01
  9.99984000e-02 1.00000000e+00 5.32967040e-01 9.41660800e-02
  1.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  2.62398612e-01 8.10134850e-01 1.65573138e-01 2.44555229e-01]
 [3.00000000e+00 0.00000000e+00 3.27669127e-01 9.08992100e-01
  9.99984000e-02 1.00000000e+00 8.18681389e-01 2.71469689e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  2.62398612e-01 6.70441281e-01 1.43578776e-01 2.44555229e-01]
 [0.00000000e+00 1.00000000e+00 3.84019133e-01 9.94448581e-01
  5.00000000e-01 1.00000000e+00 6.04394638e-02 1.71057511e-01
  1.00000000e+00 0.00000000e+00 2.00000000e+00 1.00000000e+00
  8.31629166e-01 2.44555229e-01 1.65573138e-01 2.44555229e-01]
 [2.00000000e+00 0.00000000e+00 2.23255792e-01 8.62142562e-01
  2.99999200e-01 1.00000000e+00 7.41758295e-01 1.55773753e-02
  1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  2.62398612e-01 4.93288642e-01 5.14305148e-01 2.44555229e-01]
 [1.00000000e+00 1.00000000e+00 2.03656052e-01 8.04605038e-01
  2.99999200e-01 1.00000000e+00 1.26373544e-01 4.43500903e-01
  2.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  5.98789470e-01 6.70441281e-01 1.65573138e-01 2.44555229e-01]
 [1.00000000e+00 2.00000000e+00 2.51212422e-01 8.81442937e-01
  9.99984000e-02 1.00000000e+00 8.73626456e-01 2.91570001e-01
  2.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  4.93288642e-01 6.70441281e-01 1.65573138e-01 2.44555229e-01]]
[[2.         1.         0.15957153 0.69910421 0.5        1.
  0.42307691 0.05062733 0.         2.         2.         1.
  0.76397201 0.09625996 0.39841284 0.89998624]
 [0.         0.         0.32438359 0.50391366 0.7000008  1.
  0.18131861 0.05150753 2.         2.         0.         1.
  0.74542871 0.18658964 0.52447314 0.9793179 ]
 [3.         1.         0.05544378 0.91343151 0.0999984  1.
  0.04945045 0.37281295 0.         2.         1.         1.
  0.01501027 0.56308999 0.16557314 0.9793179 ]
 [1.         2.         0.01362901 0.43625651 0.9000016  1.
  0.9065935  0.35727346 2.         0.         1.         0.
  0.64774283 0.98314621 0.43625651 0.01501027]
 [2.         1.         0.13462964 0.31221238 0.5        1.
  0.78571435 0.31551433 1.         2.         1.         0.
  0.48241935 0.09625996 0.47129428 0.59878947]
 [0.         2.         0.6826628  0.37138871 0.7000008  1.
  0.62087915 0.35769541 1.         1.         0.         1.
  0.78761662 0.39841284 0.01501027 0.07069733]
 [2.         2.         0.11890305 0.89080549 0.0999984  1.
  0.74175829 0.18185566 1.         1.         1.         2.
  0.99444858 0.79334752 0.51430515 0.51430515]
 [1.         1.         0.04158404 0.69910421 0.9000016  0.
  0.81868139 0.8453935  2.         0.         1.         0.
  0.55372743 0.6073085  0.47129428 0.59878947]
 [2.         0.         0.20422962 0.8263465  0.9000016  0.
  0.34615381 0.28369657 0.         0.         0.         1.
  0.26239861 0.93078368 0.14357878 0.07069733]
 [2.         2.         0.15257528 0.73264973 0.2999992  1.
  0.01648341 0.35976429 0.         2.         2.         1.
  0.80460504 0.82100415 0.75787137 0.07069733]
 [0.         0.         0.3834082  0.88144294 0.5        1.
  0.14835157 0.56460474 0.         2.         2.         1.
  0.01501027 0.56308999 0.52447314 0.9793179 ]
 [0.         2.         0.47999267 0.45990111 0.0999984  1.
  0.93956054 0.52463733 0.         0.         1.         1.
  0.24455523 0.67044128 0.16557314 0.9793179 ]
 [3.         1.         0.22421432 0.52447314 0.7000008  1.
  0.06043946 0.16399627 1.         0.         2.         0.
  0.54417572 0.279593   0.52447314 0.01501027]
 [3.         0.         0.59110556 0.8571918  0.2999992  1.
  0.79670336 0.72686221 0.         2.         1.         0.
  0.77594211 0.56308999 0.47129428 0.59878947]
 [2.         1.         0.10719993 0.38509383 0.5        1.
  0.15934058 0.55683587 2.         1.         1.         0.
  0.14357878 0.69910421 0.47129428 0.59878947]
 [2.         2.         0.27863924 0.53442706 0.0999984  0.
  0.88461547 0.78737215 0.         0.         2.         1.
  0.69209973 0.279593   0.52447314 0.07069733]
 [2.         2.         0.67922941 0.6554307  0.5        1.
  0.84065942 0.59038184 0.         1.         0.         1.
  0.39841284 0.279593   0.14357878 0.07069733]
 [0.         1.         0.79555068 0.50391366 0.2999992  1.
  0.8296704  0.46049306 1.         2.         0.         1.
  0.18658964 0.09625996 0.26239861 0.07069733]
 [3.         0.         0.04714391 0.93922664 0.0999984  0.
  0.55494507 0.90384755 0.         0.         1.         1.
  0.24455523 0.67044128 0.16557314 0.9793179 ]
 [2.         2.         0.07108431 0.67044128 0.2999992  1.
  0.01648341 0.31401542 0.         0.         1.         2.
  0.69209973 0.31221238 0.79900978 0.43625651]
 [1.         0.         0.54733005 0.79334752 0.0999984  0.
  0.65384619 0.58913526 2.         0.         1.         0.
  0.55372743 0.6073085  0.47129428 0.59878947]
 [2.         0.         0.63641952 0.3277152  0.0999984  0.
  0.98351659 0.47677729 1.         0.         0.         1.
  0.84713198 0.69209973 0.26239861 0.07069733]
 [3.         1.         0.06234371 0.95161496 0.5        0.
  0.32417579 0.9441226  1.         0.         1.         0.
  0.76397201 0.92218719 0.47129428 0.59878947]
 [2.         1.         0.14502179 0.0436732  0.0999984  1.
  0.74175829 0.16459315 0.         1.         1.         0.
  0.56308999 0.26239861 0.43625651 0.01501027]
 [3.         2.         0.74263128 0.29618395 0.5        1.
  0.95054955 0.57018256 0.         0.         0.         1.
  0.31221238 0.82100415 0.14357878 0.07069733]
 [2.         2.         0.71155553 0.16557314 0.5        1.
  0.02747242 0.356139   0.         1.         1.         0.
  0.56308999 0.26239861 0.43625651 0.01501027]
 [1.         2.         0.95131579 0.09625996 0.0999984  1.
  0.25824171 0.60042561 0.         0.         0.         1.
  0.86214256 0.22601193 0.26239861 0.07069733]
 [3.         0.         0.76671603 0.88614739 0.2999992  1.
  0.0934065  0.82519512 0.         0.         2.         1.
  0.07069733 0.69209973 0.39841284 0.89998624]
 [1.         1.         0.63243087 0.0436732  0.2999992  0.
  0.67582421 0.70168739 0.         1.         1.         1.
  0.91343151 0.22601193 0.07069733 0.9793179 ]
 [2.         2.         0.9564676  0.01501027 0.7000008  0.
  0.71978027 0.08150679 2.         1.         1.         2.
  0.39841284 0.22601193 0.07069733 0.51430515]
 [0.         1.         0.44173872 0.22601193 0.9000016  0.
  0.5        0.57877306 1.         0.         2.         1.
  0.92650497 0.01501027 0.39841284 0.89998624]
 [3.         1.         0.22250921 0.29618395 0.9000016  0.
  0.03846144 0.89576396 2.         0.         1.         2.
  0.14357878 0.31221238 0.79900978 0.43625651]
 [3.         1.         0.92678473 0.20671155 0.5        0.
  0.41208789 0.08940644 1.         0.         1.         2.
  0.84713198 0.69209973 0.79900978 0.43625651]
 [3.         1.         0.73780538 0.22601193 0.9000016  0.
  0.59890112 0.19683542 0.         0.         1.         1.
  0.24455523 0.67044128 0.16557314 0.9793179 ]
 [2.         1.         0.19822684 0.67044128 0.9000016  0.
  0.01648341 0.65567236 1.         1.         1.         2.
  0.99444858 0.79334752 0.51430515 0.51430515]
 [2.         0.         0.84845652 0.85218865 0.7000008  0.
  0.06043946 0.38886353 0.         2.         2.         2.
  0.95969709 0.82100415 0.75787137 0.51430515]
 [0.         0.         0.72419867 0.69910421 0.7000008  0.
  0.79670336 0.76032964 0.         0.         0.         2.
  0.86214256 0.22601193 0.26239861 0.43625651]]
18:42:47 bandwidth of the KDEs:
[1.11696431e+00 7.22012138e-01 1.43466073e-01 1.40191623e-01
 2.23393756e-01 3.50718878e-01 2.71253264e-01 1.11529199e-01
 5.87862154e-01 4.39649381e-01 7.72946761e-01 1.00000000e-03
 1.70244568e-01 2.30753282e-01 1.51033992e-01 1.00000000e-03]
[0.9293569  0.68066993 0.27015954 0.25324362 0.25292652 0.43839308
 0.2955461  0.22662072 0.68902202 0.73169819 0.59934085 0.6153512
 0.26382814 0.24397858 0.19044635 0.31684961]
18:42:47 l(x) = nan
18:42:47 g(x) = 2.5862394754904503e-05
18:42:47 best_vector: [2, 1, 0.33937901852961433, 0.9550653388153594, 0.7228357915446113, 1, 0.10419192468925037, 0.27646649674031654, 0, 2, 0, 1, 0.8481211266434611, 0.20602726533628007, 0.09160103990006352, 0.244367715548754], 7.552431948463179e-07, 18.885623719036627, 1.4263238794230622e-05
18:42:47 done sampling a new configuration.
18:42:47 HBMASTER: schedule new run for iteration 5
18:42:47 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
18:42:47 HBMASTER: submitting job (5, 0, 3) to dispatcher
18:42:47 DISPATCHER: trying to submit job (5, 0, 3)
18:42:47 DISPATCHER: trying to notify the job_runner thread.
18:42:47 HBMASTER: job (5, 0, 3) submitted to dispatcher
18:42:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:42:47 DISPATCHER: Trying to submit another job.
18:42:47 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:42:47 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:42:47 WORKER: start processing job (5, 0, 3)
18:42:47 WORKER: args: ()
18:42:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004772632969738196, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.022892393637930192, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 93, 'num_filters_3': 24, 'num_filters_4': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:43:06 DISPATCHER: Starting worker discovery
18:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:06 DISPATCHER: Finished worker discovery
18:44:06 DISPATCHER: Starting worker discovery
18:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:06 DISPATCHER: Finished worker discovery
18:45:06 DISPATCHER: Starting worker discovery
18:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:06 DISPATCHER: Finished worker discovery
18:45:14 WORKER: done with job (5, 0, 3), trying to register it.
18:45:14 WORKER: registered result for job (5, 0, 3) with dispatcher
18:45:14 DISPATCHER: job (5, 0, 3) finished
18:45:14 DISPATCHER: register_result: lock acquired
18:45:14 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:45:14 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004772632969738196, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.022892393637930192, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 93, 'num_filters_3': 24, 'num_filters_4': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8286870438495062, 'info': {'number_mnist': 0.8286870438495062, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004772632969738196, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.022892393637930192, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 93, 'num_filters_3': 24, 'num_filters_4': 19}"}}
exception: None

18:45:14 job_callback for (5, 0, 3) started
18:45:14 job_callback for (5, 0, 3) got condition
18:45:14 DISPATCHER: Trying to submit another job.
18:45:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:45:15 HBMASTER: Trying to run another job!
18:45:15 job_callback for (5, 0, 3) finished
18:45:15 start sampling a new configuration.
18:45:15 done sampling a new configuration.
18:45:15 HBMASTER: schedule new run for iteration 5
18:45:15 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
18:45:15 HBMASTER: submitting job (5, 0, 4) to dispatcher
18:45:15 DISPATCHER: trying to submit job (5, 0, 4)
18:45:15 DISPATCHER: trying to notify the job_runner thread.
18:45:15 HBMASTER: job (5, 0, 4) submitted to dispatcher
18:45:15 DISPATCHER: Trying to submit another job.
18:45:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:45:15 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:45:15 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:45:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:45:15 WORKER: start processing job (5, 0, 4)
18:45:15 WORKER: args: ()
18:45:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020659545050496445, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.04805440809745548, 'kernel_size_2': 7, 'num_filters_2': 82}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:46:06 DISPATCHER: Starting worker discovery
18:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:06 DISPATCHER: Finished worker discovery
18:47:06 DISPATCHER: Starting worker discovery
18:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:06 DISPATCHER: Finished worker discovery
18:47:41 WORKER: done with job (5, 0, 4), trying to register it.
18:47:41 WORKER: registered result for job (5, 0, 4) with dispatcher
18:47:41 DISPATCHER: job (5, 0, 4) finished
18:47:41 DISPATCHER: register_result: lock acquired
18:47:41 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:47:41 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020659545050496445, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.04805440809745548, 'kernel_size_2': 7, 'num_filters_2': 82}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8012578620941115, 'info': {'number_mnist': 0.8012578620941115, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020659545050496445, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.04805440809745548, 'kernel_size_2': 7, 'num_filters_2': 82}"}}
exception: None

18:47:41 job_callback for (5, 0, 4) started
18:47:41 DISPATCHER: Trying to submit another job.
18:47:41 job_callback for (5, 0, 4) got condition
18:47:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:47:41 HBMASTER: Trying to run another job!
18:47:41 job_callback for (5, 0, 4) finished
18:47:41 start sampling a new configuration.
18:47:41 done sampling a new configuration.
18:47:41 HBMASTER: schedule new run for iteration 5
18:47:41 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
18:47:41 HBMASTER: submitting job (5, 0, 5) to dispatcher
18:47:41 DISPATCHER: trying to submit job (5, 0, 5)
18:47:41 DISPATCHER: trying to notify the job_runner thread.
18:47:41 HBMASTER: job (5, 0, 5) submitted to dispatcher
18:47:41 DISPATCHER: Trying to submit another job.
18:47:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:47:41 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:47:41 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:47:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:47:41 WORKER: start processing job (5, 0, 5)
18:47:41 WORKER: args: ()
18:47:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028623585630316084, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01936067023307279, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:48:06 DISPATCHER: Starting worker discovery
18:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:06 DISPATCHER: Finished worker discovery
18:49:06 DISPATCHER: Starting worker discovery
18:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:06 DISPATCHER: Finished worker discovery
18:50:06 DISPATCHER: Starting worker discovery
18:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:06 DISPATCHER: Finished worker discovery
18:50:07 WORKER: done with job (5, 0, 5), trying to register it.
18:50:07 WORKER: registered result for job (5, 0, 5) with dispatcher
18:50:07 DISPATCHER: job (5, 0, 5) finished
18:50:07 DISPATCHER: register_result: lock acquired
18:50:07 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:50:07 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028623585630316084, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01936067023307279, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02086623534708333, 'info': {'number_mnist': 0.02086623534708333, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.028623585630316084, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01936067023307279, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

18:50:07 job_callback for (5, 0, 5) started
18:50:07 DISPATCHER: Trying to submit another job.
18:50:07 job_callback for (5, 0, 5) got condition
18:50:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:07 HBMASTER: Trying to run another job!
18:50:07 job_callback for (5, 0, 5) finished
18:50:07 start sampling a new configuration.
18:50:07 best_vector: [1, 0, 0.19452921484289604, 0.6473745455251181, 0.045204009091425565, 1, 0.6963932308628833, 0.18506465552123236, 1, 1, 0, 1, 0.2090931329601341, 0.9975587382854416, 0.008121132855101132, 0.24487905883460656], 3.658194136638055e-07, 15.81860282581367, 5.7867520107197734e-06
18:50:07 done sampling a new configuration.
18:50:07 HBMASTER: schedule new run for iteration 5
18:50:07 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
18:50:07 HBMASTER: submitting job (5, 0, 6) to dispatcher
18:50:07 DISPATCHER: trying to submit job (5, 0, 6)
18:50:07 DISPATCHER: trying to notify the job_runner thread.
18:50:07 HBMASTER: job (5, 0, 6) submitted to dispatcher
18:50:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:07 DISPATCHER: Trying to submit another job.
18:50:07 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:50:07 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:50:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:07 WORKER: start processing job (5, 0, 6)
18:50:07 WORKER: args: ()
18:50:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002449392759322529, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.017409033779700343}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:51:06 DISPATCHER: Starting worker discovery
18:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:06 DISPATCHER: Finished worker discovery
18:52:06 DISPATCHER: Starting worker discovery
18:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:06 DISPATCHER: Finished worker discovery
18:52:33 WORKER: done with job (5, 0, 6), trying to register it.
18:52:33 WORKER: registered result for job (5, 0, 6) with dispatcher
18:52:33 DISPATCHER: job (5, 0, 6) finished
18:52:33 DISPATCHER: register_result: lock acquired
18:52:33 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:52:33 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002449392759322529, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.017409033779700343}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8434777727563387, 'info': {'number_mnist': 0.8434777727563387, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002449392759322529, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.017409033779700343}"}}
exception: None

18:52:33 job_callback for (5, 0, 6) started
18:52:33 DISPATCHER: Trying to submit another job.
18:52:33 job_callback for (5, 0, 6) got condition
18:52:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:52:33 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.953229





18:52:33 HBMASTER: Trying to run another job!
18:52:33 job_callback for (5, 0, 6) finished
18:52:33 start sampling a new configuration.
18:52:33 best_vector: [0, 1, 0.35544578725548626, 0.6698225845501696, 0.6781458712567127, 1, 0.44570722043751815, 0.09360689404731498, 2, 2, 0, 1, 0.5547359365215578, 0.6638350416064774, 0.5678435683473618, 0.2558241756214062], 4.9880402712270243e-29, 0.00020047953617543805, -0.0005724634053718868
18:52:33 done sampling a new configuration.
18:52:33 HBMASTER: schedule new run for iteration 5
18:52:33 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
18:52:33 HBMASTER: submitting job (5, 0, 7) to dispatcher
18:52:33 DISPATCHER: trying to submit job (5, 0, 7)
18:52:33 DISPATCHER: trying to notify the job_runner thread.
18:52:33 HBMASTER: job (5, 0, 7) submitted to dispatcher
18:52:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:52:33 DISPATCHER: Trying to submit another job.
18:52:33 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:52:33 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:52:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:52:33 WORKER: start processing job (5, 0, 7)
18:52:33 WORKER: args: ()
18:52:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005139153320209733, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.013236872234274487, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 63, 'num_filters_4': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:53:06 DISPATCHER: Starting worker discovery
18:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:06 DISPATCHER: Finished worker discovery
18:54:06 DISPATCHER: Starting worker discovery
18:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:06 DISPATCHER: Finished worker discovery
18:54:58 WORKER: done with job (5, 0, 7), trying to register it.
18:54:58 WORKER: registered result for job (5, 0, 7) with dispatcher
18:54:58 DISPATCHER: job (5, 0, 7) finished
18:54:58 DISPATCHER: register_result: lock acquired
18:54:58 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:54:58 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005139153320209733, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.013236872234274487, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 63, 'num_filters_4': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9442208560064206, 'info': {'number_mnist': 0.9442208560064206, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005139153320209733, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.013236872234274487, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 63, 'num_filters_4': 52}"}}
exception: None

18:54:58 job_callback for (5, 0, 7) started
18:54:58 job_callback for (5, 0, 7) got condition
18:54:58 DISPATCHER: Trying to submit another job.
18:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:54:58 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.953229





18:54:58 HBMASTER: Trying to run another job!
18:54:58 job_callback for (5, 0, 7) finished
18:54:58 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/numpy/core/_methods.py:42: RuntimeWarning: invalid value encountered in reduce
  return umr_prod(a, axis, dtype, out, keepdims, initial, where)
18:54:58 best_vector: [3, 2, 0.2326602678406431, 0.7101042241250045, 0.4540968215752532, 0, 0.7011216063255363, 0.04419985904684412, 2, 2, 0, 1, 0.07439987968029832, 0.8733800436903569, 0.3591394655340553, 0.24448348057203417], 3.2283459222958847e-34, 30.97561488357591, nan
18:54:58 done sampling a new configuration.
18:54:58 HBMASTER: schedule new run for iteration 5
18:54:58 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
18:54:58 HBMASTER: submitting job (5, 0, 8) to dispatcher
18:54:58 DISPATCHER: trying to submit job (5, 0, 8)
18:54:58 DISPATCHER: trying to notify the job_runner thread.
18:54:58 HBMASTER: job (5, 0, 8) submitted to dispatcher
18:54:58 DISPATCHER: Trying to submit another job.
18:54:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:54:58 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:54:58 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:54:58 WORKER: start processing job (5, 0, 8)
18:54:58 WORKER: args: ()
18:54:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:55:06 DISPATCHER: Starting worker discovery
18:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:06 DISPATCHER: Finished worker discovery
18:56:06 DISPATCHER: Starting worker discovery
18:56:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:06 DISPATCHER: Finished worker discovery
18:57:06 DISPATCHER: Starting worker discovery
18:57:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:06 DISPATCHER: Finished worker discovery
18:57:22 WORKER: done with job (5, 0, 8), trying to register it.
18:57:22 WORKER: registered result for job (5, 0, 8) with dispatcher
18:57:22 DISPATCHER: job (5, 0, 8) finished
18:57:22 DISPATCHER: register_result: lock acquired
18:57:22 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
18:57:22 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9553677942853653, 'info': {'number_mnist': 0.9553677942853653, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}"}}
exception: None

18:57:22 job_callback for (5, 0, 8) started
18:57:22 job_callback for (5, 0, 8) got condition
18:57:22 DISPATCHER: Trying to submit another job.
18:57:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:57:22 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.955368





18:57:22 HBMASTER: Trying to run another job!
18:57:22 job_callback for (5, 0, 8) finished
18:57:22 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
18:57:22 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
18:57:22 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
18:57:22 HBMASTER: schedule new run for iteration 5
18:57:22 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
18:57:22 HBMASTER: submitting job (5, 0, 1) to dispatcher
18:57:22 DISPATCHER: trying to submit job (5, 0, 1)
18:57:22 DISPATCHER: trying to notify the job_runner thread.
18:57:22 HBMASTER: job (5, 0, 1) submitted to dispatcher
18:57:22 DISPATCHER: Trying to submit another job.
18:57:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:57:22 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
18:57:22 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
18:57:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:57:22 WORKER: start processing job (5, 0, 1)
18:57:22 WORKER: args: ()
18:57:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004741104606107786, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.011082859353482346, 'kernel_size_2': 7, 'num_filters_2': 46}, 'budget': 400.0, 'working_directory': '.'}
18:58:06 DISPATCHER: Starting worker discovery
18:58:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:06 DISPATCHER: Finished worker discovery
18:59:06 DISPATCHER: Starting worker discovery
18:59:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:06 DISPATCHER: Finished worker discovery
19:00:06 DISPATCHER: Starting worker discovery
19:00:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:06 DISPATCHER: Finished worker discovery
19:01:06 DISPATCHER: Starting worker discovery
19:01:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:06 DISPATCHER: Finished worker discovery
19:02:06 DISPATCHER: Starting worker discovery
19:02:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:06 DISPATCHER: Finished worker discovery
19:03:06 DISPATCHER: Starting worker discovery
19:03:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:06 DISPATCHER: Finished worker discovery
19:04:06 DISPATCHER: Starting worker discovery
19:04:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:06 DISPATCHER: Finished worker discovery
19:04:20 WORKER: done with job (5, 0, 1), trying to register it.
19:04:20 WORKER: registered result for job (5, 0, 1) with dispatcher
19:04:20 DISPATCHER: job (5, 0, 1) finished
19:04:20 DISPATCHER: register_result: lock acquired
19:04:20 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:04:20 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004741104606107786, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.011082859353482346, 'kernel_size_2': 7, 'num_filters_2': 46}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9311393931795264, 'info': {'number_mnist': 0.9311393931795264, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004741104606107786, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.011082859353482346, 'kernel_size_2': 7, 'num_filters_2': 46}"}}
exception: None

19:04:20 job_callback for (5, 0, 1) started
19:04:20 job_callback for (5, 0, 1) got condition
19:04:20 DISPATCHER: Trying to submit another job.
19:04:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:04:20 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:04:20 HBMASTER: Trying to run another job!
19:04:20 job_callback for (5, 0, 1) finished
19:04:20 HBMASTER: schedule new run for iteration 5
19:04:20 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
19:04:20 HBMASTER: submitting job (5, 0, 7) to dispatcher
19:04:20 DISPATCHER: trying to submit job (5, 0, 7)
19:04:20 DISPATCHER: trying to notify the job_runner thread.
19:04:20 HBMASTER: job (5, 0, 7) submitted to dispatcher
19:04:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:04:20 DISPATCHER: Trying to submit another job.
19:04:20 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:04:20 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:04:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:04:20 WORKER: start processing job (5, 0, 7)
19:04:20 WORKER: args: ()
19:04:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005139153320209733, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.013236872234274487, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 63, 'num_filters_4': 52}, 'budget': 400.0, 'working_directory': '.'}
19:05:06 DISPATCHER: Starting worker discovery
19:05:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:06 DISPATCHER: Finished worker discovery
19:06:06 DISPATCHER: Starting worker discovery
19:06:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:06 DISPATCHER: Finished worker discovery
19:07:06 DISPATCHER: Starting worker discovery
19:07:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:06 DISPATCHER: Finished worker discovery
19:08:06 DISPATCHER: Starting worker discovery
19:08:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:06 DISPATCHER: Finished worker discovery
19:09:06 DISPATCHER: Starting worker discovery
19:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:06 DISPATCHER: Finished worker discovery
19:10:06 DISPATCHER: Starting worker discovery
19:10:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:06 DISPATCHER: Finished worker discovery
19:11:06 DISPATCHER: Starting worker discovery
19:11:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:06 DISPATCHER: Finished worker discovery
19:11:19 WORKER: done with job (5, 0, 7), trying to register it.
19:11:19 WORKER: registered result for job (5, 0, 7) with dispatcher
19:11:19 DISPATCHER: job (5, 0, 7) finished
19:11:19 DISPATCHER: register_result: lock acquired
19:11:19 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:11:19 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005139153320209733, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.013236872234274487, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 63, 'num_filters_4': 52}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9381306504012765, 'info': {'number_mnist': 0.9381306504012765, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005139153320209733, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.013236872234274487, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 63, 'num_filters_4': 52}"}}
exception: None

19:11:19 job_callback for (5, 0, 7) started
19:11:19 DISPATCHER: Trying to submit another job.
19:11:19 job_callback for (5, 0, 7) got condition
19:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:11:19 HBMASTER: Trying to run another job!
19:11:19 job_callback for (5, 0, 7) finished
19:11:19 HBMASTER: schedule new run for iteration 5
19:11:19 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
19:11:19 HBMASTER: submitting job (5, 0, 8) to dispatcher
19:11:19 DISPATCHER: trying to submit job (5, 0, 8)
19:11:19 DISPATCHER: trying to notify the job_runner thread.
19:11:19 HBMASTER: job (5, 0, 8) submitted to dispatcher
19:11:19 DISPATCHER: Trying to submit another job.
19:11:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:11:19 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:11:19 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:11:19 WORKER: start processing job (5, 0, 8)
19:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:11:19 WORKER: args: ()
19:11:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}, 'budget': 400.0, 'working_directory': '.'}
19:12:06 DISPATCHER: Starting worker discovery
19:12:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:06 DISPATCHER: Finished worker discovery
19:13:06 DISPATCHER: Starting worker discovery
19:13:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:06 DISPATCHER: Finished worker discovery
19:14:06 DISPATCHER: Starting worker discovery
19:14:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:06 DISPATCHER: Finished worker discovery
19:15:06 DISPATCHER: Starting worker discovery
19:15:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:06 DISPATCHER: Finished worker discovery
19:16:06 DISPATCHER: Starting worker discovery
19:16:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:06 DISPATCHER: Finished worker discovery
19:17:06 DISPATCHER: Starting worker discovery
19:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:06 DISPATCHER: Finished worker discovery
19:18:06 DISPATCHER: Starting worker discovery
19:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:06 DISPATCHER: Finished worker discovery
19:18:13 WORKER: done with job (5, 0, 8), trying to register it.
19:18:13 WORKER: registered result for job (5, 0, 8) with dispatcher
19:18:13 DISPATCHER: job (5, 0, 8) finished
19:18:13 DISPATCHER: register_result: lock acquired
19:18:13 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:18:13 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9476108195624051, 'info': {'number_mnist': 0.9476108195624051, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}"}}
exception: None

19:18:13 job_callback for (5, 0, 8) started
19:18:13 DISPATCHER: Trying to submit another job.
19:18:13 job_callback for (5, 0, 8) got condition
19:18:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:13 HBMASTER: Trying to run another job!
19:18:13 job_callback for (5, 0, 8) finished
19:18:13 ITERATION: Advancing config (5, 0, 8) to next budget 1200.000000
19:18:13 HBMASTER: schedule new run for iteration 5
19:18:13 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
19:18:13 HBMASTER: submitting job (5, 0, 8) to dispatcher
19:18:13 DISPATCHER: trying to submit job (5, 0, 8)
19:18:13 DISPATCHER: trying to notify the job_runner thread.
19:18:13 HBMASTER: job (5, 0, 8) submitted to dispatcher
19:18:13 DISPATCHER: Trying to submit another job.
19:18:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:13 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:18:13 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:18:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:13 WORKER: start processing job (5, 0, 8)
19:18:13 WORKER: args: ()
19:18:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}, 'budget': 1200.0, 'working_directory': '.'}
19:19:06 DISPATCHER: Starting worker discovery
19:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:06 DISPATCHER: Finished worker discovery
19:20:06 DISPATCHER: Starting worker discovery
19:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:06 DISPATCHER: Finished worker discovery
19:21:06 DISPATCHER: Starting worker discovery
19:21:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:06 DISPATCHER: Finished worker discovery
19:22:06 DISPATCHER: Starting worker discovery
19:22:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:06 DISPATCHER: Finished worker discovery
19:23:06 DISPATCHER: Starting worker discovery
19:23:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:06 DISPATCHER: Finished worker discovery
19:24:06 DISPATCHER: Starting worker discovery
19:24:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:06 DISPATCHER: Finished worker discovery
19:25:06 DISPATCHER: Starting worker discovery
19:25:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:06 DISPATCHER: Finished worker discovery
19:26:06 DISPATCHER: Starting worker discovery
19:26:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:06 DISPATCHER: Finished worker discovery
19:27:06 DISPATCHER: Starting worker discovery
19:27:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:06 DISPATCHER: Finished worker discovery
19:28:06 DISPATCHER: Starting worker discovery
19:28:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:06 DISPATCHER: Finished worker discovery
19:29:06 DISPATCHER: Starting worker discovery
19:29:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:06 DISPATCHER: Finished worker discovery
19:30:06 DISPATCHER: Starting worker discovery
19:30:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:06 DISPATCHER: Finished worker discovery
19:31:06 DISPATCHER: Starting worker discovery
19:31:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:06 DISPATCHER: Finished worker discovery
19:32:06 DISPATCHER: Starting worker discovery
19:32:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:06 DISPATCHER: Finished worker discovery
19:33:06 DISPATCHER: Starting worker discovery
19:33:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:06 DISPATCHER: Finished worker discovery
19:34:06 DISPATCHER: Starting worker discovery
19:34:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:06 DISPATCHER: Finished worker discovery
19:35:06 DISPATCHER: Starting worker discovery
19:35:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:06 DISPATCHER: Finished worker discovery
19:36:06 DISPATCHER: Starting worker discovery
19:36:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:06 DISPATCHER: Finished worker discovery
19:37:06 DISPATCHER: Starting worker discovery
19:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:06 DISPATCHER: Finished worker discovery
19:38:06 DISPATCHER: Starting worker discovery
19:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:06 DISPATCHER: Finished worker discovery
19:38:42 WORKER: done with job (5, 0, 8), trying to register it.
19:38:42 WORKER: registered result for job (5, 0, 8) with dispatcher
19:38:42 DISPATCHER: job (5, 0, 8) finished
19:38:42 DISPATCHER: register_result: lock acquired
19:38:42 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:38:42 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9373708606583563, 'info': {'number_mnist': 0.9373708606583563, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002919581046977097, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.011415773475160852, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 98}"}}
exception: None

19:38:42 job_callback for (5, 0, 8) started
19:38:42 DISPATCHER: Trying to submit another job.
19:38:42 job_callback for (5, 0, 8) got condition
19:38:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:38:42 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:38:42 HBMASTER: Trying to run another job!
19:38:42 job_callback for (5, 0, 8) finished
19:38:42 start sampling a new configuration.
19:38:42 done sampling a new configuration.
19:38:42 HBMASTER: schedule new run for iteration 6
19:38:42 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
19:38:42 HBMASTER: submitting job (6, 0, 0) to dispatcher
19:38:42 DISPATCHER: trying to submit job (6, 0, 0)
19:38:42 DISPATCHER: trying to notify the job_runner thread.
19:38:42 HBMASTER: job (6, 0, 0) submitted to dispatcher
19:38:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:38:42 DISPATCHER: Trying to submit another job.
19:38:42 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:38:42 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:38:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:38:42 WORKER: start processing job (6, 0, 0)
19:38:42 WORKER: args: ()
19:38:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030184170677199115, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.03275498866773359}, 'budget': 400.0, 'working_directory': '.'}
19:39:06 DISPATCHER: Starting worker discovery
19:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:06 DISPATCHER: Finished worker discovery
19:40:06 DISPATCHER: Starting worker discovery
19:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:06 DISPATCHER: Finished worker discovery
19:41:06 DISPATCHER: Starting worker discovery
19:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:06 DISPATCHER: Finished worker discovery
19:42:06 DISPATCHER: Starting worker discovery
19:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:06 DISPATCHER: Finished worker discovery
19:43:06 DISPATCHER: Starting worker discovery
19:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:06 DISPATCHER: Finished worker discovery
19:44:06 DISPATCHER: Starting worker discovery
19:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:06 DISPATCHER: Finished worker discovery
19:45:06 DISPATCHER: Starting worker discovery
19:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:06 DISPATCHER: Finished worker discovery
19:45:38 WORKER: done with job (6, 0, 0), trying to register it.
19:45:38 WORKER: registered result for job (6, 0, 0) with dispatcher
19:45:38 DISPATCHER: job (6, 0, 0) finished
19:45:38 DISPATCHER: register_result: lock acquired
19:45:38 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:45:38 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030184170677199115, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.03275498866773359}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7822026372181448, 'info': {'number_mnist': 0.7822026372181448, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0030184170677199115, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.03275498866773359}"}}
exception: None

19:45:38 job_callback for (6, 0, 0) started
19:45:38 DISPATCHER: Trying to submit another job.
19:45:38 job_callback for (6, 0, 0) got condition
19:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:45:38 HBMASTER: Trying to run another job!
19:45:38 job_callback for (6, 0, 0) finished
19:45:38 start sampling a new configuration.
19:45:38 best_vector: [2, 1, 0.3376928098166241, 0.3856318622689318, 0.9228970292071377, 1, 0.04855821102009106, 0.04110962226406926, 1, 2, 1, 1, 0.5187826769881532, 0.5084595435700182, 0.6863679890095096, 0.24485936135787864], 7.86020301255105e-34, 12.722317711173817, nan
19:45:38 done sampling a new configuration.
19:45:38 HBMASTER: schedule new run for iteration 6
19:45:38 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
19:45:38 HBMASTER: submitting job (6, 0, 1) to dispatcher
19:45:38 DISPATCHER: trying to submit job (6, 0, 1)
19:45:38 DISPATCHER: trying to notify the job_runner thread.
19:45:38 HBMASTER: job (6, 0, 1) submitted to dispatcher
19:45:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:45:38 DISPATCHER: Trying to submit another job.
19:45:38 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:45:38 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:45:38 WORKER: start processing job (6, 0, 1)
19:45:38 WORKER: args: ()
19:45:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004735715669554161, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.011310579369997322, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 46, 'num_filters_3': 45, 'num_filters_4': 66, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
19:46:06 DISPATCHER: Starting worker discovery
19:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:06 DISPATCHER: Finished worker discovery
19:47:06 DISPATCHER: Starting worker discovery
19:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:06 DISPATCHER: Finished worker discovery
19:48:06 DISPATCHER: Starting worker discovery
19:48:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:07 DISPATCHER: Finished worker discovery
19:49:07 DISPATCHER: Starting worker discovery
19:49:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:07 DISPATCHER: Finished worker discovery
19:50:07 DISPATCHER: Starting worker discovery
19:50:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:07 DISPATCHER: Finished worker discovery
19:51:07 DISPATCHER: Starting worker discovery
19:51:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:07 DISPATCHER: Finished worker discovery
19:52:07 DISPATCHER: Starting worker discovery
19:52:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:07 DISPATCHER: Finished worker discovery
19:52:49 WORKER: done with job (6, 0, 1), trying to register it.
19:52:49 WORKER: registered result for job (6, 0, 1) with dispatcher
19:52:49 DISPATCHER: job (6, 0, 1) finished
19:52:49 DISPATCHER: register_result: lock acquired
19:52:49 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
19:52:49 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004735715669554161, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.011310579369997322, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 46, 'num_filters_3': 45, 'num_filters_4': 66, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8464055379049522, 'info': {'number_mnist': 0.8464055379049522, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004735715669554161, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.011310579369997322, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 46, 'num_filters_3': 45, 'num_filters_4': 66, 'num_filters_5': 26}"}}
exception: None

19:52:49 job_callback for (6, 0, 1) started
19:52:49 DISPATCHER: Trying to submit another job.
19:52:49 job_callback for (6, 0, 1) got condition
19:52:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:52:49 HBMASTER: Trying to run another job!
19:52:49 job_callback for (6, 0, 1) finished
19:52:49 start sampling a new configuration.
19:52:49 done sampling a new configuration.
19:52:49 HBMASTER: schedule new run for iteration 6
19:52:49 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
19:52:49 HBMASTER: submitting job (6, 0, 2) to dispatcher
19:52:49 DISPATCHER: trying to submit job (6, 0, 2)
19:52:49 DISPATCHER: trying to notify the job_runner thread.
19:52:49 HBMASTER: job (6, 0, 2) submitted to dispatcher
19:52:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:52:49 DISPATCHER: Trying to submit another job.
19:52:49 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
19:52:49 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
19:52:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:52:49 WORKER: start processing job (6, 0, 2)
19:52:49 WORKER: args: ()
19:52:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.055150181316961755, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.07176310069386362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 99}, 'budget': 400.0, 'working_directory': '.'}
19:53:07 DISPATCHER: Starting worker discovery
19:53:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:07 DISPATCHER: Finished worker discovery
19:54:07 DISPATCHER: Starting worker discovery
19:54:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:07 DISPATCHER: Finished worker discovery
19:55:07 DISPATCHER: Starting worker discovery
19:55:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:07 DISPATCHER: Finished worker discovery
19:56:07 DISPATCHER: Starting worker discovery
19:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:07 DISPATCHER: Finished worker discovery
19:57:07 DISPATCHER: Starting worker discovery
19:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:07 DISPATCHER: Finished worker discovery
19:58:07 DISPATCHER: Starting worker discovery
19:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:07 DISPATCHER: Finished worker discovery
19:59:07 DISPATCHER: Starting worker discovery
19:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:07 DISPATCHER: Finished worker discovery
20:00:07 DISPATCHER: Starting worker discovery
20:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:07 DISPATCHER: Finished worker discovery
20:00:24 WORKER: done with job (6, 0, 2), trying to register it.
20:00:24 WORKER: registered result for job (6, 0, 2) with dispatcher
20:00:24 DISPATCHER: job (6, 0, 2) finished
20:00:24 DISPATCHER: register_result: lock acquired
20:00:24 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:00:24 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.055150181316961755, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.07176310069386362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 99}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3811860947275747, 'info': {'number_mnist': 0.3811860947275747, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.055150181316961755, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.07176310069386362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 99}"}}
exception: None

20:00:24 job_callback for (6, 0, 2) started
20:00:24 DISPATCHER: Trying to submit another job.
20:00:24 job_callback for (6, 0, 2) got condition
20:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:00:24 HBMASTER: Trying to run another job!
20:00:24 job_callback for (6, 0, 2) finished
20:00:24 start sampling a new configuration.
20:00:24 best_vector: [2, 1, 0.468358885649074, 0.6180227015180034, 0.16518992393059928, 0, 0.6239816741765956, 0.08448735128654349, 2, 0, 0, 1, 0.044707222589165624, 0.7123954746749275, 0.5099946910232199, 0.24490539426237398], 2.8012561556427998e-34, 35.69827050573787, nan
20:00:24 done sampling a new configuration.
20:00:24 HBMASTER: schedule new run for iteration 6
20:00:24 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
20:00:24 HBMASTER: submitting job (6, 0, 3) to dispatcher
20:00:24 DISPATCHER: trying to submit job (6, 0, 3)
20:00:24 DISPATCHER: trying to notify the job_runner thread.
20:00:24 HBMASTER: job (6, 0, 3) submitted to dispatcher
20:00:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:00:24 DISPATCHER: Trying to submit another job.
20:00:24 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:00:24 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:00:24 WORKER: start processing job (6, 0, 3)
20:00:24 WORKER: args: ()
20:00:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008644059971321262, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.012880139842448662}, 'budget': 400.0, 'working_directory': '.'}
20:01:07 DISPATCHER: Starting worker discovery
20:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:07 DISPATCHER: Finished worker discovery
20:02:07 DISPATCHER: Starting worker discovery
20:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:07 DISPATCHER: Finished worker discovery
20:03:07 DISPATCHER: Starting worker discovery
20:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:07 DISPATCHER: Finished worker discovery
20:04:07 DISPATCHER: Starting worker discovery
20:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:07 DISPATCHER: Finished worker discovery
20:05:07 DISPATCHER: Starting worker discovery
20:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:07 DISPATCHER: Finished worker discovery
20:06:07 DISPATCHER: Starting worker discovery
20:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:07 DISPATCHER: Finished worker discovery
20:07:07 DISPATCHER: Starting worker discovery
20:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:07 DISPATCHER: Finished worker discovery
20:07:18 WORKER: done with job (6, 0, 3), trying to register it.
20:07:19 WORKER: registered result for job (6, 0, 3) with dispatcher
20:07:19 DISPATCHER: job (6, 0, 3) finished
20:07:19 DISPATCHER: register_result: lock acquired
20:07:19 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:07:19 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008644059971321262, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.012880139842448662}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9024773316642858, 'info': {'number_mnist': 0.9024773316642858, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008644059971321262, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.012880139842448662}"}}
exception: None

20:07:19 job_callback for (6, 0, 3) started
20:07:19 DISPATCHER: Trying to submit another job.
20:07:19 job_callback for (6, 0, 3) got condition
20:07:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:07:19 HBMASTER: Trying to run another job!
20:07:19 job_callback for (6, 0, 3) finished
20:07:19 start sampling a new configuration.
20:07:19 best_vector: [2, 2, 0.36730253150847214, 0.6076643949717235, 0.6419500029578856, 1, 0.3891084487732383, 0.11231863254145576, 2, 2, 0, 1, 0.24535489276979694, 0.553383420753955, 0.805766972853669, 0.24386715947233312], 1.0541212302424097e-33, 9.486574895849847, nan
20:07:19 done sampling a new configuration.
20:07:19 HBMASTER: schedule new run for iteration 6
20:07:19 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
20:07:19 HBMASTER: submitting job (6, 0, 4) to dispatcher
20:07:19 DISPATCHER: trying to submit job (6, 0, 4)
20:07:19 DISPATCHER: trying to notify the job_runner thread.
20:07:19 HBMASTER: job (6, 0, 4) submitted to dispatcher
20:07:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:07:19 DISPATCHER: Trying to submit another job.
20:07:19 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:07:19 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:07:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:07:19 WORKER: start processing job (6, 0, 4)
20:07:19 WORKER: args: ()
20:07:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0054275653722998494, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014000060421395871, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 50, 'num_filters_4': 85}, 'budget': 400.0, 'working_directory': '.'}
20:08:07 DISPATCHER: Starting worker discovery
20:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:07 DISPATCHER: Finished worker discovery
20:09:07 DISPATCHER: Starting worker discovery
20:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:07 DISPATCHER: Finished worker discovery
20:10:07 DISPATCHER: Starting worker discovery
20:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:07 DISPATCHER: Finished worker discovery
20:11:07 DISPATCHER: Starting worker discovery
20:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:07 DISPATCHER: Finished worker discovery
20:12:07 DISPATCHER: Starting worker discovery
20:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:07 DISPATCHER: Finished worker discovery
20:13:07 DISPATCHER: Starting worker discovery
20:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:07 DISPATCHER: Finished worker discovery
20:14:07 DISPATCHER: Starting worker discovery
20:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:07 DISPATCHER: Finished worker discovery
20:14:14 WORKER: done with job (6, 0, 4), trying to register it.
20:14:14 WORKER: registered result for job (6, 0, 4) with dispatcher
20:14:14 DISPATCHER: job (6, 0, 4) finished
20:14:14 DISPATCHER: register_result: lock acquired
20:14:14 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:14:14 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0054275653722998494, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014000060421395871, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 50, 'num_filters_4': 85}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9394787724201724, 'info': {'number_mnist': 0.9394787724201724, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0054275653722998494, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014000060421395871, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 50, 'num_filters_4': 85}"}}
exception: None

20:14:14 job_callback for (6, 0, 4) started
20:14:14 job_callback for (6, 0, 4) got condition
20:14:14 DISPATCHER: Trying to submit another job.
20:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:14:14 HBMASTER: Trying to run another job!
20:14:14 job_callback for (6, 0, 4) finished
20:14:14 start sampling a new configuration.
20:14:14 best_vector: [2, 1, 0.6533250685065202, 0.7716633500258226, 0.5810396371487544, 1, 0.5439732090869844, 0.05332333704576539, 1, 2, 0, 1, 0.4767499794425496, 0.3652268124785484, 0.6027313511083637, 0.2437916363859607], 3.7934244365473137e-34, 26.361405551290662, nan
20:14:14 done sampling a new configuration.
20:14:14 HBMASTER: schedule new run for iteration 6
20:14:14 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
20:14:14 HBMASTER: submitting job (6, 0, 5) to dispatcher
20:14:14 DISPATCHER: trying to submit job (6, 0, 5)
20:14:14 DISPATCHER: trying to notify the job_runner thread.
20:14:14 HBMASTER: job (6, 0, 5) submitted to dispatcher
20:14:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:14:14 DISPATCHER: Trying to submit another job.
20:14:14 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:14:14 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:14:14 WORKER: start processing job (6, 0, 5)
20:14:14 WORKER: args: ()
20:14:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02026049897802116, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.011732086624720141, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 34}, 'budget': 400.0, 'working_directory': '.'}
20:15:07 DISPATCHER: Starting worker discovery
20:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:07 DISPATCHER: Finished worker discovery
20:16:07 DISPATCHER: Starting worker discovery
20:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:07 DISPATCHER: Finished worker discovery
20:17:07 DISPATCHER: Starting worker discovery
20:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:07 DISPATCHER: Finished worker discovery
20:18:07 DISPATCHER: Starting worker discovery
20:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:07 DISPATCHER: Finished worker discovery
20:19:07 DISPATCHER: Starting worker discovery
20:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:07 DISPATCHER: Finished worker discovery
20:20:07 DISPATCHER: Starting worker discovery
20:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:07 DISPATCHER: Finished worker discovery
20:21:07 DISPATCHER: Starting worker discovery
20:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:07 DISPATCHER: Finished worker discovery
20:21:08 WORKER: done with job (6, 0, 5), trying to register it.
20:21:08 WORKER: registered result for job (6, 0, 5) with dispatcher
20:21:08 DISPATCHER: job (6, 0, 5) finished
20:21:08 DISPATCHER: register_result: lock acquired
20:21:08 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:21:08 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02026049897802116, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.011732086624720141, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9217711926792698, 'info': {'number_mnist': 0.9217711926792698, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02026049897802116, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.011732086624720141, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 34}"}}
exception: None

20:21:08 job_callback for (6, 0, 5) started
20:21:08 job_callback for (6, 0, 5) got condition
20:21:08 DISPATCHER: Trying to submit another job.
20:21:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:21:08 HBMASTER: Trying to run another job!
20:21:08 job_callback for (6, 0, 5) finished
20:21:08 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
20:21:08 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
20:21:08 HBMASTER: schedule new run for iteration 6
20:21:08 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
20:21:08 HBMASTER: submitting job (6, 0, 4) to dispatcher
20:21:08 DISPATCHER: trying to submit job (6, 0, 4)
20:21:08 DISPATCHER: trying to notify the job_runner thread.
20:21:08 HBMASTER: job (6, 0, 4) submitted to dispatcher
20:21:08 DISPATCHER: Trying to submit another job.
20:21:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:21:08 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:21:08 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:21:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:21:08 WORKER: start processing job (6, 0, 4)
20:21:08 WORKER: args: ()
20:21:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0054275653722998494, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014000060421395871, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 50, 'num_filters_4': 85}, 'budget': 1200.0, 'working_directory': '.'}
20:22:07 DISPATCHER: Starting worker discovery
20:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:07 DISPATCHER: Finished worker discovery
20:23:07 DISPATCHER: Starting worker discovery
20:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:07 DISPATCHER: Finished worker discovery
20:24:07 DISPATCHER: Starting worker discovery
20:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:07 DISPATCHER: Finished worker discovery
20:25:07 DISPATCHER: Starting worker discovery
20:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:07 DISPATCHER: Finished worker discovery
20:26:07 DISPATCHER: Starting worker discovery
20:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:07 DISPATCHER: Finished worker discovery
20:27:07 DISPATCHER: Starting worker discovery
20:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:07 DISPATCHER: Finished worker discovery
20:28:07 DISPATCHER: Starting worker discovery
20:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:08 DISPATCHER: Finished worker discovery
20:29:08 DISPATCHER: Starting worker discovery
20:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:08 DISPATCHER: Finished worker discovery
20:30:08 DISPATCHER: Starting worker discovery
20:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:08 DISPATCHER: Finished worker discovery
20:31:08 DISPATCHER: Starting worker discovery
20:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:08 DISPATCHER: Finished worker discovery
20:32:08 DISPATCHER: Starting worker discovery
20:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:08 DISPATCHER: Finished worker discovery
20:33:08 DISPATCHER: Starting worker discovery
20:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:08 DISPATCHER: Finished worker discovery
20:34:08 DISPATCHER: Starting worker discovery
20:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:08 DISPATCHER: Finished worker discovery
20:35:08 DISPATCHER: Starting worker discovery
20:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:08 DISPATCHER: Finished worker discovery
20:36:08 DISPATCHER: Starting worker discovery
20:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:08 DISPATCHER: Finished worker discovery
20:37:08 DISPATCHER: Starting worker discovery
20:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:08 DISPATCHER: Finished worker discovery
20:38:08 DISPATCHER: Starting worker discovery
20:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:08 DISPATCHER: Finished worker discovery
20:39:08 DISPATCHER: Starting worker discovery
20:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:08 DISPATCHER: Finished worker discovery
20:40:08 DISPATCHER: Starting worker discovery
20:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:08 DISPATCHER: Finished worker discovery
20:41:08 DISPATCHER: Starting worker discovery
20:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:08 DISPATCHER: Finished worker discovery
20:41:37 WORKER: done with job (6, 0, 4), trying to register it.
20:41:37 WORKER: registered result for job (6, 0, 4) with dispatcher
20:41:37 DISPATCHER: job (6, 0, 4) finished
20:41:37 DISPATCHER: register_result: lock acquired
20:41:37 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
20:41:37 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0054275653722998494, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014000060421395871, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 50, 'num_filters_4': 85}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9327449729140976, 'info': {'number_mnist': 0.9327449729140976, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0054275653722998494, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014000060421395871, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 50, 'num_filters_4': 85}"}}
exception: None

20:41:37 job_callback for (6, 0, 4) started
20:41:37 job_callback for (6, 0, 4) got condition
20:41:37 DISPATCHER: Trying to submit another job.
20:41:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:41:37 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:41:37 HBMASTER: Trying to run another job!
20:41:37 job_callback for (6, 0, 4) finished
20:41:37 HBMASTER: schedule new run for iteration 6
20:41:37 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
20:41:37 HBMASTER: submitting job (6, 0, 5) to dispatcher
20:41:37 DISPATCHER: trying to submit job (6, 0, 5)
20:41:37 DISPATCHER: trying to notify the job_runner thread.
20:41:37 HBMASTER: job (6, 0, 5) submitted to dispatcher
20:41:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:41:37 DISPATCHER: Trying to submit another job.
20:41:37 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
20:41:37 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
20:41:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:41:37 WORKER: start processing job (6, 0, 5)
20:41:37 WORKER: args: ()
20:41:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02026049897802116, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.011732086624720141, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 34}, 'budget': 1200.0, 'working_directory': '.'}
20:42:08 DISPATCHER: Starting worker discovery
20:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:08 DISPATCHER: Finished worker discovery
20:43:08 DISPATCHER: Starting worker discovery
20:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:08 DISPATCHER: Finished worker discovery
20:44:08 DISPATCHER: Starting worker discovery
20:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:08 DISPATCHER: Finished worker discovery
20:45:08 DISPATCHER: Starting worker discovery
20:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:08 DISPATCHER: Finished worker discovery
20:46:08 DISPATCHER: Starting worker discovery
20:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:08 DISPATCHER: Finished worker discovery
20:47:08 DISPATCHER: Starting worker discovery
20:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:08 DISPATCHER: Finished worker discovery
20:48:08 DISPATCHER: Starting worker discovery
20:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:08 DISPATCHER: Finished worker discovery
20:49:08 DISPATCHER: Starting worker discovery
20:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:08 DISPATCHER: Finished worker discovery
20:50:08 DISPATCHER: Starting worker discovery
20:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:08 DISPATCHER: Finished worker discovery
20:51:08 DISPATCHER: Starting worker discovery
20:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:08 DISPATCHER: Finished worker discovery
20:52:08 DISPATCHER: Starting worker discovery
20:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:08 DISPATCHER: Finished worker discovery
20:53:08 DISPATCHER: Starting worker discovery
20:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:08 DISPATCHER: Finished worker discovery
20:54:08 DISPATCHER: Starting worker discovery
20:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:08 DISPATCHER: Finished worker discovery
20:55:08 DISPATCHER: Starting worker discovery
20:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:08 DISPATCHER: Finished worker discovery
20:56:08 DISPATCHER: Starting worker discovery
20:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:08 DISPATCHER: Finished worker discovery
20:57:08 DISPATCHER: Starting worker discovery
20:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:08 DISPATCHER: Finished worker discovery
20:58:08 DISPATCHER: Starting worker discovery
20:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:08 DISPATCHER: Finished worker discovery
20:59:08 DISPATCHER: Starting worker discovery
20:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:08 DISPATCHER: Finished worker discovery
21:00:08 DISPATCHER: Starting worker discovery
21:00:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:08 DISPATCHER: Finished worker discovery
21:01:08 DISPATCHER: Starting worker discovery
21:01:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:08 DISPATCHER: Finished worker discovery
21:02:01 WORKER: done with job (6, 0, 5), trying to register it.
21:02:01 WORKER: registered result for job (6, 0, 5) with dispatcher
21:02:01 DISPATCHER: job (6, 0, 5) finished
21:02:01 DISPATCHER: register_result: lock acquired
21:02:01 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:02:01 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02026049897802116, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.011732086624720141, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 34}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9412642756586151, 'info': {'number_mnist': 0.9412642756586151, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02026049897802116, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.011732086624720141, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 34}"}}
exception: None

21:02:01 job_callback for (6, 0, 5) started
21:02:01 DISPATCHER: Trying to submit another job.
21:02:01 job_callback for (6, 0, 5) got condition
21:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:02:01 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:02:01 HBMASTER: Trying to run another job!
21:02:01 job_callback for (6, 0, 5) finished
21:02:01 start sampling a new configuration.
21:02:01 best_vector: [0, 2, 0.3944969721647527, 0.8883374021034078, 0.41067913576091475, 1, 0.46928408572603886, 0.04833645134458783, 1, 1, 0, 1, 0.6268888266900846, 0.21757574648380734, 0.4756602569674813, 0.24363820071812176], 2.1303093795629923e-34, 46.941538613754695, nan
21:02:01 done sampling a new configuration.
21:02:01 HBMASTER: schedule new run for iteration 7
21:02:01 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
21:02:01 HBMASTER: submitting job (7, 0, 0) to dispatcher
21:02:01 DISPATCHER: trying to submit job (7, 0, 0)
21:02:01 DISPATCHER: trying to notify the job_runner thread.
21:02:01 HBMASTER: job (7, 0, 0) submitted to dispatcher
21:02:01 DISPATCHER: Trying to submit another job.
21:02:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:02:01 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:02:01 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:02:01 WORKER: start processing job (7, 0, 0)
21:02:01 WORKER: args: ()
21:02:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006151682949299974, 'num_filters_1': 101, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011558119306689745, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 58, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
21:02:08 DISPATCHER: Starting worker discovery
21:02:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:08 DISPATCHER: Finished worker discovery
21:03:08 DISPATCHER: Starting worker discovery
21:03:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:08 DISPATCHER: Finished worker discovery
21:04:08 DISPATCHER: Starting worker discovery
21:04:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:08 DISPATCHER: Finished worker discovery
21:05:08 DISPATCHER: Starting worker discovery
21:05:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:08 DISPATCHER: Finished worker discovery
21:06:08 DISPATCHER: Starting worker discovery
21:06:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:08 DISPATCHER: Finished worker discovery
21:07:08 DISPATCHER: Starting worker discovery
21:07:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:08 DISPATCHER: Finished worker discovery
21:08:08 DISPATCHER: Starting worker discovery
21:08:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:08 DISPATCHER: Finished worker discovery
21:09:08 DISPATCHER: Starting worker discovery
21:09:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:08 DISPATCHER: Finished worker discovery
21:10:08 DISPATCHER: Starting worker discovery
21:10:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:08 DISPATCHER: Finished worker discovery
21:11:08 DISPATCHER: Starting worker discovery
21:11:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:08 DISPATCHER: Finished worker discovery
21:12:08 DISPATCHER: Starting worker discovery
21:12:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:08 DISPATCHER: Finished worker discovery
21:13:08 DISPATCHER: Starting worker discovery
21:13:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:08 DISPATCHER: Finished worker discovery
21:14:08 DISPATCHER: Starting worker discovery
21:14:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:08 DISPATCHER: Finished worker discovery
21:15:08 DISPATCHER: Starting worker discovery
21:15:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:08 DISPATCHER: Finished worker discovery
21:16:08 DISPATCHER: Starting worker discovery
21:16:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:08 DISPATCHER: Finished worker discovery
21:17:08 DISPATCHER: Starting worker discovery
21:17:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:08 DISPATCHER: Finished worker discovery
21:18:08 DISPATCHER: Starting worker discovery
21:18:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:08 DISPATCHER: Finished worker discovery
21:19:08 DISPATCHER: Starting worker discovery
21:19:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:08 DISPATCHER: Finished worker discovery
21:20:08 DISPATCHER: Starting worker discovery
21:20:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:08 DISPATCHER: Finished worker discovery
21:21:08 DISPATCHER: Starting worker discovery
21:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:08 DISPATCHER: Finished worker discovery
21:22:08 DISPATCHER: Starting worker discovery
21:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:08 DISPATCHER: Finished worker discovery
21:22:41 WORKER: done with job (7, 0, 0), trying to register it.
21:22:41 WORKER: registered result for job (7, 0, 0) with dispatcher
21:22:41 DISPATCHER: job (7, 0, 0) finished
21:22:41 DISPATCHER: register_result: lock acquired
21:22:41 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:22:41 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006151682949299974, 'num_filters_1': 101, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011558119306689745, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 58, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9347630136917449, 'info': {'number_mnist': 0.9347630136917449, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006151682949299974, 'num_filters_1': 101, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.011558119306689745, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 58, 'num_filters_3': 25}"}}
exception: None

21:22:41 job_callback for (7, 0, 0) started
21:22:41 job_callback for (7, 0, 0) got condition
21:22:41 DISPATCHER: Trying to submit another job.
21:22:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:22:41 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:22:41 HBMASTER: Trying to run another job!
21:22:41 job_callback for (7, 0, 0) finished
21:22:41 start sampling a new configuration.
21:22:41 best_vector: [2, 1, 0.3961252493048931, 0.34331863088178494, 0.26541736186743575, 1, 0.9852804460498641, 0.04731903770235275, 2, 2, 0, 1, 0.6454109204782966, 0.53170856668348, 0.31822809566035704, 0.24392270254633766], 2.790245460128931e-34, 35.83914083149489, nan
21:22:41 done sampling a new configuration.
21:22:41 HBMASTER: schedule new run for iteration 7
21:22:41 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
21:22:41 HBMASTER: submitting job (7, 0, 1) to dispatcher
21:22:41 DISPATCHER: trying to submit job (7, 0, 1)
21:22:41 DISPATCHER: trying to notify the job_runner thread.
21:22:41 HBMASTER: job (7, 0, 1) submitted to dispatcher
21:22:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:22:41 DISPATCHER: Trying to submit another job.
21:22:41 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:22:41 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:22:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:22:41 WORKER: start processing job (7, 0, 1)
21:22:41 WORKER: args: ()
21:22:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0061979846825943406, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011522944958915933, 'kernel_size_2': 7, 'num_filters_2': 61}, 'budget': 1200.0, 'working_directory': '.'}
21:23:08 DISPATCHER: Starting worker discovery
21:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:08 DISPATCHER: Finished worker discovery
21:24:08 DISPATCHER: Starting worker discovery
21:24:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:08 DISPATCHER: Finished worker discovery
21:25:08 DISPATCHER: Starting worker discovery
21:25:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:08 DISPATCHER: Finished worker discovery
21:26:08 DISPATCHER: Starting worker discovery
21:26:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:08 DISPATCHER: Finished worker discovery
21:27:08 DISPATCHER: Starting worker discovery
21:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:08 DISPATCHER: Finished worker discovery
21:28:08 DISPATCHER: Starting worker discovery
21:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:08 DISPATCHER: Finished worker discovery
21:29:08 DISPATCHER: Starting worker discovery
21:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:08 DISPATCHER: Finished worker discovery
21:30:08 DISPATCHER: Starting worker discovery
21:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:08 DISPATCHER: Finished worker discovery
21:31:08 DISPATCHER: Starting worker discovery
21:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:08 DISPATCHER: Finished worker discovery
21:32:08 DISPATCHER: Starting worker discovery
21:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:08 DISPATCHER: Finished worker discovery
21:33:08 DISPATCHER: Starting worker discovery
21:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:08 DISPATCHER: Finished worker discovery
21:34:08 DISPATCHER: Starting worker discovery
21:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:08 DISPATCHER: Finished worker discovery
21:35:08 DISPATCHER: Starting worker discovery
21:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:08 DISPATCHER: Finished worker discovery
21:36:08 DISPATCHER: Starting worker discovery
21:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:08 DISPATCHER: Finished worker discovery
21:37:08 DISPATCHER: Starting worker discovery
21:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:08 DISPATCHER: Finished worker discovery
21:38:08 DISPATCHER: Starting worker discovery
21:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:08 DISPATCHER: Finished worker discovery
21:39:08 DISPATCHER: Starting worker discovery
21:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:08 DISPATCHER: Finished worker discovery
21:40:08 DISPATCHER: Starting worker discovery
21:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:08 DISPATCHER: Finished worker discovery
21:41:08 DISPATCHER: Starting worker discovery
21:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:08 DISPATCHER: Finished worker discovery
21:42:08 DISPATCHER: Starting worker discovery
21:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:08 DISPATCHER: Finished worker discovery
21:43:00 WORKER: done with job (7, 0, 1), trying to register it.
21:43:00 WORKER: registered result for job (7, 0, 1) with dispatcher
21:43:00 DISPATCHER: job (7, 0, 1) finished
21:43:00 DISPATCHER: register_result: lock acquired
21:43:00 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
21:43:00 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0061979846825943406, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011522944958915933, 'kernel_size_2': 7, 'num_filters_2': 61}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9191303533575854, 'info': {'number_mnist': 0.9191303533575854, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0061979846825943406, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011522944958915933, 'kernel_size_2': 7, 'num_filters_2': 61}"}}
exception: None

21:43:00 job_callback for (7, 0, 1) started
21:43:00 DISPATCHER: Trying to submit another job.
21:43:00 job_callback for (7, 0, 1) got condition
21:43:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:43:00 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:43:00 HBMASTER: Trying to run another job!
21:43:00 job_callback for (7, 0, 1) finished
21:43:00 start sampling a new configuration.
21:43:00 done sampling a new configuration.
21:43:00 HBMASTER: schedule new run for iteration 7
21:43:00 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
21:43:00 HBMASTER: submitting job (7, 0, 2) to dispatcher
21:43:00 DISPATCHER: trying to submit job (7, 0, 2)
21:43:00 DISPATCHER: trying to notify the job_runner thread.
21:43:00 HBMASTER: job (7, 0, 2) submitted to dispatcher
21:43:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:43:00 DISPATCHER: Trying to submit another job.
21:43:00 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
21:43:00 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
21:43:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:43:00 WORKER: start processing job (7, 0, 2)
21:43:00 WORKER: args: ()
21:43:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04479934522967783, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.03843116286614305, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 84, 'num_filters_3': 114, 'num_filters_4': 57}, 'budget': 1200.0, 'working_directory': '.'}
21:43:08 DISPATCHER: Starting worker discovery
21:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:08 DISPATCHER: Finished worker discovery
21:44:08 DISPATCHER: Starting worker discovery
21:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:08 DISPATCHER: Finished worker discovery
21:45:08 DISPATCHER: Starting worker discovery
21:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:08 DISPATCHER: Finished worker discovery
21:46:08 DISPATCHER: Starting worker discovery
21:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:08 DISPATCHER: Finished worker discovery
21:47:08 DISPATCHER: Starting worker discovery
21:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:08 DISPATCHER: Finished worker discovery
21:48:08 DISPATCHER: Starting worker discovery
21:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:08 DISPATCHER: Finished worker discovery
21:49:08 DISPATCHER: Starting worker discovery
21:49:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:09 DISPATCHER: Finished worker discovery
21:50:09 DISPATCHER: Starting worker discovery
21:50:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:09 DISPATCHER: Finished worker discovery
21:51:09 DISPATCHER: Starting worker discovery
21:51:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:09 DISPATCHER: Finished worker discovery
21:52:09 DISPATCHER: Starting worker discovery
21:52:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:09 DISPATCHER: Finished worker discovery
21:53:09 DISPATCHER: Starting worker discovery
21:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:09 DISPATCHER: Finished worker discovery
21:54:09 DISPATCHER: Starting worker discovery
21:54:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:09 DISPATCHER: Finished worker discovery
21:55:09 DISPATCHER: Starting worker discovery
21:55:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:09 DISPATCHER: Finished worker discovery
21:56:09 DISPATCHER: Starting worker discovery
21:56:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:09 DISPATCHER: Finished worker discovery
21:57:09 DISPATCHER: Starting worker discovery
21:57:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:09 DISPATCHER: Finished worker discovery
21:58:09 DISPATCHER: Starting worker discovery
21:58:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:09 DISPATCHER: Finished worker discovery
21:59:09 DISPATCHER: Starting worker discovery
21:59:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:09 DISPATCHER: Finished worker discovery
22:00:09 DISPATCHER: Starting worker discovery
22:00:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:09 DISPATCHER: Finished worker discovery
22:01:09 DISPATCHER: Starting worker discovery
22:01:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:09 DISPATCHER: Finished worker discovery
22:02:09 DISPATCHER: Starting worker discovery
22:02:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:09 DISPATCHER: Finished worker discovery
22:03:09 DISPATCHER: Starting worker discovery
22:03:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:09 DISPATCHER: Finished worker discovery
22:03:24 WORKER: done with job (7, 0, 2), trying to register it.
22:03:24 WORKER: registered result for job (7, 0, 2) with dispatcher
22:03:24 DISPATCHER: job (7, 0, 2) finished
22:03:24 DISPATCHER: register_result: lock acquired
22:03:24 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:03:24 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04479934522967783, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.03843116286614305, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 84, 'num_filters_3': 114, 'num_filters_4': 57}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04479934522967783, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.03843116286614305, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 84, 'num_filters_3': 114, 'num_filters_4': 57}"}}
exception: None

22:03:24 job_callback for (7, 0, 2) started
22:03:24 DISPATCHER: Trying to submit another job.
22:03:24 job_callback for (7, 0, 2) got condition
22:03:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:03:24 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:03:24 HBMASTER: Trying to run another job!
22:03:24 job_callback for (7, 0, 2) finished
22:03:24 start sampling a new configuration.
22:03:24 best_vector: [0, 2, 0.16137413866569295, 0.983247564366543, 0.4074212678462811, 0, 0.9803178416356977, 0.05532063994087989, 0, 2, 2, 1, 0.31581458532284473, 0.6129655277115262, 0.5225333763408064, 0.24536831896282582], 1.7502229091190396e-34, 57.13557940475947, nan
22:03:24 done sampling a new configuration.
22:03:24 HBMASTER: schedule new run for iteration 7
22:03:24 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
22:03:24 HBMASTER: submitting job (7, 0, 3) to dispatcher
22:03:24 DISPATCHER: trying to submit job (7, 0, 3)
22:03:24 DISPATCHER: trying to notify the job_runner thread.
22:03:24 HBMASTER: job (7, 0, 3) submitted to dispatcher
22:03:24 DISPATCHER: Trying to submit another job.
22:03:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:03:24 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:03:24 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:03:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:03:24 WORKER: start processing job (7, 0, 3)
22:03:24 WORKER: args: ()
22:03:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0021025594160341554, 'num_filters_1': 124, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.011802494641905751, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 57}, 'budget': 1200.0, 'working_directory': '.'}
22:04:09 DISPATCHER: Starting worker discovery
22:04:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:09 DISPATCHER: Finished worker discovery
22:05:09 DISPATCHER: Starting worker discovery
22:05:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:09 DISPATCHER: Finished worker discovery
22:06:09 DISPATCHER: Starting worker discovery
22:06:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:09 DISPATCHER: Finished worker discovery
22:07:09 DISPATCHER: Starting worker discovery
22:07:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:09 DISPATCHER: Finished worker discovery
22:08:09 DISPATCHER: Starting worker discovery
22:08:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:09 DISPATCHER: Finished worker discovery
22:09:09 DISPATCHER: Starting worker discovery
22:09:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:09 DISPATCHER: Finished worker discovery
22:10:09 DISPATCHER: Starting worker discovery
22:10:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:09 DISPATCHER: Finished worker discovery
22:11:09 DISPATCHER: Starting worker discovery
22:11:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:09 DISPATCHER: Finished worker discovery
22:12:09 DISPATCHER: Starting worker discovery
22:12:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:09 DISPATCHER: Finished worker discovery
22:13:09 DISPATCHER: Starting worker discovery
22:13:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:09 DISPATCHER: Finished worker discovery
22:14:09 DISPATCHER: Starting worker discovery
22:14:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:09 DISPATCHER: Finished worker discovery
22:15:09 DISPATCHER: Starting worker discovery
22:15:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:09 DISPATCHER: Finished worker discovery
22:16:09 DISPATCHER: Starting worker discovery
22:16:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:09 DISPATCHER: Finished worker discovery
22:17:09 DISPATCHER: Starting worker discovery
22:17:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:09 DISPATCHER: Finished worker discovery
22:18:09 DISPATCHER: Starting worker discovery
22:18:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:09 DISPATCHER: Finished worker discovery
22:19:09 DISPATCHER: Starting worker discovery
22:19:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:09 DISPATCHER: Finished worker discovery
22:20:09 DISPATCHER: Starting worker discovery
22:20:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:09 DISPATCHER: Finished worker discovery
22:21:09 DISPATCHER: Starting worker discovery
22:21:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:09 DISPATCHER: Finished worker discovery
22:22:09 DISPATCHER: Starting worker discovery
22:22:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:09 DISPATCHER: Finished worker discovery
22:23:09 DISPATCHER: Starting worker discovery
22:23:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:09 DISPATCHER: Finished worker discovery
22:23:48 WORKER: done with job (7, 0, 3), trying to register it.
22:23:48 WORKER: registered result for job (7, 0, 3) with dispatcher
22:23:48 DISPATCHER: job (7, 0, 3) finished
22:23:48 DISPATCHER: register_result: lock acquired
22:23:48 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:23:48 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0021025594160341554, 'num_filters_1': 124, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.011802494641905751, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 57}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9032652313692083, 'info': {'number_mnist': 0.9032652313692083, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0021025594160341554, 'num_filters_1': 124, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.011802494641905751, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 57}"}}
exception: None

22:23:48 job_callback for (7, 0, 3) started
22:23:48 job_callback for (7, 0, 3) got condition
22:23:48 DISPATCHER: Trying to submit another job.
22:23:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:48 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:23:48 HBMASTER: Trying to run another job!
22:23:48 job_callback for (7, 0, 3) finished
22:23:48 start sampling a new configuration.
22:23:48 best_vector: [1, 2, 0.5648659699237422, 0.7820865154088119, 0.4575640222975573, 1, 0.25686534243811776, 0.08887002039808686, 1, 2, 0, 1, 0.8137725707697296, 0.2799943834425779, 0.6147108768733962, 0.24611881478683964], 8.86387931053287e-34, 11.281742056344436, nan
22:23:48 done sampling a new configuration.
22:23:48 HBMASTER: schedule new run for iteration 8
22:23:48 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
22:23:48 HBMASTER: submitting job (8, 0, 0) to dispatcher
22:23:48 DISPATCHER: trying to submit job (8, 0, 0)
22:23:48 DISPATCHER: trying to notify the job_runner thread.
22:23:48 HBMASTER: job (8, 0, 0) submitted to dispatcher
22:23:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:48 DISPATCHER: Trying to submit another job.
22:23:48 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:23:48 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:23:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:48 WORKER: start processing job (8, 0, 0)
22:23:48 WORKER: args: ()
22:23:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013481305173702244, 'num_filters_1': 81, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.013050362109680785, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:24:09 DISPATCHER: Starting worker discovery
22:24:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:09 DISPATCHER: Finished worker discovery
22:24:42 WORKER: done with job (8, 0, 0), trying to register it.
22:24:42 WORKER: registered result for job (8, 0, 0) with dispatcher
22:24:42 DISPATCHER: job (8, 0, 0) finished
22:24:42 DISPATCHER: register_result: lock acquired
22:24:42 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:24:42 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013481305173702244, 'num_filters_1': 81, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.013050362109680785, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9175667776835493, 'info': {'number_mnist': 0.9175667776835493, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013481305173702244, 'num_filters_1': 81, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.013050362109680785, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 87, 'num_filters_3': 28}"}}
exception: None

22:24:42 job_callback for (8, 0, 0) started
22:24:42 DISPATCHER: Trying to submit another job.
22:24:42 job_callback for (8, 0, 0) got condition
22:24:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:42 HBMASTER: Trying to run another job!
22:24:42 job_callback for (8, 0, 0) finished
22:24:42 start sampling a new configuration.
22:24:42 done sampling a new configuration.
22:24:42 HBMASTER: schedule new run for iteration 8
22:24:42 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
22:24:42 HBMASTER: submitting job (8, 0, 1) to dispatcher
22:24:42 DISPATCHER: trying to submit job (8, 0, 1)
22:24:42 DISPATCHER: trying to notify the job_runner thread.
22:24:42 HBMASTER: job (8, 0, 1) submitted to dispatcher
22:24:42 DISPATCHER: Trying to submit another job.
22:24:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:24:42 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:24:42 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:24:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:24:42 WORKER: start processing job (8, 0, 1)
22:24:42 WORKER: args: ()
22:24:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020901212822748796, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.019394499828139965}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:25:09 DISPATCHER: Starting worker discovery
22:25:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:09 DISPATCHER: Finished worker discovery
22:25:38 WORKER: done with job (8, 0, 1), trying to register it.
22:25:38 WORKER: registered result for job (8, 0, 1) with dispatcher
22:25:38 DISPATCHER: job (8, 0, 1) finished
22:25:38 DISPATCHER: register_result: lock acquired
22:25:38 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:25:38 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020901212822748796, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.019394499828139965}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7886979387756448, 'info': {'number_mnist': 0.7886979387756448, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020901212822748796, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.019394499828139965}"}}
exception: None

22:25:38 job_callback for (8, 0, 1) started
22:25:38 DISPATCHER: Trying to submit another job.
22:25:38 job_callback for (8, 0, 1) got condition
22:25:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:25:38 HBMASTER: Trying to run another job!
22:25:38 job_callback for (8, 0, 1) finished
22:25:38 start sampling a new configuration.
22:25:38 best_vector: [2, 0, 0.6051696771843489, 0.5358843073080262, 0.7182787630550255, 1, 0.28730793947568317, 0.10883805058810965, 2, 2, 0, 1, 0.8852994457111938, 0.42564790460807067, 0.6124163165157079, 0.24388017554802224], 3.2882887127957413e-34, 30.41095497815301, nan
22:25:38 done sampling a new configuration.
22:25:38 HBMASTER: schedule new run for iteration 8
22:25:38 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
22:25:38 HBMASTER: submitting job (8, 0, 2) to dispatcher
22:25:38 DISPATCHER: trying to submit job (8, 0, 2)
22:25:38 DISPATCHER: trying to notify the job_runner thread.
22:25:38 HBMASTER: job (8, 0, 2) submitted to dispatcher
22:25:38 DISPATCHER: Trying to submit another job.
22:25:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:38 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:25:38 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:25:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:38 WORKER: start processing job (8, 0, 2)
22:25:38 WORKER: args: ()
22:25:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016230778625447487, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013854841713301267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 38, 'num_filters_4': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:26:09 DISPATCHER: Starting worker discovery
22:26:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:09 DISPATCHER: Finished worker discovery
22:26:31 WORKER: done with job (8, 0, 2), trying to register it.
22:26:31 WORKER: registered result for job (8, 0, 2) with dispatcher
22:26:31 DISPATCHER: job (8, 0, 2) finished
22:26:31 DISPATCHER: register_result: lock acquired
22:26:31 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:26:31 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016230778625447487, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013854841713301267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 38, 'num_filters_4': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9531888280243473, 'info': {'number_mnist': 0.9531888280243473, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016230778625447487, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013854841713301267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 38, 'num_filters_4': 57}"}}
exception: None

22:26:31 job_callback for (8, 0, 2) started
22:26:31 DISPATCHER: Trying to submit another job.
22:26:31 job_callback for (8, 0, 2) got condition
22:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:26:31 HBMASTER: Trying to run another job!
22:26:31 job_callback for (8, 0, 2) finished
22:26:31 start sampling a new configuration.
22:26:31 best_vector: [1, 2, 0.25358621082666594, 0.5746330601814065, 0.6172721202275488, 1, 0.6688654148862684, 0.024330131675880863, 1, 1, 0, 1, 0.4348368818180185, 0.8210213652092555, 0.4832110614007209, 0.2431470165770202], 1.0372474828755312e-34, 96.40900715687725, nan
22:26:31 done sampling a new configuration.
22:26:31 HBMASTER: schedule new run for iteration 8
22:26:31 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
22:26:31 HBMASTER: submitting job (8, 0, 3) to dispatcher
22:26:31 DISPATCHER: trying to submit job (8, 0, 3)
22:26:31 DISPATCHER: trying to notify the job_runner thread.
22:26:31 HBMASTER: job (8, 0, 3) submitted to dispatcher
22:26:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:26:31 DISPATCHER: Trying to submit another job.
22:26:31 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:26:31 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:26:31 WORKER: start processing job (8, 0, 3)
22:26:31 WORKER: args: ()
22:26:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0032149366650822816, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.010756085136966891, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 88, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:27:09 DISPATCHER: Starting worker discovery
22:27:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:09 DISPATCHER: Finished worker discovery
22:27:25 WORKER: done with job (8, 0, 3), trying to register it.
22:27:25 WORKER: registered result for job (8, 0, 3) with dispatcher
22:27:25 DISPATCHER: job (8, 0, 3) finished
22:27:25 DISPATCHER: register_result: lock acquired
22:27:25 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:27:25 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0032149366650822816, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.010756085136966891, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 88, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9071461461771572, 'info': {'number_mnist': 0.9071461461771572, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0032149366650822816, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.010756085136966891, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 88, 'num_filters_4': 43}"}}
exception: None

22:27:25 job_callback for (8, 0, 3) started
22:27:25 job_callback for (8, 0, 3) got condition
22:27:25 DISPATCHER: Trying to submit another job.
22:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:27:25 HBMASTER: Trying to run another job!
22:27:25 job_callback for (8, 0, 3) finished
22:27:25 start sampling a new configuration.
22:27:25 done sampling a new configuration.
22:27:25 HBMASTER: schedule new run for iteration 8
22:27:25 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
22:27:25 HBMASTER: submitting job (8, 0, 4) to dispatcher
22:27:25 DISPATCHER: trying to submit job (8, 0, 4)
22:27:25 DISPATCHER: trying to notify the job_runner thread.
22:27:25 HBMASTER: job (8, 0, 4) submitted to dispatcher
22:27:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:27:25 DISPATCHER: Trying to submit another job.
22:27:25 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:27:25 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:27:25 WORKER: start processing job (8, 0, 4)
22:27:25 WORKER: args: ()
22:27:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0015658434273654427, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.03665356535636981, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:28:09 DISPATCHER: Starting worker discovery
22:28:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:09 DISPATCHER: Finished worker discovery
22:28:20 WORKER: done with job (8, 0, 4), trying to register it.
22:28:20 WORKER: registered result for job (8, 0, 4) with dispatcher
22:28:20 DISPATCHER: job (8, 0, 4) finished
22:28:20 DISPATCHER: register_result: lock acquired
22:28:20 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:28:20 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0015658434273654427, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.03665356535636981, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4286946718354181, 'info': {'number_mnist': 0.4286946718354181, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0015658434273654427, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.03665356535636981, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 22}"}}
exception: None

22:28:20 job_callback for (8, 0, 4) started
22:28:20 DISPATCHER: Trying to submit another job.
22:28:20 job_callback for (8, 0, 4) got condition
22:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:28:20 HBMASTER: Trying to run another job!
22:28:20 job_callback for (8, 0, 4) finished
22:28:20 start sampling a new configuration.
22:28:20 done sampling a new configuration.
22:28:20 HBMASTER: schedule new run for iteration 8
22:28:20 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
22:28:20 HBMASTER: submitting job (8, 0, 5) to dispatcher
22:28:20 DISPATCHER: trying to submit job (8, 0, 5)
22:28:20 DISPATCHER: trying to notify the job_runner thread.
22:28:20 HBMASTER: job (8, 0, 5) submitted to dispatcher
22:28:20 DISPATCHER: Trying to submit another job.
22:28:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:28:20 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:28:20 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:28:20 WORKER: start processing job (8, 0, 5)
22:28:20 WORKER: args: ()
22:28:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00204580598699175, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.05939801691962122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 62, 'num_filters_3': 34, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:29:09 DISPATCHER: Starting worker discovery
22:29:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:09 DISPATCHER: Finished worker discovery
22:29:15 WORKER: done with job (8, 0, 5), trying to register it.
22:29:15 WORKER: registered result for job (8, 0, 5) with dispatcher
22:29:15 DISPATCHER: job (8, 0, 5) finished
22:29:15 DISPATCHER: register_result: lock acquired
22:29:15 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:29:15 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00204580598699175, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.05939801691962122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 62, 'num_filters_3': 34, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14569754966963433, 'info': {'number_mnist': 0.14569754966963433, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00204580598699175, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.05939801691962122, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 62, 'num_filters_3': 34, 'num_filters_4': 22}"}}
exception: None

22:29:15 job_callback for (8, 0, 5) started
22:29:15 DISPATCHER: Trying to submit another job.
22:29:15 job_callback for (8, 0, 5) got condition
22:29:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:29:15 HBMASTER: Trying to run another job!
22:29:15 job_callback for (8, 0, 5) finished
22:29:15 start sampling a new configuration.
22:29:15 best_vector: [1, 2, 0.8061803084924155, 0.44993882574581473, 0.4360526699576313, 0, 0.47096440444163584, 0.11677724125834613, 2, 2, 0, 1, 0.6742615320797751, 0.7583794323554861, 0.46966192654678274, 0.24373043214967674], 6.15454775567442e-34, 16.24814754387131, nan
22:29:15 done sampling a new configuration.
22:29:15 HBMASTER: schedule new run for iteration 8
22:29:15 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
22:29:15 HBMASTER: submitting job (8, 0, 6) to dispatcher
22:29:15 DISPATCHER: trying to submit job (8, 0, 6)
22:29:15 DISPATCHER: trying to notify the job_runner thread.
22:29:15 HBMASTER: job (8, 0, 6) submitted to dispatcher
22:29:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:29:15 DISPATCHER: Trying to submit another job.
22:29:15 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:29:15 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:29:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:29:15 WORKER: start processing job (8, 0, 6)
22:29:15 WORKER: args: ()
22:29:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.040960063097646646, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.014188310813349925, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 65, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:30:09 WORKER: done with job (8, 0, 6), trying to register it.
22:30:09 WORKER: registered result for job (8, 0, 6) with dispatcher
22:30:09 DISPATCHER: job (8, 0, 6) finished
22:30:09 DISPATCHER: register_result: lock acquired
22:30:09 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:30:09 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.040960063097646646, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.014188310813349925, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 65, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.040960063097646646, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.014188310813349925, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 65, 'num_filters_3': 77}"}}
exception: None

22:30:09 job_callback for (8, 0, 6) started
22:30:09 DISPATCHER: Trying to submit another job.
22:30:09 job_callback for (8, 0, 6) got condition
22:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:30:09 HBMASTER: Trying to run another job!
22:30:09 job_callback for (8, 0, 6) finished
22:30:09 start sampling a new configuration.
22:30:09 best_vector: [1, 2, 0.3004377323963899, 0.4350679600936873, 0.41332321198643396, 1, 0.27630456542526527, 0.0743352530070282, 0, 2, 1, 1, 0.9486123815049833, 0.03036005676427382, 0.48390578521130306, 0.2440104148917322], 1.3969044953801553e-34, 71.58685531524894, nan
22:30:09 done sampling a new configuration.
22:30:09 HBMASTER: schedule new run for iteration 8
22:30:09 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
22:30:09 HBMASTER: submitting job (8, 0, 7) to dispatcher
22:30:09 DISPATCHER: trying to submit job (8, 0, 7)
22:30:09 DISPATCHER: trying to notify the job_runner thread.
22:30:09 HBMASTER: job (8, 0, 7) submitted to dispatcher
22:30:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:30:09 DISPATCHER: Trying to submit another job.
22:30:09 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:30:09 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:30:09 WORKER: start processing job (8, 0, 7)
22:30:09 WORKER: args: ()
22:30:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003989104972133385, 'num_filters_1': 39, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.012494313358679855, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:30:09 DISPATCHER: Starting worker discovery
22:30:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:09 DISPATCHER: Finished worker discovery
22:31:03 WORKER: done with job (8, 0, 7), trying to register it.
22:31:03 WORKER: registered result for job (8, 0, 7) with dispatcher
22:31:03 DISPATCHER: job (8, 0, 7) finished
22:31:03 DISPATCHER: register_result: lock acquired
22:31:03 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:31:03 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003989104972133385, 'num_filters_1': 39, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.012494313358679855, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8768390679221065, 'info': {'number_mnist': 0.8768390679221065, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003989104972133385, 'num_filters_1': 39, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.012494313358679855, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 17}"}}
exception: None

22:31:03 job_callback for (8, 0, 7) started
22:31:03 DISPATCHER: Trying to submit another job.
22:31:03 job_callback for (8, 0, 7) got condition
22:31:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:31:03 HBMASTER: Trying to run another job!
22:31:03 job_callback for (8, 0, 7) finished
22:31:03 start sampling a new configuration.
22:31:03 best_vector: [2, 0, 0.4212878599653482, 0.8262445491294881, 0.7033146768695994, 1, 0.7716592107475703, 0.056789701333443035, 2, 2, 0, 1, 0.22424564853053852, 0.18722843972969566, 0.5406742989188659, 0.24468274594920758], 7.2801667747705055e-34, 13.73594906459438, nan
22:31:03 done sampling a new configuration.
22:31:03 HBMASTER: schedule new run for iteration 8
22:31:03 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
22:31:03 HBMASTER: submitting job (8, 0, 8) to dispatcher
22:31:03 DISPATCHER: trying to submit job (8, 0, 8)
22:31:03 DISPATCHER: trying to notify the job_runner thread.
22:31:03 HBMASTER: job (8, 0, 8) submitted to dispatcher
22:31:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:31:03 DISPATCHER: Trying to submit another job.
22:31:03 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:31:03 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:31:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:31:03 WORKER: start processing job (8, 0, 8)
22:31:03 WORKER: args: ()
22:31:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:31:09 DISPATCHER: Starting worker discovery
22:31:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:09 DISPATCHER: Finished worker discovery
22:31:57 WORKER: done with job (8, 0, 8), trying to register it.
22:31:57 WORKER: registered result for job (8, 0, 8) with dispatcher
22:31:57 DISPATCHER: job (8, 0, 8) finished
22:31:57 DISPATCHER: register_result: lock acquired
22:31:57 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:31:57 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.942235557076359, 'info': {'number_mnist': 0.942235557076359, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}"}}
exception: None

22:31:57 job_callback for (8, 0, 8) started
22:31:57 DISPATCHER: Trying to submit another job.
22:31:57 job_callback for (8, 0, 8) got condition
22:31:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:31:57 HBMASTER: Trying to run another job!
22:31:57 job_callback for (8, 0, 8) finished
22:31:57 start sampling a new configuration.
22:31:57 done sampling a new configuration.
22:31:57 HBMASTER: schedule new run for iteration 8
22:31:57 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
22:31:57 HBMASTER: submitting job (8, 0, 9) to dispatcher
22:31:57 DISPATCHER: trying to submit job (8, 0, 9)
22:31:57 DISPATCHER: trying to notify the job_runner thread.
22:31:57 HBMASTER: job (8, 0, 9) submitted to dispatcher
22:31:57 DISPATCHER: Trying to submit another job.
22:31:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:31:57 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:31:57 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:31:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:31:57 WORKER: start processing job (8, 0, 9)
22:31:57 WORKER: args: ()
22:31:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022588912374247113, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06141679147169816, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 47, 'num_filters_3': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:32:09 DISPATCHER: Starting worker discovery
22:32:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:09 DISPATCHER: Finished worker discovery
22:32:50 WORKER: done with job (8, 0, 9), trying to register it.
22:32:50 WORKER: registered result for job (8, 0, 9) with dispatcher
22:32:50 DISPATCHER: job (8, 0, 9) finished
22:32:50 DISPATCHER: register_result: lock acquired
22:32:50 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:32:50 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022588912374247113, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06141679147169816, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 47, 'num_filters_3': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8094440653944481, 'info': {'number_mnist': 0.8094440653944481, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022588912374247113, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06141679147169816, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 47, 'num_filters_3': 52}"}}
exception: None

22:32:50 job_callback for (8, 0, 9) started
22:32:50 job_callback for (8, 0, 9) got condition
22:32:50 DISPATCHER: Trying to submit another job.
22:32:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:32:50 HBMASTER: Trying to run another job!
22:32:50 job_callback for (8, 0, 9) finished
22:32:50 start sampling a new configuration.
22:32:50 best_vector: [2, 2, 0.386005134660594, 0.8351448418077823, 0.41792789307412875, 1, 0.44128941428360147, 0.07886446682763024, 1, 2, 1, 1, 0.6276070682665318, 0.48290211934216665, 0.5339228318186233, 0.24641777579677818], 6.4167548101377765e-34, 15.584201509774202, nan
22:32:50 done sampling a new configuration.
22:32:50 HBMASTER: schedule new run for iteration 8
22:32:50 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
22:32:50 HBMASTER: submitting job (8, 0, 10) to dispatcher
22:32:50 DISPATCHER: trying to submit job (8, 0, 10)
22:32:50 DISPATCHER: trying to notify the job_runner thread.
22:32:50 HBMASTER: job (8, 0, 10) submitted to dispatcher
22:32:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:32:50 DISPATCHER: Trying to submit another job.
22:32:50 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:32:50 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:32:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:32:50 WORKER: start processing job (8, 0, 10)
22:32:50 WORKER: args: ()
22:32:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005915756223989065, 'num_filters_1': 91, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012664995415936601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 58, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:33:09 DISPATCHER: Starting worker discovery
22:33:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:09 DISPATCHER: Finished worker discovery
22:33:44 WORKER: done with job (8, 0, 10), trying to register it.
22:33:44 WORKER: registered result for job (8, 0, 10) with dispatcher
22:33:44 DISPATCHER: job (8, 0, 10) finished
22:33:44 DISPATCHER: register_result: lock acquired
22:33:44 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:33:44 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005915756223989065, 'num_filters_1': 91, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012664995415936601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 58, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9235381600926481, 'info': {'number_mnist': 0.9235381600926481, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005915756223989065, 'num_filters_1': 91, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012664995415936601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 58, 'num_filters_3': 43}"}}
exception: None

22:33:44 job_callback for (8, 0, 10) started
22:33:44 job_callback for (8, 0, 10) got condition
22:33:44 DISPATCHER: Trying to submit another job.
22:33:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:33:44 HBMASTER: Trying to run another job!
22:33:44 job_callback for (8, 0, 10) finished
22:33:44 start sampling a new configuration.
22:33:44 best_vector: [2, 2, 0.7581146282764206, 0.5342749932930064, 0.4617175562643502, 1, 0.8727134360194122, 0.13405282573554494, 1, 2, 0, 1, 0.5943085464596514, 0.6813174689727073, 0.5730602662302294, 0.2440880214084845], 8.182039319502277e-35, 122.21891889671721, nan
22:33:44 done sampling a new configuration.
22:33:44 HBMASTER: schedule new run for iteration 8
22:33:44 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
22:33:44 HBMASTER: submitting job (8, 0, 11) to dispatcher
22:33:44 DISPATCHER: trying to submit job (8, 0, 11)
22:33:44 DISPATCHER: trying to notify the job_runner thread.
22:33:44 HBMASTER: job (8, 0, 11) submitted to dispatcher
22:33:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:33:44 DISPATCHER: Trying to submit another job.
22:33:44 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:33:44 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:33:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:33:44 WORKER: start processing job (8, 0, 11)
22:33:44 WORKER: args: ()
22:33:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03282685346707988, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.014941931713087064, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:34:09 DISPATCHER: Starting worker discovery
22:34:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:09 DISPATCHER: Finished worker discovery
22:34:39 WORKER: done with job (8, 0, 11), trying to register it.
22:34:39 WORKER: registered result for job (8, 0, 11) with dispatcher
22:34:39 DISPATCHER: job (8, 0, 11) finished
22:34:39 DISPATCHER: register_result: lock acquired
22:34:39 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:34:39 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03282685346707988, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.014941931713087064, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9188032977996317, 'info': {'number_mnist': 0.9188032977996317, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03282685346707988, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.014941931713087064, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 65}"}}
exception: None

22:34:39 job_callback for (8, 0, 11) started
22:34:39 job_callback for (8, 0, 11) got condition
22:34:39 DISPATCHER: Trying to submit another job.
22:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:34:39 HBMASTER: Trying to run another job!
22:34:39 job_callback for (8, 0, 11) finished
22:34:39 start sampling a new configuration.
22:34:39 done sampling a new configuration.
22:34:39 HBMASTER: schedule new run for iteration 8
22:34:39 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
22:34:39 HBMASTER: submitting job (8, 0, 12) to dispatcher
22:34:39 DISPATCHER: trying to submit job (8, 0, 12)
22:34:39 DISPATCHER: trying to notify the job_runner thread.
22:34:39 HBMASTER: job (8, 0, 12) submitted to dispatcher
22:34:39 DISPATCHER: Trying to submit another job.
22:34:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:34:39 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:34:39 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:34:39 WORKER: start processing job (8, 0, 12)
22:34:39 WORKER: args: ()
22:34:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07211053598586005, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.06328639405358472}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:35:09 DISPATCHER: Starting worker discovery
22:35:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:09 DISPATCHER: Finished worker discovery
22:35:33 WORKER: done with job (8, 0, 12), trying to register it.
22:35:33 WORKER: registered result for job (8, 0, 12) with dispatcher
22:35:33 DISPATCHER: job (8, 0, 12) finished
22:35:33 DISPATCHER: register_result: lock acquired
22:35:33 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:35:33 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07211053598586005, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.06328639405358472}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.014729453069090724, 'info': {'number_mnist': 0.014729453069090724, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07211053598586005, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.06328639405358472}"}}
exception: None

22:35:33 job_callback for (8, 0, 12) started
22:35:33 DISPATCHER: Trying to submit another job.
22:35:33 job_callback for (8, 0, 12) got condition
22:35:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:33 HBMASTER: Trying to run another job!
22:35:33 job_callback for (8, 0, 12) finished
22:35:33 start sampling a new configuration.
22:35:33 best_vector: [1, 2, 0.3644286124188361, 0.780697955299575, 0.2993797281884815, 1, 0.6958411722916122, 0.043057656491570985, 0, 1, 0, 1, 0.3030370394171876, 0.021398965037390416, 0.453723062491215, 0.2442064170011221], 2.0002963724776304e-34, 49.992591785854636, nan
22:35:33 done sampling a new configuration.
22:35:33 HBMASTER: schedule new run for iteration 8
22:35:33 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
22:35:33 HBMASTER: submitting job (8, 0, 13) to dispatcher
22:35:33 DISPATCHER: trying to submit job (8, 0, 13)
22:35:33 DISPATCHER: trying to notify the job_runner thread.
22:35:33 HBMASTER: job (8, 0, 13) submitted to dispatcher
22:35:33 DISPATCHER: Trying to submit another job.
22:35:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:33 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:35:33 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:35:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:33 WORKER: start processing job (8, 0, 13)
22:35:33 WORKER: args: ()
22:35:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005356205422624979, 'num_filters_1': 81, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.011376778498927466, 'kernel_size_2': 3, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:36:09 DISPATCHER: Starting worker discovery
22:36:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:09 DISPATCHER: Finished worker discovery
22:36:27 WORKER: done with job (8, 0, 13), trying to register it.
22:36:27 WORKER: registered result for job (8, 0, 13) with dispatcher
22:36:27 DISPATCHER: job (8, 0, 13) finished
22:36:27 DISPATCHER: register_result: lock acquired
22:36:27 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:36:27 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005356205422624979, 'num_filters_1': 81, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.011376778498927466, 'kernel_size_2': 3, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.881168395038741, 'info': {'number_mnist': 0.881168395038741, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005356205422624979, 'num_filters_1': 81, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.011376778498927466, 'kernel_size_2': 3, 'num_filters_2': 29}"}}
exception: None

22:36:27 job_callback for (8, 0, 13) started
22:36:27 DISPATCHER: Trying to submit another job.
22:36:27 job_callback for (8, 0, 13) got condition
22:36:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:36:27 HBMASTER: Trying to run another job!
22:36:27 job_callback for (8, 0, 13) finished
22:36:27 start sampling a new configuration.
22:36:27 best_vector: [1, 2, 0.6493466021513695, 0.7587859899919647, 0.721196609538986, 1, 0.6583865484609276, 0.08522387024665276, 0, 1, 0, 1, 0.4231568759379141, 0.49852469195243465, 0.5107596815932902, 0.24598064207315298], 6.821892778568894e-34, 14.658688320952788, nan
22:36:27 done sampling a new configuration.
22:36:27 HBMASTER: schedule new run for iteration 8
22:36:27 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:36:27 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:36:27 DISPATCHER: trying to submit job (8, 0, 14)
22:36:27 DISPATCHER: trying to notify the job_runner thread.
22:36:27 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:36:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:36:27 DISPATCHER: Trying to submit another job.
22:36:27 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:36:27 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:36:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:36:27 WORKER: start processing job (8, 0, 14)
22:36:27 WORKER: args: ()
22:36:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019892675777483174, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012908590133422942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:37:09 DISPATCHER: Starting worker discovery
22:37:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:09 DISPATCHER: Finished worker discovery
22:37:21 WORKER: done with job (8, 0, 14), trying to register it.
22:37:21 WORKER: registered result for job (8, 0, 14) with dispatcher
22:37:21 DISPATCHER: job (8, 0, 14) finished
22:37:21 DISPATCHER: register_result: lock acquired
22:37:21 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:37:21 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019892675777483174, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012908590133422942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9497179096113622, 'info': {'number_mnist': 0.9497179096113622, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019892675777483174, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012908590133422942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 44, 'num_filters_4': 46}"}}
exception: None

22:37:21 job_callback for (8, 0, 14) started
22:37:21 job_callback for (8, 0, 14) got condition
22:37:21 DISPATCHER: Trying to submit another job.
22:37:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:37:21 HBMASTER: Trying to run another job!
22:37:21 job_callback for (8, 0, 14) finished
22:37:21 start sampling a new configuration.
22:37:21 best_vector: [2, 1, 0.34375505217722735, 0.4394511519875331, 0.39947417345468333, 1, 0.27690341699244503, 0.1373875078723792, 0, 1, 0, 1, 0.47904863983231455, 0.48698800725749314, 0.35541280869295944, 0.24438727115250564], 7.16314673414817e-34, 13.960345042672346, nan
22:37:21 done sampling a new configuration.
22:37:21 HBMASTER: schedule new run for iteration 8
22:37:21 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
22:37:21 HBMASTER: submitting job (8, 0, 15) to dispatcher
22:37:21 DISPATCHER: trying to submit job (8, 0, 15)
22:37:21 DISPATCHER: trying to notify the job_runner thread.
22:37:21 HBMASTER: job (8, 0, 15) submitted to dispatcher
22:37:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:37:21 DISPATCHER: Trying to submit another job.
22:37:21 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:37:21 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:37:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:37:21 WORKER: start processing job (8, 0, 15)
22:37:21 WORKER: args: ()
22:37:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00486978855150305, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.015091946909582876, 'kernel_size_2': 3, 'num_filters_2': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:38:09 DISPATCHER: Starting worker discovery
22:38:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:09 DISPATCHER: Finished worker discovery
22:38:15 WORKER: done with job (8, 0, 15), trying to register it.
22:38:15 WORKER: registered result for job (8, 0, 15) with dispatcher
22:38:15 DISPATCHER: job (8, 0, 15) finished
22:38:15 DISPATCHER: register_result: lock acquired
22:38:15 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:38:15 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00486978855150305, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.015091946909582876, 'kernel_size_2': 3, 'num_filters_2': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8637211746614522, 'info': {'number_mnist': 0.8637211746614522, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00486978855150305, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.015091946909582876, 'kernel_size_2': 3, 'num_filters_2': 43}"}}
exception: None

22:38:15 job_callback for (8, 0, 15) started
22:38:15 job_callback for (8, 0, 15) got condition
22:38:15 DISPATCHER: Trying to submit another job.
22:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:38:15 HBMASTER: Trying to run another job!
22:38:15 job_callback for (8, 0, 15) finished
22:38:15 start sampling a new configuration.
22:38:15 best_vector: [1, 1, 0.45338836280618705, 0.615905319011512, 0.5638113917534422, 1, 0.5828211217618247, 0.11107606527243057, 1, 2, 0, 1, 0.24352101864549194, 0.06132928691801087, 0.5986286179690802, 0.24570766156406743], 1.1267366596478673e-34, 88.75188283236692, nan
22:38:15 done sampling a new configuration.
22:38:15 HBMASTER: schedule new run for iteration 8
22:38:15 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
22:38:15 HBMASTER: submitting job (8, 0, 16) to dispatcher
22:38:15 DISPATCHER: trying to submit job (8, 0, 16)
22:38:15 DISPATCHER: trying to notify the job_runner thread.
22:38:15 HBMASTER: job (8, 0, 16) submitted to dispatcher
22:38:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:38:15 DISPATCHER: Trying to submit another job.
22:38:15 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:38:15 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:38:15 WORKER: start processing job (8, 0, 16)
22:38:15 WORKER: args: ()
22:38:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.008068201306994155, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.013948043486258605, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:39:09 WORKER: done with job (8, 0, 16), trying to register it.
22:39:09 WORKER: registered result for job (8, 0, 16) with dispatcher
22:39:09 DISPATCHER: job (8, 0, 16) finished
22:39:09 DISPATCHER: register_result: lock acquired
22:39:09 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:39:09 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.008068201306994155, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.013948043486258605, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9128500591165948, 'info': {'number_mnist': 0.9128500591165948, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.008068201306994155, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.013948043486258605, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 18}"}}
exception: None

22:39:09 job_callback for (8, 0, 16) started
22:39:09 job_callback for (8, 0, 16) got condition
22:39:09 DISPATCHER: Trying to submit another job.
22:39:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:09 HBMASTER: Trying to run another job!
22:39:09 job_callback for (8, 0, 16) finished
22:39:09 start sampling a new configuration.
22:39:09 best_vector: [1, 2, 0.5449982151786577, 0.6125547812840282, 0.2893307494887935, 1, 0.4257356177941731, 0.07347061828728173, 1, 1, 0, 1, 0.3384179037420888, 0.4398242356090691, 0.5851295047923893, 0.24298873181029654], 2.3059398539425192e-34, 43.366265529010946, nan
22:39:09 done sampling a new configuration.
22:39:09 HBMASTER: schedule new run for iteration 8
22:39:09 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
22:39:09 HBMASTER: submitting job (8, 0, 17) to dispatcher
22:39:09 DISPATCHER: trying to submit job (8, 0, 17)
22:39:09 DISPATCHER: trying to notify the job_runner thread.
22:39:09 HBMASTER: job (8, 0, 17) submitted to dispatcher
22:39:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:09 DISPATCHER: Trying to submit another job.
22:39:09 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:39:09 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:39:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:09 WORKER: start processing job (8, 0, 17)
22:39:09 WORKER: args: ()
22:39:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012302586587753826, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.012461992288930426, 'kernel_size_2': 5, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:39:09 DISPATCHER: Starting worker discovery
22:39:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:09 DISPATCHER: Finished worker discovery
22:40:03 WORKER: done with job (8, 0, 17), trying to register it.
22:40:03 WORKER: registered result for job (8, 0, 17) with dispatcher
22:40:03 DISPATCHER: job (8, 0, 17) finished
22:40:03 DISPATCHER: register_result: lock acquired
22:40:03 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:40:03 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012302586587753826, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.012461992288930426, 'kernel_size_2': 5, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8916000774407881, 'info': {'number_mnist': 0.8916000774407881, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.012302586587753826, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.012461992288930426, 'kernel_size_2': 5, 'num_filters_2': 32}"}}
exception: None

22:40:03 job_callback for (8, 0, 17) started
22:40:03 job_callback for (8, 0, 17) got condition
22:40:03 DISPATCHER: Trying to submit another job.
22:40:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:40:03 HBMASTER: Trying to run another job!
22:40:03 job_callback for (8, 0, 17) finished
22:40:03 start sampling a new configuration.
22:40:03 done sampling a new configuration.
22:40:03 HBMASTER: schedule new run for iteration 8
22:40:03 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
22:40:03 HBMASTER: submitting job (8, 0, 18) to dispatcher
22:40:03 DISPATCHER: trying to submit job (8, 0, 18)
22:40:03 DISPATCHER: trying to notify the job_runner thread.
22:40:03 HBMASTER: job (8, 0, 18) submitted to dispatcher
22:40:03 DISPATCHER: Trying to submit another job.
22:40:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:40:03 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:40:03 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:40:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:40:03 WORKER: start processing job (8, 0, 18)
22:40:03 WORKER: args: ()
22:40:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001418980278657382, 'num_filters_1': 96, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.03431189048311556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 29, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:40:09 DISPATCHER: Starting worker discovery
22:40:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:09 DISPATCHER: Finished worker discovery
22:40:59 WORKER: done with job (8, 0, 18), trying to register it.
22:40:59 WORKER: registered result for job (8, 0, 18) with dispatcher
22:40:59 DISPATCHER: job (8, 0, 18) finished
22:40:59 DISPATCHER: register_result: lock acquired
22:40:59 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:40:59 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001418980278657382, 'num_filters_1': 96, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.03431189048311556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 29, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6212491897280723, 'info': {'number_mnist': 0.6212491897280723, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001418980278657382, 'num_filters_1': 96, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.03431189048311556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 29, 'num_filters_4': 54}"}}
exception: None

22:40:59 job_callback for (8, 0, 18) started
22:40:59 job_callback for (8, 0, 18) got condition
22:40:59 DISPATCHER: Trying to submit another job.
22:40:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:40:59 HBMASTER: Trying to run another job!
22:40:59 job_callback for (8, 0, 18) finished
22:40:59 start sampling a new configuration.
22:40:59 best_vector: [0, 2, 0.5551639138775089, 0.48987353979349546, 0.13826741647771246, 1, 0.2926728621241962, 0.0690849801833982, 2, 2, 0, 1, 0.8432530414407172, 0.19118461718421068, 0.572192014392383, 0.244348190351391], 6.391444691465133e-34, 15.645914942131284, nan
22:40:59 done sampling a new configuration.
22:40:59 HBMASTER: schedule new run for iteration 8
22:40:59 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
22:40:59 HBMASTER: submitting job (8, 0, 19) to dispatcher
22:40:59 DISPATCHER: trying to submit job (8, 0, 19)
22:40:59 DISPATCHER: trying to notify the job_runner thread.
22:40:59 HBMASTER: job (8, 0, 19) submitted to dispatcher
22:40:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:40:59 DISPATCHER: Trying to submit another job.
22:40:59 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:40:59 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:40:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:40:59 WORKER: start processing job (8, 0, 19)
22:40:59 WORKER: args: ()
22:40:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012892223556592173, 'num_filters_1': 44, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.012299335023013724}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:41:09 DISPATCHER: Starting worker discovery
22:41:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:09 DISPATCHER: Finished worker discovery
22:41:53 WORKER: done with job (8, 0, 19), trying to register it.
22:41:53 WORKER: registered result for job (8, 0, 19) with dispatcher
22:41:53 DISPATCHER: job (8, 0, 19) finished
22:41:53 DISPATCHER: register_result: lock acquired
22:41:53 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:41:53 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012892223556592173, 'num_filters_1': 44, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.012299335023013724}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8843790835870637, 'info': {'number_mnist': 0.8843790835870637, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012892223556592173, 'num_filters_1': 44, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.012299335023013724}"}}
exception: None

22:41:53 job_callback for (8, 0, 19) started
22:41:53 DISPATCHER: Trying to submit another job.
22:41:53 job_callback for (8, 0, 19) got condition
22:41:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:41:53 HBMASTER: Trying to run another job!
22:41:53 job_callback for (8, 0, 19) finished
22:41:53 start sampling a new configuration.
22:41:53 best_vector: [1, 2, 0.4079573091967359, 0.8286694481058843, 0.6358321576479962, 1, 0.7833195702971061, 0.031027603571200685, 0, 1, 0, 1, 0.1828390650970542, 0.7895228625081006, 0.486530436916643, 0.24561882771619795], 1.151219125274985e-34, 86.86443597444023, nan
22:41:53 done sampling a new configuration.
22:41:53 HBMASTER: schedule new run for iteration 8
22:41:53 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
22:41:53 HBMASTER: submitting job (8, 0, 20) to dispatcher
22:41:53 DISPATCHER: trying to submit job (8, 0, 20)
22:41:53 DISPATCHER: trying to notify the job_runner thread.
22:41:53 HBMASTER: job (8, 0, 20) submitted to dispatcher
22:41:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:41:53 DISPATCHER: Trying to submit another job.
22:41:53 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:41:53 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:41:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:41:53 WORKER: start processing job (8, 0, 20)
22:41:53 WORKER: args: ()
22:41:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:42:09 DISPATCHER: Starting worker discovery
22:42:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:09 DISPATCHER: Finished worker discovery
22:42:47 WORKER: done with job (8, 0, 20), trying to register it.
22:42:47 WORKER: registered result for job (8, 0, 20) with dispatcher
22:42:47 DISPATCHER: job (8, 0, 20) finished
22:42:47 DISPATCHER: register_result: lock acquired
22:42:47 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:42:47 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9326880440709067, 'info': {'number_mnist': 0.9326880440709067, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}"}}
exception: None

22:42:47 job_callback for (8, 0, 20) started
22:42:47 job_callback for (8, 0, 20) got condition
22:42:47 DISPATCHER: Trying to submit another job.
22:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:47 HBMASTER: Trying to run another job!
22:42:47 job_callback for (8, 0, 20) finished
22:42:47 start sampling a new configuration.
22:42:47 best_vector: [3, 0, 0.2584846659951983, 0.5047251621480711, 0.18817267840418245, 1, 0.4114340451049548, 0.008753701545624135, 0, 2, 0, 1, 0.8214711615916147, 0.673025815829199, 0.6423103520190832, 0.2435230576085926], 1.8170855165952879e-34, 55.033183131288254, nan
22:42:47 done sampling a new configuration.
22:42:47 HBMASTER: schedule new run for iteration 8
22:42:47 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
22:42:47 HBMASTER: submitting job (8, 0, 21) to dispatcher
22:42:47 DISPATCHER: trying to submit job (8, 0, 21)
22:42:47 DISPATCHER: trying to notify the job_runner thread.
22:42:47 HBMASTER: job (8, 0, 21) submitted to dispatcher
22:42:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:42:47 DISPATCHER: Trying to submit another job.
22:42:47 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:42:47 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:47 WORKER: start processing job (8, 0, 21)
22:42:47 WORKER: args: ()
22:42:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003288284096072017, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.010265706140871803}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:43:09 DISPATCHER: Starting worker discovery
22:43:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:09 DISPATCHER: Finished worker discovery
22:43:42 WORKER: done with job (8, 0, 21), trying to register it.
22:43:42 WORKER: registered result for job (8, 0, 21) with dispatcher
22:43:42 DISPATCHER: job (8, 0, 21) finished
22:43:42 DISPATCHER: register_result: lock acquired
22:43:42 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:43:42 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003288284096072017, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.010265706140871803}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.826703203764823, 'info': {'number_mnist': 0.826703203764823, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003288284096072017, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.010265706140871803}"}}
exception: None

22:43:42 job_callback for (8, 0, 21) started
22:43:42 job_callback for (8, 0, 21) got condition
22:43:42 DISPATCHER: Trying to submit another job.
22:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:43:42 HBMASTER: Trying to run another job!
22:43:42 job_callback for (8, 0, 21) finished
22:43:42 start sampling a new configuration.
22:43:42 best_vector: [3, 0, 0.6004067276009016, 0.5576796435360916, 0.4128543612758582, 1, 0.5160182793872781, 0.22193313481474308, 0, 1, 0, 1, 0.5086555801323572, 0.8131596665186067, 0.6123440888554542, 0.24582068638274307], 1.2134898780276748e-34, 82.40695024381523, nan
22:43:42 done sampling a new configuration.
22:43:42 HBMASTER: schedule new run for iteration 8
22:43:42 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
22:43:42 HBMASTER: submitting job (8, 0, 22) to dispatcher
22:43:42 DISPATCHER: trying to submit job (8, 0, 22)
22:43:42 DISPATCHER: trying to notify the job_runner thread.
22:43:42 HBMASTER: job (8, 0, 22) submitted to dispatcher
22:43:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:43:42 DISPATCHER: Trying to submit another job.
22:43:42 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:43:42 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:43:42 WORKER: start processing job (8, 0, 22)
22:43:42 WORKER: args: ()
22:43:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01587864558261719, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.019442032529034353, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:44:09 DISPATCHER: Starting worker discovery
22:44:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:09 DISPATCHER: Finished worker discovery
22:44:35 WORKER: done with job (8, 0, 22), trying to register it.
22:44:35 WORKER: registered result for job (8, 0, 22) with dispatcher
22:44:35 DISPATCHER: job (8, 0, 22) finished
22:44:35 DISPATCHER: register_result: lock acquired
22:44:35 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:44:35 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01587864558261719, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.019442032529034353, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9255717919632998, 'info': {'number_mnist': 0.9255717919632998, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01587864558261719, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.019442032529034353, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 87}"}}
exception: None

22:44:35 job_callback for (8, 0, 22) started
22:44:35 job_callback for (8, 0, 22) got condition
22:44:35 DISPATCHER: Trying to submit another job.
22:44:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:35 HBMASTER: Trying to run another job!
22:44:35 job_callback for (8, 0, 22) finished
22:44:35 start sampling a new configuration.
22:44:35 done sampling a new configuration.
22:44:35 HBMASTER: schedule new run for iteration 8
22:44:35 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
22:44:35 HBMASTER: submitting job (8, 0, 23) to dispatcher
22:44:35 DISPATCHER: trying to submit job (8, 0, 23)
22:44:35 DISPATCHER: trying to notify the job_runner thread.
22:44:35 HBMASTER: job (8, 0, 23) submitted to dispatcher
22:44:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:35 DISPATCHER: Trying to submit another job.
22:44:35 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:44:35 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:44:35 WORKER: start processing job (8, 0, 23)
22:44:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:35 WORKER: args: ()
22:44:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0017473803530491658, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.14388932936106374, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 19, 'num_filters_4': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:45:09 DISPATCHER: Starting worker discovery
22:45:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:09 DISPATCHER: Finished worker discovery
22:45:30 WORKER: done with job (8, 0, 23), trying to register it.
22:45:30 WORKER: registered result for job (8, 0, 23) with dispatcher
22:45:30 DISPATCHER: job (8, 0, 23) finished
22:45:30 DISPATCHER: register_result: lock acquired
22:45:30 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:45:30 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0017473803530491658, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.14388932936106374, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 19, 'num_filters_4': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05373779696394587, 'info': {'number_mnist': 0.05373779696394587, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0017473803530491658, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.14388932936106374, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 19, 'num_filters_4': 59}"}}
exception: None

22:45:30 job_callback for (8, 0, 23) started
22:45:30 job_callback for (8, 0, 23) got condition
22:45:30 DISPATCHER: Trying to submit another job.
22:45:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:30 HBMASTER: Trying to run another job!
22:45:30 job_callback for (8, 0, 23) finished
22:45:30 start sampling a new configuration.
22:45:30 best_vector: [2, 1, 0.6004589181703066, 0.48407716980872706, 0.13112665507936996, 1, 0.5941352931883974, 0.05668369600884278, 1, 2, 0, 1, 0.9699663013175792, 0.6662858899206529, 0.5729593544680781, 0.24517904689079206], 1.4396361585378932e-34, 69.46199524577159, nan
22:45:30 done sampling a new configuration.
22:45:30 HBMASTER: schedule new run for iteration 8
22:45:30 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
22:45:30 HBMASTER: submitting job (8, 0, 24) to dispatcher
22:45:30 DISPATCHER: trying to submit job (8, 0, 24)
22:45:30 DISPATCHER: trying to notify the job_runner thread.
22:45:30 HBMASTER: job (8, 0, 24) submitted to dispatcher
22:45:30 DISPATCHER: Trying to submit another job.
22:45:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:30 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:45:30 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:45:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:30 WORKER: start processing job (8, 0, 24)
22:45:30 WORKER: args: ()
22:45:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01588246241744367, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011850786900857368}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:46:09 DISPATCHER: Starting worker discovery
22:46:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:09 DISPATCHER: Finished worker discovery
22:46:23 WORKER: done with job (8, 0, 24), trying to register it.
22:46:23 WORKER: registered result for job (8, 0, 24) with dispatcher
22:46:23 DISPATCHER: job (8, 0, 24) finished
22:46:23 DISPATCHER: register_result: lock acquired
22:46:23 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:46:23 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01588246241744367, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011850786900857368}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8922817910900877, 'info': {'number_mnist': 0.8922817910900877, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01588246241744367, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011850786900857368}"}}
exception: None

22:46:23 job_callback for (8, 0, 24) started
22:46:23 DISPATCHER: Trying to submit another job.
22:46:23 job_callback for (8, 0, 24) got condition
22:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:23 HBMASTER: Trying to run another job!
22:46:23 job_callback for (8, 0, 24) finished
22:46:23 start sampling a new configuration.
22:46:23 best_vector: [1, 1, 0.5819746153503702, 0.627651105065698, 0.504620006318044, 1, 0.3640755155808545, 0.19169501634127806, 1, 2, 2, 1, 0.7547899318816489, 0.7442882909804209, 0.48217381817339094, 0.2452899962669357], 2.170599772612236e-34, 46.070215827791095, nan
22:46:23 done sampling a new configuration.
22:46:23 HBMASTER: schedule new run for iteration 8
22:46:23 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
22:46:23 HBMASTER: submitting job (8, 0, 25) to dispatcher
22:46:23 DISPATCHER: trying to submit job (8, 0, 25)
22:46:23 DISPATCHER: trying to notify the job_runner thread.
22:46:23 HBMASTER: job (8, 0, 25) submitted to dispatcher
22:46:23 DISPATCHER: Trying to submit another job.
22:46:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:23 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:46:23 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:23 WORKER: start processing job (8, 0, 25)
22:46:23 WORKER: args: ()
22:46:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:09 DISPATCHER: Starting worker discovery
22:47:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:09 DISPATCHER: Finished worker discovery
22:47:17 WORKER: done with job (8, 0, 25), trying to register it.
22:47:17 WORKER: registered result for job (8, 0, 25) with dispatcher
22:47:17 DISPATCHER: job (8, 0, 25) finished
22:47:17 DISPATCHER: register_result: lock acquired
22:47:17 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:47:17 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9341418541247979, 'info': {'number_mnist': 0.9341418541247979, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}"}}
exception: None

22:47:17 job_callback for (8, 0, 25) started
22:47:17 job_callback for (8, 0, 25) got condition
22:47:17 DISPATCHER: Trying to submit another job.
22:47:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:47:17 HBMASTER: Trying to run another job!
22:47:17 job_callback for (8, 0, 25) finished
22:47:17 start sampling a new configuration.
22:47:18 best_vector: [3, 2, 0.552232652863125, 0.3980214026752669, 0.3449413323386251, 1, 0.3606040382159968, 0.022710270905315376, 0, 1, 0, 1, 0.5257348608158721, 0.6890328674280296, 0.4525976765297398, 0.24480719603156892], 8.53473611137383e-35, 117.16823894148858, nan
22:47:18 done sampling a new configuration.
22:47:18 HBMASTER: schedule new run for iteration 8
22:47:18 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
22:47:18 HBMASTER: submitting job (8, 0, 26) to dispatcher
22:47:18 DISPATCHER: trying to submit job (8, 0, 26)
22:47:18 DISPATCHER: trying to notify the job_runner thread.
22:47:18 HBMASTER: job (8, 0, 26) submitted to dispatcher
22:47:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:47:18 DISPATCHER: Trying to submit another job.
22:47:18 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:47:18 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:47:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:47:18 WORKER: start processing job (8, 0, 26)
22:47:18 WORKER: args: ()
22:47:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012719361354785184, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010704015853710223, 'kernel_size_2': 3, 'num_filters_2': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:09 DISPATCHER: Starting worker discovery
22:48:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:09 DISPATCHER: Finished worker discovery
22:48:12 WORKER: done with job (8, 0, 26), trying to register it.
22:48:12 WORKER: registered result for job (8, 0, 26) with dispatcher
22:48:12 DISPATCHER: job (8, 0, 26) finished
22:48:12 DISPATCHER: register_result: lock acquired
22:48:12 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:48:12 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012719361354785184, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010704015853710223, 'kernel_size_2': 3, 'num_filters_2': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9193056855136439, 'info': {'number_mnist': 0.9193056855136439, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012719361354785184, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010704015853710223, 'kernel_size_2': 3, 'num_filters_2': 47}"}}
exception: None

22:48:12 job_callback for (8, 0, 26) started
22:48:12 job_callback for (8, 0, 26) got condition
22:48:12 DISPATCHER: Trying to submit another job.
22:48:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:12 HBMASTER: Trying to run another job!
22:48:12 job_callback for (8, 0, 26) finished
22:48:12 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
22:48:12 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
22:48:12 HBMASTER: schedule new run for iteration 8
22:48:12 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
22:48:12 HBMASTER: submitting job (8, 0, 2) to dispatcher
22:48:12 DISPATCHER: trying to submit job (8, 0, 2)
22:48:12 DISPATCHER: trying to notify the job_runner thread.
22:48:12 HBMASTER: job (8, 0, 2) submitted to dispatcher
22:48:12 DISPATCHER: Trying to submit another job.
22:48:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:12 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:48:12 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:48:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:12 WORKER: start processing job (8, 0, 2)
22:48:12 WORKER: args: ()
22:48:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016230778625447487, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013854841713301267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 38, 'num_filters_4': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:49:09 DISPATCHER: Starting worker discovery
22:49:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:09 DISPATCHER: Finished worker discovery
22:50:09 DISPATCHER: Starting worker discovery
22:50:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:09 DISPATCHER: Finished worker discovery
22:50:37 WORKER: done with job (8, 0, 2), trying to register it.
22:50:37 WORKER: registered result for job (8, 0, 2) with dispatcher
22:50:37 DISPATCHER: job (8, 0, 2) finished
22:50:37 DISPATCHER: register_result: lock acquired
22:50:37 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:50:37 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016230778625447487, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013854841713301267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 38, 'num_filters_4': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9107303695091189, 'info': {'number_mnist': 0.9107303695091189, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016230778625447487, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013854841713301267, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 101, 'num_filters_3': 38, 'num_filters_4': 57}"}}
exception: None

22:50:37 job_callback for (8, 0, 2) started
22:50:37 job_callback for (8, 0, 2) got condition
22:50:37 DISPATCHER: Trying to submit another job.
22:50:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:50:37 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.955368





22:50:37 HBMASTER: Trying to run another job!
22:50:37 job_callback for (8, 0, 2) finished
22:50:37 HBMASTER: schedule new run for iteration 8
22:50:37 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
22:50:37 HBMASTER: submitting job (8, 0, 8) to dispatcher
22:50:37 DISPATCHER: trying to submit job (8, 0, 8)
22:50:37 DISPATCHER: trying to notify the job_runner thread.
22:50:37 HBMASTER: job (8, 0, 8) submitted to dispatcher
22:50:37 DISPATCHER: Trying to submit another job.
22:50:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:50:37 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:50:37 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:50:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:50:37 WORKER: start processing job (8, 0, 8)
22:50:37 WORKER: args: ()
22:50:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:51:09 DISPATCHER: Starting worker discovery
22:51:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:09 DISPATCHER: Finished worker discovery
22:52:09 DISPATCHER: Starting worker discovery
22:52:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:09 DISPATCHER: Finished worker discovery
22:53:01 WORKER: done with job (8, 0, 8), trying to register it.
22:53:01 WORKER: registered result for job (8, 0, 8) with dispatcher
22:53:01 DISPATCHER: job (8, 0, 8) finished
22:53:01 DISPATCHER: register_result: lock acquired
22:53:01 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:53:01 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9394819985512841, 'info': {'number_mnist': 0.9394819985512841, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}"}}
exception: None

22:53:01 job_callback for (8, 0, 8) started
22:53:01 job_callback for (8, 0, 8) got condition
22:53:01 DISPATCHER: Trying to submit another job.
22:53:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:01 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.955368





22:53:01 HBMASTER: Trying to run another job!
22:53:01 job_callback for (8, 0, 8) finished
22:53:01 HBMASTER: schedule new run for iteration 8
22:53:01 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
22:53:01 HBMASTER: submitting job (8, 0, 10) to dispatcher
22:53:01 DISPATCHER: trying to submit job (8, 0, 10)
22:53:01 DISPATCHER: trying to notify the job_runner thread.
22:53:01 HBMASTER: job (8, 0, 10) submitted to dispatcher
22:53:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:01 DISPATCHER: Trying to submit another job.
22:53:01 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:53:01 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:53:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:01 WORKER: start processing job (8, 0, 10)
22:53:01 WORKER: args: ()
22:53:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005915756223989065, 'num_filters_1': 91, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012664995415936601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 58, 'num_filters_3': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:53:09 DISPATCHER: Starting worker discovery
22:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:09 DISPATCHER: Finished worker discovery
22:54:09 DISPATCHER: Starting worker discovery
22:54:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:10 DISPATCHER: Finished worker discovery
22:55:10 DISPATCHER: Starting worker discovery
22:55:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:10 DISPATCHER: Finished worker discovery
22:55:25 WORKER: done with job (8, 0, 10), trying to register it.
22:55:25 WORKER: registered result for job (8, 0, 10) with dispatcher
22:55:25 DISPATCHER: job (8, 0, 10) finished
22:55:25 DISPATCHER: register_result: lock acquired
22:55:25 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:55:25 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005915756223989065, 'num_filters_1': 91, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012664995415936601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 58, 'num_filters_3': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9305944951327589, 'info': {'number_mnist': 0.9305944951327589, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005915756223989065, 'num_filters_1': 91, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.012664995415936601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 58, 'num_filters_3': 43}"}}
exception: None

22:55:25 job_callback for (8, 0, 10) started
22:55:25 DISPATCHER: Trying to submit another job.
22:55:25 job_callback for (8, 0, 10) got condition
22:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:25 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.955368





22:55:25 HBMASTER: Trying to run another job!
22:55:25 job_callback for (8, 0, 10) finished
22:55:25 HBMASTER: schedule new run for iteration 8
22:55:25 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
22:55:25 HBMASTER: submitting job (8, 0, 11) to dispatcher
22:55:25 DISPATCHER: trying to submit job (8, 0, 11)
22:55:25 DISPATCHER: trying to notify the job_runner thread.
22:55:25 HBMASTER: job (8, 0, 11) submitted to dispatcher
22:55:25 DISPATCHER: Trying to submit another job.
22:55:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:25 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:55:25 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:25 WORKER: start processing job (8, 0, 11)
22:55:25 WORKER: args: ()
22:55:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03282685346707988, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.014941931713087064, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:56:10 DISPATCHER: Starting worker discovery
22:56:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:10 DISPATCHER: Finished worker discovery
22:57:10 DISPATCHER: Starting worker discovery
22:57:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:10 DISPATCHER: Finished worker discovery
22:57:50 WORKER: done with job (8, 0, 11), trying to register it.
22:57:50 WORKER: registered result for job (8, 0, 11) with dispatcher
22:57:50 DISPATCHER: job (8, 0, 11) finished
22:57:50 DISPATCHER: register_result: lock acquired
22:57:50 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
22:57:50 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03282685346707988, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.014941931713087064, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9155909251693486, 'info': {'number_mnist': 0.9155909251693486, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03282685346707988, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.014941931713087064, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 65}"}}
exception: None

22:57:50 job_callback for (8, 0, 11) started
22:57:50 job_callback for (8, 0, 11) got condition
22:57:50 DISPATCHER: Trying to submit another job.
22:57:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:57:50 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.955368





22:57:50 HBMASTER: Trying to run another job!
22:57:50 job_callback for (8, 0, 11) finished
22:57:50 HBMASTER: schedule new run for iteration 8
22:57:50 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:57:50 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:57:50 DISPATCHER: trying to submit job (8, 0, 14)
22:57:50 DISPATCHER: trying to notify the job_runner thread.
22:57:50 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:57:50 DISPATCHER: Trying to submit another job.
22:57:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:57:50 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376
22:57:50 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
22:57:50 WORKER: start processing job (8, 0, 14)
22:57:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:57:50 WORKER: args: ()
22:57:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019892675777483174, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012908590133422942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:58:10 DISPATCHER: Starting worker discovery
22:58:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:10 DISPATCHER: Finished worker discovery
22:59:10 DISPATCHER: Starting worker discovery
22:59:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:10 DISPATCHER: Finished worker discovery
23:00:10 DISPATCHER: Starting worker discovery
23:00:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:10 DISPATCHER: Finished worker discovery
23:00:13 WORKER: done with job (8, 0, 14), trying to register it.
23:00:13 WORKER: registered result for job (8, 0, 14) with dispatcher
23:00:13 DISPATCHER: job (8, 0, 14) finished
23:00:13 DISPATCHER: register_result: lock acquired
23:00:13 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:00:13 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019892675777483174, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012908590133422942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 44, 'num_filters_4': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9329034988151457, 'info': {'number_mnist': 0.9329034988151457, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019892675777483174, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012908590133422942, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 44, 'num_filters_4': 46}"}}
exception: None

23:00:13 job_callback for (8, 0, 14) started
23:00:13 DISPATCHER: Trying to submit another job.
23:00:13 job_callback for (8, 0, 14) got condition
23:00:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:13 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.955368





23:00:13 HBMASTER: Trying to run another job!
23:00:13 job_callback for (8, 0, 14) finished
23:00:13 HBMASTER: schedule new run for iteration 8
23:00:13 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:00:13 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:00:13 DISPATCHER: trying to submit job (8, 0, 20)
23:00:13 DISPATCHER: trying to notify the job_runner thread.
23:00:13 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:00:13 DISPATCHER: Trying to submit another job.
23:00:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:13 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:00:13 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:00:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:13 WORKER: start processing job (8, 0, 20)
23:00:13 WORKER: args: ()
23:00:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:01:10 DISPATCHER: Starting worker discovery
23:01:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:10 DISPATCHER: Finished worker discovery
23:02:10 DISPATCHER: Starting worker discovery
23:02:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:10 DISPATCHER: Finished worker discovery
23:02:36 WORKER: done with job (8, 0, 20), trying to register it.
23:02:36 WORKER: registered result for job (8, 0, 20) with dispatcher
23:02:36 DISPATCHER: job (8, 0, 20) finished
23:02:36 DISPATCHER: register_result: lock acquired
23:02:36 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:02:36 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9416795435962239, 'info': {'number_mnist': 0.9416795435962239, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}"}}
exception: None

23:02:36 job_callback for (8, 0, 20) started
23:02:36 DISPATCHER: Trying to submit another job.
23:02:36 job_callback for (8, 0, 20) got condition
23:02:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:36 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.955368





23:02:36 HBMASTER: Trying to run another job!
23:02:36 job_callback for (8, 0, 20) finished
23:02:36 HBMASTER: schedule new run for iteration 8
23:02:36 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
23:02:36 HBMASTER: submitting job (8, 0, 22) to dispatcher
23:02:37 DISPATCHER: trying to submit job (8, 0, 22)
23:02:37 DISPATCHER: trying to notify the job_runner thread.
23:02:37 HBMASTER: job (8, 0, 22) submitted to dispatcher
23:02:37 DISPATCHER: Trying to submit another job.
23:02:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:37 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:02:37 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:37 WORKER: start processing job (8, 0, 22)
23:02:37 WORKER: args: ()
23:02:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01587864558261719, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.019442032529034353, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:03:10 DISPATCHER: Starting worker discovery
23:03:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:10 DISPATCHER: Finished worker discovery
23:04:10 DISPATCHER: Starting worker discovery
23:04:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:10 DISPATCHER: Finished worker discovery
23:05:01 WORKER: done with job (8, 0, 22), trying to register it.
23:05:01 WORKER: registered result for job (8, 0, 22) with dispatcher
23:05:01 DISPATCHER: job (8, 0, 22) finished
23:05:01 DISPATCHER: register_result: lock acquired
23:05:01 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:05:01 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01587864558261719, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.019442032529034353, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.93019345672721, 'info': {'number_mnist': 0.93019345672721, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01587864558261719, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.019442032529034353, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 87}"}}
exception: None

23:05:01 job_callback for (8, 0, 22) started
23:05:01 DISPATCHER: Trying to submit another job.
23:05:01 job_callback for (8, 0, 22) got condition
23:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:01 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.955368





23:05:01 HBMASTER: Trying to run another job!
23:05:01 job_callback for (8, 0, 22) finished
23:05:01 HBMASTER: schedule new run for iteration 8
23:05:01 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
23:05:01 HBMASTER: submitting job (8, 0, 25) to dispatcher
23:05:01 DISPATCHER: trying to submit job (8, 0, 25)
23:05:01 DISPATCHER: trying to notify the job_runner thread.
23:05:01 HBMASTER: job (8, 0, 25) submitted to dispatcher
23:05:01 DISPATCHER: Trying to submit another job.
23:05:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:01 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:05:01 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:01 WORKER: start processing job (8, 0, 25)
23:05:01 WORKER: args: ()
23:05:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:05:10 DISPATCHER: Starting worker discovery
23:05:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:10 DISPATCHER: Finished worker discovery
23:06:10 DISPATCHER: Starting worker discovery
23:06:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:10 DISPATCHER: Finished worker discovery
23:07:10 DISPATCHER: Starting worker discovery
23:07:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:10 DISPATCHER: Finished worker discovery
23:07:26 WORKER: done with job (8, 0, 25), trying to register it.
23:07:26 WORKER: registered result for job (8, 0, 25) with dispatcher
23:07:26 DISPATCHER: job (8, 0, 25) finished
23:07:26 DISPATCHER: register_result: lock acquired
23:07:26 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:07:26 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9345851498926792, 'info': {'number_mnist': 0.9345851498926792, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}"}}
exception: None

23:07:26 job_callback for (8, 0, 25) started
23:07:26 job_callback for (8, 0, 25) got condition
23:07:26 DISPATCHER: Trying to submit another job.
23:07:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:26 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.955368





23:07:26 HBMASTER: Trying to run another job!
23:07:26 job_callback for (8, 0, 25) finished
23:07:26 HBMASTER: schedule new run for iteration 8
23:07:26 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
23:07:26 HBMASTER: submitting job (8, 0, 26) to dispatcher
23:07:26 DISPATCHER: trying to submit job (8, 0, 26)
23:07:26 DISPATCHER: trying to notify the job_runner thread.
23:07:26 HBMASTER: job (8, 0, 26) submitted to dispatcher
23:07:26 DISPATCHER: Trying to submit another job.
23:07:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:26 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:07:26 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:07:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:26 WORKER: start processing job (8, 0, 26)
23:07:26 WORKER: args: ()
23:07:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012719361354785184, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010704015853710223, 'kernel_size_2': 3, 'num_filters_2': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:08:10 DISPATCHER: Starting worker discovery
23:08:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:10 DISPATCHER: Finished worker discovery
23:09:10 DISPATCHER: Starting worker discovery
23:09:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:10 DISPATCHER: Finished worker discovery
23:09:52 WORKER: done with job (8, 0, 26), trying to register it.
23:09:52 WORKER: registered result for job (8, 0, 26) with dispatcher
23:09:52 DISPATCHER: job (8, 0, 26) finished
23:09:52 DISPATCHER: register_result: lock acquired
23:09:52 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:09:52 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012719361354785184, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010704015853710223, 'kernel_size_2': 3, 'num_filters_2': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9217952206242466, 'info': {'number_mnist': 0.9217952206242466, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012719361354785184, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010704015853710223, 'kernel_size_2': 3, 'num_filters_2': 47}"}}
exception: None

23:09:52 job_callback for (8, 0, 26) started
23:09:52 DISPATCHER: Trying to submit another job.
23:09:52 job_callback for (8, 0, 26) got condition
23:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:53 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.955368





23:09:53 HBMASTER: Trying to run another job!
23:09:53 job_callback for (8, 0, 26) finished
23:09:53 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
23:09:53 ITERATION: Advancing config (8, 0, 20) to next budget 400.000000
23:09:53 ITERATION: Advancing config (8, 0, 25) to next budget 400.000000
23:09:53 HBMASTER: schedule new run for iteration 8
23:09:53 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
23:09:53 HBMASTER: submitting job (8, 0, 8) to dispatcher
23:09:53 DISPATCHER: trying to submit job (8, 0, 8)
23:09:53 DISPATCHER: trying to notify the job_runner thread.
23:09:53 HBMASTER: job (8, 0, 8) submitted to dispatcher
23:09:53 DISPATCHER: Trying to submit another job.
23:09:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:53 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:09:53 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:53 WORKER: start processing job (8, 0, 8)
23:09:53 WORKER: args: ()
23:09:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 400.0, 'working_directory': '.'}
23:10:10 DISPATCHER: Starting worker discovery
23:10:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:10 DISPATCHER: Finished worker discovery
23:11:10 DISPATCHER: Starting worker discovery
23:11:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:10 DISPATCHER: Finished worker discovery
23:12:10 DISPATCHER: Starting worker discovery
23:12:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:10 DISPATCHER: Finished worker discovery
23:13:10 DISPATCHER: Starting worker discovery
23:13:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:10 DISPATCHER: Finished worker discovery
23:14:10 DISPATCHER: Starting worker discovery
23:14:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:10 DISPATCHER: Finished worker discovery
23:15:10 DISPATCHER: Starting worker discovery
23:15:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:10 DISPATCHER: Finished worker discovery
23:16:10 DISPATCHER: Starting worker discovery
23:16:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:10 DISPATCHER: Finished worker discovery
23:16:45 WORKER: done with job (8, 0, 8), trying to register it.
23:16:45 WORKER: registered result for job (8, 0, 8) with dispatcher
23:16:45 DISPATCHER: job (8, 0, 8) finished
23:16:45 DISPATCHER: register_result: lock acquired
23:16:45 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:16:45 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9502831157242645, 'info': {'number_mnist': 0.9502831157242645, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}"}}
exception: None

23:16:45 job_callback for (8, 0, 8) started
23:16:45 job_callback for (8, 0, 8) got condition
23:16:45 DISPATCHER: Trying to submit another job.
23:16:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:16:45 HBMASTER: Trying to run another job!
23:16:45 job_callback for (8, 0, 8) finished
23:16:45 HBMASTER: schedule new run for iteration 8
23:16:45 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:16:45 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:16:45 DISPATCHER: trying to submit job (8, 0, 20)
23:16:45 DISPATCHER: trying to notify the job_runner thread.
23:16:45 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:16:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:16:45 DISPATCHER: Trying to submit another job.
23:16:45 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:16:45 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:16:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:16:45 WORKER: start processing job (8, 0, 20)
23:16:45 WORKER: args: ()
23:16:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}, 'budget': 400.0, 'working_directory': '.'}
23:17:10 DISPATCHER: Starting worker discovery
23:17:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:10 DISPATCHER: Finished worker discovery
23:18:10 DISPATCHER: Starting worker discovery
23:18:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:10 DISPATCHER: Finished worker discovery
23:19:10 DISPATCHER: Starting worker discovery
23:19:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:10 DISPATCHER: Finished worker discovery
23:20:10 DISPATCHER: Starting worker discovery
23:20:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:10 DISPATCHER: Finished worker discovery
23:21:10 DISPATCHER: Starting worker discovery
23:21:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:10 DISPATCHER: Finished worker discovery
23:22:10 DISPATCHER: Starting worker discovery
23:22:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:10 DISPATCHER: Finished worker discovery
23:23:10 DISPATCHER: Starting worker discovery
23:23:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:10 DISPATCHER: Finished worker discovery
23:23:39 WORKER: done with job (8, 0, 20), trying to register it.
23:23:39 WORKER: registered result for job (8, 0, 20) with dispatcher
23:23:39 DISPATCHER: job (8, 0, 20) finished
23:23:39 DISPATCHER: register_result: lock acquired
23:23:39 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:23:39 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.941674930147721, 'info': {'number_mnist': 0.941674930147721, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545074862837612, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.010974072952613096, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 82, 'num_filters_4': 43}"}}
exception: None

23:23:39 job_callback for (8, 0, 20) started
23:23:39 job_callback for (8, 0, 20) got condition
23:23:39 DISPATCHER: Trying to submit another job.
23:23:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:23:40 HBMASTER: Trying to run another job!
23:23:40 job_callback for (8, 0, 20) finished
23:23:40 HBMASTER: schedule new run for iteration 8
23:23:40 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
23:23:40 HBMASTER: submitting job (8, 0, 25) to dispatcher
23:23:40 DISPATCHER: trying to submit job (8, 0, 25)
23:23:40 DISPATCHER: trying to notify the job_runner thread.
23:23:40 HBMASTER: job (8, 0, 25) submitted to dispatcher
23:23:40 DISPATCHER: Trying to submit another job.
23:23:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:23:40 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:23:40 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:23:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:23:40 WORKER: start processing job (8, 0, 25)
23:23:40 WORKER: args: ()
23:23:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}, 'budget': 400.0, 'working_directory': '.'}
23:24:10 DISPATCHER: Starting worker discovery
23:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:10 DISPATCHER: Finished worker discovery
23:25:10 DISPATCHER: Starting worker discovery
23:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:10 DISPATCHER: Finished worker discovery
23:26:10 DISPATCHER: Starting worker discovery
23:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:10 DISPATCHER: Finished worker discovery
23:27:10 DISPATCHER: Starting worker discovery
23:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:10 DISPATCHER: Finished worker discovery
23:28:10 DISPATCHER: Starting worker discovery
23:28:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:10 DISPATCHER: Finished worker discovery
23:29:10 DISPATCHER: Starting worker discovery
23:29:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:10 DISPATCHER: Finished worker discovery
23:30:10 DISPATCHER: Starting worker discovery
23:30:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:10 DISPATCHER: Finished worker discovery
23:30:41 WORKER: done with job (8, 0, 25), trying to register it.
23:30:41 WORKER: registered result for job (8, 0, 25) with dispatcher
23:30:41 DISPATCHER: job (8, 0, 25) finished
23:30:41 DISPATCHER: register_result: lock acquired
23:30:41 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:30:41 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9035592653430391, 'info': {'number_mnist': 0.9035592653430391, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014586437339343665, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01775828273654856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 75}"}}
exception: None

23:30:41 job_callback for (8, 0, 25) started
23:30:41 DISPATCHER: Trying to submit another job.
23:30:41 job_callback for (8, 0, 25) got condition
23:30:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:30:41 HBMASTER: Trying to run another job!
23:30:41 job_callback for (8, 0, 25) finished
23:30:41 ITERATION: Advancing config (8, 0, 8) to next budget 1200.000000
23:30:41 HBMASTER: schedule new run for iteration 8
23:30:41 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
23:30:41 HBMASTER: submitting job (8, 0, 8) to dispatcher
23:30:41 DISPATCHER: trying to submit job (8, 0, 8)
23:30:41 DISPATCHER: trying to notify the job_runner thread.
23:30:41 HBMASTER: job (8, 0, 8) submitted to dispatcher
23:30:41 DISPATCHER: Trying to submit another job.
23:30:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:30:41 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:30:41 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:30:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:30:41 WORKER: start processing job (8, 0, 8)
23:30:41 WORKER: args: ()
23:30:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 1200.0, 'working_directory': '.'}
23:31:10 DISPATCHER: Starting worker discovery
23:31:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:10 DISPATCHER: Finished worker discovery
23:32:10 DISPATCHER: Starting worker discovery
23:32:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:10 DISPATCHER: Finished worker discovery
23:33:10 DISPATCHER: Starting worker discovery
23:33:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:10 DISPATCHER: Finished worker discovery
23:34:10 DISPATCHER: Starting worker discovery
23:34:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:10 DISPATCHER: Finished worker discovery
23:35:10 DISPATCHER: Starting worker discovery
23:35:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:10 DISPATCHER: Finished worker discovery
23:36:10 DISPATCHER: Starting worker discovery
23:36:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:10 DISPATCHER: Finished worker discovery
23:37:10 DISPATCHER: Starting worker discovery
23:37:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:10 DISPATCHER: Finished worker discovery
23:38:10 DISPATCHER: Starting worker discovery
23:38:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:10 DISPATCHER: Finished worker discovery
23:39:10 DISPATCHER: Starting worker discovery
23:39:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:10 DISPATCHER: Finished worker discovery
23:40:10 DISPATCHER: Starting worker discovery
23:40:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:10 DISPATCHER: Finished worker discovery
23:41:10 DISPATCHER: Starting worker discovery
23:41:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:10 DISPATCHER: Finished worker discovery
23:42:10 DISPATCHER: Starting worker discovery
23:42:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:10 DISPATCHER: Finished worker discovery
23:43:10 DISPATCHER: Starting worker discovery
23:43:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:10 DISPATCHER: Finished worker discovery
23:44:10 DISPATCHER: Starting worker discovery
23:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:11 DISPATCHER: Finished worker discovery
23:45:11 DISPATCHER: Starting worker discovery
23:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:11 DISPATCHER: Finished worker discovery
23:46:11 DISPATCHER: Starting worker discovery
23:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:11 DISPATCHER: Finished worker discovery
23:47:11 DISPATCHER: Starting worker discovery
23:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:11 DISPATCHER: Finished worker discovery
23:48:11 DISPATCHER: Starting worker discovery
23:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:11 DISPATCHER: Finished worker discovery
23:49:11 DISPATCHER: Starting worker discovery
23:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:11 DISPATCHER: Finished worker discovery
23:50:11 DISPATCHER: Starting worker discovery
23:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:11 DISPATCHER: Finished worker discovery
23:51:02 WORKER: done with job (8, 0, 8), trying to register it.
23:51:02 WORKER: registered result for job (8, 0, 8) with dispatcher
23:51:02 DISPATCHER: job (8, 0, 8) finished
23:51:02 DISPATCHER: register_result: lock acquired
23:51:02 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:51:02 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.947599050077542, 'info': {'number_mnist': 0.947599050077542, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0069594628346003355, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011854550876696669, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 23, 'num_filters_4': 49}"}}
exception: None

23:51:02 job_callback for (8, 0, 8) started
23:51:02 job_callback for (8, 0, 8) got condition
23:51:02 DISPATCHER: Trying to submit another job.
23:51:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:51:02 HBMASTER: Trying to run another job!
23:51:02 job_callback for (8, 0, 8) finished
23:51:02 start sampling a new configuration.
23:51:02 best_vector: [2, 2, 0.8432787482444449, 0.4320035697509538, 0.05151709851813979, 0, 0.4971834728687462, 0.06295966791567989, 1, 2, 1, 1, 0.33458072810525824, 0.0555299045523483, 0.5237902516360055, 0.24488481286018518], 2.811573636881782e-33, 3.5567270473807153, nan
23:51:02 done sampling a new configuration.
23:51:02 HBMASTER: schedule new run for iteration 9
23:51:02 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
23:51:02 HBMASTER: submitting job (9, 0, 0) to dispatcher
23:51:02 DISPATCHER: trying to submit job (9, 0, 0)
23:51:02 DISPATCHER: trying to notify the job_runner thread.
23:51:02 HBMASTER: job (9, 0, 0) submitted to dispatcher
23:51:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:51:02 DISPATCHER: Trying to submit another job.
23:51:02 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:51:02 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:51:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:51:02 WORKER: start processing job (9, 0, 0)
23:51:02 WORKER: args: ()
23:51:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04859118568212979, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012075702816396697}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:51:11 DISPATCHER: Starting worker discovery
23:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:11 DISPATCHER: Finished worker discovery
23:52:11 DISPATCHER: Starting worker discovery
23:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:11 DISPATCHER: Finished worker discovery
23:53:11 DISPATCHER: Starting worker discovery
23:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:11 DISPATCHER: Finished worker discovery
23:53:26 WORKER: done with job (9, 0, 0), trying to register it.
23:53:26 WORKER: registered result for job (9, 0, 0) with dispatcher
23:53:26 DISPATCHER: job (9, 0, 0) finished
23:53:26 DISPATCHER: register_result: lock acquired
23:53:26 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:53:26 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04859118568212979, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012075702816396697}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4012909384325227, 'info': {'number_mnist': 0.4012909384325227, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04859118568212979, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.012075702816396697}"}}
exception: None

23:53:26 job_callback for (9, 0, 0) started
23:53:26 DISPATCHER: Trying to submit another job.
23:53:26 job_callback for (9, 0, 0) got condition
23:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:53:26 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.955368





23:53:26 HBMASTER: Trying to run another job!
23:53:26 job_callback for (9, 0, 0) finished
23:53:26 start sampling a new configuration.
23:53:26 done sampling a new configuration.
23:53:26 HBMASTER: schedule new run for iteration 9
23:53:26 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
23:53:26 HBMASTER: submitting job (9, 0, 1) to dispatcher
23:53:26 DISPATCHER: trying to submit job (9, 0, 1)
23:53:26 DISPATCHER: trying to notify the job_runner thread.
23:53:26 HBMASTER: job (9, 0, 1) submitted to dispatcher
23:53:26 DISPATCHER: Trying to submit another job.
23:53:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:53:26 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:53:26 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:53:26 WORKER: start processing job (9, 0, 1)
23:53:26 WORKER: args: ()
23:53:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07399912645361979, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.04003691373408922, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 81, 'num_filters_4': 118, 'num_filters_5': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:54:11 DISPATCHER: Starting worker discovery
23:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:11 DISPATCHER: Finished worker discovery
23:55:11 DISPATCHER: Starting worker discovery
23:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:11 DISPATCHER: Finished worker discovery
23:55:49 WORKER: done with job (9, 0, 1), trying to register it.
23:55:49 WORKER: registered result for job (9, 0, 1) with dispatcher
23:55:49 DISPATCHER: job (9, 0, 1) finished
23:55:49 DISPATCHER: register_result: lock acquired
23:55:49 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:55:49 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07399912645361979, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.04003691373408922, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 81, 'num_filters_4': 118, 'num_filters_5': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07399912645361979, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.04003691373408922, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 81, 'num_filters_4': 118, 'num_filters_5': 59}"}}
exception: None

23:55:49 job_callback for (9, 0, 1) started
23:55:49 DISPATCHER: Trying to submit another job.
23:55:49 job_callback for (9, 0, 1) got condition
23:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:55:49 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.955368





23:55:49 HBMASTER: Trying to run another job!
23:55:49 job_callback for (9, 0, 1) finished
23:55:49 start sampling a new configuration.
23:55:49 done sampling a new configuration.
23:55:49 HBMASTER: schedule new run for iteration 9
23:55:49 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
23:55:49 HBMASTER: submitting job (9, 0, 2) to dispatcher
23:55:49 DISPATCHER: trying to submit job (9, 0, 2)
23:55:49 DISPATCHER: trying to notify the job_runner thread.
23:55:49 HBMASTER: job (9, 0, 2) submitted to dispatcher
23:55:49 DISPATCHER: Trying to submit another job.
23:55:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:55:49 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:55:49 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:55:49 WORKER: start processing job (9, 0, 2)
23:55:49 WORKER: args: ()
23:55:49 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0793970293902936, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.049855949077898504, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:56:11 DISPATCHER: Starting worker discovery
23:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:11 DISPATCHER: Finished worker discovery
23:57:11 DISPATCHER: Starting worker discovery
23:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:11 DISPATCHER: Finished worker discovery
23:58:11 DISPATCHER: Starting worker discovery
23:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:11 DISPATCHER: Finished worker discovery
23:58:14 WORKER: done with job (9, 0, 2), trying to register it.
23:58:14 WORKER: registered result for job (9, 0, 2) with dispatcher
23:58:14 DISPATCHER: job (9, 0, 2) finished
23:58:14 DISPATCHER: register_result: lock acquired
23:58:14 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
23:58:14 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0793970293902936, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.049855949077898504, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.002031258805629709, 'info': {'number_mnist': 0.002031258805629709, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0793970293902936, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.049855949077898504, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 31}"}}
exception: None

23:58:14 job_callback for (9, 0, 2) started
23:58:14 DISPATCHER: Trying to submit another job.
23:58:14 job_callback for (9, 0, 2) got condition
23:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:58:14 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.955368





23:58:14 HBMASTER: Trying to run another job!
23:58:14 job_callback for (9, 0, 2) finished
23:58:14 start sampling a new configuration.
23:58:14 best_vector: [3, 2, 0.6077989763782105, 0.8081763825551352, 0.3686819884999097, 0, 0.9813162624515408, 0.16605156393413684, 1, 2, 2, 1, 0.31422626503952944, 0.23697362434976182, 0.7415896898143831, 0.24404786621042127], 5.389422838500241e-32, 0.1855486255144676, -2.081738184472827e-05
23:58:14 done sampling a new configuration.
23:58:14 HBMASTER: schedule new run for iteration 9
23:58:14 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
23:58:14 HBMASTER: submitting job (9, 0, 3) to dispatcher
23:58:14 DISPATCHER: trying to submit job (9, 0, 3)
23:58:14 DISPATCHER: trying to notify the job_runner thread.
23:58:14 HBMASTER: job (9, 0, 3) submitted to dispatcher
23:58:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:58:14 DISPATCHER: Trying to submit another job.
23:58:14 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
23:58:14 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
23:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:58:14 WORKER: start processing job (9, 0, 3)
23:58:14 WORKER: args: ()
23:58:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016428501538013538, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.01644515857175321, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:59:11 DISPATCHER: Starting worker discovery
23:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:11 DISPATCHER: Finished worker discovery
00:00:11 DISPATCHER: Starting worker discovery
00:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:11 DISPATCHER: Finished worker discovery
00:00:39 WORKER: done with job (9, 0, 3), trying to register it.
00:00:39 WORKER: registered result for job (9, 0, 3) with dispatcher
00:00:39 DISPATCHER: job (9, 0, 3) finished
00:00:39 DISPATCHER: register_result: lock acquired
00:00:39 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:00:39 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016428501538013538, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.01644515857175321, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7975291889469046, 'info': {'number_mnist': 0.7975291889469046, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016428501538013538, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.01644515857175321, 'kernel_size_2': 5, 'num_filters_2': 30}"}}
exception: None

00:00:39 job_callback for (9, 0, 3) started
00:00:39 job_callback for (9, 0, 3) got condition
00:00:39 DISPATCHER: Trying to submit another job.
00:00:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:00:39 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.955368





00:00:39 HBMASTER: Trying to run another job!
00:00:39 job_callback for (9, 0, 3) finished
00:00:39 start sampling a new configuration.
00:00:39 done sampling a new configuration.
00:00:39 HBMASTER: schedule new run for iteration 9
00:00:39 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
00:00:39 HBMASTER: submitting job (9, 0, 4) to dispatcher
00:00:39 DISPATCHER: trying to submit job (9, 0, 4)
00:00:39 DISPATCHER: trying to notify the job_runner thread.
00:00:39 HBMASTER: job (9, 0, 4) submitted to dispatcher
00:00:39 DISPATCHER: Trying to submit another job.
00:00:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:00:39 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:00:39 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:00:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:00:39 WORKER: start processing job (9, 0, 4)
00:00:39 WORKER: args: ()
00:00:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05497344997631607, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04400392740098392}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:01:11 DISPATCHER: Starting worker discovery
00:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:11 DISPATCHER: Finished worker discovery
00:02:11 DISPATCHER: Starting worker discovery
00:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:11 DISPATCHER: Finished worker discovery
00:03:02 WORKER: done with job (9, 0, 4), trying to register it.
00:03:02 WORKER: registered result for job (9, 0, 4) with dispatcher
00:03:02 DISPATCHER: job (9, 0, 4) finished
00:03:02 DISPATCHER: register_result: lock acquired
00:03:02 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:03:02 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05497344997631607, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04400392740098392}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7766209594952851, 'info': {'number_mnist': 0.7766209594952851, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05497344997631607, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.04400392740098392}"}}
exception: None

00:03:02 job_callback for (9, 0, 4) started
00:03:02 DISPATCHER: Trying to submit another job.
00:03:02 job_callback for (9, 0, 4) got condition
00:03:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:03:02 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.955368





00:03:02 HBMASTER: Trying to run another job!
00:03:02 job_callback for (9, 0, 4) finished
00:03:02 start sampling a new configuration.
00:03:03 sampled vector: [0, 2, 0.24125918061741097, 0.37233733670875563, 0.49267216113510276, 1, 0.8293847848331403, 0.15849081866377096, 2, 2, 1, 2, 0.1947761727891485, 0.5839107500071039, 0.006742753178352712, 0.24386194487824703] has EI value nan
00:03:03 data in the KDEs:
[[3.00000000e+00 2.00000000e+00 2.32660268e-01 7.12809330e-01
  5.00000000e-01 0.00000000e+00 6.97802241e-01 4.41998590e-02
  2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  7.06973316e-02 8.71891227e-01 5.14305148e-01 2.44555229e-01]
 [3.00000000e+00 2.00000000e+00 2.90668065e-01 9.59697093e-01
  9.00001600e-01 1.00000000e+00 8.84615469e-01 1.66743694e-01
  1.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  5.44175724e-01 8.10134850e-01 1.65573138e-01 2.44555229e-01]
 [3.00000000e+00 1.00000000e+00 2.33440933e-01 9.67643389e-01
  2.99999200e-01 0.00000000e+00 8.62637442e-01 4.99763775e-02
  2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  4.93288642e-01 1.86589644e-01 5.24473143e-01 2.44555229e-01]
 [3.00000000e+00 0.00000000e+00 2.08378877e-01 8.26346502e-01
  9.99984000e-02 0.00000000e+00 8.73626456e-01 2.66618440e-03
  1.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  6.23899452e-01 4.82419346e-01 5.44175724e-01 2.44555229e-01]
 [0.00000000e+00 2.00000000e+00 5.44711336e-01 6.47742833e-01
  5.00000000e-01 1.00000000e+00 2.14285651e-01 4.88863885e-02
  1.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00
  4.93288642e-01 6.70441281e-01 1.65573138e-01 2.44555229e-01]
 [0.00000000e+00 1.00000000e+00 3.55445787e-01 6.70441281e-01
  7.00000800e-01 1.00000000e+00 4.45054933e-01 9.36068940e-02
  2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  5.53727433e-01 6.62995560e-01 5.72270733e-01 2.44555229e-01]
 [1.00000000e+00 2.00000000e+00 4.07957309e-01 8.26346502e-01
  7.00000800e-01 1.00000000e+00 7.85714349e-01 3.10276036e-02
  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.86589644e-01 7.87616617e-01 4.82419346e-01 2.44555229e-01]
 [2.00000000e+00 0.00000000e+00 4.21287860e-01 8.26346502e-01
  7.00000800e-01 1.00000000e+00 7.74725335e-01 5.67897013e-02
  2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  2.26011930e-01 1.86589644e-01 5.44175724e-01 2.44555229e-01]
 [2.00000000e+00 0.00000000e+00 2.28100670e-01 6.70441281e-01
  5.00000000e-01 1.00000000e+00 7.85714349e-01 1.22498808e-02
  1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  2.06711555e-01 6.99104210e-01 4.82419346e-01 2.44555229e-01]
 [1.00000000e+00 1.00000000e+00 5.81974615e-01 6.23899452e-01
  5.00000000e-01 1.00000000e+00 3.68131839e-01 1.91695016e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  7.51690971e-01 7.45428714e-01 5.44175724e-01 2.44555229e-01]
 [1.00000000e+00 2.00000000e+00 4.50957440e-01 5.03913663e-01
  2.99999200e-01 1.00000000e+00 4.89010987e-01 5.89367869e-02
  1.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  6.47742833e-01 8.71891227e-01 5.72270733e-01 2.44555229e-01]
 [1.00000000e+00 2.00000000e+00 6.49346602e-01 7.57871367e-01
  7.00000800e-01 1.00000000e+00 6.53846188e-01 8.52238702e-02
  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  4.23975468e-01 4.93288642e-01 5.14305148e-01 2.44555229e-01]
 [0.00000000e+00 0.00000000e+00 3.24383589e-01 5.03913663e-01
  7.00000800e-01 1.00000000e+00 1.81318611e-01 5.15075264e-02
  2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  7.45428714e-01 1.86589644e-01 5.24473143e-01 2.44555229e-01]
 [2.00000000e+00 2.00000000e+00 3.86005135e-01 8.36853457e-01
  5.00000000e-01 1.00000000e+00 4.45054933e-01 7.88644668e-02
  1.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  6.23899452e-01 4.82419346e-01 4.82419346e-01 2.44555229e-01]
 [3.00000000e+00 0.00000000e+00 6.00406728e-01 5.53727433e-01
  5.00000000e-01 1.00000000e+00 5.10989013e-01 2.21933135e-01
  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00
  5.03913663e-01 8.15600732e-01 5.44175724e-01 2.44555229e-01]
 [0.00000000e+00 1.00000000e+00 7.31659575e-01 5.72270733e-01
  5.00000000e-01 1.00000000e+00 6.09890134e-01 1.97672623e-01
  2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  6.15676748e-01 6.99104210e-01 5.72270733e-01 2.44555229e-01]
 [3.00000000e+00 2.00000000e+00 5.52232653e-01 3.98412835e-01
  2.99999200e-01 1.00000000e+00 3.57142826e-01 2.27102709e-02
  0.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00
  5.24473143e-01 1.86589644e-01 5.24473143e-01 2.44555229e-01]]
[[3.         0.         0.33168694 0.63992789 0.2999992  1.
  0.77472534 0.07359632 0.         2.         0.         2.
  0.35727442 0.20671155 0.09625996 0.16557314]
 [0.         0.         0.33793977 0.48241935 0.2999992  1.
  0.63186816 0.03432036 2.         1.         0.         0.
  0.51430515 0.09625996 0.14357878 0.63198159]
 [2.         1.         0.15957153 0.69910421 0.5        1.
  0.42307691 0.05062733 0.         2.         0.         2.
  0.76397201 0.09625996 0.61567675 0.16557314]
 [2.         2.         0.75811463 0.53442706 0.5        1.
  0.87362646 0.13405283 1.         2.         2.         0.
  0.59011412 0.67777156 0.95969709 0.63198159]
 [2.         2.         0.51896975 0.62389945 0.5        1.
  0.3351648  0.13884513 1.         2.         0.         2.
  0.3277152  0.31221238 0.14357878 0.16557314]
 [0.         0.         0.17167286 0.55372743 0.7000008  1.
  0.88461547 0.14428303 2.         1.         0.         2.
  0.0436732  0.66299556 0.38509383 0.16557314]
 [0.         0.         0.66043212 0.79334752 0.0999984  1.
  0.40109888 0.05430938 1.         1.         0.         2.
  0.48241935 0.66299556 0.38509383 0.16557314]
 [2.         0.         0.60516968 0.53442706 0.7000008  1.
  0.29120875 0.10883805 2.         2.         0.         0.
  0.88614739 0.42397547 0.61567675 0.63198159]
 [3.         1.         0.38316241 0.89541815 0.0999984  1.
  0.32417579 0.00564795 2.         2.         2.         0.
  0.78761662 0.7818154  0.95969709 0.63198159]
 [0.         2.         0.34296999 0.53442706 0.0999984  1.
  0.22527466 0.04507563 0.         2.         0.         2.
  0.01501027 0.3277152  0.14357878 0.16557314]
 [0.         1.         0.17101111 0.81013485 0.9000016  1.
  0.55494507 0.36923936 1.         1.         2.         2.
  0.07069733 0.93502401 0.57227073 0.16557314]
 [0.         0.         0.00833216 0.63992789 0.7000008  0.
  0.84065942 0.16163873 1.         1.         0.         0.
  0.8263465  0.09625996 0.14357878 0.63198159]
 [2.         0.         0.22325579 0.86214256 0.2999992  1.
  0.74175829 0.01557738 1.         1.         2.         2.
  0.26239861 0.93502401 0.57227073 0.16557314]
 [0.         0.         0.50560909 0.47129428 0.2999992  1.
  0.37912085 0.27144174 1.         0.         1.         2.
  0.24455523 0.279593   0.51430515 0.16557314]
 [3.         0.         0.72887943 0.54417572 0.0999984  1.
  0.11538453 0.03050602 0.         0.         1.         2.
  0.41136689 0.49328864 0.51430515 0.16557314]
 [2.         1.         0.37337223 0.68498992 0.0999984  1.
  0.53296704 0.09416608 2.         1.         0.         2.
  0.07069733 0.09625996 0.14357878 0.16557314]
 [3.         0.         0.32766913 0.9089921  0.0999984  1.
  0.81868139 0.27146969 1.         2.         1.         0.
  0.59011412 0.67777156 0.51430515 0.63198159]
 [1.         2.         0.25121242 0.88144294 0.0999984  1.
  0.87362646 0.29157    1.         1.         0.         0.
  0.8263465  0.09625996 0.14357878 0.63198159]
 [0.         1.         0.38401913 0.99444858 0.5        1.
  0.06043946 0.17105751 1.         0.         0.         0.
  0.83162917 0.24455523 0.61567675 0.63198159]
 [3.         2.         0.09999673 0.26239861 0.5        0.
  0.43406592 0.66679074 0.         0.         0.         0.
  0.18658964 0.279593   0.61567675 0.63198159]
 [1.         0.         0.19452921 0.64774283 0.0999984  1.
  0.69780224 0.18506466 1.         2.         2.         2.
  0.59011412 0.67777156 0.57227073 0.16557314]
 [2.         0.         0.57316954 0.18658964 0.2999992  1.
  0.0934065  0.24439124 2.         2.         2.         0.
  0.07069733 0.31221238 0.95969709 0.63198159]
 [2.         1.         0.33937902 0.95567329 0.7000008  1.
  0.10439552 0.2764665  0.         2.         0.         0.
  0.84713198 0.20671155 0.09625996 0.63198159]
 [3.         2.         0.65756038 0.69209973 0.2999992  1.
  0.37912085 0.52399502 2.         2.         0.         2.
  0.78761662 0.09625996 0.38509383 0.16557314]
 [3.         2.         0.60779898 0.81013485 0.2999992  0.
  0.98351659 0.16605156 1.         1.         2.         2.
  0.31221238 0.93502401 0.57227073 0.16557314]
 [2.         2.         0.8700765  0.67044128 0.0999984  1.
  0.9065935  0.49460154 1.         1.         2.         2.
  0.48241935 0.93502401 0.57227073 0.16557314]
 [2.         2.         0.08423611 0.43625651 0.0999984  1.
  0.80769238 0.16951648 1.         2.         0.         2.
  0.26239861 0.09625996 0.14357878 0.16557314]
 [0.         1.         0.44340258 0.62389945 0.7000008  1.
  0.56593408 0.23357445 0.         0.         1.         0.
  0.41136689 0.49328864 0.51430515 0.63198159]
 [0.         2.         0.58337412 0.56308999 0.0999984  1.
  0.86263744 0.75117677 1.         1.         0.         0.
  0.8263465  0.09625996 0.14357878 0.63198159]
 [2.         2.         0.84327875 0.43625651 0.0999984  0.
  0.5        0.06295967 2.         2.         2.         0.
  0.07069733 0.67777156 0.95969709 0.63198159]
 [3.         0.         0.72836202 0.16557314 0.2999992  0.
  0.57692309 0.22053326 1.         0.         1.         2.
  0.48241935 0.279593   0.51430515 0.16557314]
 [3.         0.         0.94990213 0.16557314 0.5        0.
  0.55494507 0.53628048 0.         2.         0.         0.
  0.01501027 0.3277152  0.61567675 0.63198159]
 [1.         0.         0.9346133  0.49328864 0.9000016  0.
  0.46703296 0.46306434 1.         2.         2.         0.
  0.77594211 0.7818154  0.95969709 0.63198159]]
00:03:03 bandwidth of the KDEs:
[1.09042931e+00 7.87956837e-01 1.45488920e-01 1.45453365e-01
 1.77187723e-01 3.50718878e-01 2.04259692e-01 6.11988940e-02
 6.97250030e-01 4.39649381e-01 5.92823104e-01 1.00000000e-03
 1.78547145e-01 2.27374755e-01 1.10957869e-01 1.00000000e-03]
[1.05144854 0.78256834 0.22809343 0.19275824 0.22551149 0.36383286
 0.23488609 0.16939211 0.61970242 0.67476632 0.79088885 0.88957112
 0.25752476 0.25790711 0.24583792 0.20745174]
00:03:03 l(x) = nan
00:03:03 g(x) = 0.0001125999228234793
00:03:03 best_vector: [0, 2, 0.3845669017368894, 0.4029101431492, 0.837649678188832, 1, 0.9280517792415794, 0.24130457763216118, 1, 0, 1, 1, 0.3136696116698906, 0.9930482973763528, 0.29103312085025473, 0.2433831536361225], 2.426111471661142e-31, 0.04121822149067647, -0.00018887981988940808
00:03:03 done sampling a new configuration.
00:03:03 HBMASTER: schedule new run for iteration 9
00:03:03 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
00:03:03 HBMASTER: submitting job (9, 0, 5) to dispatcher
00:03:03 DISPATCHER: trying to submit job (9, 0, 5)
00:03:03 DISPATCHER: trying to notify the job_runner thread.
00:03:03 HBMASTER: job (9, 0, 5) submitted to dispatcher
00:03:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:03:03 DISPATCHER: Trying to submit another job.
00:03:03 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:03:03 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:03:03 WORKER: start processing job (9, 0, 5)
00:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:03:03 WORKER: args: ()
00:03:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:03:11 DISPATCHER: Starting worker discovery
00:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:11 DISPATCHER: Finished worker discovery
00:04:11 DISPATCHER: Starting worker discovery
00:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:11 DISPATCHER: Finished worker discovery
00:05:11 DISPATCHER: Starting worker discovery
00:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:11 DISPATCHER: Finished worker discovery
00:05:26 WORKER: done with job (9, 0, 5), trying to register it.
00:05:26 WORKER: registered result for job (9, 0, 5) with dispatcher
00:05:26 DISPATCHER: job (9, 0, 5) finished
00:05:26 DISPATCHER: register_result: lock acquired
00:05:26 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:05:26 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9087343626184382, 'info': {'number_mnist': 0.9087343626184382, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}"}}
exception: None

00:05:26 job_callback for (9, 0, 5) started
00:05:26 DISPATCHER: Trying to submit another job.
00:05:26 job_callback for (9, 0, 5) got condition
00:05:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:05:26 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.955368





00:05:26 HBMASTER: Trying to run another job!
00:05:26 job_callback for (9, 0, 5) finished
00:05:26 start sampling a new configuration.
00:05:26 best_vector: [0, 2, 0.6654743508236862, 0.8035037946442954, 0.7935027654313896, 0, 0.6055778577102038, 0.21549963880558903, 2, 2, 0, 1, 0.3626664795889582, 0.9725951979492573, 0.8844525005637299, 0.24622472931625952], 2.2726753119756346e-30, 0.004400100598315124, -7.819925384398176e-06
00:05:26 done sampling a new configuration.
00:05:26 HBMASTER: schedule new run for iteration 9
00:05:26 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
00:05:26 HBMASTER: submitting job (9, 0, 6) to dispatcher
00:05:26 DISPATCHER: trying to submit job (9, 0, 6)
00:05:26 DISPATCHER: trying to notify the job_runner thread.
00:05:26 HBMASTER: job (9, 0, 6) submitted to dispatcher
00:05:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:05:26 DISPATCHER: Trying to submit another job.
00:05:26 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:05:26 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:05:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:05:26 WORKER: start processing job (9, 0, 6)
00:05:26 WORKER: args: ()
00:05:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021426375003547386, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.019070913404140657, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 33, 'num_filters_3': 121, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:06:11 DISPATCHER: Starting worker discovery
00:06:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:11 DISPATCHER: Finished worker discovery
00:07:11 DISPATCHER: Starting worker discovery
00:07:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:11 DISPATCHER: Finished worker discovery
00:07:49 WORKER: done with job (9, 0, 6), trying to register it.
00:07:49 WORKER: registered result for job (9, 0, 6) with dispatcher
00:07:49 DISPATCHER: job (9, 0, 6) finished
00:07:49 DISPATCHER: register_result: lock acquired
00:07:49 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:07:49 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021426375003547386, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.019070913404140657, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 33, 'num_filters_3': 121, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'number_mnist': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021426375003547386, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.019070913404140657, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 33, 'num_filters_3': 121, 'num_filters_4': 101}"}}
exception: None

00:07:49 job_callback for (9, 0, 6) started
00:07:49 DISPATCHER: Trying to submit another job.
00:07:49 job_callback for (9, 0, 6) got condition
00:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:49 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.955368





00:07:49 HBMASTER: Trying to run another job!
00:07:49 job_callback for (9, 0, 6) finished
00:07:49 start sampling a new configuration.
00:07:49 best_vector: [2, 1, 0.5881971646771013, 0.5105648427723406, 0.3263949675072487, 1, 0.753438445659325, 0.3531364747720253, 0, 0, 2, 1, 0.23798567894913453, 0.8642497964781792, 0.9430931894100081, 0.24261225387722854], 7.983372339065098e-31, 0.012526034832506713, -1.9022484690328107e-05
00:07:49 done sampling a new configuration.
00:07:49 HBMASTER: schedule new run for iteration 9
00:07:49 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:07:49 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:07:49 DISPATCHER: trying to submit job (9, 0, 7)
00:07:49 DISPATCHER: trying to notify the job_runner thread.
00:07:49 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:07:49 DISPATCHER: Trying to submit another job.
00:07:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:49 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:07:49 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:49 WORKER: start processing job (9, 0, 7)
00:07:49 WORKER: args: ()
00:07:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01501047133053124, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.028803226941289006, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:08:11 DISPATCHER: Starting worker discovery
00:08:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:11 DISPATCHER: Finished worker discovery
00:09:11 DISPATCHER: Starting worker discovery
00:09:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:11 DISPATCHER: Finished worker discovery
00:10:11 DISPATCHER: Starting worker discovery
00:10:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:11 DISPATCHER: Finished worker discovery
00:10:12 WORKER: done with job (9, 0, 7), trying to register it.
00:10:12 WORKER: registered result for job (9, 0, 7) with dispatcher
00:10:12 DISPATCHER: job (9, 0, 7) finished
00:10:12 DISPATCHER: register_result: lock acquired
00:10:12 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:10:12 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01501047133053124, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.028803226941289006, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8447441426865361, 'info': {'number_mnist': 0.8447441426865361, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01501047133053124, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.028803226941289006, 'kernel_size_2': 3, 'num_filters_2': 26}"}}
exception: None

00:10:12 job_callback for (9, 0, 7) started
00:10:12 DISPATCHER: Trying to submit another job.
00:10:12 job_callback for (9, 0, 7) got condition
00:10:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:10:12 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.955368





00:10:12 HBMASTER: Trying to run another job!
00:10:12 job_callback for (9, 0, 7) finished
00:10:12 start sampling a new configuration.
00:10:12 done sampling a new configuration.
00:10:12 HBMASTER: schedule new run for iteration 9
00:10:12 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
00:10:12 HBMASTER: submitting job (9, 0, 8) to dispatcher
00:10:12 DISPATCHER: trying to submit job (9, 0, 8)
00:10:12 DISPATCHER: trying to notify the job_runner thread.
00:10:12 HBMASTER: job (9, 0, 8) submitted to dispatcher
00:10:12 DISPATCHER: Trying to submit another job.
00:10:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:10:12 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:10:12 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:10:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:10:12 WORKER: start processing job (9, 0, 8)
00:10:12 WORKER: args: ()
00:10:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.045585809252396914, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.06496701636115107, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 98, 'num_filters_4': 49, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:11:11 DISPATCHER: Starting worker discovery
00:11:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:11 DISPATCHER: Finished worker discovery
00:12:11 DISPATCHER: Starting worker discovery
00:12:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:11 DISPATCHER: Finished worker discovery
00:12:38 WORKER: done with job (9, 0, 8), trying to register it.
00:12:38 WORKER: registered result for job (9, 0, 8) with dispatcher
00:12:38 DISPATCHER: job (9, 0, 8) finished
00:12:38 DISPATCHER: register_result: lock acquired
00:12:38 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:12:38 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.045585809252396914, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.06496701636115107, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 98, 'num_filters_4': 49, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.494816933405298, 'info': {'number_mnist': 0.494816933405298, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.045585809252396914, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.06496701636115107, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 98, 'num_filters_4': 49, 'num_filters_5': 24}"}}
exception: None

00:12:38 job_callback for (9, 0, 8) started
00:12:38 DISPATCHER: Trying to submit another job.
00:12:38 job_callback for (9, 0, 8) got condition
00:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:12:38 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.955368





00:12:38 HBMASTER: Trying to run another job!
00:12:38 job_callback for (9, 0, 8) finished
00:12:38 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
00:12:38 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
00:12:38 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
00:12:38 HBMASTER: schedule new run for iteration 9
00:12:38 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
00:12:38 HBMASTER: submitting job (9, 0, 3) to dispatcher
00:12:38 DISPATCHER: trying to submit job (9, 0, 3)
00:12:38 DISPATCHER: trying to notify the job_runner thread.
00:12:38 HBMASTER: job (9, 0, 3) submitted to dispatcher
00:12:38 DISPATCHER: Trying to submit another job.
00:12:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:12:38 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:12:38 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:12:38 WORKER: start processing job (9, 0, 3)
00:12:38 WORKER: args: ()
00:12:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016428501538013538, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.01644515857175321, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 400.0, 'working_directory': '.'}
00:13:11 DISPATCHER: Starting worker discovery
00:13:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:11 DISPATCHER: Finished worker discovery
00:14:11 DISPATCHER: Starting worker discovery
00:14:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:11 DISPATCHER: Finished worker discovery
00:15:11 DISPATCHER: Starting worker discovery
00:15:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:11 DISPATCHER: Finished worker discovery
00:16:11 DISPATCHER: Starting worker discovery
00:16:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:11 DISPATCHER: Finished worker discovery
00:17:11 DISPATCHER: Starting worker discovery
00:17:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:11 DISPATCHER: Finished worker discovery
00:18:11 DISPATCHER: Starting worker discovery
00:18:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:11 DISPATCHER: Finished worker discovery
00:19:11 DISPATCHER: Starting worker discovery
00:19:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:11 DISPATCHER: Finished worker discovery
00:19:44 WORKER: done with job (9, 0, 3), trying to register it.
00:19:44 WORKER: registered result for job (9, 0, 3) with dispatcher
00:19:44 DISPATCHER: job (9, 0, 3) finished
00:19:44 DISPATCHER: register_result: lock acquired
00:19:44 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:19:44 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016428501538013538, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.01644515857175321, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8083030665148953, 'info': {'number_mnist': 0.8083030665148953, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016428501538013538, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.01644515857175321, 'kernel_size_2': 5, 'num_filters_2': 30}"}}
exception: None

00:19:44 job_callback for (9, 0, 3) started
00:19:44 DISPATCHER: Trying to submit another job.
00:19:44 job_callback for (9, 0, 3) got condition
00:19:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:45 HBMASTER: Trying to run another job!
00:19:45 job_callback for (9, 0, 3) finished
00:19:45 HBMASTER: schedule new run for iteration 9
00:19:45 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
00:19:45 HBMASTER: submitting job (9, 0, 5) to dispatcher
00:19:45 DISPATCHER: trying to submit job (9, 0, 5)
00:19:45 DISPATCHER: trying to notify the job_runner thread.
00:19:45 HBMASTER: job (9, 0, 5) submitted to dispatcher
00:19:45 DISPATCHER: Trying to submit another job.
00:19:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:45 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:19:45 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:19:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:45 WORKER: start processing job (9, 0, 5)
00:19:45 WORKER: args: ()
00:19:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
00:20:11 DISPATCHER: Starting worker discovery
00:20:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:11 DISPATCHER: Finished worker discovery
00:21:11 DISPATCHER: Starting worker discovery
00:21:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:11 DISPATCHER: Finished worker discovery
00:22:11 DISPATCHER: Starting worker discovery
00:22:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:11 DISPATCHER: Finished worker discovery
00:23:11 DISPATCHER: Starting worker discovery
00:23:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:11 DISPATCHER: Finished worker discovery
00:24:11 DISPATCHER: Starting worker discovery
00:24:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:11 DISPATCHER: Finished worker discovery
00:25:11 DISPATCHER: Starting worker discovery
00:25:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:11 DISPATCHER: Finished worker discovery
00:26:11 DISPATCHER: Starting worker discovery
00:26:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:11 DISPATCHER: Finished worker discovery
00:26:39 WORKER: done with job (9, 0, 5), trying to register it.
00:26:39 WORKER: registered result for job (9, 0, 5) with dispatcher
00:26:39 DISPATCHER: job (9, 0, 5) finished
00:26:39 DISPATCHER: register_result: lock acquired
00:26:39 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:26:39 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9167018007571679, 'info': {'number_mnist': 0.9167018007571679, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}"}}
exception: None

00:26:39 job_callback for (9, 0, 5) started
00:26:39 DISPATCHER: Trying to submit another job.
00:26:39 job_callback for (9, 0, 5) got condition
00:26:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:26:39 HBMASTER: Trying to run another job!
00:26:39 job_callback for (9, 0, 5) finished
00:26:39 HBMASTER: schedule new run for iteration 9
00:26:39 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:26:39 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:26:39 DISPATCHER: trying to submit job (9, 0, 7)
00:26:39 DISPATCHER: trying to notify the job_runner thread.
00:26:39 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:26:39 DISPATCHER: Trying to submit another job.
00:26:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:26:39 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:26:39 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:26:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:26:39 WORKER: start processing job (9, 0, 7)
00:26:39 WORKER: args: ()
00:26:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01501047133053124, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.028803226941289006, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 400.0, 'working_directory': '.'}
00:27:11 DISPATCHER: Starting worker discovery
00:27:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:11 DISPATCHER: Finished worker discovery
00:28:11 DISPATCHER: Starting worker discovery
00:28:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:11 DISPATCHER: Finished worker discovery
00:29:11 DISPATCHER: Starting worker discovery
00:29:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:11 DISPATCHER: Finished worker discovery
00:30:11 DISPATCHER: Starting worker discovery
00:30:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:11 DISPATCHER: Finished worker discovery
00:31:11 DISPATCHER: Starting worker discovery
00:31:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:12 DISPATCHER: Finished worker discovery
00:32:12 DISPATCHER: Starting worker discovery
00:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:12 DISPATCHER: Finished worker discovery
00:33:12 DISPATCHER: Starting worker discovery
00:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:12 DISPATCHER: Finished worker discovery
00:33:33 WORKER: done with job (9, 0, 7), trying to register it.
00:33:33 WORKER: registered result for job (9, 0, 7) with dispatcher
00:33:33 DISPATCHER: job (9, 0, 7) finished
00:33:33 DISPATCHER: register_result: lock acquired
00:33:33 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:33:33 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01501047133053124, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.028803226941289006, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8704718525228912, 'info': {'number_mnist': 0.8704718525228912, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01501047133053124, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.028803226941289006, 'kernel_size_2': 3, 'num_filters_2': 26}"}}
exception: None

00:33:33 job_callback for (9, 0, 7) started
00:33:33 DISPATCHER: Trying to submit another job.
00:33:33 job_callback for (9, 0, 7) got condition
00:33:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:33:33 HBMASTER: Trying to run another job!
00:33:33 job_callback for (9, 0, 7) finished
00:33:33 ITERATION: Advancing config (9, 0, 5) to next budget 1200.000000
00:33:33 HBMASTER: schedule new run for iteration 9
00:33:33 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
00:33:33 HBMASTER: submitting job (9, 0, 5) to dispatcher
00:33:33 DISPATCHER: trying to submit job (9, 0, 5)
00:33:33 DISPATCHER: trying to notify the job_runner thread.
00:33:33 HBMASTER: job (9, 0, 5) submitted to dispatcher
00:33:33 DISPATCHER: Trying to submit another job.
00:33:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:33:33 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376
00:33:33 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.29881140179544557376
00:33:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:33:33 WORKER: start processing job (9, 0, 5)
00:33:33 WORKER: args: ()
00:33:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}, 'budget': 1200.0, 'working_directory': '.'}
00:34:12 DISPATCHER: Starting worker discovery
00:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:12 DISPATCHER: Finished worker discovery
00:35:12 DISPATCHER: Starting worker discovery
00:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:12 DISPATCHER: Finished worker discovery
00:36:12 DISPATCHER: Starting worker discovery
00:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:12 DISPATCHER: Finished worker discovery
00:37:12 DISPATCHER: Starting worker discovery
00:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:12 DISPATCHER: Finished worker discovery
00:38:12 DISPATCHER: Starting worker discovery
00:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:12 DISPATCHER: Finished worker discovery
00:39:12 DISPATCHER: Starting worker discovery
00:39:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:12 DISPATCHER: Finished worker discovery
00:40:12 DISPATCHER: Starting worker discovery
00:40:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:12 DISPATCHER: Finished worker discovery
00:41:12 DISPATCHER: Starting worker discovery
00:41:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:12 DISPATCHER: Finished worker discovery
00:42:12 DISPATCHER: Starting worker discovery
00:42:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:12 DISPATCHER: Finished worker discovery
00:43:12 DISPATCHER: Starting worker discovery
00:43:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:12 DISPATCHER: Finished worker discovery
00:44:12 DISPATCHER: Starting worker discovery
00:44:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:12 DISPATCHER: Finished worker discovery
00:45:12 DISPATCHER: Starting worker discovery
00:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:12 DISPATCHER: Finished worker discovery
00:46:12 DISPATCHER: Starting worker discovery
00:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:12 DISPATCHER: Finished worker discovery
00:47:12 DISPATCHER: Starting worker discovery
00:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:12 DISPATCHER: Finished worker discovery
00:48:12 DISPATCHER: Starting worker discovery
00:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:12 DISPATCHER: Finished worker discovery
00:49:12 DISPATCHER: Starting worker discovery
00:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:12 DISPATCHER: Finished worker discovery
00:50:12 DISPATCHER: Starting worker discovery
00:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:12 DISPATCHER: Finished worker discovery
00:51:12 DISPATCHER: Starting worker discovery
00:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:12 DISPATCHER: Finished worker discovery
00:52:12 DISPATCHER: Starting worker discovery
00:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:12 DISPATCHER: Finished worker discovery
00:53:12 DISPATCHER: Starting worker discovery
00:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:12 DISPATCHER: Finished worker discovery
00:53:57 WORKER: done with job (9, 0, 5), trying to register it.
00:53:57 WORKER: registered result for job (9, 0, 5) with dispatcher
00:53:57 DISPATCHER: job (9, 0, 5) finished
00:53:57 DISPATCHER: register_result: lock acquired
00:53:57 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.29881140179544557376 finished
00:53:57 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9077472904223409, 'info': {'number_mnist': 0.9077472904223409, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005876703822919228, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.020603665646351504, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 127, 'num_filters_4': 29, 'num_filters_5': 26}"}}
exception: None

00:53:57 job_callback for (9, 0, 5) started
00:53:57 job_callback for (9, 0, 5) got condition
00:53:57 DISPATCHER: Trying to submit another job.
00:53:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:57 HBMASTER: Trying to run another job!
00:53:57 job_callback for (9, 0, 5) finished
00:53:57 HBMASTER: shutdown initiated, shutdown_workers = True
00:53:57 WORKER: shutting down now!
00:53:57 DISPATCHER: Dispatcher shutting down
00:53:57 DISPATCHER: discover_workers shutting down
00:53:57 DISPATCHER: Trying to submit another job.
00:53:57 DISPATCHER: 'discover_worker' thread exited
00:53:57 DISPATCHER: job_runner shutting down
00:53:57 DISPATCHER: 'job_runner' thread exited
00:53:57 DISPATCHER: shut down complete
